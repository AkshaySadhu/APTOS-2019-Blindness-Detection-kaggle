{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggerDf = Logger('LOGS.csv', mode='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def show_diff(text, n_text):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/788780\n",
    "    Unify operations between two compared strings seqm is a difflib.\n",
    "    SequenceMatcher instance whose a & b are strings\n",
    "    \"\"\"\n",
    "    seqm = difflib.SequenceMatcher(None, text, n_text)\n",
    "    output= []\n",
    "    for opcode, a0, a1, b0, b1 in seqm.get_opcodes():\n",
    "        if opcode == 'equal':\n",
    "            output.append(seqm.a[a0:a1])\n",
    "        elif opcode == 'insert':\n",
    "            output.append(\"<font color=red>^\" + seqm.b[b0:b1] + \"</font>\")\n",
    "        elif opcode == 'delete':\n",
    "            output.append(\"<font color=blue>^\" + seqm.a[a0:a1] + \"</font>\")\n",
    "        elif opcode == 'replace':\n",
    "            # seqm.a[a0:a1] -> seqm.b[b0:b1]\n",
    "            output.append(\"<font color=green>^\" + seqm.b[b0:b1] + \"</font>\")\n",
    "        else:\n",
    "            raise RuntimeError(\"unexpected opcode\")\n",
    "    return ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np # linear algebra\n",
      "import pandas as pd # data processing\n",
      "import matplotlib.pyplot as plt # Plotting\n",
      "import seaborn as sns # Plotting\n",
      "\n",
      "# Import Image Libraries - Pillow and OpenCV\n",
      "from PIL import Image\n",
      "import cv2\n",
      "\n",
      "# Import PyTorch and useful fuctions\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
      "import torchvision.transforms as transforms\n",
      "from torch.utils.data.sampler import SubsetRandomSampler\n",
      "import torchvision\n",
      "import torch.optim as optim\n",
      "import torchvision.models as models # Pre-Trained models\n",
      "\n",
      "\n",
      "# Import useful sklearn functions\n",
      "import sklearn\n",
      "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "\n",
      "import time\n",
      "from datetime import datetime\n",
      "from tqdm import tqdm_notebook\n",
      "\n",
      "import os\n",
      "import random\n",
      "\n",
      "# User-defined modules\n",
      "from train_dataset import transforms_train, transforms_valid, CreateDataset\n",
      "from config import Config\n",
      "\n",
      "from logger import Logger\n",
      "\n",
      "# Open source libs\n",
      "\n",
      "\n",
      "## GLOBAL CONSTANTS:\n",
      "\n",
      "\n",
      "\n",
      "def add_data_to_loggers(loggers_list, column_name, data):\n",
      "    loggers_list[0].add_data(column_name, data)\n",
      "    loggers_list[1].add_data(column_name, data)\n",
      "\n",
      "# FOR DETERMINISTIC RESLTS\n",
      "from config import seed_torch\n",
      "\n",
      "def __init_fn(worker_id):\n",
      "    np.random.seed(13 + worker_id)\n",
      "\n",
      "def main(batch_size, lr, p_horizontalflip, model_type, info):\n",
      "    ## CONFIG!\n",
      "    cfg = Config(batch_size=batch_size, lr=lr, p_horizontalflip=p_horizontalflip, model_type=model_type)\n",
      "\n",
      "    ## REPRODUCIBILITY\n",
      "    seed_torch(cfg.seed)\n",
      "\n",
      "\n",
      "    print(os.listdir(\"./input\"))\n",
      "    base_dir = \"./input\"\n",
      "\n",
      "    # Loading Data + EDA\n",
      "\n",
      "    train_new_csv = pd.read_csv('./input/train_new.csv')\n",
      "    train_old_csv = pd.read_csv('./input/train_old.csv')\n",
      "    train_csv = None\n",
      "    train_path = None\n",
      "    if cfg.data_type == 'new_old_mixed':\n",
      "        train_csv = pd.concat([train_new_csv, train_old_csv], axis=0)\n",
      "        train_path = './input/train_mixed_images/'\n",
      "    elif cfg.data_type == 'new':\n",
      "        train_csv = train_new_csv\n",
      "        train_path = './input/train_new_images/'           #### NEED TO CHANGED IT!!!!!!!!!!!!!!!!!!!\n",
      "    elif cfg.data_type == 'old':\n",
      "        train_csv = train_old_csv\n",
      "        train_path = './input/train_old_images/'\n",
      "    elif cfg.data_type == 'new_old_mixed_ben_preprocessing':\n",
      "        train_csv = pd.concat([train_new_csv, train_old_csv], axis=0)\n",
      "        train_path = './input/train_mixed_BEN_preprocessing/'\n",
      "    elif cfg.data_type == 'new_old_balanced':\n",
      "        train_csv = pd.read_csv('./input/train_balanced.csv')\n",
      "        train_path = './input/train_mixed_images/'\n",
      "    test_csv = pd.read_csv('./input/test.csv')\n",
      "    print('Train Size = {}'.format(len(train_csv)))\n",
      "    print('Public Test Size = {}'.format(len(test_csv)))\n",
      "\n",
      "    counts = train_csv['diagnosis'].value_counts()\n",
      "    class_list = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferate']\n",
      "    for i, x in enumerate(class_list):\n",
      "        counts[x] = counts.pop(i)\n",
      "        print(\"{:^12} - class examples: {:^6}\".format(x, counts[x]))\n",
      "    print(\"Training path: {}\".format(train_path))\n",
      "    # Data Processing\n",
      "\n",
      "\n",
      "    ## SHUFFLE DATA\n",
      "    skf = None\n",
      "    # if cfg.valid_type == 'holdout':\n",
      "    train_csv, valid_csv = train_test_split(train_csv, test_size=cfg.valid_size,  shuffle=True,\n",
      "                                                                   random_state=cfg.seed, stratify=train_csv['diagnosis'])\n",
      "    # train_csv, valid_csv = train_test_split(train_csv, test_size=cfg.valid_size,  shuffle=True, random_state=cfg.seed, stratify=train_csv['diagnosis'])\n",
      "    train_data = CreateDataset(df_data=train_csv, data_dir=train_path, transform=transforms_train)\n",
      "    valid_data = CreateDataset(df_data=valid_csv, data_dir=train_path, transform=transforms_valid) # need to change It!!!!!\n",
      "    # elif cfg.valid_type == 'cv':\n",
      "    #     skf = StratifiedKFold(n_splits=cfg.n_folds, shuffle=True, random_state=cfg.seed)\n",
      "\n",
      "\n",
      "\n",
      "    # obtain training indices that will be used for validation\n",
      "\n",
      "\n",
      "    # Create Samplers\n",
      "\n",
      "\n",
      "    # prepare data loaders (combine dataset and sampler)\n",
      "    train_loader = DataLoader(train_data, batch_size=cfg.batch_size,\n",
      "                              pin_memory=True,\n",
      "                              num_workers=cfg.num_workers,\n",
      "                              shuffle=True,\n",
      "                              worker_init_fn=__init_fn)\n",
      "\n",
      "    valid_loader = DataLoader(valid_data, batch_size=cfg.batch_size,\n",
      "                              pin_memory=True,\n",
      "                              num_workers=cfg.num_workers,\n",
      "                              shuffle=True,\n",
      "                              worker_init_fn=__init_fn)\n",
      "\n",
      "    # Model\n",
      "    cfg.model.load_state_dict(\n",
      "        torch.load('./Model_weights_finetuning/finetune5_with_cropto260_b2_clahe.pth')['model'])\n",
      "\n",
      "    # check if CUDA is available\n",
      "    train_on_gpu = torch.cuda.is_available()\n",
      "\n",
      "    if not train_on_gpu:\n",
      "        print('CUDA is not available.  Training on CPU ...')\n",
      "    else:\n",
      "        print('CUDA is available!  Training on GPU ...')\n",
      "        cfg.model = cfg.model.cuda()\n",
      "\n",
      "    # Trainable Parameters\n",
      "    print(\"Number of trainable parameters: \\n{}\".format(cfg.pytorch_total_params))\n",
      "\n",
      "    #Training(Fine-Tuning) and Validation\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "\n",
      "    # keeping track of losses as it happen\n",
      "    train_losses = []\n",
      "    valid_losses = []\n",
      "    val_kappa = []\n",
      "    test_accuracies = []\n",
      "    valid_accuracies = []\n",
      "    kappa_epoch = []\n",
      "\n",
      "    # Loggers\n",
      "\n",
      "    logger_df = Logger(logsFileName=cfg.logsFileName + '.csv', mode = 'df')\n",
      "    logger_txt = Logger(logsFileName=cfg.logsFileName + '.txt', mode = 'txt')\n",
      "    loggers_list = [logger_df, logger_txt]\n",
      "\n",
      "    loggers_list[0].add_empty_row()\n",
      "    loggers_list[1].add_empty_row()\n",
      "\n",
      "    loggers_list[1].add_data('Experiment N: {}'.format(len(loggers_list[0].logsFile)-1), '')\n",
      "    loggers_list[1].add_data(info, '')\n",
      "    add_data_to_loggers(loggers_list, 'date', datetime.strftime(datetime.now(), \"%Y.%m.%d %H:%M:%S\"))\n",
      "\n",
      "    add_data_to_loggers(loggers_list, 'data-type', cfg.data_type)\n",
      "    loggers_list[0].add_data('net-architecture', open('model.py', 'r+').read())\n",
      "    add_data_to_loggers(loggers_list, 'loss-func', str(cfg.criterion))\n",
      "    add_data_to_loggers(loggers_list, 'optim', str(cfg.optimizer))\n",
      "\n",
      "    if cfg.scheduler is not None:\n",
      "        add_data_to_loggers(loggers_list, 'scheduler', str(cfg.scheduler))\n",
      "\n",
      "    if cfg.early_stopping is not None:\n",
      "        add_data_to_loggers(loggers_list, 'early-stopping-patience', cfg.early_stopping_patience)\n",
      "    else:\n",
      "        add_data_to_loggers(loggers_list, 'early-stopping-patience', cfg.early_stopping)\n",
      "\n",
      "    add_data_to_loggers(loggers_list, 'parameters-amount', cfg.pytorch_total_params)\n",
      "    add_data_to_loggers(loggers_list, 'n-epochs', cfg.n_epochs)\n",
      "    add_data_to_loggers(loggers_list, 'batch-size', cfg.batch_size)\n",
      "\n",
      "    train_loss_best = np.inf\n",
      "    valid_loss_best = np.inf\n",
      "    kappa_best = 0\n",
      "\n",
      "    add_data_to_loggers(loggers_list, 'best-train-loss', train_loss_best)\n",
      "    add_data_to_loggers(loggers_list, 'best-valid-loss', valid_loss_best)\n",
      "    add_data_to_loggers(loggers_list, 'best-kappa', kappa_best)\n",
      "    add_data_to_loggers(loggers_list, 'lb-kappa-score', np.nan)\n",
      "\n",
      "    loggers_list[0].add_data('cfg', open('config.py', 'r+').read())\n",
      "    loggers_list[0].add_data('dataset', open('train_dataset.py', 'r+').read())\n",
      "    loggers_list[0].add_data('trainloop', open('training.py', 'r+').read())\n",
      "\n",
      "\n",
      "\n",
      "    ## PRINT OUTPUT FREQUENCY\n",
      "    print_frequency = cfg.print_frequency\n",
      "    start_full_time = time.time()\n",
      "\n",
      "    for epoch in range(1, cfg.n_epochs + 1):\n",
      "        # For timing\n",
      "        # loggers_list[0].open()\n",
      "        loggers_list[1].open()\n",
      "        start_epoch_time = time.time()\n",
      "\n",
      "        # keep track of training and validation loss\n",
      "        train_loss_batch = []\n",
      "        train_loss_epoch = []\n",
      "        valid_loss_epoch = []\n",
      "        ###################\n",
      "        # train the cfg.model #\n",
      "        ###################\n",
      "        cfg.model.train()\n",
      "        batch_n = 0\n",
      "        for data, target in train_loader:\n",
      "            batch_n += 1\n",
      "            # move tensors to GPU if CUDA is available\n",
      "            if train_on_gpu:\n",
      "                data, target = data.cuda(), target.cuda().float()\n",
      "            target = target.view(-1, 1)\n",
      "            # clear the gradients of all optimized variables\n",
      "            cfg.optimizer.zero_grad()\n",
      "            with torch.set_grad_enabled(True):\n",
      "                # forward pass: compute predicted outputs by passing inputs to the cfg.model\n",
      "                output = cfg.model(data)\n",
      "                # calculate the batch loss\n",
      "                loss = cfg.criterion(output, target)\n",
      "                # backward pass: compute gradient of the loss with respect to cfg.model parameters\n",
      "                loss.backward()\n",
      "                # perform a single optimization step (parameter update)\n",
      "                cfg.optimizer.step()\n",
      "                # data = data.cpu()\n",
      "                train_loss_batch.append(loss.item())\n",
      "                if batch_n % print_frequency == (print_frequency-1):\n",
      "                    print('Train loss on {} batch: {:.6f}'.format(batch_n+1, np.mean(train_loss_batch)))\n",
      "                    loggers_list[1].add_data(None, 'Train loss on {} batch: {:.6f}'.format(batch_n+1, np.mean(train_loss_batch)))\n",
      "                    train_loss_epoch.append(np.mean(train_loss_batch))\n",
      "                    train_loss_batch = []\n",
      "        train_loss_epoch.append(np.mean(train_loss_batch))\n",
      "        torch.cuda.empty_cache()\n",
      "        ######################\n",
      "        # validate the cfg.model #\n",
      "        ######################\n",
      "        cfg.model.eval()\n",
      "        for data, target in valid_loader:\n",
      "            # move tensors to GPU if CUDA is available\n",
      "            if train_on_gpu:\n",
      "                data, target = data.cuda(), target.cuda().float()\n",
      "            # forward pass: compute predicted outputs by passing inputs to the cfg.model\n",
      "            target = target.view(-1, 1)\n",
      "            with torch.no_grad():\n",
      "                output = cfg.model(data)\n",
      "                # calculate the batch loss\n",
      "                loss = cfg.criterion(output, target)\n",
      "            # loss = loss.cpu()\n",
      "            # update average validation loss\n",
      "            valid_loss_epoch.append(loss.item())\n",
      "            y_actual = target.data.cpu().numpy()\n",
      "            y_pred = output[:, -1].detach().cpu().numpy()\n",
      "            val_kappa.append(cohen_kappa_score(y_actual, y_pred.round(), weights='quadratic'))\n",
      "\n",
      "            # calculate average losses\n",
      "        train_loss_epoch = np.mean(train_loss_epoch)\n",
      "        valid_loss_epoch = np.mean(valid_loss_epoch)\n",
      "        valid_kappa = np.nanmean(val_kappa)\n",
      "        kappa_epoch.append(valid_kappa)\n",
      "        train_losses.append(train_loss_epoch)\n",
      "        valid_losses.append(valid_loss_epoch)\n",
      "\n",
      "        ## SCHEDULER STEP\n",
      "        if cfg.scheduler is not None:\n",
      "            if cfg.early_stopping_loss == 'pytorch':\n",
      "                cfg.scheduler.step(valid_loss_epoch)\n",
      "            elif cfg.early_stopping_loss == 'kappa':\n",
      "                cfg.scheduler.step(1-valid_kappa)\n",
      "\n",
      "        ## LOGGINS LOSSES\n",
      "        if cfg.early_stopping_loss == 'pytorch':\n",
      "            if valid_loss_best > valid_loss_epoch:\n",
      "                valid_loss_best  = valid_loss_epoch\n",
      "                train_loss_best = train_loss_epoch\n",
      "                kappa_best = valid_kappa\n",
      "                add_data_to_loggers(loggers_list, 'best-train-loss', '{:.6f}'.format(train_loss_best))\n",
      "                add_data_to_loggers(loggers_list, 'best-valid-loss', '{:.6f}'.format(valid_loss_best))\n",
      "                add_data_to_loggers(loggers_list, 'best-kappa', '{:.4f}'.format(kappa_best))\n",
      "        elif cfg.early_stopping_loss == 'kappa':\n",
      "            if kappa_best < valid_kappa:\n",
      "                valid_loss_best  = valid_loss_epoch\n",
      "                train_loss_best = train_loss_epoch\n",
      "                kappa_best = valid_kappa\n",
      "                add_data_to_loggers(loggers_list, 'best-train-loss', '{:.6f}'.format(train_loss_best))\n",
      "                add_data_to_loggers(loggers_list, 'best-valid-loss', '{:.6f}'.format(valid_loss_best))\n",
      "                add_data_to_loggers(loggers_list, 'best-kappa', '{:.4f}'.format(kappa_best))\n",
      "\n",
      "        # print training/validation statistics\n",
      "        print('Epoch: {} | Training Loss: {:.6f} | Val. Loss: {:.6f} | Val. Kappa Score: {:.4f} | LR: {:.6f} | Estimated time: {:.2f}'.format(\n",
      "            epoch, train_loss_epoch, valid_loss_epoch, valid_kappa, cfg.optimizer.param_groups[0]['lr'], time.time() - start_epoch_time))\n",
      "        loggers_list[1].add_data('', 'Epoch: {} | Training Loss: {:.6f} | Val. Loss: {:.6f} | Val. Kappa Score: {:.4f} | LR: {:.6f} | Estimated time: {:.2f}'.format(\n",
      "            epoch, train_loss_epoch, valid_loss_epoch, valid_kappa, cfg.optimizer.param_groups[0]['lr'], time.time() - start_epoch_time))\n",
      "\n",
      "        ##################\n",
      "        # Early Stopping #\n",
      "        ##################\n",
      "        if cfg.early_stopping_loss == 'pytorch':\n",
      "            cfg.early_stopping(valid_loss_epoch, model_params_list=cfg.model_param_list, experiment_name=cfg.weights_dir + cfg.experiment_name, epoch=epoch)\n",
      "        elif cfg.early_stopping_loss == 'kappa':\n",
      "            cfg.early_stopping(1 - valid_kappa, model_params_list=cfg.model_param_list,\n",
      "                               experiment_name=cfg.weights_dir + cfg.experiment_name, epoch=epoch)\n",
      "        if cfg.early_stopping.early_stop:\n",
      "            add_data_to_loggers(loggers_list, 'time_estimated', '{:.2f}'.format(time.time() - start_full_time))\n",
      "            add_data_to_loggers(loggers_list, 'n-epochs', epoch)\n",
      "            loggers_list[0].save()\n",
      "            loggers_list[1].save()\n",
      "            break\n",
      "        loggers_list[0].save()\n",
      "        loggers_list[1].save()\n",
      "\n",
      "    loggers_list[1].open()\n",
      "    add_data_to_loggers(loggers_list, 'time_estimated', '{:.2f}'.format(time.time() - start_full_time))\n",
      "    loggers_list[0].save()\n",
      "    loggers_list[1].save()\n",
      "    del cfg.model\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    batch_size_list = [16]\n",
      "    lr_list = [1e-3]\n",
      "    p_horizontalflip_list = [0.4]\n",
      "    model_type_list = ['efficientnet-b2']\n",
      "    for batch_size in batch_size_list:\n",
      "        for lr in lr_list:\n",
      "            for p_horizontalflip in p_horizontalflip_list:\n",
      "                for model_type in model_type_list:\n",
      "                    info = \"\\n\\n\\nEXPERIMENT WITH BATCH_SIZE: {}, LR: {}, p_horizontalflip: {}, model_type: {}\\n\\n\\n\".format(batch_size, lr, p_horizontalflip, model_type)\n",
      "                    print(info)\n",
      "                    main(batch_size, lr, p_horizontalflip, model_type, info)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loggerDf.logsFile.loc[148]['trainloop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggerDf.logsFile.loc[3, 'data-type'] = 'finetuning_new'\n",
    "loggerDf.logsFile.loc[3, 'n-epochs'] = 50\n",
    "loggerDf.logsFile.loc[3, 'batch-size'] = 16\n",
    "loggerDf.logsFile.loc[3, 'time-estimated'] = 8100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>data-type</th>\n",
       "      <th>net-architecture</th>\n",
       "      <th>loss-func</th>\n",
       "      <th>optim</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>early-stopping-patience</th>\n",
       "      <th>parameters-amount</th>\n",
       "      <th>n-epochs</th>\n",
       "      <th>batch-size</th>\n",
       "      <th>best-train-loss</th>\n",
       "      <th>best-valid-loss</th>\n",
       "      <th>best-kappa</th>\n",
       "      <th>lb-kappa-score</th>\n",
       "      <th>cfg</th>\n",
       "      <th>dataset</th>\n",
       "      <th>trainloop</th>\n",
       "      <th>time_estimated</th>\n",
       "      <th>time-estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.08.11 01:58:43</td>\n",
       "      <td>new_old_mixed_old</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\nimport to...</td>\n",
       "      <td>MSELoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>&lt;torch.optim.lr_scheduler.CosineAnnealingLR ob...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28342833.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.651234</td>\n",
       "      <td>0.631161</td>\n",
       "      <td>0.2751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from model import MainModel\\nfrom torch import...</td>\n",
       "      <td>from torch.utils.data.dataset import Dataset\\n...</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pa...</td>\n",
       "      <td>13907.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.08.11 12:36:00</td>\n",
       "      <td>finetuning_new</td>\n",
       "      <td>import torch\\nimport torch.nn as nn\\nimport to...</td>\n",
       "      <td>MSELoss()</td>\n",
       "      <td>Adam (\\nParameter Group 0\\n    amsgrad: False\\...</td>\n",
       "      <td>&lt;torch.optim.lr_scheduler.CosineAnnealingLR ob...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28342833.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.305394</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>from model import MainModel\\nfrom torch import...</td>\n",
       "      <td>from torch.utils.data.dataset import Dataset\\n...</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pa...</td>\n",
       "      <td>4296.42</td>\n",
       "      <td>8100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date          data-type  \\\n",
       "0  2019.08.11 01:58:43  new_old_mixed_old   \n",
       "1  2019.08.11 12:36:00     finetuning_new   \n",
       "\n",
       "                                    net-architecture  loss-func  \\\n",
       "0  import torch\\nimport torch.nn as nn\\nimport to...  MSELoss()   \n",
       "1  import torch\\nimport torch.nn as nn\\nimport to...  MSELoss()   \n",
       "\n",
       "                                               optim  \\\n",
       "0  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "1  Adam (\\nParameter Group 0\\n    amsgrad: False\\...   \n",
       "\n",
       "                                           scheduler  early-stopping-patience  \\\n",
       "0  <torch.optim.lr_scheduler.CosineAnnealingLR ob...                      5.0   \n",
       "1  <torch.optim.lr_scheduler.CosineAnnealingLR ob...                     10.0   \n",
       "\n",
       "   parameters-amount  n-epochs  batch-size  best-train-loss  best-valid-loss  \\\n",
       "0         28342833.0      11.0        16.0         0.651234         0.631161   \n",
       "1         28342833.0      50.0        16.0         0.291845         0.305394   \n",
       "\n",
       "   best-kappa  lb-kappa-score  \\\n",
       "0      0.2751             NaN   \n",
       "1      0.8427             NaN   \n",
       "\n",
       "                                                 cfg  \\\n",
       "0  from model import MainModel\\nfrom torch import...   \n",
       "1  from model import MainModel\\nfrom torch import...   \n",
       "\n",
       "                                             dataset  \\\n",
       "0  from torch.utils.data.dataset import Dataset\\n...   \n",
       "1  from torch.utils.data.dataset import Dataset\\n...   \n",
       "\n",
       "                                           trainloop  time_estimated  \\\n",
       "0  import numpy as np # linear algebra\\nimport pa...        13907.77   \n",
       "1  import numpy as np # linear algebra\\nimport pa...         4296.42   \n",
       "\n",
       "   time-estimated  \n",
       "0             NaN  \n",
       "1          8100.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggerDf.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019.08.02 00:51:32'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strftime(datetime.now(), \"%Y.%m.%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.lr_finder import LRFinder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /home/paniquex/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\" to /home/paniquex/.cache/torch/checkpoints/ig_resnext101_32x16-c6f796b0.pth\n",
      "100%|██████████| 777518664/777518664 [01:08<00:00, 11411797.13it/s]\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnext101_32x16d_wsl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.read_csv('./input/train_new.csv')\n",
    "train_old = pd.read_csv('./input/train_old.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16_left</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16_right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35096</th>\n",
       "      <td>44317_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35097</th>\n",
       "      <td>44317_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35098</th>\n",
       "      <td>44323_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35099</th>\n",
       "      <td>44323_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35100</th>\n",
       "      <td>44325_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35101</th>\n",
       "      <td>44325_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35102</th>\n",
       "      <td>44327_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35103</th>\n",
       "      <td>44327_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35104</th>\n",
       "      <td>44328_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35105</th>\n",
       "      <td>44328_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35106</th>\n",
       "      <td>44330_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35107</th>\n",
       "      <td>44330_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>44331_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>44331_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35110</th>\n",
       "      <td>44334_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35111</th>\n",
       "      <td>44334_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35112</th>\n",
       "      <td>44337_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35113</th>\n",
       "      <td>44337_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35114</th>\n",
       "      <td>44338_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35115</th>\n",
       "      <td>44338_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35116</th>\n",
       "      <td>44339_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35117</th>\n",
       "      <td>44339_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35118</th>\n",
       "      <td>44343_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35119</th>\n",
       "      <td>44343_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35120</th>\n",
       "      <td>44347_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35121</th>\n",
       "      <td>44347_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35122</th>\n",
       "      <td>44348_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35123</th>\n",
       "      <td>44348_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35124</th>\n",
       "      <td>44349_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35125</th>\n",
       "      <td>44349_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis\n",
       "0          10_left          0\n",
       "1         10_right          0\n",
       "2          13_left          0\n",
       "3         13_right          0\n",
       "4          15_left          1\n",
       "5         15_right          2\n",
       "6          16_left          4\n",
       "7         16_right          4\n",
       "8          17_left          0\n",
       "9         17_right          1\n",
       "10         19_left          0\n",
       "11        19_right          0\n",
       "12         20_left          0\n",
       "13        20_right          0\n",
       "14         21_left          0\n",
       "15        21_right          0\n",
       "16         22_left          0\n",
       "17        22_right          0\n",
       "18         23_left          0\n",
       "19        23_right          0\n",
       "20         25_left          0\n",
       "21        25_right          0\n",
       "22         30_left          1\n",
       "23        30_right          2\n",
       "24         31_left          0\n",
       "25        31_right          0\n",
       "26         33_left          0\n",
       "27        33_right          0\n",
       "28         36_left          1\n",
       "29        36_right          0\n",
       "...            ...        ...\n",
       "35096   44317_left          0\n",
       "35097  44317_right          0\n",
       "35098   44323_left          1\n",
       "35099  44323_right          1\n",
       "35100   44325_left          0\n",
       "35101  44325_right          0\n",
       "35102   44327_left          0\n",
       "35103  44327_right          0\n",
       "35104   44328_left          0\n",
       "35105  44328_right          1\n",
       "35106   44330_left          0\n",
       "35107  44330_right          0\n",
       "35108   44331_left          0\n",
       "35109  44331_right          0\n",
       "35110   44334_left          0\n",
       "35111  44334_right          0\n",
       "35112   44337_left          1\n",
       "35113  44337_right          0\n",
       "35114   44338_left          0\n",
       "35115  44338_right          0\n",
       "35116   44339_left          0\n",
       "35117  44339_right          0\n",
       "35118   44343_left          0\n",
       "35119  44343_right          0\n",
       "35120   44347_left          0\n",
       "35121  44347_right          0\n",
       "35122   44348_left          0\n",
       "35123  44348_right          0\n",
       "35124   44349_left          0\n",
       "35125  44349_right          1\n",
       "\n",
       "[35126 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old.to_csv('./input/train_old.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16_left</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16_right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>23_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35096</th>\n",
       "      <td>44317_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35097</th>\n",
       "      <td>44317_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35098</th>\n",
       "      <td>44323_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35099</th>\n",
       "      <td>44323_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35100</th>\n",
       "      <td>44325_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35101</th>\n",
       "      <td>44325_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35102</th>\n",
       "      <td>44327_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35103</th>\n",
       "      <td>44327_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35104</th>\n",
       "      <td>44328_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35105</th>\n",
       "      <td>44328_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35106</th>\n",
       "      <td>44330_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35107</th>\n",
       "      <td>44330_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>44331_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>44331_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35110</th>\n",
       "      <td>44334_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35111</th>\n",
       "      <td>44334_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35112</th>\n",
       "      <td>44337_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35113</th>\n",
       "      <td>44337_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35114</th>\n",
       "      <td>44338_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35115</th>\n",
       "      <td>44338_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35116</th>\n",
       "      <td>44339_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35117</th>\n",
       "      <td>44339_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35118</th>\n",
       "      <td>44343_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35119</th>\n",
       "      <td>44343_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35120</th>\n",
       "      <td>44347_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35121</th>\n",
       "      <td>44347_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35122</th>\n",
       "      <td>44348_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35123</th>\n",
       "      <td>44348_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35124</th>\n",
       "      <td>44349_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35125</th>\n",
       "      <td>44349_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_code  diagnosis\n",
       "0          10_left          0\n",
       "1         10_right          0\n",
       "2          13_left          0\n",
       "3         13_right          0\n",
       "4          15_left          1\n",
       "5         15_right          2\n",
       "6          16_left          4\n",
       "7         16_right          4\n",
       "8          17_left          0\n",
       "9         17_right          1\n",
       "10         19_left          0\n",
       "11        19_right          0\n",
       "12         20_left          0\n",
       "13        20_right          0\n",
       "14         21_left          0\n",
       "15        21_right          0\n",
       "16         22_left          0\n",
       "17        22_right          0\n",
       "18         23_left          0\n",
       "19        23_right          0\n",
       "20         25_left          0\n",
       "21        25_right          0\n",
       "22         30_left          1\n",
       "23        30_right          2\n",
       "24         31_left          0\n",
       "25        31_right          0\n",
       "26         33_left          0\n",
       "27        33_right          0\n",
       "28         36_left          1\n",
       "29        36_right          0\n",
       "...            ...        ...\n",
       "35096   44317_left          0\n",
       "35097  44317_right          0\n",
       "35098   44323_left          1\n",
       "35099  44323_right          1\n",
       "35100   44325_left          0\n",
       "35101  44325_right          0\n",
       "35102   44327_left          0\n",
       "35103  44327_right          0\n",
       "35104   44328_left          0\n",
       "35105  44328_right          1\n",
       "35106   44330_left          0\n",
       "35107  44330_right          0\n",
       "35108   44331_left          0\n",
       "35109  44331_right          0\n",
       "35110   44334_left          0\n",
       "35111  44334_right          0\n",
       "35112   44337_left          1\n",
       "35113  44337_right          0\n",
       "35114   44338_left          0\n",
       "35115  44338_right          0\n",
       "35116   44339_left          0\n",
       "35117  44339_right          0\n",
       "35118   44343_left          0\n",
       "35119  44343_right          0\n",
       "35120   44347_left          0\n",
       "35121  44347_right          0\n",
       "35122   44348_left          0\n",
       "35123  44348_right          0\n",
       "35124   44349_left          0\n",
       "35125  44349_right          1\n",
       "\n",
       "[35126 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
