----------------------------------------

Experiment N: 1: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.006, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.11 01:58:43
data-type: new_old_mixed_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.006
    lr: 0.006
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95f97b70>
early-stopping-patience: 5
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.440871
Train loss on 100 batch: 1.171992
Train loss on 150 batch: 0.950965
Train loss on 200 batch: 0.972610
Train loss on 250 batch: 0.963871
Train loss on 300 batch: 1.017088
Train loss on 350 batch: 1.028130
Train loss on 400 batch: 0.987521
Train loss on 450 batch: 1.034287
Train loss on 500 batch: 0.975943
Train loss on 550 batch: 1.077607
Train loss on 600 batch: 0.910665
Train loss on 650 batch: 1.007742
Train loss on 700 batch: 0.972622
Train loss on 750 batch: 0.936818
Train loss on 800 batch: 1.058151
Train loss on 850 batch: 0.950107
Train loss on 900 batch: 0.970045
Train loss on 950 batch: 0.900600
Train loss on 1000 batch: 0.931557
Train loss on 1050 batch: 0.881886
Train loss on 1100 batch: 1.032057
Train loss on 1150 batch: 1.028504
Train loss on 1200 batch: 1.071495
Train loss on 1250 batch: 0.939721
Train loss on 1300 batch: 0.964457
Train loss on 1350 batch: 0.973389
Train loss on 1400 batch: 0.970769
Train loss on 1450 batch: 1.005992
Train loss on 1500 batch: 0.924910
best-train-loss: 0.997275
best-valid-loss: 0.971819
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 0.997275 | Val. Loss: 0.971819 | Val. Kappa Score: 0.0000 | Estimated time: 1262.91
Train loss on 50 batch: 0.940816
Train loss on 100 batch: 1.037834
Train loss on 150 batch: 0.941446
Train loss on 200 batch: 0.871163
Train loss on 250 batch: 0.931428
Train loss on 300 batch: 1.024308
Train loss on 350 batch: 1.077923
Train loss on 400 batch: 0.911317
Train loss on 450 batch: 0.962467
Train loss on 500 batch: 1.047928
Train loss on 550 batch: 1.001729
Train loss on 600 batch: 1.004122
Train loss on 650 batch: 0.978581
Train loss on 700 batch: 0.987995
Train loss on 750 batch: 0.888491
Train loss on 800 batch: 0.967655
Train loss on 850 batch: 1.008748
Train loss on 900 batch: 0.980192
Train loss on 950 batch: 0.972678
Train loss on 1000 batch: 0.966990
Train loss on 1050 batch: 0.833582
Train loss on 1100 batch: 0.946194
Train loss on 1150 batch: 0.863181
Train loss on 1200 batch: 0.901440
Train loss on 1250 batch: 0.892826
Train loss on 1300 batch: 0.927584
Train loss on 1350 batch: 0.904029
Train loss on 1400 batch: 0.878220
Train loss on 1450 batch: 0.938090
Train loss on 1500 batch: 0.786354
best-train-loss: 0.942457
best-valid-loss: 0.947371
best-kappa: 0.0050
: Epoch: 2 | Training Loss: 0.942457 | Val. Loss: 0.947371 | Val. Kappa Score: 0.0050 | Estimated time: 1275.72
Train loss on 50 batch: 0.790364
Train loss on 100 batch: 0.878300
Train loss on 150 batch: 0.916961
Train loss on 200 batch: 0.843829
Train loss on 250 batch: 0.877978
Train loss on 300 batch: 0.878136
Train loss on 350 batch: 0.994582
Train loss on 400 batch: 0.877182
Train loss on 450 batch: 0.845635
Train loss on 500 batch: 0.783380
Train loss on 550 batch: 0.790630
Train loss on 600 batch: 0.873015
Train loss on 650 batch: 0.856900
Train loss on 700 batch: 0.799428
Train loss on 750 batch: 0.837551
Train loss on 800 batch: 0.732637
Train loss on 850 batch: 0.753480
Train loss on 900 batch: 0.829441
Train loss on 950 batch: 0.766409
Train loss on 1000 batch: 0.831108
Train loss on 1050 batch: 0.824706
Train loss on 1100 batch: 0.821539
Train loss on 1150 batch: 0.724575
Train loss on 1200 batch: 0.870975
Train loss on 1250 batch: 0.913809
Train loss on 1300 batch: 0.780195
Train loss on 1350 batch: 0.789971
Train loss on 1400 batch: 0.716422
Train loss on 1450 batch: 0.729944
Train loss on 1500 batch: 0.825790
best-train-loss: 0.824767
best-valid-loss: 0.750835
best-kappa: 0.1241
: Epoch: 3 | Training Loss: 0.824767 | Val. Loss: 0.750835 | Val. Kappa Score: 0.1241 | Estimated time: 1279.24
Train loss on 50 batch: 0.754279
Train loss on 100 batch: 0.670334
Train loss on 150 batch: 0.738700
Train loss on 200 batch: 0.761186
Train loss on 250 batch: 0.764648
Train loss on 300 batch: 0.659241
Train loss on 350 batch: 0.796071
Train loss on 400 batch: 0.786518
Train loss on 450 batch: 0.802196
Train loss on 500 batch: 0.821650
Train loss on 550 batch: 0.711043
Train loss on 600 batch: 0.861318
Train loss on 650 batch: 0.742119
Train loss on 700 batch: 0.664656
Train loss on 750 batch: 0.766079
Train loss on 800 batch: 0.745696
Train loss on 850 batch: 0.749013
Train loss on 900 batch: 0.671802
Train loss on 950 batch: 0.766761
Train loss on 1000 batch: 0.692413
Train loss on 1050 batch: 0.776564
Train loss on 1100 batch: 0.588030
Train loss on 1150 batch: 0.675007
Train loss on 1200 batch: 0.692011
Train loss on 1250 batch: 0.665685
Train loss on 1300 batch: 0.716418
Train loss on 1350 batch: 0.745799
Train loss on 1400 batch: 0.747780
Train loss on 1450 batch: 0.700516
Train loss on 1500 batch: 0.653988
best-train-loss: 0.727807
best-valid-loss: 0.684919
best-kappa: 0.1920
: Epoch: 4 | Training Loss: 0.727807 | Val. Loss: 0.684919 | Val. Kappa Score: 0.1920 | Estimated time: 1260.80
Train loss on 50 batch: 0.723535
Train loss on 100 batch: 0.684220
Train loss on 150 batch: 0.658699
Train loss on 200 batch: 0.733438
Train loss on 250 batch: 0.605924
Train loss on 300 batch: 0.630863
Train loss on 350 batch: 0.618788
Train loss on 400 batch: 0.722685
Train loss on 450 batch: 0.691779
Train loss on 500 batch: 0.769771
Train loss on 550 batch: 0.700657
Train loss on 600 batch: 0.674467
Train loss on 650 batch: 0.716195
Train loss on 700 batch: 0.715368
Train loss on 750 batch: 0.700560
Train loss on 800 batch: 0.623315
Train loss on 850 batch: 0.671734
Train loss on 900 batch: 0.702438
Train loss on 950 batch: 0.655563
Train loss on 1000 batch: 0.731072
Train loss on 1050 batch: 0.623558
Train loss on 1100 batch: 0.595066
Train loss on 1150 batch: 0.772406
Train loss on 1200 batch: 0.618217
Train loss on 1250 batch: 0.648846
Train loss on 1300 batch: 0.613229
Train loss on 1350 batch: 0.632405
Train loss on 1400 batch: 0.638581
Train loss on 1450 batch: 0.656114
Train loss on 1500 batch: 0.646622
best-train-loss: 0.670488
best-valid-loss: 0.647824
best-kappa: 0.2414
: Epoch: 5 | Training Loss: 0.670488 | Val. Loss: 0.647824 | Val. Kappa Score: 0.2414 | Estimated time: 1261.14
Train loss on 50 batch: 0.631499
Train loss on 100 batch: 0.664683
Train loss on 150 batch: 0.663146
Train loss on 200 batch: 0.612642
Train loss on 250 batch: 0.592446
Train loss on 300 batch: 0.559658
Train loss on 350 batch: 0.690560
Train loss on 400 batch: 0.668481
Train loss on 450 batch: 0.656871
Train loss on 500 batch: 0.668393
Train loss on 550 batch: 0.670745
Train loss on 600 batch: 0.639136
Train loss on 650 batch: 0.627055
Train loss on 700 batch: 0.669385
Train loss on 750 batch: 0.628254
Train loss on 800 batch: 0.656971
Train loss on 850 batch: 0.655268
Train loss on 900 batch: 0.710017
Train loss on 950 batch: 0.633327
Train loss on 1000 batch: 0.596391
Train loss on 1050 batch: 0.748337
Train loss on 1100 batch: 0.638029
Train loss on 1150 batch: 0.684798
Train loss on 1200 batch: 0.651569
Train loss on 1250 batch: 0.623034
Train loss on 1300 batch: 0.653016
Train loss on 1350 batch: 0.623497
Train loss on 1400 batch: 0.638417
Train loss on 1450 batch: 0.720675
Train loss on 1500 batch: 0.709026
best-train-loss: 0.651234
best-valid-loss: 0.631161
best-kappa: 0.2751
: Epoch: 6 | Training Loss: 0.651234 | Val. Loss: 0.631161 | Val. Kappa Score: 0.2751 | Estimated time: 1261.63
Train loss on 50 batch: 0.682474
Train loss on 100 batch: 0.636198
Train loss on 150 batch: 0.623376
Train loss on 200 batch: 0.694094
Train loss on 250 batch: 0.605050
Train loss on 300 batch: 0.660569
Train loss on 350 batch: 0.639615
Train loss on 400 batch: 0.601230
Train loss on 450 batch: 0.662368
Train loss on 500 batch: 0.677008
Train loss on 550 batch: 0.612523
Train loss on 600 batch: 0.746407
Train loss on 650 batch: 0.688093
Train loss on 700 batch: 0.595892
Train loss on 750 batch: 0.663213
Train loss on 800 batch: 0.657568
Train loss on 850 batch: 0.655038
Train loss on 900 batch: 0.678037
Train loss on 950 batch: 0.641821
Train loss on 1000 batch: 0.606358
Train loss on 1050 batch: 0.672113
Train loss on 1100 batch: 0.655287
Train loss on 1150 batch: 0.771471
Train loss on 1200 batch: 0.643299
Train loss on 1250 batch: 0.662996
Train loss on 1300 batch: 0.754597
Train loss on 1350 batch: 0.598497
Train loss on 1400 batch: 0.602974
Train loss on 1450 batch: 0.633384
Train loss on 1500 batch: 0.634792
: Epoch: 7 | Training Loss: 0.654159 | Val. Loss: 0.633462 | Val. Kappa Score: nan | Estimated time: 1260.77
Train loss on 50 batch: 0.706389
Train loss on 100 batch: 0.658529
Train loss on 150 batch: 0.721823
Train loss on 200 batch: 0.714251
Train loss on 250 batch: 0.792507
Train loss on 300 batch: 0.751368
Train loss on 350 batch: 0.675033
Train loss on 400 batch: 0.707570
Train loss on 450 batch: 0.766525
Train loss on 500 batch: 0.707998
Train loss on 550 batch: 0.717952
Train loss on 600 batch: 0.679760
Train loss on 650 batch: 0.681147
Train loss on 700 batch: 0.645545
Train loss on 750 batch: 0.596380
Train loss on 800 batch: 0.685155
Train loss on 850 batch: 0.692934
Train loss on 900 batch: 0.681046
Train loss on 950 batch: 0.687445
Train loss on 1000 batch: 0.613154
Train loss on 1050 batch: 0.770763
Train loss on 1100 batch: 0.675331
Train loss on 1150 batch: 0.632334
Train loss on 1200 batch: 0.682531
Train loss on 1250 batch: 0.627625
Train loss on 1300 batch: 0.670730
Train loss on 1350 batch: 0.622306
Train loss on 1400 batch: 0.697972
Train loss on 1450 batch: 0.675660
Train loss on 1500 batch: 0.705586
: Epoch: 8 | Training Loss: 0.685247 | Val. Loss: 0.726130 | Val. Kappa Score: nan | Estimated time: 1261.34
Train loss on 50 batch: 0.794577
Train loss on 100 batch: 0.780502
Train loss on 150 batch: 0.717149
Train loss on 200 batch: 0.742242
Train loss on 250 batch: 0.726683
Train loss on 300 batch: 0.759728
Train loss on 350 batch: 0.791557
Train loss on 400 batch: 0.698543
Train loss on 450 batch: 0.729017
Train loss on 500 batch: 0.717033
Train loss on 550 batch: 0.739702
Train loss on 600 batch: 0.699704
Train loss on 650 batch: 0.723406
Train loss on 700 batch: 0.696421
Train loss on 750 batch: 0.721284
Train loss on 800 batch: 0.716980
Train loss on 850 batch: 0.693872
Train loss on 900 batch: 0.687026
Train loss on 950 batch: 0.643774
Train loss on 1000 batch: 0.732400
Train loss on 1050 batch: 0.783017
Train loss on 1100 batch: 0.759966
Train loss on 1150 batch: 0.722191
Train loss on 1200 batch: 0.675648
Train loss on 1250 batch: 0.764962
Train loss on 1300 batch: 0.630327
Train loss on 1350 batch: 0.579909
Train loss on 1400 batch: 0.713627
Train loss on 1450 batch: 0.745667
Train loss on 1500 batch: 0.764291
: Epoch: 9 | Training Loss: 0.718867 | Val. Loss: 1.095298 | Val. Kappa Score: nan | Estimated time: 1261.77
Train loss on 50 batch: 0.808918
Train loss on 100 batch: 0.671157
Train loss on 150 batch: 0.816547
Train loss on 200 batch: 0.725165
Train loss on 250 batch: 0.863125
Train loss on 300 batch: 0.703442
Train loss on 350 batch: 0.703747
Train loss on 400 batch: 0.767066
Train loss on 450 batch: 0.735021
Train loss on 500 batch: 0.771351
Train loss on 550 batch: 0.747471
Train loss on 600 batch: 0.689864
Train loss on 650 batch: 0.791617
Train loss on 700 batch: 0.719020
Train loss on 750 batch: 0.703517
Train loss on 800 batch: 0.686716
Train loss on 850 batch: 0.759709
Train loss on 900 batch: 0.770428
Train loss on 950 batch: 0.769891
Train loss on 1000 batch: 0.789757
Train loss on 1050 batch: 0.689679
Train loss on 1100 batch: 0.719455
Train loss on 1150 batch: 0.776069
Train loss on 1200 batch: 0.665522
Train loss on 1250 batch: 0.717093
Train loss on 1300 batch: 0.633244
Train loss on 1350 batch: 0.687668
Train loss on 1400 batch: 0.744324
Train loss on 1450 batch: 0.771171
Train loss on 1500 batch: 0.794613
: Epoch: 10 | Training Loss: 0.741784 | Val. Loss: 0.739647 | Val. Kappa Score: nan | Estimated time: 1261.36
Train loss on 50 batch: 0.734248
Train loss on 100 batch: 0.716398
Train loss on 150 batch: 0.814935
Train loss on 200 batch: 0.699650
Train loss on 250 batch: 0.673668
Train loss on 300 batch: 0.747286
Train loss on 350 batch: 0.766647
Train loss on 400 batch: 0.694045
Train loss on 450 batch: 0.676159
Train loss on 500 batch: 0.653228
Train loss on 550 batch: 0.808112
Train loss on 600 batch: 0.754455
Train loss on 650 batch: 0.640718
Train loss on 700 batch: 0.753595
Train loss on 750 batch: 0.682513
Train loss on 800 batch: 0.688376
Train loss on 850 batch: 0.634548
Train loss on 900 batch: 0.699749
Train loss on 950 batch: 0.743106
Train loss on 1000 batch: 0.654794
Train loss on 1050 batch: 0.794295
Train loss on 1100 batch: 0.592135
Train loss on 1150 batch: 0.656346
Train loss on 1200 batch: 0.604041
Train loss on 1250 batch: 0.633476
Train loss on 1300 batch: 0.661874
Train loss on 1350 batch: 0.633479
Train loss on 1400 batch: 0.785980
Train loss on 1450 batch: 0.692893
Train loss on 1500 batch: 0.655500
: Epoch: 11 | Training Loss: 0.702084 | Val. Loss: 0.687559 | Val. Kappa Score: nan | Estimated time: 1260.51
time_estimated: 13907.76
n-epochs: 11
time_estimated: 13907.77
----------------------------------------

Experiment N: 2: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.006, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : new
date: 2019.08.11 10:49:33
data-type: new_old_mixed_new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.006
    lr: 0.006
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95f96ba8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.748305
Train loss on 100 batch: 0.649131
Train loss on 150 batch: 0.743375
best-train-loss: 0.680778
best-valid-loss: 0.979563
best-kappa: 0.6506
: Epoch: 1 | Training Loss: 0.680778 | Val. Loss: 0.979563 | Val. Kappa Score: 0.6506 | Estimated time: 163.20
Train loss on 50 batch: 0.575371
Train loss on 100 batch: 0.590522
Train loss on 150 batch: 0.581668
best-train-loss: 0.573069
best-valid-loss: 0.637894
best-kappa: 0.7061
: Epoch: 2 | Training Loss: 0.573069 | Val. Loss: 0.637894 | Val. Kappa Score: 0.7061 | Estimated time: 162.64
Train loss on 50 batch: 0.475193
Train loss on 100 batch: 0.549885
Train loss on 150 batch: 0.483708
best-train-loss: 0.495515
best-valid-loss: 0.444419
best-kappa: 0.7457
: Epoch: 3 | Training Loss: 0.495515 | Val. Loss: 0.444419 | Val. Kappa Score: 0.7457 | Estimated time: 163.62
Train loss on 50 batch: 0.489245
Train loss on 100 batch: 0.488104
Train loss on 150 batch: 0.550285
best-train-loss: 0.548863
best-valid-loss: 0.418337
best-kappa: 0.7680
: Epoch: 4 | Training Loss: 0.548863 | Val. Loss: 0.418337 | Val. Kappa Score: 0.7680 | Estimated time: 163.79
Train loss on 50 batch: 0.411876
Train loss on 100 batch: 0.488039
Train loss on 150 batch: 0.506625
: Epoch: 5 | Training Loss: 0.463157 | Val. Loss: 0.450328 | Val. Kappa Score: 0.7802 | Estimated time: 163.47
Train loss on 50 batch: 0.446926
Train loss on 100 batch: 0.561550
Train loss on 150 batch: 0.536047
: Epoch: 6 | Training Loss: 0.562189 | Val. Loss: 0.898724 | Val. Kappa Score: 0.7700 | Estimated time: 165.00
Train loss on 50 batch: 0.623917
----------------------------------------

Experiment N: 3: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.006, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : new
date: 2019.08.11 11:17:21
data-type: new_old_mixed_new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.006
    lr: 0.006
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb9d1d9a20>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.748305
Train loss on 100 batch: 0.649131
Train loss on 150 batch: 0.743375
best-train-loss: 0.680778
best-valid-loss: 0.979563
best-kappa: 0.6506
: Epoch: 1 | Training Loss: 0.680778 | Val. Loss: 0.979563 | Val. Kappa Score: 0.6506 | Estimated time: 163.86
Train loss on 50 batch: 0.575371
Train loss on 100 batch: 0.590522
Train loss on 150 batch: 0.581668
best-train-loss: 0.573069
best-valid-loss: 0.637894
best-kappa: 0.7061
: Epoch: 2 | Training Loss: 0.573069 | Val. Loss: 0.637894 | Val. Kappa Score: 0.7061 | Estimated time: 163.28
Train loss on 50 batch: 0.475193
Train loss on 100 batch: 0.549885
Train loss on 150 batch: 0.483708
best-train-loss: 0.495515
best-valid-loss: 0.444419
best-kappa: 0.7457
: Epoch: 3 | Training Loss: 0.495515 | Val. Loss: 0.444419 | Val. Kappa Score: 0.7457 | Estimated time: 164.68
Train loss on 50 batch: 0.489245
Train loss on 100 batch: 0.488104
Train loss on 150 batch: 0.550285
best-train-loss: 0.548863
best-valid-loss: 0.418337
best-kappa: 0.7680
: Epoch: 4 | Training Loss: 0.548863 | Val. Loss: 0.418337 | Val. Kappa Score: 0.7680 | Estimated time: 164.63
Train loss on 50 batch: 0.411876
Train loss on 100 batch: 0.488039
Train loss on 150 batch: 0.506625
: Epoch: 5 | Training Loss: 0.463157 | Val. Loss: 0.450328 | Val. Kappa Score: 0.7802 | Estimated time: 163.65
Train loss on 50 batch: 0.446926
Train loss on 100 batch: 0.561550
Train loss on 150 batch: 0.536047
: Epoch: 6 | Training Loss: 0.562189 | Val. Loss: 0.898724 | Val. Kappa Score: 0.7700 | Estimated time: 164.49
Train loss on 50 batch: 0.623917
Train loss on 100 batch: 0.529637
Train loss on 150 batch: 0.504170
: Epoch: 7 | Training Loss: 0.544891 | Val. Loss: 1.723214 | Val. Kappa Score: 0.7423 | Estimated time: 164.71
Train loss on 50 batch: 0.461165
Train loss on 100 batch: 0.503867
Train loss on 150 batch: 0.466545
: Epoch: 8 | Training Loss: 0.500897 | Val. Loss: 0.617539 | Val. Kappa Score: 0.7442 | Estimated time: 163.97
Train loss on 50 batch: 0.464426
Train loss on 100 batch: 0.402287
Train loss on 150 batch: 0.463460
best-train-loss: 0.403721
best-valid-loss: 0.390385
best-kappa: 0.7544
: Epoch: 9 | Training Loss: 0.403721 | Val. Loss: 0.390385 | Val. Kappa Score: 0.7544 | Estimated time: 163.32
Train loss on 50 batch: 0.336075
Train loss on 100 batch: 0.422404
Train loss on 150 batch: 0.381681
best-train-loss: 0.371962
best-valid-loss: 0.363112
best-kappa: 0.7645
: Epoch: 10 | Training Loss: 0.371962 | Val. Loss: 0.363112 | Val. Kappa Score: 0.7645 | Estimated time: 164.55
Train loss on 50 batch: 0.340530
Train loss on 100 batch: 0.401018
Train loss on 150 batch: 0.411640
: Epoch: 11 | Training Loss: 0.385343 | Val. Loss: 0.370706 | Val. Kappa Score: 0.7727 | Estimated time: 163.04
Train loss on 50 batch: 0.404473
Train loss on 100 batch: 0.393606
Train loss on 150 batch: 0.430232
: Epoch: 12 | Training Loss: 0.425267 | Val. Loss: 0.681046 | Val. Kappa Score: 0.7703 | Estimated time: 165.52
Train loss on 50 batch: 0.374522
Train loss on 100 batch: 0.585037
Train loss on 150 batch: 0.533283
: Epoch: 13 | Training Loss: 0.507586 | Val. Loss: 0.598614 | Val. Kappa Score: 0.7729 | Estimated time: 164.39
Train loss on 50 batch: 0.491006
Train loss on 100 batch: 0.433952
Train loss on 150 batch: 0.397329
: Epoch: 14 | Training Loss: 0.450062 | Val. Loss: 0.898735 | Val. Kappa Score: 0.7663 | Estimated time: 162.91
Train loss on 50 batch: 0.419753
Train loss on 100 batch: 0.332175
Train loss on 150 batch: 0.333201
best-train-loss: 0.390830
best-valid-loss: 0.353406
best-kappa: 0.7721
: Epoch: 15 | Training Loss: 0.390830 | Val. Loss: 0.353406 | Val. Kappa Score: 0.7721 | Estimated time: 163.93
Train loss on 50 batch: 0.297063
Train loss on 100 batch: 0.347828
Train loss on 150 batch: 0.334721
best-train-loss: 0.324063
best-valid-loss: 0.322948
best-kappa: 0.7776
: Epoch: 16 | Training Loss: 0.324063 | Val. Loss: 0.322948 | Val. Kappa Score: 0.7776 | Estimated time: 164.21
Train loss on 50 batch: 0.399861
Train loss on 100 batch: 0.352752
Train loss on 150 batch: 0.304991
: Epoch: 17 | Training Loss: 0.327057 | Val. Loss: 0.331801 | Val. Kappa Score: 0.7828 | Estimated time: 164.22
Train loss on 50 batch: 0.394275
Train loss on 100 batch: 0.390559
Train loss on 150 batch: 0.373875
: Epoch: 18 | Training Loss: 0.370666 | Val. Loss: 0.375849 | Val. Kappa Score: 0.7867 | Estimated time: 164.12
Train loss on 50 batch: 0.440502
Train loss on 100 batch: 0.463890
Train loss on 150 batch: 0.373139
: Epoch: 19 | Training Loss: 0.438849 | Val. Loss: 0.824391 | Val. Kappa Score: 0.7811 | Estimated time: 162.82
Train loss on 50 batch: 0.431943
Train loss on 100 batch: 0.390787
Train loss on 150 batch: 0.358749
: Epoch: 20 | Training Loss: 0.389165 | Val. Loss: 0.420154 | Val. Kappa Score: 0.7838 | Estimated time: 162.60
Train loss on 50 batch: 0.320135
Train loss on 100 batch: 0.341660
Train loss on 150 batch: 0.387298
: Epoch: 21 | Training Loss: 0.333006 | Val. Loss: 0.330699 | Val. Kappa Score: 0.7875 | Estimated time: 163.79
Train loss on 50 batch: 0.337100
Train loss on 100 batch: 0.363657
Train loss on 150 batch: 0.279011
: Epoch: 22 | Training Loss: 0.320791 | Val. Loss: 0.336349 | Val. Kappa Score: 0.7908 | Estimated time: 164.73
Train loss on 50 batch: 0.333977
Train loss on 100 batch: 0.297865
Train loss on 150 batch: 0.333442
: Epoch: 23 | Training Loss: 0.308980 | Val. Loss: 0.396174 | Val. Kappa Score: 0.7933 | Estimated time: 164.26
Train loss on 50 batch: 0.383895
Train loss on 100 batch: 0.407357
Train loss on 150 batch: 0.375269
: Epoch: 24 | Training Loss: 0.383914 | Val. Loss: 0.546231 | Val. Kappa Score: 0.7940 | Estimated time: 164.68
time_estimated: 3937.36
n-epochs: 24
time_estimated: 3937.36
----------------------------------------

Experiment N: 4: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.006, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : new
date: 2019.08.11 12:36:00
data-type: new_old_mixed_new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.006
    lr: 0.006
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95f97a20>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 45
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.398009
Train loss on 100 batch: 0.399207
Train loss on 150 batch: 0.530880
best-train-loss: 0.427205
best-valid-loss: 0.396491
best-kappa: 0.8346
: Epoch: 1 | Training Loss: 0.427205 | Val. Loss: 0.396491 | Val. Kappa Score: 0.8346 | Estimated time: 163.39
Train loss on 50 batch: 0.370038
Train loss on 100 batch: 0.378715
Train loss on 150 batch: 0.353543
: Epoch: 2 | Training Loss: 0.362842 | Val. Loss: 0.483143 | Val. Kappa Score: 0.8332 | Estimated time: 162.91
Train loss on 50 batch: 0.309907
Train loss on 100 batch: 0.364683
Train loss on 150 batch: 0.349094
best-train-loss: 0.362482
best-valid-loss: 0.340151
best-kappa: 0.8402
: Epoch: 3 | Training Loss: 0.362482 | Val. Loss: 0.340151 | Val. Kappa Score: 0.8402 | Estimated time: 164.28
Train loss on 50 batch: 0.347885
Train loss on 100 batch: 0.326606
Train loss on 150 batch: 0.326952
best-train-loss: 0.369289
best-valid-loss: 0.325530
best-kappa: 0.8461
: Epoch: 4 | Training Loss: 0.369289 | Val. Loss: 0.325530 | Val. Kappa Score: 0.8461 | Estimated time: 164.76
Train loss on 50 batch: 0.316984
Train loss on 100 batch: 0.342846
Train loss on 150 batch: 0.376913
: Epoch: 5 | Training Loss: 0.345802 | Val. Loss: 0.330754 | Val. Kappa Score: 0.8507 | Estimated time: 163.43
Train loss on 50 batch: 0.358182
Train loss on 100 batch: 0.412956
Train loss on 150 batch: 0.347926
: Epoch: 6 | Training Loss: 0.398250 | Val. Loss: 0.396685 | Val. Kappa Score: 0.8508 | Estimated time: 163.59
Train loss on 50 batch: 0.457218
Train loss on 100 batch: 0.383712
Train loss on 150 batch: 0.389654
: Epoch: 7 | Training Loss: 0.412275 | Val. Loss: 0.688925 | Val. Kappa Score: 0.8363 | Estimated time: 165.70
Train loss on 50 batch: 0.363885
Train loss on 100 batch: 0.377262
Train loss on 150 batch: 0.356097
: Epoch: 8 | Training Loss: 0.391389 | Val. Loss: 0.390262 | Val. Kappa Score: 0.8362 | Estimated time: 164.04
Train loss on 50 batch: 0.354553
Train loss on 100 batch: 0.306873
Train loss on 150 batch: 0.363107
: Epoch: 9 | Training Loss: 0.310284 | Val. Loss: 0.350521 | Val. Kappa Score: 0.8388 | Estimated time: 163.73
Train loss on 50 batch: 0.270707
Train loss on 100 batch: 0.366705
Train loss on 150 batch: 0.305310
: Epoch: 10 | Training Loss: 0.303192 | Val. Loss: 0.339682 | Val. Kappa Score: 0.8411 | Estimated time: 165.52
Train loss on 50 batch: 0.271566
Train loss on 100 batch: 0.332526
Train loss on 150 batch: 0.342238
best-train-loss: 0.319932
best-valid-loss: 0.313264
best-kappa: 0.8444
: Epoch: 11 | Training Loss: 0.319932 | Val. Loss: 0.313264 | Val. Kappa Score: 0.8444 | Estimated time: 162.91
Train loss on 50 batch: 0.306716
Train loss on 100 batch: 0.336500
Train loss on 150 batch: 0.346897
: Epoch: 12 | Training Loss: 0.341086 | Val. Loss: 0.424551 | Val. Kappa Score: 0.8442 | Estimated time: 163.81
Train loss on 50 batch: 0.290273
Train loss on 100 batch: 0.431479
Train loss on 150 batch: 0.403056
: Epoch: 13 | Training Loss: 0.375773 | Val. Loss: 0.355859 | Val. Kappa Score: 0.8451 | Estimated time: 165.46
Train loss on 50 batch: 0.387827
Train loss on 100 batch: 0.354337
Train loss on 150 batch: 0.302012
: Epoch: 14 | Training Loss: 0.355405 | Val. Loss: 0.614991 | Val. Kappa Score: 0.8397 | Estimated time: 165.76
Train loss on 50 batch: 0.345596
Train loss on 100 batch: 0.284266
Train loss on 150 batch: 0.279080
: Epoch: 15 | Training Loss: 0.326269 | Val. Loss: 0.343317 | Val. Kappa Score: 0.8408 | Estimated time: 166.40
Train loss on 50 batch: 0.265854
Train loss on 100 batch: 0.313462
Train loss on 150 batch: 0.300850
best-train-loss: 0.291845
best-valid-loss: 0.305394
best-kappa: 0.8427
: Epoch: 16 | Training Loss: 0.291845 | Val. Loss: 0.305394 | Val. Kappa Score: 0.8427 | Estimated time: 165.06
Train loss on 50 batch: 0.350182
Train loss on 100 batch: 0.322576
Train loss on 150 batch: 0.283253
: Epoch: 17 | Training Loss: 0.296683 | Val. Loss: 0.320118 | Val. Kappa Score: 0.8443 | Estimated time: 166.79
Train loss on 50 batch: 0.385143
Train loss on 100 batch: 0.348948
Train loss on 150 batch: 0.331681
: Epoch: 18 | Training Loss: 0.346649 | Val. Loss: 0.460648 | Val. Kappa Score: 0.8443 | Estimated time: 166.97
Train loss on 50 batch: 0.438880
Train loss on 100 batch: 0.412214
Train loss on 150 batch: 0.350485
: Epoch: 19 | Training Loss: 0.420741 | Val. Loss: 1.318777 | Val. Kappa Score: 0.8295 | Estimated time: 164.96
Train loss on 50 batch: 0.416524
Train loss on 100 batch: 0.349464
Train loss on 150 batch: 0.305378
: Epoch: 20 | Training Loss: 0.346074 | Val. Loss: 0.378189 | Val. Kappa Score: 0.8307 | Estimated time: 164.60
Train loss on 50 batch: 0.290626
Train loss on 100 batch: 0.319506
Train loss on 150 batch: 0.362381
: Epoch: 21 | Training Loss: 0.311080 | Val. Loss: 0.314874 | Val. Kappa Score: 0.8326 | Estimated time: 168.17
Train loss on 50 batch: 0.322120
Train loss on 100 batch: 0.329265
Train loss on 150 batch: 0.252936
: Epoch: 22 | Training Loss: 0.296467 | Val. Loss: 0.316011 | Val. Kappa Score: 0.8343 | Estimated time: 166.81
Train loss on 50 batch: 0.303874
Train loss on 100 batch: 0.266243
Train loss on 150 batch: 0.304454
: Epoch: 23 | Training Loss: 0.276989 | Val. Loss: 0.336630 | Val. Kappa Score: 0.8359 | Estimated time: 165.70
Train loss on 50 batch: 0.328311
Train loss on 100 batch: 0.350804
Train loss on 150 batch: 0.352193
: Epoch: 24 | Training Loss: 0.344294 | Val. Loss: 0.445798 | Val. Kappa Score: 0.8359 | Estimated time: 166.56
Train loss on 50 batch: 0.332642
Train loss on 100 batch: 0.351148
Train loss on 150 batch: 0.382878
: Epoch: 25 | Training Loss: 0.433693 | Val. Loss: 0.544380 | Val. Kappa Score: 0.8331 | Estimated time: 169.58
Train loss on 50 batch: 0.522029
Train loss on 100 batch: 0.413275
Train loss on 150 batch: 0.372052
: Epoch: 26 | Training Loss: 0.422463 | Val. Loss: 0.604098 | Val. Kappa Score: 0.8300 | Estimated time: 164.77
time_estimated: 4296.42
n-epochs: 26
time_estimated: 4296.42
----------------------------------------

Experiment N: 5: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 08:53:57
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d09d518>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 5: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 08:55:13
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d091550>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.016527
Train loss on 100 batch: 0.981022
Train loss on 150 batch: 1.006505
Train loss on 200 batch: 0.859798
Train loss on 250 batch: 0.743586
Train loss on 300 batch: 0.772801
----------------------------------------

Experiment N: 5: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 08:59:27
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10f6a0>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.957247
Train loss on 100 batch: 1.028910
Train loss on 150 batch: 1.048629
Train loss on 200 batch: 0.881764
Train loss on 250 batch: 0.839608
Train loss on 300 batch: 0.797090
Train loss on 350 batch: 0.724853
Train loss on 400 batch: 0.838501
Train loss on 450 batch: 0.800746
Train loss on 500 batch: 0.948956
Train loss on 550 batch: 0.774738
Train loss on 600 batch: 0.726126
Train loss on 650 batch: 0.792775
Train loss on 700 batch: 0.719365
Train loss on 750 batch: 0.786348
Train loss on 800 batch: 0.648114
Train loss on 850 batch: 0.708651
Train loss on 900 batch: 0.860373
Train loss on 950 batch: 0.689005
Train loss on 1000 batch: 0.662551
Train loss on 1050 batch: 0.721036
Train loss on 1100 batch: 0.697020
Train loss on 1150 batch: 0.627562
Train loss on 1200 batch: 0.701400
Train loss on 1250 batch: 0.650103
Train loss on 1300 batch: 0.641078
Train loss on 1350 batch: 0.802054
Train loss on 1400 batch: 0.768029
Train loss on 1450 batch: 0.778918
Train loss on 1500 batch: 0.734187
Train loss on 1550 batch: 0.727582
Train loss on 1600 batch: 0.710371
Train loss on 1650 batch: 0.694148
Train loss on 1700 batch: 0.669547
Train loss on 1750 batch: 0.639188
Train loss on 1800 batch: 0.658022
Train loss on 1850 batch: 0.622138
Train loss on 1900 batch: 0.699820
Train loss on 1950 batch: 0.673769
Train loss on 2000 batch: 0.611486
Train loss on 2050 batch: 0.527973
Train loss on 2100 batch: 0.659759
Train loss on 2150 batch: 0.650972
----------------------------------------

Experiment N: 5: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 09:07:54
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fc6080>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.957247
Train loss on 100 batch: 1.028910
Train loss on 150 batch: 1.048629
Train loss on 200 batch: 0.881764
Train loss on 250 batch: 0.839608
Train loss on 300 batch: 0.797090
Train loss on 350 batch: 0.724853
Train loss on 400 batch: 0.838501
Train loss on 450 batch: 0.800746
Train loss on 500 batch: 0.948956
Train loss on 550 batch: 0.774738
Train loss on 600 batch: 0.726126
Train loss on 650 batch: 0.792775
Train loss on 700 batch: 0.719365
Train loss on 750 batch: 0.786348
Train loss on 800 batch: 0.648114
Train loss on 850 batch: 0.708651
Train loss on 900 batch: 0.860373
Train loss on 950 batch: 0.689005
Train loss on 1000 batch: 0.662551
Train loss on 1050 batch: 0.721036
Train loss on 1100 batch: 0.697020
Train loss on 1150 batch: 0.627562
Train loss on 1200 batch: 0.701400
Train loss on 1250 batch: 0.650103
Train loss on 1300 batch: 0.641078
Train loss on 1350 batch: 0.802054
Train loss on 1400 batch: 0.768029
Train loss on 1450 batch: 0.778918
Train loss on 1500 batch: 0.734187
Train loss on 1550 batch: 0.727582
Train loss on 1600 batch: 0.710371
Train loss on 1650 batch: 0.694148
Train loss on 1700 batch: 0.669547
Train loss on 1750 batch: 0.639188
Train loss on 1800 batch: 0.658022
Train loss on 1850 batch: 0.622138
Train loss on 1900 batch: 0.699820
Train loss on 1950 batch: 0.673769
Train loss on 2000 batch: 0.611486
Train loss on 2050 batch: 0.527973
Train loss on 2100 batch: 0.659759
Train loss on 2150 batch: 0.650972
best-train-loss: 0.740204
best-valid-loss: 0.495962
best-kappa: 0.8033
: Epoch: 1 | Training Loss: 0.740204 | Val. Loss: 0.495962 | Val. Kappa Score: 0.8033 | Estimated time: 327.28
Train loss on 50 batch: 0.669066
Train loss on 100 batch: 0.629075
Train loss on 150 batch: 0.651834
Train loss on 200 batch: 0.580748
Train loss on 250 batch: 0.698516
Train loss on 300 batch: 0.692646
Train loss on 350 batch: 0.589083
Train loss on 400 batch: 0.583181
Train loss on 450 batch: 0.669272
Train loss on 500 batch: 0.622437
Train loss on 550 batch: 0.588266
Train loss on 600 batch: 0.630741
Train loss on 650 batch: 0.630548
Train loss on 700 batch: 0.560465
Train loss on 750 batch: 0.640875
Train loss on 800 batch: 0.591070
Train loss on 850 batch: 0.519846
Train loss on 900 batch: 0.630213
Train loss on 950 batch: 0.622189
Train loss on 1000 batch: 0.600852
Train loss on 1050 batch: 0.596662
Train loss on 1100 batch: 0.604482
Train loss on 1150 batch: 0.610095
Train loss on 1200 batch: 0.549414
Train loss on 1250 batch: 0.514109
Train loss on 1300 batch: 0.644614
Train loss on 1350 batch: 0.773215
Train loss on 1400 batch: 0.691190
Train loss on 1450 batch: 0.648512
Train loss on 1500 batch: 0.659500
Train loss on 1550 batch: 0.562811
Train loss on 1600 batch: 0.617890
Train loss on 1650 batch: 0.627872
Train loss on 1700 batch: 0.605887
Train loss on 1750 batch: 0.662602
Train loss on 1800 batch: 0.529457
Train loss on 1850 batch: 0.572406
Train loss on 1900 batch: 0.615567
Train loss on 1950 batch: 0.569810
Train loss on 2000 batch: 0.593047
Train loss on 2050 batch: 0.579013
Train loss on 2100 batch: 0.575694
Train loss on 2150 batch: 0.630220
best-train-loss: 0.615196
best-valid-loss: 0.434326
best-kappa: 0.8151
: Epoch: 2 | Training Loss: 0.615196 | Val. Loss: 0.434326 | Val. Kappa Score: 0.8151 | Estimated time: 328.80
Train loss on 50 batch: 0.551355
Train loss on 100 batch: 0.609361
Train loss on 150 batch: 0.525251
Train loss on 200 batch: 0.520787
Train loss on 250 batch: 0.621029
Train loss on 300 batch: 0.564667
Train loss on 350 batch: 0.542728
Train loss on 400 batch: 0.526610
Train loss on 450 batch: 0.560410
Train loss on 500 batch: 0.637951
Train loss on 550 batch: 0.585715
Train loss on 600 batch: 0.592843
Train loss on 650 batch: 0.688112
Train loss on 700 batch: 0.538971
Train loss on 750 batch: 0.542354
Train loss on 800 batch: 0.656532
Train loss on 850 batch: 0.610531
Train loss on 900 batch: 0.550457
Train loss on 950 batch: 0.587414
Train loss on 1000 batch: 0.603571
Train loss on 1050 batch: 0.679680
Train loss on 1100 batch: 0.596724
Train loss on 1150 batch: 0.558906
Train loss on 1200 batch: 0.585097
Train loss on 1250 batch: 0.644522
Train loss on 1300 batch: 0.603127
Train loss on 1350 batch: 0.593875
Train loss on 1400 batch: 0.563745
Train loss on 1450 batch: 0.640856
Train loss on 1500 batch: 0.566763
Train loss on 1550 batch: 0.597598
Train loss on 1600 batch: 0.476850
Train loss on 1650 batch: 0.644918
Train loss on 1700 batch: 0.580302
Train loss on 1750 batch: 0.514731
Train loss on 1800 batch: 0.553541
Train loss on 1850 batch: 0.489642
Train loss on 1900 batch: 0.514868
Train loss on 1950 batch: 0.593468
Train loss on 2000 batch: 0.556583
Train loss on 2050 batch: 0.603086
Train loss on 2100 batch: 0.627285
Train loss on 2150 batch: 0.539333
: Epoch: 3 | Training Loss: 0.579968 | Val. Loss: 0.624287 | Val. Kappa Score: 0.7959 | Estimated time: 326.03
Train loss on 50 batch: 0.571249
Train loss on 100 batch: 0.624134
Train loss on 150 batch: 0.529018
Train loss on 200 batch: 0.567510
Train loss on 250 batch: 0.587718
Train loss on 300 batch: 0.539342
Train loss on 350 batch: 0.612980
Train loss on 400 batch: 0.596316
Train loss on 450 batch: 0.626307
Train loss on 500 batch: 0.570689
Train loss on 550 batch: 0.572986
Train loss on 600 batch: 0.605982
Train loss on 650 batch: 0.610952
Train loss on 700 batch: 0.605806
Train loss on 750 batch: 0.547317
Train loss on 800 batch: 0.577884
Train loss on 850 batch: 0.556231
Train loss on 900 batch: 0.534606
Train loss on 950 batch: 0.528856
Train loss on 1000 batch: 0.538073
Train loss on 1050 batch: 0.532405
Train loss on 1100 batch: 0.505032
Train loss on 1150 batch: 0.550390
Train loss on 1200 batch: 0.560437
Train loss on 1250 batch: 0.575232
Train loss on 1300 batch: 0.509188
Train loss on 1350 batch: 0.496882
Train loss on 1400 batch: 0.501741
Train loss on 1450 batch: 0.599738
Train loss on 1500 batch: 0.580942
Train loss on 1550 batch: 0.549552
Train loss on 1600 batch: 0.459421
Train loss on 1650 batch: 0.619336
Train loss on 1700 batch: 0.634038
Train loss on 1750 batch: 0.469785
Train loss on 1800 batch: 0.532960
Train loss on 1850 batch: 0.502628
Train loss on 1900 batch: 0.506299
Train loss on 1950 batch: 0.557069
Train loss on 2000 batch: 0.529806
Train loss on 2050 batch: 0.510062
Train loss on 2100 batch: 0.487840
Train loss on 2150 batch: 0.551395
: Epoch: 4 | Training Loss: 0.553356 | Val. Loss: 0.516079 | Val. Kappa Score: 0.8003 | Estimated time: 324.23
Train loss on 50 batch: 0.493801
Train loss on 100 batch: 0.597252
Train loss on 150 batch: 0.547189
Train loss on 200 batch: 0.553597
Train loss on 250 batch: 0.471161
Train loss on 300 batch: 0.553727
Train loss on 350 batch: 0.553416
Train loss on 400 batch: 0.474598
Train loss on 450 batch: 0.537608
Train loss on 500 batch: 0.507666
Train loss on 550 batch: 0.500665
Train loss on 600 batch: 0.523026
Train loss on 650 batch: 0.591454
Train loss on 700 batch: 0.542931
Train loss on 750 batch: 0.486242
Train loss on 800 batch: 0.576304
Train loss on 850 batch: 0.502098
Train loss on 900 batch: 0.602042
Train loss on 950 batch: 0.405770
Train loss on 1000 batch: 0.496768
Train loss on 1050 batch: 0.487361
Train loss on 1100 batch: 0.468334
Train loss on 1150 batch: 0.519651
Train loss on 1200 batch: 0.460666
Train loss on 1250 batch: 0.634511
Train loss on 1300 batch: 0.633667
Train loss on 1350 batch: 0.573901
Train loss on 1400 batch: 0.563288
Train loss on 1450 batch: 0.476681
Train loss on 1500 batch: 0.444696
Train loss on 1550 batch: 0.568566
Train loss on 1600 batch: 0.574227
Train loss on 1650 batch: 0.591897
Train loss on 1700 batch: 0.511840
Train loss on 1750 batch: 0.549842
Train loss on 1800 batch: 0.571707
Train loss on 1850 batch: 0.498723
Train loss on 1900 batch: 0.519769
Train loss on 1950 batch: 0.508189
Train loss on 2000 batch: 0.558716
Train loss on 2050 batch: 0.538956
Train loss on 2100 batch: 0.477151
Train loss on 2150 batch: 0.538842
: Epoch: 5 | Training Loss: 0.531184 | Val. Loss: 0.454688 | Val. Kappa Score: 0.8052 | Estimated time: 330.11
Train loss on 50 batch: 0.485008
Train loss on 100 batch: 0.582010
Train loss on 150 batch: 0.485461
Train loss on 200 batch: 0.479388
Train loss on 250 batch: 0.437562
Train loss on 300 batch: 0.556546
Train loss on 350 batch: 0.445082
Train loss on 400 batch: 0.406986
Train loss on 450 batch: 0.508863
Train loss on 500 batch: 0.473721
Train loss on 550 batch: 0.427203
Train loss on 600 batch: 0.493298
Train loss on 650 batch: 0.462599
Train loss on 700 batch: 0.494280
Train loss on 750 batch: 0.524829
Train loss on 800 batch: 0.437446
Train loss on 850 batch: 0.472012
Train loss on 900 batch: 0.456221
Train loss on 950 batch: 0.460874
Train loss on 1000 batch: 0.417863
Train loss on 1050 batch: 0.488314
Train loss on 1100 batch: 0.445588
Train loss on 1150 batch: 0.473865
Train loss on 1200 batch: 0.477719
Train loss on 1250 batch: 0.490060
Train loss on 1300 batch: 0.439987
Train loss on 1350 batch: 0.407586
Train loss on 1400 batch: 0.428037
Train loss on 1450 batch: 0.472861
Train loss on 1500 batch: 0.505323
Train loss on 1550 batch: 0.468068
Train loss on 1600 batch: 0.563455
Train loss on 1650 batch: 0.496500
Train loss on 1700 batch: 0.458726
Train loss on 1750 batch: 0.490047
Train loss on 1800 batch: 0.472685
Train loss on 1850 batch: 0.477343
Train loss on 1900 batch: 0.442610
Train loss on 1950 batch: 0.481178
Train loss on 2000 batch: 0.472604
Train loss on 2050 batch: 0.408758
Train loss on 2100 batch: 0.531030
Train loss on 2150 batch: 0.634106
: Epoch: 6 | Training Loss: 0.478807 | Val. Loss: 0.496361 | Val. Kappa Score: 0.8088 | Estimated time: 329.30
Train loss on 50 batch: 0.471499
Train loss on 100 batch: 0.468297
Train loss on 150 batch: 0.423976
Train loss on 200 batch: 0.392194
Train loss on 250 batch: 0.492374
Train loss on 300 batch: 0.411774
Train loss on 350 batch: 0.408645
Train loss on 400 batch: 0.455180
Train loss on 450 batch: 0.414894
Train loss on 500 batch: 0.458637
Train loss on 550 batch: 0.499241
Train loss on 600 batch: 0.470849
Train loss on 650 batch: 0.440610
Train loss on 700 batch: 0.491159
Train loss on 750 batch: 0.471254
Train loss on 800 batch: 0.525320
Train loss on 850 batch: 0.430980
Train loss on 900 batch: 0.396339
Train loss on 950 batch: 0.399695
Train loss on 1000 batch: 0.492729
Train loss on 1050 batch: 0.437898
Train loss on 1100 batch: 0.498427
Train loss on 1150 batch: 0.437581
Train loss on 1200 batch: 0.471450
Train loss on 1250 batch: 0.516234
Train loss on 1300 batch: 0.448112
Train loss on 1350 batch: 0.470591
Train loss on 1400 batch: 0.426269
Train loss on 1450 batch: 0.410712
Train loss on 1500 batch: 0.462599
Train loss on 1550 batch: 0.416536
Train loss on 1600 batch: 0.408680
Train loss on 1650 batch: 0.455208
Train loss on 1700 batch: 0.449311
Train loss on 1750 batch: 0.493007
Train loss on 1800 batch: 0.442618
Train loss on 1850 batch: 0.452833
Train loss on 1900 batch: 0.462140
Train loss on 1950 batch: 0.481963
Train loss on 2000 batch: 0.453992
Train loss on 2050 batch: 0.539863
Train loss on 2100 batch: 0.515982
Train loss on 2150 batch: 0.476382
: Epoch: 7 | Training Loss: 0.456883 | Val. Loss: 0.694674 | Val. Kappa Score: 0.8046 | Estimated time: 327.92
Train loss on 50 batch: 0.534077
Train loss on 100 batch: 0.507664
Train loss on 150 batch: 0.422718
Train loss on 200 batch: 0.526756
Train loss on 250 batch: 0.376994
Train loss on 300 batch: 0.432150
Train loss on 350 batch: 0.370380
Train loss on 400 batch: 0.439829
Train loss on 450 batch: 0.424887
Train loss on 500 batch: 0.471622
Train loss on 550 batch: 0.438430
Train loss on 600 batch: 0.457752
Train loss on 650 batch: 0.421097
Train loss on 700 batch: 0.461471
Train loss on 750 batch: 0.487240
Train loss on 800 batch: 0.444345
Train loss on 850 batch: 0.430318
Train loss on 900 batch: 0.470222
Train loss on 950 batch: 0.521230
Train loss on 1000 batch: 0.463237
Train loss on 1050 batch: 0.468001
Train loss on 1100 batch: 0.471642
Train loss on 1150 batch: 0.411872
Train loss on 1200 batch: 0.479475
Train loss on 1250 batch: 0.403708
Train loss on 1300 batch: 0.407847
Train loss on 1350 batch: 0.453521
Train loss on 1400 batch: 0.429399
Train loss on 1450 batch: 0.357124
Train loss on 1500 batch: 0.480545
Train loss on 1550 batch: 0.440990
Train loss on 1600 batch: 0.426215
Train loss on 1650 batch: 0.489127
Train loss on 1700 batch: 0.380217
Train loss on 1750 batch: 0.457408
Train loss on 1800 batch: 0.441324
Train loss on 1850 batch: 0.483962
Train loss on 1900 batch: 0.467299
Train loss on 1950 batch: 0.425798
Train loss on 2000 batch: 0.439802
Train loss on 2050 batch: 0.419721
Train loss on 2100 batch: 0.448904
Train loss on 2150 batch: 0.483536
best-train-loss: 0.448021
best-valid-loss: 0.434273
best-kappa: 0.8090
: Epoch: 8 | Training Loss: 0.448021 | Val. Loss: 0.434273 | Val. Kappa Score: 0.8090 | Estimated time: 323.44
Train loss on 50 batch: 0.448332
Train loss on 100 batch: 0.480357
Train loss on 150 batch: 0.439758
Train loss on 200 batch: 0.442244
Train loss on 250 batch: 0.450407
Train loss on 300 batch: 0.381383
Train loss on 350 batch: 0.447489
Train loss on 400 batch: 0.492781
Train loss on 450 batch: 0.459257
Train loss on 500 batch: 0.380611
Train loss on 550 batch: 0.410553
Train loss on 600 batch: 0.431272
Train loss on 650 batch: 0.443090
Train loss on 700 batch: 0.538814
Train loss on 750 batch: 0.413397
Train loss on 800 batch: 0.417600
Train loss on 850 batch: 0.518352
Train loss on 900 batch: 0.458193
Train loss on 950 batch: 0.433165
Train loss on 1000 batch: 0.399550
Train loss on 1050 batch: 0.408840
Train loss on 1100 batch: 0.450481
Train loss on 1150 batch: 0.402530
Train loss on 1200 batch: 0.372361
Train loss on 1250 batch: 0.404203
Train loss on 1300 batch: 0.403542
Train loss on 1350 batch: 0.453284
Train loss on 1400 batch: 0.452110
Train loss on 1450 batch: 0.368771
Train loss on 1500 batch: 0.480146
Train loss on 1550 batch: 0.394266
Train loss on 1600 batch: 0.449318
Train loss on 1650 batch: 0.449460
Train loss on 1700 batch: 0.359051
Train loss on 1750 batch: 0.451688
Train loss on 1800 batch: 0.443027
Train loss on 1850 batch: 0.527346
Train loss on 1900 batch: 0.387792
Train loss on 1950 batch: 0.425337
Train loss on 2000 batch: 0.458268
Train loss on 2050 batch: 0.428572
Train loss on 2100 batch: 0.429833
Train loss on 2150 batch: 0.425134
: Epoch: 9 | Training Loss: 0.436773 | Val. Loss: 0.788306 | Val. Kappa Score: 0.8062 | Estimated time: 322.86
Train loss on 50 batch: 0.485818
Train loss on 100 batch: 0.431939
Train loss on 150 batch: 0.457888
Train loss on 200 batch: 0.458298
Train loss on 250 batch: 0.409776
Train loss on 300 batch: 0.381744
Train loss on 350 batch: 0.460249
Train loss on 400 batch: 0.437004
Train loss on 450 batch: 0.502470
Train loss on 500 batch: 0.476773
Train loss on 550 batch: 0.435865
Train loss on 600 batch: 0.415361
Train loss on 650 batch: 0.412468
Train loss on 700 batch: 0.456983
Train loss on 750 batch: 0.449780
Train loss on 800 batch: 0.487919
Train loss on 850 batch: 0.403061
Train loss on 900 batch: 0.449606
Train loss on 950 batch: 0.418662
Train loss on 1000 batch: 0.430060
Train loss on 1050 batch: 0.391017
Train loss on 1100 batch: 0.417692
Train loss on 1150 batch: 0.359518
Train loss on 1200 batch: 0.435698
Train loss on 1250 batch: 0.427424
Train loss on 1300 batch: 0.378212
Train loss on 1350 batch: 0.425907
Train loss on 1400 batch: 0.489222
Train loss on 1450 batch: 0.422839
Train loss on 1500 batch: 0.347475
Train loss on 1550 batch: 0.442915
Train loss on 1600 batch: 0.392697
Train loss on 1650 batch: 0.412651
Train loss on 1700 batch: 0.404566
Train loss on 1750 batch: 0.369187
Train loss on 1800 batch: 0.456788
Train loss on 1850 batch: 0.437559
Train loss on 1900 batch: 0.359132
Train loss on 1950 batch: 0.509092
Train loss on 2000 batch: 0.474083
Train loss on 2050 batch: 0.462313
Train loss on 2100 batch: 0.496545
Train loss on 2150 batch: 0.441679
: Epoch: 10 | Training Loss: 0.433337 | Val. Loss: 0.584227 | Val. Kappa Score: 0.8082 | Estimated time: 325.48
Train loss on 50 batch: 0.440827
Train loss on 100 batch: 0.379914
Train loss on 150 batch: 0.439751
Train loss on 200 batch: 0.441580
Train loss on 250 batch: 0.377604
Train loss on 300 batch: 0.466823
Train loss on 350 batch: 0.508034
Train loss on 400 batch: 0.424351
Train loss on 450 batch: 0.413472
Train loss on 500 batch: 0.421117
Train loss on 550 batch: 0.451439
Train loss on 600 batch: 0.402013
Train loss on 650 batch: 0.431117
Train loss on 700 batch: 0.446323
Train loss on 750 batch: 0.353978
Train loss on 800 batch: 0.405406
Train loss on 850 batch: 0.476625
Train loss on 900 batch: 0.460230
Train loss on 950 batch: 0.444601
Train loss on 1000 batch: 0.400006
Train loss on 1050 batch: 0.436607
Train loss on 1100 batch: 0.401617
Train loss on 1150 batch: 0.425140
Train loss on 1200 batch: 0.390312
Train loss on 1250 batch: 0.419356
Train loss on 1300 batch: 0.432309
Train loss on 1350 batch: 0.376892
Train loss on 1400 batch: 0.436214
Train loss on 1450 batch: 0.469061
Train loss on 1500 batch: 0.383203
Train loss on 1550 batch: 0.464504
Train loss on 1600 batch: 0.483312
Train loss on 1650 batch: 0.395513
Train loss on 1700 batch: 0.458723
Train loss on 1750 batch: 0.402963
Train loss on 1800 batch: 0.486073
Train loss on 1850 batch: 0.411445
Train loss on 1900 batch: 0.429380
Train loss on 1950 batch: 0.492010
Train loss on 2000 batch: 0.439278
Train loss on 2050 batch: 0.424352
Train loss on 2100 batch: 0.437038
Train loss on 2150 batch: 0.409053
: Epoch: 11 | Training Loss: 0.429463 | Val. Loss: 0.895423 | Val. Kappa Score: 0.8069 | Estimated time: 324.33
Train loss on 50 batch: 0.414826
Train loss on 100 batch: 0.408576
Train loss on 150 batch: 0.425718
----------------------------------------

Experiment N: 6: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 10:08:45
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d092780>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.050397
Train loss on 100 batch: 1.029933
Train loss on 150 batch: 1.086609
Train loss on 200 batch: 0.979686
Train loss on 250 batch: 0.824168
Train loss on 300 batch: 0.846157
Train loss on 350 batch: 0.780562
Train loss on 400 batch: 0.942009
Train loss on 450 batch: 0.880515
Train loss on 500 batch: 0.998112
Train loss on 550 batch: 0.788949
Train loss on 600 batch: 0.769242
Train loss on 650 batch: 0.889304
Train loss on 700 batch: 0.800295
Train loss on 750 batch: 0.893172
Train loss on 800 batch: 0.726370
Train loss on 850 batch: 0.793807
Train loss on 900 batch: 0.876264
Train loss on 950 batch: 0.788756
Train loss on 1000 batch: 0.792930
Train loss on 1050 batch: 0.842979
Train loss on 1100 batch: 0.818044
Train loss on 1150 batch: 0.742595
Train loss on 1200 batch: 0.760637
Train loss on 1250 batch: 0.719345
Train loss on 1300 batch: 0.749122
Train loss on 1350 batch: 0.660216
Train loss on 1400 batch: 0.740524
Train loss on 1450 batch: 0.813592
Train loss on 1500 batch: 0.815067
Train loss on 1550 batch: 0.753968
Train loss on 1600 batch: 0.743172
Train loss on 1650 batch: 0.688137
Train loss on 1700 batch: 0.693214
Train loss on 1750 batch: 0.705652
Train loss on 1800 batch: 0.690806
Train loss on 1850 batch: 0.656012
Train loss on 1900 batch: 0.786610
Train loss on 1950 batch: 0.760353
Train loss on 2000 batch: 0.710777
Train loss on 2050 batch: 0.615103
Train loss on 2100 batch: 0.695802
Train loss on 2150 batch: 0.756566
best-train-loss: 0.799971
best-valid-loss: 0.834489
best-kappa: 0.7731
: Epoch: 1 | Training Loss: 0.799971 | Val. Loss: 0.834489 | Val. Kappa Score: 0.7731 | Estimated time: 399.51
Train loss on 50 batch: 0.794130
Train loss on 100 batch: 0.728027
Train loss on 150 batch: 0.769365
Train loss on 200 batch: 0.656916
Train loss on 250 batch: 0.755497
Train loss on 300 batch: 0.785301
Train loss on 350 batch: 0.674713
Train loss on 400 batch: 0.720238
Train loss on 450 batch: 0.693433
Train loss on 500 batch: 0.692001
Train loss on 550 batch: 0.669909
Train loss on 600 batch: 0.690621
Train loss on 650 batch: 0.706683
Train loss on 700 batch: 0.637411
Train loss on 750 batch: 0.733869
Train loss on 800 batch: 0.692999
Train loss on 850 batch: 0.677342
Train loss on 900 batch: 0.685069
Train loss on 950 batch: 0.741841
Train loss on 1000 batch: 0.703294
Train loss on 1050 batch: 0.702234
Train loss on 1100 batch: 0.615213
Train loss on 1150 batch: 0.694951
Train loss on 1200 batch: 0.631794
Train loss on 1250 batch: 0.611629
Train loss on 1300 batch: 0.702092
Train loss on 1350 batch: 0.908164
Train loss on 1400 batch: 0.709374
Train loss on 1450 batch: 0.666838
Train loss on 1500 batch: 0.776372
Train loss on 1550 batch: 0.662312
Train loss on 1600 batch: 0.700257
Train loss on 1650 batch: 0.687758
Train loss on 1700 batch: 0.689413
Train loss on 1750 batch: 0.817810
Train loss on 1800 batch: 0.647194
Train loss on 1850 batch: 0.615935
Train loss on 1900 batch: 0.686482
Train loss on 1950 batch: 0.648975
Train loss on 2000 batch: 0.699663
Train loss on 2050 batch: 0.613057
Train loss on 2100 batch: 0.645096
Train loss on 2150 batch: 0.741333
best-train-loss: 0.700151
best-valid-loss: 0.831682
best-kappa: 0.7270
: Epoch: 2 | Training Loss: 0.700151 | Val. Loss: 0.831682 | Val. Kappa Score: 0.7270 | Estimated time: 399.20
Train loss on 50 batch: 0.620848
Train loss on 100 batch: 0.719542
Train loss on 150 batch: 0.623355
Train loss on 200 batch: 0.646141
Train loss on 250 batch: 0.741408
Train loss on 300 batch: 0.614748
Train loss on 350 batch: 0.674056
Train loss on 400 batch: 0.621232
Train loss on 450 batch: 0.614060
Train loss on 500 batch: 0.704839
Train loss on 550 batch: 0.744995
Train loss on 600 batch: 0.612437
Train loss on 650 batch: 0.720830
Train loss on 700 batch: 0.619777
Train loss on 750 batch: 0.589923
Train loss on 800 batch: 0.764781
Train loss on 850 batch: 0.690683
Train loss on 900 batch: 0.641328
Train loss on 950 batch: 0.706269
Train loss on 1000 batch: 0.754586
Train loss on 1050 batch: 0.754838
Train loss on 1100 batch: 0.615641
Train loss on 1150 batch: 0.654031
Train loss on 1200 batch: 0.650071
Train loss on 1250 batch: 0.745118
Train loss on 1300 batch: 0.688620
Train loss on 1350 batch: 0.703893
Train loss on 1400 batch: 0.656670
Train loss on 1450 batch: 0.729516
Train loss on 1500 batch: 0.679136
Train loss on 1550 batch: 0.673360
Train loss on 1600 batch: 0.566159
Train loss on 1650 batch: 0.726739
Train loss on 1700 batch: 0.664247
Train loss on 1750 batch: 0.679611
Train loss on 1800 batch: 0.636045
Train loss on 1850 batch: 0.654560
Train loss on 1900 batch: 0.620772
Train loss on 1950 batch: 0.676211
Train loss on 2000 batch: 0.615109
Train loss on 2050 batch: 0.660083
Train loss on 2100 batch: 0.649940
Train loss on 2150 batch: 0.581563
best-train-loss: 0.667087
best-valid-loss: 0.549099
best-kappa: 0.7409
: Epoch: 3 | Training Loss: 0.667087 | Val. Loss: 0.549099 | Val. Kappa Score: 0.7409 | Estimated time: 398.15
Train loss on 50 batch: 0.675867
Train loss on 100 batch: 0.663424
Train loss on 150 batch: 0.582214
Train loss on 200 batch: 0.687197
Train loss on 250 batch: 0.731581
Train loss on 300 batch: 0.704843
Train loss on 350 batch: 0.662604
Train loss on 400 batch: 0.656423
Train loss on 450 batch: 0.663007
Train loss on 500 batch: 0.666239
Train loss on 550 batch: 0.634647
Train loss on 600 batch: 0.681202
Train loss on 650 batch: 0.661436
Train loss on 700 batch: 0.686338
Train loss on 750 batch: 0.680137
Train loss on 800 batch: 0.635544
Train loss on 850 batch: 0.595831
Train loss on 900 batch: 0.640918
Train loss on 950 batch: 0.653193
Train loss on 1000 batch: 0.640386
Train loss on 1050 batch: 0.663821
Train loss on 1100 batch: 0.605438
Train loss on 1150 batch: 0.605417
Train loss on 1200 batch: 0.622603
Train loss on 1250 batch: 0.600224
Train loss on 1300 batch: 0.615955
Train loss on 1350 batch: 0.601248
Train loss on 1400 batch: 0.574020
Train loss on 1450 batch: 0.734689
Train loss on 1500 batch: 0.641041
Train loss on 1550 batch: 0.620443
Train loss on 1600 batch: 0.547620
Train loss on 1650 batch: 0.708179
Train loss on 1700 batch: 0.762594
Train loss on 1750 batch: 0.589968
Train loss on 1800 batch: 0.610060
Train loss on 1850 batch: 0.583928
Train loss on 1900 batch: 0.581448
Train loss on 1950 batch: 0.667304
Train loss on 2000 batch: 0.642206
Train loss on 2050 batch: 0.648217
Train loss on 2100 batch: 0.596143
Train loss on 2150 batch: 0.631848
: Epoch: 4 | Training Loss: 0.643453 | Val. Loss: 0.639841 | Val. Kappa Score: 0.7497 | Estimated time: 394.73
Train loss on 50 batch: 0.626320
Train loss on 100 batch: 0.675047
Train loss on 150 batch: 0.649133
Train loss on 200 batch: 0.627406
Train loss on 250 batch: 0.559527
Train loss on 300 batch: 0.633309
Train loss on 350 batch: 0.667843
Train loss on 400 batch: 0.568243
Train loss on 450 batch: 0.671956
Train loss on 500 batch: 0.625972
Train loss on 550 batch: 0.608111
Train loss on 600 batch: 0.599590
Train loss on 650 batch: 0.659602
Train loss on 700 batch: 0.652826
Train loss on 750 batch: 0.533179
Train loss on 800 batch: 0.662033
Train loss on 850 batch: 0.591359
Train loss on 900 batch: 0.671583
Train loss on 950 batch: 0.505271
Train loss on 1000 batch: 0.581233
Train loss on 1050 batch: 0.569005
Train loss on 1100 batch: 0.606796
Train loss on 1150 batch: 0.594385
Train loss on 1200 batch: 0.612586
Train loss on 1250 batch: 0.718245
Train loss on 1300 batch: 0.761257
Train loss on 1350 batch: 0.664415
Train loss on 1400 batch: 0.647306
Train loss on 1450 batch: 0.576781
Train loss on 1500 batch: 0.561706
Train loss on 1550 batch: 0.602764
Train loss on 1600 batch: 0.653006
Train loss on 1650 batch: 0.745381
Train loss on 1700 batch: 0.634565
Train loss on 1750 batch: 0.624906
Train loss on 1800 batch: 0.659014
Train loss on 1850 batch: 0.623478
Train loss on 1900 batch: 0.644307
Train loss on 1950 batch: 0.609053
Train loss on 2000 batch: 0.664996
Train loss on 2050 batch: 0.661735
Train loss on 2100 batch: 0.563979
Train loss on 2150 batch: 0.591116
: Epoch: 5 | Training Loss: 0.628142 | Val. Loss: 0.588615 | Val. Kappa Score: 0.7539 | Estimated time: 397.66
Train loss on 50 batch: 0.581217
Train loss on 100 batch: 0.702885
Train loss on 150 batch: 0.634588
Train loss on 200 batch: 0.603494
Train loss on 250 batch: 0.587509
Train loss on 300 batch: 0.644977
Train loss on 350 batch: 0.552208
Train loss on 400 batch: 0.502812
Train loss on 450 batch: 0.651089
Train loss on 500 batch: 0.549811
Train loss on 550 batch: 0.621285
Train loss on 600 batch: 0.619414
Train loss on 650 batch: 0.580910
Train loss on 700 batch: 0.597604
Train loss on 750 batch: 0.714845
Train loss on 800 batch: 0.588910
Train loss on 850 batch: 0.609189
Train loss on 900 batch: 0.628746
Train loss on 950 batch: 0.610328
Train loss on 1000 batch: 0.615698
Train loss on 1050 batch: 0.586018
Train loss on 1100 batch: 0.597373
Train loss on 1150 batch: 0.591096
Train loss on 1200 batch: 0.605876
Train loss on 1250 batch: 0.623305
Train loss on 1300 batch: 0.604725
Train loss on 1350 batch: 0.497731
Train loss on 1400 batch: 0.578180
Train loss on 1450 batch: 0.552887
Train loss on 1500 batch: 0.586698
Train loss on 1550 batch: 0.600031
Train loss on 1600 batch: 0.713258
Train loss on 1650 batch: 0.642925
Train loss on 1700 batch: 0.629490
Train loss on 1750 batch: 0.655673
Train loss on 1800 batch: 0.616308
Train loss on 1850 batch: 0.618544
Train loss on 1900 batch: 0.560160
Train loss on 1950 batch: 0.592046
Train loss on 2000 batch: 0.613320
Train loss on 2050 batch: 0.559477
Train loss on 2100 batch: 0.692848
Train loss on 2150 batch: 0.717512
best-train-loss: 0.611663
best-valid-loss: 0.504925
best-kappa: 0.7644
: Epoch: 6 | Training Loss: 0.611663 | Val. Loss: 0.504925 | Val. Kappa Score: 0.7644 | Estimated time: 397.94
Train loss on 50 batch: 0.616328
Train loss on 100 batch: 0.634737
Train loss on 150 batch: 0.568843
Train loss on 200 batch: 0.531195
Train loss on 250 batch: 0.609050
Train loss on 300 batch: 0.564544
Train loss on 350 batch: 0.570598
Train loss on 400 batch: 0.585588
Train loss on 450 batch: 0.570417
Train loss on 500 batch: 0.573073
Train loss on 550 batch: 0.660256
Train loss on 600 batch: 0.612910
Train loss on 650 batch: 0.650420
Train loss on 700 batch: 0.623782
Train loss on 750 batch: 0.554295
Train loss on 800 batch: 0.662191
Train loss on 850 batch: 0.590022
Train loss on 900 batch: 0.529458
Train loss on 950 batch: 0.551371
Train loss on 1000 batch: 0.619572
Train loss on 1050 batch: 0.591555
Train loss on 1100 batch: 0.645407
Train loss on 1150 batch: 0.632996
Train loss on 1200 batch: 0.607687
Train loss on 1250 batch: 0.619073
Train loss on 1300 batch: 0.618818
Train loss on 1350 batch: 0.585567
Train loss on 1400 batch: 0.534097
Train loss on 1450 batch: 0.550649
Train loss on 1500 batch: 0.611537
Train loss on 1550 batch: 0.560190
Train loss on 1600 batch: 0.589467
Train loss on 1650 batch: 0.579034
Train loss on 1700 batch: 0.534210
Train loss on 1750 batch: 0.625486
Train loss on 1800 batch: 0.608468
Train loss on 1850 batch: 0.605510
Train loss on 1900 batch: 0.590146
Train loss on 1950 batch: 0.629028
Train loss on 2000 batch: 0.569847
Train loss on 2050 batch: 0.654365
Train loss on 2100 batch: 0.688507
Train loss on 2150 batch: 0.641860
: Epoch: 7 | Training Loss: 0.598379 | Val. Loss: 0.598786 | Val. Kappa Score: 0.7673 | Estimated time: 398.92
Train loss on 50 batch: 0.664897
Train loss on 100 batch: 0.623189
Train loss on 150 batch: 0.591381
Train loss on 200 batch: 0.634973
Train loss on 250 batch: 0.498591
Train loss on 300 batch: 0.579758
Train loss on 350 batch: 0.526792
Train loss on 400 batch: 0.548794
Train loss on 450 batch: 0.575343
Train loss on 500 batch: 0.673817
Train loss on 550 batch: 0.566722
Train loss on 600 batch: 0.617865
Train loss on 650 batch: 0.545258
Train loss on 700 batch: 0.622429
Train loss on 750 batch: 0.661136
Train loss on 800 batch: 0.615551
Train loss on 850 batch: 0.623578
Train loss on 900 batch: 0.607896
Train loss on 950 batch: 0.636211
Train loss on 1000 batch: 0.582953
Train loss on 1050 batch: 0.602861
Train loss on 1100 batch: 0.697732
Train loss on 1150 batch: 0.545415
Train loss on 1200 batch: 0.629157
Train loss on 1250 batch: 0.534682
Train loss on 1300 batch: 0.528824
Train loss on 1350 batch: 0.582126
Train loss on 1400 batch: 0.626889
Train loss on 1450 batch: 0.538893
Train loss on 1500 batch: 0.654241
Train loss on 1550 batch: 0.564482
Train loss on 1600 batch: 0.534753
Train loss on 1650 batch: 0.606530
Train loss on 1700 batch: 0.518412
Train loss on 1750 batch: 0.564003
Train loss on 1800 batch: 0.586137
Train loss on 1850 batch: 0.627173
Train loss on 1900 batch: 0.650844
Train loss on 1950 batch: 0.575984
Train loss on 2000 batch: 0.634503
Train loss on 2050 batch: 0.507285
Train loss on 2100 batch: 0.633950
Train loss on 2150 batch: 0.629996
: Epoch: 8 | Training Loss: 0.594356 | Val. Loss: 0.511660 | Val. Kappa Score: 0.7728 | Estimated time: 397.70
Train loss on 50 batch: 0.567462
Train loss on 100 batch: 0.623611
Train loss on 150 batch: 0.585282
Train loss on 200 batch: 0.612394
Train loss on 250 batch: 0.644374
Train loss on 300 batch: 0.617754
Train loss on 350 batch: 0.615958
Train loss on 400 batch: 0.612205
Train loss on 450 batch: 0.602947
Train loss on 500 batch: 0.514499
Train loss on 550 batch: 0.548482
Train loss on 600 batch: 0.547338
Train loss on 650 batch: 0.605007
Train loss on 700 batch: 0.714195
Train loss on 750 batch: 0.505023
Train loss on 800 batch: 0.556302
Train loss on 850 batch: 0.705131
Train loss on 900 batch: 0.657316
Train loss on 950 batch: 0.583688
Train loss on 1000 batch: 0.558753
Train loss on 1050 batch: 0.526134
Train loss on 1100 batch: 0.593471
Train loss on 1150 batch: 0.535190
Train loss on 1200 batch: 0.540763
Train loss on 1250 batch: 0.519577
Train loss on 1300 batch: 0.616367
Train loss on 1350 batch: 0.627463
Train loss on 1400 batch: 0.615068
Train loss on 1450 batch: 0.546021
Train loss on 1500 batch: 0.596792
Train loss on 1550 batch: 0.585919
Train loss on 1600 batch: 0.572152
Train loss on 1650 batch: 0.672494
Train loss on 1700 batch: 0.509253
Train loss on 1750 batch: 0.625177
Train loss on 1800 batch: 0.602468
Train loss on 1850 batch: 0.701541
Train loss on 1900 batch: 0.506823
Train loss on 1950 batch: 0.640577
Train loss on 2000 batch: 0.677893
Train loss on 2050 batch: 0.524743
Train loss on 2100 batch: 0.606721
Train loss on 2150 batch: 0.549032
best-train-loss: 0.591930
best-valid-loss: 0.424680
best-kappa: 0.7793
: Epoch: 9 | Training Loss: 0.591930 | Val. Loss: 0.424680 | Val. Kappa Score: 0.7793 | Estimated time: 400.23
Train loss on 50 batch: 0.682678
Train loss on 100 batch: 0.560731
Train loss on 150 batch: 0.584906
Train loss on 200 batch: 0.595538
Train loss on 250 batch: 0.618435
Train loss on 300 batch: 0.519500
Train loss on 350 batch: 0.593956
Train loss on 400 batch: 0.615954
Train loss on 450 batch: 0.640473
Train loss on 500 batch: 0.549003
Train loss on 550 batch: 0.587507
Train loss on 600 batch: 0.557289
Train loss on 650 batch: 0.604136
Train loss on 700 batch: 0.641711
Train loss on 750 batch: 0.622315
Train loss on 800 batch: 0.657151
Train loss on 850 batch: 0.539339
Train loss on 900 batch: 0.574505
Train loss on 950 batch: 0.529432
Train loss on 1000 batch: 0.565803
Train loss on 1050 batch: 0.553892
Train loss on 1100 batch: 0.552107
Train loss on 1150 batch: 0.549846
Train loss on 1200 batch: 0.573240
Train loss on 1250 batch: 0.606585
Train loss on 1300 batch: 0.473781
Train loss on 1350 batch: 0.555338
Train loss on 1400 batch: 0.623547
Train loss on 1450 batch: 0.557937
Train loss on 1500 batch: 0.493773
Train loss on 1550 batch: 0.526934
Train loss on 1600 batch: 0.514628
Train loss on 1650 batch: 0.535521
Train loss on 1700 batch: 0.603447
Train loss on 1750 batch: 0.541327
Train loss on 1800 batch: 0.515567
Train loss on 1850 batch: 0.542123
Train loss on 1900 batch: 0.530811
Train loss on 1950 batch: 0.655086
Train loss on 2000 batch: 0.556723
Train loss on 2050 batch: 0.670123
Train loss on 2100 batch: 0.673240
Train loss on 2150 batch: 0.591996
: Epoch: 10 | Training Loss: 0.577016 | Val. Loss: 0.690358 | Val. Kappa Score: 0.7731 | Estimated time: 398.93
Train loss on 50 batch: 0.629486
Train loss on 100 batch: 0.520646
Train loss on 150 batch: 0.581074
Train loss on 200 batch: 0.556948
Train loss on 250 batch: 0.469044
Train loss on 300 batch: 0.550453
Train loss on 350 batch: 0.651516
Train loss on 400 batch: 0.574157
Train loss on 450 batch: 0.612688
Train loss on 500 batch: 0.521640
Train loss on 550 batch: 0.647524
Train loss on 600 batch: 0.517614
Train loss on 650 batch: 0.583298
Train loss on 700 batch: 0.526176
Train loss on 750 batch: 0.488439
Train loss on 800 batch: 0.569610
Train loss on 850 batch: 0.586944
Train loss on 900 batch: 0.558938
Train loss on 950 batch: 0.594117
Train loss on 1000 batch: 0.622220
Train loss on 1050 batch: 0.605308
Train loss on 1100 batch: 0.529406
Train loss on 1150 batch: 0.598379
Train loss on 1200 batch: 0.550755
Train loss on 1250 batch: 0.590694
Train loss on 1300 batch: 0.531726
Train loss on 1350 batch: 0.520973
Train loss on 1400 batch: 0.598373
Train loss on 1450 batch: 0.622220
Train loss on 1500 batch: 0.542781
Train loss on 1550 batch: 0.592157
Train loss on 1600 batch: 0.621293
Train loss on 1650 batch: 0.527424
Train loss on 1700 batch: 0.571785
Train loss on 1750 batch: 0.543357
Train loss on 1800 batch: 0.632457
Train loss on 1850 batch: 0.584815
Train loss on 1900 batch: 0.581123
Train loss on 1950 batch: 0.618907
Train loss on 2000 batch: 0.570369
Train loss on 2050 batch: 0.518148
Train loss on 2100 batch: 0.591368
Train loss on 2150 batch: 0.521250
: Epoch: 11 | Training Loss: 0.569902 | Val. Loss: 0.780542 | Val. Kappa Score: 0.7697 | Estimated time: 399.14
Train loss on 50 batch: 0.596210
Train loss on 100 batch: 0.591918
Train loss on 150 batch: 0.551348
Train loss on 200 batch: 0.600120
Train loss on 250 batch: 0.492491
Train loss on 300 batch: 0.645327
Train loss on 350 batch: 0.532257
Train loss on 400 batch: 0.553062
Train loss on 450 batch: 0.586468
Train loss on 500 batch: 0.587543
Train loss on 550 batch: 0.570514
Train loss on 600 batch: 0.589159
Train loss on 650 batch: 0.529634
Train loss on 700 batch: 0.548189
Train loss on 750 batch: 0.608834
Train loss on 800 batch: 0.542194
Train loss on 850 batch: 0.471677
Train loss on 900 batch: 0.636953
Train loss on 950 batch: 0.593971
Train loss on 1000 batch: 0.553589
Train loss on 1050 batch: 0.639109
Train loss on 1100 batch: 0.552012
Train loss on 1150 batch: 0.561098
Train loss on 1200 batch: 0.572281
Train loss on 1250 batch: 0.554568
Train loss on 1300 batch: 0.580077
Train loss on 1350 batch: 0.641729
Train loss on 1400 batch: 0.525696
Train loss on 1450 batch: 0.545831
Train loss on 1500 batch: 0.527336
Train loss on 1550 batch: 0.625442
Train loss on 1600 batch: 0.561427
Train loss on 1650 batch: 0.587790
Train loss on 1700 batch: 0.615884
Train loss on 1750 batch: 0.575989
Train loss on 1800 batch: 0.539997
Train loss on 1850 batch: 0.520400
Train loss on 1900 batch: 0.653423
Train loss on 1950 batch: 0.593770
Train loss on 2000 batch: 0.451882
Train loss on 2050 batch: 0.546746
Train loss on 2100 batch: 0.619063
Train loss on 2150 batch: 0.633375
: Epoch: 12 | Training Loss: 0.570259 | Val. Loss: 0.471387 | Val. Kappa Score: 0.7737 | Estimated time: 399.32
Train loss on 50 batch: 0.597131
Train loss on 100 batch: 0.599875
Train loss on 150 batch: 0.541679
Train loss on 200 batch: 0.513509
Train loss on 250 batch: 0.437292
Train loss on 300 batch: 0.576158
Train loss on 350 batch: 0.546839
Train loss on 400 batch: 0.609287
Train loss on 450 batch: 0.495441
Train loss on 500 batch: 0.411010
Train loss on 550 batch: 0.560659
Train loss on 600 batch: 0.477752
Train loss on 650 batch: 0.602421
Train loss on 700 batch: 0.550165
Train loss on 750 batch: 0.492558
Train loss on 800 batch: 0.543412
Train loss on 850 batch: 0.528993
Train loss on 900 batch: 0.465686
Train loss on 950 batch: 0.567552
Train loss on 1000 batch: 0.528574
Train loss on 1050 batch: 0.489998
Train loss on 1100 batch: 0.559381
Train loss on 1150 batch: 0.563466
Train loss on 1200 batch: 0.556372
Train loss on 1250 batch: 0.476700
Train loss on 1300 batch: 0.548033
Train loss on 1350 batch: 0.542745
Train loss on 1400 batch: 0.516912
Train loss on 1450 batch: 0.535192
Train loss on 1500 batch: 0.537609
Train loss on 1550 batch: 0.497013
Train loss on 1600 batch: 0.530208
Train loss on 1650 batch: 0.498083
Train loss on 1700 batch: 0.555473
Train loss on 1750 batch: 0.599675
Train loss on 1800 batch: 0.435651
Train loss on 1850 batch: 0.546138
Train loss on 1900 batch: 0.510368
Train loss on 1950 batch: 0.519659
Train loss on 2000 batch: 0.506281
Train loss on 2050 batch: 0.474554
Train loss on 2100 batch: 0.583333
Train loss on 2150 batch: 0.570310
: Epoch: 13 | Training Loss: 0.529419 | Val. Loss: 0.527942 | Val. Kappa Score: 0.7771 | Estimated time: 401.44
----------------------------------------

Experiment N: 7: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.24 11:35:33
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d091668>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.957247
Train loss on 100 batch: 1.028910
Train loss on 150 batch: 1.048629
Train loss on 200 batch: 0.881764
Train loss on 250 batch: 0.839608
Train loss on 300 batch: 0.797090
Train loss on 350 batch: 0.724853
Train loss on 400 batch: 0.838501
Train loss on 450 batch: 0.800746
Train loss on 500 batch: 0.948956
Train loss on 550 batch: 0.774738
Train loss on 600 batch: 0.726126
Train loss on 650 batch: 0.792775
Train loss on 700 batch: 0.719365
Train loss on 750 batch: 0.786348
Train loss on 800 batch: 0.648114
Train loss on 850 batch: 0.708651
Train loss on 900 batch: 0.860373
Train loss on 950 batch: 0.689005
Train loss on 1000 batch: 0.662551
Train loss on 1050 batch: 0.721036
Train loss on 1100 batch: 0.697020
Train loss on 1150 batch: 0.627562
Train loss on 1200 batch: 0.701400
Train loss on 1250 batch: 0.650103
Train loss on 1300 batch: 0.641078
Train loss on 1350 batch: 0.802054
Train loss on 1400 batch: 0.768029
Train loss on 1450 batch: 0.778918
Train loss on 1500 batch: 0.734187
Train loss on 1550 batch: 0.727582
Train loss on 1600 batch: 0.710371
Train loss on 1650 batch: 0.694148
Train loss on 1700 batch: 0.669547
Train loss on 1750 batch: 0.639188
Train loss on 1800 batch: 0.658022
Train loss on 1850 batch: 0.622138
Train loss on 1900 batch: 0.699820
Train loss on 1950 batch: 0.673769
Train loss on 2000 batch: 0.611486
Train loss on 2050 batch: 0.527973
Train loss on 2100 batch: 0.659759
Train loss on 2150 batch: 0.650972
best-train-loss: 0.740204
best-valid-loss: 0.495962
best-kappa: 0.8033
: Epoch: 1 | Training Loss: 0.740204 | Val. Loss: 0.495962 | Val. Kappa Score: 0.8033 | Estimated time: 322.90
Train loss on 50 batch: 0.669066
Train loss on 100 batch: 0.629075
Train loss on 150 batch: 0.651834
Train loss on 200 batch: 0.580748
Train loss on 250 batch: 0.698516
Train loss on 300 batch: 0.692646
Train loss on 350 batch: 0.589083
Train loss on 400 batch: 0.583181
Train loss on 450 batch: 0.669272
Train loss on 500 batch: 0.622437
Train loss on 550 batch: 0.588266
Train loss on 600 batch: 0.630741
Train loss on 650 batch: 0.630548
Train loss on 700 batch: 0.560465
Train loss on 750 batch: 0.640875
Train loss on 800 batch: 0.591070
Train loss on 850 batch: 0.519846
Train loss on 900 batch: 0.630213
Train loss on 950 batch: 0.622189
Train loss on 1000 batch: 0.600852
Train loss on 1050 batch: 0.596662
Train loss on 1100 batch: 0.604482
Train loss on 1150 batch: 0.610095
Train loss on 1200 batch: 0.549414
Train loss on 1250 batch: 0.514109
Train loss on 1300 batch: 0.644614
Train loss on 1350 batch: 0.773215
Train loss on 1400 batch: 0.691190
Train loss on 1450 batch: 0.648512
Train loss on 1500 batch: 0.659500
Train loss on 1550 batch: 0.562811
Train loss on 1600 batch: 0.617890
Train loss on 1650 batch: 0.627872
Train loss on 1700 batch: 0.605887
Train loss on 1750 batch: 0.662602
Train loss on 1800 batch: 0.529457
Train loss on 1850 batch: 0.572406
Train loss on 1900 batch: 0.615567
Train loss on 1950 batch: 0.569810
Train loss on 2000 batch: 0.593047
Train loss on 2050 batch: 0.579013
Train loss on 2100 batch: 0.575694
Train loss on 2150 batch: 0.630220
best-train-loss: 0.615196
best-valid-loss: 0.434326
best-kappa: 0.8151
: Epoch: 2 | Training Loss: 0.615196 | Val. Loss: 0.434326 | Val. Kappa Score: 0.8151 | Estimated time: 324.93
Train loss on 50 batch: 0.551355
Train loss on 100 batch: 0.609361
Train loss on 150 batch: 0.525251
Train loss on 200 batch: 0.520787
Train loss on 250 batch: 0.621029
Train loss on 300 batch: 0.564667
Train loss on 350 batch: 0.542728
Train loss on 400 batch: 0.526610
Train loss on 450 batch: 0.560410
Train loss on 500 batch: 0.637951
Train loss on 550 batch: 0.585715
Train loss on 600 batch: 0.592843
Train loss on 650 batch: 0.688112
Train loss on 700 batch: 0.538971
Train loss on 750 batch: 0.542354
Train loss on 800 batch: 0.656532
Train loss on 850 batch: 0.610531
Train loss on 900 batch: 0.550457
Train loss on 950 batch: 0.587414
Train loss on 1000 batch: 0.603571
Train loss on 1050 batch: 0.679680
Train loss on 1100 batch: 0.596724
Train loss on 1150 batch: 0.558906
Train loss on 1200 batch: 0.585097
Train loss on 1250 batch: 0.644522
Train loss on 1300 batch: 0.603127
Train loss on 1350 batch: 0.593875
Train loss on 1400 batch: 0.563745
Train loss on 1450 batch: 0.640856
Train loss on 1500 batch: 0.566763
Train loss on 1550 batch: 0.597598
Train loss on 1600 batch: 0.476850
Train loss on 1650 batch: 0.644918
Train loss on 1700 batch: 0.580302
Train loss on 1750 batch: 0.514731
Train loss on 1800 batch: 0.553541
Train loss on 1850 batch: 0.489642
Train loss on 1900 batch: 0.514868
Train loss on 1950 batch: 0.593468
Train loss on 2000 batch: 0.556583
Train loss on 2050 batch: 0.603086
Train loss on 2100 batch: 0.627285
Train loss on 2150 batch: 0.539333
: Epoch: 3 | Training Loss: 0.579968 | Val. Loss: 0.624287 | Val. Kappa Score: 0.7959 | Estimated time: 324.68
Train loss on 50 batch: 0.571249
Train loss on 100 batch: 0.624134
Train loss on 150 batch: 0.529018
Train loss on 200 batch: 0.567510
Train loss on 250 batch: 0.587718
Train loss on 300 batch: 0.539342
Train loss on 350 batch: 0.612980
Train loss on 400 batch: 0.596316
Train loss on 450 batch: 0.626307
Train loss on 500 batch: 0.570689
Train loss on 550 batch: 0.572986
Train loss on 600 batch: 0.605982
Train loss on 650 batch: 0.610952
Train loss on 700 batch: 0.605806
Train loss on 750 batch: 0.547317
Train loss on 800 batch: 0.577884
Train loss on 850 batch: 0.556231
Train loss on 900 batch: 0.534606
Train loss on 950 batch: 0.528856
Train loss on 1000 batch: 0.538073
Train loss on 1050 batch: 0.532405
Train loss on 1100 batch: 0.505032
Train loss on 1150 batch: 0.550390
Train loss on 1200 batch: 0.560437
Train loss on 1250 batch: 0.575232
Train loss on 1300 batch: 0.509188
Train loss on 1350 batch: 0.496882
Train loss on 1400 batch: 0.501741
Train loss on 1450 batch: 0.599738
Train loss on 1500 batch: 0.580942
Train loss on 1550 batch: 0.549552
Train loss on 1600 batch: 0.459421
Train loss on 1650 batch: 0.619336
Train loss on 1700 batch: 0.634038
Train loss on 1750 batch: 0.469785
Train loss on 1800 batch: 0.532960
Train loss on 1850 batch: 0.502628
Train loss on 1900 batch: 0.506299
Train loss on 1950 batch: 0.557069
Train loss on 2000 batch: 0.529806
Train loss on 2050 batch: 0.510062
Train loss on 2100 batch: 0.487840
Train loss on 2150 batch: 0.551395
: Epoch: 4 | Training Loss: 0.553356 | Val. Loss: 0.516079 | Val. Kappa Score: 0.8003 | Estimated time: 322.83
Train loss on 50 batch: 0.493801
Train loss on 100 batch: 0.597252
Train loss on 150 batch: 0.547189
Train loss on 200 batch: 0.553597
Train loss on 250 batch: 0.471161
Train loss on 300 batch: 0.553727
Train loss on 350 batch: 0.553416
Train loss on 400 batch: 0.474598
Train loss on 450 batch: 0.537608
Train loss on 500 batch: 0.507666
Train loss on 550 batch: 0.500665
Train loss on 600 batch: 0.523026
Train loss on 650 batch: 0.591454
Train loss on 700 batch: 0.542931
Train loss on 750 batch: 0.486242
Train loss on 800 batch: 0.576304
Train loss on 850 batch: 0.502098
Train loss on 900 batch: 0.602042
Train loss on 950 batch: 0.405770
Train loss on 1000 batch: 0.496768
Train loss on 1050 batch: 0.487361
Train loss on 1100 batch: 0.468334
Train loss on 1150 batch: 0.519651
Train loss on 1200 batch: 0.460666
Train loss on 1250 batch: 0.634511
Train loss on 1300 batch: 0.633667
Train loss on 1350 batch: 0.573901
Train loss on 1400 batch: 0.563288
Train loss on 1450 batch: 0.476681
Train loss on 1500 batch: 0.444696
Train loss on 1550 batch: 0.568566
Train loss on 1600 batch: 0.574227
Train loss on 1650 batch: 0.591897
Train loss on 1700 batch: 0.511840
Train loss on 1750 batch: 0.549842
Train loss on 1800 batch: 0.571707
Train loss on 1850 batch: 0.498723
Train loss on 1900 batch: 0.519769
Train loss on 1950 batch: 0.508189
Train loss on 2000 batch: 0.558716
Train loss on 2050 batch: 0.538956
Train loss on 2100 batch: 0.477151
Train loss on 2150 batch: 0.538842
: Epoch: 5 | Training Loss: 0.531184 | Val. Loss: 0.454688 | Val. Kappa Score: 0.8052 | Estimated time: 322.54
Train loss on 50 batch: 0.485008
Train loss on 100 batch: 0.582010
Train loss on 150 batch: 0.485461
Train loss on 200 batch: 0.479388
Train loss on 250 batch: 0.437562
Train loss on 300 batch: 0.556546
Train loss on 350 batch: 0.445082
Train loss on 400 batch: 0.406986
Train loss on 450 batch: 0.508863
Train loss on 500 batch: 0.473721
Train loss on 550 batch: 0.427203
Train loss on 600 batch: 0.493298
Train loss on 650 batch: 0.462599
Train loss on 700 batch: 0.494280
Train loss on 750 batch: 0.524829
Train loss on 800 batch: 0.437446
Train loss on 850 batch: 0.472012
Train loss on 900 batch: 0.456221
Train loss on 950 batch: 0.460874
Train loss on 1000 batch: 0.417863
Train loss on 1050 batch: 0.488314
Train loss on 1100 batch: 0.445588
Train loss on 1150 batch: 0.473865
Train loss on 1200 batch: 0.477719
Train loss on 1250 batch: 0.490060
Train loss on 1300 batch: 0.439987
Train loss on 1350 batch: 0.407586
Train loss on 1400 batch: 0.428037
Train loss on 1450 batch: 0.472861
Train loss on 1500 batch: 0.505323
Train loss on 1550 batch: 0.468068
Train loss on 1600 batch: 0.563455
Train loss on 1650 batch: 0.496500
Train loss on 1700 batch: 0.458726
Train loss on 1750 batch: 0.490047
Train loss on 1800 batch: 0.472685
Train loss on 1850 batch: 0.477343
Train loss on 1900 batch: 0.442610
Train loss on 1950 batch: 0.481178
Train loss on 2000 batch: 0.472604
Train loss on 2050 batch: 0.408758
Train loss on 2100 batch: 0.531030
Train loss on 2150 batch: 0.634106
: Epoch: 6 | Training Loss: 0.478807 | Val. Loss: 0.496361 | Val. Kappa Score: 0.8088 | Estimated time: 329.79
Train loss on 50 batch: 0.471499
Train loss on 100 batch: 0.468297
Train loss on 150 batch: 0.423976
Train loss on 200 batch: 0.392194
Train loss on 250 batch: 0.492374
Train loss on 300 batch: 0.411774
Train loss on 350 batch: 0.408645
Train loss on 400 batch: 0.455180
Train loss on 450 batch: 0.414894
Train loss on 500 batch: 0.458637
Train loss on 550 batch: 0.499241
Train loss on 600 batch: 0.470849
Train loss on 650 batch: 0.440610
Train loss on 700 batch: 0.491159
Train loss on 750 batch: 0.471254
Train loss on 800 batch: 0.525320
Train loss on 850 batch: 0.430980
Train loss on 900 batch: 0.396339
Train loss on 950 batch: 0.399695
Train loss on 1000 batch: 0.492729
Train loss on 1050 batch: 0.437898
Train loss on 1100 batch: 0.498427
Train loss on 1150 batch: 0.437581
Train loss on 1200 batch: 0.471450
Train loss on 1250 batch: 0.516234
Train loss on 1300 batch: 0.448112
Train loss on 1350 batch: 0.470591
Train loss on 1400 batch: 0.426269
Train loss on 1450 batch: 0.410712
Train loss on 1500 batch: 0.462599
Train loss on 1550 batch: 0.416536
Train loss on 1600 batch: 0.408680
Train loss on 1650 batch: 0.455208
Train loss on 1700 batch: 0.449311
Train loss on 1750 batch: 0.493007
Train loss on 1800 batch: 0.442618
Train loss on 1850 batch: 0.452833
Train loss on 1900 batch: 0.462140
Train loss on 1950 batch: 0.481963
Train loss on 2000 batch: 0.453992
Train loss on 2050 batch: 0.539863
Train loss on 2100 batch: 0.515982
Train loss on 2150 batch: 0.476382
: Epoch: 7 | Training Loss: 0.456883 | Val. Loss: 0.694674 | Val. Kappa Score: 0.8046 | Estimated time: 328.59
Train loss on 50 batch: 0.534077
Train loss on 100 batch: 0.507664
Train loss on 150 batch: 0.422718
Train loss on 200 batch: 0.526756
Train loss on 250 batch: 0.376994
Train loss on 300 batch: 0.432150
Train loss on 350 batch: 0.370380
Train loss on 400 batch: 0.439829
Train loss on 450 batch: 0.424887
Train loss on 500 batch: 0.471622
Train loss on 550 batch: 0.438430
Train loss on 600 batch: 0.457752
Train loss on 650 batch: 0.421097
Train loss on 700 batch: 0.461471
Train loss on 750 batch: 0.487240
Train loss on 800 batch: 0.444345
Train loss on 850 batch: 0.430318
Train loss on 900 batch: 0.470222
Train loss on 950 batch: 0.521230
Train loss on 1000 batch: 0.463237
Train loss on 1050 batch: 0.468001
Train loss on 1100 batch: 0.471642
Train loss on 1150 batch: 0.411872
Train loss on 1200 batch: 0.479475
Train loss on 1250 batch: 0.403708
Train loss on 1300 batch: 0.407847
Train loss on 1350 batch: 0.453521
Train loss on 1400 batch: 0.429399
Train loss on 1450 batch: 0.357124
Train loss on 1500 batch: 0.480545
Train loss on 1550 batch: 0.440990
Train loss on 1600 batch: 0.426215
Train loss on 1650 batch: 0.489127
Train loss on 1700 batch: 0.380217
Train loss on 1750 batch: 0.457408
Train loss on 1800 batch: 0.441324
Train loss on 1850 batch: 0.483962
Train loss on 1900 batch: 0.467299
Train loss on 1950 batch: 0.425798
Train loss on 2000 batch: 0.439802
Train loss on 2050 batch: 0.419721
Train loss on 2100 batch: 0.448904
Train loss on 2150 batch: 0.483536
best-train-loss: 0.448021
best-valid-loss: 0.434273
best-kappa: 0.8090
: Epoch: 8 | Training Loss: 0.448021 | Val. Loss: 0.434273 | Val. Kappa Score: 0.8090 | Estimated time: 322.48
Train loss on 50 batch: 0.448332
Train loss on 100 batch: 0.480357
Train loss on 150 batch: 0.439758
Train loss on 200 batch: 0.442244
Train loss on 250 batch: 0.450407
Train loss on 300 batch: 0.381383
Train loss on 350 batch: 0.447489
Train loss on 400 batch: 0.492781
Train loss on 450 batch: 0.459257
Train loss on 500 batch: 0.380611
Train loss on 550 batch: 0.410553
Train loss on 600 batch: 0.431272
Train loss on 650 batch: 0.443090
Train loss on 700 batch: 0.538814
Train loss on 750 batch: 0.413397
Train loss on 800 batch: 0.417600
Train loss on 850 batch: 0.518352
Train loss on 900 batch: 0.458193
Train loss on 950 batch: 0.433165
Train loss on 1000 batch: 0.399550
Train loss on 1050 batch: 0.408840
Train loss on 1100 batch: 0.450481
Train loss on 1150 batch: 0.402530
Train loss on 1200 batch: 0.372361
Train loss on 1250 batch: 0.404203
Train loss on 1300 batch: 0.403542
Train loss on 1350 batch: 0.453284
Train loss on 1400 batch: 0.452110
Train loss on 1450 batch: 0.368771
Train loss on 1500 batch: 0.480146
Train loss on 1550 batch: 0.394266
Train loss on 1600 batch: 0.449318
Train loss on 1650 batch: 0.449460
Train loss on 1700 batch: 0.359051
Train loss on 1750 batch: 0.451688
Train loss on 1800 batch: 0.443027
Train loss on 1850 batch: 0.527346
Train loss on 1900 batch: 0.387792
Train loss on 1950 batch: 0.425337
Train loss on 2000 batch: 0.458268
Train loss on 2050 batch: 0.428572
Train loss on 2100 batch: 0.429833
Train loss on 2150 batch: 0.425134
: Epoch: 9 | Training Loss: 0.436773 | Val. Loss: 0.788306 | Val. Kappa Score: 0.8062 | Estimated time: 323.47
Train loss on 50 batch: 0.485818
Train loss on 100 batch: 0.431939
Train loss on 150 batch: 0.457888
Train loss on 200 batch: 0.458298
Train loss on 250 batch: 0.409776
Train loss on 300 batch: 0.381744
Train loss on 350 batch: 0.460249
Train loss on 400 batch: 0.437004
Train loss on 450 batch: 0.502470
Train loss on 500 batch: 0.476773
Train loss on 550 batch: 0.435865
Train loss on 600 batch: 0.415361
Train loss on 650 batch: 0.412468
Train loss on 700 batch: 0.456983
Train loss on 750 batch: 0.449780
Train loss on 800 batch: 0.487919
Train loss on 850 batch: 0.403061
Train loss on 900 batch: 0.449606
Train loss on 950 batch: 0.418662
Train loss on 1000 batch: 0.430060
Train loss on 1050 batch: 0.391017
Train loss on 1100 batch: 0.417692
Train loss on 1150 batch: 0.359518
Train loss on 1200 batch: 0.435698
Train loss on 1250 batch: 0.427424
Train loss on 1300 batch: 0.378212
Train loss on 1350 batch: 0.425907
Train loss on 1400 batch: 0.489222
Train loss on 1450 batch: 0.422839
Train loss on 1500 batch: 0.347475
Train loss on 1550 batch: 0.442915
Train loss on 1600 batch: 0.392697
Train loss on 1650 batch: 0.412651
Train loss on 1700 batch: 0.404566
Train loss on 1750 batch: 0.369187
Train loss on 1800 batch: 0.456788
Train loss on 1850 batch: 0.437559
Train loss on 1900 batch: 0.359132
Train loss on 1950 batch: 0.509092
Train loss on 2000 batch: 0.474083
Train loss on 2050 batch: 0.462313
Train loss on 2100 batch: 0.496545
Train loss on 2150 batch: 0.441679
: Epoch: 10 | Training Loss: 0.433337 | Val. Loss: 0.584227 | Val. Kappa Score: 0.8082 | Estimated time: 328.46
Train loss on 50 batch: 0.440827
Train loss on 100 batch: 0.379914
Train loss on 150 batch: 0.439751
Train loss on 200 batch: 0.441580
----------------------------------------

Experiment N: 8: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
TRAINING STAGE: : old
date: 2019.08.24 12:30:54
data-type: old_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d208>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.041483
Train loss on 100 batch: 0.968295
Train loss on 150 batch: 0.944867
Train loss on 200 batch: 0.803359
Train loss on 250 batch: 0.773732
Train loss on 300 batch: 0.771833
Train loss on 350 batch: 0.693282
Train loss on 400 batch: 0.820893
Train loss on 450 batch: 0.727491
Train loss on 500 batch: 0.843995
Train loss on 550 batch: 0.729001
Train loss on 600 batch: 0.767312
Train loss on 650 batch: 0.748661
Train loss on 700 batch: 0.672094
Train loss on 750 batch: 0.707389
Train loss on 800 batch: 0.668775
Train loss on 850 batch: 0.692741
Train loss on 900 batch: 0.808480
Train loss on 950 batch: 0.695231
Train loss on 1000 batch: 0.692600
Train loss on 1050 batch: 0.773749
Train loss on 1100 batch: 0.727720
Train loss on 1150 batch: 0.599077
Train loss on 1200 batch: 0.685462
Train loss on 1250 batch: 0.612479
Train loss on 1300 batch: 0.597774
Train loss on 1350 batch: 0.590498
Train loss on 1400 batch: 0.646002
Train loss on 1450 batch: 0.722365
Train loss on 1500 batch: 0.704352
Train loss on 1550 batch: 0.686512
Train loss on 1600 batch: 0.676617
Train loss on 1650 batch: 0.589743
Train loss on 1700 batch: 0.666408
Train loss on 1750 batch: 0.608952
Train loss on 1800 batch: 0.607613
Train loss on 1850 batch: 0.631705
Train loss on 1900 batch: 0.675876
Train loss on 1950 batch: 0.698319
Train loss on 2000 batch: 0.680000
Train loss on 2050 batch: 0.494468
Train loss on 2100 batch: 0.614203
Train loss on 2150 batch: 0.694337
best-train-loss: 0.709223
best-valid-loss: 0.586156
best-kappa: 0.7847
: Epoch: 1 | Training Loss: 0.709223 | Val. Loss: 0.586156 | Val. Kappa Score: 0.7847 | Estimated time: 261.92
Train loss on 50 batch: 0.663852
Train loss on 100 batch: 0.623338
Train loss on 150 batch: 0.637012
Train loss on 200 batch: 0.580923
Train loss on 250 batch: 0.670414
Train loss on 300 batch: 0.664622
Train loss on 350 batch: 0.582430
Train loss on 400 batch: 0.603714
Train loss on 450 batch: 0.672932
Train loss on 500 batch: 0.666025
Train loss on 550 batch: 0.594521
Train loss on 600 batch: 0.682262
Train loss on 650 batch: 0.649289
Train loss on 700 batch: 0.586684
Train loss on 750 batch: 0.638999
Train loss on 800 batch: 0.598997
Train loss on 850 batch: 0.585554
Train loss on 900 batch: 0.642813
Train loss on 950 batch: 0.628939
Train loss on 1000 batch: 0.604083
Train loss on 1050 batch: 0.610108
Train loss on 1100 batch: 0.572256
Train loss on 1150 batch: 0.590173
Train loss on 1200 batch: 0.550410
Train loss on 1250 batch: 0.518801
Train loss on 1300 batch: 0.692779
Train loss on 1350 batch: 0.757079
Train loss on 1400 batch: 0.626524
Train loss on 1450 batch: 0.630662
Train loss on 1500 batch: 0.683825
Train loss on 1550 batch: 0.561517
Train loss on 1600 batch: 0.623930
Train loss on 1650 batch: 0.591294
Train loss on 1700 batch: 0.609827
Train loss on 1750 batch: 0.689164
Train loss on 1800 batch: 0.529863
Train loss on 1850 batch: 0.542996
Train loss on 1900 batch: 0.578249
Train loss on 1950 batch: 0.581028
Train loss on 2000 batch: 0.560697
Train loss on 2050 batch: 0.586273
Train loss on 2100 batch: 0.570857
Train loss on 2150 batch: 0.680148
best-train-loss: 0.616903
best-valid-loss: 0.483860
best-kappa: 0.7963
: Epoch: 2 | Training Loss: 0.616903 | Val. Loss: 0.483860 | Val. Kappa Score: 0.7963 | Estimated time: 261.61
Train loss on 50 batch: 0.549170
Train loss on 100 batch: 0.616954
Train loss on 150 batch: 0.568130
Train loss on 200 batch: 0.515153
Train loss on 250 batch: 0.596429
Train loss on 300 batch: 0.618992
Train loss on 350 batch: 0.575693
Train loss on 400 batch: 0.511413
Train loss on 450 batch: 0.550392
Train loss on 500 batch: 0.624251
Train loss on 550 batch: 0.631237
Train loss on 600 batch: 0.576884
Train loss on 650 batch: 0.656899
Train loss on 700 batch: 0.569431
Train loss on 750 batch: 0.540818
Train loss on 800 batch: 0.624135
Train loss on 850 batch: 0.596269
Train loss on 900 batch: 0.595402
Train loss on 950 batch: 0.590472
Train loss on 1000 batch: 0.596285
Train loss on 1050 batch: 0.711186
Train loss on 1100 batch: 0.562422
Train loss on 1150 batch: 0.581081
Train loss on 1200 batch: 0.596533
Train loss on 1250 batch: 0.672254
Train loss on 1300 batch: 0.641823
Train loss on 1350 batch: 0.635828
Train loss on 1400 batch: 0.577633
Train loss on 1450 batch: 0.654485
Train loss on 1500 batch: 0.590407
Train loss on 1550 batch: 0.612950
Train loss on 1600 batch: 0.534248
Train loss on 1650 batch: 0.682153
Train loss on 1700 batch: 0.616159
Train loss on 1750 batch: 0.532854
Train loss on 1800 batch: 0.554840
Train loss on 1850 batch: 0.532378
Train loss on 1900 batch: 0.548867
Train loss on 1950 batch: 0.595363
Train loss on 2000 batch: 0.557135
Train loss on 2050 batch: 0.589466
Train loss on 2100 batch: 0.583501
Train loss on 2150 batch: 0.539184
: Epoch: 3 | Training Loss: 0.590298 | Val. Loss: 0.544360 | Val. Kappa Score: 0.7903 | Estimated time: 263.91
Train loss on 50 batch: 0.624484
Train loss on 100 batch: 0.637211
Train loss on 150 batch: 0.526618
Train loss on 200 batch: 0.525998
Train loss on 250 batch: 0.620326
Train loss on 300 batch: 0.541610
Train loss on 350 batch: 0.636166
Train loss on 400 batch: 0.609480
Train loss on 450 batch: 0.648772
Train loss on 500 batch: 0.601123
Train loss on 550 batch: 0.556214
Train loss on 600 batch: 0.587900
Train loss on 650 batch: 0.637384
Train loss on 700 batch: 0.581666
Train loss on 750 batch: 0.576437
Train loss on 800 batch: 0.525280
Train loss on 850 batch: 0.518945
Train loss on 900 batch: 0.480157
Train loss on 950 batch: 0.547772
Train loss on 1000 batch: 0.553994
Train loss on 1050 batch: 0.535971
Train loss on 1100 batch: 0.482536
Train loss on 1150 batch: 0.526015
Train loss on 1200 batch: 0.575368
Train loss on 1250 batch: 0.555760
Train loss on 1300 batch: 0.532013
Train loss on 1350 batch: 0.511282
Train loss on 1400 batch: 0.543725
Train loss on 1450 batch: 0.583160
Train loss on 1500 batch: 0.605105
Train loss on 1550 batch: 0.553069
Train loss on 1600 batch: 0.514854
Train loss on 1650 batch: 0.662608
Train loss on 1700 batch: 0.725455
Train loss on 1750 batch: 0.510902
Train loss on 1800 batch: 0.528421
Train loss on 1850 batch: 0.520998
Train loss on 1900 batch: 0.559622
Train loss on 1950 batch: 0.599635
Train loss on 2000 batch: 0.569402
Train loss on 2050 batch: 0.529548
Train loss on 2100 batch: 0.508823
Train loss on 2150 batch: 0.543509
: Epoch: 4 | Training Loss: 0.564335 | Val. Loss: 0.550083 | Val. Kappa Score: 0.7966 | Estimated time: 261.85
Train loss on 50 batch: 0.494271
Train loss on 100 batch: 0.596839
Train loss on 150 batch: 0.534396
Train loss on 200 batch: 0.588729
Train loss on 250 batch: 0.499388
Train loss on 300 batch: 0.549089
Train loss on 350 batch: 0.619457
Train loss on 400 batch: 0.510280
Train loss on 450 batch: 0.524060
Train loss on 500 batch: 0.505139
Train loss on 550 batch: 0.542778
Train loss on 600 batch: 0.508332
Train loss on 650 batch: 0.595898
Train loss on 700 batch: 0.578228
Train loss on 750 batch: 0.517385
Train loss on 800 batch: 0.629174
Train loss on 850 batch: 0.541611
Train loss on 900 batch: 0.658010
Train loss on 950 batch: 0.424158
Train loss on 1000 batch: 0.492699
Train loss on 1050 batch: 0.493855
Train loss on 1100 batch: 0.488767
Train loss on 1150 batch: 0.538560
Train loss on 1200 batch: 0.536986
Train loss on 1250 batch: 0.649083
Train loss on 1300 batch: 0.678796
Train loss on 1350 batch: 0.576756
Train loss on 1400 batch: 0.598809
Train loss on 1450 batch: 0.542526
Train loss on 1500 batch: 0.488289
Train loss on 1550 batch: 0.594066
Train loss on 1600 batch: 0.595519
Train loss on 1650 batch: 0.596975
Train loss on 1700 batch: 0.558666
Train loss on 1750 batch: 0.578686
Train loss on 1800 batch: 0.589887
Train loss on 1850 batch: 0.529540
Train loss on 1900 batch: 0.517472
Train loss on 1950 batch: 0.598257
Train loss on 2000 batch: 0.563353
Train loss on 2050 batch: 0.585847
Train loss on 2100 batch: 0.506152
Train loss on 2150 batch: 0.515133
best-train-loss: 0.555612
best-valid-loss: 0.459418
best-kappa: 0.8026
: Epoch: 5 | Training Loss: 0.555612 | Val. Loss: 0.459418 | Val. Kappa Score: 0.8026 | Estimated time: 264.04
Train loss on 50 batch: 0.499252
Train loss on 100 batch: 0.639850
Train loss on 150 batch: 0.495013
Train loss on 200 batch: 0.560639
Train loss on 250 batch: 0.506529
Train loss on 300 batch: 0.594769
Train loss on 350 batch: 0.493294
Train loss on 400 batch: 0.453465
Train loss on 450 batch: 0.552180
Train loss on 500 batch: 0.537542
Train loss on 550 batch: 0.519897
Train loss on 600 batch: 0.532521
Train loss on 650 batch: 0.531217
Train loss on 700 batch: 0.558401
Train loss on 750 batch: 0.619535
Train loss on 800 batch: 0.520779
Train loss on 850 batch: 0.558155
Train loss on 900 batch: 0.516808
Train loss on 950 batch: 0.542577
Train loss on 1000 batch: 0.476756
Train loss on 1050 batch: 0.467136
Train loss on 1100 batch: 0.508471
Train loss on 1150 batch: 0.536517
Train loss on 1200 batch: 0.507824
Train loss on 1250 batch: 0.556519
Train loss on 1300 batch: 0.505905
Train loss on 1350 batch: 0.469265
Train loss on 1400 batch: 0.541342
Train loss on 1450 batch: 0.524683
Train loss on 1500 batch: 0.531663
Train loss on 1550 batch: 0.586313
Train loss on 1600 batch: 0.667784
Train loss on 1650 batch: 0.591852
Train loss on 1700 batch: 0.532917
Train loss on 1750 batch: 0.574231
Train loss on 1800 batch: 0.546368
Train loss on 1850 batch: 0.530900
Train loss on 1900 batch: 0.501702
Train loss on 1950 batch: 0.529433
Train loss on 2000 batch: 0.532415
Train loss on 2050 batch: 0.526759
Train loss on 2100 batch: 0.581131
Train loss on 2150 batch: 0.681045
: Epoch: 6 | Training Loss: 0.542012 | Val. Loss: 0.529734 | Val. Kappa Score: 0.8060 | Estimated time: 261.11
Train loss on 50 batch: 0.521611
Train loss on 100 batch: 0.538158
Train loss on 150 batch: 0.478175
Train loss on 200 batch: 0.437180
Train loss on 250 batch: 0.565272
Train loss on 300 batch: 0.488629
Train loss on 350 batch: 0.502259
Train loss on 400 batch: 0.534520
Train loss on 450 batch: 0.485840
Train loss on 500 batch: 0.509339
Train loss on 550 batch: 0.563445
Train loss on 600 batch: 0.535262
Train loss on 650 batch: 0.521849
Train loss on 700 batch: 0.600657
Train loss on 750 batch: 0.512425
Train loss on 800 batch: 0.583952
Train loss on 850 batch: 0.485362
Train loss on 900 batch: 0.492284
Train loss on 950 batch: 0.444149
Train loss on 1000 batch: 0.531820
Train loss on 1050 batch: 0.496987
Train loss on 1100 batch: 0.566217
Train loss on 1150 batch: 0.543980
Train loss on 1200 batch: 0.543588
Train loss on 1250 batch: 0.564343
Train loss on 1300 batch: 0.484137
Train loss on 1350 batch: 0.543748
Train loss on 1400 batch: 0.496660
Train loss on 1450 batch: 0.493330
Train loss on 1500 batch: 0.508830
Train loss on 1550 batch: 0.504872
Train loss on 1600 batch: 0.454959
Train loss on 1650 batch: 0.508484
Train loss on 1700 batch: 0.517458
Train loss on 1750 batch: 0.517460
Train loss on 1800 batch: 0.519443
Train loss on 1850 batch: 0.542456
Train loss on 1900 batch: 0.541182
Train loss on 1950 batch: 0.535706
Train loss on 2000 batch: 0.506712
Train loss on 2050 batch: 0.583250
Train loss on 2100 batch: 0.570594
Train loss on 2150 batch: 0.609742
: Epoch: 7 | Training Loss: 0.521886 | Val. Loss: 0.538689 | Val. Kappa Score: 0.8071 | Estimated time: 260.89
Train loss on 50 batch: 0.626304
Train loss on 100 batch: 0.552133
Train loss on 150 batch: 0.502810
Train loss on 200 batch: 0.562728
Train loss on 250 batch: 0.445241
Train loss on 300 batch: 0.527270
Train loss on 350 batch: 0.448752
Train loss on 400 batch: 0.470406
Train loss on 450 batch: 0.519245
Train loss on 500 batch: 0.555239
Train loss on 550 batch: 0.547384
Train loss on 600 batch: 0.558540
Train loss on 650 batch: 0.462087
Train loss on 700 batch: 0.468846
Train loss on 750 batch: 0.564191
Train loss on 800 batch: 0.546160
Train loss on 850 batch: 0.542193
Train loss on 900 batch: 0.500222
Train loss on 950 batch: 0.558223
Train loss on 1000 batch: 0.503505
Train loss on 1050 batch: 0.548334
Train loss on 1100 batch: 0.536374
Train loss on 1150 batch: 0.460561
Train loss on 1200 batch: 0.520769
Train loss on 1250 batch: 0.527795
Train loss on 1300 batch: 0.501423
Train loss on 1350 batch: 0.502074
Train loss on 1400 batch: 0.474968
Train loss on 1450 batch: 0.409167
Train loss on 1500 batch: 0.526231
Train loss on 1550 batch: 0.537486
Train loss on 1600 batch: 0.509957
Train loss on 1650 batch: 0.525277
Train loss on 1700 batch: 0.461082
Train loss on 1750 batch: 0.489527
Train loss on 1800 batch: 0.503745
Train loss on 1850 batch: 0.511966
Train loss on 1900 batch: 0.524511
Train loss on 1950 batch: 0.458403
Train loss on 2000 batch: 0.503498
Train loss on 2050 batch: 0.448522
Train loss on 2100 batch: 0.498229
Train loss on 2150 batch: 0.532753
best-train-loss: 0.511932
best-valid-loss: 0.440161
best-kappa: 0.8098
: Epoch: 8 | Training Loss: 0.511932 | Val. Loss: 0.440161 | Val. Kappa Score: 0.8098 | Estimated time: 260.61
Train loss on 50 batch: 0.493011
Train loss on 100 batch: 0.536199
Train loss on 150 batch: 0.467916
Train loss on 200 batch: 0.529164
Train loss on 250 batch: 0.529206
Train loss on 300 batch: 0.461901
Train loss on 350 batch: 0.504379
Train loss on 400 batch: 0.560379
Train loss on 450 batch: 0.560505
Train loss on 500 batch: 0.431668
Train loss on 550 batch: 0.497881
Train loss on 600 batch: 0.507800
Train loss on 650 batch: 0.506507
Train loss on 700 batch: 0.588279
Train loss on 750 batch: 0.464966
Train loss on 800 batch: 0.461650
Train loss on 850 batch: 0.623594
Train loss on 900 batch: 0.532848
Train loss on 950 batch: 0.483536
Train loss on 1000 batch: 0.468344
Train loss on 1050 batch: 0.471648
Train loss on 1100 batch: 0.521078
Train loss on 1150 batch: 0.445531
Train loss on 1200 batch: 0.420942
Train loss on 1250 batch: 0.442607
Train loss on 1300 batch: 0.487261
Train loss on 1350 batch: 0.573975
Train loss on 1400 batch: 0.558404
Train loss on 1450 batch: 0.462876
Train loss on 1500 batch: 0.497995
Train loss on 1550 batch: 0.429533
Train loss on 1600 batch: 0.497911
Train loss on 1650 batch: 0.547814
Train loss on 1700 batch: 0.427458
Train loss on 1750 batch: 0.470383
Train loss on 1800 batch: 0.513445
Train loss on 1850 batch: 0.557021
Train loss on 1900 batch: 0.480916
Train loss on 1950 batch: 0.501478
Train loss on 2000 batch: 0.546447
Train loss on 2050 batch: 0.460482
Train loss on 2100 batch: 0.503845
Train loss on 2150 batch: 0.454903
: Epoch: 9 | Training Loss: 0.500752 | Val. Loss: 0.656822 | Val. Kappa Score: 0.8026 | Estimated time: 263.61
Train loss on 50 batch: 0.540502
Train loss on 100 batch: 0.453355
Train loss on 150 batch: 0.513365
Train loss on 200 batch: 0.534023
Train loss on 250 batch: 0.508337
Train loss on 300 batch: 0.437234
Train loss on 350 batch: 0.505173
Train loss on 400 batch: 0.552121
Train loss on 450 batch: 0.533196
Train loss on 500 batch: 0.549351
Train loss on 550 batch: 0.528764
Train loss on 600 batch: 0.506480
Train loss on 650 batch: 0.471616
Train loss on 700 batch: 0.510777
Train loss on 750 batch: 0.558278
Train loss on 800 batch: 0.559986
Train loss on 850 batch: 0.444791
Train loss on 900 batch: 0.503410
Train loss on 950 batch: 0.448163
Train loss on 1000 batch: 0.471919
Train loss on 1050 batch: 0.445626
Train loss on 1100 batch: 0.444604
Train loss on 1150 batch: 0.416365
Train loss on 1200 batch: 0.506171
Train loss on 1250 batch: 0.558305
Train loss on 1300 batch: 0.438367
Train loss on 1350 batch: 0.497501
Train loss on 1400 batch: 0.532169
Train loss on 1450 batch: 0.489333
Train loss on 1500 batch: 0.428838
Train loss on 1550 batch: 0.488274
Train loss on 1600 batch: 0.452528
Train loss on 1650 batch: 0.467143
Train loss on 1700 batch: 0.494808
Train loss on 1750 batch: 0.471967
Train loss on 1800 batch: 0.503398
Train loss on 1850 batch: 0.523770
Train loss on 1900 batch: 0.395301
Train loss on 1950 batch: 0.574375
Train loss on 2000 batch: 0.501942
Train loss on 2050 batch: 0.541422
Train loss on 2100 batch: 0.606125
Train loss on 2150 batch: 0.549074
: Epoch: 10 | Training Loss: 0.499556 | Val. Loss: 0.589157 | Val. Kappa Score: 0.8031 | Estimated time: 256.29
Train loss on 50 batch: 0.519488
Train loss on 100 batch: 0.456000
Train loss on 150 batch: 0.506403
Train loss on 200 batch: 0.468015
Train loss on 250 batch: 0.445523
Train loss on 300 batch: 0.517016
Train loss on 350 batch: 0.573766
Train loss on 400 batch: 0.478130
Train loss on 450 batch: 0.442897
Train loss on 500 batch: 0.459517
Train loss on 550 batch: 0.547584
Train loss on 600 batch: 0.431423
Train loss on 650 batch: 0.508666
Train loss on 700 batch: 0.498322
Train loss on 750 batch: 0.411852
Train loss on 800 batch: 0.463481
Train loss on 850 batch: 0.573733
Train loss on 900 batch: 0.498975
Train loss on 950 batch: 0.511237
Train loss on 1000 batch: 0.495429
Train loss on 1050 batch: 0.506882
Train loss on 1100 batch: 0.457034
Train loss on 1150 batch: 0.525804
Train loss on 1200 batch: 0.452740
Train loss on 1250 batch: 0.476436
Train loss on 1300 batch: 0.471768
Train loss on 1350 batch: 0.435009
Train loss on 1400 batch: 0.526916
Train loss on 1450 batch: 0.518535
Train loss on 1500 batch: 0.437890
Train loss on 1550 batch: 0.524635
Train loss on 1600 batch: 0.575078
Train loss on 1650 batch: 0.464118
Train loss on 1700 batch: 0.501605
Train loss on 1750 batch: 0.437798
Train loss on 1800 batch: 0.538983
Train loss on 1850 batch: 0.504826
Train loss on 1900 batch: 0.513316
Train loss on 1950 batch: 0.582198
Train loss on 2000 batch: 0.454011
Train loss on 2050 batch: 0.449131
Train loss on 2100 batch: 0.485200
Train loss on 2150 batch: 0.510895
: Epoch: 11 | Training Loss: 0.491291 | Val. Loss: 0.603007 | Val. Kappa Score: 0.8040 | Estimated time: 259.85
Train loss on 50 batch: 0.468342
Train loss on 100 batch: 0.458397
Train loss on 150 batch: 0.498506
Train loss on 200 batch: 0.477650
Train loss on 250 batch: 0.409507
Train loss on 300 batch: 0.524552
Train loss on 350 batch: 0.417180
Train loss on 400 batch: 0.440377
Train loss on 450 batch: 0.457824
Train loss on 500 batch: 0.492511
Train loss on 550 batch: 0.497504
Train loss on 600 batch: 0.477360
Train loss on 650 batch: 0.446941
Train loss on 700 batch: 0.403457
Train loss on 750 batch: 0.490479
Train loss on 800 batch: 0.429862
Train loss on 850 batch: 0.378123
Train loss on 900 batch: 0.487135
Train loss on 950 batch: 0.433116
Train loss on 1000 batch: 0.409265
Train loss on 1050 batch: 0.456921
Train loss on 1100 batch: 0.375954
Train loss on 1150 batch: 0.465053
Train loss on 1200 batch: 0.431590
Train loss on 1250 batch: 0.466359
Train loss on 1300 batch: 0.464833
Train loss on 1350 batch: 0.460819
Train loss on 1400 batch: 0.449150
Train loss on 1450 batch: 0.407118
Train loss on 1500 batch: 0.397180
Train loss on 1550 batch: 0.450997
Train loss on 1600 batch: 0.460177
Train loss on 1650 batch: 0.472015
Train loss on 1700 batch: 0.459877
Train loss on 1750 batch: 0.455970
Train loss on 1800 batch: 0.380953
Train loss on 1850 batch: 0.419676
Train loss on 1900 batch: 0.472182
Train loss on 1950 batch: 0.438837
Train loss on 2000 batch: 0.378800
Train loss on 2050 batch: 0.413419
Train loss on 2100 batch: 0.473132
Train loss on 2150 batch: 0.467064
: Epoch: 12 | Training Loss: 0.445276 | Val. Loss: 0.641703 | Val. Kappa Score: 0.8036 | Estimated time: 262.49
Train loss on 50 batch: 0.449632
Train loss on 100 batch: 0.449928
Train loss on 150 batch: 0.407754
Train loss on 200 batch: 0.395354
Train loss on 250 batch: 0.410837
Train loss on 300 batch: 0.480251
Train loss on 350 batch: 0.450018
Train loss on 400 batch: 0.508733
Train loss on 450 batch: 0.412969
Train loss on 500 batch: 0.352067
Train loss on 550 batch: 0.417220
Train loss on 600 batch: 0.394834
Train loss on 650 batch: 0.473937
Train loss on 700 batch: 0.452043
Train loss on 750 batch: 0.442841
Train loss on 800 batch: 0.454816
Train loss on 850 batch: 0.444965
Train loss on 900 batch: 0.349951
Train loss on 950 batch: 0.470186
Train loss on 1000 batch: 0.471009
Train loss on 1050 batch: 0.434577
Train loss on 1100 batch: 0.465650
Train loss on 1150 batch: 0.441273
Train loss on 1200 batch: 0.463255
Train loss on 1250 batch: 0.409428
Train loss on 1300 batch: 0.448727
Train loss on 1350 batch: 0.406641
Train loss on 1400 batch: 0.413126
Train loss on 1450 batch: 0.428701
Train loss on 1500 batch: 0.419042
Train loss on 1550 batch: 0.393062
Train loss on 1600 batch: 0.493478
Train loss on 1650 batch: 0.414660
Train loss on 1700 batch: 0.428297
Train loss on 1750 batch: 0.532823
Train loss on 1800 batch: 0.357022
Train loss on 1850 batch: 0.410869
Train loss on 1900 batch: 0.440828
Train loss on 1950 batch: 0.433879
Train loss on 2000 batch: 0.406763
Train loss on 2050 batch: 0.422121
Train loss on 2100 batch: 0.470254
Train loss on 2150 batch: 0.480208
: Epoch: 13 | Training Loss: 0.433471 | Val. Loss: 0.829971 | Val. Kappa Score: 0.8020 | Estimated time: 261.15
Train loss on 50 batch: 0.439604
Train loss on 100 batch: 0.492790
Train loss on 150 batch: 0.447658
Train loss on 200 batch: 0.467979
Train loss on 250 batch: 0.385710
Train loss on 300 batch: 0.463477
Train loss on 350 batch: 0.414107
Train loss on 400 batch: 0.466627
Train loss on 450 batch: 0.495702
Train loss on 500 batch: 0.392286
Train loss on 550 batch: 0.518436
Train loss on 600 batch: 0.386484
Train loss on 650 batch: 0.426670
Train loss on 700 batch: 0.367028
Train loss on 750 batch: 0.448744
Train loss on 800 batch: 0.415373
Train loss on 850 batch: 0.341914
Train loss on 900 batch: 0.374799
Train loss on 950 batch: 0.415140
Train loss on 1000 batch: 0.503433
Train loss on 1050 batch: 0.460417
Train loss on 1100 batch: 0.481576
Train loss on 1150 batch: 0.499883
Train loss on 1200 batch: 0.380447
Train loss on 1250 batch: 0.392951
Train loss on 1300 batch: 0.436874
Train loss on 1350 batch: 0.370047
Train loss on 1400 batch: 0.431937
Train loss on 1450 batch: 0.380006
Train loss on 1500 batch: 0.423207
Train loss on 1550 batch: 0.491903
Train loss on 1600 batch: 0.446936
Train loss on 1650 batch: 0.368895
Train loss on 1700 batch: 0.456874
Train loss on 1750 batch: 0.443597
Train loss on 1800 batch: 0.465969
Train loss on 1850 batch: 0.416243
Train loss on 1900 batch: 0.442387
Train loss on 1950 batch: 0.447330
Train loss on 2000 batch: 0.385638
Train loss on 2050 batch: 0.417456
Train loss on 2100 batch: 0.374564
Train loss on 2150 batch: 0.404244
: Epoch: 14 | Training Loss: 0.430262 | Val. Loss: 1.186700 | Val. Kappa Score: 0.7969 | Estimated time: 260.55
Train loss on 50 batch: 0.344287
Train loss on 100 batch: 0.349788
Train loss on 150 batch: 0.477119
Train loss on 200 batch: 0.381113
Train loss on 250 batch: 0.444872
Train loss on 300 batch: 0.310691
Train loss on 350 batch: 0.409531
Train loss on 400 batch: 0.392874
Train loss on 450 batch: 0.386119
Train loss on 500 batch: 0.360608
Train loss on 550 batch: 0.338380
Train loss on 600 batch: 0.406413
Train loss on 650 batch: 0.378333
Train loss on 700 batch: 0.427072
Train loss on 750 batch: 0.449723
Train loss on 800 batch: 0.419376
Train loss on 850 batch: 0.429248
Train loss on 900 batch: 0.374471
Train loss on 950 batch: 0.348341
Train loss on 1000 batch: 0.421300
Train loss on 1050 batch: 0.419315
Train loss on 1100 batch: 0.419663
Train loss on 1150 batch: 0.478471
Train loss on 1200 batch: 0.381897
Train loss on 1250 batch: 0.411637
Train loss on 1300 batch: 0.416096
Train loss on 1350 batch: 0.401547
Train loss on 1400 batch: 0.408008
Train loss on 1450 batch: 0.520331
Train loss on 1500 batch: 0.386967
Train loss on 1550 batch: 0.376301
Train loss on 1600 batch: 0.356127
Train loss on 1650 batch: 0.382312
Train loss on 1700 batch: 0.357577
Train loss on 1750 batch: 0.472035
Train loss on 1800 batch: 0.434568
Train loss on 1850 batch: 0.375338
Train loss on 1900 batch: 0.408716
Train loss on 1950 batch: 0.444470
Train loss on 2000 batch: 0.469081
Train loss on 2050 batch: 0.479887
Train loss on 2100 batch: 0.439698
Train loss on 2150 batch: 0.377972
: Epoch: 15 | Training Loss: 0.407525 | Val. Loss: 0.773146 | Val. Kappa Score: 0.7957 | Estimated time: 260.20
Train loss on 50 batch: 0.399560
Train loss on 100 batch: 0.426974
Train loss on 150 batch: 0.514844
Train loss on 200 batch: 0.447399
Train loss on 250 batch: 0.377890
Train loss on 300 batch: 0.349863
Train loss on 350 batch: 0.424392
Train loss on 400 batch: 0.381926
Train loss on 450 batch: 0.431401
Train loss on 500 batch: 0.455874
Train loss on 550 batch: 0.408692
Train loss on 600 batch: 0.348043
Train loss on 650 batch: 0.464736
Train loss on 700 batch: 0.351859
Train loss on 750 batch: 0.370170
Train loss on 800 batch: 0.394313
Train loss on 850 batch: 0.409948
Train loss on 900 batch: 0.383935
Train loss on 950 batch: 0.405465
Train loss on 1000 batch: 0.455985
Train loss on 1050 batch: 0.447652
Train loss on 1100 batch: 0.364551
Train loss on 1150 batch: 0.403088
Train loss on 1200 batch: 0.416936
Train loss on 1250 batch: 0.374318
Train loss on 1300 batch: 0.382477
Train loss on 1350 batch: 0.382809
Train loss on 1400 batch: 0.428164
Train loss on 1450 batch: 0.388522
Train loss on 1500 batch: 0.362854
Train loss on 1550 batch: 0.455986
Train loss on 1600 batch: 0.421451
Train loss on 1650 batch: 0.401646
Train loss on 1700 batch: 0.378710
Train loss on 1750 batch: 0.304027
Train loss on 1800 batch: 0.358329
Train loss on 1850 batch: 0.423661
Train loss on 1900 batch: 0.421063
Train loss on 1950 batch: 0.339248
Train loss on 2000 batch: 0.354777
Train loss on 2050 batch: 0.403474
Train loss on 2100 batch: 0.377990
Train loss on 2150 batch: 0.414940
: Epoch: 16 | Training Loss: 0.400197 | Val. Loss: 0.751967 | Val. Kappa Score: 0.7955 | Estimated time: 263.01
Train loss on 50 batch: 0.369436
Train loss on 100 batch: 0.384242
Train loss on 150 batch: 0.379314
Train loss on 200 batch: 0.411072
Train loss on 250 batch: 0.431711
Train loss on 300 batch: 0.428205
Train loss on 350 batch: 0.445865
Train loss on 400 batch: 0.316938
Train loss on 450 batch: 0.435979
Train loss on 500 batch: 0.403392
Train loss on 550 batch: 0.346611
Train loss on 600 batch: 0.401677
Train loss on 650 batch: 0.404484
Train loss on 700 batch: 0.406236
Train loss on 750 batch: 0.376164
Train loss on 800 batch: 0.413392
Train loss on 850 batch: 0.368336
Train loss on 900 batch: 0.382642
Train loss on 950 batch: 0.450282
Train loss on 1000 batch: 0.423498
Train loss on 1050 batch: 0.378374
Train loss on 1100 batch: 0.353916
Train loss on 1150 batch: 0.396758
Train loss on 1200 batch: 0.401121
Train loss on 1250 batch: 0.355998
Train loss on 1300 batch: 0.365909
Train loss on 1350 batch: 0.413940
Train loss on 1400 batch: 0.437591
Train loss on 1450 batch: 0.365682
Train loss on 1500 batch: 0.394502
Train loss on 1550 batch: 0.499574
Train loss on 1600 batch: 0.373347
Train loss on 1650 batch: 0.381619
Train loss on 1700 batch: 0.399618
Train loss on 1750 batch: 0.394663
Train loss on 1800 batch: 0.466130
Train loss on 1850 batch: 0.450027
Train loss on 1900 batch: 0.370901
Train loss on 1950 batch: 0.321140
Train loss on 2000 batch: 0.358979
Train loss on 2050 batch: 0.360279
Train loss on 2100 batch: 0.356389
Train loss on 2150 batch: 0.359172
: Epoch: 17 | Training Loss: 0.395068 | Val. Loss: 0.468188 | Val. Kappa Score: 0.7983 | Estimated time: 268.51
Train loss on 50 batch: 0.341866
Train loss on 100 batch: 0.393341
Train loss on 150 batch: 0.394928
Train loss on 200 batch: 0.418341
Train loss on 250 batch: 0.292396
Train loss on 300 batch: 0.386383
Train loss on 350 batch: 0.354734
Train loss on 400 batch: 0.403663
Train loss on 450 batch: 0.392067
Train loss on 500 batch: 0.337008
Train loss on 550 batch: 0.380681
Train loss on 600 batch: 0.401630
Train loss on 650 batch: 0.378642
Train loss on 700 batch: 0.336394
Train loss on 750 batch: 0.367205
Train loss on 800 batch: 0.378703
Train loss on 850 batch: 0.416316
Train loss on 900 batch: 0.356530
Train loss on 950 batch: 0.422132
Train loss on 1000 batch: 0.381696
Train loss on 1050 batch: 0.334709
Train loss on 1100 batch: 0.360282
Train loss on 1150 batch: 0.336811
Train loss on 1200 batch: 0.340007
Train loss on 1250 batch: 0.377133
Train loss on 1300 batch: 0.398867
Train loss on 1350 batch: 0.396129
Train loss on 1400 batch: 0.368272
Train loss on 1450 batch: 0.351565
Train loss on 1500 batch: 0.450899
Train loss on 1550 batch: 0.458480
Train loss on 1600 batch: 0.473114
Train loss on 1650 batch: 0.393782
Train loss on 1700 batch: 0.378911
Train loss on 1750 batch: 0.356904
Train loss on 1800 batch: 0.364039
Train loss on 1850 batch: 0.336866
Train loss on 1900 batch: 0.399834
Train loss on 1950 batch: 0.397330
Train loss on 2000 batch: 0.417955
Train loss on 2050 batch: 0.375493
Train loss on 2100 batch: 0.353434
Train loss on 2150 batch: 0.343809
: Epoch: 18 | Training Loss: 0.378852 | Val. Loss: 0.505486 | Val. Kappa Score: 0.7998 | Estimated time: 257.85
time_estimated: 4709.69
n-epochs: 18
time_estimated: 4709.69
----------------------------------------

Experiment N: 9: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.24 16:27:32
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e5c0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.028541
Train loss on 100 batch: 0.949033
Train loss on 150 batch: 0.971811
Train loss on 200 batch: 0.943388
Train loss on 250 batch: 0.795842
Train loss on 300 batch: 0.776840
Train loss on 350 batch: 0.742312
Train loss on 400 batch: 0.940863
Train loss on 450 batch: 0.770629
Train loss on 500 batch: 0.904177
Train loss on 550 batch: 0.738278
Train loss on 600 batch: 0.729706
Train loss on 650 batch: 0.810798
Train loss on 700 batch: 0.730598
Train loss on 750 batch: 0.796359
Train loss on 800 batch: 0.650066
Train loss on 850 batch: 0.689193
Train loss on 900 batch: 0.787981
Train loss on 950 batch: 0.664425
Train loss on 1000 batch: 0.664006
Train loss on 1050 batch: 0.743555
Train loss on 1100 batch: 0.694393
Train loss on 1150 batch: 0.644947
Train loss on 1200 batch: 0.730739
Train loss on 1250 batch: 0.675173
Train loss on 1300 batch: 0.620049
Train loss on 1350 batch: 0.657158
Train loss on 1400 batch: 0.659470
Train loss on 1450 batch: 0.744638
Train loss on 1500 batch: 0.783790
Train loss on 1550 batch: 0.742640
Train loss on 1600 batch: 0.687949
Train loss on 1650 batch: 0.644696
Train loss on 1700 batch: 0.659361
Train loss on 1750 batch: 0.639727
Train loss on 1800 batch: 0.613379
Train loss on 1850 batch: 0.633130
Train loss on 1900 batch: 0.679670
Train loss on 1950 batch: 0.709791
Train loss on 2000 batch: 0.684074
Train loss on 2050 batch: 0.495471
Train loss on 2100 batch: 0.640060
Train loss on 2150 batch: 0.685206
best-train-loss: 0.731604
best-valid-loss: 0.819418
best-kappa: 0.5050
: Epoch: 1 | Training Loss: 0.731604 | Val. Loss: 0.819418 | Val. Kappa Score: 0.5050 | Estimated time: 557.99
Train loss on 50 batch: 0.697110
Train loss on 100 batch: 0.647893
Train loss on 150 batch: 0.653962
Train loss on 200 batch: 0.596883
Train loss on 250 batch: 0.659736
Train loss on 300 batch: 0.686480
Train loss on 350 batch: 0.592759
Train loss on 400 batch: 0.579403
Train loss on 450 batch: 0.689514
Train loss on 500 batch: 0.674049
Train loss on 550 batch: 0.597974
Train loss on 600 batch: 0.661706
Train loss on 650 batch: 0.648710
Train loss on 700 batch: 0.556256
Train loss on 750 batch: 0.646558
Train loss on 800 batch: 0.609132
Train loss on 850 batch: 0.574816
Train loss on 900 batch: 0.657772
Train loss on 950 batch: 0.612231
Train loss on 1000 batch: 0.626807
Train loss on 1050 batch: 0.610413
Train loss on 1100 batch: 0.553007
Train loss on 1150 batch: 0.597553
Train loss on 1200 batch: 0.573690
Train loss on 1250 batch: 0.523678
Train loss on 1300 batch: 0.682947
Train loss on 1350 batch: 0.736973
Train loss on 1400 batch: 0.673162
Train loss on 1450 batch: 0.618614
Train loss on 1500 batch: 0.689827
Train loss on 1550 batch: 0.609470
Train loss on 1600 batch: 0.627113
Train loss on 1650 batch: 0.632332
Train loss on 1700 batch: 0.565269
Train loss on 1750 batch: 0.698319
Train loss on 1800 batch: 0.540861
Train loss on 1850 batch: 0.559846
Train loss on 1900 batch: 0.613698
Train loss on 1950 batch: 0.578531
Train loss on 2000 batch: 0.588398
Train loss on 2050 batch: 0.585100
Train loss on 2100 batch: 0.604427
Train loss on 2150 batch: 0.636732
best-train-loss: 0.622494
best-valid-loss: 0.619807
best-kappa: 0.5763
: Epoch: 2 | Training Loss: 0.622494 | Val. Loss: 0.619807 | Val. Kappa Score: 0.5763 | Estimated time: 556.22
Train loss on 50 batch: 0.575339
Train loss on 100 batch: 0.626812
Train loss on 150 batch: 0.531991
Train loss on 200 batch: 0.568466
Train loss on 250 batch: 0.600287
Train loss on 300 batch: 0.622379
Train loss on 350 batch: 0.585624
Train loss on 400 batch: 0.529500
Train loss on 450 batch: 0.572578
Train loss on 500 batch: 0.634653
Train loss on 550 batch: 0.619390
Train loss on 600 batch: 0.577985
Train loss on 650 batch: 0.647620
Train loss on 700 batch: 0.545808
Train loss on 750 batch: 0.493574
Train loss on 800 batch: 0.693200
Train loss on 850 batch: 0.599071
Train loss on 900 batch: 0.552370
Train loss on 950 batch: 0.584502
Train loss on 1000 batch: 0.609041
Train loss on 1050 batch: 0.701387
Train loss on 1100 batch: 0.566191
Train loss on 1150 batch: 0.570821
Train loss on 1200 batch: 0.578728
Train loss on 1250 batch: 0.619469
Train loss on 1300 batch: 0.615285
Train loss on 1350 batch: 0.609626
Train loss on 1400 batch: 0.587709
Train loss on 1450 batch: 0.650167
Train loss on 1500 batch: 0.575618
Train loss on 1550 batch: 0.583202
Train loss on 1600 batch: 0.499112
Train loss on 1650 batch: 0.629398
Train loss on 1700 batch: 0.560400
Train loss on 1750 batch: 0.515903
Train loss on 1800 batch: 0.573300
Train loss on 1850 batch: 0.506075
Train loss on 1900 batch: 0.520639
Train loss on 1950 batch: 0.591846
Train loss on 2000 batch: 0.533202
Train loss on 2050 batch: 0.596598
Train loss on 2100 batch: 0.644870
Train loss on 2150 batch: 0.515215
: Epoch: 3 | Training Loss: 0.584077 | Val. Loss: 0.766129 | Val. Kappa Score: 0.5981 | Estimated time: 556.08
Train loss on 50 batch: 0.617035
Train loss on 100 batch: 0.635103
Train loss on 150 batch: 0.481285
Train loss on 200 batch: 0.580357
Train loss on 250 batch: 0.607137
Train loss on 300 batch: 0.516468
Train loss on 350 batch: 0.620631
Train loss on 400 batch: 0.582766
Train loss on 450 batch: 0.622361
Train loss on 500 batch: 0.571228
Train loss on 550 batch: 0.553505
Train loss on 600 batch: 0.611993
Train loss on 650 batch: 0.606768
Train loss on 700 batch: 0.593918
Train loss on 750 batch: 0.564629
Train loss on 800 batch: 0.558795
Train loss on 850 batch: 0.517285
Train loss on 900 batch: 0.502962
Train loss on 950 batch: 0.561271
Train loss on 1000 batch: 0.558401
Train loss on 1050 batch: 0.553936
Train loss on 1100 batch: 0.491959
Train loss on 1150 batch: 0.544396
Train loss on 1200 batch: 0.558774
Train loss on 1250 batch: 0.541233
Train loss on 1300 batch: 0.492153
Train loss on 1350 batch: 0.528845
Train loss on 1400 batch: 0.508317
Train loss on 1450 batch: 0.614911
Train loss on 1500 batch: 0.619780
Train loss on 1550 batch: 0.536173
Train loss on 1600 batch: 0.484558
Train loss on 1650 batch: 0.605657
Train loss on 1700 batch: 0.622812
Train loss on 1750 batch: 0.532785
Train loss on 1800 batch: 0.486491
Train loss on 1850 batch: 0.509139
Train loss on 1900 batch: 0.527532
Train loss on 1950 batch: 0.562833
Train loss on 2000 batch: 0.542303
Train loss on 2050 batch: 0.509341
Train loss on 2100 batch: 0.514031
Train loss on 2150 batch: 0.575438
best-train-loss: 0.555784
best-valid-loss: 0.498665
best-kappa: 0.6539
: Epoch: 4 | Training Loss: 0.555784 | Val. Loss: 0.498665 | Val. Kappa Score: 0.6539 | Estimated time: 556.76
Train loss on 50 batch: 0.535027
Train loss on 100 batch: 0.630324
Train loss on 150 batch: 0.546279
Train loss on 200 batch: 0.549468
Train loss on 250 batch: 0.501441
Train loss on 300 batch: 0.539076
Train loss on 350 batch: 0.566234
Train loss on 400 batch: 0.505199
Train loss on 450 batch: 0.551334
Train loss on 500 batch: 0.471641
Train loss on 550 batch: 0.511174
Train loss on 600 batch: 0.547083
Train loss on 650 batch: 0.591940
Train loss on 700 batch: 0.496078
Train loss on 750 batch: 0.502219
Train loss on 800 batch: 0.606131
Train loss on 850 batch: 0.516241
Train loss on 900 batch: 0.603479
Train loss on 950 batch: 0.411505
Train loss on 1000 batch: 0.492154
Train loss on 1050 batch: 0.510337
Train loss on 1100 batch: 0.482329
Train loss on 1150 batch: 0.483423
Train loss on 1200 batch: 0.471664
Train loss on 1250 batch: 0.651627
Train loss on 1300 batch: 0.649803
Train loss on 1350 batch: 0.591454
Train loss on 1400 batch: 0.587881
Train loss on 1450 batch: 0.487044
Train loss on 1500 batch: 0.475950
Train loss on 1550 batch: 0.557879
Train loss on 1600 batch: 0.558174
Train loss on 1650 batch: 0.596829
Train loss on 1700 batch: 0.500636
Train loss on 1750 batch: 0.566048
Train loss on 1800 batch: 0.599834
Train loss on 1850 batch: 0.492456
Train loss on 1900 batch: 0.551561
Train loss on 1950 batch: 0.532702
Train loss on 2000 batch: 0.549594
Train loss on 2050 batch: 0.531849
Train loss on 2100 batch: 0.498512
Train loss on 2150 batch: 0.523606
: Epoch: 5 | Training Loss: 0.538205 | Val. Loss: 0.736381 | Val. Kappa Score: 0.6556 | Estimated time: 556.32
Train loss on 50 batch: 0.534423
Train loss on 100 batch: 0.580873
Train loss on 150 batch: 0.495176
Train loss on 200 batch: 0.541373
Train loss on 250 batch: 0.499223
Train loss on 300 batch: 0.578338
Train loss on 350 batch: 0.501798
Train loss on 400 batch: 0.408028
Train loss on 450 batch: 0.551819
Train loss on 500 batch: 0.531292
Train loss on 550 batch: 0.508330
Train loss on 600 batch: 0.506797
Train loss on 650 batch: 0.492885
Train loss on 700 batch: 0.556946
Train loss on 750 batch: 0.584599
Train loss on 800 batch: 0.477617
Train loss on 850 batch: 0.511900
Train loss on 900 batch: 0.522757
Train loss on 950 batch: 0.498775
Train loss on 1000 batch: 0.458150
Train loss on 1050 batch: 0.504580
Train loss on 1100 batch: 0.488268
Train loss on 1150 batch: 0.511555
Train loss on 1200 batch: 0.509539
Train loss on 1250 batch: 0.582330
Train loss on 1300 batch: 0.456303
Train loss on 1350 batch: 0.481506
Train loss on 1400 batch: 0.509736
Train loss on 1450 batch: 0.570782
Train loss on 1500 batch: 0.533813
Train loss on 1550 batch: 0.550775
Train loss on 1600 batch: 0.617523
Train loss on 1650 batch: 0.564964
Train loss on 1700 batch: 0.495122
Train loss on 1750 batch: 0.521484
Train loss on 1800 batch: 0.514927
Train loss on 1850 batch: 0.531461
Train loss on 1900 batch: 0.489819
Train loss on 1950 batch: 0.541590
Train loss on 2000 batch: 0.493666
Train loss on 2050 batch: 0.468245
Train loss on 2100 batch: 0.578996
Train loss on 2150 batch: 0.675554
: Epoch: 6 | Training Loss: 0.525853 | Val. Loss: 0.910239 | Val. Kappa Score: 0.6555 | Estimated time: 556.48
Train loss on 50 batch: 0.524885
Train loss on 100 batch: 0.549401
Train loss on 150 batch: 0.478159
Train loss on 200 batch: 0.429448
Train loss on 250 batch: 0.527694
Train loss on 300 batch: 0.495068
Train loss on 350 batch: 0.465692
Train loss on 400 batch: 0.491890
Train loss on 450 batch: 0.452870
Train loss on 500 batch: 0.478735
Train loss on 550 batch: 0.520866
Train loss on 600 batch: 0.522631
Train loss on 650 batch: 0.532024
Train loss on 700 batch: 0.570928
Train loss on 750 batch: 0.495037
Train loss on 800 batch: 0.596127
Train loss on 850 batch: 0.500215
Train loss on 900 batch: 0.464195
Train loss on 950 batch: 0.452841
Train loss on 1000 batch: 0.555215
Train loss on 1050 batch: 0.480359
Train loss on 1100 batch: 0.534162
Train loss on 1150 batch: 0.494550
Train loss on 1200 batch: 0.521954
Train loss on 1250 batch: 0.581173
Train loss on 1300 batch: 0.512226
Train loss on 1350 batch: 0.511895
Train loss on 1400 batch: 0.482677
Train loss on 1450 batch: 0.445474
Train loss on 1500 batch: 0.519654
Train loss on 1550 batch: 0.454430
Train loss on 1600 batch: 0.483475
Train loss on 1650 batch: 0.512705
Train loss on 1700 batch: 0.522254
Train loss on 1750 batch: 0.537074
Train loss on 1800 batch: 0.468065
Train loss on 1850 batch: 0.546004
Train loss on 1900 batch: 0.544899
Train loss on 1950 batch: 0.546497
Train loss on 2000 batch: 0.502635
Train loss on 2050 batch: 0.578933
Train loss on 2100 batch: 0.540172
Train loss on 2150 batch: 0.519897
: Epoch: 7 | Training Loss: 0.509628 | Val. Loss: 1.288094 | Val. Kappa Score: 0.6501 | Estimated time: 556.30
Train loss on 50 batch: 0.600070
Train loss on 100 batch: 0.526500
Train loss on 150 batch: 0.497138
Train loss on 200 batch: 0.528047
Train loss on 250 batch: 0.421612
Train loss on 300 batch: 0.453081
Train loss on 350 batch: 0.388034
Train loss on 400 batch: 0.446232
Train loss on 450 batch: 0.447750
Train loss on 500 batch: 0.499769
Train loss on 550 batch: 0.473942
Train loss on 600 batch: 0.489128
Train loss on 650 batch: 0.406932
Train loss on 700 batch: 0.467201
Train loss on 750 batch: 0.496062
Train loss on 800 batch: 0.448428
Train loss on 850 batch: 0.447074
Train loss on 900 batch: 0.481419
Train loss on 950 batch: 0.508459
Train loss on 1000 batch: 0.471961
Train loss on 1050 batch: 0.482004
Train loss on 1100 batch: 0.491980
Train loss on 1150 batch: 0.417303
Train loss on 1200 batch: 0.474254
Train loss on 1250 batch: 0.429512
Train loss on 1300 batch: 0.430843
Train loss on 1350 batch: 0.453230
Train loss on 1400 batch: 0.444530
Train loss on 1450 batch: 0.376307
Train loss on 1500 batch: 0.481089
Train loss on 1550 batch: 0.477709
Train loss on 1600 batch: 0.406991
Train loss on 1650 batch: 0.462028
Train loss on 1700 batch: 0.397352
Train loss on 1750 batch: 0.471229
Train loss on 1800 batch: 0.452159
Train loss on 1850 batch: 0.483569
Train loss on 1900 batch: 0.485121
Train loss on 1950 batch: 0.399375
Train loss on 2000 batch: 0.427823
Train loss on 2050 batch: 0.414904
Train loss on 2100 batch: 0.450691
Train loss on 2150 batch: 0.504273
best-train-loss: 0.460487
best-valid-loss: 0.364195
best-kappa: 0.6760
: Epoch: 8 | Training Loss: 0.460487 | Val. Loss: 0.364195 | Val. Kappa Score: 0.6760 | Estimated time: 556.33
Train loss on 50 batch: 0.430065
Train loss on 100 batch: 0.473501
Train loss on 150 batch: 0.467078
Train loss on 200 batch: 0.451714
Train loss on 250 batch: 0.498120
Train loss on 300 batch: 0.388338
Train loss on 350 batch: 0.408259
Train loss on 400 batch: 0.525070
Train loss on 450 batch: 0.477836
Train loss on 500 batch: 0.409804
Train loss on 550 batch: 0.417399
Train loss on 600 batch: 0.431607
Train loss on 650 batch: 0.443223
Train loss on 700 batch: 0.531361
Train loss on 750 batch: 0.427904
Train loss on 800 batch: 0.403075
Train loss on 850 batch: 0.557657
Train loss on 900 batch: 0.480428
Train loss on 950 batch: 0.448899
Train loss on 1000 batch: 0.410331
Train loss on 1050 batch: 0.407287
Train loss on 1100 batch: 0.463513
Train loss on 1150 batch: 0.408949
Train loss on 1200 batch: 0.404213
Train loss on 1250 batch: 0.377802
Train loss on 1300 batch: 0.413914
Train loss on 1350 batch: 0.453144
Train loss on 1400 batch: 0.455448
Train loss on 1450 batch: 0.384247
Train loss on 1500 batch: 0.442512
Train loss on 1550 batch: 0.373235
Train loss on 1600 batch: 0.442631
Train loss on 1650 batch: 0.434920
Train loss on 1700 batch: 0.354497
Train loss on 1750 batch: 0.461979
Train loss on 1800 batch: 0.443669
Train loss on 1850 batch: 0.523370
Train loss on 1900 batch: 0.397889
Train loss on 1950 batch: 0.441768
Train loss on 2000 batch: 0.455781
Train loss on 2050 batch: 0.430716
Train loss on 2100 batch: 0.426396
Train loss on 2150 batch: 0.414799
best-train-loss: 0.440264
best-valid-loss: 0.350580
best-kappa: 0.6965
: Epoch: 9 | Training Loss: 0.440264 | Val. Loss: 0.350580 | Val. Kappa Score: 0.6965 | Estimated time: 556.53
Train loss on 50 batch: 0.450931
Train loss on 100 batch: 0.414874
Train loss on 150 batch: 0.463690
Train loss on 200 batch: 0.442613
Train loss on 250 batch: 0.406718
Train loss on 300 batch: 0.370464
Train loss on 350 batch: 0.445549
Train loss on 400 batch: 0.423684
Train loss on 450 batch: 0.501859
Train loss on 500 batch: 0.488041
Train loss on 550 batch: 0.412217
Train loss on 600 batch: 0.423450
Train loss on 650 batch: 0.426828
Train loss on 700 batch: 0.460396
Train loss on 750 batch: 0.444707
Train loss on 800 batch: 0.504647
Train loss on 850 batch: 0.388689
Train loss on 900 batch: 0.456603
Train loss on 950 batch: 0.403501
Train loss on 1000 batch: 0.433030
Train loss on 1050 batch: 0.383569
Train loss on 1100 batch: 0.395576
Train loss on 1150 batch: 0.383629
Train loss on 1200 batch: 0.423488
Train loss on 1250 batch: 0.470754
Train loss on 1300 batch: 0.400067
Train loss on 1350 batch: 0.427938
Train loss on 1400 batch: 0.498290
Train loss on 1450 batch: 0.432920
Train loss on 1500 batch: 0.377669
Train loss on 1550 batch: 0.441108
Train loss on 1600 batch: 0.383953
Train loss on 1650 batch: 0.403632
Train loss on 1700 batch: 0.434698
Train loss on 1750 batch: 0.393538
Train loss on 1800 batch: 0.464382
Train loss on 1850 batch: 0.485930
Train loss on 1900 batch: 0.363665
Train loss on 1950 batch: 0.523385
Train loss on 2000 batch: 0.467476
Train loss on 2050 batch: 0.473314
Train loss on 2100 batch: 0.498559
Train loss on 2150 batch: 0.467257
: Epoch: 10 | Training Loss: 0.436533 | Val. Loss: 0.379631 | Val. Kappa Score: 0.7128 | Estimated time: 556.30
Train loss on 50 batch: 0.436111
Train loss on 100 batch: 0.376993
Train loss on 150 batch: 0.452004
Train loss on 200 batch: 0.461363
Train loss on 250 batch: 0.398060
Train loss on 300 batch: 0.464605
Train loss on 350 batch: 0.474525
Train loss on 400 batch: 0.417497
Train loss on 450 batch: 0.406964
Train loss on 500 batch: 0.406129
Train loss on 550 batch: 0.500521
Train loss on 600 batch: 0.398547
Train loss on 650 batch: 0.416841
Train loss on 700 batch: 0.452867
Train loss on 750 batch: 0.349135
Train loss on 800 batch: 0.396872
Train loss on 850 batch: 0.503498
Train loss on 900 batch: 0.454056
Train loss on 950 batch: 0.438963
Train loss on 1000 batch: 0.437424
Train loss on 1050 batch: 0.455917
Train loss on 1100 batch: 0.403955
Train loss on 1150 batch: 0.414734
Train loss on 1200 batch: 0.404600
Train loss on 1250 batch: 0.423693
Train loss on 1300 batch: 0.423805
Train loss on 1350 batch: 0.384566
Train loss on 1400 batch: 0.451964
Train loss on 1450 batch: 0.445663
Train loss on 1500 batch: 0.417326
Train loss on 1550 batch: 0.457511
Train loss on 1600 batch: 0.492205
Train loss on 1650 batch: 0.375161
Train loss on 1700 batch: 0.454519
Train loss on 1750 batch: 0.387724
Train loss on 1800 batch: 0.469155
Train loss on 1850 batch: 0.446544
Train loss on 1900 batch: 0.412292
Train loss on 1950 batch: 0.506555
Train loss on 2000 batch: 0.446815
Train loss on 2050 batch: 0.396764
Train loss on 2100 batch: 0.406875
Train loss on 2150 batch: 0.427311
: Epoch: 11 | Training Loss: 0.431149 | Val. Loss: 0.554528 | Val. Kappa Score: 0.7236 | Estimated time: 556.32
Train loss on 50 batch: 0.434054
Train loss on 100 batch: 0.422755
Train loss on 150 batch: 0.451545
Train loss on 200 batch: 0.432021
Train loss on 250 batch: 0.355117
Train loss on 300 batch: 0.515016
Train loss on 350 batch: 0.383207
Train loss on 400 batch: 0.401754
Train loss on 450 batch: 0.421003
Train loss on 500 batch: 0.434251
Train loss on 550 batch: 0.484085
Train loss on 600 batch: 0.428193
Train loss on 650 batch: 0.425790
Train loss on 700 batch: 0.410606
Train loss on 750 batch: 0.460122
Train loss on 800 batch: 0.413611
Train loss on 850 batch: 0.346801
Train loss on 900 batch: 0.434428
Train loss on 950 batch: 0.448301
Train loss on 1000 batch: 0.408469
Train loss on 1050 batch: 0.462731
Train loss on 1100 batch: 0.355853
Train loss on 1150 batch: 0.424391
Train loss on 1200 batch: 0.423927
Train loss on 1250 batch: 0.427763
Train loss on 1300 batch: 0.409246
Train loss on 1350 batch: 0.456448
Train loss on 1400 batch: 0.411148
Train loss on 1450 batch: 0.371417
Train loss on 1500 batch: 0.415832
Train loss on 1550 batch: 0.436496
Train loss on 1600 batch: 0.461679
Train loss on 1650 batch: 0.496272
Train loss on 1700 batch: 0.446552
Train loss on 1750 batch: 0.436721
Train loss on 1800 batch: 0.409994
Train loss on 1850 batch: 0.391643
Train loss on 1900 batch: 0.436769
Train loss on 1950 batch: 0.432683
Train loss on 2000 batch: 0.369676
Train loss on 2050 batch: 0.402297
Train loss on 2100 batch: 0.416552
Train loss on 2150 batch: 0.457564
: Epoch: 12 | Training Loss: 0.423447 | Val. Loss: 0.363134 | Val. Kappa Score: 0.7348 | Estimated time: 556.27
Train loss on 50 batch: 0.439552
Train loss on 100 batch: 0.453761
Train loss on 150 batch: 0.399413
Train loss on 200 batch: 0.397723
Train loss on 250 batch: 0.379678
Train loss on 300 batch: 0.428643
Train loss on 350 batch: 0.413525
Train loss on 400 batch: 0.462409
Train loss on 450 batch: 0.354824
Train loss on 500 batch: 0.321292
Train loss on 550 batch: 0.361497
Train loss on 600 batch: 0.376782
Train loss on 650 batch: 0.453376
Train loss on 700 batch: 0.430149
Train loss on 750 batch: 0.405386
Train loss on 800 batch: 0.392756
Train loss on 850 batch: 0.402744
Train loss on 900 batch: 0.341037
Train loss on 950 batch: 0.453228
Train loss on 1000 batch: 0.411576
Train loss on 1050 batch: 0.373968
Train loss on 1100 batch: 0.443253
Train loss on 1150 batch: 0.417552
Train loss on 1200 batch: 0.431773
Train loss on 1250 batch: 0.373171
Train loss on 1300 batch: 0.384914
Train loss on 1350 batch: 0.405591
Train loss on 1400 batch: 0.374424
Train loss on 1450 batch: 0.384051
Train loss on 1500 batch: 0.396829
Train loss on 1550 batch: 0.355726
Train loss on 1600 batch: 0.423356
Train loss on 1650 batch: 0.362901
Train loss on 1700 batch: 0.416818
Train loss on 1750 batch: 0.504951
Train loss on 1800 batch: 0.352520
Train loss on 1850 batch: 0.401166
Train loss on 1900 batch: 0.387057
Train loss on 1950 batch: 0.389342
Train loss on 2000 batch: 0.389635
Train loss on 2050 batch: 0.394079
Train loss on 2100 batch: 0.447733
Train loss on 2150 batch: 0.428583
: Epoch: 13 | Training Loss: 0.402287 | Val. Loss: 0.576728 | Val. Kappa Score: 0.7410 | Estimated time: 555.94
Train loss on 50 batch: 0.404591
Train loss on 100 batch: 0.448800
Train loss on 150 batch: 0.402040
Train loss on 200 batch: 0.442478
Train loss on 250 batch: 0.368482
Train loss on 300 batch: 0.458062
Train loss on 350 batch: 0.364165
Train loss on 400 batch: 0.436168
Train loss on 450 batch: 0.484910
Train loss on 500 batch: 0.398602
Train loss on 550 batch: 0.460507
Train loss on 600 batch: 0.403097
Train loss on 650 batch: 0.375539
Train loss on 700 batch: 0.329802
Train loss on 750 batch: 0.401285
Train loss on 800 batch: 0.369667
Train loss on 850 batch: 0.309139
Train loss on 900 batch: 0.328881
Train loss on 950 batch: 0.350873
Train loss on 1000 batch: 0.405805
Train loss on 1050 batch: 0.420987
Train loss on 1100 batch: 0.433506
Train loss on 1150 batch: 0.431782
Train loss on 1200 batch: 0.343176
Train loss on 1250 batch: 0.395311
Train loss on 1300 batch: 0.372290
Train loss on 1350 batch: 0.319692
Train loss on 1400 batch: 0.382207
Train loss on 1450 batch: 0.341487
Train loss on 1500 batch: 0.384444
Train loss on 1550 batch: 0.442717
Train loss on 1600 batch: 0.385036
Train loss on 1650 batch: 0.337297
Train loss on 1700 batch: 0.372127
Train loss on 1750 batch: 0.414454
Train loss on 1800 batch: 0.417836
Train loss on 1850 batch: 0.402300
Train loss on 1900 batch: 0.358068
Train loss on 1950 batch: 0.382795
Train loss on 2000 batch: 0.365271
Train loss on 2050 batch: 0.389204
Train loss on 2100 batch: 0.360010
Train loss on 2150 batch: 0.385971
: Epoch: 14 | Training Loss: 0.390267 | Val. Loss: 0.435122 | Val. Kappa Score: 0.7489 | Estimated time: 556.85
Train loss on 50 batch: 0.310921
Train loss on 100 batch: 0.323796
Train loss on 150 batch: 0.452889
Train loss on 200 batch: 0.357169
Train loss on 250 batch: 0.429359
Train loss on 300 batch: 0.299415
Train loss on 350 batch: 0.375306
Train loss on 400 batch: 0.377836
Train loss on 450 batch: 0.371009
Train loss on 500 batch: 0.361678
Train loss on 550 batch: 0.357598
Train loss on 600 batch: 0.400020
Train loss on 650 batch: 0.372241
Train loss on 700 batch: 0.400552
Train loss on 750 batch: 0.420739
Train loss on 800 batch: 0.420993
Train loss on 850 batch: 0.398529
Train loss on 900 batch: 0.350684
Train loss on 950 batch: 0.330524
Train loss on 1000 batch: 0.403383
Train loss on 1050 batch: 0.392635
Train loss on 1100 batch: 0.363575
Train loss on 1150 batch: 0.475394
Train loss on 1200 batch: 0.394726
Train loss on 1250 batch: 0.395542
Train loss on 1300 batch: 0.388062
Train loss on 1350 batch: 0.354156
Train loss on 1400 batch: 0.373134
Train loss on 1450 batch: 0.497595
Train loss on 1500 batch: 0.387417
Train loss on 1550 batch: 0.362686
Train loss on 1600 batch: 0.306443
Train loss on 1650 batch: 0.343557
Train loss on 1700 batch: 0.335221
Train loss on 1750 batch: 0.423728
Train loss on 1800 batch: 0.405565
Train loss on 1850 batch: 0.362401
Train loss on 1900 batch: 0.363899
Train loss on 1950 batch: 0.387913
Train loss on 2000 batch: 0.420979
Train loss on 2050 batch: 0.439495
Train loss on 2100 batch: 0.425382
Train loss on 2150 batch: 0.362802
: Epoch: 15 | Training Loss: 0.383152 | Val. Loss: 0.414710 | Val. Kappa Score: 0.7558 | Estimated time: 556.43
Train loss on 50 batch: 0.367941
Train loss on 100 batch: 0.420552
Train loss on 150 batch: 0.442203
Train loss on 200 batch: 0.405192
Train loss on 250 batch: 0.335580
Train loss on 300 batch: 0.339482
Train loss on 350 batch: 0.398706
Train loss on 400 batch: 0.374075
Train loss on 450 batch: 0.376166
Train loss on 500 batch: 0.442706
Train loss on 550 batch: 0.332592
Train loss on 600 batch: 0.350666
Train loss on 650 batch: 0.422848
Train loss on 700 batch: 0.362171
Train loss on 750 batch: 0.356923
Train loss on 800 batch: 0.351397
Train loss on 850 batch: 0.382522
Train loss on 900 batch: 0.378288
Train loss on 950 batch: 0.369281
Train loss on 1000 batch: 0.425998
Train loss on 1050 batch: 0.396707
Train loss on 1100 batch: 0.314658
Train loss on 1150 batch: 0.378414
Train loss on 1200 batch: 0.342819
Train loss on 1250 batch: 0.326322
Train loss on 1300 batch: 0.365922
Train loss on 1350 batch: 0.341762
Train loss on 1400 batch: 0.400290
Train loss on 1450 batch: 0.337389
Train loss on 1500 batch: 0.345720
Train loss on 1550 batch: 0.396422
Train loss on 1600 batch: 0.383046
Train loss on 1650 batch: 0.376079
Train loss on 1700 batch: 0.351458
Train loss on 1750 batch: 0.295704
Train loss on 1800 batch: 0.339986
Train loss on 1850 batch: 0.358617
Train loss on 1900 batch: 0.366788
Train loss on 1950 batch: 0.344944
Train loss on 2000 batch: 0.339041
Train loss on 2050 batch: 0.392358
Train loss on 2100 batch: 0.360945
Train loss on 2150 batch: 0.372858
: Epoch: 16 | Training Loss: 0.368885 | Val. Loss: 0.492149 | Val. Kappa Score: 0.7613 | Estimated time: 556.37
Train loss on 50 batch: 0.312954
Train loss on 100 batch: 0.349368
Train loss on 150 batch: 0.347046
Train loss on 200 batch: 0.381544
Train loss on 250 batch: 0.402844
Train loss on 300 batch: 0.387228
Train loss on 350 batch: 0.433280
Train loss on 400 batch: 0.322290
Train loss on 450 batch: 0.425194
Train loss on 500 batch: 0.386959
Train loss on 550 batch: 0.303984
Train loss on 600 batch: 0.341205
Train loss on 650 batch: 0.384666
Train loss on 700 batch: 0.363887
Train loss on 750 batch: 0.339443
Train loss on 800 batch: 0.391298
Train loss on 850 batch: 0.322650
Train loss on 900 batch: 0.348357
Train loss on 950 batch: 0.420462
Train loss on 1000 batch: 0.410212
Train loss on 1050 batch: 0.357264
Train loss on 1100 batch: 0.328647
Train loss on 1150 batch: 0.358963
Train loss on 1200 batch: 0.378689
Train loss on 1250 batch: 0.331586
Train loss on 1300 batch: 0.348957
Train loss on 1350 batch: 0.391805
Train loss on 1400 batch: 0.398286
Train loss on 1450 batch: 0.324398
Train loss on 1500 batch: 0.357162
Train loss on 1550 batch: 0.470692
Train loss on 1600 batch: 0.354649
Train loss on 1650 batch: 0.337320
Train loss on 1700 batch: 0.366692
Train loss on 1750 batch: 0.372731
Train loss on 1800 batch: 0.396506
Train loss on 1850 batch: 0.389719
Train loss on 1900 batch: 0.329031
Train loss on 1950 batch: 0.311981
Train loss on 2000 batch: 0.332482
Train loss on 2050 batch: 0.312813
Train loss on 2100 batch: 0.326090
Train loss on 2150 batch: 0.350678
: Epoch: 17 | Training Loss: 0.363989 | Val. Loss: 0.439381 | Val. Kappa Score: 0.7669 | Estimated time: 556.36
Train loss on 50 batch: 0.302245
Train loss on 100 batch: 0.338444
Train loss on 150 batch: 0.355709
Train loss on 200 batch: 0.371808
Train loss on 250 batch: 0.295079
Train loss on 300 batch: 0.344905
Train loss on 350 batch: 0.328650
Train loss on 400 batch: 0.363330
Train loss on 450 batch: 0.392974
Train loss on 500 batch: 0.327905
Train loss on 550 batch: 0.375942
Train loss on 600 batch: 0.406178
Train loss on 650 batch: 0.369128
Train loss on 700 batch: 0.323475
Train loss on 750 batch: 0.333720
Train loss on 800 batch: 0.368680
Train loss on 850 batch: 0.358154
Train loss on 900 batch: 0.364966
Train loss on 950 batch: 0.423641
Train loss on 1000 batch: 0.377117
Train loss on 1050 batch: 0.343414
Train loss on 1100 batch: 0.338453
Train loss on 1150 batch: 0.327296
Train loss on 1200 batch: 0.315148
Train loss on 1250 batch: 0.365010
Train loss on 1300 batch: 0.353504
Train loss on 1350 batch: 0.357460
Train loss on 1400 batch: 0.359897
Train loss on 1450 batch: 0.342092
Train loss on 1500 batch: 0.457350
Train loss on 1550 batch: 0.423761
Train loss on 1600 batch: 0.432736
Train loss on 1650 batch: 0.385525
Train loss on 1700 batch: 0.360162
Train loss on 1750 batch: 0.353540
Train loss on 1800 batch: 0.346312
Train loss on 1850 batch: 0.310418
Train loss on 1900 batch: 0.380905
Train loss on 1950 batch: 0.389522
Train loss on 2000 batch: 0.388971
Train loss on 2050 batch: 0.322614
Train loss on 2100 batch: 0.337237
Train loss on 2150 batch: 0.340914
: Epoch: 18 | Training Loss: 0.359055 | Val. Loss: 0.453793 | Val. Kappa Score: 0.7721 | Estimated time: 556.41
Train loss on 50 batch: 0.328063
Train loss on 100 batch: 0.273590
Train loss on 150 batch: 0.374754
Train loss on 200 batch: 0.303339
Train loss on 250 batch: 0.407558
Train loss on 300 batch: 0.354324
Train loss on 350 batch: 0.363810
Train loss on 400 batch: 0.397134
Train loss on 450 batch: 0.388874
Train loss on 500 batch: 0.383938
Train loss on 550 batch: 0.326558
Train loss on 600 batch: 0.322189
Train loss on 650 batch: 0.368506
Train loss on 700 batch: 0.344219
Train loss on 750 batch: 0.366466
Train loss on 800 batch: 0.335090
Train loss on 850 batch: 0.397728
Train loss on 900 batch: 0.330372
Train loss on 950 batch: 0.386518
Train loss on 1000 batch: 0.334724
Train loss on 1050 batch: 0.329165
Train loss on 1100 batch: 0.377945
Train loss on 1150 batch: 0.324598
Train loss on 1200 batch: 0.355716
Train loss on 1250 batch: 0.360711
Train loss on 1300 batch: 0.380423
Train loss on 1350 batch: 0.346624
Train loss on 1400 batch: 0.368494
Train loss on 1450 batch: 0.366439
Train loss on 1500 batch: 0.357666
Train loss on 1550 batch: 0.385583
Train loss on 1600 batch: 0.374277
Train loss on 1650 batch: 0.318982
Train loss on 1700 batch: 0.315131
Train loss on 1750 batch: 0.382482
Train loss on 1800 batch: 0.394731
Train loss on 1850 batch: 0.326472
Train loss on 1900 batch: 0.297549
Train loss on 1950 batch: 0.328691
Train loss on 2000 batch: 0.307986
Train loss on 2050 batch: 0.307093
Train loss on 2100 batch: 0.284244
Train loss on 2150 batch: 0.366384
: Epoch: 19 | Training Loss: 0.348094 | Val. Loss: 0.494461 | Val. Kappa Score: 0.7761 | Estimated time: 556.30
time_estimated: 10573.06
n-epochs: 19
time_estimated: 10573.07
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 01:29:15
data-type: new_old
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e6a0>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 01:29:40
data-type: new_old
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d710>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
TRAINING STAGE: : old
date: 2019.08.25 01:30:25
data-type: new_old
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a748>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
TRAINING STAGE: : old
date: 2019.08.25 01:30:57
data-type: new_old
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9600d898>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
TRAINING STAGE: : old
date: 2019.08.25 01:32:08
data-type: new_old
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d5c0>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 10: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
TRAINING STAGE: : old
date: 2019.08.25 01:33:07
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9600f860>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.060754
Train loss on 100 batch: 1.026069
Train loss on 150 batch: 0.938397
Train loss on 200 batch: 0.940800
Train loss on 250 batch: 0.893224
Train loss on 300 batch: 0.669192
Train loss on 350 batch: 0.738189
Train loss on 400 batch: 0.764980
Train loss on 450 batch: 0.742425
Train loss on 500 batch: 0.747681
Train loss on 550 batch: 0.723991
Train loss on 600 batch: 0.664910
Train loss on 650 batch: 0.755359
Train loss on 700 batch: 0.632497
Train loss on 750 batch: 0.622108
Train loss on 800 batch: 0.559664
Train loss on 850 batch: 0.649375
Train loss on 900 batch: 0.610440
Train loss on 950 batch: 0.559951
Train loss on 1000 batch: 0.770732
Train loss on 1050 batch: 0.527565
Train loss on 1100 batch: 0.557415
Train loss on 1150 batch: 0.508207
Train loss on 1200 batch: 0.758795
Train loss on 1250 batch: 0.553130
Train loss on 1300 batch: 0.562278
Train loss on 1350 batch: 0.580381
Train loss on 1400 batch: 0.622679
Train loss on 1450 batch: 0.530441
Train loss on 1500 batch: 0.485196
Train loss on 1550 batch: 0.642992
Train loss on 1600 batch: 0.540711
Train loss on 1650 batch: 0.512863
Train loss on 1700 batch: 0.509359
Train loss on 1750 batch: 0.537045
Train loss on 1800 batch: 0.460656
Train loss on 1850 batch: 0.566556
Train loss on 1900 batch: 0.517642
Train loss on 1950 batch: 0.665963
Train loss on 2000 batch: 0.609545
Train loss on 2050 batch: 0.583992
Train loss on 2100 batch: 0.597956
Train loss on 2150 batch: 0.503543
Train loss on 2200 batch: 0.528222
Train loss on 2250 batch: 0.559798
Train loss on 2300 batch: 0.543641
Train loss on 2350 batch: 0.478409
Train loss on 2400 batch: 0.488130
Train loss on 2450 batch: 0.542959
Train loss on 2500 batch: 0.594873
Train loss on 2550 batch: 0.584943
Train loss on 2600 batch: 0.503475
Train loss on 2650 batch: 0.569014
Train loss on 2700 batch: 0.430883
Train loss on 2750 batch: 0.433367
Train loss on 2800 batch: 0.574521
Train loss on 2850 batch: 0.569660
Train loss on 2900 batch: 0.554628
best-train-loss: 0.619469
best-valid-loss: 0.686214
best-kappa: 0.7253
: Epoch: 1 | Training Loss: 0.619469 | Val. Loss: 0.686214 | Val. Kappa Score: 0.7253 | Estimated time: 714.23
Train loss on 50 batch: 0.524907
Train loss on 100 batch: 0.529568
Train loss on 150 batch: 0.513854
Train loss on 200 batch: 0.520053
Train loss on 250 batch: 0.479873
Train loss on 300 batch: 0.527520
Train loss on 350 batch: 0.535179
Train loss on 400 batch: 0.501152
Train loss on 450 batch: 0.544180
Train loss on 500 batch: 0.494614
Train loss on 550 batch: 0.478116
Train loss on 600 batch: 0.522613
Train loss on 650 batch: 0.494140
Train loss on 700 batch: 0.455935
Train loss on 750 batch: 0.469698
Train loss on 800 batch: 0.531609
Train loss on 850 batch: 0.541469
Train loss on 900 batch: 0.446252
Train loss on 950 batch: 0.450296
Train loss on 1000 batch: 0.491751
Train loss on 1050 batch: 0.518075
Train loss on 1100 batch: 0.425016
Train loss on 1150 batch: 0.473696
Train loss on 1200 batch: 0.553423
Train loss on 1250 batch: 0.573955
Train loss on 1300 batch: 0.467769
Train loss on 1350 batch: 0.508962
Train loss on 1400 batch: 0.487533
Train loss on 1450 batch: 0.511214
Train loss on 1500 batch: 0.439252
Train loss on 1550 batch: 0.479298
Train loss on 1600 batch: 0.436020
Train loss on 1650 batch: 0.445601
Train loss on 1700 batch: 0.496830
Train loss on 1750 batch: 0.525887
Train loss on 1800 batch: 0.588174
Train loss on 1850 batch: 0.486521
Train loss on 1900 batch: 0.555391
Train loss on 1950 batch: 0.505544
Train loss on 2000 batch: 0.579569
Train loss on 2050 batch: 0.450692
Train loss on 2100 batch: 0.425128
Train loss on 2150 batch: 0.372512
Train loss on 2200 batch: 0.568284
Train loss on 2250 batch: 0.455562
Train loss on 2300 batch: 0.532457
Train loss on 2350 batch: 0.445151
Train loss on 2400 batch: 0.420787
Train loss on 2450 batch: 0.452436
Train loss on 2500 batch: 0.527863
Train loss on 2550 batch: 0.490082
Train loss on 2600 batch: 0.380881
Train loss on 2650 batch: 0.425179
Train loss on 2700 batch: 0.385886
Train loss on 2750 batch: 0.537910
Train loss on 2800 batch: 0.484860
Train loss on 2850 batch: 0.538709
Train loss on 2900 batch: 0.529460
best-train-loss: 0.491185
best-valid-loss: 0.513934
best-kappa: nan
: Epoch: 2 | Training Loss: 0.491185 | Val. Loss: 0.513934 | Val. Kappa Score: nan | Estimated time: 722.28
Train loss on 50 batch: 0.464596
Train loss on 100 batch: 0.430669
Train loss on 150 batch: 0.533171
Train loss on 200 batch: 0.395223
Train loss on 250 batch: 0.426870
Train loss on 300 batch: 0.477172
Train loss on 350 batch: 0.432256
Train loss on 400 batch: 0.436704
Train loss on 450 batch: 0.395994
Train loss on 500 batch: 0.483227
Train loss on 550 batch: 0.402231
Train loss on 600 batch: 0.404429
Train loss on 650 batch: 0.508259
Train loss on 700 batch: 0.539748
Train loss on 750 batch: 0.459993
Train loss on 800 batch: 0.489573
Train loss on 850 batch: 0.450917
Train loss on 900 batch: 0.440125
Train loss on 950 batch: 0.392822
Train loss on 1000 batch: 0.395992
Train loss on 1050 batch: 0.475647
Train loss on 1100 batch: 0.644986
Train loss on 1150 batch: 0.514473
Train loss on 1200 batch: 0.425928
Train loss on 1250 batch: 0.490518
Train loss on 1300 batch: 0.477667
Train loss on 1350 batch: 0.527749
Train loss on 1400 batch: 0.477606
Train loss on 1450 batch: 0.520348
Train loss on 1500 batch: 0.415968
Train loss on 1550 batch: 0.480606
Train loss on 1600 batch: 0.536797
Train loss on 1650 batch: 0.477982
Train loss on 1700 batch: 0.494107
Train loss on 1750 batch: 0.500578
Train loss on 1800 batch: 0.513307
Train loss on 1850 batch: 0.447639
Train loss on 1900 batch: 0.538872
Train loss on 1950 batch: 0.458844
Train loss on 2000 batch: 0.494971
Train loss on 2050 batch: 0.479675
Train loss on 2100 batch: 0.412348
Train loss on 2150 batch: 0.455590
Train loss on 2200 batch: 0.464925
Train loss on 2250 batch: 0.508529
Train loss on 2300 batch: 0.491401
Train loss on 2350 batch: 0.371833
Train loss on 2400 batch: 0.406117
Train loss on 2450 batch: 0.357624
Train loss on 2500 batch: 0.402297
Train loss on 2550 batch: 0.447074
Train loss on 2600 batch: 0.451282
Train loss on 2650 batch: 0.462649
Train loss on 2700 batch: 0.507203
Train loss on 2750 batch: 0.436956
Train loss on 2800 batch: 0.450262
Train loss on 2850 batch: 0.475910
Train loss on 2900 batch: 0.430944
best-train-loss: 0.462023
best-valid-loss: 0.490425
best-kappa: nan
: Epoch: 3 | Training Loss: 0.462023 | Val. Loss: 0.490425 | Val. Kappa Score: nan | Estimated time: 711.95
Train loss on 50 batch: 0.455067
Train loss on 100 batch: 0.462968
Train loss on 150 batch: 0.527242
Train loss on 200 batch: 0.372280
Train loss on 250 batch: 0.414650
Train loss on 300 batch: 0.441569
Train loss on 350 batch: 0.474823
Train loss on 400 batch: 0.464260
Train loss on 450 batch: 0.425083
Train loss on 500 batch: 0.565201
Train loss on 550 batch: 0.438104
Train loss on 600 batch: 0.486219
Train loss on 650 batch: 0.418567
Train loss on 700 batch: 0.475485
Train loss on 750 batch: 0.528000
Train loss on 800 batch: 0.527483
Train loss on 850 batch: 0.457877
Train loss on 900 batch: 0.536546
Train loss on 950 batch: 0.378530
Train loss on 1000 batch: 0.483540
Train loss on 1050 batch: 0.412901
Train loss on 1100 batch: 0.455527
Train loss on 1150 batch: 0.377476
Train loss on 1200 batch: 0.384702
Train loss on 1250 batch: 0.466206
Train loss on 1300 batch: 0.387290
Train loss on 1350 batch: 0.441551
Train loss on 1400 batch: 0.397578
Train loss on 1450 batch: 0.471195
Train loss on 1500 batch: 0.406393
Train loss on 1550 batch: 0.448775
Train loss on 1600 batch: 0.464891
Train loss on 1650 batch: 0.438723
Train loss on 1700 batch: 0.443425
Train loss on 1750 batch: 0.406228
Train loss on 1800 batch: 0.388817
Train loss on 1850 batch: 0.402274
Train loss on 1900 batch: 0.435846
Train loss on 1950 batch: 0.464639
Train loss on 2000 batch: 0.427193
Train loss on 2050 batch: 0.437790
Train loss on 2100 batch: 0.364651
Train loss on 2150 batch: 0.366467
Train loss on 2200 batch: 0.510576
Train loss on 2250 batch: 0.548472
Train loss on 2300 batch: 0.430812
Train loss on 2350 batch: 0.352839
Train loss on 2400 batch: 0.437748
Train loss on 2450 batch: 0.394008
Train loss on 2500 batch: 0.406853
Train loss on 2550 batch: 0.398055
Train loss on 2600 batch: 0.447572
Train loss on 2650 batch: 0.431526
Train loss on 2700 batch: 0.406243
Train loss on 2750 batch: 0.426968
Train loss on 2800 batch: 0.387321
Train loss on 2850 batch: 0.462554
Train loss on 2900 batch: 0.367320
: Epoch: 4 | Training Loss: 0.437578 | Val. Loss: 0.697453 | Val. Kappa Score: nan | Estimated time: 707.46
Train loss on 50 batch: 0.384847
Train loss on 100 batch: 0.519043
Train loss on 150 batch: 0.492586
Train loss on 200 batch: 0.450775
Train loss on 250 batch: 0.379853
Train loss on 300 batch: 0.406041
Train loss on 350 batch: 0.372129
Train loss on 400 batch: 0.466898
Train loss on 450 batch: 0.400123
Train loss on 500 batch: 0.416325
Train loss on 550 batch: 0.401269
Train loss on 600 batch: 0.379593
Train loss on 650 batch: 0.408937
Train loss on 700 batch: 0.388449
Train loss on 750 batch: 0.418727
Train loss on 800 batch: 0.409140
Train loss on 850 batch: 0.472442
Train loss on 900 batch: 0.443076
Train loss on 950 batch: 0.402631
Train loss on 1000 batch: 0.409904
Train loss on 1050 batch: 0.474924
Train loss on 1100 batch: 0.403921
Train loss on 1150 batch: 0.360575
Train loss on 1200 batch: 0.455767
Train loss on 1250 batch: 0.352790
Train loss on 1300 batch: 0.292735
Train loss on 1350 batch: 0.441225
Train loss on 1400 batch: 0.358930
Train loss on 1450 batch: 0.419577
Train loss on 1500 batch: 0.377665
Train loss on 1550 batch: 0.370312
Train loss on 1600 batch: 0.374407
Train loss on 1650 batch: 0.518510
Train loss on 1700 batch: 0.575759
Train loss on 1750 batch: 0.435547
Train loss on 1800 batch: 0.521098
Train loss on 1850 batch: 0.467981
Train loss on 1900 batch: 0.421942
Train loss on 1950 batch: 0.393664
Train loss on 2000 batch: 0.395783
Train loss on 2050 batch: 0.392722
Train loss on 2100 batch: 0.463694
Train loss on 2150 batch: 0.467170
Train loss on 2200 batch: 0.449383
Train loss on 2250 batch: 0.394895
Train loss on 2300 batch: 0.410738
Train loss on 2350 batch: 0.559423
Train loss on 2400 batch: 0.373226
Train loss on 2450 batch: 0.382356
Train loss on 2500 batch: 0.468439
Train loss on 2550 batch: 0.464783
Train loss on 2600 batch: 0.392690
Train loss on 2650 batch: 0.448412
Train loss on 2700 batch: 0.458606
Train loss on 2750 batch: 0.454456
Train loss on 2800 batch: 0.337045
Train loss on 2850 batch: 0.423142
Train loss on 2900 batch: 0.423936
: Epoch: 5 | Training Loss: 0.425127 | Val. Loss: 0.602818 | Val. Kappa Score: nan | Estimated time: 706.47
Train loss on 50 batch: 0.454343
Train loss on 100 batch: 0.466163
Train loss on 150 batch: 0.482549
Train loss on 200 batch: 0.371119
Train loss on 250 batch: 0.400479
Train loss on 300 batch: 0.467480
Train loss on 350 batch: 0.352071
Train loss on 400 batch: 0.482222
Train loss on 450 batch: 0.413786
Train loss on 500 batch: 0.320658
Train loss on 550 batch: 0.358106
Train loss on 600 batch: 0.466662
Train loss on 650 batch: 0.386739
Train loss on 700 batch: 0.364918
Train loss on 750 batch: 0.437386
Train loss on 800 batch: 0.373164
Train loss on 850 batch: 0.335797
Train loss on 900 batch: 0.469472
Train loss on 950 batch: 0.424452
Train loss on 1000 batch: 0.498778
Train loss on 1050 batch: 0.374523
Train loss on 1100 batch: 0.412110
Train loss on 1150 batch: 0.383546
Train loss on 1200 batch: 0.454133
Train loss on 1250 batch: 0.454535
Train loss on 1300 batch: 0.362554
Train loss on 1350 batch: 0.354096
Train loss on 1400 batch: 0.396783
Train loss on 1450 batch: 0.423721
Train loss on 1500 batch: 0.379630
Train loss on 1550 batch: 0.356886
Train loss on 1600 batch: 0.413677
Train loss on 1650 batch: 0.395868
Train loss on 1700 batch: 0.465038
Train loss on 1750 batch: 0.341522
Train loss on 1800 batch: 0.366475
Train loss on 1850 batch: 0.390702
Train loss on 1900 batch: 0.392163
Train loss on 1950 batch: 0.411285
Train loss on 2000 batch: 0.401546
Train loss on 2050 batch: 0.432444
Train loss on 2100 batch: 0.390984
Train loss on 2150 batch: 0.488617
Train loss on 2200 batch: 0.432184
Train loss on 2250 batch: 0.423920
Train loss on 2300 batch: 0.416103
Train loss on 2350 batch: 0.431502
Train loss on 2400 batch: 0.476944
Train loss on 2450 batch: 0.430801
Train loss on 2500 batch: 0.349402
Train loss on 2550 batch: 0.414982
Train loss on 2600 batch: 0.417897
Train loss on 2650 batch: 0.409190
Train loss on 2700 batch: 0.364059
Train loss on 2750 batch: 0.466264
Train loss on 2800 batch: 0.433915
Train loss on 2850 batch: 0.530033
Train loss on 2900 batch: 0.486257
: Epoch: 6 | Training Loss: 0.415846 | Val. Loss: 1.154013 | Val. Kappa Score: nan | Estimated time: 707.11
Train loss on 50 batch: 0.385769
Train loss on 100 batch: 0.387315
Train loss on 150 batch: 0.365096
Train loss on 200 batch: 0.380509
Train loss on 250 batch: 0.269727
Train loss on 300 batch: 0.339620
Train loss on 350 batch: 0.357114
Train loss on 400 batch: 0.303236
Train loss on 450 batch: 0.348019
Train loss on 500 batch: 0.382172
Train loss on 550 batch: 0.340942
Train loss on 600 batch: 0.313014
Train loss on 650 batch: 0.376342
Train loss on 700 batch: 0.394360
Train loss on 750 batch: 0.358638
Train loss on 800 batch: 0.331735
Train loss on 850 batch: 0.384771
Train loss on 900 batch: 0.411670
Train loss on 950 batch: 0.355768
Train loss on 1000 batch: 0.341936
Train loss on 1050 batch: 0.451217
Train loss on 1100 batch: 0.361619
Train loss on 1150 batch: 0.272955
Train loss on 1200 batch: 0.379054
Train loss on 1250 batch: 0.345586
Train loss on 1300 batch: 0.408395
Train loss on 1350 batch: 0.349157
Train loss on 1400 batch: 0.337627
Train loss on 1450 batch: 0.380549
Train loss on 1500 batch: 0.311394
Train loss on 1550 batch: 0.424128
Train loss on 1600 batch: 0.360591
Train loss on 1650 batch: 0.466585
Train loss on 1700 batch: 0.333027
Train loss on 1750 batch: 0.367001
Train loss on 1800 batch: 0.339442
Train loss on 1850 batch: 0.367569
Train loss on 1900 batch: 0.279331
Train loss on 1950 batch: 0.368920
Train loss on 2000 batch: 0.347249
Train loss on 2050 batch: 0.338380
Train loss on 2100 batch: 0.323570
Train loss on 2150 batch: 0.369916
Train loss on 2200 batch: 0.340217
Train loss on 2250 batch: 0.339729
Train loss on 2300 batch: 0.333054
Train loss on 2350 batch: 0.395919
Train loss on 2400 batch: 0.370243
Train loss on 2450 batch: 0.363220
Train loss on 2500 batch: 0.342092
Train loss on 2550 batch: 0.378248
Train loss on 2600 batch: 0.306129
Train loss on 2650 batch: 0.348556
Train loss on 2700 batch: 0.394934
Train loss on 2750 batch: 0.392440
Train loss on 2800 batch: 0.355526
Train loss on 2850 batch: 0.408999
Train loss on 2900 batch: 0.380580
: Epoch: 7 | Training Loss: 0.359026 | Val. Loss: 0.510814 | Val. Kappa Score: nan | Estimated time: 707.57
Train loss on 50 batch: 0.389454
Train loss on 100 batch: 0.409689
Train loss on 150 batch: 0.371848
Train loss on 200 batch: 0.351483
Train loss on 250 batch: 0.368384
Train loss on 300 batch: 0.337212
Train loss on 350 batch: 0.318363
Train loss on 400 batch: 0.365783
Train loss on 450 batch: 0.336621
Train loss on 500 batch: 0.329633
Train loss on 550 batch: 0.282545
Train loss on 600 batch: 0.340321
Train loss on 650 batch: 0.404148
Train loss on 700 batch: 0.358439
Train loss on 750 batch: 0.384125
Train loss on 800 batch: 0.389580
Train loss on 850 batch: 0.320556
Train loss on 900 batch: 0.451074
Train loss on 950 batch: 0.320260
Train loss on 1000 batch: 0.327962
Train loss on 1050 batch: 0.298779
Train loss on 1100 batch: 0.424077
Train loss on 1150 batch: 0.337833
Train loss on 1200 batch: 0.392418
Train loss on 1250 batch: 0.339034
Train loss on 1300 batch: 0.414124
Train loss on 1350 batch: 0.364874
Train loss on 1400 batch: 0.336541
Train loss on 1450 batch: 0.406958
Train loss on 1500 batch: 0.387271
Train loss on 1550 batch: 0.342587
Train loss on 1600 batch: 0.392315
Train loss on 1650 batch: 0.307695
Train loss on 1700 batch: 0.391343
Train loss on 1750 batch: 0.346720
Train loss on 1800 batch: 0.349256
Train loss on 1850 batch: 0.307812
Train loss on 1900 batch: 0.378874
Train loss on 1950 batch: 0.272546
Train loss on 2000 batch: 0.389130
Train loss on 2050 batch: 0.410539
Train loss on 2100 batch: 0.288426
Train loss on 2150 batch: 0.329239
Train loss on 2200 batch: 0.361061
Train loss on 2250 batch: 0.303132
Train loss on 2300 batch: 0.350383
Train loss on 2350 batch: 0.345775
Train loss on 2400 batch: 0.340300
Train loss on 2450 batch: 0.321845
Train loss on 2500 batch: 0.382078
Train loss on 2550 batch: 0.373780
Train loss on 2600 batch: 0.301780
Train loss on 2650 batch: 0.301234
Train loss on 2700 batch: 0.320836
Train loss on 2750 batch: 0.322039
Train loss on 2800 batch: 0.370163
Train loss on 2850 batch: 0.396753
Train loss on 2900 batch: 0.368306
best-train-loss: 0.353243
best-valid-loss: 0.404461
best-kappa: nan
: Epoch: 8 | Training Loss: 0.353243 | Val. Loss: 0.404461 | Val. Kappa Score: nan | Estimated time: 708.29
Train loss on 50 batch: 0.368926
Train loss on 100 batch: 0.361615
Train loss on 150 batch: 0.352716
Train loss on 200 batch: 0.331138
Train loss on 250 batch: 0.325490
Train loss on 300 batch: 0.322307
Train loss on 350 batch: 0.393709
Train loss on 400 batch: 0.288332
Train loss on 450 batch: 0.350343
Train loss on 500 batch: 0.360605
Train loss on 550 batch: 0.426190
Train loss on 600 batch: 0.335525
Train loss on 650 batch: 0.303491
Train loss on 700 batch: 0.243633
Train loss on 750 batch: 0.354871
Train loss on 800 batch: 0.309814
Train loss on 850 batch: 0.377340
Train loss on 900 batch: 0.425046
Train loss on 950 batch: 0.340271
Train loss on 1000 batch: 0.334489
Train loss on 1050 batch: 0.374538
Train loss on 1100 batch: 0.313839
Train loss on 1150 batch: 0.440875
Train loss on 1200 batch: 0.353458
Train loss on 1250 batch: 0.333092
Train loss on 1300 batch: 0.297668
Train loss on 1350 batch: 0.316658
Train loss on 1400 batch: 0.287432
Train loss on 1450 batch: 0.372923
Train loss on 1500 batch: 0.284270
Train loss on 1550 batch: 0.356984
Train loss on 1600 batch: 0.286516
Train loss on 1650 batch: 0.290819
Train loss on 1700 batch: 0.288597
Train loss on 1750 batch: 0.308218
Train loss on 1800 batch: 0.366941
Train loss on 1850 batch: 0.356424
Train loss on 1900 batch: 0.267505
Train loss on 1950 batch: 0.313199
Train loss on 2000 batch: 0.372070
Train loss on 2050 batch: 0.358927
Train loss on 2100 batch: 0.312328
Train loss on 2150 batch: 0.397884
Train loss on 2200 batch: 0.375914
Train loss on 2250 batch: 0.292965
Train loss on 2300 batch: 0.334087
Train loss on 2350 batch: 0.365453
Train loss on 2400 batch: 0.358664
Train loss on 2450 batch: 0.431007
Train loss on 2500 batch: 0.319130
Train loss on 2550 batch: 0.339480
Train loss on 2600 batch: 0.406137
Train loss on 2650 batch: 0.344770
Train loss on 2700 batch: 0.281493
Train loss on 2750 batch: 0.325668
Train loss on 2800 batch: 0.358126
Train loss on 2850 batch: 0.355308
Train loss on 2900 batch: 0.356479
best-train-loss: 0.342063
best-valid-loss: 0.386119
best-kappa: nan
: Epoch: 9 | Training Loss: 0.342063 | Val. Loss: 0.386119 | Val. Kappa Score: nan | Estimated time: 707.83
Train loss on 50 batch: 0.376544
Train loss on 100 batch: 0.364227
Train loss on 150 batch: 0.306006
Train loss on 200 batch: 0.347617
Train loss on 250 batch: 0.343732
Train loss on 300 batch: 0.315977
Train loss on 350 batch: 0.342035
Train loss on 400 batch: 0.314182
Train loss on 450 batch: 0.371899
Train loss on 500 batch: 0.354876
Train loss on 550 batch: 0.340560
Train loss on 600 batch: 0.455593
Train loss on 650 batch: 0.415405
Train loss on 700 batch: 0.321822
Train loss on 750 batch: 0.320580
Train loss on 800 batch: 0.333422
Train loss on 850 batch: 0.316264
Train loss on 900 batch: 0.373513
Train loss on 950 batch: 0.363032
Train loss on 1000 batch: 0.350485
Train loss on 1050 batch: 0.410787
Train loss on 1100 batch: 0.376619
Train loss on 1150 batch: 0.293439
Train loss on 1200 batch: 0.376928
Train loss on 1250 batch: 0.313771
Train loss on 1300 batch: 0.306792
Train loss on 1350 batch: 0.357136
Train loss on 1400 batch: 0.317193
Train loss on 1450 batch: 0.308389
Train loss on 1500 batch: 0.281672
Train loss on 1550 batch: 0.381994
Train loss on 1600 batch: 0.320019
Train loss on 1650 batch: 0.351124
Train loss on 1700 batch: 0.303758
Train loss on 1750 batch: 0.303074
Train loss on 1800 batch: 0.325530
Train loss on 1850 batch: 0.337549
Train loss on 1900 batch: 0.336725
Train loss on 1950 batch: 0.338785
Train loss on 2000 batch: 0.284580
Train loss on 2050 batch: 0.351771
Train loss on 2100 batch: 0.329664
Train loss on 2150 batch: 0.258284
Train loss on 2200 batch: 0.397003
Train loss on 2250 batch: 0.331858
Train loss on 2300 batch: 0.327501
Train loss on 2350 batch: 0.312062
Train loss on 2400 batch: 0.290047
Train loss on 2450 batch: 0.314687
Train loss on 2500 batch: 0.302974
Train loss on 2550 batch: 0.352341
Train loss on 2600 batch: 0.373068
Train loss on 2650 batch: 0.355469
Train loss on 2700 batch: 0.376651
Train loss on 2750 batch: 0.358553
Train loss on 2800 batch: 0.343385
Train loss on 2850 batch: 0.316441
Train loss on 2900 batch: 0.334380
: Epoch: 10 | Training Loss: 0.338227 | Val. Loss: 0.538556 | Val. Kappa Score: nan | Estimated time: 707.23
Train loss on 50 batch: 0.349215
Train loss on 100 batch: 0.333494
Train loss on 150 batch: 0.306276
Train loss on 200 batch: 0.288520
Train loss on 250 batch: 0.357633
Train loss on 300 batch: 0.316130
Train loss on 350 batch: 0.350788
Train loss on 400 batch: 0.330287
Train loss on 450 batch: 0.417151
Train loss on 500 batch: 0.334504
Train loss on 550 batch: 0.382776
Train loss on 600 batch: 0.302280
Train loss on 650 batch: 0.308504
Train loss on 700 batch: 0.355943
Train loss on 750 batch: 0.357972
Train loss on 800 batch: 0.338873
Train loss on 850 batch: 0.347564
Train loss on 900 batch: 0.332584
Train loss on 950 batch: 0.255254
Train loss on 1000 batch: 0.301717
Train loss on 1050 batch: 0.341937
Train loss on 1100 batch: 0.330547
Train loss on 1150 batch: 0.339783
Train loss on 1200 batch: 0.336403
Train loss on 1250 batch: 0.328402
Train loss on 1300 batch: 0.347318
Train loss on 1350 batch: 0.254937
Train loss on 1400 batch: 0.331002
Train loss on 1450 batch: 0.333429
Train loss on 1500 batch: 0.283732
Train loss on 1550 batch: 0.337997
Train loss on 1600 batch: 0.311225
Train loss on 1650 batch: 0.351159
Train loss on 1700 batch: 0.300301
Train loss on 1750 batch: 0.306680
Train loss on 1800 batch: 0.316643
Train loss on 1850 batch: 0.344736
Train loss on 1900 batch: 0.347635
Train loss on 1950 batch: 0.400196
Train loss on 2000 batch: 0.286965
Train loss on 2050 batch: 0.391582
Train loss on 2100 batch: 0.400694
Train loss on 2150 batch: 0.278590
Train loss on 2200 batch: 0.362636
Train loss on 2250 batch: 0.363100
Train loss on 2300 batch: 0.337816
Train loss on 2350 batch: 0.351422
Train loss on 2400 batch: 0.368021
Train loss on 2450 batch: 0.324516
Train loss on 2500 batch: 0.347724
Train loss on 2550 batch: 0.382135
Train loss on 2600 batch: 0.381643
Train loss on 2650 batch: 0.375695
Train loss on 2700 batch: 0.334168
Train loss on 2750 batch: 0.311357
Train loss on 2800 batch: 0.311199
Train loss on 2850 batch: 0.303532
Train loss on 2900 batch: 0.325119
: Epoch: 11 | Training Loss: 0.334859 | Val. Loss: 0.542594 | Val. Kappa Score: nan | Estimated time: 708.07
Train loss on 50 batch: 0.289790
Train loss on 100 batch: 0.339535
Train loss on 150 batch: 0.336395
Train loss on 200 batch: 0.330339
Train loss on 250 batch: 0.370940
Train loss on 300 batch: 0.328575
Train loss on 350 batch: 0.271973
Train loss on 400 batch: 0.443761
Train loss on 450 batch: 0.376840
Train loss on 500 batch: 0.280087
Train loss on 550 batch: 0.307409
Train loss on 600 batch: 0.301670
Train loss on 650 batch: 0.311948
Train loss on 700 batch: 0.380498
Train loss on 750 batch: 0.355415
Train loss on 800 batch: 0.413691
Train loss on 850 batch: 0.317488
Train loss on 900 batch: 0.288390
Train loss on 950 batch: 0.355526
Train loss on 1000 batch: 0.353246
Train loss on 1050 batch: 0.310818
Train loss on 1100 batch: 0.259928
Train loss on 1150 batch: 0.306693
Train loss on 1200 batch: 0.324328
Train loss on 1250 batch: 0.345220
Train loss on 1300 batch: 0.312484
Train loss on 1350 batch: 0.298533
Train loss on 1400 batch: 0.357442
Train loss on 1450 batch: 0.333537
Train loss on 1500 batch: 0.238744
Train loss on 1550 batch: 0.298199
Train loss on 1600 batch: 0.310936
Train loss on 1650 batch: 0.332552
Train loss on 1700 batch: 0.301037
Train loss on 1750 batch: 0.365512
Train loss on 1800 batch: 0.406313
Train loss on 1850 batch: 0.343045
Train loss on 1900 batch: 0.304344
Train loss on 1950 batch: 0.253577
Train loss on 2000 batch: 0.344948
Train loss on 2050 batch: 0.304162
Train loss on 2100 batch: 0.362494
Train loss on 2150 batch: 0.368920
Train loss on 2200 batch: 0.348734
Train loss on 2250 batch: 0.336422
Train loss on 2300 batch: 0.311281
Train loss on 2350 batch: 0.344699
Train loss on 2400 batch: 0.319787
Train loss on 2450 batch: 0.325884
Train loss on 2500 batch: 0.360893
Train loss on 2550 batch: 0.348347
Train loss on 2600 batch: 0.336734
Train loss on 2650 batch: 0.309333
Train loss on 2700 batch: 0.245143
Train loss on 2750 batch: 0.334695
Train loss on 2800 batch: 0.326327
Train loss on 2850 batch: 0.315603
Train loss on 2900 batch: 0.372587
: Epoch: 12 | Training Loss: 0.327471 | Val. Loss: 0.468218 | Val. Kappa Score: nan | Estimated time: 708.67
Train loss on 50 batch: 0.330276
Train loss on 100 batch: 0.342328
Train loss on 150 batch: 0.306287
Train loss on 200 batch: 0.305705
Train loss on 250 batch: 0.322774
Train loss on 300 batch: 0.262664
Train loss on 350 batch: 0.264553
Train loss on 400 batch: 0.366735
Train loss on 450 batch: 0.330962
Train loss on 500 batch: 0.339565
Train loss on 550 batch: 0.293441
Train loss on 600 batch: 0.319220
Train loss on 650 batch: 0.240546
Train loss on 700 batch: 0.263807
Train loss on 750 batch: 0.248035
Train loss on 800 batch: 0.314780
Train loss on 850 batch: 0.279833
Train loss on 900 batch: 0.376915
Train loss on 950 batch: 0.317168
Train loss on 1000 batch: 0.256440
Train loss on 1050 batch: 0.284755
Train loss on 1100 batch: 0.303402
Train loss on 1150 batch: 0.268804
Train loss on 1200 batch: 0.288251
Train loss on 1250 batch: 0.325983
Train loss on 1300 batch: 0.327608
Train loss on 1350 batch: 0.342091
Train loss on 1400 batch: 0.287520
Train loss on 1450 batch: 0.348502
Train loss on 1500 batch: 0.320508
Train loss on 1550 batch: 0.325170
Train loss on 1600 batch: 0.278184
Train loss on 1650 batch: 0.287592
Train loss on 1700 batch: 0.275271
Train loss on 1750 batch: 0.364015
Train loss on 1800 batch: 0.262753
Train loss on 1850 batch: 0.264193
Train loss on 1900 batch: 0.297638
Train loss on 1950 batch: 0.359950
Train loss on 2000 batch: 0.289773
Train loss on 2050 batch: 0.217819
Train loss on 2100 batch: 0.368493
Train loss on 2150 batch: 0.314410
Train loss on 2200 batch: 0.275456
Train loss on 2250 batch: 0.317529
Train loss on 2300 batch: 0.327472
Train loss on 2350 batch: 0.270969
Train loss on 2400 batch: 0.237479
Train loss on 2450 batch: 0.301921
Train loss on 2500 batch: 0.333792
Train loss on 2550 batch: 0.311435
Train loss on 2600 batch: 0.285517
Train loss on 2650 batch: 0.297355
Train loss on 2700 batch: 0.324320
Train loss on 2750 batch: 0.276614
Train loss on 2800 batch: 0.296162
Train loss on 2850 batch: 0.296243
Train loss on 2900 batch: 0.323311
: Epoch: 13 | Training Loss: 0.301850 | Val. Loss: 0.515464 | Val. Kappa Score: nan | Estimated time: 706.63
Train loss on 50 batch: 0.293707
Train loss on 100 batch: 0.320497
Train loss on 150 batch: 0.334456
Train loss on 200 batch: 0.313551
Train loss on 250 batch: 0.267010
Train loss on 300 batch: 0.286940
Train loss on 350 batch: 0.287063
Train loss on 400 batch: 0.317571
Train loss on 450 batch: 0.271234
Train loss on 500 batch: 0.337509
Train loss on 550 batch: 0.319716
Train loss on 600 batch: 0.424618
Train loss on 650 batch: 0.283899
Train loss on 700 batch: 0.309575
Train loss on 750 batch: 0.335462
Train loss on 800 batch: 0.289688
Train loss on 850 batch: 0.302966
Train loss on 900 batch: 0.253496
Train loss on 950 batch: 0.274409
Train loss on 1000 batch: 0.292414
Train loss on 1050 batch: 0.237105
Train loss on 1100 batch: 0.253516
Train loss on 1150 batch: 0.215945
Train loss on 1200 batch: 0.229310
Train loss on 1250 batch: 0.287986
Train loss on 1300 batch: 0.313829
Train loss on 1350 batch: 0.269989
Train loss on 1400 batch: 0.271530
Train loss on 1450 batch: 0.330089
Train loss on 1500 batch: 0.344643
Train loss on 1550 batch: 0.279044
Train loss on 1600 batch: 0.230199
Train loss on 1650 batch: 0.281653
Train loss on 1700 batch: 0.293661
Train loss on 1750 batch: 0.202871
Train loss on 1800 batch: 0.252956
Train loss on 1850 batch: 0.271605
Train loss on 1900 batch: 0.311542
Train loss on 1950 batch: 0.272028
Train loss on 2000 batch: 0.322076
Train loss on 2050 batch: 0.370733
Train loss on 2100 batch: 0.298673
Train loss on 2150 batch: 0.273034
Train loss on 2200 batch: 0.285094
Train loss on 2250 batch: 0.316028
Train loss on 2300 batch: 0.302321
Train loss on 2350 batch: 0.299703
Train loss on 2400 batch: 0.346156
Train loss on 2450 batch: 0.349323
Train loss on 2500 batch: 0.291638
Train loss on 2550 batch: 0.278824
Train loss on 2600 batch: 0.327608
Train loss on 2650 batch: 0.243156
Train loss on 2700 batch: 0.269701
Train loss on 2750 batch: 0.261124
Train loss on 2800 batch: 0.279994
Train loss on 2850 batch: 0.276675
Train loss on 2900 batch: 0.269140
: Epoch: 14 | Training Loss: 0.292110 | Val. Loss: 0.448811 | Val. Kappa Score: nan | Estimated time: 706.37
Train loss on 50 batch: 0.224719
Train loss on 100 batch: 0.282897
Train loss on 150 batch: 0.231085
Train loss on 200 batch: 0.305326
Train loss on 250 batch: 0.261458
Train loss on 300 batch: 0.309204
Train loss on 350 batch: 0.285850
Train loss on 400 batch: 0.222671
Train loss on 450 batch: 0.268340
Train loss on 500 batch: 0.295766
Train loss on 550 batch: 0.280709
Train loss on 600 batch: 0.291293
Train loss on 650 batch: 0.289477
Train loss on 700 batch: 0.241243
Train loss on 750 batch: 0.260734
Train loss on 800 batch: 0.290326
Train loss on 850 batch: 0.255206
Train loss on 900 batch: 0.297275
Train loss on 950 batch: 0.308970
Train loss on 1000 batch: 0.285329
Train loss on 1050 batch: 0.307368
Train loss on 1100 batch: 0.323772
Train loss on 1150 batch: 0.248081
Train loss on 1200 batch: 0.261395
Train loss on 1250 batch: 0.273527
Train loss on 1300 batch: 0.279786
Train loss on 1350 batch: 0.275127
Train loss on 1400 batch: 0.293770
Train loss on 1450 batch: 0.262076
Train loss on 1500 batch: 0.333672
Train loss on 1550 batch: 0.299762
Train loss on 1600 batch: 0.313403
Train loss on 1650 batch: 0.287468
Train loss on 1700 batch: 0.327191
Train loss on 1750 batch: 0.269099
Train loss on 1800 batch: 0.289279
Train loss on 1850 batch: 0.283828
Train loss on 1900 batch: 0.290521
Train loss on 1950 batch: 0.350851
Train loss on 2000 batch: 0.294291
Train loss on 2050 batch: 0.273664
Train loss on 2100 batch: 0.201357
Train loss on 2150 batch: 0.278077
Train loss on 2200 batch: 0.287776
Train loss on 2250 batch: 0.296801
Train loss on 2300 batch: 0.328588
Train loss on 2350 batch: 0.327533
Train loss on 2400 batch: 0.346348
Train loss on 2450 batch: 0.312635
Train loss on 2500 batch: 0.315723
Train loss on 2550 batch: 0.283357
Train loss on 2600 batch: 0.313047
Train loss on 2650 batch: 0.303651
Train loss on 2700 batch: 0.389775
Train loss on 2750 batch: 0.286418
Train loss on 2800 batch: 0.315900
Train loss on 2850 batch: 0.265387
Train loss on 2900 batch: 0.262785
: Epoch: 15 | Training Loss: 0.289456 | Val. Loss: 0.414580 | Val. Kappa Score: nan | Estimated time: 707.57
Train loss on 50 batch: 0.301700
Train loss on 100 batch: 0.319765
Train loss on 150 batch: 0.317233
Train loss on 200 batch: 0.330554
Train loss on 250 batch: 0.313158
Train loss on 300 batch: 0.308992
Train loss on 350 batch: 0.267998
Train loss on 400 batch: 0.274319
Train loss on 450 batch: 0.369411
Train loss on 500 batch: 0.223068
Train loss on 550 batch: 0.313373
Train loss on 600 batch: 0.289676
Train loss on 650 batch: 0.337396
Train loss on 700 batch: 0.282785
Train loss on 750 batch: 0.231756
Train loss on 800 batch: 0.238155
Train loss on 850 batch: 0.293809
Train loss on 900 batch: 0.240028
Train loss on 950 batch: 0.240955
Train loss on 1000 batch: 0.232563
Train loss on 1050 batch: 0.239718
Train loss on 1100 batch: 0.268161
Train loss on 1150 batch: 0.315392
Train loss on 1200 batch: 0.276593
Train loss on 1250 batch: 0.300086
Train loss on 1300 batch: 0.252752
Train loss on 1350 batch: 0.300678
Train loss on 1400 batch: 0.312832
Train loss on 1450 batch: 0.209605
Train loss on 1500 batch: 0.292959
Train loss on 1550 batch: 0.244921
Train loss on 1600 batch: 0.227687
Train loss on 1650 batch: 0.310291
Train loss on 1700 batch: 0.283371
Train loss on 1750 batch: 0.212367
Train loss on 1800 batch: 0.302597
Train loss on 1850 batch: 0.290614
Train loss on 1900 batch: 0.295108
Train loss on 1950 batch: 0.265699
Train loss on 2000 batch: 0.245203
Train loss on 2050 batch: 0.305334
Train loss on 2100 batch: 0.260407
Train loss on 2150 batch: 0.263025
Train loss on 2200 batch: 0.281597
Train loss on 2250 batch: 0.248541
Train loss on 2300 batch: 0.238246
Train loss on 2350 batch: 0.244208
Train loss on 2400 batch: 0.229936
Train loss on 2450 batch: 0.280717
Train loss on 2500 batch: 0.240661
Train loss on 2550 batch: 0.273849
Train loss on 2600 batch: 0.253739
Train loss on 2650 batch: 0.252400
Train loss on 2700 batch: 0.333209
Train loss on 2750 batch: 0.227481
Train loss on 2800 batch: 0.262390
Train loss on 2850 batch: 0.218543
Train loss on 2900 batch: 0.283131
: Epoch: 16 | Training Loss: 0.274339 | Val. Loss: 0.485238 | Val. Kappa Score: nan | Estimated time: 708.20
Train loss on 50 batch: 0.270585
Train loss on 100 batch: 0.289984
Train loss on 150 batch: 0.260650
Train loss on 200 batch: 0.256658
Train loss on 250 batch: 0.253927
Train loss on 300 batch: 0.284591
Train loss on 350 batch: 0.328310
Train loss on 400 batch: 0.221301
Train loss on 450 batch: 0.375454
Train loss on 500 batch: 0.278292
Train loss on 550 batch: 0.267404
Train loss on 600 batch: 0.261096
Train loss on 650 batch: 0.300229
Train loss on 700 batch: 0.231026
Train loss on 750 batch: 0.244215
Train loss on 800 batch: 0.239496
Train loss on 850 batch: 0.267060
Train loss on 900 batch: 0.330939
Train loss on 950 batch: 0.233244
Train loss on 1000 batch: 0.259287
Train loss on 1050 batch: 0.331869
Train loss on 1100 batch: 0.239407
Train loss on 1150 batch: 0.276545
Train loss on 1200 batch: 0.235680
Train loss on 1250 batch: 0.311661
Train loss on 1300 batch: 0.292001
Train loss on 1350 batch: 0.291086
Train loss on 1400 batch: 0.271675
Train loss on 1450 batch: 0.278465
Train loss on 1500 batch: 0.232814
Train loss on 1550 batch: 0.255718
Train loss on 1600 batch: 0.317325
Train loss on 1650 batch: 0.241528
Train loss on 1700 batch: 0.270383
Train loss on 1750 batch: 0.231449
Train loss on 1800 batch: 0.312785
Train loss on 1850 batch: 0.311105
Train loss on 1900 batch: 0.263091
Train loss on 1950 batch: 0.261229
Train loss on 2000 batch: 0.298385
Train loss on 2050 batch: 0.357715
Train loss on 2100 batch: 0.283272
Train loss on 2150 batch: 0.215950
Train loss on 2200 batch: 0.263064
Train loss on 2250 batch: 0.258682
Train loss on 2300 batch: 0.252847
Train loss on 2350 batch: 0.304717
Train loss on 2400 batch: 0.285095
Train loss on 2450 batch: 0.346442
Train loss on 2500 batch: 0.281747
Train loss on 2550 batch: 0.164888
Train loss on 2600 batch: 0.255322
Train loss on 2650 batch: 0.252337
Train loss on 2700 batch: 0.239420
Train loss on 2750 batch: 0.251220
Train loss on 2800 batch: 0.242398
Train loss on 2850 batch: 0.232482
Train loss on 2900 batch: 0.243436
: Epoch: 17 | Training Loss: 0.270833 | Val. Loss: 0.488369 | Val. Kappa Score: nan | Estimated time: 706.63
Train loss on 50 batch: 0.234261
Train loss on 100 batch: 0.250183
Train loss on 150 batch: 0.261381
Train loss on 200 batch: 0.282304
Train loss on 250 batch: 0.280758
Train loss on 300 batch: 0.206079
Train loss on 350 batch: 0.205318
Train loss on 400 batch: 0.300125
Train loss on 450 batch: 0.277260
Train loss on 500 batch: 0.227652
Train loss on 550 batch: 0.266008
Train loss on 600 batch: 0.323442
Train loss on 650 batch: 0.258679
Train loss on 700 batch: 0.228118
Train loss on 750 batch: 0.267714
Train loss on 800 batch: 0.296070
Train loss on 850 batch: 0.295243
Train loss on 900 batch: 0.199791
Train loss on 950 batch: 0.271883
Train loss on 1000 batch: 0.294205
Train loss on 1050 batch: 0.239552
Train loss on 1100 batch: 0.291333
Train loss on 1150 batch: 0.277547
Train loss on 1200 batch: 0.269752
Train loss on 1250 batch: 0.325136
Train loss on 1300 batch: 0.302870
Train loss on 1350 batch: 0.272787
Train loss on 1400 batch: 0.225289
Train loss on 1450 batch: 0.254975
Train loss on 1500 batch: 0.259009
Train loss on 1550 batch: 0.227516
Train loss on 1600 batch: 0.258220
Train loss on 1650 batch: 0.281381
Train loss on 1700 batch: 0.329255
Train loss on 1750 batch: 0.225367
Train loss on 1800 batch: 0.274188
Train loss on 1850 batch: 0.270730
Train loss on 1900 batch: 0.245972
Train loss on 1950 batch: 0.283238
Train loss on 2000 batch: 0.331506
Train loss on 2050 batch: 0.374125
Train loss on 2100 batch: 0.292485
Train loss on 2150 batch: 0.299205
Train loss on 2200 batch: 0.254816
Train loss on 2250 batch: 0.270554
Train loss on 2300 batch: 0.274874
Train loss on 2350 batch: 0.233749
Train loss on 2400 batch: 0.286949
Train loss on 2450 batch: 0.210306
Train loss on 2500 batch: 0.265656
Train loss on 2550 batch: 0.304702
Train loss on 2600 batch: 0.308955
Train loss on 2650 batch: 0.284779
Train loss on 2700 batch: 0.246861
Train loss on 2750 batch: 0.291247
Train loss on 2800 batch: 0.212014
Train loss on 2850 batch: 0.235181
Train loss on 2900 batch: 0.284211
: Epoch: 18 | Training Loss: 0.269846 | Val. Loss: 0.430521 | Val. Kappa Score: nan | Estimated time: 708.19
Train loss on 50 batch: 0.249511
Train loss on 100 batch: 0.252118
Train loss on 150 batch: 0.243067
Train loss on 200 batch: 0.322345
Train loss on 250 batch: 0.205418
Train loss on 300 batch: 0.321784
Train loss on 350 batch: 0.265050
Train loss on 400 batch: 0.294526
Train loss on 450 batch: 0.254374
Train loss on 500 batch: 0.290262
Train loss on 550 batch: 0.321234
Train loss on 600 batch: 0.274476
Train loss on 650 batch: 0.274966
Train loss on 700 batch: 0.283436
Train loss on 750 batch: 0.213476
Train loss on 800 batch: 0.256155
Train loss on 850 batch: 0.274052
Train loss on 900 batch: 0.283235
Train loss on 950 batch: 0.227837
Train loss on 1000 batch: 0.273726
Train loss on 1050 batch: 0.231672
Train loss on 1100 batch: 0.285128
Train loss on 1150 batch: 0.254900
Train loss on 1200 batch: 0.196010
Train loss on 1250 batch: 0.256762
Train loss on 1300 batch: 0.242973
Train loss on 1350 batch: 0.238830
Train loss on 1400 batch: 0.283262
Train loss on 1450 batch: 0.291946
Train loss on 1500 batch: 0.240205
Train loss on 1550 batch: 0.262600
Train loss on 1600 batch: 0.272254
Train loss on 1650 batch: 0.267971
Train loss on 1700 batch: 0.222700
Train loss on 1750 batch: 0.255849
Train loss on 1800 batch: 0.234338
Train loss on 1850 batch: 0.297982
Train loss on 1900 batch: 0.214613
Train loss on 1950 batch: 0.281951
Train loss on 2000 batch: 0.246139
Train loss on 2050 batch: 0.318792
Train loss on 2100 batch: 0.290972
Train loss on 2150 batch: 0.237409
Train loss on 2200 batch: 0.278808
Train loss on 2250 batch: 0.226228
Train loss on 2300 batch: 0.238046
Train loss on 2350 batch: 0.328057
Train loss on 2400 batch: 0.281057
Train loss on 2450 batch: 0.276649
Train loss on 2500 batch: 0.195514
Train loss on 2550 batch: 0.232016
Train loss on 2600 batch: 0.277968
Train loss on 2650 batch: 0.243326
Train loss on 2700 batch: 0.215880
Train loss on 2750 batch: 0.256091
Train loss on 2800 batch: 0.226638
Train loss on 2850 batch: 0.278982
Train loss on 2900 batch: 0.256079
: Epoch: 19 | Training Loss: 0.258927 | Val. Loss: 0.461104 | Val. Kappa Score: nan | Estimated time: 708.40
time_estimated: 13469.38
n-epochs: 19
time_estimated: 13469.38
----------------------------------------

Experiment N: 11: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
TRAINING STAGE: : old
date: 2019.08.25 12:38:38
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10f668>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.045167
Train loss on 100 batch: 0.993319
Train loss on 150 batch: 0.909442
Train loss on 200 batch: 0.969143
Train loss on 250 batch: 0.918876
Train loss on 300 batch: 0.720798
Train loss on 350 batch: 0.766441
Train loss on 400 batch: 0.735442
Train loss on 450 batch: 0.758929
Train loss on 500 batch: 0.815861
Train loss on 550 batch: 0.828438
Train loss on 600 batch: 0.711737
Train loss on 650 batch: 0.885578
Train loss on 700 batch: 0.734126
Train loss on 750 batch: 0.682246
Train loss on 800 batch: 0.615318
Train loss on 850 batch: 0.656739
Train loss on 900 batch: 0.638320
Train loss on 950 batch: 0.604637
Train loss on 1000 batch: 0.791860
Train loss on 1050 batch: 0.541252
Train loss on 1100 batch: 0.670823
Train loss on 1150 batch: 0.582976
Train loss on 1200 batch: 0.780355
Train loss on 1250 batch: 0.625488
Train loss on 1300 batch: 0.574799
Train loss on 1350 batch: 0.667163
Train loss on 1400 batch: 0.683428
Train loss on 1450 batch: 0.599202
Train loss on 1500 batch: 0.514729
Train loss on 1550 batch: 0.681335
Train loss on 1600 batch: 0.642629
Train loss on 1650 batch: 0.542505
Train loss on 1700 batch: 0.601804
Train loss on 1750 batch: 0.530311
Train loss on 1800 batch: 0.499236
Train loss on 1850 batch: 0.633578
Train loss on 1900 batch: 0.580677
Train loss on 1950 batch: 0.669319
Train loss on 2000 batch: 0.605772
Train loss on 2050 batch: 0.672320
Train loss on 2100 batch: 0.673490
Train loss on 2150 batch: 0.536966
Train loss on 2200 batch: 0.542267
Train loss on 2250 batch: 0.601627
Train loss on 2300 batch: 0.560205
Train loss on 2350 batch: 0.540495
Train loss on 2400 batch: 0.555170
Train loss on 2450 batch: 0.578830
Train loss on 2500 batch: 0.601657
Train loss on 2550 batch: 0.577294
Train loss on 2600 batch: 0.529107
Train loss on 2650 batch: 0.621029
Train loss on 2700 batch: 0.470772
Train loss on 2750 batch: 0.481849
Train loss on 2800 batch: 0.589444
Train loss on 2850 batch: 0.578529
Train loss on 2900 batch: 0.532982
best-train-loss: 0.659743
best-valid-loss: 0.580471
best-kappa: 0.7622
: Epoch: 1 | Training Loss: 0.659743 | Val. Loss: 0.580471 | Val. Kappa Score: 0.7622 | Estimated time: 755.04
Train loss on 50 batch: 0.559631
Train loss on 100 batch: 0.549816
Train loss on 150 batch: 0.586696
Train loss on 200 batch: 0.542140
Train loss on 250 batch: 0.511973
Train loss on 300 batch: 0.576125
Train loss on 350 batch: 0.641696
Train loss on 400 batch: 0.557728
Train loss on 450 batch: 0.544938
Train loss on 500 batch: 0.561750
Train loss on 550 batch: 0.545212
Train loss on 600 batch: 0.630342
Train loss on 650 batch: 0.616116
Train loss on 700 batch: 0.574587
Train loss on 750 batch: 0.474123
Train loss on 800 batch: 0.573140
Train loss on 850 batch: 0.550225
Train loss on 900 batch: 0.502431
Train loss on 950 batch: 0.443695
Train loss on 1000 batch: 0.577634
Train loss on 1050 batch: 0.525968
Train loss on 1100 batch: 0.424793
Train loss on 1150 batch: 0.473396
Train loss on 1200 batch: 0.573066
Train loss on 1250 batch: 0.592483
Train loss on 1300 batch: 0.540447
Train loss on 1350 batch: 0.558057
Train loss on 1400 batch: 0.531929
Train loss on 1450 batch: 0.483517
Train loss on 1500 batch: 0.478714
Train loss on 1550 batch: 0.537056
Train loss on 1600 batch: 0.461375
Train loss on 1650 batch: 0.464057
Train loss on 1700 batch: 0.562167
Train loss on 1750 batch: 0.493619
Train loss on 1800 batch: 0.584625
Train loss on 1850 batch: 0.529480
Train loss on 1900 batch: 0.543593
Train loss on 1950 batch: 0.501735
Train loss on 2000 batch: 0.545271
Train loss on 2050 batch: 0.554659
Train loss on 2100 batch: 0.450047
Train loss on 2150 batch: 0.473073
Train loss on 2200 batch: 0.592741
Train loss on 2250 batch: 0.447478
Train loss on 2300 batch: 0.582506
Train loss on 2350 batch: 0.511293
Train loss on 2400 batch: 0.522208
Train loss on 2450 batch: 0.484044
Train loss on 2500 batch: 0.542053
Train loss on 2550 batch: 0.475017
Train loss on 2600 batch: 0.397272
Train loss on 2650 batch: 0.435857
Train loss on 2700 batch: 0.431459
Train loss on 2750 batch: 0.545258
Train loss on 2800 batch: 0.481255
Train loss on 2850 batch: 0.598501
Train loss on 2900 batch: 0.618523
: Epoch: 2 | Training Loss: 0.528152 | Val. Loss: 0.689438 | Val. Kappa Score: nan | Estimated time: 745.84
Train loss on 50 batch: 0.500342
Train loss on 100 batch: 0.475151
Train loss on 150 batch: 0.598192
Train loss on 200 batch: 0.481635
Train loss on 250 batch: 0.433480
Train loss on 300 batch: 0.502159
Train loss on 350 batch: 0.449726
Train loss on 400 batch: 0.473240
Train loss on 450 batch: 0.477700
Train loss on 500 batch: 0.511654
Train loss on 550 batch: 0.409366
Train loss on 600 batch: 0.429118
Train loss on 650 batch: 0.492356
Train loss on 700 batch: 0.565751
Train loss on 750 batch: 0.512183
Train loss on 800 batch: 0.539067
Train loss on 850 batch: 0.476527
Train loss on 900 batch: 0.538600
Train loss on 950 batch: 0.420196
Train loss on 1000 batch: 0.396446
Train loss on 1050 batch: 0.534410
Train loss on 1100 batch: 0.570259
Train loss on 1150 batch: 0.463687
Train loss on 1200 batch: 0.465365
Train loss on 1250 batch: 0.527682
Train loss on 1300 batch: 0.527908
Train loss on 1350 batch: 0.605734
Train loss on 1400 batch: 0.498321
Train loss on 1450 batch: 0.463602
Train loss on 1500 batch: 0.425004
Train loss on 1550 batch: 0.465402
Train loss on 1600 batch: 0.512576
Train loss on 1650 batch: 0.478896
Train loss on 1700 batch: 0.493353
Train loss on 1750 batch: 0.534795
Train loss on 1800 batch: 0.552831
Train loss on 1850 batch: 0.420148
Train loss on 1900 batch: 0.565223
Train loss on 1950 batch: 0.439013
Train loss on 2000 batch: 0.525550
Train loss on 2050 batch: 0.556125
Train loss on 2100 batch: 0.425090
Train loss on 2150 batch: 0.502185
Train loss on 2200 batch: 0.507439
Train loss on 2250 batch: 0.497819
Train loss on 2300 batch: 0.465272
Train loss on 2350 batch: 0.370447
Train loss on 2400 batch: 0.443514
Train loss on 2450 batch: 0.426011
Train loss on 2500 batch: 0.421975
Train loss on 2550 batch: 0.454861
Train loss on 2600 batch: 0.476263
Train loss on 2650 batch: 0.477078
Train loss on 2700 batch: 0.582407
Train loss on 2750 batch: 0.422728
Train loss on 2800 batch: 0.481564
Train loss on 2850 batch: 0.463909
Train loss on 2900 batch: 0.463101
: Epoch: 3 | Training Loss: 0.484317 | Val. Loss: 0.947827 | Val. Kappa Score: nan | Estimated time: 744.10
Train loss on 50 batch: 0.444820
Train loss on 100 batch: 0.479880
Train loss on 150 batch: 0.512899
Train loss on 200 batch: 0.409791
Train loss on 250 batch: 0.459204
Train loss on 300 batch: 0.465738
Train loss on 350 batch: 0.450524
Train loss on 400 batch: 0.497336
Train loss on 450 batch: 0.433905
Train loss on 500 batch: 0.607840
Train loss on 550 batch: 0.446282
Train loss on 600 batch: 0.488743
Train loss on 650 batch: 0.443716
Train loss on 700 batch: 0.448327
Train loss on 750 batch: 0.585829
Train loss on 800 batch: 0.496313
Train loss on 850 batch: 0.414586
Train loss on 900 batch: 0.547444
Train loss on 950 batch: 0.484737
Train loss on 1000 batch: 0.506955
Train loss on 1050 batch: 0.479009
Train loss on 1100 batch: 0.469519
Train loss on 1150 batch: 0.396019
Train loss on 1200 batch: 0.385115
Train loss on 1250 batch: 0.482001
Train loss on 1300 batch: 0.436908
Train loss on 1350 batch: 0.535071
Train loss on 1400 batch: 0.438085
Train loss on 1450 batch: 0.448444
Train loss on 1500 batch: 0.462750
Train loss on 1550 batch: 0.459295
Train loss on 1600 batch: 0.425373
Train loss on 1650 batch: 0.422480
Train loss on 1700 batch: 0.441613
Train loss on 1750 batch: 0.440026
Train loss on 1800 batch: 0.405236
Train loss on 1850 batch: 0.423524
Train loss on 1900 batch: 0.478284
Train loss on 1950 batch: 0.543638
Train loss on 2000 batch: 0.438218
Train loss on 2050 batch: 0.489832
Train loss on 2100 batch: 0.371087
Train loss on 2150 batch: 0.412204
Train loss on 2200 batch: 0.495347
Train loss on 2250 batch: 0.553936
Train loss on 2300 batch: 0.467372
Train loss on 2350 batch: 0.378869
Train loss on 2400 batch: 0.452163
Train loss on 2450 batch: 0.447332
Train loss on 2500 batch: 0.429759
Train loss on 2550 batch: 0.414770
Train loss on 2600 batch: 0.457387
Train loss on 2650 batch: 0.464984
Train loss on 2700 batch: 0.422938
Train loss on 2750 batch: 0.448141
Train loss on 2800 batch: 0.415540
Train loss on 2850 batch: 0.476717
Train loss on 2900 batch: 0.390285
best-train-loss: 0.457755
best-valid-loss: 0.527332
best-kappa: nan
: Epoch: 4 | Training Loss: 0.457755 | Val. Loss: 0.527332 | Val. Kappa Score: nan | Estimated time: 743.45
Train loss on 50 batch: 0.391744
Train loss on 100 batch: 0.532626
Train loss on 150 batch: 0.510686
Train loss on 200 batch: 0.495260
Train loss on 250 batch: 0.415517
Train loss on 300 batch: 0.430985
Train loss on 350 batch: 0.353168
Train loss on 400 batch: 0.495062
Train loss on 450 batch: 0.434236
Train loss on 500 batch: 0.434366
Train loss on 550 batch: 0.419304
Train loss on 600 batch: 0.423136
Train loss on 650 batch: 0.438842
Train loss on 700 batch: 0.421400
Train loss on 750 batch: 0.432378
Train loss on 800 batch: 0.437232
Train loss on 850 batch: 0.521378
Train loss on 900 batch: 0.430554
Train loss on 950 batch: 0.408589
Train loss on 1000 batch: 0.413115
Train loss on 1050 batch: 0.509233
Train loss on 1100 batch: 0.442922
Train loss on 1150 batch: 0.409003
Train loss on 1200 batch: 0.497359
Train loss on 1250 batch: 0.354003
Train loss on 1300 batch: 0.328621
Train loss on 1350 batch: 0.479918
Train loss on 1400 batch: 0.372249
Train loss on 1450 batch: 0.415243
Train loss on 1500 batch: 0.416324
Train loss on 1550 batch: 0.391296
Train loss on 1600 batch: 0.396140
Train loss on 1650 batch: 0.504410
Train loss on 1700 batch: 0.556296
Train loss on 1750 batch: 0.459703
Train loss on 1800 batch: 0.512688
Train loss on 1850 batch: 0.509045
Train loss on 1900 batch: 0.422170
Train loss on 1950 batch: 0.388057
Train loss on 2000 batch: 0.408420
Train loss on 2050 batch: 0.449989
Train loss on 2100 batch: 0.497796
Train loss on 2150 batch: 0.454251
Train loss on 2200 batch: 0.452770
Train loss on 2250 batch: 0.384238
Train loss on 2300 batch: 0.422114
Train loss on 2350 batch: 0.467492
Train loss on 2400 batch: 0.377005
Train loss on 2450 batch: 0.421795
Train loss on 2500 batch: 0.519298
Train loss on 2550 batch: 0.458364
Train loss on 2600 batch: 0.442385
Train loss on 2650 batch: 0.534454
Train loss on 2700 batch: 0.476672
Train loss on 2750 batch: 0.472718
Train loss on 2800 batch: 0.367757
Train loss on 2850 batch: 0.440067
Train loss on 2900 batch: 0.414417
: Epoch: 5 | Training Loss: 0.442808 | Val. Loss: 0.541492 | Val. Kappa Score: nan | Estimated time: 744.18
Train loss on 50 batch: 0.450241
Train loss on 100 batch: 0.500359
Train loss on 150 batch: 0.463771
Train loss on 200 batch: 0.373254
Train loss on 250 batch: 0.422165
Train loss on 300 batch: 0.437770
Train loss on 350 batch: 0.414294
Train loss on 400 batch: 0.461154
Train loss on 450 batch: 0.443491
Train loss on 500 batch: 0.353075
Train loss on 550 batch: 0.377719
Train loss on 600 batch: 0.443496
Train loss on 650 batch: 0.394351
Train loss on 700 batch: 0.367348
Train loss on 750 batch: 0.482431
Train loss on 800 batch: 0.378340
Train loss on 850 batch: 0.357447
Train loss on 900 batch: 0.455434
Train loss on 950 batch: 0.405572
Train loss on 1000 batch: 0.503936
Train loss on 1050 batch: 0.380948
Train loss on 1100 batch: 0.433444
Train loss on 1150 batch: 0.392738
Train loss on 1200 batch: 0.487718
Train loss on 1250 batch: 0.450590
Train loss on 1300 batch: 0.374692
Train loss on 1350 batch: 0.370387
Train loss on 1400 batch: 0.380846
Train loss on 1450 batch: 0.425114
Train loss on 1500 batch: 0.398924
Train loss on 1550 batch: 0.415085
Train loss on 1600 batch: 0.436199
Train loss on 1650 batch: 0.413417
Train loss on 1700 batch: 0.447737
Train loss on 1750 batch: 0.322989
Train loss on 1800 batch: 0.368961
Train loss on 1850 batch: 0.355558
Train loss on 1900 batch: 0.338264
Train loss on 1950 batch: 0.428467
Train loss on 2000 batch: 0.402399
Train loss on 2050 batch: 0.447028
Train loss on 2100 batch: 0.415544
Train loss on 2150 batch: 0.479730
Train loss on 2200 batch: 0.414295
Train loss on 2250 batch: 0.451075
Train loss on 2300 batch: 0.454196
Train loss on 2350 batch: 0.430358
Train loss on 2400 batch: 0.485791
Train loss on 2450 batch: 0.447663
Train loss on 2500 batch: 0.335396
Train loss on 2550 batch: 0.380951
Train loss on 2600 batch: 0.412742
Train loss on 2650 batch: 0.401664
Train loss on 2700 batch: 0.454840
Train loss on 2750 batch: 0.482167
Train loss on 2800 batch: 0.434185
Train loss on 2850 batch: 0.586147
Train loss on 2900 batch: 0.463222
: Epoch: 6 | Training Loss: 0.423427 | Val. Loss: 0.562412 | Val. Kappa Score: nan | Estimated time: 746.62
Train loss on 50 batch: 0.443639
Train loss on 100 batch: 0.453208
Train loss on 150 batch: 0.431658
Train loss on 200 batch: 0.423660
Train loss on 250 batch: 0.348949
Train loss on 300 batch: 0.375519
Train loss on 350 batch: 0.439489
Train loss on 400 batch: 0.357811
Train loss on 450 batch: 0.385401
Train loss on 500 batch: 0.427297
Train loss on 550 batch: 0.411158
Train loss on 600 batch: 0.383272
Train loss on 650 batch: 0.440491
Train loss on 700 batch: 0.434004
Train loss on 750 batch: 0.424827
Train loss on 800 batch: 0.388767
Train loss on 850 batch: 0.452967
Train loss on 900 batch: 0.463703
Train loss on 950 batch: 0.419620
Train loss on 1000 batch: 0.430718
Train loss on 1050 batch: 0.504210
Train loss on 1100 batch: 0.395551
Train loss on 1150 batch: 0.341159
Train loss on 1200 batch: 0.402172
Train loss on 1250 batch: 0.396974
Train loss on 1300 batch: 0.451628
Train loss on 1350 batch: 0.437975
Train loss on 1400 batch: 0.429798
Train loss on 1450 batch: 0.465603
Train loss on 1500 batch: 0.356546
Train loss on 1550 batch: 0.458892
Train loss on 1600 batch: 0.426423
Train loss on 1650 batch: 0.552681
Train loss on 1700 batch: 0.372534
Train loss on 1750 batch: 0.359809
Train loss on 1800 batch: 0.392734
Train loss on 1850 batch: 0.398278
Train loss on 1900 batch: 0.349316
Train loss on 1950 batch: 0.461935
Train loss on 2000 batch: 0.378747
Train loss on 2050 batch: 0.409690
Train loss on 2100 batch: 0.381010
Train loss on 2150 batch: 0.450013
Train loss on 2200 batch: 0.385626
Train loss on 2250 batch: 0.400416
Train loss on 2300 batch: 0.384461
Train loss on 2350 batch: 0.430012
Train loss on 2400 batch: 0.418504
Train loss on 2450 batch: 0.426089
Train loss on 2500 batch: 0.401864
Train loss on 2550 batch: 0.477693
Train loss on 2600 batch: 0.385429
Train loss on 2650 batch: 0.363376
Train loss on 2700 batch: 0.440948
Train loss on 2750 batch: 0.475102
Train loss on 2800 batch: 0.494225
Train loss on 2850 batch: 0.446635
Train loss on 2900 batch: 0.401209
: Epoch: 7 | Training Loss: 0.418067 | Val. Loss: 0.578906 | Val. Kappa Score: nan | Estimated time: 743.51
Train loss on 50 batch: 0.435562
Train loss on 100 batch: 0.419498
Train loss on 150 batch: 0.347227
Train loss on 200 batch: 0.381667
Train loss on 250 batch: 0.410456
Train loss on 300 batch: 0.397706
Train loss on 350 batch: 0.335768
Train loss on 400 batch: 0.397798
Train loss on 450 batch: 0.326372
Train loss on 500 batch: 0.375442
Train loss on 550 batch: 0.327100
Train loss on 600 batch: 0.365758
Train loss on 650 batch: 0.448105
Train loss on 700 batch: 0.355257
Train loss on 750 batch: 0.385023
Train loss on 800 batch: 0.427495
Train loss on 850 batch: 0.322006
Train loss on 900 batch: 0.448613
Train loss on 950 batch: 0.318263
Train loss on 1000 batch: 0.349635
Train loss on 1050 batch: 0.328115
Train loss on 1100 batch: 0.437365
Train loss on 1150 batch: 0.336769
Train loss on 1200 batch: 0.414159
Train loss on 1250 batch: 0.371907
Train loss on 1300 batch: 0.417509
Train loss on 1350 batch: 0.359525
Train loss on 1400 batch: 0.397541
Train loss on 1450 batch: 0.484336
Train loss on 1500 batch: 0.404368
Train loss on 1550 batch: 0.344151
Train loss on 1600 batch: 0.418862
Train loss on 1650 batch: 0.266319
Train loss on 1700 batch: 0.365738
Train loss on 1750 batch: 0.363949
Train loss on 1800 batch: 0.380163
Train loss on 1850 batch: 0.339241
Train loss on 1900 batch: 0.367049
Train loss on 1950 batch: 0.264479
Train loss on 2000 batch: 0.432295
Train loss on 2050 batch: 0.396170
Train loss on 2100 batch: 0.316925
Train loss on 2150 batch: 0.369876
Train loss on 2200 batch: 0.347586
Train loss on 2250 batch: 0.327620
Train loss on 2300 batch: 0.371309
Train loss on 2350 batch: 0.337267
Train loss on 2400 batch: 0.346792
Train loss on 2450 batch: 0.365786
Train loss on 2500 batch: 0.418239
Train loss on 2550 batch: 0.373812
Train loss on 2600 batch: 0.329432
Train loss on 2650 batch: 0.318096
Train loss on 2700 batch: 0.314949
Train loss on 2750 batch: 0.348212
Train loss on 2800 batch: 0.379701
Train loss on 2850 batch: 0.472571
Train loss on 2900 batch: 0.357600
best-train-loss: 0.370695
best-valid-loss: 0.389818
best-kappa: nan
: Epoch: 8 | Training Loss: 0.370695 | Val. Loss: 0.389818 | Val. Kappa Score: nan | Estimated time: 741.35
Train loss on 50 batch: 0.393993
Train loss on 100 batch: 0.392427
Train loss on 150 batch: 0.388733
Train loss on 200 batch: 0.325736
Train loss on 250 batch: 0.381376
Train loss on 300 batch: 0.370616
Train loss on 350 batch: 0.448186
Train loss on 400 batch: 0.316360
Train loss on 450 batch: 0.331207
Train loss on 500 batch: 0.352124
Train loss on 550 batch: 0.440266
Train loss on 600 batch: 0.358529
Train loss on 650 batch: 0.322529
Train loss on 700 batch: 0.256253
Train loss on 750 batch: 0.382618
Train loss on 800 batch: 0.307837
Train loss on 850 batch: 0.372620
Train loss on 900 batch: 0.418785
Train loss on 950 batch: 0.374659
Train loss on 1000 batch: 0.336545
Train loss on 1050 batch: 0.350760
Train loss on 1100 batch: 0.332092
Train loss on 1150 batch: 0.460619
Train loss on 1200 batch: 0.379121
Train loss on 1250 batch: 0.306032
Train loss on 1300 batch: 0.316542
Train loss on 1350 batch: 0.318890
Train loss on 1400 batch: 0.313850
Train loss on 1450 batch: 0.352251
Train loss on 1500 batch: 0.343031
Train loss on 1550 batch: 0.335833
Train loss on 1600 batch: 0.287856
Train loss on 1650 batch: 0.281608
Train loss on 1700 batch: 0.277474
Train loss on 1750 batch: 0.289479
Train loss on 1800 batch: 0.427175
Train loss on 1850 batch: 0.379896
Train loss on 1900 batch: 0.264410
Train loss on 1950 batch: 0.355937
Train loss on 2000 batch: 0.359336
Train loss on 2050 batch: 0.364402
Train loss on 2100 batch: 0.350605
Train loss on 2150 batch: 0.393389
Train loss on 2200 batch: 0.403665
Train loss on 2250 batch: 0.308740
Train loss on 2300 batch: 0.356202
Train loss on 2350 batch: 0.340362
Train loss on 2400 batch: 0.352084
Train loss on 2450 batch: 0.444946
Train loss on 2500 batch: 0.337516
Train loss on 2550 batch: 0.378427
Train loss on 2600 batch: 0.373626
Train loss on 2650 batch: 0.352531
Train loss on 2700 batch: 0.325556
Train loss on 2750 batch: 0.348138
Train loss on 2800 batch: 0.366052
Train loss on 2850 batch: 0.361931
Train loss on 2900 batch: 0.347080
: Epoch: 9 | Training Loss: 0.354602 | Val. Loss: 0.411732 | Val. Kappa Score: nan | Estimated time: 741.11
Train loss on 50 batch: 0.399003
Train loss on 100 batch: 0.360552
Train loss on 150 batch: 0.333869
Train loss on 200 batch: 0.381510
Train loss on 250 batch: 0.367868
Train loss on 300 batch: 0.319569
Train loss on 350 batch: 0.343305
Train loss on 400 batch: 0.299888
Train loss on 450 batch: 0.418671
Train loss on 500 batch: 0.346332
Train loss on 550 batch: 0.341330
Train loss on 600 batch: 0.426957
Train loss on 650 batch: 0.419524
Train loss on 700 batch: 0.300235
Train loss on 750 batch: 0.330480
Train loss on 800 batch: 0.384034
Train loss on 850 batch: 0.321311
Train loss on 900 batch: 0.371851
Train loss on 950 batch: 0.361207
Train loss on 1000 batch: 0.366701
Train loss on 1050 batch: 0.419667
Train loss on 1100 batch: 0.386852
Train loss on 1150 batch: 0.319215
Train loss on 1200 batch: 0.382698
Train loss on 1250 batch: 0.340782
Train loss on 1300 batch: 0.312315
Train loss on 1350 batch: 0.378121
Train loss on 1400 batch: 0.315876
Train loss on 1450 batch: 0.364302
Train loss on 1500 batch: 0.323514
Train loss on 1550 batch: 0.363842
Train loss on 1600 batch: 0.316712
Train loss on 1650 batch: 0.388962
Train loss on 1700 batch: 0.328641
Train loss on 1750 batch: 0.285503
Train loss on 1800 batch: 0.388593
Train loss on 1850 batch: 0.340938
Train loss on 1900 batch: 0.337727
Train loss on 1950 batch: 0.321614
Train loss on 2000 batch: 0.279935
Train loss on 2050 batch: 0.340617
Train loss on 2100 batch: 0.381875
Train loss on 2150 batch: 0.266679
Train loss on 2200 batch: 0.400691
Train loss on 2250 batch: 0.326633
Train loss on 2300 batch: 0.313404
Train loss on 2350 batch: 0.306748
Train loss on 2400 batch: 0.318503
Train loss on 2450 batch: 0.350361
Train loss on 2500 batch: 0.311366
Train loss on 2550 batch: 0.359928
Train loss on 2600 batch: 0.414807
Train loss on 2650 batch: 0.347506
Train loss on 2700 batch: 0.398674
Train loss on 2750 batch: 0.383982
Train loss on 2800 batch: 0.347383
Train loss on 2850 batch: 0.317907
Train loss on 2900 batch: 0.413968
: Epoch: 10 | Training Loss: 0.350860 | Val. Loss: 0.793947 | Val. Kappa Score: nan | Estimated time: 745.42
Train loss on 50 batch: 0.365152
Train loss on 100 batch: 0.327285
Train loss on 150 batch: 0.363946
Train loss on 200 batch: 0.325088
Train loss on 250 batch: 0.369536
Train loss on 300 batch: 0.292913
Train loss on 350 batch: 0.326968
Train loss on 400 batch: 0.342272
Train loss on 450 batch: 0.440424
Train loss on 500 batch: 0.355318
Train loss on 550 batch: 0.358564
Train loss on 600 batch: 0.338976
Train loss on 650 batch: 0.319105
Train loss on 700 batch: 0.358860
Train loss on 750 batch: 0.397701
Train loss on 800 batch: 0.367999
Train loss on 850 batch: 0.363884
Train loss on 900 batch: 0.354490
Train loss on 950 batch: 0.258615
Train loss on 1000 batch: 0.330248
Train loss on 1050 batch: 0.364183
Train loss on 1100 batch: 0.349891
Train loss on 1150 batch: 0.395191
Train loss on 1200 batch: 0.353278
Train loss on 1250 batch: 0.348111
Train loss on 1300 batch: 0.349436
Train loss on 1350 batch: 0.260194
Train loss on 1400 batch: 0.357510
Train loss on 1450 batch: 0.334419
Train loss on 1500 batch: 0.297944
Train loss on 1550 batch: 0.336177
Train loss on 1600 batch: 0.308820
Train loss on 1650 batch: 0.352979
Train loss on 1700 batch: 0.325985
Train loss on 1750 batch: 0.310188
Train loss on 1800 batch: 0.298228
Train loss on 1850 batch: 0.369464
Train loss on 1900 batch: 0.353126
Train loss on 1950 batch: 0.430810
Train loss on 2000 batch: 0.311285
Train loss on 2050 batch: 0.385529
Train loss on 2100 batch: 0.374334
Train loss on 2150 batch: 0.303599
Train loss on 2200 batch: 0.369935
Train loss on 2250 batch: 0.339766
Train loss on 2300 batch: 0.322092
Train loss on 2350 batch: 0.349040
Train loss on 2400 batch: 0.375327
Train loss on 2450 batch: 0.323969
Train loss on 2500 batch: 0.365987
Train loss on 2550 batch: 0.396162
Train loss on 2600 batch: 0.397381
Train loss on 2650 batch: 0.348842
Train loss on 2700 batch: 0.345880
Train loss on 2750 batch: 0.323773
Train loss on 2800 batch: 0.343846
Train loss on 2850 batch: 0.329357
Train loss on 2900 batch: 0.321394
: Epoch: 11 | Training Loss: 0.345804 | Val. Loss: 0.487416 | Val. Kappa Score: nan | Estimated time: 744.54
Train loss on 50 batch: 0.337710
Train loss on 100 batch: 0.350613
Train loss on 150 batch: 0.329789
Train loss on 200 batch: 0.305286
Train loss on 250 batch: 0.358239
Train loss on 300 batch: 0.343556
Train loss on 350 batch: 0.295925
Train loss on 400 batch: 0.416577
Train loss on 450 batch: 0.329677
Train loss on 500 batch: 0.266038
Train loss on 550 batch: 0.313304
Train loss on 600 batch: 0.277621
Train loss on 650 batch: 0.307112
Train loss on 700 batch: 0.385676
Train loss on 750 batch: 0.332055
Train loss on 800 batch: 0.409653
Train loss on 850 batch: 0.334336
Train loss on 900 batch: 0.303796
Train loss on 950 batch: 0.374546
Train loss on 1000 batch: 0.309478
Train loss on 1050 batch: 0.321517
Train loss on 1100 batch: 0.263042
Train loss on 1150 batch: 0.311395
Train loss on 1200 batch: 0.335698
Train loss on 1250 batch: 0.326241
Train loss on 1300 batch: 0.286402
Train loss on 1350 batch: 0.285850
Train loss on 1400 batch: 0.321336
Train loss on 1450 batch: 0.318090
Train loss on 1500 batch: 0.238606
Train loss on 1550 batch: 0.300025
Train loss on 1600 batch: 0.311803
Train loss on 1650 batch: 0.276674
Train loss on 1700 batch: 0.309386
Train loss on 1750 batch: 0.361005
Train loss on 1800 batch: 0.402669
Train loss on 1850 batch: 0.309129
Train loss on 1900 batch: 0.292944
Train loss on 1950 batch: 0.239453
Train loss on 2000 batch: 0.340868
Train loss on 2050 batch: 0.315421
Train loss on 2100 batch: 0.304501
Train loss on 2150 batch: 0.356882
Train loss on 2200 batch: 0.354543
Train loss on 2250 batch: 0.299490
Train loss on 2300 batch: 0.326961
Train loss on 2350 batch: 0.321085
Train loss on 2400 batch: 0.303824
Train loss on 2450 batch: 0.261531
Train loss on 2500 batch: 0.362992
Train loss on 2550 batch: 0.327906
Train loss on 2600 batch: 0.302218
Train loss on 2650 batch: 0.298802
Train loss on 2700 batch: 0.250807
Train loss on 2750 batch: 0.270037
Train loss on 2800 batch: 0.300304
Train loss on 2850 batch: 0.304232
Train loss on 2900 batch: 0.371494
: Epoch: 12 | Training Loss: 0.317250 | Val. Loss: 0.472098 | Val. Kappa Score: nan | Estimated time: 740.57
Train loss on 50 batch: 0.326108
Train loss on 100 batch: 0.350072
Train loss on 150 batch: 0.302783
Train loss on 200 batch: 0.294163
Train loss on 250 batch: 0.315553
Train loss on 300 batch: 0.244062
Train loss on 350 batch: 0.247662
Train loss on 400 batch: 0.383789
Train loss on 450 batch: 0.330525
Train loss on 500 batch: 0.339841
Train loss on 550 batch: 0.323975
Train loss on 600 batch: 0.346718
Train loss on 650 batch: 0.264503
Train loss on 700 batch: 0.270609
Train loss on 750 batch: 0.270779
Train loss on 800 batch: 0.299469
Train loss on 850 batch: 0.273997
Train loss on 900 batch: 0.399721
Train loss on 950 batch: 0.350673
Train loss on 1000 batch: 0.254799
Train loss on 1050 batch: 0.269392
Train loss on 1100 batch: 0.296158
Train loss on 1150 batch: 0.296577
Train loss on 1200 batch: 0.295592
Train loss on 1250 batch: 0.370959
Train loss on 1300 batch: 0.318635
Train loss on 1350 batch: 0.332491
Train loss on 1400 batch: 0.302160
Train loss on 1450 batch: 0.369406
Train loss on 1500 batch: 0.353706
Train loss on 1550 batch: 0.328677
Train loss on 1600 batch: 0.299699
Train loss on 1650 batch: 0.318531
Train loss on 1700 batch: 0.266146
Train loss on 1750 batch: 0.365479
Train loss on 1800 batch: 0.269355
Train loss on 1850 batch: 0.280959
Train loss on 1900 batch: 0.288183
Train loss on 1950 batch: 0.346486
Train loss on 2000 batch: 0.301961
Train loss on 2050 batch: 0.232648
Train loss on 2100 batch: 0.378261
Train loss on 2150 batch: 0.300857
Train loss on 2200 batch: 0.296170
Train loss on 2250 batch: 0.335203
Train loss on 2300 batch: 0.321297
Train loss on 2350 batch: 0.338349
Train loss on 2400 batch: 0.258121
Train loss on 2450 batch: 0.294359
Train loss on 2500 batch: 0.333061
Train loss on 2550 batch: 0.317935
Train loss on 2600 batch: 0.274706
Train loss on 2650 batch: 0.294642
Train loss on 2700 batch: 0.378407
Train loss on 2750 batch: 0.307903
Train loss on 2800 batch: 0.335564
Train loss on 2850 batch: 0.316001
Train loss on 2900 batch: 0.321365
: Epoch: 13 | Training Loss: 0.311723 | Val. Loss: 0.698890 | Val. Kappa Score: nan | Estimated time: 741.51
Train loss on 50 batch: 0.291352
Train loss on 100 batch: 0.314606
Train loss on 150 batch: 0.321892
Train loss on 200 batch: 0.320641
Train loss on 250 batch: 0.296344
Train loss on 300 batch: 0.336165
Train loss on 350 batch: 0.283844
Train loss on 400 batch: 0.321268
Train loss on 450 batch: 0.324694
Train loss on 500 batch: 0.342544
Train loss on 550 batch: 0.297507
Train loss on 600 batch: 0.435533
Train loss on 650 batch: 0.308790
Train loss on 700 batch: 0.328280
Train loss on 750 batch: 0.339807
Train loss on 800 batch: 0.316956
Train loss on 850 batch: 0.306949
Train loss on 900 batch: 0.226883
Train loss on 950 batch: 0.309407
Train loss on 1000 batch: 0.334774
Train loss on 1050 batch: 0.255836
Train loss on 1100 batch: 0.282482
Train loss on 1150 batch: 0.243473
Train loss on 1200 batch: 0.249738
Train loss on 1250 batch: 0.293562
Train loss on 1300 batch: 0.334239
Train loss on 1350 batch: 0.321095
Train loss on 1400 batch: 0.308731
Train loss on 1450 batch: 0.339544
Train loss on 1500 batch: 0.327283
Train loss on 1550 batch: 0.262866
Train loss on 1600 batch: 0.256551
Train loss on 1650 batch: 0.276822
Train loss on 1700 batch: 0.282953
Train loss on 1750 batch: 0.203404
Train loss on 1800 batch: 0.271324
Train loss on 1850 batch: 0.271346
Train loss on 1900 batch: 0.308455
Train loss on 1950 batch: 0.283881
Train loss on 2000 batch: 0.302314
Train loss on 2050 batch: 0.342815
Train loss on 2100 batch: 0.314408
Train loss on 2150 batch: 0.278031
Train loss on 2200 batch: 0.257137
Train loss on 2250 batch: 0.293268
Train loss on 2300 batch: 0.319161
Train loss on 2350 batch: 0.333526
Train loss on 2400 batch: 0.342039
Train loss on 2450 batch: 0.371613
Train loss on 2500 batch: 0.319262
Train loss on 2550 batch: 0.326371
Train loss on 2600 batch: 0.361944
Train loss on 2650 batch: 0.279857
Train loss on 2700 batch: 0.286448
Train loss on 2750 batch: 0.288883
Train loss on 2800 batch: 0.307466
Train loss on 2850 batch: 0.291389
Train loss on 2900 batch: 0.295541
best-train-loss: 0.305022
best-valid-loss: 0.360134
best-kappa: nan
: Epoch: 14 | Training Loss: 0.305022 | Val. Loss: 0.360134 | Val. Kappa Score: nan | Estimated time: 740.90
Train loss on 50 batch: 0.230001
Train loss on 100 batch: 0.262153
Train loss on 150 batch: 0.262791
Train loss on 200 batch: 0.357487
Train loss on 250 batch: 0.247364
Train loss on 300 batch: 0.340534
Train loss on 350 batch: 0.295737
Train loss on 400 batch: 0.236599
Train loss on 450 batch: 0.249963
Train loss on 500 batch: 0.313807
Train loss on 550 batch: 0.269957
Train loss on 600 batch: 0.322371
Train loss on 650 batch: 0.287314
Train loss on 700 batch: 0.230493
Train loss on 750 batch: 0.263989
Train loss on 800 batch: 0.306747
Train loss on 850 batch: 0.258575
Train loss on 900 batch: 0.305206
Train loss on 950 batch: 0.313764
Train loss on 1000 batch: 0.324148
Train loss on 1050 batch: 0.322911
Train loss on 1100 batch: 0.340067
Train loss on 1150 batch: 0.260905
Train loss on 1200 batch: 0.296695
Train loss on 1250 batch: 0.275059
Train loss on 1300 batch: 0.285787
Train loss on 1350 batch: 0.290759
Train loss on 1400 batch: 0.313791
Train loss on 1450 batch: 0.264373
Train loss on 1500 batch: 0.318023
Train loss on 1550 batch: 0.295556
Train loss on 1600 batch: 0.300868
Train loss on 1650 batch: 0.291726
Train loss on 1700 batch: 0.369760
Train loss on 1750 batch: 0.286269
Train loss on 1800 batch: 0.311481
Train loss on 1850 batch: 0.279498
Train loss on 1900 batch: 0.292079
Train loss on 1950 batch: 0.345962
Train loss on 2000 batch: 0.292052
Train loss on 2050 batch: 0.303255
Train loss on 2100 batch: 0.215214
Train loss on 2150 batch: 0.267366
Train loss on 2200 batch: 0.284686
Train loss on 2250 batch: 0.294053
Train loss on 2300 batch: 0.334250
Train loss on 2350 batch: 0.329803
Train loss on 2400 batch: 0.318466
Train loss on 2450 batch: 0.297016
Train loss on 2500 batch: 0.318730
Train loss on 2550 batch: 0.302793
Train loss on 2600 batch: 0.310461
Train loss on 2650 batch: 0.291779
Train loss on 2700 batch: 0.405545
Train loss on 2750 batch: 0.306318
Train loss on 2800 batch: 0.346662
Train loss on 2850 batch: 0.324280
Train loss on 2900 batch: 0.307431
: Epoch: 15 | Training Loss: 0.297751 | Val. Loss: 0.389995 | Val. Kappa Score: nan | Estimated time: 742.07
Train loss on 50 batch: 0.295088
Train loss on 100 batch: 0.346680
Train loss on 150 batch: 0.326415
Train loss on 200 batch: 0.385741
Train loss on 250 batch: 0.367405
Train loss on 300 batch: 0.342089
Train loss on 350 batch: 0.298554
Train loss on 400 batch: 0.286765
Train loss on 450 batch: 0.393091
Train loss on 500 batch: 0.252081
Train loss on 550 batch: 0.341653
Train loss on 600 batch: 0.308557
Train loss on 650 batch: 0.351865
Train loss on 700 batch: 0.325506
Train loss on 750 batch: 0.268142
Train loss on 800 batch: 0.262519
Train loss on 850 batch: 0.334593
Train loss on 900 batch: 0.275311
Train loss on 950 batch: 0.276670
Train loss on 1000 batch: 0.286591
Train loss on 1050 batch: 0.290476
Train loss on 1100 batch: 0.299446
Train loss on 1150 batch: 0.323847
Train loss on 1200 batch: 0.292853
Train loss on 1250 batch: 0.314215
Train loss on 1300 batch: 0.271421
Train loss on 1350 batch: 0.364218
Train loss on 1400 batch: 0.339971
Train loss on 1450 batch: 0.261695
Train loss on 1500 batch: 0.340089
Train loss on 1550 batch: 0.278965
Train loss on 1600 batch: 0.248723
Train loss on 1650 batch: 0.299219
Train loss on 1700 batch: 0.321982
Train loss on 1750 batch: 0.245260
Train loss on 1800 batch: 0.314057
Train loss on 1850 batch: 0.294144
Train loss on 1900 batch: 0.287932
Train loss on 1950 batch: 0.279822
Train loss on 2000 batch: 0.242240
Train loss on 2050 batch: 0.314442
Train loss on 2100 batch: 0.286084
Train loss on 2150 batch: 0.303971
Train loss on 2200 batch: 0.307906
Train loss on 2250 batch: 0.311068
Train loss on 2300 batch: 0.270090
Train loss on 2350 batch: 0.271844
Train loss on 2400 batch: 0.279130
Train loss on 2450 batch: 0.286764
Train loss on 2500 batch: 0.304754
Train loss on 2550 batch: 0.309094
Train loss on 2600 batch: 0.296572
Train loss on 2650 batch: 0.242577
Train loss on 2700 batch: 0.380771
Train loss on 2750 batch: 0.221495
Train loss on 2800 batch: 0.297487
Train loss on 2850 batch: 0.260341
Train loss on 2900 batch: 0.298833
: Epoch: 16 | Training Loss: 0.300999 | Val. Loss: 0.582894 | Val. Kappa Score: nan | Estimated time: 742.15
Train loss on 50 batch: 0.307953
Train loss on 100 batch: 0.347834
Train loss on 150 batch: 0.271140
Train loss on 200 batch: 0.313405
Train loss on 250 batch: 0.280467
Train loss on 300 batch: 0.301296
Train loss on 350 batch: 0.342676
Train loss on 400 batch: 0.251399
Train loss on 450 batch: 0.401561
Train loss on 500 batch: 0.303810
Train loss on 550 batch: 0.281423
Train loss on 600 batch: 0.301558
Train loss on 650 batch: 0.318353
Train loss on 700 batch: 0.234349
Train loss on 750 batch: 0.258174
Train loss on 800 batch: 0.269262
Train loss on 850 batch: 0.339504
Train loss on 900 batch: 0.344497
Train loss on 950 batch: 0.255737
Train loss on 1000 batch: 0.271851
Train loss on 1050 batch: 0.379129
Train loss on 1100 batch: 0.245263
Train loss on 1150 batch: 0.282725
Train loss on 1200 batch: 0.274104
Train loss on 1250 batch: 0.357182
Train loss on 1300 batch: 0.333298
Train loss on 1350 batch: 0.332093
Train loss on 1400 batch: 0.280548
Train loss on 1450 batch: 0.305513
Train loss on 1500 batch: 0.243282
Train loss on 1550 batch: 0.263146
Train loss on 1600 batch: 0.357380
Train loss on 1650 batch: 0.272184
Train loss on 1700 batch: 0.275642
Train loss on 1750 batch: 0.273971
Train loss on 1800 batch: 0.343086
Train loss on 1850 batch: 0.313267
Train loss on 1900 batch: 0.321394
Train loss on 1950 batch: 0.258749
Train loss on 2000 batch: 0.331918
Train loss on 2050 batch: 0.382092
Train loss on 2100 batch: 0.294033
Train loss on 2150 batch: 0.234944
Train loss on 2200 batch: 0.354079
Train loss on 2250 batch: 0.324623
Train loss on 2300 batch: 0.274172
Train loss on 2350 batch: 0.321161
Train loss on 2400 batch: 0.324317
Train loss on 2450 batch: 0.325459
Train loss on 2500 batch: 0.292136
Train loss on 2550 batch: 0.192843
Train loss on 2600 batch: 0.255162
Train loss on 2650 batch: 0.237163
Train loss on 2700 batch: 0.266776
Train loss on 2750 batch: 0.299394
Train loss on 2800 batch: 0.271779
Train loss on 2850 batch: 0.261353
Train loss on 2900 batch: 0.273293
: Epoch: 17 | Training Loss: 0.297957 | Val. Loss: 0.370506 | Val. Kappa Score: nan | Estimated time: 740.42
Train loss on 50 batch: 0.283576
Train loss on 100 batch: 0.282714
Train loss on 150 batch: 0.301687
Train loss on 200 batch: 0.258232
Train loss on 250 batch: 0.318280
Train loss on 300 batch: 0.197041
Train loss on 350 batch: 0.213799
Train loss on 400 batch: 0.276568
Train loss on 450 batch: 0.270670
Train loss on 500 batch: 0.248216
Train loss on 550 batch: 0.274996
Train loss on 600 batch: 0.304520
Train loss on 650 batch: 0.258943
Train loss on 700 batch: 0.237316
Train loss on 750 batch: 0.253142
Train loss on 800 batch: 0.302390
Train loss on 850 batch: 0.282235
Train loss on 900 batch: 0.239962
Train loss on 950 batch: 0.305373
Train loss on 1000 batch: 0.280465
Train loss on 1050 batch: 0.274255
Train loss on 1100 batch: 0.334400
Train loss on 1150 batch: 0.320172
Train loss on 1200 batch: 0.268692
Train loss on 1250 batch: 0.359610
Train loss on 1300 batch: 0.284201
Train loss on 1350 batch: 0.325683
Train loss on 1400 batch: 0.263621
Train loss on 1450 batch: 0.240861
Train loss on 1500 batch: 0.240536
Train loss on 1550 batch: 0.244683
Train loss on 1600 batch: 0.256993
Train loss on 1650 batch: 0.288372
Train loss on 1700 batch: 0.312987
Train loss on 1750 batch: 0.252312
Train loss on 1800 batch: 0.313218
Train loss on 1850 batch: 0.260722
Train loss on 1900 batch: 0.259399
Train loss on 1950 batch: 0.303999
Train loss on 2000 batch: 0.313612
Train loss on 2050 batch: 0.380396
Train loss on 2100 batch: 0.314572
Train loss on 2150 batch: 0.288480
Train loss on 2200 batch: 0.267256
Train loss on 2250 batch: 0.305077
Train loss on 2300 batch: 0.274805
Train loss on 2350 batch: 0.253901
Train loss on 2400 batch: 0.284842
Train loss on 2450 batch: 0.265844
Train loss on 2500 batch: 0.247713
Train loss on 2550 batch: 0.307937
Train loss on 2600 batch: 0.324526
Train loss on 2650 batch: 0.328092
Train loss on 2700 batch: 0.277742
Train loss on 2750 batch: 0.309429
Train loss on 2800 batch: 0.228621
Train loss on 2850 batch: 0.256525
Train loss on 2900 batch: 0.304930
best-train-loss: 0.283221
best-valid-loss: 0.340251
best-kappa: nan
: Epoch: 18 | Training Loss: 0.283221 | Val. Loss: 0.340251 | Val. Kappa Score: nan | Estimated time: 740.07
Train loss on 50 batch: 0.249333
Train loss on 100 batch: 0.241427
Train loss on 150 batch: 0.256837
Train loss on 200 batch: 0.329708
Train loss on 250 batch: 0.216288
Train loss on 300 batch: 0.327117
Train loss on 350 batch: 0.292856
Train loss on 400 batch: 0.304476
Train loss on 450 batch: 0.243473
Train loss on 500 batch: 0.316611
Train loss on 550 batch: 0.339062
Train loss on 600 batch: 0.284150
Train loss on 650 batch: 0.289701
Train loss on 700 batch: 0.256497
Train loss on 750 batch: 0.221803
Train loss on 800 batch: 0.267814
Train loss on 850 batch: 0.308664
Train loss on 900 batch: 0.304704
Train loss on 950 batch: 0.233607
Train loss on 1000 batch: 0.311046
Train loss on 1050 batch: 0.256328
Train loss on 1100 batch: 0.290012
Train loss on 1150 batch: 0.281145
Train loss on 1200 batch: 0.244230
Train loss on 1250 batch: 0.277287
Train loss on 1300 batch: 0.268857
Train loss on 1350 batch: 0.251552
Train loss on 1400 batch: 0.311838
Train loss on 1450 batch: 0.311714
Train loss on 1500 batch: 0.229129
Train loss on 1550 batch: 0.294105
Train loss on 1600 batch: 0.309353
Train loss on 1650 batch: 0.282106
Train loss on 1700 batch: 0.268185
Train loss on 1750 batch: 0.279764
Train loss on 1800 batch: 0.264691
Train loss on 1850 batch: 0.298394
Train loss on 1900 batch: 0.292025
Train loss on 1950 batch: 0.310321
Train loss on 2000 batch: 0.271716
Train loss on 2050 batch: 0.290243
Train loss on 2100 batch: 0.312090
Train loss on 2150 batch: 0.275666
Train loss on 2200 batch: 0.290100
Train loss on 2250 batch: 0.223521
Train loss on 2300 batch: 0.229213
Train loss on 2350 batch: 0.316865
Train loss on 2400 batch: 0.324999
Train loss on 2450 batch: 0.274687
Train loss on 2500 batch: 0.206909
Train loss on 2550 batch: 0.260213
Train loss on 2600 batch: 0.287087
Train loss on 2650 batch: 0.267755
Train loss on 2700 batch: 0.240934
Train loss on 2750 batch: 0.259159
Train loss on 2800 batch: 0.231180
Train loss on 2850 batch: 0.297337
Train loss on 2900 batch: 0.259980
: Epoch: 19 | Training Loss: 0.275223 | Val. Loss: 0.452602 | Val. Kappa Score: nan | Estimated time: 742.06
Train loss on 50 batch: 0.306119
Train loss on 100 batch: 0.255069
Train loss on 150 batch: 0.265439
Train loss on 200 batch: 0.254513
Train loss on 250 batch: 0.252829
Train loss on 300 batch: 0.280712
Train loss on 350 batch: 0.269298
Train loss on 400 batch: 0.253769
Train loss on 450 batch: 0.236034
Train loss on 500 batch: 0.247473
Train loss on 550 batch: 0.338222
Train loss on 600 batch: 0.270808
Train loss on 650 batch: 0.242909
Train loss on 700 batch: 0.231551
Train loss on 750 batch: 0.283805
Train loss on 800 batch: 0.219948
Train loss on 850 batch: 0.235364
Train loss on 900 batch: 0.265121
Train loss on 950 batch: 0.392583
Train loss on 1000 batch: 0.294049
Train loss on 1050 batch: 0.258694
Train loss on 1100 batch: 0.258994
Train loss on 1150 batch: 0.295303
Train loss on 1200 batch: 0.256637
Train loss on 1250 batch: 0.269814
Train loss on 1300 batch: 0.267350
Train loss on 1350 batch: 0.232705
Train loss on 1400 batch: 0.332274
Train loss on 1450 batch: 0.271984
Train loss on 1500 batch: 0.232206
Train loss on 1550 batch: 0.346341
Train loss on 1600 batch: 0.213769
Train loss on 1650 batch: 0.243572
Train loss on 1700 batch: 0.270385
Train loss on 1750 batch: 0.323689
Train loss on 1800 batch: 0.237693
Train loss on 1850 batch: 0.332493
Train loss on 1900 batch: 0.295309
Train loss on 1950 batch: 0.269508
Train loss on 2000 batch: 0.251205
Train loss on 2050 batch: 0.273229
Train loss on 2100 batch: 0.304384
Train loss on 2150 batch: 0.284925
Train loss on 2200 batch: 0.216750
Train loss on 2250 batch: 0.294807
Train loss on 2300 batch: 0.233539
Train loss on 2350 batch: 0.240226
Train loss on 2400 batch: 0.300270
Train loss on 2450 batch: 0.235171
Train loss on 2500 batch: 0.261105
Train loss on 2550 batch: 0.266246
Train loss on 2600 batch: 0.242901
Train loss on 2650 batch: 0.296260
Train loss on 2700 batch: 0.297155
Train loss on 2750 batch: 0.348651
Train loss on 2800 batch: 0.302321
Train loss on 2850 batch: 0.271094
Train loss on 2900 batch: 0.261438
: Epoch: 20 | Training Loss: 0.272164 | Val. Loss: 0.385304 | Val. Kappa Score: nan | Estimated time: 741.87
Train loss on 50 batch: 0.274000
Train loss on 100 batch: 0.317617
Train loss on 150 batch: 0.278087
Train loss on 200 batch: 0.287790
Train loss on 250 batch: 0.242811
Train loss on 300 batch: 0.280025
Train loss on 350 batch: 0.284828
Train loss on 400 batch: 0.238704
Train loss on 450 batch: 0.319118
Train loss on 500 batch: 0.259769
Train loss on 550 batch: 0.223565
Train loss on 600 batch: 0.291490
Train loss on 650 batch: 0.258957
Train loss on 700 batch: 0.274857
Train loss on 750 batch: 0.248495
Train loss on 800 batch: 0.278047
Train loss on 850 batch: 0.279962
Train loss on 900 batch: 0.184704
Train loss on 950 batch: 0.306421
Train loss on 1000 batch: 0.250592
Train loss on 1050 batch: 0.308154
Train loss on 1100 batch: 0.264455
Train loss on 1150 batch: 0.309030
Train loss on 1200 batch: 0.313558
Train loss on 1250 batch: 0.324720
Train loss on 1300 batch: 0.239130
Train loss on 1350 batch: 0.232574
Train loss on 1400 batch: 0.264314
Train loss on 1450 batch: 0.297454
Train loss on 1500 batch: 0.218105
Train loss on 1550 batch: 0.209033
Train loss on 1600 batch: 0.312009
Train loss on 1650 batch: 0.246979
Train loss on 1700 batch: 0.262531
Train loss on 1750 batch: 0.201194
Train loss on 1800 batch: 0.301811
Train loss on 1850 batch: 0.277516
Train loss on 1900 batch: 0.254682
Train loss on 1950 batch: 0.292954
Train loss on 2000 batch: 0.300920
Train loss on 2050 batch: 0.245018
Train loss on 2100 batch: 0.281736
Train loss on 2150 batch: 0.209826
Train loss on 2200 batch: 0.279205
Train loss on 2250 batch: 0.253788
Train loss on 2300 batch: 0.283993
Train loss on 2350 batch: 0.315442
Train loss on 2400 batch: 0.263623
Train loss on 2450 batch: 0.268863
Train loss on 2500 batch: 0.269011
Train loss on 2550 batch: 0.282812
Train loss on 2600 batch: 0.254136
Train loss on 2650 batch: 0.284458
Train loss on 2700 batch: 0.264486
Train loss on 2750 batch: 0.320841
Train loss on 2800 batch: 0.258428
Train loss on 2850 batch: 0.271495
Train loss on 2900 batch: 0.292682
: Epoch: 21 | Training Loss: 0.270388 | Val. Loss: 0.480641 | Val. Kappa Score: nan | Estimated time: 743.08
Train loss on 50 batch: 0.254815
Train loss on 100 batch: 0.220243
Train loss on 150 batch: 0.319999
Train loss on 200 batch: 0.273029
Train loss on 250 batch: 0.256061
Train loss on 300 batch: 0.243621
Train loss on 350 batch: 0.278188
Train loss on 400 batch: 0.288066
Train loss on 450 batch: 0.189729
Train loss on 500 batch: 0.212929
Train loss on 550 batch: 0.237777
Train loss on 600 batch: 0.270573
Train loss on 650 batch: 0.263612
Train loss on 700 batch: 0.226815
Train loss on 750 batch: 0.249797
Train loss on 800 batch: 0.238154
Train loss on 850 batch: 0.278496
Train loss on 900 batch: 0.326097
Train loss on 950 batch: 0.243230
Train loss on 1000 batch: 0.248785
Train loss on 1050 batch: 0.284624
Train loss on 1100 batch: 0.265139
Train loss on 1150 batch: 0.266807
Train loss on 1200 batch: 0.285086
Train loss on 1250 batch: 0.297848
Train loss on 1300 batch: 0.261511
Train loss on 1350 batch: 0.234928
Train loss on 1400 batch: 0.248433
Train loss on 1450 batch: 0.269281
Train loss on 1500 batch: 0.255956
Train loss on 1550 batch: 0.356420
Train loss on 1600 batch: 0.272589
Train loss on 1650 batch: 0.261592
Train loss on 1700 batch: 0.204689
Train loss on 1750 batch: 0.315217
Train loss on 1800 batch: 0.288369
Train loss on 1850 batch: 0.233421
Train loss on 1900 batch: 0.282224
Train loss on 1950 batch: 0.271651
Train loss on 2000 batch: 0.224803
Train loss on 2050 batch: 0.220924
Train loss on 2100 batch: 0.253003
Train loss on 2150 batch: 0.223105
Train loss on 2200 batch: 0.263279
Train loss on 2250 batch: 0.232647
Train loss on 2300 batch: 0.255804
Train loss on 2350 batch: 0.239719
Train loss on 2400 batch: 0.331482
Train loss on 2450 batch: 0.246928
Train loss on 2500 batch: 0.234625
Train loss on 2550 batch: 0.281061
Train loss on 2600 batch: 0.280382
Train loss on 2650 batch: 0.278640
Train loss on 2700 batch: 0.321962
Train loss on 2750 batch: 0.297356
Train loss on 2800 batch: 0.269336
Train loss on 2850 batch: 0.218892
Train loss on 2900 batch: 0.273826
: Epoch: 22 | Training Loss: 0.262331 | Val. Loss: 0.382786 | Val. Kappa Score: nan | Estimated time: 742.79
Train loss on 50 batch: 0.267155
Train loss on 100 batch: 0.242319
Train loss on 150 batch: 0.239665
Train loss on 200 batch: 0.258167
Train loss on 250 batch: 0.297673
Train loss on 300 batch: 0.240965
Train loss on 350 batch: 0.232054
Train loss on 400 batch: 0.248345
Train loss on 450 batch: 0.247959
Train loss on 500 batch: 0.334614
Train loss on 550 batch: 0.247188
Train loss on 600 batch: 0.229745
Train loss on 650 batch: 0.237120
Train loss on 700 batch: 0.239150
Train loss on 750 batch: 0.294250
Train loss on 800 batch: 0.186558
Train loss on 850 batch: 0.252129
Train loss on 900 batch: 0.237654
Train loss on 950 batch: 0.315373
Train loss on 1000 batch: 0.228570
Train loss on 1050 batch: 0.337085
Train loss on 1100 batch: 0.268484
Train loss on 1150 batch: 0.264894
Train loss on 1200 batch: 0.257067
Train loss on 1250 batch: 0.266200
Train loss on 1300 batch: 0.242305
Train loss on 1350 batch: 0.234119
Train loss on 1400 batch: 0.241632
Train loss on 1450 batch: 0.199766
Train loss on 1500 batch: 0.239432
Train loss on 1550 batch: 0.280216
Train loss on 1600 batch: 0.259272
Train loss on 1650 batch: 0.330905
Train loss on 1700 batch: 0.231979
Train loss on 1750 batch: 0.311619
Train loss on 1800 batch: 0.269060
Train loss on 1850 batch: 0.264328
Train loss on 1900 batch: 0.256833
Train loss on 1950 batch: 0.268901
Train loss on 2000 batch: 0.245633
Train loss on 2050 batch: 0.315201
Train loss on 2100 batch: 0.234034
Train loss on 2150 batch: 0.257850
Train loss on 2200 batch: 0.289230
Train loss on 2250 batch: 0.239553
Train loss on 2300 batch: 0.282498
Train loss on 2350 batch: 0.221230
Train loss on 2400 batch: 0.288050
Train loss on 2450 batch: 0.284674
Train loss on 2500 batch: 0.209722
Train loss on 2550 batch: 0.264404
Train loss on 2600 batch: 0.284291
Train loss on 2650 batch: 0.261144
Train loss on 2700 batch: 0.260035
Train loss on 2750 batch: 0.207118
Train loss on 2800 batch: 0.272225
Train loss on 2850 batch: 0.329209
Train loss on 2900 batch: 0.258535
: Epoch: 23 | Training Loss: 0.261222 | Val. Loss: 0.405281 | Val. Kappa Score: nan | Estimated time: 742.48
Train loss on 50 batch: 0.289016
Train loss on 100 batch: 0.253848
Train loss on 150 batch: 0.223245
Train loss on 200 batch: 0.231010
Train loss on 250 batch: 0.282521
Train loss on 300 batch: 0.270541
Train loss on 350 batch: 0.233516
Train loss on 400 batch: 0.250305
Train loss on 450 batch: 0.276303
Train loss on 500 batch: 0.250919
Train loss on 550 batch: 0.236685
Train loss on 600 batch: 0.304700
Train loss on 650 batch: 0.257072
Train loss on 700 batch: 0.284293
Train loss on 750 batch: 0.271181
Train loss on 800 batch: 0.229429
Train loss on 850 batch: 0.244196
Train loss on 900 batch: 0.244848
Train loss on 950 batch: 0.214508
Train loss on 1000 batch: 0.294467
Train loss on 1050 batch: 0.265209
Train loss on 1100 batch: 0.314220
Train loss on 1150 batch: 0.243077
Train loss on 1200 batch: 0.229364
Train loss on 1250 batch: 0.269302
Train loss on 1300 batch: 0.243368
Train loss on 1350 batch: 0.264043
Train loss on 1400 batch: 0.250324
Train loss on 1450 batch: 0.287779
Train loss on 1500 batch: 0.254217
Train loss on 1550 batch: 0.273891
Train loss on 1600 batch: 0.222963
Train loss on 1650 batch: 0.266215
Train loss on 1700 batch: 0.290861
Train loss on 1750 batch: 0.290367
Train loss on 1800 batch: 0.222449
Train loss on 1850 batch: 0.250171
Train loss on 1900 batch: 0.223903
Train loss on 1950 batch: 0.290346
Train loss on 2000 batch: 0.238995
Train loss on 2050 batch: 0.277716
Train loss on 2100 batch: 0.241252
Train loss on 2150 batch: 0.227414
Train loss on 2200 batch: 0.267923
Train loss on 2250 batch: 0.202220
Train loss on 2300 batch: 0.301596
Train loss on 2350 batch: 0.274103
Train loss on 2400 batch: 0.281552
Train loss on 2450 batch: 0.316967
Train loss on 2500 batch: 0.255277
Train loss on 2550 batch: 0.210366
Train loss on 2600 batch: 0.253447
Train loss on 2650 batch: 0.243842
Train loss on 2700 batch: 0.309530
Train loss on 2750 batch: 0.217302
Train loss on 2800 batch: 0.220746
Train loss on 2850 batch: 0.281091
Train loss on 2900 batch: 0.284803
: Epoch: 24 | Training Loss: 0.258176 | Val. Loss: 0.532228 | Val. Kappa Score: nan | Estimated time: 743.34
Train loss on 50 batch: 0.229335
Train loss on 100 batch: 0.243893
Train loss on 150 batch: 0.220346
Train loss on 200 batch: 0.239678
Train loss on 250 batch: 0.194860
Train loss on 300 batch: 0.231115
Train loss on 350 batch: 0.264818
Train loss on 400 batch: 0.284755
Train loss on 450 batch: 0.307925
Train loss on 500 batch: 0.218126
Train loss on 550 batch: 0.258447
Train loss on 600 batch: 0.227908
Train loss on 650 batch: 0.301680
Train loss on 700 batch: 0.217818
Train loss on 750 batch: 0.266542
Train loss on 800 batch: 0.288100
Train loss on 850 batch: 0.311316
Train loss on 900 batch: 0.238864
Train loss on 950 batch: 0.234369
Train loss on 1000 batch: 0.253942
Train loss on 1050 batch: 0.242373
Train loss on 1100 batch: 0.220280
Train loss on 1150 batch: 0.235173
Train loss on 1200 batch: 0.235733
Train loss on 1250 batch: 0.252465
Train loss on 1300 batch: 0.195073
Train loss on 1350 batch: 0.237222
Train loss on 1400 batch: 0.290468
Train loss on 1450 batch: 0.234372
Train loss on 1500 batch: 0.285214
Train loss on 1550 batch: 0.285267
Train loss on 1600 batch: 0.210235
Train loss on 1650 batch: 0.293743
Train loss on 1700 batch: 0.243395
Train loss on 1750 batch: 0.241538
Train loss on 1800 batch: 0.222732
Train loss on 1850 batch: 0.219937
Train loss on 1900 batch: 0.272152
Train loss on 1950 batch: 0.223160
Train loss on 2000 batch: 0.238537
Train loss on 2050 batch: 0.258034
Train loss on 2100 batch: 0.316427
Train loss on 2150 batch: 0.307701
Train loss on 2200 batch: 0.242472
Train loss on 2250 batch: 0.295217
Train loss on 2300 batch: 0.275265
Train loss on 2350 batch: 0.268324
Train loss on 2400 batch: 0.233797
Train loss on 2450 batch: 0.203059
Train loss on 2500 batch: 0.287623
Train loss on 2550 batch: 0.206233
Train loss on 2600 batch: 0.210145
Train loss on 2650 batch: 0.260794
Train loss on 2700 batch: 0.217121
Train loss on 2750 batch: 0.280671
Train loss on 2800 batch: 0.270199
Train loss on 2850 batch: 0.351320
Train loss on 2900 batch: 0.239535
: Epoch: 25 | Training Loss: 0.252549 | Val. Loss: 0.434027 | Val. Kappa Score: nan | Estimated time: 744.58
Train loss on 50 batch: 0.216073
Train loss on 100 batch: 0.225340
Train loss on 150 batch: 0.266779
Train loss on 200 batch: 0.309596
Train loss on 250 batch: 0.250389
Train loss on 300 batch: 0.303502
Train loss on 350 batch: 0.275940
Train loss on 400 batch: 0.244194
Train loss on 450 batch: 0.276533
Train loss on 500 batch: 0.270312
Train loss on 550 batch: 0.249305
Train loss on 600 batch: 0.217682
Train loss on 650 batch: 0.217535
Train loss on 700 batch: 0.293490
Train loss on 750 batch: 0.269008
Train loss on 800 batch: 0.258838
Train loss on 850 batch: 0.244434
Train loss on 900 batch: 0.275503
Train loss on 950 batch: 0.196831
Train loss on 1000 batch: 0.230875
Train loss on 1050 batch: 0.252462
Train loss on 1100 batch: 0.262884
Train loss on 1150 batch: 0.338061
Train loss on 1200 batch: 0.239324
Train loss on 1250 batch: 0.240713
Train loss on 1300 batch: 0.156056
Train loss on 1350 batch: 0.227998
Train loss on 1400 batch: 0.277986
Train loss on 1450 batch: 0.260213
Train loss on 1500 batch: 0.291439
Train loss on 1550 batch: 0.286176
Train loss on 1600 batch: 0.266790
Train loss on 1650 batch: 0.264644
Train loss on 1700 batch: 0.249336
Train loss on 1750 batch: 0.220955
Train loss on 1800 batch: 0.305780
Train loss on 1850 batch: 0.279801
Train loss on 1900 batch: 0.276806
Train loss on 1950 batch: 0.263609
Train loss on 2000 batch: 0.255627
Train loss on 2050 batch: 0.237416
Train loss on 2100 batch: 0.208102
Train loss on 2150 batch: 0.298768
Train loss on 2200 batch: 0.264072
Train loss on 2250 batch: 0.286615
Train loss on 2300 batch: 0.264802
Train loss on 2350 batch: 0.228939
Train loss on 2400 batch: 0.256572
Train loss on 2450 batch: 0.239178
Train loss on 2500 batch: 0.179625
Train loss on 2550 batch: 0.232598
Train loss on 2600 batch: 0.251362
Train loss on 2650 batch: 0.244813
Train loss on 2700 batch: 0.289664
Train loss on 2750 batch: 0.219811
Train loss on 2800 batch: 0.223151
Train loss on 2850 batch: 0.214823
Train loss on 2900 batch: 0.250425
: Epoch: 26 | Training Loss: 0.254499 | Val. Loss: 0.451132 | Val. Kappa Score: nan | Estimated time: 741.19
Train loss on 50 batch: 0.231388
Train loss on 100 batch: 0.317516
Train loss on 150 batch: 0.242478
Train loss on 200 batch: 0.219581
Train loss on 250 batch: 0.202814
Train loss on 300 batch: 0.265081
Train loss on 350 batch: 0.258533
Train loss on 400 batch: 0.245530
Train loss on 450 batch: 0.294741
Train loss on 500 batch: 0.216132
Train loss on 550 batch: 0.243819
Train loss on 600 batch: 0.231261
Train loss on 650 batch: 0.230043
Train loss on 700 batch: 0.230691
Train loss on 750 batch: 0.218572
Train loss on 800 batch: 0.232333
Train loss on 850 batch: 0.228117
Train loss on 900 batch: 0.231749
Train loss on 950 batch: 0.283737
Train loss on 1000 batch: 0.298974
Train loss on 1050 batch: 0.235421
Train loss on 1100 batch: 0.312380
Train loss on 1150 batch: 0.219935
Train loss on 1200 batch: 0.319208
Train loss on 1250 batch: 0.316118
Train loss on 1300 batch: 0.264048
Train loss on 1350 batch: 0.272701
Train loss on 1400 batch: 0.305289
Train loss on 1450 batch: 0.264459
Train loss on 1500 batch: 0.216197
Train loss on 1550 batch: 0.236031
Train loss on 1600 batch: 0.245744
Train loss on 1650 batch: 0.244332
Train loss on 1700 batch: 0.262812
Train loss on 1750 batch: 0.255356
Train loss on 1800 batch: 0.267174
Train loss on 1850 batch: 0.302718
Train loss on 1900 batch: 0.238362
Train loss on 1950 batch: 0.223109
Train loss on 2000 batch: 0.191611
Train loss on 2050 batch: 0.224785
Train loss on 2100 batch: 0.226691
Train loss on 2150 batch: 0.242675
Train loss on 2200 batch: 0.232912
Train loss on 2250 batch: 0.320178
Train loss on 2300 batch: 0.268672
Train loss on 2350 batch: 0.268975
Train loss on 2400 batch: 0.243049
Train loss on 2450 batch: 0.203064
Train loss on 2500 batch: 0.248920
Train loss on 2550 batch: 0.278003
Train loss on 2600 batch: 0.256573
Train loss on 2650 batch: 0.272633
Train loss on 2700 batch: 0.266003
Train loss on 2750 batch: 0.315202
Train loss on 2800 batch: 0.291320
Train loss on 2850 batch: 0.278280
Train loss on 2900 batch: 0.212749
: Epoch: 27 | Training Loss: 0.253915 | Val. Loss: 0.422762 | Val. Kappa Score: nan | Estimated time: 755.41
Train loss on 50 batch: 0.270182
Train loss on 100 batch: 0.250076
Train loss on 150 batch: 0.278445
Train loss on 200 batch: 0.293775
Train loss on 250 batch: 0.229253
Train loss on 300 batch: 0.254671
Train loss on 350 batch: 0.246959
Train loss on 400 batch: 0.268688
Train loss on 450 batch: 0.296354
Train loss on 500 batch: 0.243526
Train loss on 550 batch: 0.251926
Train loss on 600 batch: 0.217007
Train loss on 650 batch: 0.219399
Train loss on 700 batch: 0.262975
Train loss on 750 batch: 0.244322
Train loss on 800 batch: 0.226702
Train loss on 850 batch: 0.247643
Train loss on 900 batch: 0.226917
Train loss on 950 batch: 0.247442
Train loss on 1000 batch: 0.269766
Train loss on 1050 batch: 0.253672
Train loss on 1100 batch: 0.204551
Train loss on 1150 batch: 0.268361
Train loss on 1200 batch: 0.278428
Train loss on 1250 batch: 0.268676
Train loss on 1300 batch: 0.241555
Train loss on 1350 batch: 0.223571
Train loss on 1400 batch: 0.232077
Train loss on 1450 batch: 0.221148
Train loss on 1500 batch: 0.234071
Train loss on 1550 batch: 0.251673
Train loss on 1600 batch: 0.260442
Train loss on 1650 batch: 0.201457
Train loss on 1700 batch: 0.222509
Train loss on 1750 batch: 0.312404
Train loss on 1800 batch: 0.224602
Train loss on 1850 batch: 0.260922
Train loss on 1900 batch: 0.233519
Train loss on 1950 batch: 0.252162
Train loss on 2000 batch: 0.244107
Train loss on 2050 batch: 0.244748
Train loss on 2100 batch: 0.275989
Train loss on 2150 batch: 0.256442
Train loss on 2200 batch: 0.265878
Train loss on 2250 batch: 0.289085
Train loss on 2300 batch: 0.256922
Train loss on 2350 batch: 0.206804
Train loss on 2400 batch: 0.223508
Train loss on 2450 batch: 0.302881
Train loss on 2500 batch: 0.203084
Train loss on 2550 batch: 0.228928
Train loss on 2600 batch: 0.226298
Train loss on 2650 batch: 0.222645
Train loss on 2700 batch: 0.234819
Train loss on 2750 batch: 0.260639
Train loss on 2800 batch: 0.245209
Train loss on 2850 batch: 0.262481
Train loss on 2900 batch: 0.235177
: Epoch: 28 | Training Loss: 0.249130 | Val. Loss: 0.432102 | Val. Kappa Score: nan | Estimated time: 783.69
time_estimated: 20863.63
n-epochs: 28
time_estimated: 20863.64
----------------------------------------

Experiment N: 12: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 19:06:25
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10f6d8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 12: 



EXPERIMENT WITH BATCH_SIZE: 10, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 19:06:53
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a780>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 10
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 12: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 19:07:11
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d6d8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 12: 



EXPERIMENT WITH BATCH_SIZE: 4, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.25 19:07:40
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b748>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.028820
Train loss on 100 batch: 1.142548
Train loss on 150 batch: 1.183578
Train loss on 200 batch: 1.063142
Train loss on 250 batch: 1.208246
Train loss on 300 batch: 1.381709
Train loss on 350 batch: 1.242934
Train loss on 400 batch: 0.982299
Train loss on 450 batch: 1.325697
Train loss on 500 batch: 1.079662
Train loss on 550 batch: 0.849748
Train loss on 600 batch: 1.079211
Train loss on 650 batch: 1.005050
Train loss on 700 batch: 0.938181
Train loss on 750 batch: 1.239937
Train loss on 800 batch: 0.932697
Train loss on 850 batch: 0.957513
Train loss on 900 batch: 0.642519
Train loss on 950 batch: 0.756413
Train loss on 1000 batch: 1.243914
Train loss on 1050 batch: 1.060811
Train loss on 1100 batch: 0.876424
Train loss on 1150 batch: 0.875077
Train loss on 1200 batch: 0.862737
Train loss on 1250 batch: 1.085354
Train loss on 1300 batch: 0.872379
Train loss on 1350 batch: 0.695071
Train loss on 1400 batch: 0.907465
Train loss on 1450 batch: 1.014018
Train loss on 1500 batch: 0.990821
Train loss on 1550 batch: 1.030147
Train loss on 1600 batch: 1.049116
Train loss on 1650 batch: 1.070284
Train loss on 1700 batch: 0.954326
Train loss on 1750 batch: 0.896631
Train loss on 1800 batch: 1.061179
Train loss on 1850 batch: 0.984660
Train loss on 1900 batch: 1.043187
Train loss on 1950 batch: 1.060194
Train loss on 2000 batch: 1.135560
Train loss on 2050 batch: 0.912481
Train loss on 2100 batch: 0.885626
Train loss on 2150 batch: 1.055258
Train loss on 2200 batch: 1.008712
Train loss on 2250 batch: 0.850108
Train loss on 2300 batch: 0.946691
Train loss on 2350 batch: 0.873256
Train loss on 2400 batch: 0.858181
Train loss on 2450 batch: 0.801217
Train loss on 2500 batch: 1.100114
Train loss on 2550 batch: 0.922783
Train loss on 2600 batch: 1.075858
Train loss on 2650 batch: 0.932133
Train loss on 2700 batch: 0.940143
Train loss on 2750 batch: 0.965257
Train loss on 2800 batch: 1.036512
Train loss on 2850 batch: 0.851864
Train loss on 2900 batch: 1.283308
Train loss on 2950 batch: 1.109684
Train loss on 3000 batch: 0.914673
Train loss on 3050 batch: 0.934620
Train loss on 3100 batch: 0.846271
Train loss on 3150 batch: 0.781363
Train loss on 3200 batch: 0.855824
Train loss on 3250 batch: 0.932198
Train loss on 3300 batch: 0.686723
Train loss on 3350 batch: 0.895943
Train loss on 3400 batch: 0.692568
Train loss on 3450 batch: 0.710036
Train loss on 3500 batch: 1.206388
Train loss on 3550 batch: 1.117249
Train loss on 3600 batch: 1.036306
Train loss on 3650 batch: 0.904942
Train loss on 3700 batch: 0.861642
Train loss on 3750 batch: 0.854077
Train loss on 3800 batch: 0.852407
Train loss on 3850 batch: 0.876007
Train loss on 3900 batch: 0.638798
Train loss on 3950 batch: 0.692984
Train loss on 4000 batch: 1.027131
Train loss on 4050 batch: 0.914543
Train loss on 4100 batch: 0.855200
Train loss on 4150 batch: 0.935911
Train loss on 4200 batch: 0.934926
Train loss on 4250 batch: 0.857265
Train loss on 4300 batch: 0.928872
Train loss on 4350 batch: 0.788019
Train loss on 4400 batch: 0.813090
Train loss on 4450 batch: 0.882946
Train loss on 4500 batch: 0.724725
Train loss on 4550 batch: 0.888919
Train loss on 4600 batch: 0.846499
Train loss on 4650 batch: 1.077793
Train loss on 4700 batch: 0.846952
Train loss on 4750 batch: 0.804066
Train loss on 4800 batch: 0.787981
Train loss on 4850 batch: 0.949196
Train loss on 4900 batch: 0.728647
Train loss on 4950 batch: 0.729667
Train loss on 5000 batch: 0.770237
Train loss on 5050 batch: 0.730648
Train loss on 5100 batch: 0.785070
Train loss on 5150 batch: 0.851658
Train loss on 5200 batch: 0.861759
Train loss on 5250 batch: 0.884104
Train loss on 5300 batch: 0.893140
Train loss on 5350 batch: 0.747094
Train loss on 5400 batch: 0.633689
Train loss on 5450 batch: 0.893017
Train loss on 5500 batch: 0.726501
Train loss on 5550 batch: 0.826203
Train loss on 5600 batch: 0.707696
Train loss on 5650 batch: 0.873652
Train loss on 5700 batch: 1.062546
Train loss on 5750 batch: 0.814894
Train loss on 5800 batch: 1.089363
Train loss on 5850 batch: 0.844124
Train loss on 5900 batch: 1.021191
Train loss on 5950 batch: 0.728885
Train loss on 6000 batch: 0.734579
Train loss on 6050 batch: 0.874907
Train loss on 6100 batch: 0.794080
Train loss on 6150 batch: 0.978854
Train loss on 6200 batch: 1.002674
Train loss on 6250 batch: 0.767153
Train loss on 6300 batch: 0.957825
Train loss on 6350 batch: 1.030560
Train loss on 6400 batch: 0.669780
Train loss on 6450 batch: 0.708703
Train loss on 6500 batch: 0.719017
Train loss on 6550 batch: 0.781487
Train loss on 6600 batch: 0.629228
Train loss on 6650 batch: 0.764308
Train loss on 6700 batch: 0.823360
Train loss on 6750 batch: 0.892553
Train loss on 6800 batch: 0.795775
Train loss on 6850 batch: 0.916986
Train loss on 6900 batch: 0.685506
Train loss on 6950 batch: 0.694140
Train loss on 7000 batch: 0.710377
Train loss on 7050 batch: 0.595600
Train loss on 7100 batch: 0.773823
Train loss on 7150 batch: 0.831991
Train loss on 7200 batch: 0.615166
Train loss on 7250 batch: 0.785511
Train loss on 7300 batch: 0.688439
Train loss on 7350 batch: 0.753683
Train loss on 7400 batch: 0.802635
Train loss on 7450 batch: 0.783686
Train loss on 7500 batch: 0.964446
Train loss on 7550 batch: 0.749791
Train loss on 7600 batch: 0.874400
Train loss on 7650 batch: 0.627239
Train loss on 7700 batch: 0.557918
Train loss on 7750 batch: 0.745862
Train loss on 7800 batch: 0.822171
Train loss on 7850 batch: 0.810867
Train loss on 7900 batch: 0.882641
Train loss on 7950 batch: 0.773014
Train loss on 8000 batch: 0.622071
Train loss on 8050 batch: 0.594794
Train loss on 8100 batch: 0.588426
Train loss on 8150 batch: 0.607771
Train loss on 8200 batch: 0.669092
Train loss on 8250 batch: 0.642525
Train loss on 8300 batch: 0.717786
Train loss on 8350 batch: 0.778147
Train loss on 8400 batch: 0.604846
Train loss on 8450 batch: 0.741995
Train loss on 8500 batch: 0.780365
Train loss on 8550 batch: 0.672185
Train loss on 8600 batch: 0.817170
Train loss on 8650 batch: 0.693231
Train loss on 8700 batch: 0.773990
Train loss on 8750 batch: 0.839716
best-train-loss: 0.873882
best-valid-loss: 1.605304
best-kappa: 0.4701
: Epoch: 1 | Training Loss: 0.873882 | Val. Loss: 1.605304 | Val. Kappa Score: 0.4701 | Estimated time: 2170.91
Train loss on 50 batch: 0.711051
Train loss on 100 batch: 0.692458
Train loss on 150 batch: 0.596563
Train loss on 200 batch: 0.620534
Train loss on 250 batch: 0.742712
Train loss on 300 batch: 0.695441
Train loss on 350 batch: 0.562014
Train loss on 400 batch: 0.805082
Train loss on 450 batch: 0.792641
Train loss on 500 batch: 0.666172
Train loss on 550 batch: 0.806052
Train loss on 600 batch: 0.795786
Train loss on 650 batch: 0.613654
Train loss on 700 batch: 0.658736
Train loss on 750 batch: 0.855947
Train loss on 800 batch: 0.658098
Train loss on 850 batch: 0.906032
Train loss on 900 batch: 0.771359
Train loss on 950 batch: 0.731862
Train loss on 1000 batch: 0.744627
Train loss on 1050 batch: 0.715798
Train loss on 1100 batch: 0.999879
Train loss on 1150 batch: 0.550468
Train loss on 1200 batch: 0.658084
Train loss on 1250 batch: 0.847096
Train loss on 1300 batch: 0.795046
Train loss on 1350 batch: 0.516491
Train loss on 1400 batch: 0.653342
Train loss on 1450 batch: 0.672238
Train loss on 1500 batch: 0.641470
Train loss on 1550 batch: 0.574362
Train loss on 1600 batch: 0.628376
Train loss on 1650 batch: 0.733483
Train loss on 1700 batch: 0.628667
Train loss on 1750 batch: 0.679209
Train loss on 1800 batch: 0.612250
Train loss on 1850 batch: 0.648230
Train loss on 1900 batch: 0.738314
Train loss on 1950 batch: 0.697920
Train loss on 2000 batch: 0.705645
Train loss on 2050 batch: 0.621699
Train loss on 2100 batch: 0.449363
Train loss on 2150 batch: 0.634502
Train loss on 2200 batch: 0.814588
Train loss on 2250 batch: 0.751402
Train loss on 2300 batch: 0.721792
Train loss on 2350 batch: 0.628743
Train loss on 2400 batch: 0.605532
Train loss on 2450 batch: 0.898092
Train loss on 2500 batch: 0.623777
Train loss on 2550 batch: 0.667062
Train loss on 2600 batch: 0.618681
Train loss on 2650 batch: 0.646927
Train loss on 2700 batch: 0.517527
Train loss on 2750 batch: 0.543369
Train loss on 2800 batch: 0.712861
Train loss on 2850 batch: 0.588312
Train loss on 2900 batch: 0.647035
Train loss on 2950 batch: 0.551898
Train loss on 3000 batch: 0.859677
Train loss on 3050 batch: 0.645965
Train loss on 3100 batch: 0.754078
Train loss on 3150 batch: 0.602115
Train loss on 3200 batch: 0.552756
Train loss on 3250 batch: 0.506441
Train loss on 3300 batch: 0.585925
Train loss on 3350 batch: 0.471990
Train loss on 3400 batch: 0.561759
Train loss on 3450 batch: 0.670830
Train loss on 3500 batch: 0.673829
Train loss on 3550 batch: 0.592356
Train loss on 3600 batch: 0.767835
Train loss on 3650 batch: 0.656751
Train loss on 3700 batch: 0.600686
Train loss on 3750 batch: 0.751161
Train loss on 3800 batch: 0.615132
Train loss on 3850 batch: 0.581930
Train loss on 3900 batch: 0.574309
Train loss on 3950 batch: 0.748900
Train loss on 4000 batch: 0.620679
Train loss on 4050 batch: 0.536787
Train loss on 4100 batch: 0.672280
Train loss on 4150 batch: 0.673007
Train loss on 4200 batch: 0.645771
Train loss on 4250 batch: 0.590825
Train loss on 4300 batch: 0.571634
Train loss on 4350 batch: 0.621076
Train loss on 4400 batch: 0.495260
Train loss on 4450 batch: 0.526883
Train loss on 4500 batch: 0.563755
Train loss on 4550 batch: 0.764324
Train loss on 4600 batch: 0.570439
Train loss on 4650 batch: 0.521063
Train loss on 4700 batch: 0.526764
Train loss on 4750 batch: 0.541821
Train loss on 4800 batch: 0.608021
Train loss on 4850 batch: 0.632686
Train loss on 4900 batch: 0.441293
Train loss on 4950 batch: 0.575975
Train loss on 5000 batch: 0.456972
Train loss on 5050 batch: 0.737384
Train loss on 5100 batch: 0.669674
Train loss on 5150 batch: 0.578563
Train loss on 5200 batch: 0.666319
Train loss on 5250 batch: 0.712824
Train loss on 5300 batch: 0.751619
Train loss on 5350 batch: 0.688620
Train loss on 5400 batch: 0.732287
Train loss on 5450 batch: 0.648904
Train loss on 5500 batch: 0.541857
Train loss on 5550 batch: 0.724648
Train loss on 5600 batch: 0.561290
Train loss on 5650 batch: 0.732042
Train loss on 5700 batch: 0.563131
Train loss on 5750 batch: 0.680911
Train loss on 5800 batch: 0.682875
Train loss on 5850 batch: 0.620498
Train loss on 5900 batch: 0.672021
Train loss on 5950 batch: 0.498003
Train loss on 6000 batch: 0.868114
Train loss on 6050 batch: 0.575740
Train loss on 6100 batch: 0.590556
Train loss on 6150 batch: 0.584582
Train loss on 6200 batch: 0.511333
Train loss on 6250 batch: 0.547272
Train loss on 6300 batch: 0.577173
Train loss on 6350 batch: 0.746269
Train loss on 6400 batch: 0.397529
Train loss on 6450 batch: 0.392611
Train loss on 6500 batch: 0.817940
Train loss on 6550 batch: 0.631531
Train loss on 6600 batch: 0.446531
Train loss on 6650 batch: 0.402368
Train loss on 6700 batch: 0.593072
Train loss on 6750 batch: 0.491265
Train loss on 6800 batch: 0.761563
Train loss on 6850 batch: 0.582388
Train loss on 6900 batch: 0.590935
Train loss on 6950 batch: 0.913130
Train loss on 7000 batch: 0.544771
Train loss on 7050 batch: 0.470028
Train loss on 7100 batch: 0.666420
Train loss on 7150 batch: 0.557956
Train loss on 7200 batch: 0.455315
Train loss on 7250 batch: 0.481642
Train loss on 7300 batch: 0.568877
Train loss on 7350 batch: 0.589078
Train loss on 7400 batch: 0.568511
Train loss on 7450 batch: 0.800120
Train loss on 7500 batch: 0.636196
Train loss on 7550 batch: 0.537813
Train loss on 7600 batch: 0.561694
Train loss on 7650 batch: 0.724426
Train loss on 7700 batch: 0.405301
Train loss on 7750 batch: 0.524116
Train loss on 7800 batch: 0.382528
Train loss on 7850 batch: 0.444199
Train loss on 7900 batch: 0.705287
Train loss on 7950 batch: 0.510161
Train loss on 8000 batch: 0.598634
Train loss on 8050 batch: 0.488438
Train loss on 8100 batch: 0.422017
Train loss on 8150 batch: 0.574508
Train loss on 8200 batch: 0.595941
Train loss on 8250 batch: 0.529917
Train loss on 8300 batch: 0.501524
Train loss on 8350 batch: 0.603494
Train loss on 8400 batch: 0.704832
Train loss on 8450 batch: 0.677354
Train loss on 8500 batch: 0.590247
Train loss on 8550 batch: 0.819247
Train loss on 8600 batch: 0.550879
Train loss on 8650 batch: 0.548374
Train loss on 8700 batch: 0.697526
Train loss on 8750 batch: 0.593853
best-train-loss: 0.630186
best-valid-loss: 1.172496
best-kappa: 0.5080
: Epoch: 2 | Training Loss: 0.630186 | Val. Loss: 1.172496 | Val. Kappa Score: 0.5080 | Estimated time: 2127.43
Train loss on 50 batch: 0.492189
Train loss on 100 batch: 0.599241
Train loss on 150 batch: 0.630154
Train loss on 200 batch: 0.468463
Train loss on 250 batch: 0.717783
Train loss on 300 batch: 0.478853
Train loss on 350 batch: 0.596077
Train loss on 400 batch: 0.534042
Train loss on 450 batch: 0.528770
Train loss on 500 batch: 0.488336
Train loss on 550 batch: 0.564276
Train loss on 600 batch: 0.523525
Train loss on 650 batch: 0.494627
Train loss on 700 batch: 0.460367
Train loss on 750 batch: 0.635490
Train loss on 800 batch: 0.460456
Train loss on 850 batch: 0.626253
Train loss on 900 batch: 0.598301
Train loss on 950 batch: 0.372828
Train loss on 1000 batch: 0.445557
Train loss on 1050 batch: 0.596827
Train loss on 1100 batch: 0.411569
Train loss on 1150 batch: 0.543157
Train loss on 1200 batch: 0.552201
Train loss on 1250 batch: 0.413011
Train loss on 1300 batch: 0.540915
Train loss on 1350 batch: 0.511132
Train loss on 1400 batch: 0.605671
Train loss on 1450 batch: 0.470906
Train loss on 1500 batch: 0.606320
Train loss on 1550 batch: 0.494651
Train loss on 1600 batch: 0.412465
Train loss on 1650 batch: 0.564078
Train loss on 1700 batch: 0.431504
Train loss on 1750 batch: 0.516851
Train loss on 1800 batch: 0.371254
Train loss on 1850 batch: 0.538924
Train loss on 1900 batch: 0.628836
Train loss on 1950 batch: 0.502182
Train loss on 2000 batch: 0.612894
Train loss on 2050 batch: 0.779003
Train loss on 2100 batch: 0.659351
Train loss on 2150 batch: 0.538685
Train loss on 2200 batch: 0.434568
Train loss on 2250 batch: 0.540721
Train loss on 2300 batch: 0.555128
Train loss on 2350 batch: 0.595066
Train loss on 2400 batch: 0.688335
Train loss on 2450 batch: 0.809882
Train loss on 2500 batch: 0.569131
Train loss on 2550 batch: 0.545468
Train loss on 2600 batch: 0.578495
Train loss on 2650 batch: 0.656712
Train loss on 2700 batch: 0.472419
Train loss on 2750 batch: 0.430588
Train loss on 2800 batch: 0.494670
Train loss on 2850 batch: 0.538220
Train loss on 2900 batch: 0.291451
Train loss on 2950 batch: 0.510014
Train loss on 3000 batch: 0.449491
Train loss on 3050 batch: 0.597874
Train loss on 3100 batch: 0.545779
Train loss on 3150 batch: 0.447364
Train loss on 3200 batch: 0.600028
Train loss on 3250 batch: 0.537346
Train loss on 3300 batch: 0.704598
Train loss on 3350 batch: 0.589099
Train loss on 3400 batch: 0.496018
Train loss on 3450 batch: 0.572299
Train loss on 3500 batch: 0.407215
Train loss on 3550 batch: 0.519107
Train loss on 3600 batch: 0.499874
Train loss on 3650 batch: 0.529137
Train loss on 3700 batch: 0.630249
Train loss on 3750 batch: 0.581827
Train loss on 3800 batch: 0.606976
Train loss on 3850 batch: 0.468632
Train loss on 3900 batch: 0.639672
Train loss on 3950 batch: 0.644307
Train loss on 4000 batch: 0.581609
Train loss on 4050 batch: 0.766061
Train loss on 4100 batch: 0.673078
Train loss on 4150 batch: 0.648224
Train loss on 4200 batch: 0.462172
Train loss on 4250 batch: 0.593678
Train loss on 4300 batch: 0.544700
Train loss on 4350 batch: 0.590378
Train loss on 4400 batch: 0.565059
Train loss on 4450 batch: 0.516979
Train loss on 4500 batch: 0.569121
Train loss on 4550 batch: 0.518010
Train loss on 4600 batch: 0.585554
Train loss on 4650 batch: 0.595395
Train loss on 4700 batch: 0.651253
Train loss on 4750 batch: 0.549091
Train loss on 4800 batch: 0.481102
Train loss on 4850 batch: 0.641384
Train loss on 4900 batch: 0.487375
Train loss on 4950 batch: 0.416858
Train loss on 5000 batch: 0.532060
Train loss on 5050 batch: 0.810839
Train loss on 5100 batch: 0.492491
Train loss on 5150 batch: 0.655395
Train loss on 5200 batch: 0.583371
Train loss on 5250 batch: 0.554028
Train loss on 5300 batch: 0.675425
Train loss on 5350 batch: 0.645755
Train loss on 5400 batch: 0.467891
Train loss on 5450 batch: 0.421066
Train loss on 5500 batch: 0.502580
Train loss on 5550 batch: 0.604226
Train loss on 5600 batch: 0.623079
Train loss on 5650 batch: 0.625855
Train loss on 5700 batch: 0.566875
Train loss on 5750 batch: 0.575462
Train loss on 5800 batch: 0.611089
Train loss on 5850 batch: 0.395993
Train loss on 5900 batch: 0.459471
Train loss on 5950 batch: 0.743610
Train loss on 6000 batch: 0.607475
Train loss on 6050 batch: 0.631175
Train loss on 6100 batch: 0.524854
Train loss on 6150 batch: 0.625070
Train loss on 6200 batch: 0.530865
Train loss on 6250 batch: 0.524493
Train loss on 6300 batch: 0.386734
Train loss on 6350 batch: 0.463119
Train loss on 6400 batch: 0.534372
Train loss on 6450 batch: 0.709161
Train loss on 6500 batch: 0.602430
Train loss on 6550 batch: 0.450702
Train loss on 6600 batch: 0.559955
Train loss on 6650 batch: 0.609253
Train loss on 6700 batch: 0.529738
Train loss on 6750 batch: 0.497492
Train loss on 6800 batch: 0.620915
Train loss on 6850 batch: 0.572076
Train loss on 6900 batch: 0.566752
Train loss on 6950 batch: 0.430719
Train loss on 7000 batch: 0.450632
Train loss on 7050 batch: 0.525190
Train loss on 7100 batch: 0.351069
Train loss on 7150 batch: 0.437465
Train loss on 7200 batch: 0.484290
Train loss on 7250 batch: 0.494923
Train loss on 7300 batch: 0.531111
Train loss on 7350 batch: 0.497119
Train loss on 7400 batch: 0.582684
Train loss on 7450 batch: 0.521278
Train loss on 7500 batch: 0.421909
Train loss on 7550 batch: 0.341661
Train loss on 7600 batch: 0.609519
Train loss on 7650 batch: 0.520972
Train loss on 7700 batch: 0.579272
Train loss on 7750 batch: 0.496544
Train loss on 7800 batch: 0.488057
Train loss on 7850 batch: 0.489008
Train loss on 7900 batch: 0.559977
Train loss on 7950 batch: 0.491172
Train loss on 8000 batch: 0.616973
Train loss on 8050 batch: 0.617087
Train loss on 8100 batch: 0.852429
Train loss on 8150 batch: 0.520799
Train loss on 8200 batch: 0.377817
Train loss on 8250 batch: 0.552025
Train loss on 8300 batch: 0.478724
Train loss on 8350 batch: 0.527073
Train loss on 8400 batch: 0.585775
Train loss on 8450 batch: 0.571850
Train loss on 8500 batch: 0.516383
Train loss on 8550 batch: 0.528860
Train loss on 8600 batch: 0.477129
Train loss on 8650 batch: 0.679412
Train loss on 8700 batch: 0.535536
Train loss on 8750 batch: 0.434278
best-train-loss: 0.545569
best-valid-loss: 1.009435
best-kappa: 0.5566
: Epoch: 3 | Training Loss: 0.545569 | Val. Loss: 1.009435 | Val. Kappa Score: 0.5566 | Estimated time: 2124.62
Train loss on 50 batch: 0.443754
Train loss on 100 batch: 0.372468
Train loss on 150 batch: 0.664930
Train loss on 200 batch: 0.555998
Train loss on 250 batch: 0.575831
Train loss on 300 batch: 0.567023
Train loss on 350 batch: 0.481851
Train loss on 400 batch: 0.776105
Train loss on 450 batch: 0.507600
Train loss on 500 batch: 0.533174
Train loss on 550 batch: 0.422006
Train loss on 600 batch: 0.464527
Train loss on 650 batch: 0.524583
Train loss on 700 batch: 0.463022
Train loss on 750 batch: 0.347452
Train loss on 800 batch: 0.562010
Train loss on 850 batch: 0.458355
Train loss on 900 batch: 0.599844
Train loss on 950 batch: 0.638026
Train loss on 1000 batch: 0.481745
Train loss on 1050 batch: 0.579099
Train loss on 1100 batch: 0.693821
Train loss on 1150 batch: 0.558193
Train loss on 1200 batch: 0.437993
Train loss on 1250 batch: 0.481105
Train loss on 1300 batch: 0.568094
Train loss on 1350 batch: 0.417008
Train loss on 1400 batch: 0.739552
Train loss on 1450 batch: 0.736764
Train loss on 1500 batch: 0.511353
Train loss on 1550 batch: 0.725443
Train loss on 1600 batch: 0.357907
Train loss on 1650 batch: 0.467262
Train loss on 1700 batch: 0.652581
Train loss on 1750 batch: 0.548579
Train loss on 1800 batch: 0.563662
Train loss on 1850 batch: 0.530386
Train loss on 1900 batch: 0.383804
Train loss on 1950 batch: 0.419376
Train loss on 2000 batch: 0.686760
Train loss on 2050 batch: 0.433425
Train loss on 2100 batch: 0.337962
Train loss on 2150 batch: 0.585650
Train loss on 2200 batch: 0.634009
Train loss on 2250 batch: 0.529558
Train loss on 2300 batch: 0.566808
Train loss on 2350 batch: 0.661959
Train loss on 2400 batch: 0.386376
Train loss on 2450 batch: 0.428630
Train loss on 2500 batch: 0.532115
Train loss on 2550 batch: 0.520449
Train loss on 2600 batch: 0.646824
Train loss on 2650 batch: 0.461004
Train loss on 2700 batch: 0.635710
Train loss on 2750 batch: 0.535342
Train loss on 2800 batch: 0.600894
Train loss on 2850 batch: 0.414485
Train loss on 2900 batch: 0.652024
Train loss on 2950 batch: 0.521699
Train loss on 3000 batch: 0.490354
Train loss on 3050 batch: 0.558475
Train loss on 3100 batch: 0.475834
Train loss on 3150 batch: 0.498956
Train loss on 3200 batch: 0.484179
Train loss on 3250 batch: 0.452948
Train loss on 3300 batch: 0.594167
Train loss on 3350 batch: 0.413762
Train loss on 3400 batch: 0.571223
Train loss on 3450 batch: 0.405258
Train loss on 3500 batch: 0.453661
Train loss on 3550 batch: 0.582276
Train loss on 3600 batch: 0.442020
Train loss on 3650 batch: 0.508672
Train loss on 3700 batch: 0.544647
Train loss on 3750 batch: 0.671042
Train loss on 3800 batch: 0.505244
Train loss on 3850 batch: 0.549141
Train loss on 3900 batch: 0.535249
Train loss on 3950 batch: 0.642049
Train loss on 4000 batch: 0.554663
Train loss on 4050 batch: 0.499709
Train loss on 4100 batch: 0.481404
Train loss on 4150 batch: 0.460986
Train loss on 4200 batch: 0.573925
Train loss on 4250 batch: 0.443194
Train loss on 4300 batch: 0.652177
Train loss on 4350 batch: 0.460682
Train loss on 4400 batch: 0.399496
Train loss on 4450 batch: 0.525179
Train loss on 4500 batch: 0.456874
Train loss on 4550 batch: 0.405174
Train loss on 4600 batch: 0.471737
Train loss on 4650 batch: 0.679168
Train loss on 4700 batch: 0.462690
Train loss on 4750 batch: 0.548167
Train loss on 4800 batch: 0.443575
Train loss on 4850 batch: 0.459190
Train loss on 4900 batch: 0.488264
Train loss on 4950 batch: 0.559017
Train loss on 5000 batch: 0.538130
Train loss on 5050 batch: 0.452913
Train loss on 5100 batch: 0.529574
Train loss on 5150 batch: 0.490234
Train loss on 5200 batch: 0.402586
Train loss on 5250 batch: 0.596436
Train loss on 5300 batch: 0.599608
Train loss on 5350 batch: 0.440068
Train loss on 5400 batch: 0.488324
Train loss on 5450 batch: 0.360006
Train loss on 5500 batch: 0.375604
Train loss on 5550 batch: 0.602249
Train loss on 5600 batch: 0.500960
Train loss on 5650 batch: 0.670952
Train loss on 5700 batch: 0.452169
Train loss on 5750 batch: 0.579234
Train loss on 5800 batch: 0.601499
Train loss on 5850 batch: 0.600663
Train loss on 5900 batch: 0.500994
Train loss on 5950 batch: 0.596646
Train loss on 6000 batch: 0.308502
Train loss on 6050 batch: 0.522721
Train loss on 6100 batch: 0.520158
Train loss on 6150 batch: 0.533317
Train loss on 6200 batch: 0.444512
Train loss on 6250 batch: 0.512922
Train loss on 6300 batch: 0.347296
Train loss on 6350 batch: 0.387957
Train loss on 6400 batch: 0.484626
Train loss on 6450 batch: 0.551554
Train loss on 6500 batch: 0.569256
Train loss on 6550 batch: 0.592510
Train loss on 6600 batch: 0.578397
Train loss on 6650 batch: 0.565739
Train loss on 6700 batch: 0.786301
Train loss on 6750 batch: 0.629081
Train loss on 6800 batch: 0.649509
Train loss on 6850 batch: 0.484057
Train loss on 6900 batch: 0.565816
Train loss on 6950 batch: 0.427175
Train loss on 7000 batch: 0.394844
Train loss on 7050 batch: 0.492955
Train loss on 7100 batch: 0.639550
Train loss on 7150 batch: 0.410363
Train loss on 7200 batch: 0.567460
Train loss on 7250 batch: 0.487459
Train loss on 7300 batch: 0.447341
Train loss on 7350 batch: 0.461207
Train loss on 7400 batch: 0.529138
Train loss on 7450 batch: 0.533941
Train loss on 7500 batch: 0.462526
Train loss on 7550 batch: 0.560239
Train loss on 7600 batch: 0.470573
Train loss on 7650 batch: 0.403748
Train loss on 7700 batch: 0.524905
Train loss on 7750 batch: 0.463023
Train loss on 7800 batch: 0.441730
Train loss on 7850 batch: 0.479494
Train loss on 7900 batch: 0.556034
Train loss on 7950 batch: 0.487997
Train loss on 8000 batch: 0.367588
Train loss on 8050 batch: 0.499988
Train loss on 8100 batch: 0.593824
Train loss on 8150 batch: 0.529086
Train loss on 8200 batch: 0.591490
Train loss on 8250 batch: 0.427604
Train loss on 8300 batch: 0.391861
Train loss on 8350 batch: 0.496320
Train loss on 8400 batch: 0.440045
Train loss on 8450 batch: 0.446699
Train loss on 8500 batch: 0.542303
Train loss on 8550 batch: 0.564821
Train loss on 8600 batch: 0.410632
Train loss on 8650 batch: 0.634010
Train loss on 8700 batch: 0.478832
Train loss on 8750 batch: 0.500601
: Epoch: 4 | Training Loss: 0.517036 | Val. Loss: 1.855826 | Val. Kappa Score: 0.5395 | Estimated time: 2124.62
Train loss on 50 batch: 0.454917
Train loss on 100 batch: 0.543051
Train loss on 150 batch: 0.378475
Train loss on 200 batch: 0.567253
Train loss on 250 batch: 0.547961
Train loss on 300 batch: 0.556077
Train loss on 350 batch: 0.627371
Train loss on 400 batch: 0.541013
Train loss on 450 batch: 0.562865
Train loss on 500 batch: 0.676964
Train loss on 550 batch: 0.445984
Train loss on 600 batch: 0.362870
Train loss on 650 batch: 0.446205
Train loss on 700 batch: 0.422387
Train loss on 750 batch: 0.497922
Train loss on 800 batch: 0.615779
Train loss on 850 batch: 0.447918
Train loss on 900 batch: 0.473105
Train loss on 950 batch: 0.471380
Train loss on 1000 batch: 0.505809
Train loss on 1050 batch: 0.487601
Train loss on 1100 batch: 0.568438
Train loss on 1150 batch: 0.532415
Train loss on 1200 batch: 0.636854
Train loss on 1250 batch: 0.436140
Train loss on 1300 batch: 0.712326
Train loss on 1350 batch: 0.430356
Train loss on 1400 batch: 0.561787
Train loss on 1450 batch: 0.411992
Train loss on 1500 batch: 0.447567
Train loss on 1550 batch: 0.559979
Train loss on 1600 batch: 0.337353
Train loss on 1650 batch: 0.583908
Train loss on 1700 batch: 0.503939
Train loss on 1750 batch: 0.586961
Train loss on 1800 batch: 0.449416
Train loss on 1850 batch: 0.447626
Train loss on 1900 batch: 0.450392
Train loss on 1950 batch: 0.458207
Train loss on 2000 batch: 0.475559
Train loss on 2050 batch: 0.641634
Train loss on 2100 batch: 0.373664
Train loss on 2150 batch: 0.474293
Train loss on 2200 batch: 0.308997
Train loss on 2250 batch: 0.458029
Train loss on 2300 batch: 0.320719
Train loss on 2350 batch: 0.519684
Train loss on 2400 batch: 0.625975
Train loss on 2450 batch: 0.650293
Train loss on 2500 batch: 0.575113
Train loss on 2550 batch: 0.548352
Train loss on 2600 batch: 0.487995
Train loss on 2650 batch: 0.413322
Train loss on 2700 batch: 0.476044
Train loss on 2750 batch: 0.441457
Train loss on 2800 batch: 0.576690
Train loss on 2850 batch: 0.406437
Train loss on 2900 batch: 0.471733
Train loss on 2950 batch: 0.417847
Train loss on 3000 batch: 0.552749
Train loss on 3050 batch: 0.504876
Train loss on 3100 batch: 0.626869
Train loss on 3150 batch: 0.540737
Train loss on 3200 batch: 0.542758
Train loss on 3250 batch: 0.511429
Train loss on 3300 batch: 0.397591
Train loss on 3350 batch: 0.512249
Train loss on 3400 batch: 0.442698
Train loss on 3450 batch: 0.582503
Train loss on 3500 batch: 0.570883
Train loss on 3550 batch: 0.633765
Train loss on 3600 batch: 0.558456
Train loss on 3650 batch: 0.385199
Train loss on 3700 batch: 0.414521
Train loss on 3750 batch: 0.433624
Train loss on 3800 batch: 0.312394
Train loss on 3850 batch: 0.435674
Train loss on 3900 batch: 0.355044
Train loss on 3950 batch: 0.600636
Train loss on 4000 batch: 0.495428
Train loss on 4050 batch: 0.490834
Train loss on 4100 batch: 0.358627
Train loss on 4150 batch: 0.436657
Train loss on 4200 batch: 0.434935
Train loss on 4250 batch: 0.541542
Train loss on 4300 batch: 0.424027
Train loss on 4350 batch: 0.423176
Train loss on 4400 batch: 0.490011
Train loss on 4450 batch: 0.464798
Train loss on 4500 batch: 0.452007
Train loss on 4550 batch: 0.456920
Train loss on 4600 batch: 0.417636
Train loss on 4650 batch: 0.519653
Train loss on 4700 batch: 0.418183
Train loss on 4750 batch: 0.605278
Train loss on 4800 batch: 0.432392
Train loss on 4850 batch: 0.696757
Train loss on 4900 batch: 0.575710
Train loss on 4950 batch: 0.520191
Train loss on 5000 batch: 0.495113
Train loss on 5050 batch: 0.795356
Train loss on 5100 batch: 0.569921
Train loss on 5150 batch: 0.525098
Train loss on 5200 batch: 0.450270
Train loss on 5250 batch: 0.544848
Train loss on 5300 batch: 0.602125
Train loss on 5350 batch: 0.487044
Train loss on 5400 batch: 0.594180
Train loss on 5450 batch: 0.634399
Train loss on 5500 batch: 0.649195
Train loss on 5550 batch: 0.498815
Train loss on 5600 batch: 0.450248
Train loss on 5650 batch: 0.442773
Train loss on 5700 batch: 0.524367
Train loss on 5750 batch: 0.435615
Train loss on 5800 batch: 0.392535
Train loss on 5850 batch: 0.535938
Train loss on 5900 batch: 0.389768
Train loss on 5950 batch: 0.391327
Train loss on 6000 batch: 0.444116
Train loss on 6050 batch: 0.519145
Train loss on 6100 batch: 0.394944
Train loss on 6150 batch: 0.502327
Train loss on 6200 batch: 0.533927
Train loss on 6250 batch: 0.471552
Train loss on 6300 batch: 0.637895
Train loss on 6350 batch: 0.589350
Train loss on 6400 batch: 0.484381
Train loss on 6450 batch: 0.588708
Train loss on 6500 batch: 0.569312
Train loss on 6550 batch: 0.406798
Train loss on 6600 batch: 0.573829
Train loss on 6650 batch: 0.406045
Train loss on 6700 batch: 0.541919
Train loss on 6750 batch: 0.560652
Train loss on 6800 batch: 0.432915
Train loss on 6850 batch: 0.565396
Train loss on 6900 batch: 0.367361
Train loss on 6950 batch: 0.586479
Train loss on 7000 batch: 0.424635
Train loss on 7050 batch: 0.631037
Train loss on 7100 batch: 0.352989
Train loss on 7150 batch: 0.583693
Train loss on 7200 batch: 0.372298
Train loss on 7250 batch: 0.364945
Train loss on 7300 batch: 0.349815
Train loss on 7350 batch: 0.475424
Train loss on 7400 batch: 0.356848
Train loss on 7450 batch: 0.454880
Train loss on 7500 batch: 0.822714
Train loss on 7550 batch: 0.406136
Train loss on 7600 batch: 0.591310
Train loss on 7650 batch: 0.607603
Train loss on 7700 batch: 0.348074
Train loss on 7750 batch: 0.491367
Train loss on 7800 batch: 0.660437
Train loss on 7850 batch: 0.562664
Train loss on 7900 batch: 0.555835
Train loss on 7950 batch: 0.657618
Train loss on 8000 batch: 0.599407
Train loss on 8050 batch: 0.478440
Train loss on 8100 batch: 0.575929
Train loss on 8150 batch: 0.572783
Train loss on 8200 batch: 0.682164
Train loss on 8250 batch: 0.466032
Train loss on 8300 batch: 0.389988
Train loss on 8350 batch: 0.544821
Train loss on 8400 batch: 0.446513
Train loss on 8450 batch: 0.536226
Train loss on 8500 batch: 0.540383
Train loss on 8550 batch: 0.361307
Train loss on 8600 batch: 0.441653
Train loss on 8650 batch: 0.465684
Train loss on 8700 batch: 0.470949
Train loss on 8750 batch: 0.574974
: Epoch: 5 | Training Loss: 0.501984 | Val. Loss: 1.252245 | Val. Kappa Score: 0.5326 | Estimated time: 2126.02
Train loss on 50 batch: 0.543814
Train loss on 100 batch: 0.504460
Train loss on 150 batch: 0.538848
Train loss on 200 batch: 0.545008
Train loss on 250 batch: 0.690934
Train loss on 300 batch: 0.431855
Train loss on 350 batch: 0.600696
Train loss on 400 batch: 0.519130
Train loss on 450 batch: 0.684322
Train loss on 500 batch: 0.579139
Train loss on 550 batch: 0.571531
Train loss on 600 batch: 0.418412
Train loss on 650 batch: 0.593676
Train loss on 700 batch: 0.553414
Train loss on 750 batch: 0.510551
Train loss on 800 batch: 0.669402
Train loss on 850 batch: 0.557038
Train loss on 900 batch: 0.575799
Train loss on 950 batch: 0.358466
Train loss on 1000 batch: 0.383155
Train loss on 1050 batch: 0.508089
Train loss on 1100 batch: 0.358559
Train loss on 1150 batch: 0.750916
Train loss on 1200 batch: 0.527990
Train loss on 1250 batch: 0.497688
Train loss on 1300 batch: 0.396460
Train loss on 1350 batch: 0.619972
Train loss on 1400 batch: 0.388180
Train loss on 1450 batch: 0.476591
Train loss on 1500 batch: 0.331896
Train loss on 1550 batch: 0.268833
Train loss on 1600 batch: 0.475511
Train loss on 1650 batch: 0.550670
Train loss on 1700 batch: 0.472235
Train loss on 1750 batch: 0.511258
Train loss on 1800 batch: 0.532271
Train loss on 1850 batch: 0.460454
Train loss on 1900 batch: 0.399722
Train loss on 1950 batch: 0.575014
Train loss on 2000 batch: 0.386809
Train loss on 2050 batch: 0.332781
Train loss on 2100 batch: 0.428466
Train loss on 2150 batch: 0.469660
Train loss on 2200 batch: 0.613006
Train loss on 2250 batch: 0.484516
Train loss on 2300 batch: 0.486282
Train loss on 2350 batch: 0.398876
Train loss on 2400 batch: 0.665620
Train loss on 2450 batch: 0.435589
Train loss on 2500 batch: 0.530365
Train loss on 2550 batch: 0.370564
Train loss on 2600 batch: 0.544884
Train loss on 2650 batch: 0.596741
Train loss on 2700 batch: 0.484567
Train loss on 2750 batch: 0.448119
Train loss on 2800 batch: 0.499402
Train loss on 2850 batch: 0.415922
Train loss on 2900 batch: 0.505618
Train loss on 2950 batch: 0.544406
Train loss on 3000 batch: 0.685703
Train loss on 3050 batch: 0.428043
Train loss on 3100 batch: 0.392359
Train loss on 3150 batch: 0.395737
Train loss on 3200 batch: 0.452936
Train loss on 3250 batch: 0.536537
Train loss on 3300 batch: 0.603124
Train loss on 3350 batch: 0.440266
Train loss on 3400 batch: 0.471547
Train loss on 3450 batch: 0.488866
Train loss on 3500 batch: 0.423189
Train loss on 3550 batch: 0.582853
Train loss on 3600 batch: 0.514060
Train loss on 3650 batch: 0.389487
Train loss on 3700 batch: 0.540711
Train loss on 3750 batch: 0.518646
Train loss on 3800 batch: 0.471751
Train loss on 3850 batch: 0.364724
Train loss on 3900 batch: 0.424042
Train loss on 3950 batch: 0.462498
Train loss on 4000 batch: 0.393116
Train loss on 4050 batch: 0.420790
Train loss on 4100 batch: 0.502160
Train loss on 4150 batch: 0.477280
Train loss on 4200 batch: 0.477120
Train loss on 4250 batch: 0.458778
Train loss on 4300 batch: 0.426579
Train loss on 4350 batch: 0.547705
Train loss on 4400 batch: 0.328804
Train loss on 4450 batch: 0.453366
Train loss on 4500 batch: 0.535286
Train loss on 4550 batch: 0.431407
Train loss on 4600 batch: 0.452802
Train loss on 4650 batch: 0.346402
Train loss on 4700 batch: 0.506733
Train loss on 4750 batch: 0.484321
Train loss on 4800 batch: 0.459263
Train loss on 4850 batch: 0.398862
Train loss on 4900 batch: 0.477128
Train loss on 4950 batch: 0.681259
Train loss on 5000 batch: 0.583597
Train loss on 5050 batch: 0.441640
Train loss on 5100 batch: 0.523112
Train loss on 5150 batch: 0.531500
Train loss on 5200 batch: 0.419931
Train loss on 5250 batch: 0.376272
Train loss on 5300 batch: 0.403023
Train loss on 5350 batch: 0.305233
Train loss on 5400 batch: 0.424652
Train loss on 5450 batch: 0.429799
Train loss on 5500 batch: 0.501076
Train loss on 5550 batch: 0.362968
Train loss on 5600 batch: 0.383370
Train loss on 5650 batch: 0.464220
Train loss on 5700 batch: 0.456452
Train loss on 5750 batch: 0.455847
Train loss on 5800 batch: 0.438219
Train loss on 5850 batch: 0.527085
Train loss on 5900 batch: 0.492650
Train loss on 5950 batch: 0.550878
Train loss on 6000 batch: 0.404910
Train loss on 6050 batch: 0.424091
Train loss on 6100 batch: 0.439798
Train loss on 6150 batch: 0.518932
Train loss on 6200 batch: 0.368117
Train loss on 6250 batch: 0.453707
Train loss on 6300 batch: 0.644623
Train loss on 6350 batch: 0.653648
Train loss on 6400 batch: 0.516940
Train loss on 6450 batch: 0.461823
Train loss on 6500 batch: 0.448585
Train loss on 6550 batch: 0.704744
Train loss on 6600 batch: 0.515172
Train loss on 6650 batch: 0.517476
Train loss on 6700 batch: 0.553622
Train loss on 6750 batch: 0.695754
Train loss on 6800 batch: 0.426754
Train loss on 6850 batch: 0.397196
Train loss on 6900 batch: 0.557693
Train loss on 6950 batch: 0.393004
Train loss on 7000 batch: 0.584444
Train loss on 7050 batch: 0.509700
Train loss on 7100 batch: 0.602408
Train loss on 7150 batch: 0.407769
Train loss on 7200 batch: 0.469691
Train loss on 7250 batch: 0.491669
Train loss on 7300 batch: 0.471615
Train loss on 7350 batch: 0.563420
Train loss on 7400 batch: 0.455247
Train loss on 7450 batch: 0.379845
Train loss on 7500 batch: 0.375503
Train loss on 7550 batch: 0.419138
Train loss on 7600 batch: 0.418796
Train loss on 7650 batch: 0.534011
Train loss on 7700 batch: 0.467138
Train loss on 7750 batch: 0.476735
Train loss on 7800 batch: 0.437803
Train loss on 7850 batch: 0.447950
Train loss on 7900 batch: 0.321036
Train loss on 7950 batch: 0.587918
Train loss on 8000 batch: 0.574616
Train loss on 8050 batch: 0.518349
Train loss on 8100 batch: 0.337365
Train loss on 8150 batch: 0.396836
Train loss on 8200 batch: 0.445337
Train loss on 8250 batch: 0.726123
Train loss on 8300 batch: 0.522492
Train loss on 8350 batch: 0.571280
Train loss on 8400 batch: 0.591722
Train loss on 8450 batch: 0.667001
Train loss on 8500 batch: 0.711525
Train loss on 8550 batch: 0.508500
Train loss on 8600 batch: 0.492204
Train loss on 8650 batch: 0.472126
Train loss on 8700 batch: 0.531203
Train loss on 8750 batch: 0.561793
----------------------------------------

Experiment N: 13: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
TRAINING STAGE: : old
date: 2019.08.25 22:41:29
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c7b8>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 13: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
TRAINING STAGE: : old
date: 2019.08.25 22:41:48
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d6d8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.008533
Train loss on 100 batch: 0.984735
Train loss on 150 batch: 0.878350
Train loss on 200 batch: 0.862789
Train loss on 250 batch: 0.787601
Train loss on 300 batch: 0.714090
Train loss on 350 batch: 0.719365
Train loss on 400 batch: 0.593321
Train loss on 450 batch: 0.692562
Train loss on 500 batch: 0.801028
Train loss on 550 batch: 0.798682
Train loss on 600 batch: 0.695287
Train loss on 650 batch: 0.823215
Train loss on 700 batch: 0.640527
Train loss on 750 batch: 0.650065
Train loss on 800 batch: 0.598696
Train loss on 850 batch: 0.707581
Train loss on 900 batch: 0.661523
----------------------------------------

Experiment N: 13: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet101


: 
TRAINING STAGE: : old
date: 2019.08.25 22:46:52
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10f7b8>
early-stopping-patience: 10
parameters-amount: 42502209
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.444736
----------------------------------------

Experiment N: 13: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet101


: 
TRAINING STAGE: : old
date: 2019.08.25 22:47:36
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d710>
early-stopping-patience: 10
parameters-amount: 42502209
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 13: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet101


: 
TRAINING STAGE: : old
date: 2019.08.25 22:48:05
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e6a0>
early-stopping-patience: 10
parameters-amount: 42502209
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.444736
Train loss on 100 batch: 1.160418
Train loss on 150 batch: 1.087471
Train loss on 200 batch: 0.981820
Train loss on 250 batch: 1.054453
Train loss on 300 batch: 0.843994
Train loss on 350 batch: 0.944902
Train loss on 400 batch: 0.870606
Train loss on 450 batch: 0.811433
Train loss on 500 batch: 0.990677
Train loss on 550 batch: 1.066134
Train loss on 600 batch: 0.942764
Train loss on 650 batch: 1.087327
Train loss on 700 batch: 0.980071
Train loss on 750 batch: 0.977644
Train loss on 800 batch: 0.914196
Train loss on 850 batch: 0.943083
Train loss on 900 batch: 0.959846
Train loss on 950 batch: 0.937250
Train loss on 1000 batch: 1.160524
Train loss on 1050 batch: 0.857830
Train loss on 1100 batch: 0.878783
Train loss on 1150 batch: 0.817113
Train loss on 1200 batch: 1.078167
Train loss on 1250 batch: 0.919118
Train loss on 1300 batch: 0.833327
Train loss on 1350 batch: 0.974919
Train loss on 1400 batch: 1.025374
Train loss on 1450 batch: 0.935085
Train loss on 1500 batch: 0.920544
Train loss on 1550 batch: 1.027999
Train loss on 1600 batch: 0.924929
Train loss on 1650 batch: 0.945914
Train loss on 1700 batch: 0.920116
Train loss on 1750 batch: 1.067243
Train loss on 1800 batch: 0.824384
Train loss on 1850 batch: 0.968614
Train loss on 1900 batch: 0.987398
Train loss on 1950 batch: 1.059015
Train loss on 2000 batch: 0.938279
Train loss on 2050 batch: 0.935787
Train loss on 2100 batch: 1.061256
Train loss on 2150 batch: 0.952777
Train loss on 2200 batch: 1.047944
Train loss on 2250 batch: 1.003985
Train loss on 2300 batch: 0.943969
Train loss on 2350 batch: 0.822138
Train loss on 2400 batch: 0.916319
Train loss on 2450 batch: 0.874985
Train loss on 2500 batch: 0.921287
Train loss on 2550 batch: 1.048197
Train loss on 2600 batch: 1.020805
Train loss on 2650 batch: 1.048157
Train loss on 2700 batch: 0.869343
Train loss on 2750 batch: 0.858742
Train loss on 2800 batch: 0.987525
Train loss on 2850 batch: 0.955870
Train loss on 2900 batch: 0.934097
best-train-loss: 0.973581
best-valid-loss: 1.869637
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 0.973581 | Val. Loss: 1.869637 | Val. Kappa Score: 0.0000 | Estimated time: 1158.32
Train loss on 50 batch: 1.008397
Train loss on 100 batch: 0.948176
Train loss on 150 batch: 1.023532
Train loss on 200 batch: 0.917073
Train loss on 250 batch: 0.887275
Train loss on 300 batch: 0.965470
Train loss on 350 batch: 0.970110
Train loss on 400 batch: 1.038962
Train loss on 450 batch: 0.936467
Train loss on 500 batch: 0.992989
Train loss on 550 batch: 0.928662
Train loss on 600 batch: 0.906799
Train loss on 650 batch: 0.935691
Train loss on 700 batch: 0.936282
Train loss on 750 batch: 0.972335
Train loss on 800 batch: 0.875626
Train loss on 850 batch: 0.970499
Train loss on 900 batch: 0.867304
Train loss on 950 batch: 0.961157
Train loss on 1000 batch: 0.924245
Train loss on 1050 batch: 1.002811
Train loss on 1100 batch: 0.880594
Train loss on 1150 batch: 0.871987
Train loss on 1200 batch: 0.963274
Train loss on 1250 batch: 0.881067
Train loss on 1300 batch: 1.001326
Train loss on 1350 batch: 0.939754
Train loss on 1400 batch: 0.991146
Train loss on 1450 batch: 0.891672
Train loss on 1500 batch: 0.893064
Train loss on 1550 batch: 0.932933
Train loss on 1600 batch: 0.929457
Train loss on 1650 batch: 0.911182
Train loss on 1700 batch: 0.905295
Train loss on 1750 batch: 0.974051
Train loss on 1800 batch: 1.226455
Train loss on 1850 batch: 1.038669
Train loss on 1900 batch: 0.874093
Train loss on 1950 batch: 0.964819
Train loss on 2000 batch: 1.048034
Train loss on 2050 batch: 0.922945
Train loss on 2100 batch: 1.022818
Train loss on 2150 batch: 0.835251
Train loss on 2200 batch: 1.042479
Train loss on 2250 batch: 0.862081
Train loss on 2300 batch: 1.063892
Train loss on 2350 batch: 0.992638
Train loss on 2400 batch: 0.944785
Train loss on 2450 batch: 0.874347
Train loss on 2500 batch: 1.177280
Train loss on 2550 batch: 0.954109
Train loss on 2600 batch: 0.849030
Train loss on 2650 batch: 0.947689
Train loss on 2700 batch: 0.852470
Train loss on 2750 batch: 0.943664
Train loss on 2800 batch: 0.951992
Train loss on 2850 batch: 1.154983
Train loss on 2900 batch: 1.027916
: Epoch: 2 | Training Loss: 0.956259 | Val. Loss: 2.106778 | Val. Kappa Score: 0.0000 | Estimated time: 1147.16
Train loss on 50 batch: 0.887796
Train loss on 100 batch: 0.951914
Train loss on 150 batch: 1.052600
Train loss on 200 batch: 0.831777
Train loss on 250 batch: 0.947311
Train loss on 300 batch: 0.958689
Train loss on 350 batch: 0.930377
Train loss on 400 batch: 0.937837
Train loss on 450 batch: 0.904561
Train loss on 500 batch: 1.048269
Train loss on 550 batch: 0.891701
Train loss on 600 batch: 0.804257
Train loss on 650 batch: 0.899325
Train loss on 700 batch: 1.088496
Train loss on 750 batch: 0.870451
Train loss on 800 batch: 0.888840
Train loss on 850 batch: 1.043231
Train loss on 900 batch: 1.023530
Train loss on 950 batch: 0.858561
Train loss on 1000 batch: 0.771627
Train loss on 1050 batch: 1.033906
Train loss on 1100 batch: 1.063216
Train loss on 1150 batch: 0.934533
Train loss on 1200 batch: 0.910231
Train loss on 1250 batch: 0.938803
Train loss on 1300 batch: 1.033010
Train loss on 1350 batch: 1.170930
Train loss on 1400 batch: 0.965571
Train loss on 1450 batch: 0.852584
Train loss on 1500 batch: 0.956024
Train loss on 1550 batch: 0.987278
Train loss on 1600 batch: 0.875553
Train loss on 1650 batch: 0.984285
Train loss on 1700 batch: 0.970718
Train loss on 1750 batch: 1.054969
Train loss on 1800 batch: 1.039934
Train loss on 1850 batch: 0.803826
Train loss on 1900 batch: 0.965416
Train loss on 1950 batch: 1.106329
Train loss on 2000 batch: 1.109262
Train loss on 2050 batch: 0.925849
Train loss on 2100 batch: 0.826559
Train loss on 2150 batch: 1.080041
Train loss on 2200 batch: 1.065858
Train loss on 2250 batch: 0.936687
Train loss on 2300 batch: 0.965178
Train loss on 2350 batch: 0.942827
Train loss on 2400 batch: 0.812992
Train loss on 2450 batch: 0.859716
Train loss on 2500 batch: 0.887670
Train loss on 2550 batch: 0.950412
Train loss on 2600 batch: 0.865161
Train loss on 2650 batch: 0.942514
Train loss on 2700 batch: 1.046651
Train loss on 2750 batch: 0.908589
Train loss on 2800 batch: 0.974336
Train loss on 2850 batch: 0.796159
Train loss on 2900 batch: 1.001233
: Epoch: 3 | Training Loss: 0.948799 | Val. Loss: 2.194795 | Val. Kappa Score: -0.0008 | Estimated time: 1145.70
Train loss on 50 batch: 0.939773
Train loss on 100 batch: 0.976648
Train loss on 150 batch: 0.991717
Train loss on 200 batch: 0.795139
Train loss on 250 batch: 0.996324
Train loss on 300 batch: 0.968051
Train loss on 350 batch: 1.058701
Train loss on 400 batch: 0.982125
Train loss on 450 batch: 0.948973
Train loss on 500 batch: 1.051029
Train loss on 550 batch: 0.824375
Train loss on 600 batch: 0.984846
Train loss on 650 batch: 0.953356
Train loss on 700 batch: 0.881015
Train loss on 750 batch: 1.138086
Train loss on 800 batch: 1.016592
Train loss on 850 batch: 0.996346
Train loss on 900 batch: 0.961358
Train loss on 950 batch: 1.057679
Train loss on 1000 batch: 0.983021
Train loss on 1050 batch: 0.784126
Train loss on 1100 batch: 1.039259
Train loss on 1150 batch: 0.934045
Train loss on 1200 batch: 0.973915
Train loss on 1250 batch: 0.914911
Train loss on 1300 batch: 0.977366
Train loss on 1350 batch: 1.083124
Train loss on 1400 batch: 0.956241
Train loss on 1450 batch: 0.967378
Train loss on 1500 batch: 0.924112
Train loss on 1550 batch: 0.964364
Train loss on 1600 batch: 0.961985
Train loss on 1650 batch: 0.934108
Train loss on 1700 batch: 0.922427
Train loss on 1750 batch: 0.992435
Train loss on 1800 batch: 0.875867
Train loss on 1850 batch: 0.900773
Train loss on 1900 batch: 0.983301
Train loss on 1950 batch: 0.984760
Train loss on 2000 batch: 0.831536
Train loss on 2050 batch: 0.931596
Train loss on 2100 batch: 0.857842
Train loss on 2150 batch: 0.828826
Train loss on 2200 batch: 0.971263
Train loss on 2250 batch: 1.117687
Train loss on 2300 batch: 1.020236
Train loss on 2350 batch: 0.931584
Train loss on 2400 batch: 0.948774
Train loss on 2450 batch: 0.890435
Train loss on 2500 batch: 0.901896
Train loss on 2550 batch: 0.868211
Train loss on 2600 batch: 0.983429
Train loss on 2650 batch: 0.876046
Train loss on 2700 batch: 0.864227
Train loss on 2750 batch: 0.941949
Train loss on 2800 batch: 0.842696
Train loss on 2850 batch: 0.939972
Train loss on 2900 batch: 0.829208
: Epoch: 4 | Training Loss: 0.945532 | Val. Loss: 2.063177 | Val. Kappa Score: 0.0261 | Estimated time: 1140.83
Train loss on 50 batch: 0.986573
Train loss on 100 batch: 0.904123
Train loss on 150 batch: 1.063492
Train loss on 200 batch: 0.968836
Train loss on 250 batch: 0.831664
Train loss on 300 batch: 0.916112
Train loss on 350 batch: 0.926836
Train loss on 400 batch: 0.926748
Train loss on 450 batch: 0.899071
Train loss on 500 batch: 0.847639
Train loss on 550 batch: 0.977076
Train loss on 600 batch: 0.923400
Train loss on 650 batch: 1.025452
Train loss on 700 batch: 0.866337
Train loss on 750 batch: 0.948897
Train loss on 800 batch: 0.841503
Train loss on 850 batch: 1.053145
Train loss on 900 batch: 0.907045
Train loss on 950 batch: 0.836987
Train loss on 1000 batch: 0.874866
Train loss on 1050 batch: 1.100181
Train loss on 1100 batch: 0.828438
Train loss on 1150 batch: 0.927464
Train loss on 1200 batch: 1.010500
Train loss on 1250 batch: 0.787293
Train loss on 1300 batch: 0.699072
Train loss on 1350 batch: 0.948733
Train loss on 1400 batch: 0.733877
Train loss on 1450 batch: 0.882164
Train loss on 1500 batch: 0.976737
Train loss on 1550 batch: 0.892522
Train loss on 1600 batch: 1.029145
Train loss on 1650 batch: 1.030644
Train loss on 1700 batch: 1.071328
Train loss on 1750 batch: 1.121240
Train loss on 1800 batch: 0.999374
Train loss on 1850 batch: 1.041813
Train loss on 1900 batch: 0.793820
Train loss on 1950 batch: 0.828637
Train loss on 2000 batch: 0.891219
Train loss on 2050 batch: 0.799748
Train loss on 2100 batch: 1.091352
Train loss on 2150 batch: 1.067017
Train loss on 2200 batch: 1.001535
Train loss on 2250 batch: 0.930744
Train loss on 2300 batch: 0.902050
Train loss on 2350 batch: 1.000720
Train loss on 2400 batch: 0.933898
Train loss on 2450 batch: 0.925729
Train loss on 2500 batch: 1.072746
Train loss on 2550 batch: 0.958085
Train loss on 2600 batch: 0.960689
Train loss on 2650 batch: 1.025335
Train loss on 2700 batch: 0.934321
Train loss on 2750 batch: 0.908831
Train loss on 2800 batch: 0.910217
Train loss on 2850 batch: 0.938932
Train loss on 2900 batch: 0.900710
: Epoch: 5 | Training Loss: 0.940840 | Val. Loss: 1.918614 | Val. Kappa Score: 0.0209 | Estimated time: 1141.95
Train loss on 50 batch: 0.880933
Train loss on 100 batch: 0.967329
Train loss on 150 batch: 1.035463
Train loss on 200 batch: 0.938177
Train loss on 250 batch: 0.973109
Train loss on 300 batch: 0.975966
Train loss on 350 batch: 0.807213
Train loss on 400 batch: 0.845222
Train loss on 450 batch: 0.932197
Train loss on 500 batch: 0.838372
Train loss on 550 batch: 0.846253
Train loss on 600 batch: 0.891301
Train loss on 650 batch: 0.889961
Train loss on 700 batch: 0.785895
Train loss on 750 batch: 0.954808
Train loss on 800 batch: 0.991523
Train loss on 850 batch: 0.885298
Train loss on 900 batch: 1.059245
Train loss on 950 batch: 0.988470
Train loss on 1000 batch: 1.056895
Train loss on 1050 batch: 0.885590
Train loss on 1100 batch: 0.912783
Train loss on 1150 batch: 0.941234
Train loss on 1200 batch: 0.947032
Train loss on 1250 batch: 0.884348
Train loss on 1300 batch: 0.837036
Train loss on 1350 batch: 0.816797
Train loss on 1400 batch: 0.967931
Train loss on 1450 batch: 1.040111
Train loss on 1500 batch: 0.988289
Train loss on 1550 batch: 0.840904
Train loss on 1600 batch: 0.905308
Train loss on 1650 batch: 0.826611
Train loss on 1700 batch: 0.934974
Train loss on 1750 batch: 0.981894
Train loss on 1800 batch: 0.793763
Train loss on 1850 batch: 0.971266
Train loss on 1900 batch: 0.963191
Train loss on 1950 batch: 0.978537
Train loss on 2000 batch: 0.969518
Train loss on 2050 batch: 0.986126
Train loss on 2100 batch: 0.957984
Train loss on 2150 batch: 1.028527
Train loss on 2200 batch: 0.969954
Train loss on 2250 batch: 1.100690
Train loss on 2300 batch: 0.860674
Train loss on 2350 batch: 0.992519
Train loss on 2400 batch: 0.898460
Train loss on 2450 batch: 0.915008
Train loss on 2500 batch: 0.883546
Train loss on 2550 batch: 0.947450
Train loss on 2600 batch: 0.857675
Train loss on 2650 batch: 0.879725
Train loss on 2700 batch: 0.832160
Train loss on 2750 batch: 1.016426
Train loss on 2800 batch: 0.879286
Train loss on 2850 batch: 1.277169
Train loss on 2900 batch: 0.957777
----------------------------------------

Experiment N: 14: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
TRAINING STAGE: : old
date: 2019.08.26 01:51:44
data-type: new_old_balanced_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e6d8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.056836
Train loss on 100 batch: 0.969318
Train loss on 150 batch: 0.985526
Train loss on 200 batch: 0.877110
Train loss on 250 batch: 0.781922
Train loss on 300 batch: 0.758603
Train loss on 350 batch: 0.766531
Train loss on 400 batch: 0.834468
Train loss on 450 batch: 0.841744
Train loss on 500 batch: 0.827771
Train loss on 550 batch: 0.718661
Train loss on 600 batch: 0.722217
Train loss on 650 batch: 0.802698
Train loss on 700 batch: 0.637656
Train loss on 750 batch: 0.779976
Train loss on 800 batch: 0.658603
Train loss on 850 batch: 0.711975
Train loss on 900 batch: 0.835266
Train loss on 950 batch: 0.692650
Train loss on 1000 batch: 0.694265
Train loss on 1050 batch: 0.741898
Train loss on 1100 batch: 0.692142
Train loss on 1150 batch: 0.655591
Train loss on 1200 batch: 0.685379
Train loss on 1250 batch: 0.628609
Train loss on 1300 batch: 0.599880
Train loss on 1350 batch: 0.597461
Train loss on 1400 batch: 0.613777
Train loss on 1450 batch: 0.723544
Train loss on 1500 batch: 0.787941
Train loss on 1550 batch: 0.687267
Train loss on 1600 batch: 0.666656
Train loss on 1650 batch: 0.588322
Train loss on 1700 batch: 0.680254
Train loss on 1750 batch: 0.654795
Train loss on 1800 batch: 0.607711
Train loss on 1850 batch: 0.614352
Train loss on 1900 batch: 0.637573
Train loss on 1950 batch: 0.654832
Train loss on 2000 batch: 0.648358
Train loss on 2050 batch: 0.475426
Train loss on 2100 batch: 0.633837
Train loss on 2150 batch: 0.652394
best-train-loss: 0.717004
best-valid-loss: 0.899689
best-kappa: 0.5327
: Epoch: 1 | Training Loss: 0.717004 | Val. Loss: 0.899689 | Val. Kappa Score: 0.5327 | Estimated time: 338.21
Train loss on 50 batch: 0.645541
Train loss on 100 batch: 0.645659
Train loss on 150 batch: 0.644590
Train loss on 200 batch: 0.604789
Train loss on 250 batch: 0.670907
Train loss on 300 batch: 0.701913
Train loss on 350 batch: 0.605221
Train loss on 400 batch: 0.589281
Train loss on 450 batch: 0.618138
Train loss on 500 batch: 0.658414
Train loss on 550 batch: 0.590098
Train loss on 600 batch: 0.600426
Train loss on 650 batch: 0.606257
Train loss on 700 batch: 0.584911
Train loss on 750 batch: 0.609926
Train loss on 800 batch: 0.629995
Train loss on 850 batch: 0.529401
Train loss on 900 batch: 0.632171
Train loss on 950 batch: 0.605613
Train loss on 1000 batch: 0.652224
Train loss on 1050 batch: 0.575388
Train loss on 1100 batch: 0.545823
Train loss on 1150 batch: 0.633781
Train loss on 1200 batch: 0.557831
Train loss on 1250 batch: 0.547320
Train loss on 1300 batch: 0.639010
Train loss on 1350 batch: 0.705169
Train loss on 1400 batch: 0.598375
Train loss on 1450 batch: 0.615725
Train loss on 1500 batch: 0.654081
Train loss on 1550 batch: 0.581645
Train loss on 1600 batch: 0.607684
Train loss on 1650 batch: 0.583889
Train loss on 1700 batch: 0.587745
Train loss on 1750 batch: 0.650544
Train loss on 1800 batch: 0.542880
Train loss on 1850 batch: 0.514765
Train loss on 1900 batch: 0.563629
Train loss on 1950 batch: 0.540093
Train loss on 2000 batch: 0.538826
Train loss on 2050 batch: 0.549486
Train loss on 2100 batch: 0.562304
Train loss on 2150 batch: 0.639531
best-train-loss: 0.604116
best-valid-loss: 0.606687
best-kappa: 0.6117
: Epoch: 2 | Training Loss: 0.604116 | Val. Loss: 0.606687 | Val. Kappa Score: 0.6117 | Estimated time: 334.82
Train loss on 50 batch: 0.523297
Train loss on 100 batch: 0.613379
Train loss on 150 batch: 0.535753
Train loss on 200 batch: 0.492406
Train loss on 250 batch: 0.530612
Train loss on 300 batch: 0.522739
Train loss on 350 batch: 0.558069
Train loss on 400 batch: 0.508573
Train loss on 450 batch: 0.555952
Train loss on 500 batch: 0.567870
Train loss on 550 batch: 0.614575
Train loss on 600 batch: 0.523854
Train loss on 650 batch: 0.638305
Train loss on 700 batch: 0.545415
Train loss on 750 batch: 0.502677
Train loss on 800 batch: 0.589527
Train loss on 850 batch: 0.596851
Train loss on 900 batch: 0.548749
Train loss on 950 batch: 0.597137
Train loss on 1000 batch: 0.558139
Train loss on 1050 batch: 0.646193
Train loss on 1100 batch: 0.559582
Train loss on 1150 batch: 0.556869
Train loss on 1200 batch: 0.540086
Train loss on 1250 batch: 0.594682
Train loss on 1300 batch: 0.599972
Train loss on 1350 batch: 0.583053
Train loss on 1400 batch: 0.574732
Train loss on 1450 batch: 0.627634
Train loss on 1500 batch: 0.541633
Train loss on 1550 batch: 0.564822
Train loss on 1600 batch: 0.487594
Train loss on 1650 batch: 0.643266
Train loss on 1700 batch: 0.596245
Train loss on 1750 batch: 0.489376
Train loss on 1800 batch: 0.506344
Train loss on 1850 batch: 0.484320
Train loss on 1900 batch: 0.522430
Train loss on 1950 batch: 0.604952
Train loss on 2000 batch: 0.599114
Train loss on 2050 batch: 0.595204
Train loss on 2100 batch: 0.591267
Train loss on 2150 batch: 0.555360
best-train-loss: 0.562542
best-valid-loss: 0.541251
best-kappa: 0.6661
: Epoch: 3 | Training Loss: 0.562542 | Val. Loss: 0.541251 | Val. Kappa Score: 0.6661 | Estimated time: 336.46
Train loss on 50 batch: 0.564911
Train loss on 100 batch: 0.637188
Train loss on 150 batch: 0.485534
Train loss on 200 batch: 0.548611
Train loss on 250 batch: 0.563231
Train loss on 300 batch: 0.545613
Train loss on 350 batch: 0.576759
Train loss on 400 batch: 0.549728
Train loss on 450 batch: 0.614809
Train loss on 500 batch: 0.566656
Train loss on 550 batch: 0.542229
Train loss on 600 batch: 0.585628
Train loss on 650 batch: 0.569049
Train loss on 700 batch: 0.613689
Train loss on 750 batch: 0.552460
Train loss on 800 batch: 0.562366
Train loss on 850 batch: 0.518700
Train loss on 900 batch: 0.499700
Train loss on 950 batch: 0.525161
Train loss on 1000 batch: 0.515645
Train loss on 1050 batch: 0.505351
Train loss on 1100 batch: 0.476324
Train loss on 1150 batch: 0.505947
Train loss on 1200 batch: 0.571333
Train loss on 1250 batch: 0.512893
Train loss on 1300 batch: 0.517480
Train loss on 1350 batch: 0.530051
Train loss on 1400 batch: 0.504489
Train loss on 1450 batch: 0.557031
Train loss on 1500 batch: 0.559023
Train loss on 1550 batch: 0.529708
Train loss on 1600 batch: 0.474073
Train loss on 1650 batch: 0.582996
Train loss on 1700 batch: 0.627067
Train loss on 1750 batch: 0.501855
Train loss on 1800 batch: 0.464327
Train loss on 1850 batch: 0.476603
Train loss on 1900 batch: 0.488300
Train loss on 1950 batch: 0.530493
Train loss on 2000 batch: 0.535834
Train loss on 2050 batch: 0.499260
Train loss on 2100 batch: 0.485366
Train loss on 2150 batch: 0.566303
: Epoch: 4 | Training Loss: 0.537765 | Val. Loss: 0.660361 | Val. Kappa Score: 0.6886 | Estimated time: 336.77
Train loss on 50 batch: 0.506996
Train loss on 100 batch: 0.605958
Train loss on 150 batch: 0.530620
Train loss on 200 batch: 0.580808
Train loss on 250 batch: 0.454354
Train loss on 300 batch: 0.497367
Train loss on 350 batch: 0.554152
Train loss on 400 batch: 0.463502
Train loss on 450 batch: 0.531767
Train loss on 500 batch: 0.520574
Train loss on 550 batch: 0.558216
Train loss on 600 batch: 0.561793
Train loss on 650 batch: 0.577004
Train loss on 700 batch: 0.510968
Train loss on 750 batch: 0.475147
Train loss on 800 batch: 0.572539
Train loss on 850 batch: 0.511568
Train loss on 900 batch: 0.619930
Train loss on 950 batch: 0.411217
Train loss on 1000 batch: 0.495893
Train loss on 1050 batch: 0.478567
Train loss on 1100 batch: 0.490998
Train loss on 1150 batch: 0.503651
Train loss on 1200 batch: 0.511205
Train loss on 1250 batch: 0.635393
Train loss on 1300 batch: 0.642587
Train loss on 1350 batch: 0.580446
Train loss on 1400 batch: 0.542377
Train loss on 1450 batch: 0.515916
Train loss on 1500 batch: 0.441721
Train loss on 1550 batch: 0.494955
Train loss on 1600 batch: 0.551231
Train loss on 1650 batch: 0.558123
Train loss on 1700 batch: 0.496975
Train loss on 1750 batch: 0.559216
Train loss on 1800 batch: 0.592651
Train loss on 1850 batch: 0.512618
Train loss on 1900 batch: 0.533231
Train loss on 1950 batch: 0.493391
Train loss on 2000 batch: 0.511077
Train loss on 2050 batch: 0.510224
Train loss on 2100 batch: 0.471288
Train loss on 2150 batch: 0.547271
best-train-loss: 0.528979
best-valid-loss: 0.527042
best-kappa: 0.7100
: Epoch: 5 | Training Loss: 0.528979 | Val. Loss: 0.527042 | Val. Kappa Score: 0.7100 | Estimated time: 335.96
Train loss on 50 batch: 0.468265
Train loss on 100 batch: 0.559951
Train loss on 150 batch: 0.487563
Train loss on 200 batch: 0.491581
Train loss on 250 batch: 0.524522
Train loss on 300 batch: 0.578138
Train loss on 350 batch: 0.480497
Train loss on 400 batch: 0.423003
Train loss on 450 batch: 0.591433
Train loss on 500 batch: 0.512767
Train loss on 550 batch: 0.441434
Train loss on 600 batch: 0.495644
Train loss on 650 batch: 0.505443
Train loss on 700 batch: 0.540379
Train loss on 750 batch: 0.545627
Train loss on 800 batch: 0.493992
Train loss on 850 batch: 0.504265
Train loss on 900 batch: 0.537719
Train loss on 950 batch: 0.514477
Train loss on 1000 batch: 0.477530
Train loss on 1050 batch: 0.430936
Train loss on 1100 batch: 0.508860
Train loss on 1150 batch: 0.485251
Train loss on 1200 batch: 0.504759
Train loss on 1250 batch: 0.531051
Train loss on 1300 batch: 0.509026
Train loss on 1350 batch: 0.451457
Train loss on 1400 batch: 0.484418
Train loss on 1450 batch: 0.520427
Train loss on 1500 batch: 0.548871
Train loss on 1550 batch: 0.573887
Train loss on 1600 batch: 0.601128
Train loss on 1650 batch: 0.516682
Train loss on 1700 batch: 0.493568
Train loss on 1750 batch: 0.540868
Train loss on 1800 batch: 0.587961
Train loss on 1850 batch: 0.492728
Train loss on 1900 batch: 0.443872
Train loss on 1950 batch: 0.535988
Train loss on 2000 batch: 0.465272
Train loss on 2050 batch: 0.464375
Train loss on 2100 batch: 0.580396
Train loss on 2150 batch: 0.582626
: Epoch: 6 | Training Loss: 0.513356 | Val. Loss: 0.650813 | Val. Kappa Score: 0.7234 | Estimated time: 335.86
Train loss on 50 batch: 0.484941
Train loss on 100 batch: 0.510097
Train loss on 150 batch: 0.489314
Train loss on 200 batch: 0.421938
Train loss on 250 batch: 0.497062
Train loss on 300 batch: 0.471637
Train loss on 350 batch: 0.450331
Train loss on 400 batch: 0.491278
Train loss on 450 batch: 0.444167
Train loss on 500 batch: 0.456334
Train loss on 550 batch: 0.564917
Train loss on 600 batch: 0.529166
Train loss on 650 batch: 0.501004
Train loss on 700 batch: 0.566109
Train loss on 750 batch: 0.513836
Train loss on 800 batch: 0.585427
Train loss on 850 batch: 0.468632
Train loss on 900 batch: 0.480864
Train loss on 950 batch: 0.453538
Train loss on 1000 batch: 0.547318
Train loss on 1050 batch: 0.443064
Train loss on 1100 batch: 0.550531
Train loss on 1150 batch: 0.516659
Train loss on 1200 batch: 0.470150
Train loss on 1250 batch: 0.561791
Train loss on 1300 batch: 0.501258
Train loss on 1350 batch: 0.513724
Train loss on 1400 batch: 0.471074
Train loss on 1450 batch: 0.475509
Train loss on 1500 batch: 0.439782
Train loss on 1550 batch: 0.453794
Train loss on 1600 batch: 0.465368
Train loss on 1650 batch: 0.493402
Train loss on 1700 batch: 0.483020
Train loss on 1750 batch: 0.529125
Train loss on 1800 batch: 0.492166
Train loss on 1850 batch: 0.547915
Train loss on 1900 batch: 0.493739
Train loss on 1950 batch: 0.486403
Train loss on 2000 batch: 0.527249
Train loss on 2050 batch: 0.567834
Train loss on 2100 batch: 0.557598
Train loss on 2150 batch: 0.560273
best-train-loss: 0.500219
best-valid-loss: 0.425711
best-kappa: 0.7402
: Epoch: 7 | Training Loss: 0.500219 | Val. Loss: 0.425711 | Val. Kappa Score: 0.7402 | Estimated time: 335.54
Train loss on 50 batch: 0.533571
Train loss on 100 batch: 0.565843
Train loss on 150 batch: 0.483851
Train loss on 200 batch: 0.538337
Train loss on 250 batch: 0.432886
Train loss on 300 batch: 0.478763
Train loss on 350 batch: 0.416793
Train loss on 400 batch: 0.481326
Train loss on 450 batch: 0.456490
Train loss on 500 batch: 0.493424
Train loss on 550 batch: 0.495894
Train loss on 600 batch: 0.539829
Train loss on 650 batch: 0.434194
Train loss on 700 batch: 0.490724
Train loss on 750 batch: 0.487069
Train loss on 800 batch: 0.448233
Train loss on 850 batch: 0.518950
Train loss on 900 batch: 0.477754
Train loss on 950 batch: 0.537061
Train loss on 1000 batch: 0.470092
Train loss on 1050 batch: 0.575052
Train loss on 1100 batch: 0.501459
Train loss on 1150 batch: 0.450966
Train loss on 1200 batch: 0.489655
Train loss on 1250 batch: 0.464052
Train loss on 1300 batch: 0.489842
Train loss on 1350 batch: 0.465593
Train loss on 1400 batch: 0.461359
Train loss on 1450 batch: 0.399708
Train loss on 1500 batch: 0.545621
Train loss on 1550 batch: 0.505341
Train loss on 1600 batch: 0.466354
Train loss on 1650 batch: 0.529882
Train loss on 1700 batch: 0.429205
Train loss on 1750 batch: 0.522238
Train loss on 1800 batch: 0.491172
Train loss on 1850 batch: 0.526905
Train loss on 1900 batch: 0.531530
Train loss on 1950 batch: 0.491949
Train loss on 2000 batch: 0.500707
Train loss on 2050 batch: 0.469191
Train loss on 2100 batch: 0.470776
Train loss on 2150 batch: 0.532066
: Epoch: 8 | Training Loss: 0.490473 | Val. Loss: 0.526505 | Val. Kappa Score: 0.7470 | Estimated time: 336.21
Train loss on 50 batch: 0.464459
Train loss on 100 batch: 0.507912
Train loss on 150 batch: 0.434688
Train loss on 200 batch: 0.442886
Train loss on 250 batch: 0.519339
Train loss on 300 batch: 0.463118
Train loss on 350 batch: 0.462105
Train loss on 400 batch: 0.545770
Train loss on 450 batch: 0.518020
Train loss on 500 batch: 0.403691
Train loss on 550 batch: 0.441891
Train loss on 600 batch: 0.505989
Train loss on 650 batch: 0.466947
Train loss on 700 batch: 0.555608
Train loss on 750 batch: 0.428934
Train loss on 800 batch: 0.464193
Train loss on 850 batch: 0.644128
Train loss on 900 batch: 0.503355
Train loss on 950 batch: 0.465570
Train loss on 1000 batch: 0.436444
Train loss on 1050 batch: 0.452794
Train loss on 1100 batch: 0.503207
Train loss on 1150 batch: 0.421688
Train loss on 1200 batch: 0.439133
Train loss on 1250 batch: 0.393877
Train loss on 1300 batch: 0.419631
Train loss on 1350 batch: 0.495278
Train loss on 1400 batch: 0.516413
Train loss on 1450 batch: 0.440229
Train loss on 1500 batch: 0.470583
Train loss on 1550 batch: 0.435546
Train loss on 1600 batch: 0.452270
Train loss on 1650 batch: 0.548069
Train loss on 1700 batch: 0.413138
Train loss on 1750 batch: 0.474428
Train loss on 1800 batch: 0.486912
Train loss on 1850 batch: 0.539068
Train loss on 1900 batch: 0.384730
Train loss on 1950 batch: 0.488333
Train loss on 2000 batch: 0.523216
Train loss on 2050 batch: 0.479370
Train loss on 2100 batch: 0.490244
Train loss on 2150 batch: 0.472859
best-train-loss: 0.476186
best-valid-loss: 0.423600
best-kappa: 0.7568
: Epoch: 9 | Training Loss: 0.476186 | Val. Loss: 0.423600 | Val. Kappa Score: 0.7568 | Estimated time: 336.63
Train loss on 50 batch: 0.504136
Train loss on 100 batch: 0.431273
Train loss on 150 batch: 0.492003
Train loss on 200 batch: 0.495488
Train loss on 250 batch: 0.457410
Train loss on 300 batch: 0.407460
Train loss on 350 batch: 0.520949
Train loss on 400 batch: 0.497756
Train loss on 450 batch: 0.557913
Train loss on 500 batch: 0.525276
Train loss on 550 batch: 0.465668
Train loss on 600 batch: 0.484539
Train loss on 650 batch: 0.443017
Train loss on 700 batch: 0.491911
Train loss on 750 batch: 0.506728
Train loss on 800 batch: 0.495590
Train loss on 850 batch: 0.438413
Train loss on 900 batch: 0.507864
Train loss on 950 batch: 0.408343
Train loss on 1000 batch: 0.530393
Train loss on 1050 batch: 0.443450
Train loss on 1100 batch: 0.426031
Train loss on 1150 batch: 0.418503
Train loss on 1200 batch: 0.466537
Train loss on 1250 batch: 0.491683
Train loss on 1300 batch: 0.412198
Train loss on 1350 batch: 0.446651
Train loss on 1400 batch: 0.502140
Train loss on 1450 batch: 0.471876
Train loss on 1500 batch: 0.392563
Train loss on 1550 batch: 0.530641
Train loss on 1600 batch: 0.416318
Train loss on 1650 batch: 0.450136
Train loss on 1700 batch: 0.436349
Train loss on 1750 batch: 0.414101
Train loss on 1800 batch: 0.487226
Train loss on 1850 batch: 0.490258
Train loss on 1900 batch: 0.372081
Train loss on 1950 batch: 0.525816
Train loss on 2000 batch: 0.507642
Train loss on 2050 batch: 0.551197
Train loss on 2100 batch: 0.578545
Train loss on 2150 batch: 0.453116
: Epoch: 10 | Training Loss: 0.473521 | Val. Loss: 0.619168 | Val. Kappa Score: 0.7580 | Estimated time: 335.61
Train loss on 50 batch: 0.506913
Train loss on 100 batch: 0.429899
Train loss on 150 batch: 0.429571
Train loss on 200 batch: 0.474403
Train loss on 250 batch: 0.444712
Train loss on 300 batch: 0.497153
Train loss on 350 batch: 0.562253
Train loss on 400 batch: 0.461900
Train loss on 450 batch: 0.477708
Train loss on 500 batch: 0.436942
Train loss on 550 batch: 0.521499
Train loss on 600 batch: 0.418552
Train loss on 650 batch: 0.472669
Train loss on 700 batch: 0.436454
Train loss on 750 batch: 0.408908
Train loss on 800 batch: 0.417748
Train loss on 850 batch: 0.511871
Train loss on 900 batch: 0.471233
Train loss on 950 batch: 0.501393
Train loss on 1000 batch: 0.447330
Train loss on 1050 batch: 0.445289
Train loss on 1100 batch: 0.431778
Train loss on 1150 batch: 0.462648
Train loss on 1200 batch: 0.413943
Train loss on 1250 batch: 0.437834
Train loss on 1300 batch: 0.472075
Train loss on 1350 batch: 0.391460
Train loss on 1400 batch: 0.521860
Train loss on 1450 batch: 0.490693
Train loss on 1500 batch: 0.437337
Train loss on 1550 batch: 0.481542
Train loss on 1600 batch: 0.540369
Train loss on 1650 batch: 0.433008
Train loss on 1700 batch: 0.434837
Train loss on 1750 batch: 0.467397
Train loss on 1800 batch: 0.511801
Train loss on 1850 batch: 0.483109
Train loss on 1900 batch: 0.492017
Train loss on 1950 batch: 0.527184
Train loss on 2000 batch: 0.441939
Train loss on 2050 batch: 0.431448
Train loss on 2100 batch: 0.453605
Train loss on 2150 batch: 0.474849
: Epoch: 11 | Training Loss: 0.464483 | Val. Loss: 0.738445 | Val. Kappa Score: 0.7586 | Estimated time: 334.69
Train loss on 50 batch: 0.438490
Train loss on 100 batch: 0.473532
Train loss on 150 batch: 0.475642
Train loss on 200 batch: 0.502572
Train loss on 250 batch: 0.415723
Train loss on 300 batch: 0.564630
Train loss on 350 batch: 0.434005
Train loss on 400 batch: 0.411523
Train loss on 450 batch: 0.416024
Train loss on 500 batch: 0.490175
Train loss on 550 batch: 0.518510
Train loss on 600 batch: 0.528802
Train loss on 650 batch: 0.461661
Train loss on 700 batch: 0.441556
Train loss on 750 batch: 0.473055
Train loss on 800 batch: 0.428533
Train loss on 850 batch: 0.367863
Train loss on 900 batch: 0.444369
Train loss on 950 batch: 0.510265
Train loss on 1000 batch: 0.427742
Train loss on 1050 batch: 0.481664
Train loss on 1100 batch: 0.365528
Train loss on 1150 batch: 0.478372
Train loss on 1200 batch: 0.444858
Train loss on 1250 batch: 0.455871
Train loss on 1300 batch: 0.460249
Train loss on 1350 batch: 0.525596
Train loss on 1400 batch: 0.416723
Train loss on 1450 batch: 0.420969
Train loss on 1500 batch: 0.406002
Train loss on 1550 batch: 0.462067
Train loss on 1600 batch: 0.521163
Train loss on 1650 batch: 0.528384
Train loss on 1700 batch: 0.487157
Train loss on 1750 batch: 0.453781
Train loss on 1800 batch: 0.434397
Train loss on 1850 batch: 0.416000
Train loss on 1900 batch: 0.460213
Train loss on 1950 batch: 0.465086
Train loss on 2000 batch: 0.402336
Train loss on 2050 batch: 0.430159
Train loss on 2100 batch: 0.505871
Train loss on 2150 batch: 0.519906
best-train-loss: 0.457911
best-valid-loss: 0.423066
best-kappa: 0.7643
: Epoch: 12 | Training Loss: 0.457911 | Val. Loss: 0.423066 | Val. Kappa Score: 0.7643 | Estimated time: 336.57
Train loss on 50 batch: 0.457469
Train loss on 100 batch: 0.440899
Train loss on 150 batch: 0.457429
Train loss on 200 batch: 0.451657
Train loss on 250 batch: 0.427069
Train loss on 300 batch: 0.474870
Train loss on 350 batch: 0.468057
Train loss on 400 batch: 0.495424
Train loss on 450 batch: 0.473125
Train loss on 500 batch: 0.374855
Train loss on 550 batch: 0.438988
Train loss on 600 batch: 0.368178
Train loss on 650 batch: 0.504598
Train loss on 700 batch: 0.518954
Train loss on 750 batch: 0.455810
Train loss on 800 batch: 0.486906
Train loss on 850 batch: 0.425987
Train loss on 900 batch: 0.408074
Train loss on 950 batch: 0.473661
Train loss on 1000 batch: 0.465016
Train loss on 1050 batch: 0.458940
Train loss on 1100 batch: 0.462538
Train loss on 1150 batch: 0.459930
Train loss on 1200 batch: 0.416155
Train loss on 1250 batch: 0.411188
Train loss on 1300 batch: 0.438957
Train loss on 1350 batch: 0.477454
Train loss on 1400 batch: 0.400157
Train loss on 1450 batch: 0.446686
Train loss on 1500 batch: 0.497850
Train loss on 1550 batch: 0.402865
Train loss on 1600 batch: 0.483250
Train loss on 1650 batch: 0.405401
Train loss on 1700 batch: 0.473545
Train loss on 1750 batch: 0.506842
Train loss on 1800 batch: 0.402943
Train loss on 1850 batch: 0.402695
Train loss on 1900 batch: 0.439601
Train loss on 1950 batch: 0.451238
Train loss on 2000 batch: 0.445539
Train loss on 2050 batch: 0.479881
Train loss on 2100 batch: 0.493165
Train loss on 2150 batch: 0.494050
: Epoch: 13 | Training Loss: 0.450820 | Val. Loss: 0.763677 | Val. Kappa Score: 0.7667 | Estimated time: 335.91
Train loss on 50 batch: 0.434510
Train loss on 100 batch: 0.507971
Train loss on 150 batch: 0.463137
Train loss on 200 batch: 0.465331
Train loss on 250 batch: 0.391582
Train loss on 300 batch: 0.489680
Train loss on 350 batch: 0.419288
Train loss on 400 batch: 0.458822
Train loss on 450 batch: 0.543800
Train loss on 500 batch: 0.459017
Train loss on 550 batch: 0.545473
Train loss on 600 batch: 0.416822
Train loss on 650 batch: 0.453333
Train loss on 700 batch: 0.400773
Train loss on 750 batch: 0.487494
Train loss on 800 batch: 0.423114
Train loss on 850 batch: 0.380532
Train loss on 900 batch: 0.389964
Train loss on 950 batch: 0.395542
Train loss on 1000 batch: 0.518786
Train loss on 1050 batch: 0.511931
Train loss on 1100 batch: 0.511534
Train loss on 1150 batch: 0.476173
Train loss on 1200 batch: 0.410312
Train loss on 1250 batch: 0.419755
Train loss on 1300 batch: 0.415468
Train loss on 1350 batch: 0.380729
Train loss on 1400 batch: 0.453618
Train loss on 1450 batch: 0.419558
Train loss on 1500 batch: 0.410246
Train loss on 1550 batch: 0.508919
Train loss on 1600 batch: 0.446908
Train loss on 1650 batch: 0.361327
Train loss on 1700 batch: 0.424652
Train loss on 1750 batch: 0.468145
Train loss on 1800 batch: 0.459268
Train loss on 1850 batch: 0.478512
Train loss on 1900 batch: 0.435160
Train loss on 1950 batch: 0.464006
Train loss on 2000 batch: 0.379655
Train loss on 2050 batch: 0.484884
Train loss on 2100 batch: 0.407018
Train loss on 2150 batch: 0.440050
: Epoch: 14 | Training Loss: 0.448293 | Val. Loss: 0.585352 | Val. Kappa Score: 0.7700 | Estimated time: 337.59
Train loss on 50 batch: 0.340564
Train loss on 100 batch: 0.365688
Train loss on 150 batch: 0.461113
Train loss on 200 batch: 0.415839
Train loss on 250 batch: 0.459893
Train loss on 300 batch: 0.364071
Train loss on 350 batch: 0.409057
Train loss on 400 batch: 0.410927
Train loss on 450 batch: 0.413923
Train loss on 500 batch: 0.397311
Train loss on 550 batch: 0.416076
Train loss on 600 batch: 0.444301
Train loss on 650 batch: 0.413695
Train loss on 700 batch: 0.470959
Train loss on 750 batch: 0.448207
Train loss on 800 batch: 0.459830
Train loss on 850 batch: 0.417544
Train loss on 900 batch: 0.412130
Train loss on 950 batch: 0.414008
Train loss on 1000 batch: 0.480576
Train loss on 1050 batch: 0.442357
Train loss on 1100 batch: 0.378709
Train loss on 1150 batch: 0.521130
Train loss on 1200 batch: 0.421979
Train loss on 1250 batch: 0.445727
Train loss on 1300 batch: 0.495878
Train loss on 1350 batch: 0.415989
Train loss on 1400 batch: 0.414394
Train loss on 1450 batch: 0.534830
Train loss on 1500 batch: 0.492637
Train loss on 1550 batch: 0.415915
Train loss on 1600 batch: 0.369327
Train loss on 1650 batch: 0.414790
Train loss on 1700 batch: 0.390476
Train loss on 1750 batch: 0.498184
Train loss on 1800 batch: 0.499191
Train loss on 1850 batch: 0.436118
Train loss on 1900 batch: 0.499942
Train loss on 1950 batch: 0.456943
Train loss on 2000 batch: 0.494911
Train loss on 2050 batch: 0.527320
Train loss on 2100 batch: 0.487367
Train loss on 2150 batch: 0.419711
: Epoch: 15 | Training Loss: 0.440450 | Val. Loss: 0.528791 | Val. Kappa Score: 0.7719 | Estimated time: 335.77
Train loss on 50 batch: 0.425212
Train loss on 100 batch: 0.438786
Train loss on 150 batch: 0.497080
Train loss on 200 batch: 0.486489
Train loss on 250 batch: 0.389195
Train loss on 300 batch: 0.387392
Train loss on 350 batch: 0.423202
Train loss on 400 batch: 0.366950
Train loss on 450 batch: 0.405319
Train loss on 500 batch: 0.455780
Train loss on 550 batch: 0.399429
Train loss on 600 batch: 0.357876
Train loss on 650 batch: 0.381169
Train loss on 700 batch: 0.354992
Train loss on 750 batch: 0.373257
Train loss on 800 batch: 0.347964
Train loss on 850 batch: 0.405876
Train loss on 900 batch: 0.420162
Train loss on 950 batch: 0.386361
Train loss on 1000 batch: 0.466247
Train loss on 1050 batch: 0.445254
Train loss on 1100 batch: 0.365342
Train loss on 1150 batch: 0.407499
Train loss on 1200 batch: 0.379482
Train loss on 1250 batch: 0.414196
Train loss on 1300 batch: 0.375842
Train loss on 1350 batch: 0.389321
Train loss on 1400 batch: 0.436246
Train loss on 1450 batch: 0.359939
Train loss on 1500 batch: 0.378860
Train loss on 1550 batch: 0.422461
Train loss on 1600 batch: 0.417186
Train loss on 1650 batch: 0.405947
Train loss on 1700 batch: 0.401684
Train loss on 1750 batch: 0.314533
Train loss on 1800 batch: 0.332067
Train loss on 1850 batch: 0.359453
Train loss on 1900 batch: 0.392820
Train loss on 1950 batch: 0.370342
Train loss on 2000 batch: 0.379575
Train loss on 2050 batch: 0.413393
Train loss on 2100 batch: 0.354807
Train loss on 2150 batch: 0.349910
: Epoch: 16 | Training Loss: 0.395976 | Val. Loss: 0.679205 | Val. Kappa Score: 0.7728 | Estimated time: 336.53
Train loss on 50 batch: 0.395845
Train loss on 100 batch: 0.357825
Train loss on 150 batch: 0.362213
Train loss on 200 batch: 0.349683
Train loss on 250 batch: 0.434279
Train loss on 300 batch: 0.426850
Train loss on 350 batch: 0.418725
Train loss on 400 batch: 0.325941
Train loss on 450 batch: 0.422432
Train loss on 500 batch: 0.408352
Train loss on 550 batch: 0.341824
Train loss on 600 batch: 0.364634
Train loss on 650 batch: 0.429763
Train loss on 700 batch: 0.400256
Train loss on 750 batch: 0.367228
Train loss on 800 batch: 0.418849
Train loss on 850 batch: 0.342110
Train loss on 900 batch: 0.379239
Train loss on 950 batch: 0.423445
Train loss on 1000 batch: 0.397577
Train loss on 1050 batch: 0.369371
Train loss on 1100 batch: 0.320405
Train loss on 1150 batch: 0.401761
Train loss on 1200 batch: 0.421420
Train loss on 1250 batch: 0.340214
Train loss on 1300 batch: 0.368880
Train loss on 1350 batch: 0.433912
Train loss on 1400 batch: 0.412828
Train loss on 1450 batch: 0.357478
Train loss on 1500 batch: 0.389356
Train loss on 1550 batch: 0.465205
Train loss on 1600 batch: 0.345158
Train loss on 1650 batch: 0.391585
Train loss on 1700 batch: 0.387571
Train loss on 1750 batch: 0.394277
Train loss on 1800 batch: 0.420647
Train loss on 1850 batch: 0.467498
Train loss on 1900 batch: 0.382775
Train loss on 1950 batch: 0.351574
Train loss on 2000 batch: 0.388203
Train loss on 2050 batch: 0.355543
Train loss on 2100 batch: 0.388900
Train loss on 2150 batch: 0.364145
: Epoch: 17 | Training Loss: 0.389098 | Val. Loss: 0.503562 | Val. Kappa Score: 0.7765 | Estimated time: 335.70
Train loss on 50 batch: 0.350713
Train loss on 100 batch: 0.380344
Train loss on 150 batch: 0.384551
Train loss on 200 batch: 0.463330
Train loss on 250 batch: 0.320883
Train loss on 300 batch: 0.399621
Train loss on 350 batch: 0.359303
Train loss on 400 batch: 0.363070
Train loss on 450 batch: 0.365821
Train loss on 500 batch: 0.347501
Train loss on 550 batch: 0.390959
Train loss on 600 batch: 0.375538
Train loss on 650 batch: 0.405433
Train loss on 700 batch: 0.345659
Train loss on 750 batch: 0.376454
Train loss on 800 batch: 0.380488
Train loss on 850 batch: 0.386991
Train loss on 900 batch: 0.385489
Train loss on 950 batch: 0.449215
Train loss on 1000 batch: 0.417223
Train loss on 1050 batch: 0.362493
Train loss on 1100 batch: 0.330817
Train loss on 1150 batch: 0.345590
Train loss on 1200 batch: 0.377505
Train loss on 1250 batch: 0.397708
Train loss on 1300 batch: 0.376624
Train loss on 1350 batch: 0.405148
Train loss on 1400 batch: 0.366531
Train loss on 1450 batch: 0.383800
Train loss on 1500 batch: 0.457674
Train loss on 1550 batch: 0.453108
Train loss on 1600 batch: 0.473003
Train loss on 1650 batch: 0.400918
Train loss on 1700 batch: 0.384752
Train loss on 1750 batch: 0.352911
Train loss on 1800 batch: 0.356074
Train loss on 1850 batch: 0.341666
Train loss on 1900 batch: 0.429649
Train loss on 1950 batch: 0.424188
Train loss on 2000 batch: 0.390148
Train loss on 2050 batch: 0.361339
Train loss on 2100 batch: 0.362820
Train loss on 2150 batch: 0.345512
best-train-loss: 0.383820
best-valid-loss: 0.386589
best-kappa: 0.7804
: Epoch: 18 | Training Loss: 0.383820 | Val. Loss: 0.386589 | Val. Kappa Score: 0.7804 | Estimated time: 334.46
Train loss on 50 batch: 0.328506
Train loss on 100 batch: 0.311766
Train loss on 150 batch: 0.374633
Train loss on 200 batch: 0.284987
Train loss on 250 batch: 0.436094
Train loss on 300 batch: 0.391441
Train loss on 350 batch: 0.428173
Train loss on 400 batch: 0.426935
Train loss on 450 batch: 0.375980
Train loss on 500 batch: 0.419414
Train loss on 550 batch: 0.378463
Train loss on 600 batch: 0.369563
Train loss on 650 batch: 0.386563
Train loss on 700 batch: 0.368786
Train loss on 750 batch: 0.373378
Train loss on 800 batch: 0.346251
Train loss on 850 batch: 0.398928
Train loss on 900 batch: 0.338221
Train loss on 950 batch: 0.400369
Train loss on 1000 batch: 0.350574
Train loss on 1050 batch: 0.389983
Train loss on 1100 batch: 0.405695
Train loss on 1150 batch: 0.343247
Train loss on 1200 batch: 0.384913
Train loss on 1250 batch: 0.356029
Train loss on 1300 batch: 0.407849
Train loss on 1350 batch: 0.397165
Train loss on 1400 batch: 0.384341
Train loss on 1450 batch: 0.408942
Train loss on 1500 batch: 0.371493
Train loss on 1550 batch: 0.407237
Train loss on 1600 batch: 0.422914
Train loss on 1650 batch: 0.357197
Train loss on 1700 batch: 0.348005
Train loss on 1750 batch: 0.409249
Train loss on 1800 batch: 0.411190
Train loss on 1850 batch: 0.387973
Train loss on 1900 batch: 0.321348
Train loss on 1950 batch: 0.373474
Train loss on 2000 batch: 0.326632
Train loss on 2050 batch: 0.373433
Train loss on 2100 batch: 0.313299
Train loss on 2150 batch: 0.367371
: Epoch: 19 | Training Loss: 0.375160 | Val. Loss: 0.429323 | Val. Kappa Score: 0.7838 | Estimated time: 334.11
Train loss on 50 batch: 0.354508
Train loss on 100 batch: 0.334392
Train loss on 150 batch: 0.376511
Train loss on 200 batch: 0.366589
Train loss on 250 batch: 0.397433
Train loss on 300 batch: 0.353360
Train loss on 350 batch: 0.308446
Train loss on 400 batch: 0.344042
Train loss on 450 batch: 0.370194
Train loss on 500 batch: 0.306027
Train loss on 550 batch: 0.405892
Train loss on 600 batch: 0.388660
Train loss on 650 batch: 0.382023
Train loss on 700 batch: 0.407585
Train loss on 750 batch: 0.448198
Train loss on 800 batch: 0.374071
Train loss on 850 batch: 0.340645
Train loss on 900 batch: 0.331693
Train loss on 950 batch: 0.417235
Train loss on 1000 batch: 0.353833
Train loss on 1050 batch: 0.374972
Train loss on 1100 batch: 0.382779
Train loss on 1150 batch: 0.382154
Train loss on 1200 batch: 0.340506
Train loss on 1250 batch: 0.330303
Train loss on 1300 batch: 0.406017
Train loss on 1350 batch: 0.431151
Train loss on 1400 batch: 0.384608
Train loss on 1450 batch: 0.366593
Train loss on 1500 batch: 0.389473
Train loss on 1550 batch: 0.357616
Train loss on 1600 batch: 0.353032
Train loss on 1650 batch: 0.346840
Train loss on 1700 batch: 0.420601
Train loss on 1750 batch: 0.376814
Train loss on 1800 batch: 0.382518
Train loss on 1850 batch: 0.332914
Train loss on 1900 batch: 0.358408
Train loss on 1950 batch: 0.384186
Train loss on 2000 batch: 0.396985
Train loss on 2050 batch: 0.382824
Train loss on 2100 batch: 0.439284
Train loss on 2150 batch: 0.356195
: Epoch: 20 | Training Loss: 0.373809 | Val. Loss: 0.443268 | Val. Kappa Score: 0.7863 | Estimated time: 337.39
Train loss on 50 batch: 0.344835
Train loss on 100 batch: 0.401481
Train loss on 150 batch: 0.406677
Train loss on 200 batch: 0.373511
Train loss on 250 batch: 0.370446
Train loss on 300 batch: 0.353263
Train loss on 350 batch: 0.395422
Train loss on 400 batch: 0.336925
Train loss on 450 batch: 0.397120
Train loss on 500 batch: 0.335087
Train loss on 550 batch: 0.349240
Train loss on 600 batch: 0.338462
Train loss on 650 batch: 0.362682
Train loss on 700 batch: 0.387272
Train loss on 750 batch: 0.388587
Train loss on 800 batch: 0.416034
Train loss on 850 batch: 0.374166
Train loss on 900 batch: 0.352289
Train loss on 950 batch: 0.433838
Train loss on 1000 batch: 0.350641
Train loss on 1050 batch: 0.320188
Train loss on 1100 batch: 0.336638
Train loss on 1150 batch: 0.392761
Train loss on 1200 batch: 0.336500
Train loss on 1250 batch: 0.333914
Train loss on 1300 batch: 0.347635
Train loss on 1350 batch: 0.405698
Train loss on 1400 batch: 0.350062
Train loss on 1450 batch: 0.381804
Train loss on 1500 batch: 0.374353
Train loss on 1550 batch: 0.367526
Train loss on 1600 batch: 0.380527
Train loss on 1650 batch: 0.331022
Train loss on 1700 batch: 0.377582
Train loss on 1750 batch: 0.402673
Train loss on 1800 batch: 0.351428
Train loss on 1850 batch: 0.383151
Train loss on 1900 batch: 0.324734
Train loss on 1950 batch: 0.377556
Train loss on 2000 batch: 0.372569
Train loss on 2050 batch: 0.393057
Train loss on 2100 batch: 0.345251
Train loss on 2150 batch: 0.394318
: Epoch: 21 | Training Loss: 0.368160 | Val. Loss: 0.523255 | Val. Kappa Score: 0.7879 | Estimated time: 335.16
Train loss on 50 batch: 0.334058
Train loss on 100 batch: 0.374328
Train loss on 150 batch: 0.336526
Train loss on 200 batch: 0.346520
Train loss on 250 batch: 0.337861
Train loss on 300 batch: 0.329961
Train loss on 350 batch: 0.297646
Train loss on 400 batch: 0.329139
Train loss on 450 batch: 0.309095
Train loss on 500 batch: 0.341159
Train loss on 550 batch: 0.324834
Train loss on 600 batch: 0.320546
Train loss on 650 batch: 0.366368
Train loss on 700 batch: 0.369199
Train loss on 750 batch: 0.315740
Train loss on 800 batch: 0.373317
Train loss on 850 batch: 0.308821
Train loss on 900 batch: 0.347464
Train loss on 950 batch: 0.393018
Train loss on 1000 batch: 0.311164
Train loss on 1050 batch: 0.331201
Train loss on 1100 batch: 0.346312
Train loss on 1150 batch: 0.401501
Train loss on 1200 batch: 0.364938
Train loss on 1250 batch: 0.355768
Train loss on 1300 batch: 0.339492
Train loss on 1350 batch: 0.395387
Train loss on 1400 batch: 0.362085
Train loss on 1450 batch: 0.350385
Train loss on 1500 batch: 0.331582
Train loss on 1550 batch: 0.304967
Train loss on 1600 batch: 0.321808
Train loss on 1650 batch: 0.337071
Train loss on 1700 batch: 0.336377
Train loss on 1750 batch: 0.345123
Train loss on 1800 batch: 0.377324
Train loss on 1850 batch: 0.304235
Train loss on 1900 batch: 0.340191
Train loss on 1950 batch: 0.386659
Train loss on 2000 batch: 0.349733
Train loss on 2050 batch: 0.383875
Train loss on 2100 batch: 0.350993
Train loss on 2150 batch: 0.294900
: Epoch: 22 | Training Loss: 0.343726 | Val. Loss: 0.591537 | Val. Kappa Score: 0.7888 | Estimated time: 334.44
Train loss on 50 batch: 0.330558
Train loss on 100 batch: 0.339703
Train loss on 150 batch: 0.328280
Train loss on 200 batch: 0.345335
Train loss on 250 batch: 0.303194
Train loss on 300 batch: 0.337355
Train loss on 350 batch: 0.337357
Train loss on 400 batch: 0.383589
Train loss on 450 batch: 0.352672
Train loss on 500 batch: 0.332923
Train loss on 550 batch: 0.318971
Train loss on 600 batch: 0.319544
Train loss on 650 batch: 0.332299
Train loss on 700 batch: 0.369351
Train loss on 750 batch: 0.292807
Train loss on 800 batch: 0.401694
Train loss on 850 batch: 0.328865
Train loss on 900 batch: 0.347445
Train loss on 950 batch: 0.296688
Train loss on 1000 batch: 0.341843
Train loss on 1050 batch: 0.329396
Train loss on 1100 batch: 0.288891
Train loss on 1150 batch: 0.351308
Train loss on 1200 batch: 0.356003
Train loss on 1250 batch: 0.369086
Train loss on 1300 batch: 0.338148
Train loss on 1350 batch: 0.372674
Train loss on 1400 batch: 0.332336
Train loss on 1450 batch: 0.349264
Train loss on 1500 batch: 0.336125
Train loss on 1550 batch: 0.337826
Train loss on 1600 batch: 0.287416
Train loss on 1650 batch: 0.341755
Train loss on 1700 batch: 0.330832
Train loss on 1750 batch: 0.332610
Train loss on 1800 batch: 0.318255
Train loss on 1850 batch: 0.362923
Train loss on 1900 batch: 0.314391
Train loss on 1950 batch: 0.364255
Train loss on 2000 batch: 0.329073
Train loss on 2050 batch: 0.295789
Train loss on 2100 batch: 0.317858
Train loss on 2150 batch: 0.383038
: Epoch: 23 | Training Loss: 0.336560 | Val. Loss: 0.539093 | Val. Kappa Score: 0.7904 | Estimated time: 336.32
Train loss on 50 batch: 0.324346
Train loss on 100 batch: 0.329276
Train loss on 150 batch: 0.273270
Train loss on 200 batch: 0.365254
Train loss on 250 batch: 0.307704
Train loss on 300 batch: 0.344316
Train loss on 350 batch: 0.296732
Train loss on 400 batch: 0.307610
Train loss on 450 batch: 0.355600
Train loss on 500 batch: 0.334138
Train loss on 550 batch: 0.330005
Train loss on 600 batch: 0.312008
Train loss on 650 batch: 0.270695
Train loss on 700 batch: 0.327339
Train loss on 750 batch: 0.354576
Train loss on 800 batch: 0.339758
Train loss on 850 batch: 0.368277
Train loss on 900 batch: 0.256938
Train loss on 950 batch: 0.370064
Train loss on 1000 batch: 0.318336
Train loss on 1050 batch: 0.283484
Train loss on 1100 batch: 0.367194
Train loss on 1150 batch: 0.401861
Train loss on 1200 batch: 0.328394
Train loss on 1250 batch: 0.356633
Train loss on 1300 batch: 0.364713
Train loss on 1350 batch: 0.300504
Train loss on 1400 batch: 0.319326
Train loss on 1450 batch: 0.289262
Train loss on 1500 batch: 0.334796
Train loss on 1550 batch: 0.366156
Train loss on 1600 batch: 0.314152
Train loss on 1650 batch: 0.340673
Train loss on 1700 batch: 0.336573
Train loss on 1750 batch: 0.352006
Train loss on 1800 batch: 0.319628
Train loss on 1850 batch: 0.339530
Train loss on 1900 batch: 0.322269
Train loss on 1950 batch: 0.326051
Train loss on 2000 batch: 0.358699
Train loss on 2050 batch: 0.329077
Train loss on 2100 batch: 0.299282
Train loss on 2150 batch: 0.329768
: Epoch: 24 | Training Loss: 0.329702 | Val. Loss: 0.578178 | Val. Kappa Score: 0.7911 | Estimated time: 335.10
Train loss on 50 batch: 0.262316
Train loss on 100 batch: 0.341884
Train loss on 150 batch: 0.336172
Train loss on 200 batch: 0.290897
Train loss on 250 batch: 0.315440
Train loss on 300 batch: 0.332375
Train loss on 350 batch: 0.357651
Train loss on 400 batch: 0.294581
Train loss on 450 batch: 0.295499
Train loss on 500 batch: 0.350335
Train loss on 550 batch: 0.291615
Train loss on 600 batch: 0.385025
Train loss on 650 batch: 0.326858
Train loss on 700 batch: 0.315185
Train loss on 750 batch: 0.307485
Train loss on 800 batch: 0.337455
Train loss on 850 batch: 0.293662
Train loss on 900 batch: 0.299410
Train loss on 950 batch: 0.287074
Train loss on 1000 batch: 0.265911
Train loss on 1050 batch: 0.316612
Train loss on 1100 batch: 0.343237
Train loss on 1150 batch: 0.308693
Train loss on 1200 batch: 0.288889
Train loss on 1250 batch: 0.371478
Train loss on 1300 batch: 0.302932
Train loss on 1350 batch: 0.274417
Train loss on 1400 batch: 0.291586
Train loss on 1450 batch: 0.333821
Train loss on 1500 batch: 0.307541
Train loss on 1550 batch: 0.343250
Train loss on 1600 batch: 0.353212
Train loss on 1650 batch: 0.302524
Train loss on 1700 batch: 0.311244
Train loss on 1750 batch: 0.341961
Train loss on 1800 batch: 0.276008
Train loss on 1850 batch: 0.308151
Train loss on 1900 batch: 0.277392
Train loss on 1950 batch: 0.273388
Train loss on 2000 batch: 0.320201
Train loss on 2050 batch: 0.346624
Train loss on 2100 batch: 0.341335
Train loss on 2150 batch: 0.344840
: Epoch: 25 | Training Loss: 0.315685 | Val. Loss: 0.585802 | Val. Kappa Score: 0.7919 | Estimated time: 337.28
Train loss on 50 batch: 0.276300
Train loss on 100 batch: 0.329898
Train loss on 150 batch: 0.333751
Train loss on 200 batch: 0.321524
Train loss on 250 batch: 0.335409
Train loss on 300 batch: 0.305169
Train loss on 350 batch: 0.354882
Train loss on 400 batch: 0.336375
Train loss on 450 batch: 0.310402
Train loss on 500 batch: 0.289097
Train loss on 550 batch: 0.332330
Train loss on 600 batch: 0.306600
Train loss on 650 batch: 0.341833
Train loss on 700 batch: 0.275305
Train loss on 750 batch: 0.283557
Train loss on 800 batch: 0.284808
Train loss on 850 batch: 0.365451
Train loss on 900 batch: 0.332103
Train loss on 950 batch: 0.276132
Train loss on 1000 batch: 0.241002
Train loss on 1050 batch: 0.292673
Train loss on 1100 batch: 0.351807
Train loss on 1150 batch: 0.346295
Train loss on 1200 batch: 0.367088
Train loss on 1250 batch: 0.315024
Train loss on 1300 batch: 0.282847
Train loss on 1350 batch: 0.347924
Train loss on 1400 batch: 0.363699
Train loss on 1450 batch: 0.321642
Train loss on 1500 batch: 0.289922
Train loss on 1550 batch: 0.253244
Train loss on 1600 batch: 0.276216
Train loss on 1650 batch: 0.329835
Train loss on 1700 batch: 0.322761
Train loss on 1750 batch: 0.287420
Train loss on 1800 batch: 0.320405
Train loss on 1850 batch: 0.303947
Train loss on 1900 batch: 0.324715
Train loss on 1950 batch: 0.280405
Train loss on 2000 batch: 0.359669
Train loss on 2050 batch: 0.313823
Train loss on 2100 batch: 0.301922
Train loss on 2150 batch: 0.301254
: Epoch: 26 | Training Loss: 0.313243 | Val. Loss: 0.531077 | Val. Kappa Score: 0.7931 | Estimated time: 335.75
Train loss on 50 batch: 0.310211
Train loss on 100 batch: 0.355966
Train loss on 150 batch: 0.283737
Train loss on 200 batch: 0.294997
Train loss on 250 batch: 0.350070
Train loss on 300 batch: 0.290778
Train loss on 350 batch: 0.329764
Train loss on 400 batch: 0.270791
Train loss on 450 batch: 0.286242
Train loss on 500 batch: 0.327200
Train loss on 550 batch: 0.260334
Train loss on 600 batch: 0.294636
Train loss on 650 batch: 0.275272
Train loss on 700 batch: 0.347822
Train loss on 750 batch: 0.358561
Train loss on 800 batch: 0.290962
Train loss on 850 batch: 0.293747
Train loss on 900 batch: 0.337303
Train loss on 950 batch: 0.370424
Train loss on 1000 batch: 0.287322
Train loss on 1050 batch: 0.331304
Train loss on 1100 batch: 0.293805
Train loss on 1150 batch: 0.298187
Train loss on 1200 batch: 0.289782
Train loss on 1250 batch: 0.313388
Train loss on 1300 batch: 0.301149
Train loss on 1350 batch: 0.335480
Train loss on 1400 batch: 0.349094
Train loss on 1450 batch: 0.316934
Train loss on 1500 batch: 0.272359
Train loss on 1550 batch: 0.280805
Train loss on 1600 batch: 0.280496
Train loss on 1650 batch: 0.274432
Train loss on 1700 batch: 0.342453
Train loss on 1750 batch: 0.342642
Train loss on 1800 batch: 0.326509
Train loss on 1850 batch: 0.285145
Train loss on 1900 batch: 0.291998
Train loss on 1950 batch: 0.313699
Train loss on 2000 batch: 0.303025
Train loss on 2050 batch: 0.302055
Train loss on 2100 batch: 0.378494
Train loss on 2150 batch: 0.336258
: Epoch: 27 | Training Loss: 0.311445 | Val. Loss: 0.418729 | Val. Kappa Score: 0.7951 | Estimated time: 335.15
Train loss on 50 batch: 0.312986
Train loss on 100 batch: 0.300864
Train loss on 150 batch: 0.357035
Train loss on 200 batch: 0.266354
Train loss on 250 batch: 0.331480
Train loss on 300 batch: 0.274147
Train loss on 350 batch: 0.328888
Train loss on 400 batch: 0.301159
Train loss on 450 batch: 0.276312
Train loss on 500 batch: 0.256616
Train loss on 550 batch: 0.346737
Train loss on 600 batch: 0.323355
Train loss on 650 batch: 0.291934
Train loss on 700 batch: 0.268543
Train loss on 750 batch: 0.317250
Train loss on 800 batch: 0.345383
Train loss on 850 batch: 0.275589
Train loss on 900 batch: 0.361673
Train loss on 950 batch: 0.342482
Train loss on 1000 batch: 0.269589
Train loss on 1050 batch: 0.279249
Train loss on 1100 batch: 0.298715
Train loss on 1150 batch: 0.288780
Train loss on 1200 batch: 0.318867
Train loss on 1250 batch: 0.274602
Train loss on 1300 batch: 0.326675
Train loss on 1350 batch: 0.273591
Train loss on 1400 batch: 0.271585
Train loss on 1450 batch: 0.307028
Train loss on 1500 batch: 0.287524
Train loss on 1550 batch: 0.305053
Train loss on 1600 batch: 0.243319
Train loss on 1650 batch: 0.298177
Train loss on 1700 batch: 0.331267
Train loss on 1750 batch: 0.273392
Train loss on 1800 batch: 0.304529
Train loss on 1850 batch: 0.343339
Train loss on 1900 batch: 0.239989
Train loss on 1950 batch: 0.264293
Train loss on 2000 batch: 0.288616
Train loss on 2050 batch: 0.292283
Train loss on 2100 batch: 0.303448
Train loss on 2150 batch: 0.341307
: Epoch: 28 | Training Loss: 0.300114 | Val. Loss: 0.493574 | Val. Kappa Score: 0.7967 | Estimated time: 335.80
time_estimated: 9406.29
n-epochs: 28
time_estimated: 9406.30
----------------------------------------

Experiment N: 15: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
TRAINING STAGE: : old
date: 2019.08.26 14:36:00
data-type: new_old
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a5c0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
