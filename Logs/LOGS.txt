----------------------------------------

date: 2019.08.05 23:20:37
data-type: 
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 15
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.021080
Train loss on 50 batch: 0.568937
Train loss on 75 batch: 0.467596
best-train-loss: 0.685871
best-valid-loss: 0.405802
best-kappa: 0.5765
: Epoch: 1 | Training Loss: 0.685871 | Val. Loss: 0.405802 | Val. Kappa Score: 0.5765 | Estimated time: 32.22
Train loss on 25 batch: 0.294227
Train loss on 50 batch: 0.417146
Train loss on 75 batch: 0.310886
best-train-loss: 0.340753
best-valid-loss: 0.329401
best-kappa: 0.6176
: Epoch: 2 | Training Loss: 0.340753 | Val. Loss: 0.329401 | Val. Kappa Score: 0.6176 | Estimated time: 32.83
Train loss on 25 batch: 0.235554
Train loss on 50 batch: 0.310407
Train loss on 75 batch: 0.246925
: Epoch: 3 | Training Loss: 0.264295 | Val. Loss: 0.445808 | Val. Kappa Score: 0.6006 | Estimated time: 32.73
Train loss on 25 batch: 0.210998
Train loss on 50 batch: 0.249383
Train loss on 75 batch: 0.174025
: Epoch: 4 | Training Loss: 0.211469 | Val. Loss: 0.367638 | Val. Kappa Score: 0.6045 | Estimated time: 32.63
Train loss on 25 batch: 0.200852
Train loss on 50 batch: 0.194220
Train loss on 75 batch: 0.164910
: Epoch: 5 | Training Loss: 0.186661 | Val. Loss: 0.366342 | Val. Kappa Score: 0.6141 | Estimated time: 33.29
Train loss on 25 batch: 0.176481
Train loss on 50 batch: 0.138044
Train loss on 75 batch: 0.154058
: Epoch: 6 | Training Loss: 0.156194 | Val. Loss: 0.359860 | Val. Kappa Score: 0.6150 | Estimated time: 32.55
Train loss on 25 batch: 0.136368
Train loss on 50 batch: 0.110207
Train loss on 75 batch: 0.114789
: Epoch: 7 | Training Loss: 0.120455 | Val. Loss: 0.429435 | Val. Kappa Score: 0.6095 | Estimated time: 32.60
Train loss on 25 batch: 0.112098
Train loss on 50 batch: 0.100773
Train loss on 75 batch: 0.105986
: Epoch: 8 | Training Loss: 0.106286 | Val. Loss: 0.370006 | Val. Kappa Score: 0.6052 | Estimated time: 32.54
Train loss on 25 batch: 0.082635
Train loss on 50 batch: 0.109628
Train loss on 75 batch: 0.094662
: Epoch: 9 | Training Loss: 0.095642 | Val. Loss: 0.339616 | Val. Kappa Score: 0.6079 | Estimated time: 33.33
Train loss on 25 batch: 0.081668
Train loss on 50 batch: 0.072722
Train loss on 75 batch: 0.087220
: Epoch: 10 | Training Loss: 0.080537 | Val. Loss: 0.341263 | Val. Kappa Score: 0.6094 | Estimated time: 32.77
time_estimated: 327.82
n-epochs: 10
time_estimated: 327.82
----------------------------------------

date: 2019.08.05 23:26:32
data-type: 
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 15
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.065694
Train loss on 50 batch: 0.581047
Train loss on 75 batch: 0.467959
best-train-loss: 0.704900
best-valid-loss: 0.357303
best-kappa: 0.5810
: Epoch: 1 | Training Loss: 0.704900 | Val. Loss: 0.357303 | Val. Kappa Score: 0.5810 | Estimated time: 32.33
----------------------------------------

date: 2019.08.05 23:29:59
data-type: 
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 15
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.909976
Train loss on 50 batch: 0.536030
Train loss on 75 batch: 0.482577
best-train-loss: 0.642861
best-valid-loss: 0.444819
best-kappa: 0.5235
: Epoch: 1 | Training Loss: 0.642861 | Val. Loss: 0.444819 | Val. Kappa Score: 0.5235 | Estimated time: 32.62
Train loss on 25 batch: 0.280182
Train loss on 50 batch: 0.442702
Train loss on 75 batch: 0.331886
best-train-loss: 0.351590
best-valid-loss: 0.348497
best-kappa: 0.5525
: Epoch: 2 | Training Loss: 0.351590 | Val. Loss: 0.348497 | Val. Kappa Score: 0.5525 | Estimated time: 33.64
Train loss on 25 batch: 0.244896
Train loss on 50 batch: 0.297663
Train loss on 75 batch: 0.259664
: Epoch: 3 | Training Loss: 0.267408 | Val. Loss: 0.388869 | Val. Kappa Score: 0.5595 | Estimated time: 33.36
Train loss on 25 batch: 0.221811
Train loss on 50 batch: 0.215310
Train loss on 75 batch: 0.180531
: Epoch: 4 | Training Loss: 0.205884 | Val. Loss: 0.360883 | Val. Kappa Score: 0.5686 | Estimated time: 32.49
Train loss on 25 batch: 0.186980
Train loss on 50 batch: 0.168055
Train loss on 75 batch: 0.165554
best-train-loss: 0.173530
best-valid-loss: 0.323613
best-kappa: 0.5826
: Epoch: 5 | Training Loss: 0.173530 | Val. Loss: 0.323613 | Val. Kappa Score: 0.5826 | Estimated time: 33.25
Train loss on 25 batch: 0.148535
Train loss on 50 batch: 0.130657
Train loss on 75 batch: 0.160270
: Epoch: 6 | Training Loss: 0.146487 | Val. Loss: 0.358213 | Val. Kappa Score: 0.5926 | Estimated time: 32.19
Train loss on 25 batch: 0.133970
Train loss on 50 batch: 0.130792
Train loss on 75 batch: 0.116552
best-train-loss: 0.127105
best-valid-loss: 0.312844
best-kappa: 0.6027
: Epoch: 7 | Training Loss: 0.127105 | Val. Loss: 0.312844 | Val. Kappa Score: 0.6027 | Estimated time: 32.45
Train loss on 25 batch: 0.109873
Train loss on 50 batch: 0.144357
Train loss on 75 batch: 0.117573
best-train-loss: 0.123934
best-valid-loss: 0.298256
best-kappa: 0.6095
: Epoch: 8 | Training Loss: 0.123934 | Val. Loss: 0.298256 | Val. Kappa Score: 0.6095 | Estimated time: 34.57
Train loss on 25 batch: 0.066862
Train loss on 50 batch: 0.103183
Train loss on 75 batch: 0.116625
: Epoch: 9 | Training Loss: 0.095557 | Val. Loss: 0.326622 | Val. Kappa Score: 0.6167 | Estimated time: 33.66
Train loss on 25 batch: 0.074280
Train loss on 50 batch: 0.077932
Train loss on 75 batch: 0.102799
: Epoch: 10 | Training Loss: 0.085004 | Val. Loss: 0.331563 | Val. Kappa Score: 0.6200 | Estimated time: 32.78
Train loss on 25 batch: 0.065935
Train loss on 50 batch: 0.065332
Train loss on 75 batch: 0.106686
: Epoch: 11 | Training Loss: 0.079318 | Val. Loss: 0.437912 | Val. Kappa Score: 0.6132 | Estimated time: 33.11
Train loss on 25 batch: 0.101432
Train loss on 50 batch: 0.056934
Train loss on 75 batch: 0.070905
: Epoch: 12 | Training Loss: 0.076424 | Val. Loss: 0.482125 | Val. Kappa Score: 0.6037 | Estimated time: 33.71
Train loss on 25 batch: 0.163777
Train loss on 50 batch: 0.090855
Train loss on 75 batch: 0.061769
: Epoch: 13 | Training Loss: 0.105467 | Val. Loss: 0.313358 | Val. Kappa Score: 0.6080 | Estimated time: 34.08
Train loss on 25 batch: 0.135733
Train loss on 50 batch: 0.098944
Train loss on 75 batch: 0.073088
: Epoch: 14 | Training Loss: 0.102589 | Val. Loss: 0.343891 | Val. Kappa Score: 0.6096 | Estimated time: 33.73
Train loss on 25 batch: 0.114260
Train loss on 50 batch: 0.089526
Train loss on 75 batch: 0.065735
: Epoch: 15 | Training Loss: 0.089840 | Val. Loss: 0.361561 | Val. Kappa Score: 0.6115 | Estimated time: 34.07
time_estimated: 500.88
----------------------------------------

Experiment N: 3: 
date: 2019.08.05 23:43:43
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 10
parameters-amount: 44599361
n-epochs: 50
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.855013
Train loss on 50 batch: 0.524103
Train loss on 75 batch: 0.472575
best-train-loss: 0.617230
best-valid-loss: 0.343498
best-kappa: 0.6288
: Epoch: 1 | Training Loss: 0.617230 | Val. Loss: 0.343498 | Val. Kappa Score: 0.6288 | Estimated time: 34.43
Train loss on 25 batch: 0.292851
Train loss on 50 batch: 0.409704
Train loss on 75 batch: 0.293402
: Epoch: 2 | Training Loss: 0.331986 | Val. Loss: 0.368891 | Val. Kappa Score: 0.6259 | Estimated time: 34.64
Train loss on 25 batch: 0.257287
Train loss on 50 batch: 0.282074
Train loss on 75 batch: 0.223019
: Epoch: 3 | Training Loss: 0.254126 | Val. Loss: 0.453602 | Val. Kappa Score: 0.6115 | Estimated time: 34.96
Train loss on 25 batch: 0.234189
Train loss on 50 batch: 0.199468
Train loss on 75 batch: 0.173046
: Epoch: 4 | Training Loss: 0.202234 | Val. Loss: 0.363635 | Val. Kappa Score: 0.6079 | Estimated time: 34.32
Train loss on 25 batch: 0.160608
Train loss on 50 batch: 0.173438
Train loss on 75 batch: 0.141531
: Epoch: 5 | Training Loss: 0.158526 | Val. Loss: 0.345910 | Val. Kappa Score: 0.6165 | Estimated time: 33.19
Train loss on 25 batch: 0.160709
Train loss on 50 batch: 0.135599
Train loss on 75 batch: 0.143887
: Epoch: 6 | Training Loss: 0.146732 | Val. Loss: 0.377198 | Val. Kappa Score: 0.6202 | Estimated time: 34.17
Train loss on 25 batch: 0.119477
Train loss on 50 batch: 0.127407
Train loss on 75 batch: 0.124111
: Epoch: 7 | Training Loss: 0.123665 | Val. Loss: 0.371382 | Val. Kappa Score: 0.6299 | Estimated time: 34.93
Train loss on 25 batch: 0.134855
Train loss on 50 batch: 0.109445
Train loss on 75 batch: 0.126610
best-train-loss: 0.123637
best-valid-loss: 0.318295
best-kappa: 0.6324
: Epoch: 8 | Training Loss: 0.123637 | Val. Loss: 0.318295 | Val. Kappa Score: 0.6324 | Estimated time: 34.36
Train loss on 25 batch: 0.084243
Train loss on 50 batch: 0.097879
Train loss on 75 batch: 0.094992
: Epoch: 9 | Training Loss: 0.092371 | Val. Loss: 0.325424 | Val. Kappa Score: 0.6352 | Estimated time: 34.67
Train loss on 25 batch: 0.065759
Train loss on 50 batch: 0.075437
Train loss on 75 batch: 0.077907
best-train-loss: 0.073034
best-valid-loss: 0.316579
best-kappa: 0.6370
: Epoch: 10 | Training Loss: 0.073034 | Val. Loss: 0.316579 | Val. Kappa Score: 0.6370 | Estimated time: 35.16
Train loss on 25 batch: 0.069062
Train loss on 50 batch: 0.056719
Train loss on 75 batch: 0.074153
: Epoch: 11 | Training Loss: 0.066645 | Val. Loss: 0.430701 | Val. Kappa Score: 0.6144 | Estimated time: 35.67
Train loss on 25 batch: 0.066250
Train loss on 50 batch: 0.057497
Train loss on 75 batch: 0.080020
: Epoch: 12 | Training Loss: 0.067923 | Val. Loss: 0.347795 | Val. Kappa Score: 0.6142 | Estimated time: 34.97
Train loss on 25 batch: 0.096587
Train loss on 50 batch: 0.061736
Train loss on 75 batch: 0.070797
: Epoch: 13 | Training Loss: 0.076373 | Val. Loss: 0.330075 | Val. Kappa Score: 0.6174 | Estimated time: 34.69
Train loss on 25 batch: 0.133814
Train loss on 50 batch: 0.067120
Train loss on 75 batch: 0.047737
: Epoch: 14 | Training Loss: 0.082890 | Val. Loss: 0.320868 | Val. Kappa Score: 0.6195 | Estimated time: 34.62
Train loss on 25 batch: 0.112175
Train loss on 50 batch: 0.064022
Train loss on 75 batch: 0.040416
: Epoch: 15 | Training Loss: 0.072204 | Val. Loss: 0.328183 | Val. Kappa Score: 0.6209 | Estimated time: 34.43
Train loss on 25 batch: 0.107857
Train loss on 50 batch: 0.080141
Train loss on 75 batch: 0.072293
: Epoch: 16 | Training Loss: 0.086764 | Val. Loss: 0.331790 | Val. Kappa Score: 0.6234 | Estimated time: 34.52
Train loss on 25 batch: 0.126716
Train loss on 50 batch: 0.113190
Train loss on 75 batch: 0.092853
: Epoch: 17 | Training Loss: 0.110920 | Val. Loss: 0.351704 | Val. Kappa Score: 0.6259 | Estimated time: 34.19
Train loss on 25 batch: 0.100328
Train loss on 50 batch: 0.111155
Train loss on 75 batch: 0.093969
: Epoch: 18 | Training Loss: 0.101817 | Val. Loss: 0.449094 | Val. Kappa Score: 0.6246 | Estimated time: 33.83
Train loss on 25 batch: 0.135840
Train loss on 50 batch: 0.108216
Train loss on 75 batch: 0.073681
: Epoch: 19 | Training Loss: 0.105913 | Val. Loss: 0.409215 | Val. Kappa Score: 0.6240 | Estimated time: 33.89
Train loss on 25 batch: 0.090572
Train loss on 50 batch: 0.083283
Train loss on 75 batch: 0.051163
: Epoch: 20 | Training Loss: 0.075006 | Val. Loss: 0.357250 | Val. Kappa Score: 0.6253 | Estimated time: 34.67
time_estimated: 690.71
n-epochs: 20
time_estimated: 690.71
----------------------------------------

Experiment N: 4: 
date: 2019.08.05 23:55:42
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 10
parameters-amount: 44599361
n-epochs: 50
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.925301
Train loss on 50 batch: 0.566351
Train loss on 75 batch: 0.461882
best-train-loss: 0.651178
best-valid-loss: 0.372516
best-kappa: 0.5517
: Epoch: 1 | Training Loss: 0.651178 | Val. Loss: 0.372516 | Val. Kappa Score: 0.5517 | Estimated time: 33.99
Train loss on 25 batch: 0.299813
Train loss on 50 batch: 0.435008
Train loss on 75 batch: 0.335888
: Epoch: 2 | Training Loss: 0.356903 | Val. Loss: 0.375164 | Val. Kappa Score: 0.5889 | Estimated time: 32.51
Train loss on 25 batch: 0.265776
Train loss on 50 batch: 0.273220
Train loss on 75 batch: 0.249039
best-train-loss: 0.262678
best-valid-loss: 0.360661
best-kappa: 0.5852
: Epoch: 3 | Training Loss: 0.262678 | Val. Loss: 0.360661 | Val. Kappa Score: 0.5852 | Estimated time: 33.72
Train loss on 25 batch: 0.217595
Train loss on 50 batch: 0.209602
Train loss on 75 batch: 0.201454
best-train-loss: 0.209550
best-valid-loss: 0.349786
best-kappa: 0.5813
: Epoch: 4 | Training Loss: 0.209550 | Val. Loss: 0.349786 | Val. Kappa Score: 0.5813 | Estimated time: 34.22
Train loss on 25 batch: 0.169699
Train loss on 50 batch: 0.163804
Train loss on 75 batch: 0.160156
best-train-loss: 0.164553
best-valid-loss: 0.345696
best-kappa: 0.5982
: Epoch: 5 | Training Loss: 0.164553 | Val. Loss: 0.345696 | Val. Kappa Score: 0.5982 | Estimated time: 34.10
Train loss on 25 batch: 0.137086
Train loss on 50 batch: 0.121317
Train loss on 75 batch: 0.152539
best-train-loss: 0.136981
best-valid-loss: 0.303939
best-kappa: 0.6071
: Epoch: 6 | Training Loss: 0.136981 | Val. Loss: 0.303939 | Val. Kappa Score: 0.6071 | Estimated time: 32.66
Train loss on 25 batch: 0.106037
Train loss on 50 batch: 0.116354
Train loss on 75 batch: 0.107541
: Epoch: 7 | Training Loss: 0.109977 | Val. Loss: 0.316695 | Val. Kappa Score: 0.6177 | Estimated time: 33.64
Train loss on 25 batch: 0.100152
Train loss on 50 batch: 0.101385
Train loss on 75 batch: 0.126032
: Epoch: 8 | Training Loss: 0.109190 | Val. Loss: 0.335842 | Val. Kappa Score: 0.6177 | Estimated time: 34.25
Train loss on 25 batch: 0.077219
Train loss on 50 batch: 0.059987
Train loss on 75 batch: 0.097132
: Epoch: 9 | Training Loss: 0.078113 | Val. Loss: 0.374154 | Val. Kappa Score: 0.6158 | Estimated time: 33.86
Train loss on 25 batch: 0.096437
Train loss on 50 batch: 0.059340
Train loss on 75 batch: 0.096824
: Epoch: 10 | Training Loss: 0.084201 | Val. Loss: 0.322282 | Val. Kappa Score: 0.6211 | Estimated time: 34.31
Train loss on 25 batch: 0.100586
Train loss on 50 batch: 0.084360
Train loss on 75 batch: 0.078290
: Epoch: 11 | Training Loss: 0.087745 | Val. Loss: 0.314939 | Val. Kappa Score: 0.6237 | Estimated time: 34.77
Train loss on 25 batch: 0.089181
Train loss on 50 batch: 0.119021
Train loss on 75 batch: 0.100175
: Epoch: 12 | Training Loss: 0.102792 | Val. Loss: 0.507885 | Val. Kappa Score: 0.6120 | Estimated time: 32.99
Train loss on 25 batch: 0.101705
Train loss on 50 batch: 0.063927
Train loss on 75 batch: 0.067113
: Epoch: 13 | Training Loss: 0.077581 | Val. Loss: 0.373254 | Val. Kappa Score: 0.6108 | Estimated time: 34.61
Train loss on 25 batch: 0.161055
Train loss on 50 batch: 0.085851
Train loss on 75 batch: 0.059492
: Epoch: 14 | Training Loss: 0.102133 | Val. Loss: 0.319141 | Val. Kappa Score: 0.6144 | Estimated time: 34.12
Train loss on 25 batch: 0.147901
Train loss on 50 batch: 0.103861
Train loss on 75 batch: 0.076210
: Epoch: 15 | Training Loss: 0.109324 | Val. Loss: 0.346469 | Val. Kappa Score: 0.6156 | Estimated time: 33.64
Train loss on 25 batch: 0.125321
Train loss on 50 batch: 0.110178
Train loss on 75 batch: 0.073719
: Epoch: 16 | Training Loss: 0.103073 | Val. Loss: 0.393278 | Val. Kappa Score: 0.6170 | Estimated time: 35.02
Train loss on 25 batch: 0.123935
Train loss on 50 batch: 0.090833
Train loss on 75 batch: 0.061606
: Epoch: 17 | Training Loss: 0.092125 | Val. Loss: 0.415927 | Val. Kappa Score: 0.6164 | Estimated time: 34.81
Train loss on 25 batch: 0.086450
Train loss on 50 batch: 0.074899
Train loss on 75 batch: 0.057725
: Epoch: 18 | Training Loss: 0.073025 | Val. Loss: 0.375572 | Val. Kappa Score: 0.6166 | Estimated time: 35.11
Train loss on 25 batch: 0.082469
Train loss on 50 batch: 0.059065
Train loss on 75 batch: 0.052898
: Epoch: 19 | Training Loss: 0.064811 | Val. Loss: 0.334801 | Val. Kappa Score: 0.6188 | Estimated time: 34.84
Train loss on 25 batch: 0.046246
Train loss on 50 batch: 0.055318
Train loss on 75 batch: 0.054624
: Epoch: 20 | Training Loss: 0.052063 | Val. Loss: 0.372255 | Val. Kappa Score: 0.6189 | Estimated time: 34.91
Train loss on 25 batch: 0.051745
Train loss on 50 batch: 0.040245
Train loss on 75 batch: 0.064962
: Epoch: 21 | Training Loss: 0.052317 | Val. Loss: 0.414179 | Val. Kappa Score: 0.6193 | Estimated time: 34.48
time_estimated: 717.39
n-epochs: 21
time_estimated: 717.39
--------------------------------------------------------------------------------


best-kappa: nan
: Epoch: 1 | Training Loss: 1.045346 | Val. Loss: 1.872787 | Val. Kappa Score: nan | Estimated time: 200.10
----------------------------------------

Experiment N: 5: 
date: 2019.08.06 08:11:27
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 1
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 2.712615
Train loss on 50 batch: 1.535099
Train loss on 75 batch: 1.573558
Train loss on 100 batch: 2.219481
Train loss on 125 batch: 2.076194
Train loss on 150 batch: 1.778103
Train loss on 175 batch: 1.375433
Train loss on 200 batch: 2.066559
Train loss on 225 batch: 2.132294
Train loss on 250 batch: 1.595278
Train loss on 275 batch: 1.908248
Train loss on 300 batch: 0.488297
Train loss on 325 batch: 0.588546
Train loss on 350 batch: 0.268877
Train loss on 375 batch: 1.009746
Train loss on 400 batch: 1.125007
Train loss on 425 batch: 1.102224
Train loss on 450 batch: 0.968535
Train loss on 475 batch: 0.395644
Train loss on 500 batch: 0.550990
Train loss on 525 batch: 0.937180
Train loss on 550 batch: 0.757790
Train loss on 575 batch: 0.939940
Train loss on 600 batch: 2.185565
Train loss on 625 batch: 1.532070
Train loss on 650 batch: 1.665872
Train loss on 675 batch: 1.987288
Train loss on 700 batch: 0.684724
Train loss on 725 batch: 0.958249
Train loss on 750 batch: 0.717018
Train loss on 775 batch: 0.672477
Train loss on 800 batch: 0.864748
Train loss on 825 batch: 1.588427
Train loss on 850 batch: 0.727581
Train loss on 875 batch: 0.858136
Train loss on 900 batch: 3.179825
Train loss on 925 batch: 1.394386
Train loss on 950 batch: 2.796518
Train loss on 975 batch: 2.202275
Train loss on 1000 batch: 1.646416
Train loss on 1025 batch: 1.053391
Train loss on 1050 batch: 0.928082
Train loss on 1075 batch: 0.774155
Train loss on 1100 batch: 1.479301
Train loss on 1125 batch: 0.396975
Train loss on 1150 batch: 0.346687
Train loss on 1175 batch: 0.712901
Train loss on 1200 batch: 0.542859
Train loss on 1225 batch: 0.682436
Train loss on 1250 batch: 1.186481
Train loss on 1275 batch: 1.315122
Train loss on 1300 batch: 1.087987
Train loss on 1325 batch: 0.616436
Train loss on 1350 batch: 1.350660
Train loss on 1375 batch: 1.276353
Train loss on 1400 batch: 0.744323
Train loss on 1425 batch: 0.769679
Train loss on 1450 batch: 0.877635
Train loss on 1475 batch: 0.495482
Train loss on 1500 batch: 0.782804
Train loss on 1525 batch: 1.134125
Train loss on 1550 batch: 0.817088
Train loss on 1575 batch: 0.606007
Train loss on 1600 batch: 1.248634
Train loss on 1625 batch: 1.349539
Train loss on 1650 batch: 0.822297
Train loss on 1675 batch: 0.814345
Train loss on 1700 batch: 0.901620
Train loss on 1725 batch: 1.644346
Train loss on 1750 batch: 0.418591
Train loss on 1775 batch: 1.176345
Train loss on 1800 batch: 0.567497
Train loss on 1825 batch: 0.502169
Train loss on 1850 batch: 0.990116
Train loss on 1875 batch: 0.657601
Train loss on 1900 batch: 0.897768
Train loss on 1925 batch: 0.617817
Train loss on 1950 batch: 0.800019
Train loss on 1975 batch: 0.983708
Train loss on 2000 batch: 0.684278
Train loss on 2025 batch: 0.733487
Train loss on 2050 batch: 0.738249
Train loss on 2075 batch: 0.752554
Train loss on 2100 batch: 1.734450
Train loss on 2125 batch: 0.648781
Train loss on 2150 batch: 0.687906
Train loss on 2175 batch: 0.779114
Train loss on 2200 batch: 1.139126
Train loss on 2225 batch: 0.689597
Train loss on 2250 batch: 1.151967
Train loss on 2275 batch: 1.335958
Train loss on 2300 batch: 1.104626
Train loss on 2325 batch: 0.285692
Train loss on 2350 batch: 1.017444
Train loss on 2375 batch: 2.081408
Train loss on 2400 batch: 0.824505
Train loss on 2425 batch: 0.226107
Train loss on 2450 batch: 0.714244
Train loss on 2475 batch: 1.170642
Train loss on 2500 batch: 0.547865
Train loss on 2525 batch: 0.989330
Train loss on 2550 batch: 0.510002
Train loss on 2575 batch: 0.991193
Train loss on 2600 batch: 0.637073
Train loss on 2625 batch: 0.826939
Train loss on 2650 batch: 0.642236
Train loss on 2675 batch: 0.812633
Train loss on 2700 batch: 0.821667
Train loss on 2725 batch: 0.656662
Train loss on 2750 batch: 0.501445
Train loss on 2775 batch: 0.474720
Train loss on 2800 batch: 0.752678
Train loss on 2825 batch: 0.720673
Train loss on 2850 batch: 0.948227
Train loss on 2875 batch: 0.683727
Train loss on 2900 batch: 1.402214
Train loss on 2925 batch: 0.749423
best-train-loss: 1.045346
best-valid-loss: 1.872787
best-kappa: nan
: Epoch: 1 | Training Loss: 1.045346 | Val. Loss: 1.872787 | Val. Kappa Score: nan | Estimated time: 201.39
Train loss on 25 batch: 1.069707
Train loss on 50 batch: 1.094323
Train loss on 75 batch: 0.598979
Train loss on 100 batch: 0.419758
Train loss on 125 batch: 0.617238
Train loss on 150 batch: 0.833414
Train loss on 175 batch: 0.566249
Train loss on 200 batch: 0.299833
Train loss on 225 batch: 0.762643
Train loss on 250 batch: 1.059884
Train loss on 275 batch: 0.483626
Train loss on 300 batch: 0.220368
Train loss on 325 batch: 0.670009
Train loss on 350 batch: 1.024684
Train loss on 375 batch: 0.414848
Train loss on 400 batch: 0.501307
Train loss on 425 batch: 0.914322
Train loss on 450 batch: 0.738719
Train loss on 475 batch: 1.115753
Train loss on 500 batch: 0.466154
Train loss on 525 batch: 0.496254
Train loss on 550 batch: 0.585623
Train loss on 575 batch: 1.478854
Train loss on 600 batch: 0.634266
Train loss on 625 batch: 0.341718
Train loss on 650 batch: 0.594777
Train loss on 675 batch: 0.891109
Train loss on 700 batch: 0.748178
Train loss on 725 batch: 0.551125
Train loss on 750 batch: 0.535757
Train loss on 775 batch: 0.824238
Train loss on 800 batch: 0.689214
Train loss on 825 batch: 1.286287
Train loss on 850 batch: 0.645143
Train loss on 875 batch: 0.965033
Train loss on 900 batch: 0.902166
Train loss on 925 batch: 1.258933
Train loss on 950 batch: 1.180729
Train loss on 975 batch: 0.191381
Train loss on 1000 batch: 1.728350
Train loss on 1025 batch: 0.638573
Train loss on 1050 batch: 0.331899
Train loss on 1075 batch: 0.468574
Train loss on 1100 batch: 0.565243
Train loss on 1125 batch: 0.621751
Train loss on 1150 batch: 0.693208
Train loss on 1175 batch: 0.843713
Train loss on 1200 batch: 0.729841
Train loss on 1225 batch: 0.454603
Train loss on 1250 batch: 0.578008
Train loss on 1275 batch: 0.100128
Train loss on 1300 batch: 0.653778
Train loss on 1325 batch: 0.722654
Train loss on 1350 batch: 1.189251
Train loss on 1375 batch: 0.627654
Train loss on 1400 batch: 0.779177
Train loss on 1425 batch: 0.484328
Train loss on 1450 batch: 0.427984
Train loss on 1475 batch: 0.444073
Train loss on 1500 batch: 0.537271
Train loss on 1525 batch: 0.318340
Train loss on 1550 batch: 0.403277
Train loss on 1575 batch: 0.506573
Train loss on 1600 batch: 0.503691
Train loss on 1625 batch: 0.469431
Train loss on 1650 batch: 0.545545
Train loss on 1675 batch: 0.318129
Train loss on 1700 batch: 0.981251
Train loss on 1725 batch: 0.448734
Train loss on 1750 batch: 0.790820
Train loss on 1775 batch: 0.616575
Train loss on 1800 batch: 0.872113
Train loss on 1825 batch: 1.533331
Train loss on 1850 batch: 0.887208
Train loss on 1875 batch: 0.643674
Train loss on 1900 batch: 0.545023
Train loss on 1925 batch: 0.578932
Train loss on 1950 batch: 1.099622
Train loss on 1975 batch: 0.951740
Train loss on 2000 batch: 0.843425
Train loss on 2025 batch: 0.524093
Train loss on 2050 batch: 0.494071
Train loss on 2075 batch: 1.017188
Train loss on 2100 batch: 1.160524
Train loss on 2125 batch: 0.822321
Train loss on 2150 batch: 0.669565
Train loss on 2175 batch: 0.364715
Train loss on 2200 batch: 0.375144
Train loss on 2225 batch: 0.558638
Train loss on 2250 batch: 0.707681
Train loss on 2275 batch: 0.738901
Train loss on 2300 batch: 0.909365
Train loss on 2325 batch: 0.315972
Train loss on 2350 batch: 0.868240
Train loss on 2375 batch: 0.422502
Train loss on 2400 batch: 0.720622
Train loss on 2425 batch: 0.610985
Train loss on 2450 batch: 1.204208
Train loss on 2475 batch: 0.689664
Train loss on 2500 batch: 0.756842
Train loss on 2525 batch: 0.565675
Train loss on 2550 batch: 0.504090
Train loss on 2575 batch: 0.606372
Train loss on 2600 batch: 1.001659
Train loss on 2625 batch: 0.466660
Train loss on 2650 batch: 0.391075
Train loss on 2675 batch: 0.849000
Train loss on 2700 batch: 0.927725
Train loss on 2725 batch: 0.576137
Train loss on 2750 batch: 1.373029
Train loss on 2775 batch: 0.627863
Train loss on 2800 batch: 0.594634
Train loss on 2825 batch: 0.690739
Train loss on 2850 batch: 0.548122
Train loss on 2875 batch: 0.685794
Train loss on 2900 batch: 0.571803
Train loss on 2925 batch: 0.480867
best-train-loss: 0.696945
best-valid-loss: 1.850193
best-kappa: nan
: Epoch: 2 | Training Loss: 0.696945 | Val. Loss: 1.850193 | Val. Kappa Score: nan | Estimated time: 200.29
Train loss on 25 batch: 0.614866
Train loss on 50 batch: 0.500407
Train loss on 75 batch: 0.476632
Train loss on 100 batch: 0.430768
Train loss on 125 batch: 0.437456
Train loss on 150 batch: 0.609407
Train loss on 175 batch: 0.469939
Train loss on 200 batch: 0.660225
Train loss on 225 batch: 0.497430
Train loss on 250 batch: 0.487019
Train loss on 275 batch: 0.209223
Train loss on 300 batch: 0.711811
Train loss on 325 batch: 0.877376
Train loss on 350 batch: 0.146599
Train loss on 375 batch: 0.540822
Train loss on 400 batch: 0.639549
Train loss on 425 batch: 0.434058
Train loss on 450 batch: 0.977945
Train loss on 475 batch: 0.746623
Train loss on 500 batch: 0.261866
Train loss on 525 batch: 0.543559
Train loss on 550 batch: 0.796564
Train loss on 575 batch: 0.687364
Train loss on 600 batch: 0.272931
Train loss on 625 batch: 1.077775
Train loss on 650 batch: 0.940488
Train loss on 675 batch: 0.612773
Train loss on 700 batch: 0.395896
Train loss on 725 batch: 0.422898
Train loss on 750 batch: 0.453817
Train loss on 775 batch: 0.756266
Train loss on 800 batch: 0.623890
Train loss on 825 batch: 0.431415
Train loss on 850 batch: 0.163376
Train loss on 875 batch: 0.770031
Train loss on 900 batch: 0.294300
Train loss on 925 batch: 0.489498
Train loss on 950 batch: 0.123405
Train loss on 975 batch: 0.502527
Train loss on 1000 batch: 0.362193
Train loss on 1025 batch: 0.762863
Train loss on 1050 batch: 0.450797
Train loss on 1075 batch: 0.211778
Train loss on 1100 batch: 0.571662
Train loss on 1125 batch: 0.663874
Train loss on 1150 batch: 0.427477
Train loss on 1175 batch: 0.370794
Train loss on 1200 batch: 0.565117
Train loss on 1225 batch: 0.673125
Train loss on 1250 batch: 0.448975
Train loss on 1275 batch: 0.786811
Train loss on 1300 batch: 0.618364
Train loss on 1325 batch: 0.519520
Train loss on 1350 batch: 0.342030
Train loss on 1375 batch: 0.836207
Train loss on 1400 batch: 0.520382
Train loss on 1425 batch: 0.216699
Train loss on 1450 batch: 0.495522
Train loss on 1475 batch: 1.097290
Train loss on 1500 batch: 1.109371
Train loss on 1525 batch: 0.260898
Train loss on 1550 batch: 0.798798
Train loss on 1575 batch: 0.590096
Train loss on 1600 batch: 0.828633
Train loss on 1625 batch: 0.693396
Train loss on 1650 batch: 0.213480
Train loss on 1675 batch: 0.735798
Train loss on 1700 batch: 0.425772
Train loss on 1725 batch: 0.420641
Train loss on 1750 batch: 1.423120
Train loss on 1775 batch: 0.583759
Train loss on 1800 batch: 0.370474
Train loss on 1825 batch: 1.244070
Train loss on 1850 batch: 0.104637
Train loss on 1875 batch: 0.398120
Train loss on 1900 batch: 0.578905
Train loss on 1925 batch: 0.832584
Train loss on 1950 batch: 0.743154
Train loss on 1975 batch: 1.080780
Train loss on 2000 batch: 0.408990
Train loss on 2025 batch: 0.881431
Train loss on 2050 batch: 0.389183
Train loss on 2075 batch: 0.386397
Train loss on 2100 batch: 0.910192
Train loss on 2125 batch: 0.463845
Train loss on 2150 batch: 0.814836
Train loss on 2175 batch: 0.773154
Train loss on 2200 batch: 1.003002
Train loss on 2225 batch: 0.158887
Train loss on 2250 batch: 0.398934
Train loss on 2275 batch: 0.584500
Train loss on 2300 batch: 0.356200
Train loss on 2325 batch: 0.769152
Train loss on 2350 batch: 0.246437
Train loss on 2375 batch: 0.423626
Train loss on 2400 batch: 0.241595
Train loss on 2425 batch: 0.151763
Train loss on 2450 batch: 0.684177
Train loss on 2475 batch: 0.318132
Train loss on 2500 batch: 0.383250
Train loss on 2525 batch: 0.503649
Train loss on 2550 batch: 0.518712
Train loss on 2575 batch: 0.846479
Train loss on 2600 batch: 0.491759
Train loss on 2625 batch: 0.238829
Train loss on 2650 batch: 0.372061
Train loss on 2675 batch: 0.317889
Train loss on 2700 batch: 0.892825
Train loss on 2725 batch: 0.582392
Train loss on 2750 batch: 0.783819
Train loss on 2775 batch: 0.740020
Train loss on 2800 batch: 0.522006
Train loss on 2825 batch: 0.882949
Train loss on 2850 batch: 0.229451
Train loss on 2875 batch: 0.587787
Train loss on 2900 batch: 0.589355
Train loss on 2925 batch: 0.539135
: Epoch: 3 | Training Loss: 0.562851 | Val. Loss: 1.897690 | Val. Kappa Score: nan | Estimated time: 202.50
Train loss on 25 batch: 0.423193
Train loss on 50 batch: 0.780845
Train loss on 75 batch: 0.439024
Train loss on 100 batch: 0.364697
Train loss on 125 batch: 0.232191
Train loss on 150 batch: 0.213467
Train loss on 175 batch: 0.220144
Train loss on 200 batch: 0.312428
Train loss on 225 batch: 0.789502
Train loss on 250 batch: 0.334766
Train loss on 275 batch: 0.563070
Train loss on 300 batch: 0.789643
Train loss on 325 batch: 0.892980
Train loss on 350 batch: 0.528634
Train loss on 375 batch: 0.495240
Train loss on 400 batch: 0.773183
Train loss on 425 batch: 0.541700
Train loss on 450 batch: 0.552699
Train loss on 475 batch: 0.779739
Train loss on 500 batch: 0.606985
Train loss on 525 batch: 0.749347
Train loss on 550 batch: 0.638176
Train loss on 575 batch: 0.414332
Train loss on 600 batch: 0.599935
Train loss on 625 batch: 0.558906
Train loss on 650 batch: 0.763163
Train loss on 675 batch: 0.681929
Train loss on 700 batch: 0.708718
Train loss on 725 batch: 0.389133
Train loss on 750 batch: 0.724600
Train loss on 775 batch: 0.815507
Train loss on 800 batch: 0.510681
Train loss on 825 batch: 0.377473
Train loss on 850 batch: 0.575002
Train loss on 875 batch: 0.454682
Train loss on 900 batch: 0.184318
Train loss on 925 batch: 0.489935
Train loss on 950 batch: 0.638874
Train loss on 975 batch: 0.178312
Train loss on 1000 batch: 0.385131
Train loss on 1025 batch: 0.969199
Train loss on 1050 batch: 0.336981
Train loss on 1075 batch: 0.685803
Train loss on 1100 batch: 0.218763
Train loss on 1125 batch: 0.745761
Train loss on 1150 batch: 0.296923
Train loss on 1175 batch: 0.950206
Train loss on 1200 batch: 0.511906
Train loss on 1225 batch: 0.843040
Train loss on 1250 batch: 0.571906
Train loss on 1275 batch: 0.606152
Train loss on 1300 batch: 0.644484
Train loss on 1325 batch: 0.512137
Train loss on 1350 batch: 0.279429
Train loss on 1375 batch: 0.533967
Train loss on 1400 batch: 0.569055
Train loss on 1425 batch: 0.462627
Train loss on 1450 batch: 0.649430
Train loss on 1475 batch: 0.595141
Train loss on 1500 batch: 0.427325
Train loss on 1525 batch: 0.405779
Train loss on 1550 batch: 0.454327
Train loss on 1575 batch: 0.435398
Train loss on 1600 batch: 0.407897
Train loss on 1625 batch: 0.335505
Train loss on 1650 batch: 0.155743
Train loss on 1675 batch: 0.650475
Train loss on 1700 batch: 0.413587
Train loss on 1725 batch: 0.411006
Train loss on 1750 batch: 0.843370
Train loss on 1775 batch: 0.560617
Train loss on 1800 batch: 0.513085
Train loss on 1825 batch: 1.099465
Train loss on 1850 batch: 0.781435
Train loss on 1875 batch: 0.797863
Train loss on 1900 batch: 0.954333
Train loss on 1925 batch: 0.518920
Train loss on 1950 batch: 0.865569
Train loss on 1975 batch: 0.802777
Train loss on 2000 batch: 0.614934
Train loss on 2025 batch: 1.035740
Train loss on 2050 batch: 0.433867
Train loss on 2075 batch: 0.604515
Train loss on 2100 batch: 0.345176
Train loss on 2125 batch: 0.131130
Train loss on 2150 batch: 0.474677
Train loss on 2175 batch: 0.495121
Train loss on 2200 batch: 0.345256
Train loss on 2225 batch: 0.743018
Train loss on 2250 batch: 0.558578
Train loss on 2275 batch: 0.333731
Train loss on 2300 batch: 0.321105
Train loss on 2325 batch: 0.088723
Train loss on 2350 batch: 0.384701
Train loss on 2375 batch: 0.397736
Train loss on 2400 batch: 0.496616
Train loss on 2425 batch: 0.391762
Train loss on 2450 batch: 0.565057
Train loss on 2475 batch: 0.342635
Train loss on 2500 batch: 0.736520
Train loss on 2525 batch: 0.055441
Train loss on 2550 batch: 0.633690
Train loss on 2575 batch: 0.386383
Train loss on 2600 batch: 0.447259
Train loss on 2625 batch: 0.427319
Train loss on 2650 batch: 0.308742
Train loss on 2675 batch: 0.413438
Train loss on 2700 batch: 0.280005
Train loss on 2725 batch: 0.526916
Train loss on 2750 batch: 0.411933
Train loss on 2775 batch: 0.841498
Train loss on 2800 batch: 0.606808
Train loss on 2825 batch: 0.705135
Train loss on 2850 batch: 0.403371
Train loss on 2875 batch: 0.281149
Train loss on 2900 batch: 0.606249
Train loss on 2925 batch: 0.132580
: Epoch: 4 | Training Loss: 0.526480 | Val. Loss: 2.249388 | Val. Kappa Score: nan | Estimated time: 200.89
Train loss on 25 batch: 0.241644
Train loss on 50 batch: 1.951447
Train loss on 75 batch: 0.942514
Train loss on 100 batch: 0.751850
Train loss on 125 batch: 0.805866
Train loss on 150 batch: 0.602461
Train loss on 175 batch: 0.507995
Train loss on 200 batch: 0.522207
Train loss on 225 batch: 0.630554
Train loss on 250 batch: 0.541760
Train loss on 275 batch: 0.850739
Train loss on 300 batch: 0.534362
Train loss on 325 batch: 0.710088
Train loss on 350 batch: 0.416121
Train loss on 375 batch: 0.446605
Train loss on 400 batch: 0.560611
Train loss on 425 batch: 0.608121
Train loss on 450 batch: 0.398319
Train loss on 475 batch: 0.429581
Train loss on 500 batch: 0.608257
Train loss on 525 batch: 0.524929
Train loss on 550 batch: 0.481823
Train loss on 575 batch: 0.751820
Train loss on 600 batch: 0.227825
Train loss on 625 batch: 0.382093
Train loss on 650 batch: 0.343983
Train loss on 675 batch: 0.233459
Train loss on 700 batch: 0.393566
Train loss on 725 batch: 0.671760
Train loss on 750 batch: 0.403510
Train loss on 775 batch: 0.681523
Train loss on 800 batch: 0.321505
Train loss on 825 batch: 0.167920
Train loss on 850 batch: 0.372640
Train loss on 875 batch: 0.327518
Train loss on 900 batch: 0.377688
Train loss on 925 batch: 0.442253
Train loss on 950 batch: 0.232025
Train loss on 975 batch: 0.741514
Train loss on 1000 batch: 0.271772
Train loss on 1025 batch: 0.576330
Train loss on 1050 batch: 0.247791
Train loss on 1075 batch: 0.573505
Train loss on 1100 batch: 0.313705
Train loss on 1125 batch: 0.317852
Train loss on 1150 batch: 0.387302
Train loss on 1175 batch: 0.517251
Train loss on 1200 batch: 0.145316
Train loss on 1225 batch: 0.143981
Train loss on 1250 batch: 0.483863
Train loss on 1275 batch: 0.244023
Train loss on 1300 batch: 0.415466
Train loss on 1325 batch: 0.248209
Train loss on 1350 batch: 0.393712
Train loss on 1375 batch: 0.200163
Train loss on 1400 batch: 0.356170
Train loss on 1425 batch: 0.211902
Train loss on 1450 batch: 0.309324
Train loss on 1475 batch: 0.872154
Train loss on 1500 batch: 0.252321
Train loss on 1525 batch: 0.413577
Train loss on 1550 batch: 0.739035
Train loss on 1575 batch: 0.147828
Train loss on 1600 batch: 0.324153
Train loss on 1625 batch: 0.512307
Train loss on 1650 batch: 0.574657
Train loss on 1675 batch: 0.112631
Train loss on 1700 batch: 0.397152
Train loss on 1725 batch: 1.335935
Train loss on 1750 batch: 0.416681
Train loss on 1775 batch: 0.520589
Train loss on 1800 batch: 0.698166
Train loss on 1825 batch: 0.188696
Train loss on 1850 batch: 0.307098
Train loss on 1875 batch: 0.231307
Train loss on 1900 batch: 0.841825
Train loss on 1925 batch: 0.612312
Train loss on 1950 batch: 0.813751
Train loss on 1975 batch: 0.893175
Train loss on 2000 batch: 0.506572
Train loss on 2025 batch: 0.556524
Train loss on 2050 batch: 0.512722
Train loss on 2075 batch: 0.520519
Train loss on 2100 batch: 0.396579
Train loss on 2125 batch: 0.421217
Train loss on 2150 batch: 0.398800
Train loss on 2175 batch: 0.359234
Train loss on 2200 batch: 0.561199
Train loss on 2225 batch: 0.956600
Train loss on 2250 batch: 0.323351
Train loss on 2275 batch: 0.296241
Train loss on 2300 batch: 0.357276
Train loss on 2325 batch: 1.002264
Train loss on 2350 batch: 0.274475
Train loss on 2375 batch: 0.897364
Train loss on 2400 batch: 0.572511
Train loss on 2425 batch: 0.305579
Train loss on 2450 batch: 0.454599
Train loss on 2475 batch: 0.287789
Train loss on 2500 batch: 0.532126
Train loss on 2525 batch: 0.192122
Train loss on 2550 batch: 0.188435
Train loss on 2575 batch: 0.271159
Train loss on 2600 batch: 0.243472
Train loss on 2625 batch: 0.432644
Train loss on 2650 batch: 0.297188
Train loss on 2675 batch: 0.511622
Train loss on 2700 batch: 0.367537
Train loss on 2725 batch: 0.779265
Train loss on 2750 batch: 0.528419
Train loss on 2775 batch: 0.264367
Train loss on 2800 batch: 0.476872
Train loss on 2825 batch: 0.286361
Train loss on 2850 batch: 0.397610
Train loss on 2875 batch: 0.558865
Train loss on 2900 batch: 0.546185
Train loss on 2925 batch: 0.692198
best-train-loss: 0.480609
best-valid-loss: 1.536686
best-kappa: nan
: Epoch: 5 | Training Loss: 0.480609 | Val. Loss: 1.536686 | Val. Kappa Score: nan | Estimated time: 201.58
Train loss on 25 batch: 0.333196
Train loss on 50 batch: 0.389137
Train loss on 75 batch: 0.513960
Train loss on 100 batch: 0.212671
Train loss on 125 batch: 0.221086
Train loss on 150 batch: 0.239370
Train loss on 175 batch: 0.436102
Train loss on 200 batch: 0.429051
Train loss on 225 batch: 0.248292
Train loss on 250 batch: 0.159525
Train loss on 275 batch: 1.163315
Train loss on 300 batch: 0.721427
Train loss on 325 batch: 0.342925
Train loss on 350 batch: 0.317468
Train loss on 375 batch: 0.277060
Train loss on 400 batch: 0.552000
Train loss on 425 batch: 0.472120
Train loss on 450 batch: 0.551617
Train loss on 475 batch: 0.267231
Train loss on 500 batch: 0.713688
Train loss on 525 batch: 0.870501
Train loss on 550 batch: 0.550849
Train loss on 575 batch: 0.260304
Train loss on 600 batch: 0.318360
Train loss on 625 batch: 0.471036
Train loss on 650 batch: 0.247713
Train loss on 675 batch: 0.247178
Train loss on 700 batch: 0.495921
Train loss on 725 batch: 0.644554
Train loss on 750 batch: 0.594227
Train loss on 775 batch: 0.507463
Train loss on 800 batch: 0.186596
Train loss on 825 batch: 0.241490
Train loss on 850 batch: 0.056125
Train loss on 875 batch: 0.359273
Train loss on 900 batch: 0.258580
Train loss on 925 batch: 0.305725
Train loss on 950 batch: 0.196315
Train loss on 975 batch: 0.338458
Train loss on 1000 batch: 0.313532
Train loss on 1025 batch: 0.479134
Train loss on 1050 batch: 0.418404
Train loss on 1075 batch: 0.160575
Train loss on 1100 batch: 0.457058
Train loss on 1125 batch: 0.332302
Train loss on 1150 batch: 1.017846
Train loss on 1175 batch: 0.284534
Train loss on 1200 batch: 0.459797
Train loss on 1225 batch: 0.491006
Train loss on 1250 batch: 0.267076
Train loss on 1275 batch: 0.688197
Train loss on 1300 batch: 0.412684
Train loss on 1325 batch: 1.136244
Train loss on 1350 batch: 1.233828
Train loss on 1375 batch: 0.683259
Train loss on 1400 batch: 0.232637
Train loss on 1425 batch: 0.493220
Train loss on 1450 batch: 0.193057
Train loss on 1475 batch: 0.278920
Train loss on 1500 batch: 0.408642
Train loss on 1525 batch: 0.585192
Train loss on 1550 batch: 0.361405
Train loss on 1575 batch: 0.723042
Train loss on 1600 batch: 0.171085
Train loss on 1625 batch: 0.120531
Train loss on 1650 batch: 0.856327
Train loss on 1675 batch: 1.178394
Train loss on 1700 batch: 0.811259
Train loss on 1725 batch: 0.509960
Train loss on 1750 batch: 0.153283
Train loss on 1775 batch: 0.600274
Train loss on 1800 batch: 0.365275
Train loss on 1825 batch: 0.242389
Train loss on 1850 batch: 0.361834
Train loss on 1875 batch: 0.301999
Train loss on 1900 batch: 0.247810
Train loss on 1925 batch: 0.461629
Train loss on 1950 batch: 0.451612
Train loss on 1975 batch: 0.594069
Train loss on 2000 batch: 0.667662
Train loss on 2025 batch: 0.510457
Train loss on 2050 batch: 0.370401
Train loss on 2075 batch: 0.775337
Train loss on 2100 batch: 0.422355
Train loss on 2125 batch: 0.595086
Train loss on 2150 batch: 0.415047
Train loss on 2175 batch: 0.531353
Train loss on 2200 batch: 0.414608
Train loss on 2225 batch: 1.566568
Train loss on 2250 batch: 0.515672
Train loss on 2275 batch: 0.316791
Train loss on 2300 batch: 0.679772
Train loss on 2325 batch: 0.242008
Train loss on 2350 batch: 0.787529
Train loss on 2375 batch: 0.292070
Train loss on 2400 batch: 0.510213
Train loss on 2425 batch: 0.174772
Train loss on 2450 batch: 0.373644
Train loss on 2475 batch: 0.626082
Train loss on 2500 batch: 0.608248
Train loss on 2525 batch: 0.508259
Train loss on 2550 batch: 0.709043
Train loss on 2575 batch: 0.325583
Train loss on 2600 batch: 0.325653
Train loss on 2625 batch: 0.286138
Train loss on 2650 batch: 0.419542
Train loss on 2675 batch: 0.461705
Train loss on 2700 batch: 0.387299
Train loss on 2725 batch: 0.279086
Train loss on 2750 batch: 0.361951
Train loss on 2775 batch: 0.262558
Train loss on 2800 batch: 0.241089
Train loss on 2825 batch: 0.146170
Train loss on 2850 batch: 0.288525
Train loss on 2875 batch: 0.227760
Train loss on 2900 batch: 0.329401
Train loss on 2925 batch: 0.268212
: Epoch: 6 | Training Loss: 0.448503 | Val. Loss: 1.779034 | Val. Kappa Score: nan | Estimated time: 201.32
Train loss on 25 batch: 0.281594
Train loss on 50 batch: 0.791785
Train loss on 75 batch: 1.106992
Train loss on 100 batch: 0.592565
Train loss on 125 batch: 0.454600
Train loss on 150 batch: 0.126916
Train loss on 175 batch: 0.135004
Train loss on 200 batch: 0.450146
Train loss on 225 batch: 0.359437
Train loss on 250 batch: 0.889096
Train loss on 275 batch: 0.537954
Train loss on 300 batch: 0.345705
Train loss on 325 batch: 0.319822
Train loss on 350 batch: 0.445852
Train loss on 375 batch: 0.186362
Train loss on 400 batch: 0.302717
Train loss on 425 batch: 0.506170
Train loss on 450 batch: 0.129843
Train loss on 475 batch: 0.635697
Train loss on 500 batch: 0.205642
Train loss on 525 batch: 0.433098
Train loss on 550 batch: 0.161853
Train loss on 575 batch: 0.805705
Train loss on 600 batch: 0.210254
Train loss on 625 batch: 0.268850
Train loss on 650 batch: 0.478695
Train loss on 675 batch: 0.359479
Train loss on 700 batch: 0.363107
Train loss on 725 batch: 0.420585
Train loss on 750 batch: 0.433206
Train loss on 775 batch: 0.307578
Train loss on 800 batch: 0.426435
Train loss on 825 batch: 0.198472
Train loss on 850 batch: 0.578452
Train loss on 875 batch: 0.526076
Train loss on 900 batch: 0.250611
Train loss on 925 batch: 0.300989
Train loss on 950 batch: 0.531066
Train loss on 975 batch: 0.433931
Train loss on 1000 batch: 0.757303
Train loss on 1025 batch: 0.423331
Train loss on 1050 batch: 0.288506
Train loss on 1075 batch: 0.439435
Train loss on 1100 batch: 0.369129
Train loss on 1125 batch: 0.913264
Train loss on 1150 batch: 0.346029
Train loss on 1175 batch: 0.433786
Train loss on 1200 batch: 0.265251
Train loss on 1225 batch: 0.114873
Train loss on 1250 batch: 0.169020
Train loss on 1275 batch: 0.280024
Train loss on 1300 batch: 0.256333
Train loss on 1325 batch: 0.315283
Train loss on 1350 batch: 0.595533
Train loss on 1375 batch: 0.381423
Train loss on 1400 batch: 0.682482
Train loss on 1425 batch: 0.282119
Train loss on 1450 batch: 0.295888
Train loss on 1475 batch: 0.317645
Train loss on 1500 batch: 0.597690
Train loss on 1525 batch: 0.643364
Train loss on 1550 batch: 0.444918
Train loss on 1575 batch: 0.355560
Train loss on 1600 batch: 0.297981
Train loss on 1625 batch: 0.429341
Train loss on 1650 batch: 0.364283
Train loss on 1675 batch: 0.227361
Train loss on 1700 batch: 0.262008
Train loss on 1725 batch: 0.214061
Train loss on 1750 batch: 0.235568
Train loss on 1775 batch: 0.279082
Train loss on 1800 batch: 0.192829
Train loss on 1825 batch: 0.245928
Train loss on 1850 batch: 0.432024
Train loss on 1875 batch: 0.667302
Train loss on 1900 batch: 0.120391
Train loss on 1925 batch: 0.643147
Train loss on 1950 batch: 0.168880
Train loss on 1975 batch: 0.519099
Train loss on 2000 batch: 0.861724
Train loss on 2025 batch: 0.176076
Train loss on 2050 batch: 0.243924
Train loss on 2075 batch: 0.332311
Train loss on 2100 batch: 0.299135
Train loss on 2125 batch: 0.347686
Train loss on 2150 batch: 0.746266
Train loss on 2175 batch: 0.454673
Train loss on 2200 batch: 0.446613
Train loss on 2225 batch: 0.887457
Train loss on 2250 batch: 0.258034
Train loss on 2275 batch: 0.397387
Train loss on 2300 batch: 0.395928
Train loss on 2325 batch: 0.556817
Train loss on 2350 batch: 0.354989
Train loss on 2375 batch: 0.049273
Train loss on 2400 batch: 0.490726
Train loss on 2425 batch: 1.303446
Train loss on 2450 batch: 0.511566
Train loss on 2475 batch: 0.697833
Train loss on 2500 batch: 0.245420
Train loss on 2525 batch: 0.371087
Train loss on 2550 batch: 0.336122
Train loss on 2575 batch: 0.375444
Train loss on 2600 batch: 0.330167
Train loss on 2625 batch: 0.237448
Train loss on 2650 batch: 0.515066
Train loss on 2675 batch: 0.113111
Train loss on 2700 batch: 0.247898
Train loss on 2725 batch: 0.234365
Train loss on 2750 batch: 0.384863
Train loss on 2775 batch: 0.516488
Train loss on 2800 batch: 0.288076
Train loss on 2825 batch: 0.606140
Train loss on 2850 batch: 0.383668
Train loss on 2875 batch: 0.623462
Train loss on 2900 batch: 0.296699
Train loss on 2925 batch: 0.275833
best-train-loss: 0.408146
best-valid-loss: 1.496722
best-kappa: nan
: Epoch: 7 | Training Loss: 0.408146 | Val. Loss: 1.496722 | Val. Kappa Score: nan | Estimated time: 201.27
Train loss on 25 batch: 0.192518
Train loss on 50 batch: 0.148070
Train loss on 75 batch: 0.309184
Train loss on 100 batch: 0.449632
Train loss on 125 batch: 0.432158
Train loss on 150 batch: 0.536204
Train loss on 175 batch: 0.779166
Train loss on 200 batch: 0.159278
Train loss on 225 batch: 0.545884
Train loss on 250 batch: 0.292577
Train loss on 275 batch: 0.335475
Train loss on 300 batch: 0.312970
Train loss on 325 batch: 0.395025
Train loss on 350 batch: 0.299884
Train loss on 375 batch: 0.481727
Train loss on 400 batch: 0.146213
Train loss on 425 batch: 0.329898
Train loss on 450 batch: 0.310413
Train loss on 475 batch: 0.298748
Train loss on 500 batch: 0.437284
Train loss on 525 batch: 0.426841
Train loss on 550 batch: 0.473518
Train loss on 575 batch: 0.391935
Train loss on 600 batch: 0.463814
Train loss on 625 batch: 0.404373
Train loss on 650 batch: 0.703825
Train loss on 675 batch: 0.406522
Train loss on 700 batch: 0.272518
Train loss on 725 batch: 0.347698
Train loss on 750 batch: 0.238328
Train loss on 775 batch: 0.371451
Train loss on 800 batch: 0.265474
Train loss on 825 batch: 0.515362
Train loss on 850 batch: 0.304015
Train loss on 875 batch: 0.340149
Train loss on 900 batch: 0.282101
Train loss on 925 batch: 0.358853
Train loss on 950 batch: 0.084251
Train loss on 975 batch: 0.138798
Train loss on 1000 batch: 0.469709
Train loss on 1025 batch: 0.460788
Train loss on 1050 batch: 0.218511
Train loss on 1075 batch: 0.303077
Train loss on 1100 batch: 0.056374
Train loss on 1125 batch: 0.306194
Train loss on 1150 batch: 0.310984
Train loss on 1175 batch: 0.331750
Train loss on 1200 batch: 0.455651
Train loss on 1225 batch: 0.709233
Train loss on 1250 batch: 0.436896
Train loss on 1275 batch: 0.480155
Train loss on 1300 batch: 0.235724
Train loss on 1325 batch: 0.425655
Train loss on 1350 batch: 0.626866
Train loss on 1375 batch: 0.674452
Train loss on 1400 batch: 0.470635
Train loss on 1425 batch: 0.197863
Train loss on 1450 batch: 0.170249
Train loss on 1475 batch: 0.298012
Train loss on 1500 batch: 0.175171
Train loss on 1525 batch: 0.442565
Train loss on 1550 batch: 0.434689
Train loss on 1575 batch: 0.427052
Train loss on 1600 batch: 0.469333
Train loss on 1625 batch: 0.274879
Train loss on 1650 batch: 0.469831
Train loss on 1675 batch: 0.500654
Train loss on 1700 batch: 0.130570
Train loss on 1725 batch: 0.336814
Train loss on 1750 batch: 0.910561
Train loss on 1775 batch: 0.089082
Train loss on 1800 batch: 0.590728
Train loss on 1825 batch: 0.724286
Train loss on 1850 batch: 0.529523
Train loss on 1875 batch: 0.261362
Train loss on 1900 batch: 0.787169
Train loss on 1925 batch: 0.151674
Train loss on 1950 batch: 0.069282
Train loss on 1975 batch: 0.706732
Train loss on 2000 batch: 0.232744
Train loss on 2025 batch: 0.447813
Train loss on 2050 batch: 0.175104
Train loss on 2075 batch: 0.108564
Train loss on 2100 batch: 0.257055
Train loss on 2125 batch: 0.180219
Train loss on 2150 batch: 0.198218
Train loss on 2175 batch: 0.506989
Train loss on 2200 batch: 0.453812
Train loss on 2225 batch: 0.327643
Train loss on 2250 batch: 0.393213
Train loss on 2275 batch: 0.600650
Train loss on 2300 batch: 0.844220
Train loss on 2325 batch: 0.564569
Train loss on 2350 batch: 0.428262
Train loss on 2375 batch: 0.336880
Train loss on 2400 batch: 0.358393
Train loss on 2425 batch: 0.562381
Train loss on 2450 batch: 0.370412
Train loss on 2475 batch: 0.116516
Train loss on 2500 batch: 0.225003
Train loss on 2525 batch: 0.703807
Train loss on 2550 batch: 0.184788
Train loss on 2575 batch: 0.523582
Train loss on 2600 batch: 0.317270
Train loss on 2625 batch: 0.757139
Train loss on 2650 batch: 0.263123
Train loss on 2675 batch: 0.310061
Train loss on 2700 batch: 0.346680
Train loss on 2725 batch: 0.290096
Train loss on 2750 batch: 0.481018
Train loss on 2775 batch: 0.150237
Train loss on 2800 batch: 0.551877
Train loss on 2825 batch: 0.295947
Train loss on 2850 batch: 0.131518
Train loss on 2875 batch: 0.122319
Train loss on 2900 batch: 0.315686
Train loss on 2925 batch: 0.208682
: Epoch: 8 | Training Loss: 0.373892 | Val. Loss: 1.712422 | Val. Kappa Score: nan | Estimated time: 200.39
Train loss on 25 batch: 0.405461
Train loss on 50 batch: 0.641558
Train loss on 75 batch: 0.412402
Train loss on 100 batch: 0.610387
Train loss on 125 batch: 0.310627
Train loss on 150 batch: 0.165801
Train loss on 175 batch: 0.325401
Train loss on 200 batch: 0.236908
Train loss on 225 batch: 0.168976
Train loss on 250 batch: 0.515321
Train loss on 275 batch: 0.801050
Train loss on 300 batch: 0.433154
Train loss on 325 batch: 0.340583
Train loss on 350 batch: 0.561804
Train loss on 375 batch: 0.169628
Train loss on 400 batch: 0.195207
Train loss on 425 batch: 0.546453
Train loss on 450 batch: 0.314727
Train loss on 475 batch: 0.312977
Train loss on 500 batch: 0.378703
Train loss on 525 batch: 0.335223
Train loss on 550 batch: 0.378174
Train loss on 575 batch: 0.253459
Train loss on 600 batch: 0.301435
Train loss on 625 batch: 0.393237
Train loss on 650 batch: 0.259188
Train loss on 675 batch: 0.379614
Train loss on 700 batch: 0.175777
Train loss on 725 batch: 0.308762
Train loss on 750 batch: 0.829709
Train loss on 775 batch: 0.304155
Train loss on 800 batch: 0.210932
Train loss on 825 batch: 0.071062
Train loss on 850 batch: 0.257327
Train loss on 875 batch: 0.492708
Train loss on 900 batch: 0.233738
Train loss on 925 batch: 0.508308
Train loss on 950 batch: 0.435184
Train loss on 975 batch: 0.196466
Train loss on 1000 batch: 0.210082
Train loss on 1025 batch: 0.217331
Train loss on 1050 batch: 0.300164
Train loss on 1075 batch: 0.543497
Train loss on 1100 batch: 0.705471
Train loss on 1125 batch: 0.060418
Train loss on 1150 batch: 0.487053
Train loss on 1175 batch: 0.246853
Train loss on 1200 batch: 0.423883
Train loss on 1225 batch: 0.352234
Train loss on 1250 batch: 0.242196
Train loss on 1275 batch: 0.401246
Train loss on 1300 batch: 0.539628
Train loss on 1325 batch: 0.309425
Train loss on 1350 batch: 0.286746
Train loss on 1375 batch: 0.267455
Train loss on 1400 batch: 0.455856
Train loss on 1425 batch: 0.267400
Train loss on 1450 batch: 0.274365
Train loss on 1475 batch: 0.529396
Train loss on 1500 batch: 0.392107
Train loss on 1525 batch: 0.373165
Train loss on 1550 batch: 0.442446
Train loss on 1575 batch: 0.274323
Train loss on 1600 batch: 0.384684
Train loss on 1625 batch: 0.415743
Train loss on 1650 batch: 0.162190
Train loss on 1675 batch: 0.180494
Train loss on 1700 batch: 0.266246
Train loss on 1725 batch: 0.488668
Train loss on 1750 batch: 0.346663
Train loss on 1775 batch: 0.172592
Train loss on 1800 batch: 0.478457
Train loss on 1825 batch: 0.231508
Train loss on 1850 batch: 0.448001
Train loss on 1875 batch: 0.487738
Train loss on 1900 batch: 0.523194
Train loss on 1925 batch: 0.337882
Train loss on 1950 batch: 0.420394
Train loss on 1975 batch: 0.134098
Train loss on 2000 batch: 0.602876
Train loss on 2025 batch: 0.451948
Train loss on 2050 batch: 0.493997
Train loss on 2075 batch: 0.138754
Train loss on 2100 batch: 0.144750
Train loss on 2125 batch: 0.222618
Train loss on 2150 batch: 0.497479
Train loss on 2175 batch: 0.168951
Train loss on 2200 batch: 0.380934
Train loss on 2225 batch: 0.291662
Train loss on 2250 batch: 0.650464
Train loss on 2275 batch: 0.331725
Train loss on 2300 batch: 0.208073
Train loss on 2325 batch: 0.217495
Train loss on 2350 batch: 0.468114
Train loss on 2375 batch: 0.357420
Train loss on 2400 batch: 0.122017
Train loss on 2425 batch: 0.620376
Train loss on 2450 batch: 0.795127
Train loss on 2475 batch: 0.596684
Train loss on 2500 batch: 0.484604
Train loss on 2525 batch: 0.627497
Train loss on 2550 batch: 0.494066
Train loss on 2575 batch: 0.268933
Train loss on 2600 batch: 0.217478
Train loss on 2625 batch: 0.134992
Train loss on 2650 batch: 0.258170
Train loss on 2675 batch: 0.446189
Train loss on 2700 batch: 0.558052
Train loss on 2725 batch: 0.202068
Train loss on 2750 batch: 0.187705
Train loss on 2775 batch: 0.088300
Train loss on 2800 batch: 0.107264
Train loss on 2825 batch: 0.212284
Train loss on 2850 batch: 0.328601
Train loss on 2875 batch: 0.343463
Train loss on 2900 batch: 0.587594
Train loss on 2925 batch: 0.247184
: Epoch: 9 | Training Loss: 0.357340 | Val. Loss: 1.850856 | Val. Kappa Score: nan | Estimated time: 201.63
Train loss on 25 batch: 0.104481
Train loss on 50 batch: 0.308316
Train loss on 75 batch: 0.390701
Train loss on 100 batch: 0.397296
Train loss on 125 batch: 0.258129
Train loss on 150 batch: 0.214205
Train loss on 175 batch: 0.230084
Train loss on 200 batch: 0.167448
Train loss on 225 batch: 0.305696
Train loss on 250 batch: 0.489120
Train loss on 275 batch: 0.577467
Train loss on 300 batch: 0.147991
Train loss on 325 batch: 0.605787
Train loss on 350 batch: 0.538446
Train loss on 375 batch: 0.304399
Train loss on 400 batch: 0.114738
Train loss on 425 batch: 0.626439
Train loss on 450 batch: 0.285920
Train loss on 475 batch: 0.414492
Train loss on 500 batch: 0.187772
Train loss on 525 batch: 0.138498
Train loss on 550 batch: 0.189530
Train loss on 575 batch: 0.353613
Train loss on 600 batch: 0.293747
Train loss on 625 batch: 0.119299
Train loss on 650 batch: 0.499415
Train loss on 675 batch: 0.290158
Train loss on 700 batch: 0.368850
Train loss on 725 batch: 0.244384
Train loss on 750 batch: 0.207774
Train loss on 775 batch: 0.372865
Train loss on 800 batch: 0.674304
Train loss on 825 batch: 0.674883
Train loss on 850 batch: 0.613484
Train loss on 875 batch: 0.237055
Train loss on 900 batch: 0.260548
Train loss on 925 batch: 0.079464
Train loss on 950 batch: 0.335736
Train loss on 975 batch: 0.377648
Train loss on 1000 batch: 0.668488
Train loss on 1025 batch: 0.376066
Train loss on 1050 batch: 0.444988
Train loss on 1075 batch: 0.210548
Train loss on 1100 batch: 0.228582
Train loss on 1125 batch: 0.244730
Train loss on 1150 batch: 0.604840
Train loss on 1175 batch: 0.440994
Train loss on 1200 batch: 0.681654
Train loss on 1225 batch: 0.576088
Train loss on 1250 batch: 0.489776
Train loss on 1275 batch: 0.628674
Train loss on 1300 batch: 0.178867
Train loss on 1325 batch: 0.336428
Train loss on 1350 batch: 0.373925
Train loss on 1375 batch: 0.482850
Train loss on 1400 batch: 0.247930
Train loss on 1425 batch: 0.159149
Train loss on 1450 batch: 0.233680
Train loss on 1475 batch: 0.084398
Train loss on 1500 batch: 0.412818
Train loss on 1525 batch: 0.360592
Train loss on 1550 batch: 0.526628
Train loss on 1575 batch: 0.325906
Train loss on 1600 batch: 0.282999
Train loss on 1625 batch: 0.397788
Train loss on 1650 batch: 0.210454
Train loss on 1675 batch: 0.280579
Train loss on 1700 batch: 0.404662
Train loss on 1725 batch: 0.227358
Train loss on 1750 batch: 0.389512
Train loss on 1775 batch: 0.555352
Train loss on 1800 batch: 0.352263
Train loss on 1825 batch: 0.583356
Train loss on 1850 batch: 0.258849
Train loss on 1875 batch: 0.055446
Train loss on 1900 batch: 0.356618
Train loss on 1925 batch: 0.585417
Train loss on 1950 batch: 0.161176
Train loss on 1975 batch: 0.111716
Train loss on 2000 batch: 0.247480
Train loss on 2025 batch: 0.211241
Train loss on 2050 batch: 0.501477
Train loss on 2075 batch: 0.305591
Train loss on 2100 batch: 0.348155
Train loss on 2125 batch: 0.472062
Train loss on 2150 batch: 0.231111
Train loss on 2175 batch: 0.459988
Train loss on 2200 batch: 0.245526
Train loss on 2225 batch: 0.615894
Train loss on 2250 batch: 0.593203
Train loss on 2275 batch: 0.248459
Train loss on 2300 batch: 0.346815
Train loss on 2325 batch: 0.215996
Train loss on 2350 batch: 0.374649
Train loss on 2375 batch: 0.421596
Train loss on 2400 batch: 0.369334
Train loss on 2425 batch: 0.242746
Train loss on 2450 batch: 0.199948
Train loss on 2475 batch: 0.512644
Train loss on 2500 batch: 0.669652
Train loss on 2525 batch: 0.171654
Train loss on 2550 batch: 0.163477
Train loss on 2575 batch: 0.964782
Train loss on 2600 batch: 0.158043
Train loss on 2625 batch: 0.674462
Train loss on 2650 batch: 0.440012
Train loss on 2675 batch: 0.169361
Train loss on 2700 batch: 0.678710
Train loss on 2725 batch: 0.781683
Train loss on 2750 batch: 0.319539
Train loss on 2775 batch: 0.774140
Train loss on 2800 batch: 0.116100
Train loss on 2825 batch: 0.465198
Train loss on 2850 batch: 0.299090
Train loss on 2875 batch: 0.325248
Train loss on 2900 batch: 0.584519
Train loss on 2925 batch: 0.423464
: Epoch: 10 | Training Loss: 0.366456 | Val. Loss: 1.700503 | Val. Kappa Score: nan | Estimated time: 201.27
Train loss on 25 batch: 0.180097
Train loss on 50 batch: 0.658115
Train loss on 75 batch: 0.272652
Train loss on 100 batch: 0.216045
Train loss on 125 batch: 0.244546
Train loss on 150 batch: 0.213808
Train loss on 175 batch: 0.215936
Train loss on 200 batch: 0.291590
Train loss on 225 batch: 0.193351
Train loss on 250 batch: 0.391105
Train loss on 275 batch: 0.361296
Train loss on 300 batch: 0.330680
Train loss on 325 batch: 0.180853
Train loss on 350 batch: 0.258982
Train loss on 375 batch: 0.382771
Train loss on 400 batch: 0.373822
Train loss on 425 batch: 0.413804
Train loss on 450 batch: 0.238776
Train loss on 475 batch: 0.253651
Train loss on 500 batch: 0.640299
Train loss on 525 batch: 0.193355
Train loss on 550 batch: 0.188915
Train loss on 575 batch: 0.377475
Train loss on 600 batch: 0.695423
Train loss on 625 batch: 0.641257
Train loss on 650 batch: 0.397783
Train loss on 675 batch: 0.044470
Train loss on 700 batch: 0.374558
Train loss on 725 batch: 0.240915
Train loss on 750 batch: 0.607738
Train loss on 775 batch: 0.188047
Train loss on 800 batch: 0.247022
Train loss on 825 batch: 0.245421
Train loss on 850 batch: 0.430974
Train loss on 875 batch: 0.124934
Train loss on 900 batch: 0.435336
Train loss on 925 batch: 0.305240
Train loss on 950 batch: 0.246052
Train loss on 975 batch: 0.474403
Train loss on 1000 batch: 0.311583
Train loss on 1025 batch: 0.574061
Train loss on 1050 batch: 0.926452
Train loss on 1075 batch: 0.155012
Train loss on 1100 batch: 0.526289
Train loss on 1125 batch: 0.412533
Train loss on 1150 batch: 0.298924
Train loss on 1175 batch: 0.135953
Train loss on 1200 batch: 0.244924
Train loss on 1225 batch: 0.388531
Train loss on 1250 batch: 0.266463
Train loss on 1275 batch: 0.304743
Train loss on 1300 batch: 0.648843
Train loss on 1325 batch: 0.468750
Train loss on 1350 batch: 0.373580
Train loss on 1375 batch: 0.368044
Train loss on 1400 batch: 0.339344
Train loss on 1425 batch: 0.474728
Train loss on 1450 batch: 0.475033
Train loss on 1475 batch: 0.218300
Train loss on 1500 batch: 0.229594
Train loss on 1525 batch: 0.256924
Train loss on 1550 batch: 0.246317
Train loss on 1575 batch: 0.189326
Train loss on 1600 batch: 0.800105
Train loss on 1625 batch: 0.307287
Train loss on 1650 batch: 0.118584
Train loss on 1675 batch: 0.185801
Train loss on 1700 batch: 0.285235
Train loss on 1725 batch: 0.257263
Train loss on 1750 batch: 0.265451
Train loss on 1775 batch: 0.198624
Train loss on 1800 batch: 0.372796
Train loss on 1825 batch: 0.158234
Train loss on 1850 batch: 0.324129
Train loss on 1875 batch: 0.483110
Train loss on 1900 batch: 0.410148
Train loss on 1925 batch: 0.409042
Train loss on 1950 batch: 0.253609
Train loss on 1975 batch: 0.400332
Train loss on 2000 batch: 0.297715
Train loss on 2025 batch: 0.387251
Train loss on 2050 batch: 0.355028
Train loss on 2075 batch: 0.463171
Train loss on 2100 batch: 0.416337
Train loss on 2125 batch: 0.445152
Train loss on 2150 batch: 0.065915
Train loss on 2175 batch: 0.539922
Train loss on 2200 batch: 0.295922
Train loss on 2225 batch: 0.334733
Train loss on 2250 batch: 0.518352
Train loss on 2275 batch: 0.248053
Train loss on 2300 batch: 0.336175
Train loss on 2325 batch: 0.233965
Train loss on 2350 batch: 0.234041
Train loss on 2375 batch: 0.115122
Train loss on 2400 batch: 0.253068
Train loss on 2425 batch: 0.116472
Train loss on 2450 batch: 0.394967
Train loss on 2475 batch: 0.228760
Train loss on 2500 batch: 0.509485
Train loss on 2525 batch: 0.370589
Train loss on 2550 batch: 0.589830
Train loss on 2575 batch: 0.383491
Train loss on 2600 batch: 0.374044
Train loss on 2625 batch: 0.595509
Train loss on 2650 batch: 0.202973
Train loss on 2675 batch: 0.242138
Train loss on 2700 batch: 0.211797
Train loss on 2725 batch: 0.145741
Train loss on 2750 batch: 0.398854
Train loss on 2775 batch: 0.156049
Train loss on 2800 batch: 0.335273
Train loss on 2825 batch: 0.442265
Train loss on 2850 batch: 0.415112
Train loss on 2875 batch: 0.404402
Train loss on 2900 batch: 0.284628
Train loss on 2925 batch: 0.274225
best-train-loss: 0.337197
best-valid-loss: 1.329923
best-kappa: nan
: Epoch: 11 | Training Loss: 0.337197 | Val. Loss: 1.329923 | Val. Kappa Score: nan | Estimated time: 200.77
Train loss on 25 batch: 0.307615
Train loss on 50 batch: 0.866710
Train loss on 75 batch: 0.328001
Train loss on 100 batch: 0.081892
Train loss on 125 batch: 0.253817
Train loss on 150 batch: 0.269857
Train loss on 175 batch: 0.110510
Train loss on 200 batch: 0.410596
Train loss on 225 batch: 0.396276
Train loss on 250 batch: 0.388977
Train loss on 275 batch: 0.344416
Train loss on 300 batch: 0.198956
Train loss on 325 batch: 0.354723
Train loss on 350 batch: 0.315126
Train loss on 375 batch: 0.609381
Train loss on 400 batch: 0.282836
Train loss on 425 batch: 0.535484
Train loss on 450 batch: 0.237748
Train loss on 475 batch: 0.268614
Train loss on 500 batch: 0.426026
Train loss on 525 batch: 0.297342
Train loss on 550 batch: 0.413745
Train loss on 575 batch: 0.144800
Train loss on 600 batch: 0.178980
Train loss on 625 batch: 0.143577
Train loss on 650 batch: 0.232212
Train loss on 675 batch: 0.453521
Train loss on 700 batch: 0.595156
Train loss on 725 batch: 0.358076
Train loss on 750 batch: 0.195281
Train loss on 775 batch: 0.614065
Train loss on 800 batch: 0.547539
Train loss on 825 batch: 0.200622
Train loss on 850 batch: 0.272099
Train loss on 875 batch: 0.313696
Train loss on 900 batch: 0.228903
Train loss on 925 batch: 0.355193
Train loss on 950 batch: 0.398374
Train loss on 975 batch: 0.461260
Train loss on 1000 batch: 0.391734
Train loss on 1025 batch: 0.580468
Train loss on 1050 batch: 0.245007
Train loss on 1075 batch: 0.278155
Train loss on 1100 batch: 0.193970
Train loss on 1125 batch: 0.257111
Train loss on 1150 batch: 0.334538
Train loss on 1175 batch: 0.164465
Train loss on 1200 batch: 0.162145
Train loss on 1225 batch: 0.104418
Train loss on 1250 batch: 0.258233
Train loss on 1275 batch: 0.394487
Train loss on 1300 batch: 0.419993
Train loss on 1325 batch: 0.226042
Train loss on 1350 batch: 0.148583
Train loss on 1375 batch: 0.096779
Train loss on 1400 batch: 0.235737
Train loss on 1425 batch: 0.329113
Train loss on 1450 batch: 0.301184
Train loss on 1475 batch: 0.356262
Train loss on 1500 batch: 0.209782
Train loss on 1525 batch: 0.134308
Train loss on 1550 batch: 0.167780
Train loss on 1575 batch: 0.246297
Train loss on 1600 batch: 0.146379
Train loss on 1625 batch: 0.243340
Train loss on 1650 batch: 0.331831
Train loss on 1675 batch: 0.336609
Train loss on 1700 batch: 0.115639
Train loss on 1725 batch: 0.359128
Train loss on 1750 batch: 0.209425
Train loss on 1775 batch: 0.413017
Train loss on 1800 batch: 0.579822
Train loss on 1825 batch: 0.313377
Train loss on 1850 batch: 0.412088
Train loss on 1875 batch: 0.684659
Train loss on 1900 batch: 0.328179
Train loss on 1925 batch: 0.761966
Train loss on 1950 batch: 0.253811
Train loss on 1975 batch: 0.690833
Train loss on 2000 batch: 0.439697
Train loss on 2025 batch: 0.354232
Train loss on 2050 batch: 0.311691
Train loss on 2075 batch: 0.409498
Train loss on 2100 batch: 0.086554
Train loss on 2125 batch: 0.127888
Train loss on 2150 batch: 0.192884
Train loss on 2175 batch: 0.384749
Train loss on 2200 batch: 0.202788
Train loss on 2225 batch: 0.580853
Train loss on 2250 batch: 0.336227
Train loss on 2275 batch: 0.168955
Train loss on 2300 batch: 0.162921
Train loss on 2325 batch: 0.247690
Train loss on 2350 batch: 0.537698
Train loss on 2375 batch: 0.147157
Train loss on 2400 batch: 0.214756
Train loss on 2425 batch: 0.472753
Train loss on 2450 batch: 0.194304
Train loss on 2475 batch: 0.314726
Train loss on 2500 batch: 0.310640
Train loss on 2525 batch: 0.284878
Train loss on 2550 batch: 0.232435
Train loss on 2575 batch: 0.183523
Train loss on 2600 batch: 0.260475
Train loss on 2625 batch: 0.542597
Train loss on 2650 batch: 0.510183
Train loss on 2675 batch: 0.207275
Train loss on 2700 batch: 0.399038
Train loss on 2725 batch: 0.301939
Train loss on 2750 batch: 0.208706
Train loss on 2775 batch: 0.517425
Train loss on 2800 batch: 0.321274
Train loss on 2825 batch: 0.274935
Train loss on 2850 batch: 0.608996
Train loss on 2875 batch: 0.121249
Train loss on 2900 batch: 0.195643
Train loss on 2925 batch: 0.165244
: Epoch: 12 | Training Loss: 0.319172 | Val. Loss: 1.560870 | Val. Kappa Score: nan | Estimated time: 199.36
Train loss on 25 batch: 0.295334
Train loss on 50 batch: 0.047221
Train loss on 75 batch: 0.318798
Train loss on 100 batch: 0.141588
Train loss on 125 batch: 0.119562
Train loss on 150 batch: 0.237163
Train loss on 175 batch: 0.159054
Train loss on 200 batch: 0.253800
Train loss on 225 batch: 0.291646
Train loss on 250 batch: 0.171128
Train loss on 275 batch: 0.348206
Train loss on 300 batch: 0.299106
Train loss on 325 batch: 0.591406
Train loss on 350 batch: 0.471391
Train loss on 375 batch: 0.319127
Train loss on 400 batch: 0.212454
Train loss on 425 batch: 0.216021
Train loss on 450 batch: 0.258480
Train loss on 475 batch: 0.431256
Train loss on 500 batch: 0.339709
Train loss on 525 batch: 0.503524
Train loss on 550 batch: 0.269420
Train loss on 575 batch: 0.309406
Train loss on 600 batch: 0.149847
Train loss on 625 batch: 0.438771
Train loss on 650 batch: 0.331389
Train loss on 675 batch: 0.218741
Train loss on 700 batch: 0.084144
Train loss on 725 batch: 0.361877
Train loss on 750 batch: 0.403094
Train loss on 775 batch: 0.266226
Train loss on 800 batch: 0.425182
Train loss on 825 batch: 0.183430
Train loss on 850 batch: 0.546716
Train loss on 875 batch: 0.233072
Train loss on 900 batch: 0.313713
Train loss on 925 batch: 0.249902
Train loss on 950 batch: 0.291378
Train loss on 975 batch: 0.144328
Train loss on 1000 batch: 0.430263
Train loss on 1025 batch: 0.258988
Train loss on 1050 batch: 0.558434
Train loss on 1075 batch: 0.304588
Train loss on 1100 batch: 0.149175
Train loss on 1125 batch: 0.163669
Train loss on 1150 batch: 0.149673
Train loss on 1175 batch: 0.206639
Train loss on 1200 batch: 0.313680
Train loss on 1225 batch: 0.307837
Train loss on 1250 batch: 1.067796
Train loss on 1275 batch: 0.279111
Train loss on 1300 batch: 0.075493
Train loss on 1325 batch: 0.474407
Train loss on 1350 batch: 0.395982
Train loss on 1375 batch: 0.364047
Train loss on 1400 batch: 0.320004
Train loss on 1425 batch: 0.159800
Train loss on 1450 batch: 0.345865
Train loss on 1475 batch: 0.266192
Train loss on 1500 batch: 0.186158
Train loss on 1525 batch: 0.202944
Train loss on 1550 batch: 0.148342
Train loss on 1575 batch: 0.075240
Train loss on 1600 batch: 0.133238
Train loss on 1625 batch: 0.233783
Train loss on 1650 batch: 0.260001
Train loss on 1675 batch: 0.332054
Train loss on 1700 batch: 0.222720
Train loss on 1725 batch: 0.335666
Train loss on 1750 batch: 0.590669
Train loss on 1775 batch: 0.099681
Train loss on 1800 batch: 0.095096
Train loss on 1825 batch: 0.649302
Train loss on 1850 batch: 0.156377
Train loss on 1875 batch: 0.266340
Train loss on 1900 batch: 0.603980
Train loss on 1925 batch: 0.282850
Train loss on 1950 batch: 0.738573
Train loss on 1975 batch: 0.817918
Train loss on 2000 batch: 0.600156
Train loss on 2025 batch: 0.882222
Train loss on 2050 batch: 0.636250
Train loss on 2075 batch: 0.608158
Train loss on 2100 batch: 0.187277
Train loss on 2125 batch: 0.533200
Train loss on 2150 batch: 0.420667
Train loss on 2175 batch: 0.256740
Train loss on 2200 batch: 0.292849
Train loss on 2225 batch: 0.361887
Train loss on 2250 batch: 0.431674
Train loss on 2275 batch: 0.136627
Train loss on 2300 batch: 0.149785
Train loss on 2325 batch: 0.542626
Train loss on 2350 batch: 0.049236
Train loss on 2375 batch: 0.244484
Train loss on 2400 batch: 0.391257
Train loss on 2425 batch: 0.317015
Train loss on 2450 batch: 0.149324
Train loss on 2475 batch: 0.421712
Train loss on 2500 batch: 0.238235
Train loss on 2525 batch: 0.219954
Train loss on 2550 batch: 0.114748
Train loss on 2575 batch: 0.241640
Train loss on 2600 batch: 0.610172
Train loss on 2625 batch: 0.321896
Train loss on 2650 batch: 0.252515
Train loss on 2675 batch: 0.427068
Train loss on 2700 batch: 0.193686
Train loss on 2725 batch: 0.823016
Train loss on 2750 batch: 0.274919
Train loss on 2775 batch: 0.204345
Train loss on 2800 batch: 0.200241
Train loss on 2825 batch: 0.342885
Train loss on 2850 batch: 0.375650
Train loss on 2875 batch: 0.217690
Train loss on 2900 batch: 0.165144
Train loss on 2925 batch: 0.372517
: Epoch: 13 | Training Loss: 0.320330 | Val. Loss: 1.510836 | Val. Kappa Score: nan | Estimated time: 199.57
Train loss on 25 batch: 0.161213
Train loss on 50 batch: 0.179340
Train loss on 75 batch: 0.182936
Train loss on 100 batch: 0.334438
Train loss on 125 batch: 0.154410
Train loss on 150 batch: 0.297319
Train loss on 175 batch: 0.282990
Train loss on 200 batch: 0.494721
Train loss on 225 batch: 0.342319
Train loss on 250 batch: 0.562160
Train loss on 275 batch: 0.384183
Train loss on 300 batch: 0.327751
Train loss on 325 batch: 0.170402
Train loss on 350 batch: 0.426946
Train loss on 375 batch: 0.578133
Train loss on 400 batch: 0.661894
Train loss on 425 batch: 0.580041
Train loss on 450 batch: 0.195573
Train loss on 475 batch: 0.339115
Train loss on 500 batch: 0.103476
Train loss on 525 batch: 0.326464
Train loss on 550 batch: 0.314154
Train loss on 575 batch: 0.139993
Train loss on 600 batch: 0.219822
Train loss on 625 batch: 0.271299
Train loss on 650 batch: 0.560602
Train loss on 675 batch: 0.122793
Train loss on 700 batch: 0.155469
Train loss on 725 batch: 0.306120
Train loss on 750 batch: 0.362415
Train loss on 775 batch: 0.193924
Train loss on 800 batch: 0.340863
Train loss on 825 batch: 0.337197
Train loss on 850 batch: 0.581734
Train loss on 875 batch: 0.419116
Train loss on 900 batch: 0.286300
Train loss on 925 batch: 0.890999
Train loss on 950 batch: 0.138693
Train loss on 975 batch: 0.353143
Train loss on 1000 batch: 0.172739
Train loss on 1025 batch: 0.086634
Train loss on 1050 batch: 0.292188
Train loss on 1075 batch: 0.771775
Train loss on 1100 batch: 0.383661
Train loss on 1125 batch: 0.280916
Train loss on 1150 batch: 0.420812
Train loss on 1175 batch: 0.324715
Train loss on 1200 batch: 0.517987
Train loss on 1225 batch: 0.356921
Train loss on 1250 batch: 0.623166
Train loss on 1275 batch: 0.305875
Train loss on 1300 batch: 0.359255
Train loss on 1325 batch: 0.302973
Train loss on 1350 batch: 0.221501
Train loss on 1375 batch: 0.234026
Train loss on 1400 batch: 0.413559
Train loss on 1425 batch: 0.250943
Train loss on 1450 batch: 0.232740
Train loss on 1475 batch: 0.282004
Train loss on 1500 batch: 0.061039
Train loss on 1525 batch: 0.139203
Train loss on 1550 batch: 0.280976
Train loss on 1575 batch: 0.307481
Train loss on 1600 batch: 0.056581
Train loss on 1625 batch: 0.378972
Train loss on 1650 batch: 0.135302
Train loss on 1675 batch: 0.396910
Train loss on 1700 batch: 0.217319
Train loss on 1725 batch: 0.429267
Train loss on 1750 batch: 0.184366
Train loss on 1775 batch: 0.366794
Train loss on 1800 batch: 0.183551
Train loss on 1825 batch: 0.179390
Train loss on 1850 batch: 0.384659
Train loss on 1875 batch: 0.105520
Train loss on 1900 batch: 0.465754
Train loss on 1925 batch: 0.148255
Train loss on 1950 batch: 0.316572
Train loss on 1975 batch: 0.513351
Train loss on 2000 batch: 0.311215
Train loss on 2025 batch: 0.333432
Train loss on 2050 batch: 0.348914
Train loss on 2075 batch: 0.180496
Train loss on 2100 batch: 0.291234
Train loss on 2125 batch: 0.113242
Train loss on 2150 batch: 0.187501
Train loss on 2175 batch: 0.607718
Train loss on 2200 batch: 0.238292
Train loss on 2225 batch: 0.258902
Train loss on 2250 batch: 0.189184
Train loss on 2275 batch: 0.182891
Train loss on 2300 batch: 0.295669
Train loss on 2325 batch: 0.236480
Train loss on 2350 batch: 0.141433
Train loss on 2375 batch: 0.192874
Train loss on 2400 batch: 0.184498
Train loss on 2425 batch: 0.677215
Train loss on 2450 batch: 0.078867
Train loss on 2475 batch: 0.384065
Train loss on 2500 batch: 0.157988
Train loss on 2525 batch: 0.231390
Train loss on 2550 batch: 0.082759
Train loss on 2575 batch: 0.308600
Train loss on 2600 batch: 0.286955
Train loss on 2625 batch: 0.130714
Train loss on 2650 batch: 0.511565
Train loss on 2675 batch: 0.177994
Train loss on 2700 batch: 0.164192
Train loss on 2725 batch: 0.385778
Train loss on 2750 batch: 0.142188
Train loss on 2775 batch: 0.508663
Train loss on 2800 batch: 0.191386
Train loss on 2825 batch: 0.110590
Train loss on 2850 batch: 0.034004
Train loss on 2875 batch: 0.088810
Train loss on 2900 batch: 0.501485
Train loss on 2925 batch: 0.275043
: Epoch: 14 | Training Loss: 0.298208 | Val. Loss: 2.031343 | Val. Kappa Score: nan | Estimated time: 201.11
Train loss on 25 batch: 0.132868
Train loss on 50 batch: 0.507028
Train loss on 75 batch: 0.164789
Train loss on 100 batch: 0.306368
Train loss on 125 batch: 0.504489
Train loss on 150 batch: 0.222812
Train loss on 175 batch: 0.096504
Train loss on 200 batch: 0.480550
Train loss on 225 batch: 0.299122
Train loss on 250 batch: 0.051497
Train loss on 275 batch: 0.161230
Train loss on 300 batch: 0.123362
Train loss on 325 batch: 0.227146
Train loss on 350 batch: 0.186975
Train loss on 375 batch: 0.293708
Train loss on 400 batch: 0.285835
Train loss on 425 batch: 0.153674
Train loss on 450 batch: 0.088155
Train loss on 475 batch: 0.164576
Train loss on 500 batch: 0.290452
Train loss on 525 batch: 0.201803
Train loss on 550 batch: 0.486392
Train loss on 575 batch: 0.268514
Train loss on 600 batch: 0.296406
Train loss on 625 batch: 0.924521
Train loss on 650 batch: 0.616660
Train loss on 675 batch: 0.569699
Train loss on 700 batch: 0.214122
Train loss on 725 batch: 0.100623
Train loss on 750 batch: 0.278161
Train loss on 775 batch: 0.135339
Train loss on 800 batch: 0.643509
Train loss on 825 batch: 0.324218
Train loss on 850 batch: 0.393674
Train loss on 875 batch: 0.377728
Train loss on 900 batch: 0.257980
Train loss on 925 batch: 0.298530
Train loss on 950 batch: 0.522948
Train loss on 975 batch: 0.175752
Train loss on 1000 batch: 0.279459
Train loss on 1025 batch: 0.396075
Train loss on 1050 batch: 0.432703
Train loss on 1075 batch: 0.026964
Train loss on 1100 batch: 0.113644
Train loss on 1125 batch: 0.166675
Train loss on 1150 batch: 0.126574
Train loss on 1175 batch: 0.059531
Train loss on 1200 batch: 0.114922
Train loss on 1225 batch: 0.120805
Train loss on 1250 batch: 0.274236
Train loss on 1275 batch: 0.257560
Train loss on 1300 batch: 0.259828
Train loss on 1325 batch: 0.340800
Train loss on 1350 batch: 0.222505
Train loss on 1375 batch: 0.140718
Train loss on 1400 batch: 0.393401
Train loss on 1425 batch: 0.222986
Train loss on 1450 batch: 0.188333
Train loss on 1475 batch: 0.253001
Train loss on 1500 batch: 0.407029
Train loss on 1525 batch: 0.148696
Train loss on 1550 batch: 0.250447
Train loss on 1575 batch: 0.042166
Train loss on 1600 batch: 0.161211
Train loss on 1625 batch: 0.279877
Train loss on 1650 batch: 0.402808
Train loss on 1675 batch: 0.169349
Train loss on 1700 batch: 0.229277
Train loss on 1725 batch: 0.236517
Train loss on 1750 batch: 0.820329
Train loss on 1775 batch: 0.200545
Train loss on 1800 batch: 0.352735
Train loss on 1825 batch: 0.991152
Train loss on 1850 batch: 0.264053
Train loss on 1875 batch: 0.577305
Train loss on 1900 batch: 0.310271
Train loss on 1925 batch: 0.257088
Train loss on 1950 batch: 0.219543
Train loss on 1975 batch: 0.372679
Train loss on 2000 batch: 0.240071
Train loss on 2025 batch: 0.716399
Train loss on 2050 batch: 0.382707
Train loss on 2075 batch: 0.274915
Train loss on 2100 batch: 0.448954
Train loss on 2125 batch: 0.278392
Train loss on 2150 batch: 0.321705
Train loss on 2175 batch: 0.445467
Train loss on 2200 batch: 0.144470
Train loss on 2225 batch: 0.079196
Train loss on 2250 batch: 0.307094
Train loss on 2275 batch: 0.230333
Train loss on 2300 batch: 0.113671
Train loss on 2325 batch: 0.273537
Train loss on 2350 batch: 0.202258
Train loss on 2375 batch: 0.102684
Train loss on 2400 batch: 0.353550
Train loss on 2425 batch: 0.243406
Train loss on 2450 batch: 0.239191
Train loss on 2475 batch: 0.162729
Train loss on 2500 batch: 0.243210
Train loss on 2525 batch: 0.125633
Train loss on 2550 batch: 0.749161
Train loss on 2575 batch: 0.468122
Train loss on 2600 batch: 0.351846
Train loss on 2625 batch: 0.418807
Train loss on 2650 batch: 0.266780
Train loss on 2675 batch: 0.478843
Train loss on 2700 batch: 0.573302
Train loss on 2725 batch: 0.321265
Train loss on 2750 batch: 0.173020
Train loss on 2775 batch: 0.251436
Train loss on 2800 batch: 0.262488
Train loss on 2825 batch: 0.370124
Train loss on 2850 batch: 0.071404
Train loss on 2875 batch: 0.162472
Train loss on 2900 batch: 0.132885
Train loss on 2925 batch: 0.262368
: Epoch: 15 | Training Loss: 0.291927 | Val. Loss: 1.377982 | Val. Kappa Score: nan | Estimated time: 200.68
Train loss on 25 batch: 0.251940
Train loss on 50 batch: 0.397469
Train loss on 75 batch: 0.407072
Train loss on 100 batch: 0.169938
Train loss on 125 batch: 0.068203
Train loss on 150 batch: 0.310669
Train loss on 175 batch: 0.039356
Train loss on 200 batch: 0.157035
Train loss on 225 batch: 0.236543
Train loss on 250 batch: 0.225914
Train loss on 275 batch: 0.160302
Train loss on 300 batch: 0.111085
Train loss on 325 batch: 0.106156
Train loss on 350 batch: 0.195257
Train loss on 375 batch: 0.125422
Train loss on 400 batch: 0.214450
Train loss on 425 batch: 0.504461
Train loss on 450 batch: 0.054994
Train loss on 475 batch: 0.140069
Train loss on 500 batch: 0.371623
Train loss on 525 batch: 0.078004
Train loss on 550 batch: 0.375395
Train loss on 575 batch: 0.110163
Train loss on 600 batch: 0.310218
Train loss on 625 batch: 0.059832
Train loss on 650 batch: 0.066032
Train loss on 675 batch: 0.134708
Train loss on 700 batch: 0.320024
Train loss on 725 batch: 0.248384
Train loss on 750 batch: 0.478528
Train loss on 775 batch: 0.700524
Train loss on 800 batch: 0.405099
Train loss on 825 batch: 0.665752
Train loss on 850 batch: 0.408768
Train loss on 875 batch: 0.516055
Train loss on 900 batch: 0.302983
Train loss on 925 batch: 0.308602
Train loss on 950 batch: 0.268788
Train loss on 975 batch: 0.464448
Train loss on 1000 batch: 0.283286
Train loss on 1025 batch: 0.171524
Train loss on 1050 batch: 0.359905
Train loss on 1075 batch: 0.140703
Train loss on 1100 batch: 0.087294
Train loss on 1125 batch: 0.178107
Train loss on 1150 batch: 0.120511
Train loss on 1175 batch: 0.272336
Train loss on 1200 batch: 0.067180
Train loss on 1225 batch: 0.240787
Train loss on 1250 batch: 0.299793
Train loss on 1275 batch: 0.122853
Train loss on 1300 batch: 0.099820
Train loss on 1325 batch: 0.204506
Train loss on 1350 batch: 0.248999
Train loss on 1375 batch: 0.213312
Train loss on 1400 batch: 0.388689
Train loss on 1425 batch: 0.232560
Train loss on 1450 batch: 0.099556
Train loss on 1475 batch: 0.296492
Train loss on 1500 batch: 0.283625
Train loss on 1525 batch: 0.735591
Train loss on 1550 batch: 0.160556
Train loss on 1575 batch: 0.112787
Train loss on 1600 batch: 0.217090
Train loss on 1625 batch: 0.097367
Train loss on 1650 batch: 0.378837
Train loss on 1675 batch: 0.207763
Train loss on 1700 batch: 0.283505
Train loss on 1725 batch: 0.320900
Train loss on 1750 batch: 0.116497
Train loss on 1775 batch: 0.325408
Train loss on 1800 batch: 0.167095
Train loss on 1825 batch: 0.302004
Train loss on 1850 batch: 0.101555
Train loss on 1875 batch: 0.182381
Train loss on 1900 batch: 0.158653
Train loss on 1925 batch: 0.585997
Train loss on 1950 batch: 0.310806
Train loss on 1975 batch: 0.160182
Train loss on 2000 batch: 0.393172
Train loss on 2025 batch: 0.101452
Train loss on 2050 batch: 0.217301
Train loss on 2075 batch: 0.398588
Train loss on 2100 batch: 0.177511
Train loss on 2125 batch: 0.261372
Train loss on 2150 batch: 0.341987
Train loss on 2175 batch: 0.300172
Train loss on 2200 batch: 0.228940
Train loss on 2225 batch: 0.250137
Train loss on 2250 batch: 0.328625
Train loss on 2275 batch: 0.304375
Train loss on 2300 batch: 0.099130
Train loss on 2325 batch: 0.558614
Train loss on 2350 batch: 0.090825
Train loss on 2375 batch: 0.687052
Train loss on 2400 batch: 0.250839
Train loss on 2425 batch: 0.219895
Train loss on 2450 batch: 0.111758
Train loss on 2475 batch: 0.156445
Train loss on 2500 batch: 0.523306
Train loss on 2525 batch: 0.277833
Train loss on 2550 batch: 0.093144
Train loss on 2575 batch: 0.292395
Train loss on 2600 batch: 0.335410
Train loss on 2625 batch: 0.231473
Train loss on 2650 batch: 0.185921
Train loss on 2675 batch: 0.251611
Train loss on 2700 batch: 0.336038
Train loss on 2725 batch: 0.476852
Train loss on 2750 batch: 0.164466
Train loss on 2775 batch: 0.069050
Train loss on 2800 batch: 0.416751
Train loss on 2825 batch: 0.202902
Train loss on 2850 batch: 0.149076
Train loss on 2875 batch: 0.261441
Train loss on 2900 batch: 0.268027
Train loss on 2925 batch: 0.049374
: Epoch: 16 | Training Loss: 0.255302 | Val. Loss: 1.639829 | Val. Kappa Score: nan | Estimated time: 202.44
Train loss on 25 batch: 0.119385
Train loss on 50 batch: 0.095558
Train loss on 75 batch: 0.149512
Train loss on 100 batch: 0.192578
Train loss on 125 batch: 0.240593
Train loss on 150 batch: 0.252734
Train loss on 175 batch: 0.135983
Train loss on 200 batch: 0.056292
Train loss on 225 batch: 0.164967
Train loss on 250 batch: 0.214620
Train loss on 275 batch: 0.094010
Train loss on 300 batch: 0.401750
Train loss on 325 batch: 0.359464
Train loss on 350 batch: 0.234836
Train loss on 375 batch: 0.281134
Train loss on 400 batch: 0.245112
Train loss on 425 batch: 0.131079
Train loss on 450 batch: 0.142995
Train loss on 475 batch: 0.249839
Train loss on 500 batch: 0.434833
Train loss on 525 batch: 0.180591
Train loss on 550 batch: 0.220658
Train loss on 575 batch: 0.406873
Train loss on 600 batch: 0.344807
Train loss on 625 batch: 0.213932
Train loss on 650 batch: 0.209782
Train loss on 675 batch: 0.157170
Train loss on 700 batch: 0.209643
Train loss on 725 batch: 0.316125
Train loss on 750 batch: 0.259700
Train loss on 775 batch: 0.287519
Train loss on 800 batch: 0.113442
Train loss on 825 batch: 0.262245
Train loss on 850 batch: 0.318108
Train loss on 875 batch: 0.216091
Train loss on 900 batch: 0.283289
Train loss on 925 batch: 0.326471
Train loss on 950 batch: 0.073230
Train loss on 975 batch: 0.336515
Train loss on 1000 batch: 0.337794
Train loss on 1025 batch: 0.379327
Train loss on 1050 batch: 0.163370
Train loss on 1075 batch: 0.284097
Train loss on 1100 batch: 0.234347
Train loss on 1125 batch: 0.160410
Train loss on 1150 batch: 0.168422
Train loss on 1175 batch: 0.150045
Train loss on 1200 batch: 0.186160
Train loss on 1225 batch: 0.577987
Train loss on 1250 batch: 0.192131
Train loss on 1275 batch: 0.096344
Train loss on 1300 batch: 0.117026
Train loss on 1325 batch: 0.244709
Train loss on 1350 batch: 0.141896
Train loss on 1375 batch: 0.501155
Train loss on 1400 batch: 0.423872
Train loss on 1425 batch: 0.243235
Train loss on 1450 batch: 0.336445
Train loss on 1475 batch: 0.279104
Train loss on 1500 batch: 0.112204
Train loss on 1525 batch: 0.121515
Train loss on 1550 batch: 0.223306
Train loss on 1575 batch: 0.166870
Train loss on 1600 batch: 0.301984
Train loss on 1625 batch: 0.212531
Train loss on 1650 batch: 0.243558
Train loss on 1675 batch: 0.239111
Train loss on 1700 batch: 0.223478
Train loss on 1725 batch: 0.031208
Train loss on 1750 batch: 0.072015
Train loss on 1775 batch: 0.517916
Train loss on 1800 batch: 0.132800
Train loss on 1825 batch: 0.219095
Train loss on 1850 batch: 0.274895
Train loss on 1875 batch: 0.572241
Train loss on 1900 batch: 0.365432
Train loss on 1925 batch: 0.212767
Train loss on 1950 batch: 0.216179
Train loss on 1975 batch: 0.251604
Train loss on 2000 batch: 0.181770
Train loss on 2025 batch: 0.241801
Train loss on 2050 batch: 0.108357
Train loss on 2075 batch: 0.372689
Train loss on 2100 batch: 0.429235
Train loss on 2125 batch: 0.398001
Train loss on 2150 batch: 0.253708
Train loss on 2175 batch: 0.144243
Train loss on 2200 batch: 0.317914
Train loss on 2225 batch: 1.013323
Train loss on 2250 batch: 0.178346
Train loss on 2275 batch: 0.079539
Train loss on 2300 batch: 0.234886
Train loss on 2325 batch: 0.154298
Train loss on 2350 batch: 0.221243
Train loss on 2375 batch: 0.244907
Train loss on 2400 batch: 0.225292
Train loss on 2425 batch: 0.252242
Train loss on 2450 batch: 0.104677
Train loss on 2475 batch: 0.536189
Train loss on 2500 batch: 0.193301
Train loss on 2525 batch: 0.143213
Train loss on 2550 batch: 0.266650
Train loss on 2575 batch: 0.229001
Train loss on 2600 batch: 0.375317
Train loss on 2625 batch: 0.137019
Train loss on 2650 batch: 0.172750
Train loss on 2675 batch: 0.112860
Train loss on 2700 batch: 0.214302
Train loss on 2725 batch: 0.106393
Train loss on 2750 batch: 0.172617
Train loss on 2775 batch: 0.550258
Train loss on 2800 batch: 0.346426
Train loss on 2825 batch: 0.082531
Train loss on 2850 batch: 0.273876
Train loss on 2875 batch: 0.190604
Train loss on 2900 batch: 0.337907
Train loss on 2925 batch: 0.156202
: Epoch: 17 | Training Loss: 0.244581 | Val. Loss: 2.218761 | Val. Kappa Score: nan | Estimated time: 201.03
Train loss on 25 batch: 0.129551
Train loss on 50 batch: 0.111870
Train loss on 75 batch: 0.263858
Train loss on 100 batch: 0.432517
Train loss on 125 batch: 0.304152
Train loss on 150 batch: 0.071898
Train loss on 175 batch: 0.236090
Train loss on 200 batch: 0.068214
Train loss on 225 batch: 0.190691
Train loss on 250 batch: 0.167532
Train loss on 275 batch: 0.690176
Train loss on 300 batch: 0.264628
Train loss on 325 batch: 0.388357
Train loss on 350 batch: 0.152338
Train loss on 375 batch: 0.439111
Train loss on 400 batch: 0.085192
Train loss on 425 batch: 0.148808
Train loss on 450 batch: 0.185905
Train loss on 475 batch: 0.150883
Train loss on 500 batch: 0.266856
Train loss on 525 batch: 0.043104
Train loss on 550 batch: 0.342306
Train loss on 575 batch: 0.063221
Train loss on 600 batch: 0.276486
Train loss on 625 batch: 0.404569
Train loss on 650 batch: 0.275584
Train loss on 675 batch: 0.149323
Train loss on 700 batch: 0.202668
Train loss on 725 batch: 0.277716
Train loss on 750 batch: 0.284415
Train loss on 775 batch: 0.174566
Train loss on 800 batch: 0.179736
Train loss on 825 batch: 0.190641
Train loss on 850 batch: 0.250244
Train loss on 875 batch: 0.413717
Train loss on 900 batch: 0.197852
Train loss on 925 batch: 0.223444
Train loss on 950 batch: 0.130280
Train loss on 975 batch: 0.248537
Train loss on 1000 batch: 0.116073
Train loss on 1025 batch: 0.113656
Train loss on 1050 batch: 0.408875
Train loss on 1075 batch: 0.098269
Train loss on 1100 batch: 0.125481
Train loss on 1125 batch: 0.105955
Train loss on 1150 batch: 0.292686
Train loss on 1175 batch: 0.149953
Train loss on 1200 batch: 0.027647
Train loss on 1225 batch: 0.090253
Train loss on 1250 batch: 0.176163
Train loss on 1275 batch: 0.216180
Train loss on 1300 batch: 0.192170
Train loss on 1325 batch: 0.094946
Train loss on 1350 batch: 0.303351
Train loss on 1375 batch: 0.247274
Train loss on 1400 batch: 0.528472
Train loss on 1425 batch: 0.177590
Train loss on 1450 batch: 0.290350
Train loss on 1475 batch: 0.088622
Train loss on 1500 batch: 0.092296
Train loss on 1525 batch: 0.334958
Train loss on 1550 batch: 0.496747
Train loss on 1575 batch: 0.176520
Train loss on 1600 batch: 0.189712
Train loss on 1625 batch: 0.166218
Train loss on 1650 batch: 0.366686
Train loss on 1675 batch: 0.353484
Train loss on 1700 batch: 0.127495
Train loss on 1725 batch: 0.283341
Train loss on 1750 batch: 0.199422
Train loss on 1775 batch: 0.227162
Train loss on 1800 batch: 0.740098
Train loss on 1825 batch: 0.181191
Train loss on 1850 batch: 0.171730
Train loss on 1875 batch: 0.246297
Train loss on 1900 batch: 0.167780
Train loss on 1925 batch: 0.177008
Train loss on 1950 batch: 0.256611
Train loss on 1975 batch: 0.208847
Train loss on 2000 batch: 0.316571
Train loss on 2025 batch: 0.258429
Train loss on 2050 batch: 0.250096
Train loss on 2075 batch: 0.270372
Train loss on 2100 batch: 0.207029
Train loss on 2125 batch: 0.238375
Train loss on 2150 batch: 0.276756
Train loss on 2175 batch: 0.345528
Train loss on 2200 batch: 0.348146
Train loss on 2225 batch: 0.199805
Train loss on 2250 batch: 0.254573
Train loss on 2275 batch: 0.258362
Train loss on 2300 batch: 0.052860
Train loss on 2325 batch: 0.354350
Train loss on 2350 batch: 0.162517
Train loss on 2375 batch: 0.207756
Train loss on 2400 batch: 0.311385
Train loss on 2425 batch: 0.080434
Train loss on 2450 batch: 0.381744
Train loss on 2475 batch: 0.181766
Train loss on 2500 batch: 0.276198
Train loss on 2525 batch: 0.174424
Train loss on 2550 batch: 0.237622
Train loss on 2575 batch: 0.288577
Train loss on 2600 batch: 0.090163
Train loss on 2625 batch: 0.033146
Train loss on 2650 batch: 0.200852
Train loss on 2675 batch: 0.120986
Train loss on 2700 batch: 0.140869
Train loss on 2725 batch: 0.272265
Train loss on 2750 batch: 0.070933
Train loss on 2775 batch: 0.233790
Train loss on 2800 batch: 0.122530
Train loss on 2825 batch: 0.396697
Train loss on 2850 batch: 0.311083
Train loss on 2875 batch: 0.246985
Train loss on 2900 batch: 0.226634
Train loss on 2925 batch: 0.106826
: Epoch: 18 | Training Loss: 0.227282 | Val. Loss: 1.655581 | Val. Kappa Score: nan | Estimated time: 200.98
Train loss on 25 batch: 0.452711
Train loss on 50 batch: 0.208674
Train loss on 75 batch: 0.446944
Train loss on 100 batch: 0.129836
Train loss on 125 batch: 0.199789
Train loss on 150 batch: 0.084760
Train loss on 175 batch: 0.160919
Train loss on 200 batch: 0.195594
Train loss on 225 batch: 0.413993
Train loss on 250 batch: 0.345347
Train loss on 275 batch: 0.400619
Train loss on 300 batch: 0.173341
Train loss on 325 batch: 0.314279
Train loss on 350 batch: 0.157514
Train loss on 375 batch: 0.140402
Train loss on 400 batch: 0.091358
Train loss on 425 batch: 0.131287
Train loss on 450 batch: 0.044404
Train loss on 475 batch: 0.053217
Train loss on 500 batch: 0.092037
Train loss on 525 batch: 0.492991
Train loss on 550 batch: 0.467690
Train loss on 575 batch: 0.403064
Train loss on 600 batch: 0.086151
Train loss on 625 batch: 0.078263
Train loss on 650 batch: 0.156551
Train loss on 675 batch: 0.159399
Train loss on 700 batch: 0.059890
Train loss on 725 batch: 0.136775
Train loss on 750 batch: 0.042215
Train loss on 775 batch: 0.077835
Train loss on 800 batch: 0.180655
Train loss on 825 batch: 0.671179
Train loss on 850 batch: 0.503533
Train loss on 875 batch: 0.094412
Train loss on 900 batch: 0.205036
Train loss on 925 batch: 0.091112
Train loss on 950 batch: 0.134626
Train loss on 975 batch: 0.095574
Train loss on 1000 batch: 0.133119
Train loss on 1025 batch: 0.308123
Train loss on 1050 batch: 0.297628
Train loss on 1075 batch: 0.407332
Train loss on 1100 batch: 0.141706
Train loss on 1125 batch: 0.273097
Train loss on 1150 batch: 0.160949
Train loss on 1175 batch: 0.082586
Train loss on 1200 batch: 0.090020
Train loss on 1225 batch: 0.153863
Train loss on 1250 batch: 0.100113
Train loss on 1275 batch: 0.076949
Train loss on 1300 batch: 0.436739
Train loss on 1325 batch: 0.154957
Train loss on 1350 batch: 0.306088
Train loss on 1375 batch: 0.339756
Train loss on 1400 batch: 0.142741
Train loss on 1425 batch: 0.449422
Train loss on 1450 batch: 0.163515
Train loss on 1475 batch: 0.184550
Train loss on 1500 batch: 0.163760
Train loss on 1525 batch: 0.171154
Train loss on 1550 batch: 0.338578
Train loss on 1575 batch: 0.171846
Train loss on 1600 batch: 0.109231
Train loss on 1625 batch: 0.135468
Train loss on 1650 batch: 0.549511
Train loss on 1675 batch: 0.202150
Train loss on 1700 batch: 0.210950
Train loss on 1725 batch: 0.064763
Train loss on 1750 batch: 0.169910
Train loss on 1775 batch: 0.119107
Train loss on 1800 batch: 0.187979
Train loss on 1825 batch: 0.268497
Train loss on 1850 batch: 0.430001
Train loss on 1875 batch: 0.304671
Train loss on 1900 batch: 0.207424
Train loss on 1925 batch: 0.114161
Train loss on 1950 batch: 0.231360
Train loss on 1975 batch: 0.089964
Train loss on 2000 batch: 0.395906
Train loss on 2025 batch: 0.417908
Train loss on 2050 batch: 0.262531
Train loss on 2075 batch: 0.538390
Train loss on 2100 batch: 0.304371
Train loss on 2125 batch: 0.331270
Train loss on 2150 batch: 0.056719
Train loss on 2175 batch: 0.077456
Train loss on 2200 batch: 0.202347
Train loss on 2225 batch: 0.219570
Train loss on 2250 batch: 0.129249
Train loss on 2275 batch: 0.236424
Train loss on 2300 batch: 0.067223
Train loss on 2325 batch: 0.099085
Train loss on 2350 batch: 0.382694
Train loss on 2375 batch: 0.211333
Train loss on 2400 batch: 0.332547
Train loss on 2425 batch: 0.085003
Train loss on 2450 batch: 0.209314
Train loss on 2475 batch: 0.476143
Train loss on 2500 batch: 0.581098
Train loss on 2525 batch: 0.074381
Train loss on 2550 batch: 0.153870
Train loss on 2575 batch: 0.217550
Train loss on 2600 batch: 0.262891
Train loss on 2625 batch: 0.133765
Train loss on 2650 batch: 0.127595
Train loss on 2675 batch: 0.229475
Train loss on 2700 batch: 0.175208
Train loss on 2725 batch: 0.161186
Train loss on 2750 batch: 0.468272
Train loss on 2775 batch: 0.409550
Train loss on 2800 batch: 0.068358
Train loss on 2825 batch: 0.361568
Train loss on 2850 batch: 0.349049
Train loss on 2875 batch: 0.212545
Train loss on 2900 batch: 0.305003
Train loss on 2925 batch: 0.113511
: Epoch: 19 | Training Loss: 0.226137 | Val. Loss: 2.141472 | Val. Kappa Score: nan | Estimated time: 199.87
Train loss on 25 batch: 0.186421
Train loss on 50 batch: 0.070386
Train loss on 75 batch: 0.126025
Train loss on 100 batch: 0.102490
Train loss on 125 batch: 0.100252
Train loss on 150 batch: 0.140592
Train loss on 175 batch: 0.248344
Train loss on 200 batch: 0.076149
Train loss on 225 batch: 0.088643
Train loss on 250 batch: 0.105645
Train loss on 275 batch: 0.156167
Train loss on 300 batch: 0.340604
Train loss on 325 batch: 0.181607
Train loss on 350 batch: 0.043317
Train loss on 375 batch: 0.190389
Train loss on 400 batch: 0.241660
Train loss on 425 batch: 0.348693
Train loss on 450 batch: 0.073385
Train loss on 475 batch: 0.374892
Train loss on 500 batch: 0.051087
Train loss on 525 batch: 0.214872
Train loss on 550 batch: 0.310419
Train loss on 575 batch: 0.238485
Train loss on 600 batch: 0.261361
Train loss on 625 batch: 0.415382
Train loss on 650 batch: 0.276441
Train loss on 675 batch: 0.096672
Train loss on 700 batch: 0.104284
Train loss on 725 batch: 0.116451
Train loss on 750 batch: 0.192277
Train loss on 775 batch: 0.283514
Train loss on 800 batch: 0.329878
Train loss on 825 batch: 0.168970
Train loss on 850 batch: 0.152162
Train loss on 875 batch: 0.256681
Train loss on 900 batch: 0.283456
Train loss on 925 batch: 0.114293
Train loss on 950 batch: 0.199810
Train loss on 975 batch: 0.119253
Train loss on 1000 batch: 0.223197
Train loss on 1025 batch: 0.094025
Train loss on 1050 batch: 0.209209
Train loss on 1075 batch: 0.148839
Train loss on 1100 batch: 0.354929
Train loss on 1125 batch: 0.430857
Train loss on 1150 batch: 0.320063
Train loss on 1175 batch: 0.319588
Train loss on 1200 batch: 0.527431
Train loss on 1225 batch: 0.493711
Train loss on 1250 batch: 0.346324
Train loss on 1275 batch: 0.209109
Train loss on 1300 batch: 0.288037
Train loss on 1325 batch: 0.078998
Train loss on 1350 batch: 0.147934
Train loss on 1375 batch: 0.057539
Train loss on 1400 batch: 0.269216
Train loss on 1425 batch: 0.267256
Train loss on 1450 batch: 0.282840
Train loss on 1475 batch: 0.584046
Train loss on 1500 batch: 0.131085
Train loss on 1525 batch: 0.542312
Train loss on 1550 batch: 0.109928
Train loss on 1575 batch: 0.060455
Train loss on 1600 batch: 0.132370
Train loss on 1625 batch: 0.099970
Train loss on 1650 batch: 0.193684
Train loss on 1675 batch: 0.225813
Train loss on 1700 batch: 0.271377
Train loss on 1725 batch: 0.204007
Train loss on 1750 batch: 0.166513
Train loss on 1775 batch: 0.081011
Train loss on 1800 batch: 0.065395
Train loss on 1825 batch: 0.448040
Train loss on 1850 batch: 0.196668
Train loss on 1875 batch: 0.349818
Train loss on 1900 batch: 0.104654
Train loss on 1925 batch: 0.296853
Train loss on 1950 batch: 0.092137
Train loss on 1975 batch: 0.225338
Train loss on 2000 batch: 0.169450
Train loss on 2025 batch: 0.085754
Train loss on 2050 batch: 0.099125
Train loss on 2075 batch: 0.265301
Train loss on 2100 batch: 0.059565
Train loss on 2125 batch: 0.365200
Train loss on 2150 batch: 0.125996
Train loss on 2175 batch: 0.075036
Train loss on 2200 batch: 0.221609
Train loss on 2225 batch: 0.067320
Train loss on 2250 batch: 0.283546
Train loss on 2275 batch: 0.262715
Train loss on 2300 batch: 0.259527
Train loss on 2325 batch: 0.156159
Train loss on 2350 batch: 0.186139
Train loss on 2375 batch: 0.188467
Train loss on 2400 batch: 0.418570
Train loss on 2425 batch: 0.153114
Train loss on 2450 batch: 0.270136
Train loss on 2475 batch: 0.210483
Train loss on 2500 batch: 0.319356
Train loss on 2525 batch: 0.159876
Train loss on 2550 batch: 0.418934
Train loss on 2575 batch: 0.214539
Train loss on 2600 batch: 0.175344
Train loss on 2625 batch: 0.134339
Train loss on 2650 batch: 0.094316
Train loss on 2675 batch: 0.113629
Train loss on 2700 batch: 0.147881
Train loss on 2725 batch: 0.161182
Train loss on 2750 batch: 0.313693
Train loss on 2775 batch: 0.362638
Train loss on 2800 batch: 0.171403
Train loss on 2825 batch: 0.204323
Train loss on 2850 batch: 0.180137
Train loss on 2875 batch: 0.208571
Train loss on 2900 batch: 0.160818
Train loss on 2925 batch: 0.442979
: Epoch: 20 | Training Loss: 0.213155 | Val. Loss: 1.975112 | Val. Kappa Score: nan | Estimated time: 200.18
Train loss on 25 batch: 0.373225
Train loss on 50 batch: 0.106171
Train loss on 75 batch: 0.060714
Train loss on 100 batch: 0.095737
Train loss on 125 batch: 0.083039
Train loss on 150 batch: 0.248954
Train loss on 175 batch: 0.199727
Train loss on 200 batch: 0.100970
Train loss on 225 batch: 0.307359
Train loss on 250 batch: 0.211142
Train loss on 275 batch: 0.189316
Train loss on 300 batch: 0.112297
Train loss on 325 batch: 0.181529
Train loss on 350 batch: 0.114468
Train loss on 375 batch: 0.076321
Train loss on 400 batch: 0.123294
Train loss on 425 batch: 0.245845
Train loss on 450 batch: 0.061795
Train loss on 475 batch: 0.183738
Train loss on 500 batch: 0.241356
Train loss on 525 batch: 0.062639
Train loss on 550 batch: 0.165456
Train loss on 575 batch: 0.063734
Train loss on 600 batch: 0.177804
Train loss on 625 batch: 0.224443
Train loss on 650 batch: 0.250907
Train loss on 675 batch: 0.098910
Train loss on 700 batch: 0.172672
Train loss on 725 batch: 0.046393
Train loss on 750 batch: 0.145045
Train loss on 775 batch: 0.430828
Train loss on 800 batch: 0.167488
Train loss on 825 batch: 0.095254
Train loss on 850 batch: 0.279825
Train loss on 875 batch: 0.136672
Train loss on 900 batch: 0.093839
Train loss on 925 batch: 0.183606
Train loss on 950 batch: 0.248840
Train loss on 975 batch: 0.405286
Train loss on 1000 batch: 0.153660
Train loss on 1025 batch: 0.125116
Train loss on 1050 batch: 0.285336
Train loss on 1075 batch: 0.346573
Train loss on 1100 batch: 0.229708
Train loss on 1125 batch: 0.333226
Train loss on 1150 batch: 0.465344
Train loss on 1175 batch: 0.076929
Train loss on 1200 batch: 0.236896
Train loss on 1225 batch: 0.575987
Train loss on 1250 batch: 0.260510
Train loss on 1275 batch: 0.127049
Train loss on 1300 batch: 0.132612
Train loss on 1325 batch: 0.322820
Train loss on 1350 batch: 0.155842
Train loss on 1375 batch: 0.144589
Train loss on 1400 batch: 0.062695
Train loss on 1425 batch: 0.059308
Train loss on 1450 batch: 0.108005
Train loss on 1475 batch: 0.276335
Train loss on 1500 batch: 0.040739
Train loss on 1525 batch: 0.134854
Train loss on 1550 batch: 0.225549
Train loss on 1575 batch: 0.253084
Train loss on 1600 batch: 0.419708
Train loss on 1625 batch: 0.071343
Train loss on 1650 batch: 0.254297
Train loss on 1675 batch: 0.040285
Train loss on 1700 batch: 0.223474
Train loss on 1725 batch: 0.261179
Train loss on 1750 batch: 0.509562
Train loss on 1775 batch: 0.146361
Train loss on 1800 batch: 0.256715
Train loss on 1825 batch: 0.205236
Train loss on 1850 batch: 0.093686
Train loss on 1875 batch: 0.206636
Train loss on 1900 batch: 0.136569
Train loss on 1925 batch: 0.094783
Train loss on 1950 batch: 0.113975
Train loss on 1975 batch: 0.175291
Train loss on 2000 batch: 0.067750
Train loss on 2025 batch: 0.586595
Train loss on 2050 batch: 0.162558
Train loss on 2075 batch: 0.450747
Train loss on 2100 batch: 0.231040
Train loss on 2125 batch: 0.436515
Train loss on 2150 batch: 0.096468
Train loss on 2175 batch: 0.070125
Train loss on 2200 batch: 0.577175
Train loss on 2225 batch: 0.321046
Train loss on 2250 batch: 0.265287
Train loss on 2275 batch: 0.083712
Train loss on 2300 batch: 0.363281
Train loss on 2325 batch: 0.069141
Train loss on 2350 batch: 0.242121
Train loss on 2375 batch: 0.231363
Train loss on 2400 batch: 0.097393
Train loss on 2425 batch: 0.085943
Train loss on 2450 batch: 0.116507
Train loss on 2475 batch: 0.049366
Train loss on 2500 batch: 0.168666
Train loss on 2525 batch: 0.268821
Train loss on 2550 batch: 0.203203
Train loss on 2575 batch: 0.233293
Train loss on 2600 batch: 0.207032
Train loss on 2625 batch: 0.062952
Train loss on 2650 batch: 0.106476
Train loss on 2675 batch: 0.123692
Train loss on 2700 batch: 0.080968
Train loss on 2725 batch: 0.217152
Train loss on 2750 batch: 0.280674
Train loss on 2775 batch: 0.117832
Train loss on 2800 batch: 0.208737
Train loss on 2825 batch: 0.145712
Train loss on 2850 batch: 0.169389
Train loss on 2875 batch: 0.061367
Train loss on 2900 batch: 0.473545
Train loss on 2925 batch: 0.166454
: Epoch: 21 | Training Loss: 0.196655 | Val. Loss: 2.207472 | Val. Kappa Score: nan | Estimated time: 199.96
Train loss on 25 batch: 0.159695
Train loss on 50 batch: 0.045497
Train loss on 75 batch: 0.248384
Train loss on 100 batch: 0.203266
Train loss on 125 batch: 0.131734
Train loss on 150 batch: 0.283573
Train loss on 175 batch: 0.173169
Train loss on 200 batch: 0.149164
Train loss on 225 batch: 0.137654
Train loss on 250 batch: 0.109199
Train loss on 275 batch: 0.226485
Train loss on 300 batch: 0.135115
Train loss on 325 batch: 0.243487
Train loss on 350 batch: 0.221228
Train loss on 375 batch: 0.311970
Train loss on 400 batch: 0.395078
Train loss on 425 batch: 0.145244
Train loss on 450 batch: 0.277917
Train loss on 475 batch: 0.033717
Train loss on 500 batch: 0.140853
Train loss on 525 batch: 0.206279
Train loss on 550 batch: 0.399167
Train loss on 575 batch: 0.209482
Train loss on 600 batch: 0.287420
Train loss on 625 batch: 0.252170
Train loss on 650 batch: 0.048010
Train loss on 675 batch: 0.154316
Train loss on 700 batch: 0.103727
Train loss on 725 batch: 0.160986
Train loss on 750 batch: 0.165492
Train loss on 775 batch: 0.058021
Train loss on 800 batch: 0.258992
Train loss on 825 batch: 0.110669
Train loss on 850 batch: 0.427832
Train loss on 875 batch: 0.317893
Train loss on 900 batch: 0.477320
Train loss on 925 batch: 0.382570
Train loss on 950 batch: 0.283355
Train loss on 975 batch: 0.461777
Train loss on 1000 batch: 0.264061
Train loss on 1025 batch: 0.392248
Train loss on 1050 batch: 0.298089
Train loss on 1075 batch: 0.302218
Train loss on 1100 batch: 0.223857
Train loss on 1125 batch: 0.133461
Train loss on 1150 batch: 0.150322
Train loss on 1175 batch: 0.239297
Train loss on 1200 batch: 0.671036
Train loss on 1225 batch: 0.049732
Train loss on 1250 batch: 0.115680
Train loss on 1275 batch: 0.045821
Train loss on 1300 batch: 0.102018
Train loss on 1325 batch: 0.286694
Train loss on 1350 batch: 0.321441
Train loss on 1375 batch: 0.215002
Train loss on 1400 batch: 0.258348
Train loss on 1425 batch: 0.238887
Train loss on 1450 batch: 0.336328
Train loss on 1475 batch: 0.154876
Train loss on 1500 batch: 0.065561
Train loss on 1525 batch: 0.056650
Train loss on 1550 batch: 0.101721
Train loss on 1575 batch: 0.207117
Train loss on 1600 batch: 0.122762
Train loss on 1625 batch: 0.159471
Train loss on 1650 batch: 0.288389
Train loss on 1675 batch: 0.145409
Train loss on 1700 batch: 0.054339
Train loss on 1725 batch: 0.247837
Train loss on 1750 batch: 0.141906
Train loss on 1775 batch: 0.153497
Train loss on 1800 batch: 0.230661
Train loss on 1825 batch: 0.161572
Train loss on 1850 batch: 0.301674
Train loss on 1875 batch: 0.419058
Train loss on 1900 batch: 0.079414
Train loss on 1925 batch: 0.052613
Train loss on 1950 batch: 0.022066
Train loss on 1975 batch: 0.049093
Train loss on 2000 batch: 0.201518
Train loss on 2025 batch: 0.847941
Train loss on 2050 batch: 0.267134
Train loss on 2075 batch: 0.190546
Train loss on 2100 batch: 0.469792
Train loss on 2125 batch: 0.216414
Train loss on 2150 batch: 0.169857
Train loss on 2175 batch: 0.119868
Train loss on 2200 batch: 0.333215
Train loss on 2225 batch: 0.403987
Train loss on 2250 batch: 0.119240
Train loss on 2275 batch: 0.174757
Train loss on 2300 batch: 0.151821
Train loss on 2325 batch: 0.291538
Train loss on 2350 batch: 0.266339
Train loss on 2375 batch: 0.119478
Train loss on 2400 batch: 0.421842
Train loss on 2425 batch: 0.075514
Train loss on 2450 batch: 0.311654
Train loss on 2475 batch: 0.080154
Train loss on 2500 batch: 0.133890
Train loss on 2525 batch: 0.238320
Train loss on 2550 batch: 0.127273
Train loss on 2575 batch: 0.304699
Train loss on 2600 batch: 0.086473
Train loss on 2625 batch: 0.106493
Train loss on 2650 batch: 0.131547
Train loss on 2675 batch: 0.066684
Train loss on 2700 batch: 0.111879
Train loss on 2725 batch: 0.107771
Train loss on 2750 batch: 0.124029
Train loss on 2775 batch: 0.308539
Train loss on 2800 batch: 0.273708
Train loss on 2825 batch: 0.087533
Train loss on 2850 batch: 0.467208
Train loss on 2875 batch: 0.190255
Train loss on 2900 batch: 0.346787
Train loss on 2925 batch: 0.144120
: Epoch: 22 | Training Loss: 0.213572 | Val. Loss: 1.806367 | Val. Kappa Score: nan | Estimated time: 199.20
Train loss on 25 batch: 0.184294
Train loss on 50 batch: 0.447720
Train loss on 75 batch: 0.130264
Train loss on 100 batch: 0.312785
Train loss on 125 batch: 0.229352
Train loss on 150 batch: 0.040096
Train loss on 175 batch: 0.179763
Train loss on 200 batch: 0.058488
Train loss on 225 batch: 0.084062
Train loss on 250 batch: 0.317406
Train loss on 275 batch: 0.153669
Train loss on 300 batch: 0.385828
Train loss on 325 batch: 0.244725
Train loss on 350 batch: 0.123377
Train loss on 375 batch: 0.164427
Train loss on 400 batch: 0.338660
Train loss on 425 batch: 0.066476
Train loss on 450 batch: 0.150695
Train loss on 475 batch: 0.286620
Train loss on 500 batch: 0.044839
Train loss on 525 batch: 0.057580
Train loss on 550 batch: 0.510356
Train loss on 575 batch: 0.316617
Train loss on 600 batch: 0.207567
Train loss on 625 batch: 0.232347
Train loss on 650 batch: 0.057660
Train loss on 675 batch: 0.166805
Train loss on 700 batch: 0.248298
Train loss on 725 batch: 0.402671
Train loss on 750 batch: 0.190523
Train loss on 775 batch: 0.277521
Train loss on 800 batch: 0.092233
Train loss on 825 batch: 0.151164
Train loss on 850 batch: 0.066679
Train loss on 875 batch: 0.079767
Train loss on 900 batch: 0.180566
Train loss on 925 batch: 0.256555
Train loss on 950 batch: 0.167584
Train loss on 975 batch: 0.171367
Train loss on 1000 batch: 0.239176
Train loss on 1025 batch: 0.162774
Train loss on 1050 batch: 0.085005
Train loss on 1075 batch: 0.249961
Train loss on 1100 batch: 0.263440
Train loss on 1125 batch: 0.075002
Train loss on 1150 batch: 0.229155
Train loss on 1175 batch: 0.091780
Train loss on 1200 batch: 0.266214
Train loss on 1225 batch: 0.152264
Train loss on 1250 batch: 0.024275
Train loss on 1275 batch: 0.297701
Train loss on 1300 batch: 0.246996
Train loss on 1325 batch: 0.172875
Train loss on 1350 batch: 0.164501
Train loss on 1375 batch: 0.181910
Train loss on 1400 batch: 0.400585
Train loss on 1425 batch: 0.141809
Train loss on 1450 batch: 0.142519
Train loss on 1475 batch: 0.272991
Train loss on 1500 batch: 0.081967
Train loss on 1525 batch: 0.128295
Train loss on 1550 batch: 0.311227
Train loss on 1575 batch: 0.019530
Train loss on 1600 batch: 0.077712
Train loss on 1625 batch: 0.132610
Train loss on 1650 batch: 0.185261
Train loss on 1675 batch: 0.059654
Train loss on 1700 batch: 0.257300
Train loss on 1725 batch: 0.147277
Train loss on 1750 batch: 0.109879
Train loss on 1775 batch: 0.220855
Train loss on 1800 batch: 0.161392
Train loss on 1825 batch: 0.158476
Train loss on 1850 batch: 0.283553
Train loss on 1875 batch: 0.062300
Train loss on 1900 batch: 0.145845
Train loss on 1925 batch: 0.177380
Train loss on 1950 batch: 0.130964
Train loss on 1975 batch: 0.060369
Train loss on 2000 batch: 0.079807
Train loss on 2025 batch: 0.058694
Train loss on 2050 batch: 0.064228
Train loss on 2075 batch: 0.067151
Train loss on 2100 batch: 0.170101
Train loss on 2125 batch: 0.100277
Train loss on 2150 batch: 0.177282
Train loss on 2175 batch: 0.042658
Train loss on 2200 batch: 0.241627
Train loss on 2225 batch: 0.379908
Train loss on 2250 batch: 0.221135
Train loss on 2275 batch: 0.391308
Train loss on 2300 batch: 0.347312
Train loss on 2325 batch: 0.159125
Train loss on 2350 batch: 0.223625
Train loss on 2375 batch: 0.058088
Train loss on 2400 batch: 0.070731
Train loss on 2425 batch: 0.161327
Train loss on 2450 batch: 0.421418
Train loss on 2475 batch: 0.245394
Train loss on 2500 batch: 0.111635
Train loss on 2525 batch: 0.111175
Train loss on 2550 batch: 0.155405
Train loss on 2575 batch: 0.085769
Train loss on 2600 batch: 0.101530
Train loss on 2625 batch: 0.132082
Train loss on 2650 batch: 0.055098
Train loss on 2675 batch: 0.112757
Train loss on 2700 batch: 0.105250
Train loss on 2725 batch: 0.169762
Train loss on 2750 batch: 0.289367
Train loss on 2775 batch: 0.324783
Train loss on 2800 batch: 0.188519
Train loss on 2825 batch: 0.130977
Train loss on 2850 batch: 0.183362
Train loss on 2875 batch: 0.138929
Train loss on 2900 batch: 0.435055
Train loss on 2925 batch: 0.068143
: Epoch: 23 | Training Loss: 0.180607 | Val. Loss: 1.784960 | Val. Kappa Score: nan | Estimated time: 200.35
Train loss on 25 batch: 0.177712
Train loss on 50 batch: 0.065692
Train loss on 75 batch: 0.258518
Train loss on 100 batch: 0.167973
Train loss on 125 batch: 0.054879
Train loss on 150 batch: 0.045029
Train loss on 175 batch: 0.196884
Train loss on 200 batch: 0.102911
Train loss on 225 batch: 0.060651
Train loss on 250 batch: 0.145608
Train loss on 275 batch: 0.544147
Train loss on 300 batch: 0.254073
Train loss on 325 batch: 0.207844
Train loss on 350 batch: 0.227622
Train loss on 375 batch: 0.315900
Train loss on 400 batch: 0.091902
Train loss on 425 batch: 0.116951
Train loss on 450 batch: 0.355335
Train loss on 475 batch: 0.114154
Train loss on 500 batch: 0.265854
Train loss on 525 batch: 0.263900
Train loss on 550 batch: 0.309735
Train loss on 575 batch: 0.245187
Train loss on 600 batch: 0.108112
Train loss on 625 batch: 0.077043
Train loss on 650 batch: 0.232572
Train loss on 675 batch: 0.088716
Train loss on 700 batch: 0.194842
Train loss on 725 batch: 0.171405
Train loss on 750 batch: 0.126919
Train loss on 775 batch: 0.325092
Train loss on 800 batch: 0.066478
Train loss on 825 batch: 0.110971
Train loss on 850 batch: 0.175719
Train loss on 875 batch: 0.150299
Train loss on 900 batch: 0.137864
Train loss on 925 batch: 0.259354
Train loss on 950 batch: 0.172620
Train loss on 975 batch: 0.142510
Train loss on 1000 batch: 0.138271
Train loss on 1025 batch: 0.223320
Train loss on 1050 batch: 0.055542
Train loss on 1075 batch: 0.051280
Train loss on 1100 batch: 0.332638
Train loss on 1125 batch: 0.062964
Train loss on 1150 batch: 0.039487
Train loss on 1175 batch: 0.268565
Train loss on 1200 batch: 0.164145
Train loss on 1225 batch: 0.207394
Train loss on 1250 batch: 0.088964
Train loss on 1275 batch: 0.084390
Train loss on 1300 batch: 0.190437
Train loss on 1325 batch: 0.138566
Train loss on 1350 batch: 0.198733
Train loss on 1375 batch: 0.476315
Train loss on 1400 batch: 0.185437
Train loss on 1425 batch: 0.301632
Train loss on 1450 batch: 0.146494
Train loss on 1475 batch: 0.195839
Train loss on 1500 batch: 0.166903
Train loss on 1525 batch: 0.056628
Train loss on 1550 batch: 0.234504
Train loss on 1575 batch: 0.168176
Train loss on 1600 batch: 0.233646
Train loss on 1625 batch: 0.167192
Train loss on 1650 batch: 0.099893
Train loss on 1675 batch: 0.157366
Train loss on 1700 batch: 0.197240
Train loss on 1725 batch: 0.052683
Train loss on 1750 batch: 0.196383
Train loss on 1775 batch: 0.183503
Train loss on 1800 batch: 0.128264
Train loss on 1825 batch: 0.292423
Train loss on 1850 batch: 0.323422
Train loss on 1875 batch: 0.110117
Train loss on 1900 batch: 0.266077
Train loss on 1925 batch: 0.213140
Train loss on 1950 batch: 0.137934
Train loss on 1975 batch: 0.074350
Train loss on 2000 batch: 0.230689
Train loss on 2025 batch: 0.314682
Train loss on 2050 batch: 0.072067
Train loss on 2075 batch: 0.259130
Train loss on 2100 batch: 0.165784
Train loss on 2125 batch: 0.204955
Train loss on 2150 batch: 0.160479
Train loss on 2175 batch: 0.111070
Train loss on 2200 batch: 0.217791
Train loss on 2225 batch: 0.166741
Train loss on 2250 batch: 0.049607
Train loss on 2275 batch: 0.378095
Train loss on 2300 batch: 0.088082
Train loss on 2325 batch: 0.149627
Train loss on 2350 batch: 0.123372
Train loss on 2375 batch: 0.268884
Train loss on 2400 batch: 0.121463
Train loss on 2425 batch: 0.044016
Train loss on 2450 batch: 0.103520
Train loss on 2475 batch: 0.108196
Train loss on 2500 batch: 0.277586
Train loss on 2525 batch: 0.236206
Train loss on 2550 batch: 0.277065
Train loss on 2575 batch: 0.123936
Train loss on 2600 batch: 0.110776
Train loss on 2625 batch: 0.159356
Train loss on 2650 batch: 0.097517
Train loss on 2675 batch: 0.258750
Train loss on 2700 batch: 0.069380
Train loss on 2725 batch: 0.177029
Train loss on 2750 batch: 0.307730
Train loss on 2775 batch: 0.175677
Train loss on 2800 batch: 0.375286
Train loss on 2825 batch: 0.209674
Train loss on 2850 batch: 0.309592
Train loss on 2875 batch: 0.131868
Train loss on 2900 batch: 0.050353
Train loss on 2925 batch: 0.254897
: Epoch: 24 | Training Loss: 0.180172 | Val. Loss: 1.949999 | Val. Kappa Score: nan | Estimated time: 201.06
Train loss on 25 batch: 0.115102
Train loss on 50 batch: 0.128453
Train loss on 75 batch: 0.285810
Train loss on 100 batch: 0.189481
Train loss on 125 batch: 0.105208
Train loss on 150 batch: 0.197485
Train loss on 175 batch: 0.069683
Train loss on 200 batch: 0.112335
Train loss on 225 batch: 0.052188
Train loss on 250 batch: 0.078174
Train loss on 275 batch: 0.112405
Train loss on 300 batch: 0.160250
Train loss on 325 batch: 0.136256
Train loss on 350 batch: 0.152519
Train loss on 375 batch: 0.289193
Train loss on 400 batch: 0.147722
Train loss on 425 batch: 0.084685
Train loss on 450 batch: 0.107076
Train loss on 475 batch: 0.100850
Train loss on 500 batch: 0.165714
Train loss on 525 batch: 0.187978
Train loss on 550 batch: 0.060801
Train loss on 575 batch: 0.074115
Train loss on 600 batch: 0.155721
Train loss on 625 batch: 0.100338
Train loss on 650 batch: 0.197635
Train loss on 675 batch: 0.107703
Train loss on 700 batch: 0.078809
Train loss on 725 batch: 0.114544
Train loss on 750 batch: 0.108373
Train loss on 775 batch: 0.088212
Train loss on 800 batch: 0.065702
Train loss on 825 batch: 0.161280
Train loss on 850 batch: 0.275452
Train loss on 875 batch: 0.054525
Train loss on 900 batch: 0.139246
Train loss on 925 batch: 0.059093
Train loss on 950 batch: 0.103866
Train loss on 975 batch: 0.323743
Train loss on 1000 batch: 0.162112
Train loss on 1025 batch: 0.097378
Train loss on 1050 batch: 0.259038
Train loss on 1075 batch: 0.115447
Train loss on 1100 batch: 0.185913
Train loss on 1125 batch: 0.139301
Train loss on 1150 batch: 0.166959
Train loss on 1175 batch: 0.292270
Train loss on 1200 batch: 0.046364
Train loss on 1225 batch: 0.127043
Train loss on 1250 batch: 0.041550
Train loss on 1275 batch: 0.232996
Train loss on 1300 batch: 0.050153
Train loss on 1325 batch: 0.205280
Train loss on 1350 batch: 0.087837
Train loss on 1375 batch: 0.290613
Train loss on 1400 batch: 0.174217
Train loss on 1425 batch: 0.152189
Train loss on 1450 batch: 0.266219
Train loss on 1475 batch: 0.137234
Train loss on 1500 batch: 0.083618
Train loss on 1525 batch: 0.117757
Train loss on 1550 batch: 0.356256
Train loss on 1575 batch: 0.103463
Train loss on 1600 batch: 0.087435
Train loss on 1625 batch: 0.061447
Train loss on 1650 batch: 0.059412
Train loss on 1675 batch: 0.235796
Train loss on 1700 batch: 0.066071
Train loss on 1725 batch: 0.026739
Train loss on 1750 batch: 0.149072
Train loss on 1775 batch: 0.095706
Train loss on 1800 batch: 0.205774
Train loss on 1825 batch: 0.121734
Train loss on 1850 batch: 0.323504
Train loss on 1875 batch: 0.160397
Train loss on 1900 batch: 0.300610
Train loss on 1925 batch: 0.122113
Train loss on 1950 batch: 0.095413
Train loss on 1975 batch: 0.105688
Train loss on 2000 batch: 0.074850
Train loss on 2025 batch: 0.106354
Train loss on 2050 batch: 0.091574
Train loss on 2075 batch: 0.156243
Train loss on 2100 batch: 0.375338
Train loss on 2125 batch: 0.079566
Train loss on 2150 batch: 0.154927
Train loss on 2175 batch: 0.160614
Train loss on 2200 batch: 0.189017
Train loss on 2225 batch: 0.169295
Train loss on 2250 batch: 0.075694
Train loss on 2275 batch: 0.203382
Train loss on 2300 batch: 0.315327
Train loss on 2325 batch: 0.100179
Train loss on 2350 batch: 0.214460
Train loss on 2375 batch: 0.188499
Train loss on 2400 batch: 0.359656
Train loss on 2425 batch: 0.155100
Train loss on 2450 batch: 0.156381
Train loss on 2475 batch: 0.233566
Train loss on 2500 batch: 0.204135
Train loss on 2525 batch: 0.107817
Train loss on 2550 batch: 0.088440
Train loss on 2575 batch: 0.102354
Train loss on 2600 batch: 0.054803
Train loss on 2625 batch: 0.102942
Train loss on 2650 batch: 0.293695
Train loss on 2675 batch: 0.352569
Train loss on 2700 batch: 0.394444
Train loss on 2725 batch: 0.378647
Train loss on 2750 batch: 0.219198
Train loss on 2775 batch: 0.076393
Train loss on 2800 batch: 0.160646
Train loss on 2825 batch: 0.126424
Train loss on 2850 batch: 0.114475
Train loss on 2875 batch: 0.205011
Train loss on 2900 batch: 0.057701
Train loss on 2925 batch: 0.088911
: Epoch: 25 | Training Loss: 0.154226 | Val. Loss: 1.758241 | Val. Kappa Score: nan | Estimated time: 202.75
Train loss on 25 batch: 0.117197
Train loss on 50 batch: 0.087041
Train loss on 75 batch: 0.122185
Train loss on 100 batch: 0.187280
Train loss on 125 batch: 0.139488
Train loss on 150 batch: 0.103989
Train loss on 175 batch: 0.078938
Train loss on 200 batch: 0.380830
Train loss on 225 batch: 0.060870
Train loss on 250 batch: 0.061022
Train loss on 275 batch: 0.125610
Train loss on 300 batch: 0.039119
Train loss on 325 batch: 0.336741
Train loss on 350 batch: 0.117719
Train loss on 375 batch: 0.322651
Train loss on 400 batch: 0.177009
Train loss on 425 batch: 0.082454
Train loss on 450 batch: 0.209989
Train loss on 475 batch: 0.099523
Train loss on 500 batch: 0.071776
Train loss on 525 batch: 0.151135
Train loss on 550 batch: 0.234488
Train loss on 575 batch: 0.096754
Train loss on 600 batch: 0.100523
Train loss on 625 batch: 0.069651
Train loss on 650 batch: 0.228518
Train loss on 675 batch: 0.294727
Train loss on 700 batch: 0.104904
Train loss on 725 batch: 0.225522
Train loss on 750 batch: 0.181601
Train loss on 775 batch: 0.132357
Train loss on 800 batch: 0.138122
Train loss on 825 batch: 0.577956
Train loss on 850 batch: 0.031801
Train loss on 875 batch: 0.150398
Train loss on 900 batch: 0.200758
Train loss on 925 batch: 0.090779
Train loss on 950 batch: 0.377982
Train loss on 975 batch: 0.222854
Train loss on 1000 batch: 0.460298
Train loss on 1025 batch: 0.113899
Train loss on 1050 batch: 0.249060
Train loss on 1075 batch: 0.101198
Train loss on 1100 batch: 0.075516
Train loss on 1125 batch: 0.476516
Train loss on 1150 batch: 0.129306
Train loss on 1175 batch: 0.073862
Train loss on 1200 batch: 0.124552
Train loss on 1225 batch: 0.236976
Train loss on 1250 batch: 0.082446
Train loss on 1275 batch: 0.097763
Train loss on 1300 batch: 0.132725
Train loss on 1325 batch: 0.079411
Train loss on 1350 batch: 0.249371
Train loss on 1375 batch: 0.186270
Train loss on 1400 batch: 0.061432
Train loss on 1425 batch: 0.185049
Train loss on 1450 batch: 0.168718
Train loss on 1475 batch: 0.164108
Train loss on 1500 batch: 0.051499
Train loss on 1525 batch: 0.037907
Train loss on 1550 batch: 0.293374
Train loss on 1575 batch: 0.108224
Train loss on 1600 batch: 0.077345
Train loss on 1625 batch: 0.084506
Train loss on 1650 batch: 0.041284
Train loss on 1675 batch: 0.062814
Train loss on 1700 batch: 0.107852
Train loss on 1725 batch: 0.070372
Train loss on 1750 batch: 0.048733
Train loss on 1775 batch: 0.190175
Train loss on 1800 batch: 0.136652
Train loss on 1825 batch: 0.114221
Train loss on 1850 batch: 0.238472
Train loss on 1875 batch: 0.085808
Train loss on 1900 batch: 0.107826
Train loss on 1925 batch: 0.090490
Train loss on 1950 batch: 0.370789
Train loss on 1975 batch: 0.087535
Train loss on 2000 batch: 0.053530
Train loss on 2025 batch: 0.108518
Train loss on 2050 batch: 0.454218
Train loss on 2075 batch: 0.174078
Train loss on 2100 batch: 0.059907
Train loss on 2125 batch: 0.250174
Train loss on 2150 batch: 0.135310
Train loss on 2175 batch: 0.145977
Train loss on 2200 batch: 0.098892
Train loss on 2225 batch: 0.089395
Train loss on 2250 batch: 0.204284
Train loss on 2275 batch: 0.070365
Train loss on 2300 batch: 0.102482
Train loss on 2325 batch: 0.236130
Train loss on 2350 batch: 0.279625
Train loss on 2375 batch: 0.116516
Train loss on 2400 batch: 0.127678
Train loss on 2425 batch: 0.118745
Train loss on 2450 batch: 0.131437
Train loss on 2475 batch: 0.066355
Train loss on 2500 batch: 0.118865
Train loss on 2525 batch: 0.100106
Train loss on 2550 batch: 0.087835
Train loss on 2575 batch: 0.061256
Train loss on 2600 batch: 0.323453
Train loss on 2625 batch: 0.304397
Train loss on 2650 batch: 0.153341
Train loss on 2675 batch: 0.244886
Train loss on 2700 batch: 0.120824
Train loss on 2725 batch: 0.073651
Train loss on 2750 batch: 0.035153
Train loss on 2775 batch: 0.094899
Train loss on 2800 batch: 0.034963
Train loss on 2825 batch: 0.530950
Train loss on 2850 batch: 0.039728
Train loss on 2875 batch: 0.114120
Train loss on 2900 batch: 0.360695
Train loss on 2925 batch: 0.098600
: Epoch: 26 | Training Loss: 0.156478 | Val. Loss: 2.224023 | Val. Kappa Score: nan | Estimated time: 200.09
time_estimated: 5222.55
n-epochs: 26
time_estimated: 5222.55
----------------------------------------

Experiment N: 6: 
date: 2019.08.06 09:38:31
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 2
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 2.700224
Train loss on 50 batch: 1.909298
Train loss on 75 batch: 2.517559
Train loss on 100 batch: 1.898081
Train loss on 125 batch: 1.862242
Train loss on 150 batch: 0.933132
Train loss on 175 batch: 0.755201
Train loss on 200 batch: 1.635448
Train loss on 225 batch: 1.366291
Train loss on 250 batch: 0.627711
Train loss on 275 batch: 0.920109
Train loss on 300 batch: 1.058515
Train loss on 325 batch: 1.058341
Train loss on 350 batch: 0.620083
Train loss on 375 batch: 0.807053
Train loss on 400 batch: 0.600107
Train loss on 425 batch: 1.019961
Train loss on 450 batch: 1.976387
Train loss on 475 batch: 2.705626
Train loss on 500 batch: 1.625613
Train loss on 525 batch: 1.006691
Train loss on 550 batch: 0.787395
Train loss on 575 batch: 0.486630
Train loss on 600 batch: 0.676664
Train loss on 625 batch: 0.951710
Train loss on 650 batch: 1.355588
Train loss on 675 batch: 1.216761
Train loss on 700 batch: 0.793434
Train loss on 725 batch: 0.675752
Train loss on 750 batch: 0.591825
Train loss on 775 batch: 0.714588
Train loss on 800 batch: 0.697047
Train loss on 825 batch: 0.633199
Train loss on 850 batch: 0.903213
Train loss on 875 batch: 0.954233
Train loss on 900 batch: 0.747875
Train loss on 925 batch: 0.782283
Train loss on 950 batch: 0.575186
Train loss on 975 batch: 0.813494
Train loss on 1000 batch: 0.417913
Train loss on 1025 batch: 0.482950
Train loss on 1050 batch: 0.974521
Train loss on 1075 batch: 0.725755
Train loss on 1100 batch: 0.731740
Train loss on 1125 batch: 0.543189
Train loss on 1150 batch: 1.095298
Train loss on 1175 batch: 0.520505
Train loss on 1200 batch: 0.937097
Train loss on 1225 batch: 0.306001
Train loss on 1250 batch: 0.522191
Train loss on 1275 batch: 0.746443
Train loss on 1300 batch: 0.953490
Train loss on 1325 batch: 0.800609
Train loss on 1350 batch: 0.740495
Train loss on 1375 batch: 0.557152
Train loss on 1400 batch: 0.658936
Train loss on 1425 batch: 0.648009
Train loss on 1450 batch: 0.766431
best-train-loss: 0.984298
best-valid-loss: 0.829985
best-kappa: nan
: Epoch: 1 | Training Loss: 0.984298 | Val. Loss: 0.829985 | Val. Kappa Score: nan | Estimated time: 110.29
Train loss on 25 batch: 0.865784
Train loss on 50 batch: 0.517267
Train loss on 75 batch: 0.745176
Train loss on 100 batch: 0.295339
Train loss on 125 batch: 0.636834
Train loss on 150 batch: 0.497373
Train loss on 175 batch: 0.918581
Train loss on 200 batch: 0.375979
Train loss on 225 batch: 0.744635
Train loss on 250 batch: 0.606012
Train loss on 275 batch: 0.437103
Train loss on 300 batch: 0.668868
Train loss on 325 batch: 0.464553
Train loss on 350 batch: 0.486275
Train loss on 375 batch: 0.474292
Train loss on 400 batch: 0.915880
Train loss on 425 batch: 0.870852
Train loss on 450 batch: 0.627150
Train loss on 475 batch: 1.001670
Train loss on 500 batch: 0.551077
Train loss on 525 batch: 0.333423
Train loss on 550 batch: 0.301330
Train loss on 575 batch: 0.390576
Train loss on 600 batch: 0.676532
Train loss on 625 batch: 0.237226
Train loss on 650 batch: 0.332634
Train loss on 675 batch: 0.414447
Train loss on 700 batch: 0.760344
Train loss on 725 batch: 0.640556
Train loss on 750 batch: 0.428449
Train loss on 775 batch: 0.446566
Train loss on 800 batch: 0.411897
Train loss on 825 batch: 0.365595
Train loss on 850 batch: 0.571973
Train loss on 875 batch: 0.709282
Train loss on 900 batch: 0.484972
Train loss on 925 batch: 0.790555
Train loss on 950 batch: 0.631923
Train loss on 975 batch: 0.528759
Train loss on 1000 batch: 0.689836
Train loss on 1025 batch: 0.417948
Train loss on 1050 batch: 0.596292
Train loss on 1075 batch: 0.969958
Train loss on 1100 batch: 0.322812
Train loss on 1125 batch: 0.761610
Train loss on 1150 batch: 0.474448
Train loss on 1175 batch: 0.582565
Train loss on 1200 batch: 0.354564
Train loss on 1225 batch: 0.714146
Train loss on 1250 batch: 0.596356
Train loss on 1275 batch: 0.468530
Train loss on 1300 batch: 0.827321
Train loss on 1325 batch: 0.249763
Train loss on 1350 batch: 0.716035
Train loss on 1375 batch: 0.664140
Train loss on 1400 batch: 0.608361
Train loss on 1425 batch: 0.519145
Train loss on 1450 batch: 0.414024
best-train-loss: 0.570786
best-valid-loss: 0.614815
best-kappa: nan
: Epoch: 2 | Training Loss: 0.570786 | Val. Loss: 0.614815 | Val. Kappa Score: nan | Estimated time: 110.23
Train loss on 25 batch: 0.527912
Train loss on 50 batch: 0.303407
Train loss on 75 batch: 0.666314
Train loss on 100 batch: 0.409444
Train loss on 125 batch: 0.628334
Train loss on 150 batch: 0.462650
Train loss on 175 batch: 0.354144
Train loss on 200 batch: 0.663896
Train loss on 225 batch: 0.451939
Train loss on 250 batch: 0.515911
Train loss on 275 batch: 0.399449
Train loss on 300 batch: 0.323998
Train loss on 325 batch: 0.747272
Train loss on 350 batch: 0.398965
Train loss on 375 batch: 0.452154
Train loss on 400 batch: 0.441927
Train loss on 425 batch: 0.381178
Train loss on 450 batch: 0.415079
Train loss on 475 batch: 0.424516
Train loss on 500 batch: 0.362870
Train loss on 525 batch: 0.515642
Train loss on 550 batch: 0.486199
Train loss on 575 batch: 0.693407
Train loss on 600 batch: 0.443410
Train loss on 625 batch: 0.376244
Train loss on 650 batch: 0.321630
Train loss on 675 batch: 0.356343
Train loss on 700 batch: 0.700482
Train loss on 725 batch: 0.319051
Train loss on 750 batch: 0.723007
Train loss on 775 batch: 0.652794
Train loss on 800 batch: 0.438173
Train loss on 825 batch: 0.406047
Train loss on 850 batch: 0.495367
Train loss on 875 batch: 0.673794
Train loss on 900 batch: 0.411575
Train loss on 925 batch: 0.671389
Train loss on 950 batch: 0.514141
Train loss on 975 batch: 0.560559
Train loss on 1000 batch: 0.574266
Train loss on 1025 batch: 0.410805
Train loss on 1050 batch: 0.623985
Train loss on 1075 batch: 0.479552
Train loss on 1100 batch: 0.910860
Train loss on 1125 batch: 0.225567
Train loss on 1150 batch: 0.278179
Train loss on 1175 batch: 0.520391
Train loss on 1200 batch: 0.360283
Train loss on 1225 batch: 0.345719
Train loss on 1250 batch: 0.215693
Train loss on 1275 batch: 0.349129
Train loss on 1300 batch: 0.397839
Train loss on 1325 batch: 0.307331
Train loss on 1350 batch: 0.327520
Train loss on 1375 batch: 0.532551
Train loss on 1400 batch: 0.391499
Train loss on 1425 batch: 0.270459
Train loss on 1450 batch: 0.424418
: Epoch: 3 | Training Loss: 0.466149 | Val. Loss: 0.646662 | Val. Kappa Score: nan | Estimated time: 111.18
Train loss on 25 batch: 0.202763
Train loss on 50 batch: 0.297279
Train loss on 75 batch: 0.207219
Train loss on 100 batch: 0.424455
Train loss on 125 batch: 0.471149
Train loss on 150 batch: 0.431378
Train loss on 175 batch: 0.489228
Train loss on 200 batch: 0.341926
Train loss on 225 batch: 0.482363
Train loss on 250 batch: 0.442284
Train loss on 275 batch: 0.528401
Train loss on 300 batch: 0.471437
Train loss on 325 batch: 0.484265
Train loss on 350 batch: 0.575725
Train loss on 375 batch: 0.810354
Train loss on 400 batch: 0.433166
Train loss on 425 batch: 0.312241
Train loss on 450 batch: 0.247184
Train loss on 475 batch: 0.539994
Train loss on 500 batch: 0.218396
Train loss on 525 batch: 0.597155
Train loss on 550 batch: 0.549667
Train loss on 575 batch: 0.409131
Train loss on 600 batch: 0.515071
Train loss on 625 batch: 0.422137
Train loss on 650 batch: 0.504546
Train loss on 675 batch: 0.407212
Train loss on 700 batch: 0.392500
Train loss on 725 batch: 0.578371
Train loss on 750 batch: 0.308096
Train loss on 775 batch: 0.391449
Train loss on 800 batch: 0.380784
Train loss on 825 batch: 0.142854
Train loss on 850 batch: 0.391995
Train loss on 875 batch: 0.505692
Train loss on 900 batch: 0.537118
Train loss on 925 batch: 0.812909
Train loss on 950 batch: 0.973576
Train loss on 975 batch: 0.553821
Train loss on 1000 batch: 0.604731
Train loss on 1025 batch: 0.685469
Train loss on 1050 batch: 0.375146
Train loss on 1075 batch: 0.383508
Train loss on 1100 batch: 0.345862
Train loss on 1125 batch: 0.645559
Train loss on 1150 batch: 0.350676
Train loss on 1175 batch: 0.184872
Train loss on 1200 batch: 0.404070
Train loss on 1225 batch: 0.479245
Train loss on 1250 batch: 0.566478
Train loss on 1275 batch: 0.209007
Train loss on 1300 batch: 0.321064
Train loss on 1325 batch: 0.321582
Train loss on 1350 batch: 0.314983
Train loss on 1375 batch: 0.643637
Train loss on 1400 batch: 0.670521
Train loss on 1425 batch: 0.513505
Train loss on 1450 batch: 0.452656
: Epoch: 4 | Training Loss: 0.452722 | Val. Loss: 0.737904 | Val. Kappa Score: nan | Estimated time: 110.45
Train loss on 25 batch: 0.462243
Train loss on 50 batch: 0.876753
Train loss on 75 batch: 0.577501
Train loss on 100 batch: 0.461988
Train loss on 125 batch: 0.501489
Train loss on 150 batch: 0.563190
Train loss on 175 batch: 0.415745
Train loss on 200 batch: 0.412268
Train loss on 225 batch: 0.670959
Train loss on 250 batch: 0.348373
Train loss on 275 batch: 0.484762
Train loss on 300 batch: 0.300998
Train loss on 325 batch: 0.325252
Train loss on 350 batch: 0.272059
Train loss on 375 batch: 0.450693
Train loss on 400 batch: 0.402565
Train loss on 425 batch: 0.285288
Train loss on 450 batch: 0.272426
Train loss on 475 batch: 0.277218
Train loss on 500 batch: 0.564767
Train loss on 525 batch: 0.258726
Train loss on 550 batch: 0.383340
Train loss on 575 batch: 0.247256
Train loss on 600 batch: 0.282390
Train loss on 625 batch: 0.234942
Train loss on 650 batch: 0.230805
Train loss on 675 batch: 0.272870
Train loss on 700 batch: 0.175712
Train loss on 725 batch: 0.123803
Train loss on 750 batch: 0.590470
Train loss on 775 batch: 0.409554
Train loss on 800 batch: 0.292931
Train loss on 825 batch: 0.552075
Train loss on 850 batch: 0.226849
Train loss on 875 batch: 0.729770
Train loss on 900 batch: 0.478260
Train loss on 925 batch: 0.209065
Train loss on 950 batch: 0.312719
Train loss on 975 batch: 0.554915
Train loss on 1000 batch: 0.536352
Train loss on 1025 batch: 0.505824
Train loss on 1050 batch: 0.269428
Train loss on 1075 batch: 0.228809
Train loss on 1100 batch: 0.371343
Train loss on 1125 batch: 0.415583
Train loss on 1150 batch: 0.283603
Train loss on 1175 batch: 0.470970
Train loss on 1200 batch: 0.584569
Train loss on 1225 batch: 0.416374
Train loss on 1250 batch: 0.294346
Train loss on 1275 batch: 0.167344
Train loss on 1300 batch: 0.310183
Train loss on 1325 batch: 0.395209
Train loss on 1350 batch: 0.497056
Train loss on 1375 batch: 0.598967
Train loss on 1400 batch: 0.260891
Train loss on 1425 batch: 0.241425
Train loss on 1450 batch: 0.497416
: Epoch: 5 | Training Loss: 0.393770 | Val. Loss: 0.724345 | Val. Kappa Score: nan | Estimated time: 109.75
Train loss on 25 batch: 0.206692
Train loss on 50 batch: 0.330646
Train loss on 75 batch: 0.186532
Train loss on 100 batch: 0.382617
Train loss on 125 batch: 0.239857
Train loss on 150 batch: 0.840189
Train loss on 175 batch: 0.157847
Train loss on 200 batch: 0.277477
Train loss on 225 batch: 0.322708
Train loss on 250 batch: 0.407776
Train loss on 275 batch: 0.655651
Train loss on 300 batch: 0.223706
Train loss on 325 batch: 0.284285
Train loss on 350 batch: 0.265597
Train loss on 375 batch: 0.659770
Train loss on 400 batch: 0.275579
Train loss on 425 batch: 0.152983
Train loss on 450 batch: 0.231247
Train loss on 475 batch: 0.333318
Train loss on 500 batch: 0.263500
Train loss on 525 batch: 0.477981
Train loss on 550 batch: 0.320775
Train loss on 575 batch: 0.529202
Train loss on 600 batch: 0.324217
Train loss on 625 batch: 0.269068
Train loss on 650 batch: 0.502154
Train loss on 675 batch: 0.546217
Train loss on 700 batch: 0.451645
Train loss on 725 batch: 0.651542
Train loss on 750 batch: 0.292500
Train loss on 775 batch: 0.284190
Train loss on 800 batch: 0.463585
Train loss on 825 batch: 0.499190
Train loss on 850 batch: 0.425810
Train loss on 875 batch: 0.424031
Train loss on 900 batch: 0.464372
Train loss on 925 batch: 0.254848
Train loss on 950 batch: 0.250687
Train loss on 975 batch: 0.466999
Train loss on 1000 batch: 0.518949
Train loss on 1025 batch: 0.376501
Train loss on 1050 batch: 0.336776
Train loss on 1075 batch: 0.449499
Train loss on 1100 batch: 0.278130
Train loss on 1125 batch: 0.559312
Train loss on 1150 batch: 0.585143
Train loss on 1175 batch: 0.468617
Train loss on 1200 batch: 0.231033
Train loss on 1225 batch: 0.283921
Train loss on 1250 batch: 0.421351
Train loss on 1275 batch: 0.674038
Train loss on 1300 batch: 0.326662
Train loss on 1325 batch: 0.449537
Train loss on 1350 batch: 0.382641
Train loss on 1375 batch: 0.284929
Train loss on 1400 batch: 0.256570
Train loss on 1425 batch: 0.231750
Train loss on 1450 batch: 0.228933
best-train-loss: 0.378298
best-valid-loss: 0.493759
best-kappa: nan
: Epoch: 6 | Training Loss: 0.378298 | Val. Loss: 0.493759 | Val. Kappa Score: nan | Estimated time: 111.00
Train loss on 25 batch: 0.375601
Train loss on 50 batch: 0.503001
Train loss on 75 batch: 0.317061
Train loss on 100 batch: 0.254279
Train loss on 125 batch: 0.599302
Train loss on 150 batch: 0.341238
Train loss on 175 batch: 0.333727
Train loss on 200 batch: 0.212009
Train loss on 225 batch: 0.351594
Train loss on 250 batch: 0.448074
Train loss on 275 batch: 0.144818
Train loss on 300 batch: 0.388150
Train loss on 325 batch: 0.296054
Train loss on 350 batch: 0.302192
Train loss on 375 batch: 0.258604
Train loss on 400 batch: 0.355333
Train loss on 425 batch: 0.381128
Train loss on 450 batch: 0.380716
Train loss on 475 batch: 0.353909
Train loss on 500 batch: 0.389676
Train loss on 525 batch: 0.340760
Train loss on 550 batch: 0.212798
Train loss on 575 batch: 0.534185
Train loss on 600 batch: 0.215040
Train loss on 625 batch: 0.144518
Train loss on 650 batch: 0.237640
Train loss on 675 batch: 0.322815
Train loss on 700 batch: 0.430107
Train loss on 725 batch: 0.298026
Train loss on 750 batch: 0.191175
Train loss on 775 batch: 0.429267
Train loss on 800 batch: 0.314617
Train loss on 825 batch: 0.552241
Train loss on 850 batch: 0.325408
Train loss on 875 batch: 0.158701
Train loss on 900 batch: 0.324332
Train loss on 925 batch: 0.298872
Train loss on 950 batch: 0.394432
Train loss on 975 batch: 0.411069
Train loss on 1000 batch: 0.630001
Train loss on 1025 batch: 0.166490
Train loss on 1050 batch: 0.320534
Train loss on 1075 batch: 0.455905
Train loss on 1100 batch: 0.479769
Train loss on 1125 batch: 0.449490
Train loss on 1150 batch: 0.525215
Train loss on 1175 batch: 0.313692
Train loss on 1200 batch: 0.287790
Train loss on 1225 batch: 0.803157
Train loss on 1250 batch: 0.409192
Train loss on 1275 batch: 0.259295
Train loss on 1300 batch: 0.320543
Train loss on 1325 batch: 0.392220
Train loss on 1350 batch: 0.189113
Train loss on 1375 batch: 0.284261
Train loss on 1400 batch: 0.288426
Train loss on 1425 batch: 0.554629
Train loss on 1450 batch: 0.401367
: Epoch: 7 | Training Loss: 0.356096 | Val. Loss: 0.626180 | Val. Kappa Score: nan | Estimated time: 109.51
Train loss on 25 batch: 0.273205
Train loss on 50 batch: 0.422598
Train loss on 75 batch: 0.403891
Train loss on 100 batch: 0.449390
Train loss on 125 batch: 0.423302
Train loss on 150 batch: 0.374815
Train loss on 175 batch: 0.317728
Train loss on 200 batch: 0.298963
Train loss on 225 batch: 0.217273
Train loss on 250 batch: 0.323036
Train loss on 275 batch: 0.401860
Train loss on 300 batch: 0.435779
Train loss on 325 batch: 0.561940
Train loss on 350 batch: 0.265230
Train loss on 375 batch: 0.201293
Train loss on 400 batch: 0.345457
Train loss on 425 batch: 0.308577
Train loss on 450 batch: 0.222600
Train loss on 475 batch: 0.324059
Train loss on 500 batch: 0.332570
Train loss on 525 batch: 0.220087
Train loss on 550 batch: 0.185839
Train loss on 575 batch: 0.307162
Train loss on 600 batch: 0.268986
Train loss on 625 batch: 0.611097
Train loss on 650 batch: 0.383915
Train loss on 675 batch: 0.393065
Train loss on 700 batch: 0.449000
Train loss on 725 batch: 0.143888
Train loss on 750 batch: 0.222200
Train loss on 775 batch: 0.280616
Train loss on 800 batch: 0.390529
Train loss on 825 batch: 0.287714
Train loss on 850 batch: 0.182379
Train loss on 875 batch: 0.488200
Train loss on 900 batch: 0.393889
Train loss on 925 batch: 0.558829
Train loss on 950 batch: 0.465503
Train loss on 975 batch: 0.106064
Train loss on 1000 batch: 0.432696
Train loss on 1025 batch: 0.207006
Train loss on 1050 batch: 0.217272
Train loss on 1075 batch: 0.135566
Train loss on 1100 batch: 0.371645
Train loss on 1125 batch: 0.240666
Train loss on 1150 batch: 0.520560
Train loss on 1175 batch: 0.452528
Train loss on 1200 batch: 0.326861
Train loss on 1225 batch: 0.246333
Train loss on 1250 batch: 0.192198
Train loss on 1275 batch: 0.343001
Train loss on 1300 batch: 0.286617
Train loss on 1325 batch: 0.536900
Train loss on 1350 batch: 0.375157
Train loss on 1375 batch: 0.325169
Train loss on 1400 batch: 0.388644
Train loss on 1425 batch: 0.300736
Train loss on 1450 batch: 0.230214
: Epoch: 8 | Training Loss: 0.334005 | Val. Loss: 0.514299 | Val. Kappa Score: nan | Estimated time: 110.23
Train loss on 25 batch: 0.433253
Train loss on 50 batch: 0.623443
Train loss on 75 batch: 0.312661
Train loss on 100 batch: 0.353062
Train loss on 125 batch: 0.327720
Train loss on 150 batch: 0.556153
Train loss on 175 batch: 0.451464
Train loss on 200 batch: 0.215978
Train loss on 225 batch: 0.405082
Train loss on 250 batch: 0.272233
Train loss on 275 batch: 0.262189
Train loss on 300 batch: 0.239614
Train loss on 325 batch: 0.327495
Train loss on 350 batch: 0.233064
Train loss on 375 batch: 0.304264
Train loss on 400 batch: 0.355324
Train loss on 425 batch: 0.213125
Train loss on 450 batch: 0.270084
Train loss on 475 batch: 0.295499
Train loss on 500 batch: 0.310858
Train loss on 525 batch: 0.213917
Train loss on 550 batch: 0.468763
Train loss on 575 batch: 0.194483
Train loss on 600 batch: 0.243199
Train loss on 625 batch: 0.268048
Train loss on 650 batch: 0.376786
Train loss on 675 batch: 0.345313
Train loss on 700 batch: 0.237425
Train loss on 725 batch: 0.141777
Train loss on 750 batch: 0.444594
Train loss on 775 batch: 0.374353
Train loss on 800 batch: 0.272928
Train loss on 825 batch: 0.499375
Train loss on 850 batch: 0.268984
Train loss on 875 batch: 0.262960
Train loss on 900 batch: 0.216142
Train loss on 925 batch: 0.219498
Train loss on 950 batch: 0.282600
Train loss on 975 batch: 0.167357
Train loss on 1000 batch: 0.308323
Train loss on 1025 batch: 0.254302
Train loss on 1050 batch: 0.163936
Train loss on 1075 batch: 0.173001
Train loss on 1100 batch: 0.171067
Train loss on 1125 batch: 0.410841
Train loss on 1150 batch: 0.219718
Train loss on 1175 batch: 0.383084
Train loss on 1200 batch: 0.167374
Train loss on 1225 batch: 0.330674
Train loss on 1250 batch: 0.573739
Train loss on 1275 batch: 0.452610
Train loss on 1300 batch: 0.159897
Train loss on 1325 batch: 0.240984
Train loss on 1350 batch: 0.454222
Train loss on 1375 batch: 0.370614
Train loss on 1400 batch: 0.132122
Train loss on 1425 batch: 0.169061
Train loss on 1450 batch: 0.409907
best-train-loss: 0.307009
best-valid-loss: 0.430778
best-kappa: nan
: Epoch: 9 | Training Loss: 0.307009 | Val. Loss: 0.430778 | Val. Kappa Score: nan | Estimated time: 111.52
Train loss on 25 batch: 0.133778
Train loss on 50 batch: 0.358173
Train loss on 75 batch: 0.177053
Train loss on 100 batch: 0.282061
Train loss on 125 batch: 0.437577
Train loss on 150 batch: 0.396995
Train loss on 175 batch: 0.517054
Train loss on 200 batch: 0.248592
Train loss on 225 batch: 0.389012
Train loss on 250 batch: 0.246860
Train loss on 275 batch: 0.170136
Train loss on 300 batch: 0.232146
Train loss on 325 batch: 0.312523
Train loss on 350 batch: 0.178391
Train loss on 375 batch: 0.269557
Train loss on 400 batch: 0.277756
Train loss on 425 batch: 0.434732
Train loss on 450 batch: 0.176690
Train loss on 475 batch: 0.243953
Train loss on 500 batch: 0.356046
Train loss on 525 batch: 0.353022
Train loss on 550 batch: 0.252757
Train loss on 575 batch: 0.228323
Train loss on 600 batch: 0.477036
Train loss on 625 batch: 0.393444
Train loss on 650 batch: 0.268780
Train loss on 675 batch: 0.218098
Train loss on 700 batch: 0.323363
Train loss on 725 batch: 0.215890
Train loss on 750 batch: 0.282518
Train loss on 775 batch: 0.321405
Train loss on 800 batch: 0.221832
Train loss on 825 batch: 0.416648
Train loss on 850 batch: 0.366489
Train loss on 875 batch: 0.250961
Train loss on 900 batch: 0.412084
Train loss on 925 batch: 0.253164
Train loss on 950 batch: 0.228830
Train loss on 975 batch: 0.256602
Train loss on 1000 batch: 0.183455
Train loss on 1025 batch: 0.313329
Train loss on 1050 batch: 0.286772
Train loss on 1075 batch: 0.280339
Train loss on 1100 batch: 0.330353
Train loss on 1125 batch: 0.343783
Train loss on 1150 batch: 0.220110
Train loss on 1175 batch: 0.238947
Train loss on 1200 batch: 0.368184
Train loss on 1225 batch: 0.179523
Train loss on 1250 batch: 0.340797
Train loss on 1275 batch: 0.215192
Train loss on 1300 batch: 0.254705
Train loss on 1325 batch: 0.387429
Train loss on 1350 batch: 0.295851
Train loss on 1375 batch: 0.460998
Train loss on 1400 batch: 0.397751
Train loss on 1425 batch: 0.246958
Train loss on 1450 batch: 0.379403
: Epoch: 10 | Training Loss: 0.298348 | Val. Loss: 0.467861 | Val. Kappa Score: nan | Estimated time: 108.79
Train loss on 25 batch: 0.262112
Train loss on 50 batch: 0.119812
Train loss on 75 batch: 0.114786
Train loss on 100 batch: 0.152953
Train loss on 125 batch: 0.192758
Train loss on 150 batch: 0.253813
Train loss on 175 batch: 0.130252
Train loss on 200 batch: 0.343908
Train loss on 225 batch: 0.182699
Train loss on 250 batch: 0.296807
Train loss on 275 batch: 0.184968
Train loss on 300 batch: 0.403960
Train loss on 325 batch: 0.218750
Train loss on 350 batch: 0.134928
Train loss on 375 batch: 0.328558
Train loss on 400 batch: 0.214210
Train loss on 425 batch: 0.326880
Train loss on 450 batch: 0.325729
Train loss on 475 batch: 0.209006
Train loss on 500 batch: 0.273061
Train loss on 525 batch: 0.418685
Train loss on 550 batch: 0.541361
Train loss on 575 batch: 0.218969
Train loss on 600 batch: 0.190896
Train loss on 625 batch: 0.367435
Train loss on 650 batch: 0.273662
Train loss on 675 batch: 0.221459
Train loss on 700 batch: 0.295862
Train loss on 725 batch: 0.415034
Train loss on 750 batch: 0.209266
Train loss on 775 batch: 0.177952
Train loss on 800 batch: 0.430518
Train loss on 825 batch: 0.258035
Train loss on 850 batch: 0.232099
Train loss on 875 batch: 0.219657
Train loss on 900 batch: 0.284474
Train loss on 925 batch: 0.179748
Train loss on 950 batch: 0.396624
Train loss on 975 batch: 0.353785
Train loss on 1000 batch: 0.280479
Train loss on 1025 batch: 0.214342
Train loss on 1050 batch: 0.323144
Train loss on 1075 batch: 0.186484
Train loss on 1100 batch: 0.315754
Train loss on 1125 batch: 0.284237
Train loss on 1150 batch: 0.298719
Train loss on 1175 batch: 0.248611
Train loss on 1200 batch: 0.155454
Train loss on 1225 batch: 0.244203
Train loss on 1250 batch: 0.427807
Train loss on 1275 batch: 0.321574
Train loss on 1300 batch: 0.386677
Train loss on 1325 batch: 0.453483
Train loss on 1350 batch: 0.183468
Train loss on 1375 batch: 0.188704
Train loss on 1400 batch: 0.184155
Train loss on 1425 batch: 0.251466
Train loss on 1450 batch: 0.327496
: Epoch: 11 | Training Loss: 0.269513 | Val. Loss: 0.637633 | Val. Kappa Score: nan | Estimated time: 110.40
Train loss on 25 batch: 0.664439
Train loss on 50 batch: 0.242810
Train loss on 75 batch: 0.203049
Train loss on 100 batch: 0.128251
Train loss on 125 batch: 0.323148
Train loss on 150 batch: 0.209266
Train loss on 175 batch: 0.163496
Train loss on 200 batch: 0.199822
Train loss on 225 batch: 0.210479
Train loss on 250 batch: 0.302712
Train loss on 275 batch: 0.185692
Train loss on 300 batch: 0.160394
Train loss on 325 batch: 0.189744
Train loss on 350 batch: 0.253435
Train loss on 375 batch: 0.255102
Train loss on 400 batch: 0.469908
Train loss on 425 batch: 0.254884
Train loss on 450 batch: 0.190637
Train loss on 475 batch: 0.379119
Train loss on 500 batch: 0.377556
Train loss on 525 batch: 0.194474
Train loss on 550 batch: 0.346783
Train loss on 575 batch: 0.346813
Train loss on 600 batch: 0.217540
Train loss on 625 batch: 0.075431
Train loss on 650 batch: 0.426695
Train loss on 675 batch: 0.172783
Train loss on 700 batch: 0.220993
Train loss on 725 batch: 0.330613
Train loss on 750 batch: 0.305631
Train loss on 775 batch: 0.188561
Train loss on 800 batch: 0.255640
Train loss on 825 batch: 0.278336
Train loss on 850 batch: 0.289128
Train loss on 875 batch: 0.273465
Train loss on 900 batch: 0.286332
Train loss on 925 batch: 0.217889
Train loss on 950 batch: 0.250322
Train loss on 975 batch: 0.326214
Train loss on 1000 batch: 0.517222
Train loss on 1025 batch: 0.185924
Train loss on 1050 batch: 0.321108
Train loss on 1075 batch: 0.216862
Train loss on 1100 batch: 0.318371
Train loss on 1125 batch: 0.458285
Train loss on 1150 batch: 0.189937
Train loss on 1175 batch: 0.324952
Train loss on 1200 batch: 0.232245
Train loss on 1225 batch: 0.175806
Train loss on 1250 batch: 0.249992
Train loss on 1275 batch: 0.137895
Train loss on 1300 batch: 0.194367
Train loss on 1325 batch: 0.286817
Train loss on 1350 batch: 0.209655
Train loss on 1375 batch: 0.223158
Train loss on 1400 batch: 0.213853
Train loss on 1425 batch: 0.403880
Train loss on 1450 batch: 0.199379
: Epoch: 12 | Training Loss: 0.265988 | Val. Loss: 0.507585 | Val. Kappa Score: nan | Estimated time: 111.66
Train loss on 25 batch: 0.163302
Train loss on 50 batch: 0.197487
Train loss on 75 batch: 0.104174
Train loss on 100 batch: 0.119177
Train loss on 125 batch: 0.161230
Train loss on 150 batch: 0.345643
Train loss on 175 batch: 0.275519
Train loss on 200 batch: 0.096351
Train loss on 225 batch: 0.144139
Train loss on 250 batch: 0.172913
Train loss on 275 batch: 0.136049
Train loss on 300 batch: 0.145428
Train loss on 325 batch: 0.387788
Train loss on 350 batch: 0.153490
Train loss on 375 batch: 0.125019
Train loss on 400 batch: 0.288418
Train loss on 425 batch: 0.270737
Train loss on 450 batch: 0.170738
Train loss on 475 batch: 0.184948
Train loss on 500 batch: 0.117394
Train loss on 525 batch: 0.232610
Train loss on 550 batch: 0.219608
Train loss on 575 batch: 0.310145
Train loss on 600 batch: 0.265705
Train loss on 625 batch: 0.411305
Train loss on 650 batch: 0.269528
Train loss on 675 batch: 0.155380
Train loss on 700 batch: 0.172707
Train loss on 725 batch: 0.176141
Train loss on 750 batch: 0.084631
Train loss on 775 batch: 0.111233
Train loss on 800 batch: 0.106642
Train loss on 825 batch: 0.136629
Train loss on 850 batch: 0.239410
Train loss on 875 batch: 0.248787
Train loss on 900 batch: 0.115277
Train loss on 925 batch: 0.296870
Train loss on 950 batch: 0.330814
Train loss on 975 batch: 0.316985
Train loss on 1000 batch: 0.472423
Train loss on 1025 batch: 0.480362
Train loss on 1050 batch: 0.292393
Train loss on 1075 batch: 0.241670
Train loss on 1100 batch: 0.257605
Train loss on 1125 batch: 0.373872
Train loss on 1150 batch: 0.284208
Train loss on 1175 batch: 0.276343
Train loss on 1200 batch: 0.402781
Train loss on 1225 batch: 0.185196
Train loss on 1250 batch: 0.318773
Train loss on 1275 batch: 0.160079
Train loss on 1300 batch: 0.364145
Train loss on 1325 batch: 0.255334
Train loss on 1350 batch: 0.283719
Train loss on 1375 batch: 0.415926
Train loss on 1400 batch: 0.159556
Train loss on 1425 batch: 0.252237
Train loss on 1450 batch: 0.137235
: Epoch: 13 | Training Loss: 0.234038 | Val. Loss: 0.489708 | Val. Kappa Score: nan | Estimated time: 111.73
Train loss on 25 batch: 0.171363
Train loss on 50 batch: 0.189111
Train loss on 75 batch: 0.200096
Train loss on 100 batch: 0.264587
Train loss on 125 batch: 0.165837
Train loss on 150 batch: 0.226956
Train loss on 175 batch: 0.234692
Train loss on 200 batch: 0.328504
Train loss on 225 batch: 0.218870
Train loss on 250 batch: 0.176342
Train loss on 275 batch: 0.124486
Train loss on 300 batch: 0.073757
Train loss on 325 batch: 0.177777
Train loss on 350 batch: 0.216531
Train loss on 375 batch: 0.213462
Train loss on 400 batch: 0.166755
Train loss on 425 batch: 0.310396
Train loss on 450 batch: 0.289699
Train loss on 475 batch: 0.292670
Train loss on 500 batch: 0.212600
Train loss on 525 batch: 0.157296
Train loss on 550 batch: 0.354338
Train loss on 575 batch: 0.379803
Train loss on 600 batch: 0.193003
Train loss on 625 batch: 0.380504
Train loss on 650 batch: 0.210633
Train loss on 675 batch: 0.229169
Train loss on 700 batch: 0.229899
Train loss on 725 batch: 0.167701
Train loss on 750 batch: 0.076966
Train loss on 775 batch: 0.178025
Train loss on 800 batch: 0.087196
Train loss on 825 batch: 0.217700
Train loss on 850 batch: 0.298788
Train loss on 875 batch: 0.187556
Train loss on 900 batch: 0.156241
Train loss on 925 batch: 0.194708
Train loss on 950 batch: 0.243202
Train loss on 975 batch: 0.239503
Train loss on 1000 batch: 0.322984
Train loss on 1025 batch: 0.245586
Train loss on 1050 batch: 0.167493
Train loss on 1075 batch: 0.177214
Train loss on 1100 batch: 0.202621
Train loss on 1125 batch: 0.191339
Train loss on 1150 batch: 0.090047
Train loss on 1175 batch: 0.227609
Train loss on 1200 batch: 0.186289
Train loss on 1225 batch: 0.242276
Train loss on 1250 batch: 0.177440
Train loss on 1275 batch: 0.133363
Train loss on 1300 batch: 0.208651
Train loss on 1325 batch: 0.139876
Train loss on 1350 batch: 0.239235
Train loss on 1375 batch: 0.220689
Train loss on 1400 batch: 0.313342
Train loss on 1425 batch: 0.133457
Train loss on 1450 batch: 0.228218
: Epoch: 14 | Training Loss: 0.211801 | Val. Loss: 0.633531 | Val. Kappa Score: nan | Estimated time: 110.53
Train loss on 25 batch: 0.257446
Train loss on 50 batch: 0.193552
Train loss on 75 batch: 0.248363
Train loss on 100 batch: 0.192175
Train loss on 125 batch: 0.137206
Train loss on 150 batch: 0.119696
Train loss on 175 batch: 0.185830
Train loss on 200 batch: 0.179396
Train loss on 225 batch: 0.124290
Train loss on 250 batch: 0.111989
Train loss on 275 batch: 0.231006
Train loss on 300 batch: 0.227054
Train loss on 325 batch: 0.155131
Train loss on 350 batch: 0.238654
Train loss on 375 batch: 0.094358
Train loss on 400 batch: 0.269834
Train loss on 425 batch: 0.200230
Train loss on 450 batch: 0.221451
Train loss on 475 batch: 0.262933
Train loss on 500 batch: 0.164631
Train loss on 525 batch: 0.272023
Train loss on 550 batch: 0.070928
Train loss on 575 batch: 0.076071
Train loss on 600 batch: 0.150406
Train loss on 625 batch: 0.238173
Train loss on 650 batch: 0.167679
Train loss on 675 batch: 0.179986
Train loss on 700 batch: 0.251003
Train loss on 725 batch: 0.211809
Train loss on 750 batch: 0.123020
Train loss on 775 batch: 0.195282
Train loss on 800 batch: 0.112630
Train loss on 825 batch: 0.193479
Train loss on 850 batch: 0.218273
Train loss on 875 batch: 0.188347
Train loss on 900 batch: 0.179164
Train loss on 925 batch: 0.462133
Train loss on 950 batch: 0.278893
Train loss on 975 batch: 0.153537
Train loss on 1000 batch: 0.183790
Train loss on 1025 batch: 0.293387
Train loss on 1050 batch: 0.174898
Train loss on 1075 batch: 0.181297
Train loss on 1100 batch: 0.161036
Train loss on 1125 batch: 0.220228
Train loss on 1150 batch: 0.166797
Train loss on 1175 batch: 0.158368
Train loss on 1200 batch: 0.198775
Train loss on 1225 batch: 0.195919
Train loss on 1250 batch: 0.251234
Train loss on 1275 batch: 0.197195
Train loss on 1300 batch: 0.225824
Train loss on 1325 batch: 0.423206
Train loss on 1350 batch: 0.470390
Train loss on 1375 batch: 0.192796
Train loss on 1400 batch: 0.192582
Train loss on 1425 batch: 0.181072
Train loss on 1450 batch: 0.203289
: Epoch: 15 | Training Loss: 0.203623 | Val. Loss: 0.714136 | Val. Kappa Score: nan | Estimated time: 110.24
Train loss on 25 batch: 0.190251
Train loss on 50 batch: 0.182705
Train loss on 75 batch: 0.047728
Train loss on 100 batch: 0.147698
Train loss on 125 batch: 0.246959
Train loss on 150 batch: 0.068031
Train loss on 175 batch: 0.150653
Train loss on 200 batch: 0.192309
Train loss on 225 batch: 0.142331
Train loss on 250 batch: 0.175104
Train loss on 275 batch: 0.248712
Train loss on 300 batch: 0.226919
Train loss on 325 batch: 0.028984
Train loss on 350 batch: 0.178642
Train loss on 375 batch: 0.128723
Train loss on 400 batch: 0.248301
Train loss on 425 batch: 0.221826
Train loss on 450 batch: 0.320162
Train loss on 475 batch: 0.216641
Train loss on 500 batch: 0.247498
Train loss on 525 batch: 0.253994
Train loss on 550 batch: 0.132598
Train loss on 575 batch: 0.145013
Train loss on 600 batch: 0.141507
Train loss on 625 batch: 0.138806
Train loss on 650 batch: 0.214519
Train loss on 675 batch: 0.181247
Train loss on 700 batch: 0.144069
Train loss on 725 batch: 0.176045
Train loss on 750 batch: 0.204289
Train loss on 775 batch: 0.214517
Train loss on 800 batch: 0.134403
Train loss on 825 batch: 0.211250
Train loss on 850 batch: 0.251354
Train loss on 875 batch: 0.221092
Train loss on 900 batch: 0.165513
Train loss on 925 batch: 0.148578
Train loss on 950 batch: 0.134051
Train loss on 975 batch: 0.318607
Train loss on 1000 batch: 0.131472
Train loss on 1025 batch: 0.058893
Train loss on 1050 batch: 0.249425
Train loss on 1075 batch: 0.168297
Train loss on 1100 batch: 0.181324
Train loss on 1125 batch: 0.275375
Train loss on 1150 batch: 0.244245
Train loss on 1175 batch: 0.175949
Train loss on 1200 batch: 0.219277
Train loss on 1225 batch: 0.110420
Train loss on 1250 batch: 0.171108
Train loss on 1275 batch: 0.182768
Train loss on 1300 batch: 0.212603
Train loss on 1325 batch: 0.222122
Train loss on 1350 batch: 0.274728
Train loss on 1375 batch: 0.222218
Train loss on 1400 batch: 0.197377
Train loss on 1425 batch: 0.260372
Train loss on 1450 batch: 0.233958
: Epoch: 16 | Training Loss: 0.188510 | Val. Loss: 0.568388 | Val. Kappa Score: nan | Estimated time: 111.49
Train loss on 25 batch: 0.078621
Train loss on 50 batch: 0.115804
Train loss on 75 batch: 0.186696
Train loss on 100 batch: 0.062597
Train loss on 125 batch: 0.117226
Train loss on 150 batch: 0.163026
Train loss on 175 batch: 0.115831
Train loss on 200 batch: 0.141516
Train loss on 225 batch: 0.084869
Train loss on 250 batch: 0.091843
Train loss on 275 batch: 0.125828
Train loss on 300 batch: 0.123607
Train loss on 325 batch: 0.155456
Train loss on 350 batch: 0.093147
Train loss on 375 batch: 0.226551
Train loss on 400 batch: 0.215599
Train loss on 425 batch: 0.177891
Train loss on 450 batch: 0.265461
Train loss on 475 batch: 0.097544
Train loss on 500 batch: 0.167463
Train loss on 525 batch: 0.194433
Train loss on 550 batch: 0.080819
Train loss on 575 batch: 0.159667
Train loss on 600 batch: 0.181255
Train loss on 625 batch: 0.199765
Train loss on 650 batch: 0.097467
Train loss on 675 batch: 0.133702
Train loss on 700 batch: 0.216352
Train loss on 725 batch: 0.253234
Train loss on 750 batch: 0.176586
Train loss on 775 batch: 0.107389
Train loss on 800 batch: 0.281876
Train loss on 825 batch: 0.142459
Train loss on 850 batch: 0.205654
Train loss on 875 batch: 0.051348
Train loss on 900 batch: 0.130790
Train loss on 925 batch: 0.193951
Train loss on 950 batch: 0.232660
Train loss on 975 batch: 0.151059
Train loss on 1000 batch: 0.206818
Train loss on 1025 batch: 0.106578
Train loss on 1050 batch: 0.171280
Train loss on 1075 batch: 0.261176
Train loss on 1100 batch: 0.095162
Train loss on 1125 batch: 0.403167
Train loss on 1150 batch: 0.193071
Train loss on 1175 batch: 0.182454
Train loss on 1200 batch: 0.290788
Train loss on 1225 batch: 0.142490
Train loss on 1250 batch: 0.204769
Train loss on 1275 batch: 0.136264
Train loss on 1300 batch: 0.252953
Train loss on 1325 batch: 0.135588
Train loss on 1350 batch: 0.123669
Train loss on 1375 batch: 0.127229
Train loss on 1400 batch: 0.268627
Train loss on 1425 batch: 0.065804
Train loss on 1450 batch: 0.245927
: Epoch: 17 | Training Loss: 0.165704 | Val. Loss: 0.644156 | Val. Kappa Score: nan | Estimated time: 110.98
Train loss on 25 batch: 0.106178
Train loss on 50 batch: 0.218880
Train loss on 75 batch: 0.128730
Train loss on 100 batch: 0.149542
Train loss on 125 batch: 0.147568
Train loss on 150 batch: 0.202116
Train loss on 175 batch: 0.229060
Train loss on 200 batch: 0.245565
Train loss on 225 batch: 0.123697
Train loss on 250 batch: 0.084901
Train loss on 275 batch: 0.083564
Train loss on 300 batch: 0.076326
Train loss on 325 batch: 0.219579
Train loss on 350 batch: 0.119900
Train loss on 375 batch: 0.113184
Train loss on 400 batch: 0.169080
Train loss on 425 batch: 0.078542
Train loss on 450 batch: 0.186486
Train loss on 475 batch: 0.100001
Train loss on 500 batch: 0.136951
Train loss on 525 batch: 0.085402
Train loss on 550 batch: 0.108897
Train loss on 575 batch: 0.125753
Train loss on 600 batch: 0.107833
Train loss on 625 batch: 0.137640
Train loss on 650 batch: 0.165575
Train loss on 675 batch: 0.157453
Train loss on 700 batch: 0.215291
Train loss on 725 batch: 0.135770
Train loss on 750 batch: 0.097976
Train loss on 775 batch: 0.205389
Train loss on 800 batch: 0.076468
Train loss on 825 batch: 0.074768
Train loss on 850 batch: 0.137292
Train loss on 875 batch: 0.101721
Train loss on 900 batch: 0.150214
Train loss on 925 batch: 0.209662
Train loss on 950 batch: 0.148991
Train loss on 975 batch: 0.140564
Train loss on 1000 batch: 0.152442
Train loss on 1025 batch: 0.180318
Train loss on 1050 batch: 0.184078
Train loss on 1075 batch: 0.153517
Train loss on 1100 batch: 0.242344
Train loss on 1125 batch: 0.199259
Train loss on 1150 batch: 0.122867
Train loss on 1175 batch: 0.115121
Train loss on 1200 batch: 0.196589
Train loss on 1225 batch: 0.306352
Train loss on 1250 batch: 0.185569
Train loss on 1275 batch: 0.195219
Train loss on 1300 batch: 0.135009
Train loss on 1325 batch: 0.090973
Train loss on 1350 batch: 0.104133
Train loss on 1375 batch: 0.154459
Train loss on 1400 batch: 0.238699
Train loss on 1425 batch: 0.289946
Train loss on 1450 batch: 0.182317
: Epoch: 18 | Training Loss: 0.153995 | Val. Loss: 0.561528 | Val. Kappa Score: nan | Estimated time: 110.81
Train loss on 25 batch: 0.190771
Train loss on 50 batch: 0.270864
Train loss on 75 batch: 0.118647
Train loss on 100 batch: 0.121073
Train loss on 125 batch: 0.221813
Train loss on 150 batch: 0.197487
Train loss on 175 batch: 0.105220
Train loss on 200 batch: 0.093421
Train loss on 225 batch: 0.053539
Train loss on 250 batch: 0.053682
Train loss on 275 batch: 0.166683
Train loss on 300 batch: 0.102615
Train loss on 325 batch: 0.102681
Train loss on 350 batch: 0.053126
Train loss on 375 batch: 0.044427
Train loss on 400 batch: 0.105127
Train loss on 425 batch: 0.287540
Train loss on 450 batch: 0.175962
Train loss on 475 batch: 0.082149
Train loss on 500 batch: 0.078763
Train loss on 525 batch: 0.188556
Train loss on 550 batch: 0.253946
Train loss on 575 batch: 0.128825
Train loss on 600 batch: 0.118897
Train loss on 625 batch: 0.065602
Train loss on 650 batch: 0.129320
Train loss on 675 batch: 0.134592
Train loss on 700 batch: 0.177434
Train loss on 725 batch: 0.123428
Train loss on 750 batch: 0.155878
Train loss on 775 batch: 0.164055
Train loss on 800 batch: 0.152334
Train loss on 825 batch: 0.129934
Train loss on 850 batch: 0.130434
Train loss on 875 batch: 0.128341
Train loss on 900 batch: 0.169103
Train loss on 925 batch: 0.183298
Train loss on 950 batch: 0.133748
Train loss on 975 batch: 0.148047
Train loss on 1000 batch: 0.173460
Train loss on 1025 batch: 0.168777
Train loss on 1050 batch: 0.203645
Train loss on 1075 batch: 0.139099
Train loss on 1100 batch: 0.078091
Train loss on 1125 batch: 0.324849
Train loss on 1150 batch: 0.171346
Train loss on 1175 batch: 0.144657
Train loss on 1200 batch: 0.227731
Train loss on 1225 batch: 0.117793
Train loss on 1250 batch: 0.183548
Train loss on 1275 batch: 0.137356
Train loss on 1300 batch: 0.123727
Train loss on 1325 batch: 0.119463
Train loss on 1350 batch: 0.159346
Train loss on 1375 batch: 0.298413
Train loss on 1400 batch: 0.201253
Train loss on 1425 batch: 0.227493
Train loss on 1450 batch: 0.252021
: Epoch: 19 | Training Loss: 0.153335 | Val. Loss: 0.543263 | Val. Kappa Score: nan | Estimated time: 110.30
Train loss on 25 batch: 0.151411
Train loss on 50 batch: 0.178633
Train loss on 75 batch: 0.086081
Train loss on 100 batch: 0.113234
Train loss on 125 batch: 0.088167
Train loss on 150 batch: 0.224643
Train loss on 175 batch: 0.133402
Train loss on 200 batch: 0.168751
Train loss on 225 batch: 0.101794
Train loss on 250 batch: 0.184959
Train loss on 275 batch: 0.107719
Train loss on 300 batch: 0.099076
Train loss on 325 batch: 0.134521
Train loss on 350 batch: 0.146718
Train loss on 375 batch: 0.062805
Train loss on 400 batch: 0.202635
Train loss on 425 batch: 0.142502
Train loss on 450 batch: 0.184850
Train loss on 475 batch: 0.220842
Train loss on 500 batch: 0.084844
Train loss on 525 batch: 0.099181
Train loss on 550 batch: 0.121652
Train loss on 575 batch: 0.267672
Train loss on 600 batch: 0.221663
Train loss on 625 batch: 0.260081
Train loss on 650 batch: 0.183393
Train loss on 675 batch: 0.088351
Train loss on 700 batch: 0.106539
Train loss on 725 batch: 0.121423
Train loss on 750 batch: 0.122903
Train loss on 775 batch: 0.125037
Train loss on 800 batch: 0.065244
Train loss on 825 batch: 0.182652
Train loss on 850 batch: 0.171955
Train loss on 875 batch: 0.132349
Train loss on 900 batch: 0.047079
Train loss on 925 batch: 0.198846
Train loss on 950 batch: 0.162015
Train loss on 975 batch: 0.133746
Train loss on 1000 batch: 0.079700
Train loss on 1025 batch: 0.084998
Train loss on 1050 batch: 0.129361
Train loss on 1075 batch: 0.087543
Train loss on 1100 batch: 0.087927
Train loss on 1125 batch: 0.121829
Train loss on 1150 batch: 0.218745
Train loss on 1175 batch: 0.126553
Train loss on 1200 batch: 0.150443
Train loss on 1225 batch: 0.104899
Train loss on 1250 batch: 0.222642
Train loss on 1275 batch: 0.143092
Train loss on 1300 batch: 0.164417
Train loss on 1325 batch: 0.110359
Train loss on 1350 batch: 0.094923
Train loss on 1375 batch: 0.122485
Train loss on 1400 batch: 0.195304
Train loss on 1425 batch: 0.101616
Train loss on 1450 batch: 0.139213
: Epoch: 20 | Training Loss: 0.139921 | Val. Loss: 0.640063 | Val. Kappa Score: nan | Estimated time: 110.73
Train loss on 25 batch: 0.110968
Train loss on 50 batch: 0.083180
Train loss on 75 batch: 0.133836
Train loss on 100 batch: 0.157497
Train loss on 125 batch: 0.107192
Train loss on 150 batch: 0.119848
Train loss on 175 batch: 0.215315
Train loss on 200 batch: 0.133497
Train loss on 225 batch: 0.092438
Train loss on 250 batch: 0.106833
Train loss on 275 batch: 0.093244
Train loss on 300 batch: 0.114850
Train loss on 325 batch: 0.121786
Train loss on 350 batch: 0.107456
Train loss on 375 batch: 0.100003
Train loss on 400 batch: 0.180343
Train loss on 425 batch: 0.145814
Train loss on 450 batch: 0.048799
Train loss on 475 batch: 0.110006
Train loss on 500 batch: 0.087208
Train loss on 525 batch: 0.144668
Train loss on 550 batch: 0.126733
Train loss on 575 batch: 0.150675
Train loss on 600 batch: 0.217155
Train loss on 625 batch: 0.203380
Train loss on 650 batch: 0.087764
Train loss on 675 batch: 0.148450
Train loss on 700 batch: 0.059802
Train loss on 725 batch: 0.109698
Train loss on 750 batch: 0.105538
Train loss on 775 batch: 0.083792
Train loss on 800 batch: 0.229179
Train loss on 825 batch: 0.121206
Train loss on 850 batch: 0.063530
Train loss on 875 batch: 0.388626
Train loss on 900 batch: 0.142748
Train loss on 925 batch: 0.104392
Train loss on 950 batch: 0.124912
Train loss on 975 batch: 0.072005
Train loss on 1000 batch: 0.128228
Train loss on 1025 batch: 0.177098
Train loss on 1050 batch: 0.209704
Train loss on 1075 batch: 0.151430
Train loss on 1100 batch: 0.162266
Train loss on 1125 batch: 0.143906
Train loss on 1150 batch: 0.212258
Train loss on 1175 batch: 0.107510
Train loss on 1200 batch: 0.109895
Train loss on 1225 batch: 0.094137
Train loss on 1250 batch: 0.098145
Train loss on 1275 batch: 0.166997
Train loss on 1300 batch: 0.263441
Train loss on 1325 batch: 0.173094
Train loss on 1350 batch: 0.188870
Train loss on 1375 batch: 0.196176
Train loss on 1400 batch: 0.199032
Train loss on 1425 batch: 0.070363
Train loss on 1450 batch: 0.140936
: Epoch: 21 | Training Loss: 0.138756 | Val. Loss: 0.584041 | Val. Kappa Score: nan | Estimated time: 110.59
Train loss on 25 batch: 0.057241
Train loss on 50 batch: 0.124413
Train loss on 75 batch: 0.131686
Train loss on 100 batch: 0.089087
Train loss on 125 batch: 0.071325
Train loss on 150 batch: 0.091904
Train loss on 175 batch: 0.127396
Train loss on 200 batch: 0.216309
Train loss on 225 batch: 0.172751
Train loss on 250 batch: 0.081371
Train loss on 275 batch: 0.129997
Train loss on 300 batch: 0.199376
Train loss on 325 batch: 0.172888
Train loss on 350 batch: 0.167416
Train loss on 375 batch: 0.078968
Train loss on 400 batch: 0.148788
Train loss on 425 batch: 0.140532
Train loss on 450 batch: 0.093014
Train loss on 475 batch: 0.108043
Train loss on 500 batch: 0.118559
Train loss on 525 batch: 0.150515
Train loss on 550 batch: 0.205937
Train loss on 575 batch: 0.142457
Train loss on 600 batch: 0.291896
Train loss on 625 batch: 0.048773
Train loss on 650 batch: 0.080584
Train loss on 675 batch: 0.180209
Train loss on 700 batch: 0.097882
Train loss on 725 batch: 0.117501
Train loss on 750 batch: 0.213507
Train loss on 775 batch: 0.085219
Train loss on 800 batch: 0.106655
Train loss on 825 batch: 0.110529
Train loss on 850 batch: 0.036950
Train loss on 875 batch: 0.123331
Train loss on 900 batch: 0.083129
Train loss on 925 batch: 0.090819
Train loss on 950 batch: 0.181048
Train loss on 975 batch: 0.055841
Train loss on 1000 batch: 0.083045
Train loss on 1025 batch: 0.129039
Train loss on 1050 batch: 0.177764
Train loss on 1075 batch: 0.116917
Train loss on 1100 batch: 0.087387
Train loss on 1125 batch: 0.134597
Train loss on 1150 batch: 0.140343
Train loss on 1175 batch: 0.175759
Train loss on 1200 batch: 0.203239
Train loss on 1225 batch: 0.119616
Train loss on 1250 batch: 0.080063
Train loss on 1275 batch: 0.113943
Train loss on 1300 batch: 0.131080
Train loss on 1325 batch: 0.094988
Train loss on 1350 batch: 0.120448
Train loss on 1375 batch: 0.091793
Train loss on 1400 batch: 0.109622
Train loss on 1425 batch: 0.123458
Train loss on 1450 batch: 0.092282
: Epoch: 22 | Training Loss: 0.124987 | Val. Loss: 0.604387 | Val. Kappa Score: nan | Estimated time: 110.08
Train loss on 25 batch: 0.216929
Train loss on 50 batch: 0.092282
Train loss on 75 batch: 0.093898
Train loss on 100 batch: 0.052968
Train loss on 125 batch: 0.043753
Train loss on 150 batch: 0.064297
Train loss on 175 batch: 0.050463
Train loss on 200 batch: 0.297660
Train loss on 225 batch: 0.109373
Train loss on 250 batch: 0.097754
Train loss on 275 batch: 0.123705
Train loss on 300 batch: 0.101870
Train loss on 325 batch: 0.093464
Train loss on 350 batch: 0.120113
Train loss on 375 batch: 0.143718
Train loss on 400 batch: 0.070465
Train loss on 425 batch: 0.093953
Train loss on 450 batch: 0.054646
Train loss on 475 batch: 0.165239
Train loss on 500 batch: 0.120275
Train loss on 525 batch: 0.091436
Train loss on 550 batch: 0.113325
Train loss on 575 batch: 0.134761
Train loss on 600 batch: 0.166899
Train loss on 625 batch: 0.114838
Train loss on 650 batch: 0.110739
Train loss on 675 batch: 0.120409
Train loss on 700 batch: 0.161273
Train loss on 725 batch: 0.111366
Train loss on 750 batch: 0.109278
Train loss on 775 batch: 0.158895
Train loss on 800 batch: 0.142243
Train loss on 825 batch: 0.122374
Train loss on 850 batch: 0.133746
Train loss on 875 batch: 0.078950
Train loss on 900 batch: 0.150233
Train loss on 925 batch: 0.130016
Train loss on 950 batch: 0.055107
Train loss on 975 batch: 0.124168
Train loss on 1000 batch: 0.043773
Train loss on 1025 batch: 0.068435
Train loss on 1050 batch: 0.080944
Train loss on 1075 batch: 0.134077
Train loss on 1100 batch: 0.051038
Train loss on 1125 batch: 0.165966
Train loss on 1150 batch: 0.113973
Train loss on 1175 batch: 0.175979
Train loss on 1200 batch: 0.056234
Train loss on 1225 batch: 0.165349
Train loss on 1250 batch: 0.111198
Train loss on 1275 batch: 0.110459
Train loss on 1300 batch: 0.154032
Train loss on 1325 batch: 0.105179
Train loss on 1350 batch: 0.067812
Train loss on 1375 batch: 0.136100
Train loss on 1400 batch: 0.096608
Train loss on 1425 batch: 0.147014
Train loss on 1450 batch: 0.147081
: Epoch: 23 | Training Loss: 0.114968 | Val. Loss: 1.037853 | Val. Kappa Score: nan | Estimated time: 110.57
Train loss on 25 batch: 0.091252
Train loss on 50 batch: 0.093794
Train loss on 75 batch: 0.141625
Train loss on 100 batch: 0.077365
Train loss on 125 batch: 0.086325
Train loss on 150 batch: 0.094772
Train loss on 175 batch: 0.091420
Train loss on 200 batch: 0.100011
Train loss on 225 batch: 0.059767
Train loss on 250 batch: 0.068774
Train loss on 275 batch: 0.067233
Train loss on 300 batch: 0.102463
Train loss on 325 batch: 0.060441
Train loss on 350 batch: 0.152009
Train loss on 375 batch: 0.087691
Train loss on 400 batch: 0.127030
Train loss on 425 batch: 0.048245
Train loss on 450 batch: 0.089711
Train loss on 475 batch: 0.138674
Train loss on 500 batch: 0.100363
Train loss on 525 batch: 0.098503
Train loss on 550 batch: 0.136926
Train loss on 575 batch: 0.072489
Train loss on 600 batch: 0.084260
Train loss on 625 batch: 0.111610
Train loss on 650 batch: 0.058183
Train loss on 675 batch: 0.155949
Train loss on 700 batch: 0.153338
Train loss on 725 batch: 0.040222
Train loss on 750 batch: 0.096172
Train loss on 775 batch: 0.078263
Train loss on 800 batch: 0.042833
Train loss on 825 batch: 0.080022
Train loss on 850 batch: 0.064601
Train loss on 875 batch: 0.127613
Train loss on 900 batch: 0.137866
Train loss on 925 batch: 0.174808
Train loss on 950 batch: 0.164886
Train loss on 975 batch: 0.071060
Train loss on 1000 batch: 0.108093
Train loss on 1025 batch: 0.093534
Train loss on 1050 batch: 0.069252
Train loss on 1075 batch: 0.175955
Train loss on 1100 batch: 0.095243
Train loss on 1125 batch: 0.065244
Train loss on 1150 batch: 0.122706
Train loss on 1175 batch: 0.059692
Train loss on 1200 batch: 0.188321
Train loss on 1225 batch: 0.094305
Train loss on 1250 batch: 0.089978
Train loss on 1275 batch: 0.196577
Train loss on 1300 batch: 0.092295
Train loss on 1325 batch: 0.094735
Train loss on 1350 batch: 0.121743
Train loss on 1375 batch: 0.099655
Train loss on 1400 batch: 0.097315
Train loss on 1425 batch: 0.112578
Train loss on 1450 batch: 0.067295
: Epoch: 24 | Training Loss: 0.101260 | Val. Loss: 0.551398 | Val. Kappa Score: nan | Estimated time: 110.67
time_estimated: 2654.21
n-epochs: 24
time_estimated: 2654.21
----------------------------------------

Experiment N: 7: 
date: 2019.08.06 10:22:46
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.776254
Train loss on 50 batch: 1.481683
Train loss on 75 batch: 1.231817
Train loss on 100 batch: 1.126001
Train loss on 125 batch: 0.632080
Train loss on 150 batch: 0.803190
Train loss on 175 batch: 0.764787
Train loss on 200 batch: 0.747315
Train loss on 225 batch: 1.300588
Train loss on 250 batch: 1.998305
Train loss on 275 batch: 0.647753
Train loss on 300 batch: 0.507915
Train loss on 325 batch: 0.823722
Train loss on 350 batch: 0.876194
Train loss on 375 batch: 0.509040
Train loss on 400 batch: 0.607004
Train loss on 425 batch: 0.488888
Train loss on 450 batch: 0.530607
Train loss on 475 batch: 0.405838
Train loss on 500 batch: 0.499125
Train loss on 525 batch: 0.604905
Train loss on 550 batch: 0.965102
Train loss on 575 batch: 0.639229
Train loss on 600 batch: 0.679758
Train loss on 625 batch: 0.357133
Train loss on 650 batch: 0.833551
Train loss on 675 batch: 0.692218
Train loss on 700 batch: 0.573661
Train loss on 725 batch: 0.478432
best-train-loss: 0.813176
best-valid-loss: 0.592302
best-kappa: nan
: Epoch: 1 | Training Loss: 0.813176 | Val. Loss: 0.592302 | Val. Kappa Score: nan | Estimated time: 65.62
Train loss on 25 batch: 0.468214
Train loss on 50 batch: 0.353824
Train loss on 75 batch: 0.497312
Train loss on 100 batch: 0.337799
Train loss on 125 batch: 0.712293
Train loss on 150 batch: 0.618811
Train loss on 175 batch: 0.430814
Train loss on 200 batch: 0.544264
Train loss on 225 batch: 0.566293
Train loss on 250 batch: 0.671699
Train loss on 275 batch: 0.360719
Train loss on 300 batch: 0.634918
Train loss on 325 batch: 0.302613
Train loss on 350 batch: 0.417936
Train loss on 375 batch: 0.458909
Train loss on 400 batch: 0.306026
Train loss on 425 batch: 0.427472
Train loss on 450 batch: 0.434038
Train loss on 475 batch: 0.561747
Train loss on 500 batch: 0.540323
Train loss on 525 batch: 0.619393
Train loss on 550 batch: 0.521973
Train loss on 575 batch: 0.385456
Train loss on 600 batch: 0.397998
Train loss on 625 batch: 0.474204
Train loss on 650 batch: 0.567853
Train loss on 675 batch: 0.421879
Train loss on 700 batch: 0.632819
Train loss on 725 batch: 0.404185
best-train-loss: 0.485234
best-valid-loss: 0.495820
best-kappa: nan
: Epoch: 2 | Training Loss: 0.485234 | Val. Loss: 0.495820 | Val. Kappa Score: nan | Estimated time: 66.20
Train loss on 25 batch: 0.389716
Train loss on 50 batch: 0.387942
Train loss on 75 batch: 0.461958
Train loss on 100 batch: 0.637569
Train loss on 125 batch: 0.419277
Train loss on 150 batch: 0.344723
Train loss on 175 batch: 0.327566
Train loss on 200 batch: 0.410459
Train loss on 225 batch: 0.505275
Train loss on 250 batch: 0.309954
Train loss on 275 batch: 0.440421
Train loss on 300 batch: 0.551415
Train loss on 325 batch: 0.324984
Train loss on 350 batch: 0.475738
Train loss on 375 batch: 0.479745
Train loss on 400 batch: 0.532180
Train loss on 425 batch: 0.396790
Train loss on 450 batch: 0.570443
Train loss on 475 batch: 0.592544
Train loss on 500 batch: 0.457019
Train loss on 525 batch: 0.426395
Train loss on 550 batch: 0.425363
Train loss on 575 batch: 0.233523
Train loss on 600 batch: 0.388977
Train loss on 625 batch: 0.222392
Train loss on 650 batch: 0.340884
Train loss on 675 batch: 0.368084
Train loss on 700 batch: 0.319882
Train loss on 725 batch: 0.360849
best-train-loss: 0.417313
best-valid-loss: 0.448734
best-kappa: nan
: Epoch: 3 | Training Loss: 0.417313 | Val. Loss: 0.448734 | Val. Kappa Score: nan | Estimated time: 66.47
Train loss on 25 batch: 0.302521
Train loss on 50 batch: 0.244598
Train loss on 75 batch: 0.402459
Train loss on 100 batch: 0.287811
Train loss on 125 batch: 0.278200
Train loss on 150 batch: 0.410692
Train loss on 175 batch: 0.264522
Train loss on 200 batch: 0.331928
Train loss on 225 batch: 0.184699
Train loss on 250 batch: 0.292361
Train loss on 275 batch: 0.448043
Train loss on 300 batch: 0.355612
Train loss on 325 batch: 0.367969
Train loss on 350 batch: 0.372925
Train loss on 375 batch: 0.428037
Train loss on 400 batch: 0.315362
Train loss on 425 batch: 0.236177
Train loss on 450 batch: 0.359039
Train loss on 475 batch: 0.503204
Train loss on 500 batch: 0.430227
Train loss on 525 batch: 0.479426
Train loss on 550 batch: 0.325815
Train loss on 575 batch: 0.352096
Train loss on 600 batch: 0.224520
Train loss on 625 batch: 0.443487
Train loss on 650 batch: 0.325418
Train loss on 675 batch: 0.513449
Train loss on 700 batch: 0.431808
Train loss on 725 batch: 0.393869
best-train-loss: 0.355389
best-valid-loss: 0.384108
best-kappa: nan
: Epoch: 4 | Training Loss: 0.355389 | Val. Loss: 0.384108 | Val. Kappa Score: nan | Estimated time: 66.24
Train loss on 25 batch: 0.429385
Train loss on 50 batch: 0.394830
Train loss on 75 batch: 0.470841
Train loss on 100 batch: 0.320135
Train loss on 125 batch: 0.441066
Train loss on 150 batch: 0.319390
Train loss on 175 batch: 0.280109
Train loss on 200 batch: 0.384648
Train loss on 225 batch: 0.212507
Train loss on 250 batch: 0.291230
Train loss on 275 batch: 0.296564
Train loss on 300 batch: 0.206206
Train loss on 325 batch: 0.254949
Train loss on 350 batch: 0.205275
Train loss on 375 batch: 0.324771
Train loss on 400 batch: 0.280103
Train loss on 425 batch: 0.379617
Train loss on 450 batch: 0.483287
Train loss on 475 batch: 0.204257
Train loss on 500 batch: 0.357146
Train loss on 525 batch: 0.415541
Train loss on 550 batch: 0.218255
Train loss on 575 batch: 0.269954
Train loss on 600 batch: 0.375170
Train loss on 625 batch: 0.312323
Train loss on 650 batch: 0.164443
Train loss on 675 batch: 0.368055
Train loss on 700 batch: 0.246490
Train loss on 725 batch: 0.262715
best-train-loss: 0.316182
best-valid-loss: 0.362818
best-kappa: nan
: Epoch: 5 | Training Loss: 0.316182 | Val. Loss: 0.362818 | Val. Kappa Score: nan | Estimated time: 64.83
Train loss on 25 batch: 0.259284
Train loss on 50 batch: 0.270942
Train loss on 75 batch: 0.300201
Train loss on 100 batch: 0.325371
Train loss on 125 batch: 0.273151
Train loss on 150 batch: 0.329368
Train loss on 175 batch: 0.191927
Train loss on 200 batch: 0.327234
Train loss on 225 batch: 0.176335
Train loss on 250 batch: 0.277725
Train loss on 275 batch: 0.315152
Train loss on 300 batch: 0.244859
Train loss on 325 batch: 0.293425
Train loss on 350 batch: 0.468862
Train loss on 375 batch: 0.396686
Train loss on 400 batch: 0.375918
Train loss on 425 batch: 0.337527
Train loss on 450 batch: 0.284866
Train loss on 475 batch: 0.213359
Train loss on 500 batch: 0.308278
Train loss on 525 batch: 0.270293
Train loss on 550 batch: 0.303300
Train loss on 575 batch: 0.565851
Train loss on 600 batch: 0.288444
Train loss on 625 batch: 0.229168
Train loss on 650 batch: 0.410894
Train loss on 675 batch: 0.288069
Train loss on 700 batch: 0.230743
Train loss on 725 batch: 0.175190
: Epoch: 6 | Training Loss: 0.301118 | Val. Loss: 0.367388 | Val. Kappa Score: nan | Estimated time: 66.44
Train loss on 25 batch: 0.369346
Train loss on 50 batch: 0.222458
Train loss on 75 batch: 0.283135
Train loss on 100 batch: 0.236137
Train loss on 125 batch: 0.343346
Train loss on 150 batch: 0.287838
Train loss on 175 batch: 0.229240
Train loss on 200 batch: 0.245512
Train loss on 225 batch: 0.342388
Train loss on 250 batch: 0.317719
Train loss on 275 batch: 0.283617
Train loss on 300 batch: 0.203920
Train loss on 325 batch: 0.144426
Train loss on 350 batch: 0.345049
Train loss on 375 batch: 0.233623
Train loss on 400 batch: 0.268411
Train loss on 425 batch: 0.304265
Train loss on 450 batch: 0.208009
Train loss on 475 batch: 0.229124
Train loss on 500 batch: 0.356588
Train loss on 525 batch: 0.272363
Train loss on 550 batch: 0.259457
Train loss on 575 batch: 0.300634
Train loss on 600 batch: 0.224425
Train loss on 625 batch: 0.417230
Train loss on 650 batch: 0.216972
Train loss on 675 batch: 0.201147
Train loss on 700 batch: 0.222986
Train loss on 725 batch: 0.306941
: Epoch: 7 | Training Loss: 0.271597 | Val. Loss: 0.979274 | Val. Kappa Score: nan | Estimated time: 66.05
Train loss on 25 batch: 0.300734
Train loss on 50 batch: 0.300280
Train loss on 75 batch: 0.269329
Train loss on 100 batch: 0.268442
Train loss on 125 batch: 0.201048
Train loss on 150 batch: 0.360989
Train loss on 175 batch: 0.407333
Train loss on 200 batch: 0.250123
Train loss on 225 batch: 0.221147
Train loss on 250 batch: 0.254219
Train loss on 275 batch: 0.169101
Train loss on 300 batch: 0.140440
Train loss on 325 batch: 0.357247
Train loss on 350 batch: 0.346971
Train loss on 375 batch: 0.149102
Train loss on 400 batch: 0.267477
Train loss on 425 batch: 0.272953
Train loss on 450 batch: 0.423549
Train loss on 475 batch: 0.489119
Train loss on 500 batch: 0.233746
Train loss on 525 batch: 0.244132
Train loss on 550 batch: 0.223791
Train loss on 575 batch: 0.306516
Train loss on 600 batch: 0.295274
Train loss on 625 batch: 0.192194
Train loss on 650 batch: 0.249069
Train loss on 675 batch: 0.328554
Train loss on 700 batch: 0.262201
Train loss on 725 batch: 0.210275
: Epoch: 8 | Training Loss: 0.275702 | Val. Loss: 0.366169 | Val. Kappa Score: nan | Estimated time: 65.90
Train loss on 25 batch: 0.350399
Train loss on 50 batch: 0.270084
Train loss on 75 batch: 0.308068
Train loss on 100 batch: 0.283308
Train loss on 125 batch: 0.199769
Train loss on 150 batch: 0.189399
Train loss on 175 batch: 0.206023
Train loss on 200 batch: 0.316729
Train loss on 225 batch: 0.157767
Train loss on 250 batch: 0.209478
Train loss on 275 batch: 0.254824
Train loss on 300 batch: 0.189305
Train loss on 325 batch: 0.230295
Train loss on 350 batch: 0.225369
Train loss on 375 batch: 0.287719
Train loss on 400 batch: 0.188292
Train loss on 425 batch: 0.236878
Train loss on 450 batch: 0.239693
Train loss on 475 batch: 0.279479
Train loss on 500 batch: 0.166137
Train loss on 525 batch: 0.174517
Train loss on 550 batch: 0.141163
Train loss on 575 batch: 0.278808
Train loss on 600 batch: 0.269001
Train loss on 625 batch: 0.348196
Train loss on 650 batch: 0.215502
Train loss on 675 batch: 0.289304
Train loss on 700 batch: 0.119568
Train loss on 725 batch: 0.271700
: Epoch: 9 | Training Loss: 0.237820 | Val. Loss: 0.396456 | Val. Kappa Score: nan | Estimated time: 66.30
Train loss on 25 batch: 0.239821
Train loss on 50 batch: 0.187757
Train loss on 75 batch: 0.284623
Train loss on 100 batch: 0.279850
Train loss on 125 batch: 0.186279
Train loss on 150 batch: 0.108593
Train loss on 175 batch: 0.165802
Train loss on 200 batch: 0.225592
Train loss on 225 batch: 0.277679
Train loss on 250 batch: 0.144675
Train loss on 275 batch: 0.232099
Train loss on 300 batch: 0.285466
Train loss on 325 batch: 0.188468
Train loss on 350 batch: 0.222930
Train loss on 375 batch: 0.118105
Train loss on 400 batch: 0.257832
Train loss on 425 batch: 0.270496
Train loss on 450 batch: 0.232660
Train loss on 475 batch: 0.130814
Train loss on 500 batch: 0.193835
Train loss on 525 batch: 0.258132
Train loss on 550 batch: 0.229502
Train loss on 575 batch: 0.264408
Train loss on 600 batch: 0.178754
Train loss on 625 batch: 0.218855
Train loss on 650 batch: 0.171408
Train loss on 675 batch: 0.201792
Train loss on 700 batch: 0.302671
Train loss on 725 batch: 0.272684
: Epoch: 10 | Training Loss: 0.218330 | Val. Loss: 0.368032 | Val. Kappa Score: nan | Estimated time: 67.41
Train loss on 25 batch: 0.124984
Train loss on 50 batch: 0.161314
Train loss on 75 batch: 0.130182
Train loss on 100 batch: 0.132621
Train loss on 125 batch: 0.285699
Train loss on 150 batch: 0.185552
Train loss on 175 batch: 0.166176
Train loss on 200 batch: 0.170565
Train loss on 225 batch: 0.258471
Train loss on 250 batch: 0.193316
Train loss on 275 batch: 0.298764
Train loss on 300 batch: 0.175841
Train loss on 325 batch: 0.165990
Train loss on 350 batch: 0.229834
Train loss on 375 batch: 0.266329
Train loss on 400 batch: 0.177316
Train loss on 425 batch: 0.105862
Train loss on 450 batch: 0.159796
Train loss on 475 batch: 0.204457
Train loss on 500 batch: 0.169355
Train loss on 525 batch: 0.185612
Train loss on 550 batch: 0.220300
Train loss on 575 batch: 0.266322
Train loss on 600 batch: 0.171891
Train loss on 625 batch: 0.218147
Train loss on 650 batch: 0.373855
Train loss on 675 batch: 0.194452
Train loss on 700 batch: 0.117713
Train loss on 725 batch: 0.148756
best-train-loss: 0.195154
best-valid-loss: 0.360901
best-kappa: nan
: Epoch: 11 | Training Loss: 0.195154 | Val. Loss: 0.360901 | Val. Kappa Score: nan | Estimated time: 65.93
Train loss on 25 batch: 0.219833
Train loss on 50 batch: 0.205415
Train loss on 75 batch: 0.205683
Train loss on 100 batch: 0.209214
Train loss on 125 batch: 0.163664
Train loss on 150 batch: 0.151099
Train loss on 175 batch: 0.162742
Train loss on 200 batch: 0.252952
Train loss on 225 batch: 0.176494
Train loss on 250 batch: 0.217632
Train loss on 275 batch: 0.184086
Train loss on 300 batch: 0.163065
Train loss on 325 batch: 0.161921
Train loss on 350 batch: 0.156935
Train loss on 375 batch: 0.226465
Train loss on 400 batch: 0.134034
Train loss on 425 batch: 0.156285
Train loss on 450 batch: 0.133409
Train loss on 475 batch: 0.203963
Train loss on 500 batch: 0.237632
Train loss on 525 batch: 0.182778
Train loss on 550 batch: 0.164595
Train loss on 575 batch: 0.165519
Train loss on 600 batch: 0.191255
Train loss on 625 batch: 0.176142
Train loss on 650 batch: 0.118625
Train loss on 675 batch: 0.196053
Train loss on 700 batch: 0.174712
Train loss on 725 batch: 0.230734
: Epoch: 12 | Training Loss: 0.183550 | Val. Loss: 0.387884 | Val. Kappa Score: nan | Estimated time: 65.88
Train loss on 25 batch: 0.225311
Train loss on 50 batch: 0.068024
Train loss on 75 batch: 0.105587
Train loss on 100 batch: 0.102842
Train loss on 125 batch: 0.122456
Train loss on 150 batch: 0.133649
Train loss on 175 batch: 0.212692
Train loss on 200 batch: 0.092210
Train loss on 225 batch: 0.205309
Train loss on 250 batch: 0.113231
Train loss on 275 batch: 0.194442
Train loss on 300 batch: 0.138158
Train loss on 325 batch: 0.212665
Train loss on 350 batch: 0.183997
Train loss on 375 batch: 0.108530
Train loss on 400 batch: 0.084824
Train loss on 425 batch: 0.126316
Train loss on 450 batch: 0.103504
Train loss on 475 batch: 0.174030
Train loss on 500 batch: 0.239558
Train loss on 525 batch: 0.271788
Train loss on 550 batch: 0.212073
Train loss on 575 batch: 0.330283
Train loss on 600 batch: 0.167052
Train loss on 625 batch: 0.202486
Train loss on 650 batch: 0.176544
Train loss on 675 batch: 0.171272
Train loss on 700 batch: 0.153996
Train loss on 725 batch: 0.138737
best-train-loss: 0.164537
best-valid-loss: 0.325475
best-kappa: nan
: Epoch: 13 | Training Loss: 0.164537 | Val. Loss: 0.325475 | Val. Kappa Score: nan | Estimated time: 65.39
Train loss on 25 batch: 0.114433
Train loss on 50 batch: 0.140062
Train loss on 75 batch: 0.101679
Train loss on 100 batch: 0.178442
Train loss on 125 batch: 0.122512
Train loss on 150 batch: 0.107345
Train loss on 175 batch: 0.138498
Train loss on 200 batch: 0.100058
Train loss on 225 batch: 0.186952
Train loss on 250 batch: 0.231278
Train loss on 275 batch: 0.268397
Train loss on 300 batch: 0.164181
Train loss on 325 batch: 0.243439
Train loss on 350 batch: 0.183535
Train loss on 375 batch: 0.142327
Train loss on 400 batch: 0.111277
Train loss on 425 batch: 0.167206
Train loss on 450 batch: 0.157661
Train loss on 475 batch: 0.125326
Train loss on 500 batch: 0.143664
Train loss on 525 batch: 0.154165
Train loss on 550 batch: 0.096404
Train loss on 575 batch: 0.080711
Train loss on 600 batch: 0.213361
Train loss on 625 batch: 0.104880
Train loss on 650 batch: 0.098589
Train loss on 675 batch: 0.197350
Train loss on 700 batch: 0.165029
Train loss on 725 batch: 0.117687
: Epoch: 14 | Training Loss: 0.150222 | Val. Loss: 0.369181 | Val. Kappa Score: nan | Estimated time: 66.50
Train loss on 25 batch: 0.151162
Train loss on 50 batch: 0.106842
Train loss on 75 batch: 0.088772
Train loss on 100 batch: 0.116655
Train loss on 125 batch: 0.111478
Train loss on 150 batch: 0.158429
Train loss on 175 batch: 0.189861
Train loss on 200 batch: 0.115325
Train loss on 225 batch: 0.098382
Train loss on 250 batch: 0.208712
Train loss on 275 batch: 0.119993
Train loss on 300 batch: 0.113138
Train loss on 325 batch: 0.107297
Train loss on 350 batch: 0.162098
Train loss on 375 batch: 0.160738
Train loss on 400 batch: 0.067332
Train loss on 425 batch: 0.119887
Train loss on 450 batch: 0.158031
Train loss on 475 batch: 0.169841
Train loss on 500 batch: 0.168153
Train loss on 525 batch: 0.214344
Train loss on 550 batch: 0.146052
Train loss on 575 batch: 0.131493
Train loss on 600 batch: 0.095360
Train loss on 625 batch: 0.120773
Train loss on 650 batch: 0.113001
Train loss on 675 batch: 0.153144
Train loss on 700 batch: 0.166710
Train loss on 725 batch: 0.112358
: Epoch: 15 | Training Loss: 0.136047 | Val. Loss: 0.383940 | Val. Kappa Score: nan | Estimated time: 66.49
Train loss on 25 batch: 0.159126
Train loss on 50 batch: 0.066950
Train loss on 75 batch: 0.077189
Train loss on 100 batch: 0.105124
Train loss on 125 batch: 0.128830
Train loss on 150 batch: 0.109368
Train loss on 175 batch: 0.083271
Train loss on 200 batch: 0.150388
Train loss on 225 batch: 0.260213
Train loss on 250 batch: 0.145997
Train loss on 275 batch: 0.152166
Train loss on 300 batch: 0.155996
Train loss on 325 batch: 0.147169
Train loss on 350 batch: 0.149218
Train loss on 375 batch: 0.156022
Train loss on 400 batch: 0.134798
Train loss on 425 batch: 0.118429
Train loss on 450 batch: 0.110699
Train loss on 475 batch: 0.063528
Train loss on 500 batch: 0.116113
Train loss on 525 batch: 0.098049
Train loss on 550 batch: 0.103901
Train loss on 575 batch: 0.119593
Train loss on 600 batch: 0.208955
Train loss on 625 batch: 0.104823
Train loss on 650 batch: 0.105981
Train loss on 675 batch: 0.128969
Train loss on 700 batch: 0.164913
Train loss on 725 batch: 0.160679
: Epoch: 16 | Training Loss: 0.130567 | Val. Loss: 0.342666 | Val. Kappa Score: nan | Estimated time: 66.13
Train loss on 25 batch: 0.137316
Train loss on 50 batch: 0.096276
Train loss on 75 batch: 0.114166
Train loss on 100 batch: 0.117413
Train loss on 125 batch: 0.103763
Train loss on 150 batch: 0.087164
Train loss on 175 batch: 0.088977
Train loss on 200 batch: 0.145314
Train loss on 225 batch: 0.096201
Train loss on 250 batch: 0.072087
Train loss on 275 batch: 0.067445
Train loss on 300 batch: 0.097203
Train loss on 325 batch: 0.097028
Train loss on 350 batch: 0.100851
Train loss on 375 batch: 0.072201
Train loss on 400 batch: 0.111996
Train loss on 425 batch: 0.118024
Train loss on 450 batch: 0.099094
Train loss on 475 batch: 0.235544
Train loss on 500 batch: 0.150547
Train loss on 525 batch: 0.163357
Train loss on 550 batch: 0.081409
Train loss on 575 batch: 0.167565
Train loss on 600 batch: 0.147678
Train loss on 625 batch: 0.133202
Train loss on 650 batch: 0.115339
Train loss on 675 batch: 0.105710
Train loss on 700 batch: 0.136066
Train loss on 725 batch: 0.187312
: Epoch: 17 | Training Loss: 0.118836 | Val. Loss: 0.366776 | Val. Kappa Score: nan | Estimated time: 66.56
Train loss on 25 batch: 0.118019
Train loss on 50 batch: 0.134336
Train loss on 75 batch: 0.095013
Train loss on 100 batch: 0.145473
Train loss on 125 batch: 0.120948
Train loss on 150 batch: 0.103156
Train loss on 175 batch: 0.100690
Train loss on 200 batch: 0.106144
Train loss on 225 batch: 0.089604
Train loss on 250 batch: 0.115323
Train loss on 275 batch: 0.093087
Train loss on 300 batch: 0.099863
Train loss on 325 batch: 0.132920
Train loss on 350 batch: 0.095418
Train loss on 375 batch: 0.095673
Train loss on 400 batch: 0.173931
Train loss on 425 batch: 0.132916
Train loss on 450 batch: 0.125194
Train loss on 475 batch: 0.135824
Train loss on 500 batch: 0.091543
Train loss on 525 batch: 0.145420
Train loss on 550 batch: 0.184547
Train loss on 575 batch: 0.143104
Train loss on 600 batch: 0.134072
Train loss on 625 batch: 0.158963
Train loss on 650 batch: 0.167856
Train loss on 675 batch: 0.125444
Train loss on 700 batch: 0.095754
Train loss on 725 batch: 0.104101
: Epoch: 18 | Training Loss: 0.122908 | Val. Loss: 0.427592 | Val. Kappa Score: nan | Estimated time: 66.38
Train loss on 25 batch: 0.165800
Train loss on 50 batch: 0.092640
Train loss on 75 batch: 0.118929
Train loss on 100 batch: 0.082901
Train loss on 125 batch: 0.059405
Train loss on 150 batch: 0.090504
Train loss on 175 batch: 0.074718
Train loss on 200 batch: 0.045062
Train loss on 225 batch: 0.170433
Train loss on 250 batch: 0.073238
Train loss on 275 batch: 0.083449
Train loss on 300 batch: 0.049627
Train loss on 325 batch: 0.088239
Train loss on 350 batch: 0.123191
Train loss on 375 batch: 0.102529
Train loss on 400 batch: 0.125253
Train loss on 425 batch: 0.142832
Train loss on 450 batch: 0.109872
Train loss on 475 batch: 0.142207
Train loss on 500 batch: 0.072985
Train loss on 525 batch: 0.151273
Train loss on 550 batch: 0.090193
Train loss on 575 batch: 0.088440
Train loss on 600 batch: 0.118134
Train loss on 625 batch: 0.081653
Train loss on 650 batch: 0.097158
Train loss on 675 batch: 0.197805
Train loss on 700 batch: 0.155265
Train loss on 725 batch: 0.174561
: Epoch: 19 | Training Loss: 0.109252 | Val. Loss: 0.359334 | Val. Kappa Score: nan | Estimated time: 64.90
Train loss on 25 batch: 0.080171
Train loss on 50 batch: 0.059984
Train loss on 75 batch: 0.056336
Train loss on 100 batch: 0.081172
Train loss on 125 batch: 0.134524
Train loss on 150 batch: 0.119030
Train loss on 175 batch: 0.096898
Train loss on 200 batch: 0.094653
Train loss on 225 batch: 0.154029
Train loss on 250 batch: 0.152050
Train loss on 275 batch: 0.077310
Train loss on 300 batch: 0.160819
Train loss on 325 batch: 0.142816
Train loss on 350 batch: 0.100341
Train loss on 375 batch: 0.102871
Train loss on 400 batch: 0.079053
Train loss on 425 batch: 0.156053
Train loss on 450 batch: 0.089667
Train loss on 475 batch: 0.117535
Train loss on 500 batch: 0.095035
Train loss on 525 batch: 0.060308
Train loss on 550 batch: 0.075716
Train loss on 575 batch: 0.110785
Train loss on 600 batch: 0.138088
Train loss on 625 batch: 0.112177
Train loss on 650 batch: 0.071370
Train loss on 675 batch: 0.118941
Train loss on 700 batch: 0.080299
Train loss on 725 batch: 0.110663
: Epoch: 20 | Training Loss: 0.104438 | Val. Loss: 0.378249 | Val. Kappa Score: nan | Estimated time: 66.24
Train loss on 25 batch: 0.115028
Train loss on 50 batch: 0.117372
Train loss on 75 batch: 0.103857
Train loss on 100 batch: 0.086368
Train loss on 125 batch: 0.054362
Train loss on 150 batch: 0.083461
Train loss on 175 batch: 0.084453
Train loss on 200 batch: 0.075818
Train loss on 225 batch: 0.091849
Train loss on 250 batch: 0.111179
Train loss on 275 batch: 0.127656
Train loss on 300 batch: 0.071515
Train loss on 325 batch: 0.117153
Train loss on 350 batch: 0.054086
Train loss on 375 batch: 0.093809
Train loss on 400 batch: 0.069956
Train loss on 425 batch: 0.122696
Train loss on 450 batch: 0.143945
Train loss on 475 batch: 0.088725
Train loss on 500 batch: 0.049663
Train loss on 525 batch: 0.110425
Train loss on 550 batch: 0.189762
Train loss on 575 batch: 0.129373
Train loss on 600 batch: 0.097015
Train loss on 625 batch: 0.053896
Train loss on 650 batch: 0.119723
Train loss on 675 batch: 0.100106
Train loss on 700 batch: 0.071963
Train loss on 725 batch: 0.066151
: Epoch: 21 | Training Loss: 0.096599 | Val. Loss: 0.445051 | Val. Kappa Score: nan | Estimated time: 65.25
Train loss on 25 batch: 0.046519
Train loss on 50 batch: 0.120258
Train loss on 75 batch: 0.071217
Train loss on 100 batch: 0.110170
Train loss on 125 batch: 0.067586
Train loss on 150 batch: 0.121018
Train loss on 175 batch: 0.096521
Train loss on 200 batch: 0.080649
Train loss on 225 batch: 0.133621
Train loss on 250 batch: 0.048765
Train loss on 275 batch: 0.092276
Train loss on 300 batch: 0.110863
Train loss on 325 batch: 0.109065
Train loss on 350 batch: 0.123415
Train loss on 375 batch: 0.059697
Train loss on 400 batch: 0.088328
Train loss on 425 batch: 0.086925
Train loss on 450 batch: 0.091177
Train loss on 475 batch: 0.082225
Train loss on 500 batch: 0.058137
Train loss on 525 batch: 0.148220
Train loss on 550 batch: 0.097255
Train loss on 575 batch: 0.085029
Train loss on 600 batch: 0.158804
Train loss on 625 batch: 0.105371
Train loss on 650 batch: 0.173598
Train loss on 675 batch: 0.073948
Train loss on 700 batch: 0.114950
Train loss on 725 batch: 0.120156
: Epoch: 22 | Training Loss: 0.099164 | Val. Loss: 0.333078 | Val. Kappa Score: nan | Estimated time: 66.93
Train loss on 25 batch: 0.109158
Train loss on 50 batch: 0.063531
Train loss on 75 batch: 0.078679
Train loss on 100 batch: 0.135191
Train loss on 125 batch: 0.079053
Train loss on 150 batch: 0.107021
Train loss on 175 batch: 0.091003
Train loss on 200 batch: 0.115211
Train loss on 225 batch: 0.073214
Train loss on 250 batch: 0.099657
Train loss on 275 batch: 0.073103
Train loss on 300 batch: 0.122012
Train loss on 325 batch: 0.064934
Train loss on 350 batch: 0.073439
Train loss on 375 batch: 0.102615
Train loss on 400 batch: 0.059787
Train loss on 425 batch: 0.062864
Train loss on 450 batch: 0.054992
Train loss on 475 batch: 0.086604
Train loss on 500 batch: 0.077862
Train loss on 525 batch: 0.058070
Train loss on 550 batch: 0.074918
Train loss on 575 batch: 0.084120
Train loss on 600 batch: 0.077236
Train loss on 625 batch: 0.059574
Train loss on 650 batch: 0.099544
Train loss on 675 batch: 0.069794
Train loss on 700 batch: 0.096702
Train loss on 725 batch: 0.111732
: Epoch: 23 | Training Loss: 0.084883 | Val. Loss: 0.383323 | Val. Kappa Score: nan | Estimated time: 66.27
Train loss on 25 batch: 0.106067
Train loss on 50 batch: 0.108451
Train loss on 75 batch: 0.066835
Train loss on 100 batch: 0.058321
Train loss on 125 batch: 0.108237
Train loss on 150 batch: 0.086542
Train loss on 175 batch: 0.061979
Train loss on 200 batch: 0.113873
Train loss on 225 batch: 0.087372
Train loss on 250 batch: 0.127277
Train loss on 275 batch: 0.111386
Train loss on 300 batch: 0.073837
Train loss on 325 batch: 0.049474
Train loss on 350 batch: 0.075336
Train loss on 375 batch: 0.078515
Train loss on 400 batch: 0.092018
Train loss on 425 batch: 0.081111
Train loss on 450 batch: 0.077295
Train loss on 475 batch: 0.115748
Train loss on 500 batch: 0.083351
Train loss on 525 batch: 0.083663
Train loss on 550 batch: 0.095120
Train loss on 575 batch: 0.061850
Train loss on 600 batch: 0.041581
Train loss on 625 batch: 0.065758
Train loss on 650 batch: 0.112710
Train loss on 675 batch: 0.071934
Train loss on 700 batch: 0.087443
Train loss on 725 batch: 0.054556
: Epoch: 24 | Training Loss: 0.084057 | Val. Loss: 0.394928 | Val. Kappa Score: nan | Estimated time: 66.17
Train loss on 25 batch: 0.084114
Train loss on 50 batch: 0.039557
Train loss on 75 batch: 0.047293
Train loss on 100 batch: 0.068505
Train loss on 125 batch: 0.070875
Train loss on 150 batch: 0.052558
Train loss on 175 batch: 0.059860
Train loss on 200 batch: 0.053512
Train loss on 225 batch: 0.078694
Train loss on 250 batch: 0.067016
Train loss on 275 batch: 0.088910
Train loss on 300 batch: 0.059782
Train loss on 325 batch: 0.074616
Train loss on 350 batch: 0.076332
Train loss on 375 batch: 0.096035
Train loss on 400 batch: 0.080576
Train loss on 425 batch: 0.073560
Train loss on 450 batch: 0.094008
Train loss on 475 batch: 0.083498
Train loss on 500 batch: 0.069270
Train loss on 525 batch: 0.073499
Train loss on 550 batch: 0.091636
Train loss on 575 batch: 0.181732
Train loss on 600 batch: 0.093779
Train loss on 625 batch: 0.103242
Train loss on 650 batch: 0.040457
Train loss on 675 batch: 0.154220
Train loss on 700 batch: 0.111286
Train loss on 725 batch: 0.066099
: Epoch: 25 | Training Loss: 0.080501 | Val. Loss: 0.403270 | Val. Kappa Score: nan | Estimated time: 65.23
Train loss on 25 batch: 0.064258
Train loss on 50 batch: 0.066242
Train loss on 75 batch: 0.062335
Train loss on 100 batch: 0.072745
Train loss on 125 batch: 0.088044
Train loss on 150 batch: 0.111588
Train loss on 175 batch: 0.127457
Train loss on 200 batch: 0.152663
Train loss on 225 batch: 0.102066
Train loss on 250 batch: 0.090194
Train loss on 275 batch: 0.045960
Train loss on 300 batch: 0.066524
Train loss on 325 batch: 0.093746
Train loss on 350 batch: 0.070523
Train loss on 375 batch: 0.062486
Train loss on 400 batch: 0.056245
Train loss on 425 batch: 0.060435
Train loss on 450 batch: 0.065585
Train loss on 475 batch: 0.053287
Train loss on 500 batch: 0.062825
Train loss on 525 batch: 0.176132
Train loss on 550 batch: 0.105138
Train loss on 575 batch: 0.062245
Train loss on 600 batch: 0.055441
Train loss on 625 batch: 0.058233
Train loss on 650 batch: 0.108586
Train loss on 675 batch: 0.094927
Train loss on 700 batch: 0.051131
Train loss on 725 batch: 0.054179
: Epoch: 26 | Training Loss: 0.080732 | Val. Loss: 0.363330 | Val. Kappa Score: nan | Estimated time: 66.43
Train loss on 25 batch: 0.147658
Train loss on 50 batch: 0.110179
Train loss on 75 batch: 0.060271
Train loss on 100 batch: 0.042178
Train loss on 125 batch: 0.100135
Train loss on 150 batch: 0.069879
Train loss on 175 batch: 0.120620
Train loss on 200 batch: 0.111637
Train loss on 225 batch: 0.082712
Train loss on 250 batch: 0.086321
Train loss on 275 batch: 0.058282
Train loss on 300 batch: 0.071735
Train loss on 325 batch: 0.052624
Train loss on 350 batch: 0.048203
Train loss on 375 batch: 0.080559
Train loss on 400 batch: 0.096884
Train loss on 425 batch: 0.056033
Train loss on 450 batch: 0.064563
Train loss on 475 batch: 0.065515
Train loss on 500 batch: 0.049824
Train loss on 525 batch: 0.093153
Train loss on 550 batch: 0.103458
Train loss on 575 batch: 0.135734
Train loss on 600 batch: 0.076514
Train loss on 625 batch: 0.089933
Train loss on 650 batch: 0.077070
Train loss on 675 batch: 0.101507
Train loss on 700 batch: 0.062893
Train loss on 725 batch: 0.098494
: Epoch: 27 | Training Loss: 0.083261 | Val. Loss: 0.386082 | Val. Kappa Score: nan | Estimated time: 65.91
Train loss on 25 batch: 0.048160
Train loss on 50 batch: 0.080920
Train loss on 75 batch: 0.051010
Train loss on 100 batch: 0.060501
Train loss on 125 batch: 0.051680
Train loss on 150 batch: 0.105040
Train loss on 175 batch: 0.043539
Train loss on 200 batch: 0.062323
Train loss on 225 batch: 0.091195
Train loss on 250 batch: 0.073860
Train loss on 275 batch: 0.059444
Train loss on 300 batch: 0.082252
Train loss on 325 batch: 0.093168
Train loss on 350 batch: 0.066644
Train loss on 375 batch: 0.081069
Train loss on 400 batch: 0.070943
Train loss on 425 batch: 0.071634
Train loss on 450 batch: 0.083955
Train loss on 475 batch: 0.065441
Train loss on 500 batch: 0.089211
Train loss on 525 batch: 0.123809
Train loss on 550 batch: 0.111211
Train loss on 575 batch: 0.084763
Train loss on 600 batch: 0.103377
Train loss on 625 batch: 0.056360
Train loss on 650 batch: 0.057381
Train loss on 675 batch: 0.100568
Train loss on 700 batch: 0.039629
Train loss on 725 batch: 0.053624
: Epoch: 28 | Training Loss: 0.074576 | Val. Loss: 0.366472 | Val. Kappa Score: nan | Estimated time: 65.13
time_estimated: 1850.02
n-epochs: 28
time_estimated: 1850.03
----------------------------------------

Experiment N: 8: 
date: 2019.08.06 10:53:37
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.463367
Train loss on 50 batch: 0.811986
Train loss on 75 batch: 0.630837
Train loss on 100 batch: 0.512677
Train loss on 125 batch: 1.454058
Train loss on 150 batch: 0.444837
Train loss on 175 batch: 0.743015
Train loss on 200 batch: 0.515323
Train loss on 225 batch: 0.469837
Train loss on 250 batch: 0.530133
Train loss on 275 batch: 0.709623
Train loss on 300 batch: 0.536255
Train loss on 325 batch: 0.600197
Train loss on 350 batch: 0.469620
best-train-loss: 0.706555
best-valid-loss: 0.337588
best-kappa: 0.6248
: Epoch: 1 | Training Loss: 0.706555 | Val. Loss: 0.337588 | Val. Kappa Score: 0.6248 | Estimated time: 44.76
Train loss on 25 batch: 0.512927
Train loss on 50 batch: 0.359910
Train loss on 75 batch: 0.468222
Train loss on 100 batch: 0.425693
Train loss on 125 batch: 0.557646
Train loss on 150 batch: 0.415462
Train loss on 175 batch: 0.454178
Train loss on 200 batch: 0.304263
Train loss on 225 batch: 0.311299
Train loss on 250 batch: 0.658436
Train loss on 275 batch: 0.604436
Train loss on 300 batch: 0.385592
Train loss on 325 batch: 0.445588
Train loss on 350 batch: 0.448147
: Epoch: 2 | Training Loss: 0.453700 | Val. Loss: 0.578749 | Val. Kappa Score: nan | Estimated time: 44.91
Train loss on 25 batch: 0.400348
Train loss on 50 batch: 0.498537
Train loss on 75 batch: 0.405776
Train loss on 100 batch: 0.344606
Train loss on 125 batch: 0.264357
Train loss on 150 batch: 0.333220
Train loss on 175 batch: 0.294785
Train loss on 200 batch: 0.460581
Train loss on 225 batch: 0.491243
Train loss on 250 batch: 0.368672
Train loss on 275 batch: 0.344645
Train loss on 300 batch: 0.377156
Train loss on 325 batch: 0.230887
Train loss on 350 batch: 0.377632
: Epoch: 3 | Training Loss: 0.370889 | Val. Loss: 0.394445 | Val. Kappa Score: nan | Estimated time: 45.79
Train loss on 25 batch: 0.214386
Train loss on 50 batch: 0.285653
Train loss on 75 batch: 0.365677
Train loss on 100 batch: 0.238125
Train loss on 125 batch: 0.195399
Train loss on 150 batch: 0.401503
Train loss on 175 batch: 0.329072
Train loss on 200 batch: 0.279740
Train loss on 225 batch: 0.282893
Train loss on 250 batch: 0.363108
Train loss on 275 batch: 0.262943
Train loss on 300 batch: 0.284105
Train loss on 325 batch: 0.328875
Train loss on 350 batch: 0.422470
: Epoch: 4 | Training Loss: 0.303853 | Val. Loss: 0.435879 | Val. Kappa Score: nan | Estimated time: 44.75
Train loss on 25 batch: 0.301760
Train loss on 50 batch: 0.318982
Train loss on 75 batch: 0.336440
Train loss on 100 batch: 0.281798
Train loss on 125 batch: 0.242720
Train loss on 150 batch: 0.243240
Train loss on 175 batch: 0.230698
Train loss on 200 batch: 0.305052
Train loss on 225 batch: 0.449058
Train loss on 250 batch: 0.319501
Train loss on 275 batch: 0.269160
Train loss on 300 batch: 0.351282
Train loss on 325 batch: 0.214207
Train loss on 350 batch: 0.251723
: Epoch: 5 | Training Loss: 0.293973 | Val. Loss: 0.339508 | Val. Kappa Score: nan | Estimated time: 44.87
Train loss on 25 batch: 0.236219
Train loss on 50 batch: 0.263033
Train loss on 75 batch: 0.255431
Train loss on 100 batch: 0.261612
Train loss on 125 batch: 0.239284
Train loss on 150 batch: 0.319372
Train loss on 175 batch: 0.318997
Train loss on 200 batch: 0.275313
Train loss on 225 batch: 0.302820
Train loss on 250 batch: 0.185215
Train loss on 275 batch: 0.258108
Train loss on 300 batch: 0.253519
Train loss on 325 batch: 0.311453
Train loss on 350 batch: 0.213693
: Epoch: 6 | Training Loss: 0.263862 | Val. Loss: 0.346701 | Val. Kappa Score: nan | Estimated time: 45.59
Train loss on 25 batch: 0.218211
Train loss on 50 batch: 0.204606
Train loss on 75 batch: 0.190762
Train loss on 100 batch: 0.208365
Train loss on 125 batch: 0.244756
Train loss on 150 batch: 0.235248
Train loss on 175 batch: 0.178417
Train loss on 200 batch: 0.196463
Train loss on 225 batch: 0.228613
Train loss on 250 batch: 0.272699
Train loss on 275 batch: 0.247753
Train loss on 300 batch: 0.206998
Train loss on 325 batch: 0.321018
Train loss on 350 batch: 0.362630
: Epoch: 7 | Training Loss: 0.236896 | Val. Loss: 0.375658 | Val. Kappa Score: nan | Estimated time: 45.45
Train loss on 25 batch: 0.294844
Train loss on 50 batch: 0.237092
Train loss on 75 batch: 0.269600
Train loss on 100 batch: 0.313953
Train loss on 125 batch: 0.267507
Train loss on 150 batch: 0.156593
Train loss on 175 batch: 0.322572
Train loss on 200 batch: 0.261938
Train loss on 225 batch: 0.258440
Train loss on 250 batch: 0.321246
Train loss on 275 batch: 0.221880
Train loss on 300 batch: 0.249491
Train loss on 325 batch: 0.190846
Train loss on 350 batch: 0.340999
: Epoch: 8 | Training Loss: 0.264786 | Val. Loss: 0.399444 | Val. Kappa Score: nan | Estimated time: 44.47
Train loss on 25 batch: 0.309833
Train loss on 50 batch: 0.257468
Train loss on 75 batch: 0.163953
Train loss on 100 batch: 0.167459
Train loss on 125 batch: 0.195942
Train loss on 150 batch: 0.219784
Train loss on 175 batch: 0.169038
Train loss on 200 batch: 0.217978
Train loss on 225 batch: 0.195981
Train loss on 250 batch: 0.198599
Train loss on 275 batch: 0.136504
Train loss on 300 batch: 0.167384
Train loss on 325 batch: 0.228959
Train loss on 350 batch: 0.180271
: Epoch: 9 | Training Loss: 0.200654 | Val. Loss: 0.366811 | Val. Kappa Score: nan | Estimated time: 44.18
Train loss on 25 batch: 0.382526
Train loss on 50 batch: 0.279038
Train loss on 75 batch: 0.158507
Train loss on 100 batch: 0.202009
Train loss on 125 batch: 0.163189
Train loss on 150 batch: 0.213441
Train loss on 175 batch: 0.200205
Train loss on 200 batch: 0.226110
Train loss on 225 batch: 0.224829
Train loss on 250 batch: 0.151166
Train loss on 275 batch: 0.186978
Train loss on 300 batch: 0.178966
Train loss on 325 batch: 0.138502
Train loss on 350 batch: 0.215648
: Epoch: 10 | Training Loss: 0.208651 | Val. Loss: 0.345578 | Val. Kappa Score: nan | Estimated time: 44.95
Train loss on 25 batch: 0.119321
Train loss on 50 batch: 0.162877
Train loss on 75 batch: 0.138005
Train loss on 100 batch: 0.080303
Train loss on 125 batch: 0.153540
Train loss on 150 batch: 0.161394
Train loss on 175 batch: 0.141422
Train loss on 200 batch: 0.230636
Train loss on 225 batch: 0.099487
Train loss on 250 batch: 0.197266
Train loss on 275 batch: 0.199526
Train loss on 300 batch: 0.128025
Train loss on 325 batch: 0.207214
Train loss on 350 batch: 0.166069
: Epoch: 11 | Training Loss: 0.156077 | Val. Loss: 0.352684 | Val. Kappa Score: nan | Estimated time: 45.07
Train loss on 25 batch: 0.209635
Train loss on 50 batch: 0.203989
Train loss on 75 batch: 0.159903
Train loss on 100 batch: 0.170055
Train loss on 125 batch: 0.175007
Train loss on 150 batch: 0.131704
Train loss on 175 batch: 0.124530
Train loss on 200 batch: 0.178462
Train loss on 225 batch: 0.138648
Train loss on 250 batch: 0.132061
Train loss on 275 batch: 0.145659
Train loss on 300 batch: 0.141980
Train loss on 325 batch: 0.119004
Train loss on 350 batch: 0.171930
: Epoch: 12 | Training Loss: 0.157326 | Val. Loss: 0.390421 | Val. Kappa Score: nan | Estimated time: 46.13
Train loss on 25 batch: 0.166213
Train loss on 50 batch: 0.137994
Train loss on 75 batch: 0.142034
Train loss on 100 batch: 0.163145
Train loss on 125 batch: 0.125190
Train loss on 150 batch: 0.162272
Train loss on 175 batch: 0.164799
Train loss on 200 batch: 0.080607
Train loss on 225 batch: 0.091444
Train loss on 250 batch: 0.136109
Train loss on 275 batch: 0.134218
Train loss on 300 batch: 0.200268
Train loss on 325 batch: 0.163910
Train loss on 350 batch: 0.168306
: Epoch: 13 | Training Loss: 0.145465 | Val. Loss: 0.365824 | Val. Kappa Score: nan | Estimated time: 45.07
Train loss on 25 batch: 0.122487
Train loss on 50 batch: 0.131890
Train loss on 75 batch: 0.125654
Train loss on 100 batch: 0.160390
Train loss on 125 batch: 0.182203
Train loss on 150 batch: 0.115941
Train loss on 175 batch: 0.183066
Train loss on 200 batch: 0.143384
Train loss on 225 batch: 0.155120
Train loss on 250 batch: 0.138982
Train loss on 275 batch: 0.130359
Train loss on 300 batch: 0.116275
Train loss on 325 batch: 0.100095
Train loss on 350 batch: 0.108160
best-train-loss: 0.136715
best-valid-loss: 0.306875
best-kappa: nan
: Epoch: 14 | Training Loss: 0.136715 | Val. Loss: 0.306875 | Val. Kappa Score: nan | Estimated time: 44.83
Train loss on 25 batch: 0.095939
Train loss on 50 batch: 0.106651
Train loss on 75 batch: 0.080434
Train loss on 100 batch: 0.118534
Train loss on 125 batch: 0.128057
Train loss on 150 batch: 0.100910
Train loss on 175 batch: 0.094387
Train loss on 200 batch: 0.105921
Train loss on 225 batch: 0.122941
Train loss on 250 batch: 0.141645
Train loss on 275 batch: 0.113244
Train loss on 300 batch: 0.133321
Train loss on 325 batch: 0.086755
Train loss on 350 batch: 0.167845
: Epoch: 15 | Training Loss: 0.114042 | Val. Loss: 0.334911 | Val. Kappa Score: nan | Estimated time: 45.48
Train loss on 25 batch: 0.099277
Train loss on 50 batch: 0.095274
Train loss on 75 batch: 0.121740
Train loss on 100 batch: 0.071439
Train loss on 125 batch: 0.130359
Train loss on 150 batch: 0.083929
Train loss on 175 batch: 0.159211
Train loss on 200 batch: 0.113390
Train loss on 225 batch: 0.100148
Train loss on 250 batch: 0.079242
Train loss on 275 batch: 0.092532
Train loss on 300 batch: 0.122887
Train loss on 325 batch: 0.109157
Train loss on 350 batch: 0.105290
: Epoch: 16 | Training Loss: 0.105991 | Val. Loss: 0.313043 | Val. Kappa Score: nan | Estimated time: 45.44
Train loss on 25 batch: 0.165862
Train loss on 50 batch: 0.134365
Train loss on 75 batch: 0.143409
Train loss on 100 batch: 0.130349
Train loss on 125 batch: 0.119371
Train loss on 150 batch: 0.088275
Train loss on 175 batch: 0.088396
Train loss on 200 batch: 0.069430
Train loss on 225 batch: 0.100540
Train loss on 250 batch: 0.136554
Train loss on 275 batch: 0.099794
Train loss on 300 batch: 0.145158
Train loss on 325 batch: 0.119501
Train loss on 350 batch: 0.091764
: Epoch: 17 | Training Loss: 0.116626 | Val. Loss: 0.333885 | Val. Kappa Score: nan | Estimated time: 45.21
Train loss on 25 batch: 0.094352
Train loss on 50 batch: 0.143964
Train loss on 75 batch: 0.091234
Train loss on 100 batch: 0.082752
Train loss on 125 batch: 0.097504
Train loss on 150 batch: 0.085132
Train loss on 175 batch: 0.076549
Train loss on 200 batch: 0.071327
Train loss on 225 batch: 0.098915
Train loss on 250 batch: 0.114743
Train loss on 275 batch: 0.182947
Train loss on 300 batch: 0.159736
Train loss on 325 batch: 0.136194
Train loss on 350 batch: 0.086233
: Epoch: 18 | Training Loss: 0.108685 | Val. Loss: 0.348677 | Val. Kappa Score: nan | Estimated time: 46.14
Train loss on 25 batch: 0.118178
Train loss on 50 batch: 0.103872
Train loss on 75 batch: 0.085827
Train loss on 100 batch: 0.068302
Train loss on 125 batch: 0.193338
Train loss on 150 batch: 0.107571
Train loss on 175 batch: 0.127172
Train loss on 200 batch: 0.091068
Train loss on 225 batch: 0.118077
Train loss on 250 batch: 0.063912
Train loss on 275 batch: 0.095838
Train loss on 300 batch: 0.099010
Train loss on 325 batch: 0.110226
Train loss on 350 batch: 0.128985
: Epoch: 19 | Training Loss: 0.107955 | Val. Loss: 0.324106 | Val. Kappa Score: nan | Estimated time: 44.71
Train loss on 25 batch: 0.084246
Train loss on 50 batch: 0.069983
Train loss on 75 batch: 0.096840
Train loss on 100 batch: 0.103865
Train loss on 125 batch: 0.107100
Train loss on 150 batch: 0.185116
Train loss on 175 batch: 0.111376
Train loss on 200 batch: 0.081286
Train loss on 225 batch: 0.087515
Train loss on 250 batch: 0.111440
Train loss on 275 batch: 0.061675
Train loss on 300 batch: 0.090039
Train loss on 325 batch: 0.068996
Train loss on 350 batch: 0.057154
: Epoch: 20 | Training Loss: 0.094045 | Val. Loss: 0.314353 | Val. Kappa Score: nan | Estimated time: 44.97
Train loss on 25 batch: 0.079904
Train loss on 50 batch: 0.084512
Train loss on 75 batch: 0.056332
Train loss on 100 batch: 0.088694
Train loss on 125 batch: 0.111441
Train loss on 150 batch: 0.120852
Train loss on 175 batch: 0.071375
Train loss on 200 batch: 0.074853
Train loss on 225 batch: 0.104903
Train loss on 250 batch: 0.054145
Train loss on 275 batch: 0.116744
Train loss on 300 batch: 0.059546
Train loss on 325 batch: 0.058418
Train loss on 350 batch: 0.120596
: Epoch: 21 | Training Loss: 0.085880 | Val. Loss: 0.332673 | Val. Kappa Score: nan | Estimated time: 45.46
Train loss on 25 batch: 0.054774
Train loss on 50 batch: 0.041731
Train loss on 75 batch: 0.058462
Train loss on 100 batch: 0.051182
Train loss on 125 batch: 0.096981
Train loss on 150 batch: 0.089740
Train loss on 175 batch: 0.086458
Train loss on 200 batch: 0.121792
Train loss on 225 batch: 0.072809
Train loss on 250 batch: 0.099109
Train loss on 275 batch: 0.082729
Train loss on 300 batch: 0.089163
Train loss on 325 batch: 0.078847
Train loss on 350 batch: 0.072372
: Epoch: 22 | Training Loss: 0.078296 | Val. Loss: 0.332881 | Val. Kappa Score: nan | Estimated time: 44.84
Train loss on 25 batch: 0.082401
Train loss on 50 batch: 0.122399
Train loss on 75 batch: 0.093733
Train loss on 100 batch: 0.064662
Train loss on 125 batch: 0.087222
Train loss on 150 batch: 0.067701
Train loss on 175 batch: 0.046709
Train loss on 200 batch: 0.068517
Train loss on 225 batch: 0.066482
Train loss on 250 batch: 0.059932
Train loss on 275 batch: 0.056694
Train loss on 300 batch: 0.074289
Train loss on 325 batch: 0.064949
Train loss on 350 batch: 0.071258
: Epoch: 23 | Training Loss: 0.073353 | Val. Loss: 0.310290 | Val. Kappa Score: nan | Estimated time: 44.82
Train loss on 25 batch: 0.094140
Train loss on 50 batch: 0.060798
Train loss on 75 batch: 0.071553
Train loss on 100 batch: 0.066941
Train loss on 125 batch: 0.082228
Train loss on 150 batch: 0.109760
Train loss on 175 batch: 0.059209
Train loss on 200 batch: 0.064674
Train loss on 225 batch: 0.056719
Train loss on 250 batch: 0.086833
Train loss on 275 batch: 0.110348
Train loss on 300 batch: 0.066325
Train loss on 325 batch: 0.073093
Train loss on 350 batch: 0.069966
: Epoch: 24 | Training Loss: 0.076613 | Val. Loss: 0.333656 | Val. Kappa Score: nan | Estimated time: 45.03
Train loss on 25 batch: 0.058356
Train loss on 50 batch: 0.049166
Train loss on 75 batch: 0.055219
Train loss on 100 batch: 0.052589
Train loss on 125 batch: 0.061829
Train loss on 150 batch: 0.058927
Train loss on 175 batch: 0.075443
Train loss on 200 batch: 0.068275
Train loss on 225 batch: 0.066680
Train loss on 250 batch: 0.083950
Train loss on 275 batch: 0.076194
Train loss on 300 batch: 0.085177
Train loss on 325 batch: 0.072230
Train loss on 350 batch: 0.126844
: Epoch: 25 | Training Loss: 0.070777 | Val. Loss: 0.377247 | Val. Kappa Score: nan | Estimated time: 45.33
Train loss on 25 batch: 0.067583
Train loss on 50 batch: 0.063346
Train loss on 75 batch: 0.084333
Train loss on 100 batch: 0.102934
Train loss on 125 batch: 0.081777
Train loss on 150 batch: 0.065818
Train loss on 175 batch: 0.049820
Train loss on 200 batch: 0.060158
Train loss on 225 batch: 0.051009
Train loss on 250 batch: 0.056395
Train loss on 275 batch: 0.097650
Train loss on 300 batch: 0.062608
Train loss on 325 batch: 0.065896
Train loss on 350 batch: 0.055507
: Epoch: 26 | Training Loss: 0.068917 | Val. Loss: 0.351717 | Val. Kappa Score: nan | Estimated time: 44.82
Train loss on 25 batch: 0.062314
Train loss on 50 batch: 0.051458
Train loss on 75 batch: 0.083476
Train loss on 100 batch: 0.083999
Train loss on 125 batch: 0.113224
Train loss on 150 batch: 0.058513
Train loss on 175 batch: 0.068985
Train loss on 200 batch: 0.102220
Train loss on 225 batch: 0.050663
Train loss on 250 batch: 0.087273
Train loss on 275 batch: 0.093174
Train loss on 300 batch: 0.085646
Train loss on 325 batch: 0.094234
Train loss on 350 batch: 0.094242
: Epoch: 27 | Training Loss: 0.080673 | Val. Loss: 0.378610 | Val. Kappa Score: nan | Estimated time: 45.09
Train loss on 25 batch: 0.056440
Train loss on 50 batch: 0.049965
Train loss on 75 batch: 0.063542
Train loss on 100 batch: 0.038264
Train loss on 125 batch: 0.055564
Train loss on 150 batch: 0.052295
Train loss on 175 batch: 0.054057
Train loss on 200 batch: 0.077317
Train loss on 225 batch: 0.064909
Train loss on 250 batch: 0.112234
Train loss on 275 batch: 0.136967
Train loss on 300 batch: 0.088991
Train loss on 325 batch: 0.048331
Train loss on 350 batch: 0.072079
best-train-loss: 0.069354
best-valid-loss: 0.294995
best-kappa: nan
: Epoch: 28 | Training Loss: 0.069354 | Val. Loss: 0.294995 | Val. Kappa Score: nan | Estimated time: 45.82
Train loss on 25 batch: 0.066265
Train loss on 50 batch: 0.076592
Train loss on 75 batch: 0.060266
Train loss on 100 batch: 0.061077
Train loss on 125 batch: 0.123202
Train loss on 150 batch: 0.055292
Train loss on 175 batch: 0.050628
Train loss on 200 batch: 0.071532
Train loss on 225 batch: 0.063306
Train loss on 250 batch: 0.050954
Train loss on 275 batch: 0.051888
Train loss on 300 batch: 0.087807
Train loss on 325 batch: 0.066152
Train loss on 350 batch: 0.078707
: Epoch: 29 | Training Loss: 0.068834 | Val. Loss: 0.316842 | Val. Kappa Score: nan | Estimated time: 45.18
Train loss on 25 batch: 0.052084
Train loss on 50 batch: 0.058693
Train loss on 75 batch: 0.039388
Train loss on 100 batch: 0.052280
Train loss on 125 batch: 0.043096
Train loss on 150 batch: 0.065829
Train loss on 175 batch: 0.090304
Train loss on 200 batch: 0.058589
Train loss on 225 batch: 0.039513
Train loss on 250 batch: 0.051208
Train loss on 275 batch: 0.064032
Train loss on 300 batch: 0.110503
Train loss on 325 batch: 0.059445
Train loss on 350 batch: 0.102646
: Epoch: 30 | Training Loss: 0.063401 | Val. Loss: 0.337978 | Val. Kappa Score: nan | Estimated time: 45.19
Train loss on 25 batch: 0.100041
Train loss on 50 batch: 0.063048
Train loss on 75 batch: 0.062767
Train loss on 100 batch: 0.059419
Train loss on 125 batch: 0.039028
Train loss on 150 batch: 0.069132
Train loss on 175 batch: 0.072152
Train loss on 200 batch: 0.061188
Train loss on 225 batch: 0.061271
Train loss on 250 batch: 0.054292
Train loss on 275 batch: 0.052066
Train loss on 300 batch: 0.042024
Train loss on 325 batch: 0.053332
Train loss on 350 batch: 0.104023
: Epoch: 31 | Training Loss: 0.063842 | Val. Loss: 0.355377 | Val. Kappa Score: nan | Estimated time: 45.04
Train loss on 25 batch: 0.055002
Train loss on 50 batch: 0.061389
Train loss on 75 batch: 0.041836
Train loss on 100 batch: 0.058343
Train loss on 125 batch: 0.076665
Train loss on 150 batch: 0.065992
Train loss on 175 batch: 0.037721
Train loss on 200 batch: 0.044126
Train loss on 225 batch: 0.080434
Train loss on 250 batch: 0.038474
Train loss on 275 batch: 0.047089
Train loss on 300 batch: 0.068394
Train loss on 325 batch: 0.042208
Train loss on 350 batch: 0.029002
best-train-loss: 0.053334
best-valid-loss: 0.293608
best-kappa: nan
: Epoch: 32 | Training Loss: 0.053334 | Val. Loss: 0.293608 | Val. Kappa Score: nan | Estimated time: 44.11
Train loss on 25 batch: 0.036835
Train loss on 50 batch: 0.050783
Train loss on 75 batch: 0.061372
Train loss on 100 batch: 0.036518
Train loss on 125 batch: 0.027007
Train loss on 150 batch: 0.020165
Train loss on 175 batch: 0.024622
Train loss on 200 batch: 0.044753
Train loss on 225 batch: 0.051573
Train loss on 250 batch: 0.040279
Train loss on 275 batch: 0.065831
Train loss on 300 batch: 0.066204
Train loss on 325 batch: 0.033615
Train loss on 350 batch: 0.048200
: Epoch: 33 | Training Loss: 0.043411 | Val. Loss: 0.304582 | Val. Kappa Score: nan | Estimated time: 44.65
Train loss on 25 batch: 0.070194
Train loss on 50 batch: 0.053823
Train loss on 75 batch: 0.051048
Train loss on 100 batch: 0.047374
Train loss on 125 batch: 0.043182
Train loss on 150 batch: 0.047931
Train loss on 175 batch: 0.054795
Train loss on 200 batch: 0.057735
Train loss on 225 batch: 0.059079
Train loss on 250 batch: 0.033514
Train loss on 275 batch: 0.091778
Train loss on 300 batch: 0.063828
Train loss on 325 batch: 0.032413
Train loss on 350 batch: 0.050443
: Epoch: 34 | Training Loss: 0.054081 | Val. Loss: 0.340815 | Val. Kappa Score: nan | Estimated time: 45.39
Train loss on 25 batch: 0.044841
Train loss on 50 batch: 0.037774
Train loss on 75 batch: 0.045939
Train loss on 100 batch: 0.058348
Train loss on 125 batch: 0.028555
Train loss on 150 batch: 0.050424
Train loss on 175 batch: 0.037860
Train loss on 200 batch: 0.061421
Train loss on 225 batch: 0.075359
Train loss on 250 batch: 0.089524
Train loss on 275 batch: 0.053730
Train loss on 300 batch: 0.036750
Train loss on 325 batch: 0.029332
Train loss on 350 batch: 0.052376
: Epoch: 35 | Training Loss: 0.050159 | Val. Loss: 0.299154 | Val. Kappa Score: nan | Estimated time: 45.02
Train loss on 25 batch: 0.054302
Train loss on 50 batch: 0.064485
Train loss on 75 batch: 0.055427
Train loss on 100 batch: 0.045603
Train loss on 125 batch: 0.055760
Train loss on 150 batch: 0.051724
Train loss on 175 batch: 0.049072
Train loss on 200 batch: 0.033163
Train loss on 225 batch: 0.047833
Train loss on 250 batch: 0.041239
Train loss on 275 batch: 0.038054
Train loss on 300 batch: 0.050000
Train loss on 325 batch: 0.049996
Train loss on 350 batch: 0.085645
: Epoch: 36 | Training Loss: 0.051593 | Val. Loss: 0.317088 | Val. Kappa Score: nan | Estimated time: 45.22
Train loss on 25 batch: 0.055822
Train loss on 50 batch: 0.040647
Train loss on 75 batch: 0.048383
Train loss on 100 batch: 0.037601
Train loss on 125 batch: 0.047618
Train loss on 150 batch: 0.044060
Train loss on 175 batch: 0.052663
Train loss on 200 batch: 0.031598
Train loss on 225 batch: 0.031531
Train loss on 250 batch: 0.044777
Train loss on 275 batch: 0.035710
Train loss on 300 batch: 0.072682
Train loss on 325 batch: 0.083268
Train loss on 350 batch: 0.090300
: Epoch: 37 | Training Loss: 0.051190 | Val. Loss: 0.310857 | Val. Kappa Score: nan | Estimated time: 45.38
Train loss on 25 batch: 0.064990
Train loss on 50 batch: 0.059600
Train loss on 75 batch: 0.056862
Train loss on 100 batch: 0.030297
Train loss on 125 batch: 0.050073
Train loss on 150 batch: 0.042489
Train loss on 175 batch: 0.061593
Train loss on 200 batch: 0.043647
Train loss on 225 batch: 0.052267
Train loss on 250 batch: 0.066246
Train loss on 275 batch: 0.050312
Train loss on 300 batch: 0.054336
Train loss on 325 batch: 0.039722
Train loss on 350 batch: 0.065863
: Epoch: 38 | Training Loss: 0.052735 | Val. Loss: 0.314273 | Val. Kappa Score: nan | Estimated time: 45.92
Train loss on 25 batch: 0.063801
Train loss on 50 batch: 0.067250
Train loss on 75 batch: 0.049653
Train loss on 100 batch: 0.121174
Train loss on 125 batch: 0.085313
Train loss on 150 batch: 0.051463
Train loss on 175 batch: 0.064734
Train loss on 200 batch: 0.038284
Train loss on 225 batch: 0.046382
Train loss on 250 batch: 0.038760
Train loss on 275 batch: 0.093599
Train loss on 300 batch: 0.074941
Train loss on 325 batch: 0.039065
Train loss on 350 batch: 0.093818
: Epoch: 39 | Training Loss: 0.066303 | Val. Loss: 0.320217 | Val. Kappa Score: nan | Estimated time: 45.48
Train loss on 25 batch: 0.060565
Train loss on 50 batch: 0.068101
Train loss on 75 batch: 0.052863
Train loss on 100 batch: 0.053041
Train loss on 125 batch: 0.053446
Train loss on 150 batch: 0.039172
Train loss on 175 batch: 0.055077
Train loss on 200 batch: 0.053040
Train loss on 225 batch: 0.047557
Train loss on 250 batch: 0.048518
Train loss on 275 batch: 0.092073
Train loss on 300 batch: 0.088193
Train loss on 325 batch: 0.050477
Train loss on 350 batch: 0.038414
: Epoch: 40 | Training Loss: 0.057181 | Val. Loss: 0.317786 | Val. Kappa Score: nan | Estimated time: 45.34
Train loss on 25 batch: 0.039736
Train loss on 50 batch: 0.038896
Train loss on 75 batch: 0.032634
Train loss on 100 batch: 0.054439
Train loss on 125 batch: 0.039512
Train loss on 150 batch: 0.068405
Train loss on 175 batch: 0.042141
Train loss on 200 batch: 0.033668
Train loss on 225 batch: 0.041565
Train loss on 250 batch: 0.038876
Train loss on 275 batch: 0.037522
Train loss on 300 batch: 0.025279
Train loss on 325 batch: 0.028662
Train loss on 350 batch: 0.026058
: Epoch: 41 | Training Loss: 0.039100 | Val. Loss: 0.301531 | Val. Kappa Score: nan | Estimated time: 44.94
Train loss on 25 batch: 0.025968
Train loss on 50 batch: 0.039964
Train loss on 75 batch: 0.065085
Train loss on 100 batch: 0.034297
Train loss on 125 batch: 0.036705
Train loss on 150 batch: 0.027732
Train loss on 175 batch: 0.045266
Train loss on 200 batch: 0.031838
Train loss on 225 batch: 0.040139
Train loss on 250 batch: 0.035957
Train loss on 275 batch: 0.030698
Train loss on 300 batch: 0.020327
Train loss on 325 batch: 0.053436
Train loss on 350 batch: 0.031456
best-train-loss: 0.037062
best-valid-loss: 0.289037
best-kappa: nan
: Epoch: 42 | Training Loss: 0.037062 | Val. Loss: 0.289037 | Val. Kappa Score: nan | Estimated time: 45.37
Train loss on 25 batch: 0.043573
Train loss on 50 batch: 0.019253
Train loss on 75 batch: 0.021424
Train loss on 100 batch: 0.039695
Train loss on 125 batch: 0.027765
Train loss on 150 batch: 0.027281
Train loss on 175 batch: 0.056238
Train loss on 200 batch: 0.051725
Train loss on 225 batch: 0.043248
Train loss on 250 batch: 0.035514
Train loss on 275 batch: 0.073201
Train loss on 300 batch: 0.054734
Train loss on 325 batch: 0.036747
Train loss on 350 batch: 0.030634
: Epoch: 43 | Training Loss: 0.040074 | Val. Loss: 0.293035 | Val. Kappa Score: nan | Estimated time: 45.86
Train loss on 25 batch: 0.030403
Train loss on 50 batch: 0.042049
Train loss on 75 batch: 0.047430
Train loss on 100 batch: 0.033680
Train loss on 125 batch: 0.027681
Train loss on 150 batch: 0.051276
Train loss on 175 batch: 0.027461
Train loss on 200 batch: 0.032592
Train loss on 225 batch: 0.024092
Train loss on 250 batch: 0.027151
Train loss on 275 batch: 0.023696
Train loss on 300 batch: 0.050249
Train loss on 325 batch: 0.031250
Train loss on 350 batch: 0.046076
: Epoch: 44 | Training Loss: 0.035363 | Val. Loss: 0.331204 | Val. Kappa Score: nan | Estimated time: 45.21
Train loss on 25 batch: 0.030170
Train loss on 50 batch: 0.037479
Train loss on 75 batch: 0.027916
Train loss on 100 batch: 0.040516
Train loss on 125 batch: 0.029695
Train loss on 150 batch: 0.049855
Train loss on 175 batch: 0.030977
Train loss on 200 batch: 0.065929
Train loss on 225 batch: 0.040290
Train loss on 250 batch: 0.038956
Train loss on 275 batch: 0.042554
Train loss on 300 batch: 0.045530
Train loss on 325 batch: 0.042472
Train loss on 350 batch: 0.020197
: Epoch: 45 | Training Loss: 0.038753 | Val. Loss: 0.314946 | Val. Kappa Score: nan | Estimated time: 45.07
Train loss on 25 batch: 0.051627
Train loss on 50 batch: 0.040283
Train loss on 75 batch: 0.040140
Train loss on 100 batch: 0.070101
Train loss on 125 batch: 0.062302
Train loss on 150 batch: 0.042438
Train loss on 175 batch: 0.052186
Train loss on 200 batch: 0.027078
Train loss on 225 batch: 0.029200
Train loss on 250 batch: 0.038379
Train loss on 275 batch: 0.057990
Train loss on 300 batch: 0.036084
Train loss on 325 batch: 0.043981
Train loss on 350 batch: 0.039232
best-train-loss: 0.045073
best-valid-loss: 0.288753
best-kappa: nan
: Epoch: 46 | Training Loss: 0.045073 | Val. Loss: 0.288753 | Val. Kappa Score: nan | Estimated time: 45.58
Train loss on 25 batch: 0.054282
Train loss on 50 batch: 0.027628
Train loss on 75 batch: 0.046885
Train loss on 100 batch: 0.091693
Train loss on 125 batch: 0.039468
Train loss on 150 batch: 0.045886
Train loss on 175 batch: 0.038181
Train loss on 200 batch: 0.039592
Train loss on 225 batch: 0.035150
Train loss on 250 batch: 0.041519
Train loss on 275 batch: 0.037827
Train loss on 300 batch: 0.022021
Train loss on 325 batch: 0.031990
Train loss on 350 batch: 0.036623
: Epoch: 47 | Training Loss: 0.042053 | Val. Loss: 0.350486 | Val. Kappa Score: nan | Estimated time: 45.48
Train loss on 25 batch: 0.057987
Train loss on 50 batch: 0.043545
Train loss on 75 batch: 0.033212
Train loss on 100 batch: 0.022951
Train loss on 125 batch: 0.031022
Train loss on 150 batch: 0.039876
Train loss on 175 batch: 0.062117
Train loss on 200 batch: 0.031191
Train loss on 225 batch: 0.031349
Train loss on 250 batch: 0.036091
Train loss on 275 batch: 0.056674
Train loss on 300 batch: 0.049406
Train loss on 325 batch: 0.039953
Train loss on 350 batch: 0.069931
: Epoch: 48 | Training Loss: 0.043236 | Val. Loss: 0.323159 | Val. Kappa Score: nan | Estimated time: 45.56
Train loss on 25 batch: 0.076772
Train loss on 50 batch: 0.080407
Train loss on 75 batch: 0.104816
Train loss on 100 batch: 0.062590
Train loss on 125 batch: 0.064770
Train loss on 150 batch: 0.062194
Train loss on 175 batch: 0.064198
Train loss on 200 batch: 0.073386
Train loss on 225 batch: 0.037978
Train loss on 250 batch: 0.043778
Train loss on 275 batch: 0.046198
Train loss on 300 batch: 0.050825
Train loss on 325 batch: 0.030162
Train loss on 350 batch: 0.074612
: Epoch: 49 | Training Loss: 0.062335 | Val. Loss: 0.341080 | Val. Kappa Score: nan | Estimated time: 45.34
Train loss on 25 batch: 0.041448
Train loss on 50 batch: 0.057249
Train loss on 75 batch: 0.064031
Train loss on 100 batch: 0.032937
Train loss on 125 batch: 0.043046
Train loss on 150 batch: 0.062831
Train loss on 175 batch: 0.044508
Train loss on 200 batch: 0.037121
Train loss on 225 batch: 0.031238
Train loss on 250 batch: 0.022990
Train loss on 275 batch: 0.036682
Train loss on 300 batch: 0.041427
Train loss on 325 batch: 0.044961
Train loss on 350 batch: 0.040596
: Epoch: 50 | Training Loss: 0.042933 | Val. Loss: 0.319356 | Val. Kappa Score: nan | Estimated time: 44.45
Train loss on 25 batch: 0.072444
Train loss on 50 batch: 0.037663
Train loss on 75 batch: 0.036377
Train loss on 100 batch: 0.027401
Train loss on 125 batch: 0.025964
Train loss on 150 batch: 0.032718
Train loss on 175 batch: 0.030425
Train loss on 200 batch: 0.023431
Train loss on 225 batch: 0.034299
Train loss on 250 batch: 0.021138
Train loss on 275 batch: 0.025591
Train loss on 300 batch: 0.030005
Train loss on 325 batch: 0.055065
Train loss on 350 batch: 0.039560
: Epoch: 51 | Training Loss: 0.035149 | Val. Loss: 0.307656 | Val. Kappa Score: nan | Estimated time: 45.71
Train loss on 25 batch: 0.024403
Train loss on 50 batch: 0.033022
Train loss on 75 batch: 0.022759
Train loss on 100 batch: 0.023774
Train loss on 125 batch: 0.026253
Train loss on 150 batch: 0.042358
Train loss on 175 batch: 0.032330
Train loss on 200 batch: 0.030756
Train loss on 225 batch: 0.031234
Train loss on 250 batch: 0.033905
Train loss on 275 batch: 0.046077
Train loss on 300 batch: 0.044675
Train loss on 325 batch: 0.035032
Train loss on 350 batch: 0.058270
: Epoch: 52 | Training Loss: 0.034632 | Val. Loss: 0.321032 | Val. Kappa Score: nan | Estimated time: 45.52
Train loss on 25 batch: 0.016990
Train loss on 50 batch: 0.015059
Train loss on 75 batch: 0.032740
Train loss on 100 batch: 0.029636
Train loss on 125 batch: 0.060536
Train loss on 150 batch: 0.026771
Train loss on 175 batch: 0.037650
Train loss on 200 batch: 0.024148
Train loss on 225 batch: 0.020852
Train loss on 250 batch: 0.036123
Train loss on 275 batch: 0.036112
Train loss on 300 batch: 0.032203
Train loss on 325 batch: 0.033057
Train loss on 350 batch: 0.028721
: Epoch: 53 | Training Loss: 0.030757 | Val. Loss: 0.310227 | Val. Kappa Score: nan | Estimated time: 46.11
Train loss on 25 batch: 0.051389
Train loss on 50 batch: 0.023924
Train loss on 75 batch: 0.034314
Train loss on 100 batch: 0.046643
Train loss on 125 batch: 0.032898
Train loss on 150 batch: 0.039611
Train loss on 175 batch: 0.036155
Train loss on 200 batch: 0.030595
Train loss on 225 batch: 0.029521
Train loss on 250 batch: 0.020376
Train loss on 275 batch: 0.037857
Train loss on 300 batch: 0.021462
Train loss on 325 batch: 0.028776
Train loss on 350 batch: 0.021952
best-train-loss: 0.032534
best-valid-loss: 0.287978
best-kappa: nan
: Epoch: 54 | Training Loss: 0.032534 | Val. Loss: 0.287978 | Val. Kappa Score: nan | Estimated time: 45.71
Train loss on 25 batch: 0.040988
Train loss on 50 batch: 0.020777
Train loss on 75 batch: 0.042633
Train loss on 100 batch: 0.024993
Train loss on 125 batch: 0.023718
Train loss on 150 batch: 0.015387
Train loss on 175 batch: 0.022167
Train loss on 200 batch: 0.037576
Train loss on 225 batch: 0.024793
Train loss on 250 batch: 0.026040
Train loss on 275 batch: 0.028220
Train loss on 300 batch: 0.034465
Train loss on 325 batch: 0.052036
Train loss on 350 batch: 0.039320
: Epoch: 55 | Training Loss: 0.030937 | Val. Loss: 0.318415 | Val. Kappa Score: nan | Estimated time: 44.53
Train loss on 25 batch: 0.041513
Train loss on 50 batch: 0.034252
Train loss on 75 batch: 0.037450
Train loss on 100 batch: 0.021608
Train loss on 125 batch: 0.028410
Train loss on 150 batch: 0.038924
Train loss on 175 batch: 0.029294
Train loss on 200 batch: 0.035298
Train loss on 225 batch: 0.017025
Train loss on 250 batch: 0.023498
Train loss on 275 batch: 0.019139
Train loss on 300 batch: 0.031064
Train loss on 325 batch: 0.048802
Train loss on 350 batch: 0.043458
: Epoch: 56 | Training Loss: 0.032124 | Val. Loss: 0.331902 | Val. Kappa Score: nan | Estimated time: 45.45
Train loss on 25 batch: 0.048561
Train loss on 50 batch: 0.022047
Train loss on 75 batch: 0.032029
Train loss on 100 batch: 0.020047
Train loss on 125 batch: 0.017147
Train loss on 150 batch: 0.048339
Train loss on 175 batch: 0.014676
Train loss on 200 batch: 0.018784
Train loss on 225 batch: 0.037241
Train loss on 250 batch: 0.027698
Train loss on 275 batch: 0.035967
Train loss on 300 batch: 0.038203
Train loss on 325 batch: 0.032783
Train loss on 350 batch: 0.024514
: Epoch: 57 | Training Loss: 0.029860 | Val. Loss: 0.336385 | Val. Kappa Score: nan | Estimated time: 45.66
Train loss on 25 batch: 0.031382
Train loss on 50 batch: 0.031623
Train loss on 75 batch: 0.046653
Train loss on 100 batch: 0.025157
Train loss on 125 batch: 0.035251
Train loss on 150 batch: 0.029377
Train loss on 175 batch: 0.053049
Train loss on 200 batch: 0.041906
Train loss on 225 batch: 0.035899
Train loss on 250 batch: 0.079098
Train loss on 275 batch: 0.033587
Train loss on 300 batch: 0.036635
Train loss on 325 batch: 0.039774
Train loss on 350 batch: 0.029621
: Epoch: 58 | Training Loss: 0.039215 | Val. Loss: 0.374511 | Val. Kappa Score: nan | Estimated time: 45.14
Train loss on 25 batch: 0.040213
Train loss on 50 batch: 0.043280
Train loss on 75 batch: 0.049756
Train loss on 100 batch: 0.042484
Train loss on 125 batch: 0.042949
Train loss on 150 batch: 0.055290
Train loss on 175 batch: 0.025494
Train loss on 200 batch: 0.035381
Train loss on 225 batch: 0.044676
Train loss on 250 batch: 0.020566
Train loss on 275 batch: 0.064201
Train loss on 300 batch: 0.039460
Train loss on 325 batch: 0.019702
Train loss on 350 batch: 0.030849
: Epoch: 59 | Training Loss: 0.039593 | Val. Loss: 0.310573 | Val. Kappa Score: nan | Estimated time: 44.84
Train loss on 25 batch: 0.037711
Train loss on 50 batch: 0.041124
Train loss on 75 batch: 0.055839
Train loss on 100 batch: 0.043820
Train loss on 125 batch: 0.037547
Train loss on 150 batch: 0.045177
Train loss on 175 batch: 0.026141
Train loss on 200 batch: 0.021115
Train loss on 225 batch: 0.039920
Train loss on 250 batch: 0.022562
Train loss on 275 batch: 0.052160
Train loss on 300 batch: 0.067318
Train loss on 325 batch: 0.051357
Train loss on 350 batch: 0.035736
: Epoch: 60 | Training Loss: 0.041252 | Val. Loss: 0.348861 | Val. Kappa Score: nan | Estimated time: 45.11
Train loss on 25 batch: 0.026928
Train loss on 50 batch: 0.040217
Train loss on 75 batch: 0.023210
Train loss on 100 batch: 0.039350
Train loss on 125 batch: 0.037745
Train loss on 150 batch: 0.038872
Train loss on 175 batch: 0.040945
Train loss on 200 batch: 0.041104
Train loss on 225 batch: 0.038011
Train loss on 250 batch: 0.022610
Train loss on 275 batch: 0.036233
Train loss on 300 batch: 0.068742
Train loss on 325 batch: 0.034349
Train loss on 350 batch: 0.035453
: Epoch: 61 | Training Loss: 0.037412 | Val. Loss: 0.335915 | Val. Kappa Score: nan | Estimated time: 45.77
Train loss on 25 batch: 0.054712
Train loss on 50 batch: 0.047457
Train loss on 75 batch: 0.051929
Train loss on 100 batch: 0.040046
Train loss on 125 batch: 0.044657
Train loss on 150 batch: 0.037161
Train loss on 175 batch: 0.032527
Train loss on 200 batch: 0.026941
Train loss on 225 batch: 0.034565
Train loss on 250 batch: 0.032268
Train loss on 275 batch: 0.035153
Train loss on 300 batch: 0.033862
Train loss on 325 batch: 0.028533
Train loss on 350 batch: 0.031086
: Epoch: 62 | Training Loss: 0.037921 | Val. Loss: 0.350748 | Val. Kappa Score: nan | Estimated time: 44.70
Train loss on 25 batch: 0.044879
Train loss on 50 batch: 0.051977
Train loss on 75 batch: 0.042685
Train loss on 100 batch: 0.041392
Train loss on 125 batch: 0.040813
Train loss on 150 batch: 0.078782
Train loss on 175 batch: 0.031041
Train loss on 200 batch: 0.040871
Train loss on 225 batch: 0.058344
Train loss on 250 batch: 0.037414
Train loss on 275 batch: 0.058072
Train loss on 300 batch: 0.032015
Train loss on 325 batch: 0.030468
Train loss on 350 batch: 0.024619
: Epoch: 63 | Training Loss: 0.043812 | Val. Loss: 0.329550 | Val. Kappa Score: nan | Estimated time: 45.60
Train loss on 25 batch: 0.048727
Train loss on 50 batch: 0.072140
Train loss on 75 batch: 0.042073
Train loss on 100 batch: 0.029232
Train loss on 125 batch: 0.058040
Train loss on 150 batch: 0.036945
Train loss on 175 batch: 0.052308
Train loss on 200 batch: 0.032426
Train loss on 225 batch: 0.052790
Train loss on 250 batch: 0.034946
Train loss on 275 batch: 0.028823
Train loss on 300 batch: 0.025934
Train loss on 325 batch: 0.027637
Train loss on 350 batch: 0.025366
: Epoch: 64 | Training Loss: 0.040528 | Val. Loss: 0.314244 | Val. Kappa Score: nan | Estimated time: 44.66
Train loss on 25 batch: 0.029009
Train loss on 50 batch: 0.022128
Train loss on 75 batch: 0.053676
Train loss on 100 batch: 0.027221
Train loss on 125 batch: 0.021948
Train loss on 150 batch: 0.015746
Train loss on 175 batch: 0.024132
Train loss on 200 batch: 0.020033
Train loss on 225 batch: 0.020875
Train loss on 250 batch: 0.023455
Train loss on 275 batch: 0.027176
Train loss on 300 batch: 0.047665
Train loss on 325 batch: 0.023358
Train loss on 350 batch: 0.033988
: Epoch: 65 | Training Loss: 0.027886 | Val. Loss: 0.304584 | Val. Kappa Score: nan | Estimated time: 45.35
Train loss on 25 batch: 0.069040
Train loss on 50 batch: 0.057904
Train loss on 75 batch: 0.050142
Train loss on 100 batch: 0.060796
Train loss on 125 batch: 0.031581
Train loss on 150 batch: 0.036316
Train loss on 175 batch: 0.029622
Train loss on 200 batch: 0.029583
Train loss on 225 batch: 0.025978
Train loss on 250 batch: 0.039249
Train loss on 275 batch: 0.036596
Train loss on 300 batch: 0.030429
Train loss on 325 batch: 0.024884
Train loss on 350 batch: 0.042201
: Epoch: 66 | Training Loss: 0.040309 | Val. Loss: 0.311282 | Val. Kappa Score: nan | Estimated time: 45.73
Train loss on 25 batch: 0.020393
Train loss on 50 batch: 0.026179
Train loss on 75 batch: 0.020637
Train loss on 100 batch: 0.020875
Train loss on 125 batch: 0.026525
Train loss on 150 batch: 0.039340
Train loss on 175 batch: 0.020560
Train loss on 200 batch: 0.036321
Train loss on 225 batch: 0.021705
Train loss on 250 batch: 0.040793
Train loss on 275 batch: 0.032464
Train loss on 300 batch: 0.042750
Train loss on 325 batch: 0.024409
Train loss on 350 batch: 0.022664
: Epoch: 67 | Training Loss: 0.028258 | Val. Loss: 0.328368 | Val. Kappa Score: nan | Estimated time: 45.09
Train loss on 25 batch: 0.060076
Train loss on 50 batch: 0.024861
Train loss on 75 batch: 0.034383
Train loss on 100 batch: 0.027245
Train loss on 125 batch: 0.011184
Train loss on 150 batch: 0.031167
Train loss on 175 batch: 0.025761
Train loss on 200 batch: 0.033097
Train loss on 225 batch: 0.015511
Train loss on 250 batch: 0.042710
Train loss on 275 batch: 0.028594
Train loss on 300 batch: 0.037172
Train loss on 325 batch: 0.021195
Train loss on 350 batch: 0.029193
: Epoch: 68 | Training Loss: 0.030153 | Val. Loss: 0.300084 | Val. Kappa Score: nan | Estimated time: 45.30
Train loss on 25 batch: 0.033703
Train loss on 50 batch: 0.024278
Train loss on 75 batch: 0.025744
Train loss on 100 batch: 0.023280
Train loss on 125 batch: 0.025654
Train loss on 150 batch: 0.019314
Train loss on 175 batch: 0.018206
Train loss on 200 batch: 0.022297
Train loss on 225 batch: 0.013955
Train loss on 250 batch: 0.040990
Train loss on 275 batch: 0.040517
Train loss on 300 batch: 0.029551
Train loss on 325 batch: 0.027480
Train loss on 350 batch: 0.045286
: Epoch: 69 | Training Loss: 0.027875 | Val. Loss: 0.327140 | Val. Kappa Score: nan | Estimated time: 44.71
time_estimated: 3120.40
n-epochs: 69
time_estimated: 3120.40
----------------------------------------

Experiment N: 9: 
date: 2019.08.06 11:45:38
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.153761
Train loss on 50 batch: 0.749919
Train loss on 75 batch: 0.938109
Train loss on 100 batch: 0.554084
Train loss on 125 batch: 0.584142
Train loss on 150 batch: 0.557860
Train loss on 175 batch: 0.432875
best-train-loss: 0.710107
best-valid-loss: 0.415079
best-kappa: 0.5693
: Epoch: 1 | Training Loss: 0.710107 | Val. Loss: 0.415079 | Val. Kappa Score: 0.5693 | Estimated time: 35.00
Train loss on 25 batch: 0.432124
Train loss on 50 batch: 0.451882
Train loss on 75 batch: 0.458764
Train loss on 100 batch: 0.317839
Train loss on 125 batch: 0.437146
Train loss on 150 batch: 0.345147
Train loss on 175 batch: 0.374919
: Epoch: 2 | Training Loss: 0.402546 | Val. Loss: 0.416028 | Val. Kappa Score: 0.6069 | Estimated time: 35.41
Train loss on 25 batch: 0.396025
Train loss on 50 batch: 0.350977
Train loss on 75 batch: 0.361734
Train loss on 100 batch: 0.305577
Train loss on 125 batch: 0.348226
Train loss on 150 batch: 0.350682
Train loss on 175 batch: 0.357888
: Epoch: 3 | Training Loss: 0.353015 | Val. Loss: 0.496864 | Val. Kappa Score: 0.6079 | Estimated time: 36.27
Train loss on 25 batch: 0.205608
Train loss on 50 batch: 0.243111
Train loss on 75 batch: 0.224250
Train loss on 100 batch: 0.250878
Train loss on 125 batch: 0.308544
Train loss on 150 batch: 0.267800
Train loss on 175 batch: 0.234758
: Epoch: 4 | Training Loss: 0.247850 | Val. Loss: 0.427010 | Val. Kappa Score: 0.5972 | Estimated time: 35.34
Train loss on 25 batch: 0.275730
Train loss on 50 batch: 0.227222
Train loss on 75 batch: 0.199459
Train loss on 100 batch: 0.214846
Train loss on 125 batch: 0.281901
Train loss on 150 batch: 0.262991
Train loss on 175 batch: 0.239612
best-train-loss: 0.243109
best-valid-loss: 0.318114
best-kappa: 0.6065
: Epoch: 5 | Training Loss: 0.243109 | Val. Loss: 0.318114 | Val. Kappa Score: 0.6065 | Estimated time: 35.80
Train loss on 25 batch: 0.188516
Train loss on 50 batch: 0.231809
Train loss on 75 batch: 0.240524
Train loss on 100 batch: 0.202575
Train loss on 125 batch: 0.196055
Train loss on 150 batch: 0.214119
Train loss on 175 batch: 0.200191
best-train-loss: 0.210541
best-valid-loss: 0.305145
best-kappa: 0.6150
: Epoch: 6 | Training Loss: 0.210541 | Val. Loss: 0.305145 | Val. Kappa Score: 0.6150 | Estimated time: 35.64
Train loss on 25 batch: 0.162370
Train loss on 50 batch: 0.177677
Train loss on 75 batch: 0.177760
Train loss on 100 batch: 0.133632
Train loss on 125 batch: 0.150009
Train loss on 150 batch: 0.138575
Train loss on 175 batch: 0.199763
: Epoch: 7 | Training Loss: 0.162826 | Val. Loss: 0.360637 | Val. Kappa Score: 0.6169 | Estimated time: 35.34
Train loss on 25 batch: 0.149296
Train loss on 50 batch: 0.149335
Train loss on 75 batch: 0.109105
Train loss on 100 batch: 0.121515
Train loss on 125 batch: 0.156435
Train loss on 150 batch: 0.123248
Train loss on 175 batch: 0.166406
: Epoch: 8 | Training Loss: 0.139334 | Val. Loss: 0.533941 | Val. Kappa Score: 0.6048 | Estimated time: 35.54
Train loss on 25 batch: 0.665585
Train loss on 50 batch: 0.243924
Train loss on 75 batch: 0.238937
Train loss on 100 batch: 0.188457
Train loss on 125 batch: 0.218501
Train loss on 150 batch: 0.171878
Train loss on 175 batch: 0.160734
: Epoch: 9 | Training Loss: 0.269717 | Val. Loss: 0.326797 | Val. Kappa Score: 0.6080 | Estimated time: 35.40
Train loss on 25 batch: 0.293930
Train loss on 50 batch: 0.150362
Train loss on 75 batch: 0.210247
Train loss on 100 batch: 0.122190
Train loss on 125 batch: 0.140477
Train loss on 150 batch: 0.184859
Train loss on 175 batch: 0.160641
: Epoch: 10 | Training Loss: 0.180387 | Val. Loss: 0.356206 | Val. Kappa Score: 0.6087 | Estimated time: 35.89
Train loss on 25 batch: 0.118970
Train loss on 50 batch: 0.106513
Train loss on 75 batch: 0.151296
Train loss on 100 batch: 0.155173
Train loss on 125 batch: 0.141119
Train loss on 150 batch: 0.112878
Train loss on 175 batch: 0.114937
: Epoch: 11 | Training Loss: 0.128698 | Val. Loss: 0.337269 | Val. Kappa Score: 0.6137 | Estimated time: 34.65
Train loss on 25 batch: 0.135967
Train loss on 50 batch: 0.122012
Train loss on 75 batch: 0.109682
Train loss on 100 batch: 0.088682
Train loss on 125 batch: 0.101572
Train loss on 150 batch: 0.080561
Train loss on 175 batch: 0.108836
: Epoch: 12 | Training Loss: 0.106759 | Val. Loss: 0.383214 | Val. Kappa Score: 0.6131 | Estimated time: 35.61
Train loss on 25 batch: 0.172465
Train loss on 50 batch: 0.114083
Train loss on 75 batch: 0.135754
Train loss on 100 batch: 0.082428
Train loss on 125 batch: 0.138482
Train loss on 150 batch: 0.119457
Train loss on 175 batch: 0.117019
: Epoch: 13 | Training Loss: 0.125670 | Val. Loss: 0.391584 | Val. Kappa Score: 0.6121 | Estimated time: 36.02
Train loss on 25 batch: 0.244583
Train loss on 50 batch: 0.148296
Train loss on 75 batch: 0.167645
Train loss on 100 batch: 0.142438
Train loss on 125 batch: 0.117431
Train loss on 150 batch: 0.104266
Train loss on 175 batch: 0.080956
: Epoch: 14 | Training Loss: 0.143659 | Val. Loss: 0.367049 | Val. Kappa Score: 0.6130 | Estimated time: 36.03
Train loss on 25 batch: 0.198487
Train loss on 50 batch: 0.159444
Train loss on 75 batch: 0.133859
Train loss on 100 batch: 0.123850
Train loss on 125 batch: 0.133098
Train loss on 150 batch: 0.088031
Train loss on 175 batch: 0.104606
: Epoch: 15 | Training Loss: 0.134482 | Val. Loss: 0.314976 | Val. Kappa Score: 0.6159 | Estimated time: 35.24
Train loss on 25 batch: 0.085327
Train loss on 50 batch: 0.078216
Train loss on 75 batch: 0.090655
Train loss on 100 batch: 0.087444
Train loss on 125 batch: 0.078590
Train loss on 150 batch: 0.072386
Train loss on 175 batch: 0.067734
: Epoch: 16 | Training Loss: 0.080050 | Val. Loss: 0.346387 | Val. Kappa Score: 0.6172 | Estimated time: 35.73
Train loss on 25 batch: 0.220394
Train loss on 50 batch: 0.115610
Train loss on 75 batch: 0.084236
Train loss on 100 batch: 0.090879
Train loss on 125 batch: 0.080051
Train loss on 150 batch: 0.108201
Train loss on 175 batch: 0.095173
: Epoch: 17 | Training Loss: 0.113507 | Val. Loss: 0.332292 | Val. Kappa Score: 0.6187 | Estimated time: 35.16
Train loss on 25 batch: 0.093133
Train loss on 50 batch: 0.060556
Train loss on 75 batch: 0.077781
Train loss on 100 batch: 0.056059
Train loss on 125 batch: 0.060864
Train loss on 150 batch: 0.079450
Train loss on 175 batch: 0.064816
: Epoch: 18 | Training Loss: 0.070380 | Val. Loss: 0.311583 | Val. Kappa Score: 0.6191 | Estimated time: 34.88
Train loss on 25 batch: 0.136519
Train loss on 50 batch: 0.098654
Train loss on 75 batch: 0.125309
Train loss on 100 batch: 0.105352
Train loss on 125 batch: 0.138070
Train loss on 150 batch: 0.099666
Train loss on 175 batch: 0.121642
: Epoch: 19 | Training Loss: 0.117887 | Val. Loss: 0.340958 | Val. Kappa Score: 0.6197 | Estimated time: 35.72
Train loss on 25 batch: 0.089101
Train loss on 50 batch: 0.083971
Train loss on 75 batch: 0.120582
Train loss on 100 batch: 0.069970
Train loss on 125 batch: 0.075984
Train loss on 150 batch: 0.052581
Train loss on 175 batch: 0.060597
: Epoch: 20 | Training Loss: 0.078969 | Val. Loss: 0.320763 | Val. Kappa Score: 0.6199 | Estimated time: 35.37
Train loss on 25 batch: 0.057267
Train loss on 50 batch: 0.045239
Train loss on 75 batch: 0.052007
Train loss on 100 batch: 0.056901
Train loss on 125 batch: 0.063293
Train loss on 150 batch: 0.069026
Train loss on 175 batch: 0.051485
best-train-loss: 0.056460
best-valid-loss: 0.302047
best-kappa: 0.6217
: Epoch: 21 | Training Loss: 0.056460 | Val. Loss: 0.302047 | Val. Kappa Score: 0.6217 | Estimated time: 36.02
Train loss on 25 batch: 0.057102
Train loss on 50 batch: 0.077303
Train loss on 75 batch: 0.057051
Train loss on 100 batch: 0.059751
Train loss on 125 batch: 0.066082
Train loss on 150 batch: 0.061116
Train loss on 175 batch: 0.061255
: Epoch: 22 | Training Loss: 0.062809 | Val. Loss: 0.309244 | Val. Kappa Score: 0.6226 | Estimated time: 35.91
Train loss on 25 batch: 0.041579
Train loss on 50 batch: 0.068729
Train loss on 75 batch: 0.051927
Train loss on 100 batch: 0.050831
Train loss on 125 batch: 0.032161
Train loss on 150 batch: 0.039099
Train loss on 175 batch: 0.039341
best-train-loss: 0.046238
best-valid-loss: 0.291257
best-kappa: 0.6244
: Epoch: 23 | Training Loss: 0.046238 | Val. Loss: 0.291257 | Val. Kappa Score: 0.6244 | Estimated time: 35.02
Train loss on 25 batch: 0.039427
Train loss on 50 batch: 0.049815
Train loss on 75 batch: 0.075114
Train loss on 100 batch: 0.045595
Train loss on 125 batch: 0.057637
Train loss on 150 batch: 0.058516
Train loss on 175 batch: 0.044604
: Epoch: 24 | Training Loss: 0.052958 | Val. Loss: 0.302477 | Val. Kappa Score: 0.6258 | Estimated time: 35.09
Train loss on 25 batch: 0.031084
Train loss on 50 batch: 0.031812
Train loss on 75 batch: 0.035755
Train loss on 100 batch: 0.041160
Train loss on 125 batch: 0.047458
Train loss on 150 batch: 0.051569
Train loss on 175 batch: 0.061864
: Epoch: 25 | Training Loss: 0.042957 | Val. Loss: 0.326407 | Val. Kappa Score: 0.6267 | Estimated time: 35.51
Train loss on 25 batch: 0.044899
Train loss on 50 batch: 0.060734
Train loss on 75 batch: 0.039139
Train loss on 100 batch: 0.050445
Train loss on 125 batch: 0.059985
Train loss on 150 batch: 0.053765
Train loss on 175 batch: 0.044869
: Epoch: 26 | Training Loss: 0.050548 | Val. Loss: 0.367792 | Val. Kappa Score: 0.6265 | Estimated time: 35.74
Train loss on 25 batch: 0.217473
Train loss on 50 batch: 0.122355
Train loss on 75 batch: 0.083997
Train loss on 100 batch: 0.058970
Train loss on 125 batch: 0.050502
Train loss on 150 batch: 0.071868
Train loss on 175 batch: 0.090037
: Epoch: 27 | Training Loss: 0.099315 | Val. Loss: 0.318609 | Val. Kappa Score: 0.6278 | Estimated time: 35.31
Train loss on 25 batch: 0.074232
Train loss on 50 batch: 0.066000
Train loss on 75 batch: 0.063816
Train loss on 100 batch: 0.056238
Train loss on 125 batch: 0.066477
Train loss on 150 batch: 0.072317
Train loss on 175 batch: 0.044580
: Epoch: 28 | Training Loss: 0.063380 | Val. Loss: 0.358136 | Val. Kappa Score: 0.6283 | Estimated time: 35.54
Train loss on 25 batch: 0.065892
Train loss on 50 batch: 0.061304
Train loss on 75 batch: 0.068733
Train loss on 100 batch: 0.041506
Train loss on 125 batch: 0.053975
Train loss on 150 batch: 0.065479
Train loss on 175 batch: 0.071152
: Epoch: 29 | Training Loss: 0.061149 | Val. Loss: 0.325448 | Val. Kappa Score: 0.6280 | Estimated time: 35.52
Train loss on 25 batch: 0.113177
Train loss on 50 batch: 0.111619
Train loss on 75 batch: 0.089581
Train loss on 100 batch: 0.077386
Train loss on 125 batch: 0.054269
Train loss on 150 batch: 0.072951
Train loss on 175 batch: 0.082648
: Epoch: 30 | Training Loss: 0.085947 | Val. Loss: 0.416864 | Val. Kappa Score: 0.6228 | Estimated time: 36.22
Train loss on 25 batch: 0.214079
Train loss on 50 batch: 0.187001
Train loss on 75 batch: 0.122971
Train loss on 100 batch: 0.217342
Train loss on 125 batch: 0.201861
Train loss on 150 batch: 0.114364
Train loss on 175 batch: 0.103888
: Epoch: 31 | Training Loss: 0.165929 | Val. Loss: 0.385764 | Val. Kappa Score: 0.6218 | Estimated time: 35.83
Train loss on 25 batch: 0.113714
Train loss on 50 batch: 0.115188
Train loss on 75 batch: 0.128535
Train loss on 100 batch: 0.114712
Train loss on 125 batch: 0.091578
Train loss on 150 batch: 0.085755
Train loss on 175 batch: 0.058223
: Epoch: 32 | Training Loss: 0.101101 | Val. Loss: 0.328080 | Val. Kappa Score: 0.6225 | Estimated time: 35.67
Train loss on 25 batch: 0.136847
Train loss on 50 batch: 0.090641
Train loss on 75 batch: 0.052704
Train loss on 100 batch: 0.052499
Train loss on 125 batch: 0.061189
Train loss on 150 batch: 0.080676
Train loss on 175 batch: 0.067980
: Epoch: 33 | Training Loss: 0.077505 | Val. Loss: 0.315868 | Val. Kappa Score: 0.6228 | Estimated time: 35.70
Train loss on 25 batch: 0.095725
Train loss on 50 batch: 0.094161
Train loss on 75 batch: 0.076229
Train loss on 100 batch: 0.065837
Train loss on 125 batch: 0.067438
Train loss on 150 batch: 0.076329
Train loss on 175 batch: 0.078853
: Epoch: 34 | Training Loss: 0.079225 | Val. Loss: 0.331384 | Val. Kappa Score: 0.6235 | Estimated time: 35.47
Train loss on 25 batch: 0.112788
Train loss on 50 batch: 0.078366
Train loss on 75 batch: 0.067708
Train loss on 100 batch: 0.076424
Train loss on 125 batch: 0.113226
Train loss on 150 batch: 0.058997
Train loss on 175 batch: 0.066868
: Epoch: 35 | Training Loss: 0.082054 | Val. Loss: 0.311281 | Val. Kappa Score: 0.6244 | Estimated time: 35.51
Train loss on 25 batch: 0.096134
Train loss on 50 batch: 0.058194
Train loss on 75 batch: 0.077108
Train loss on 100 batch: 0.080858
Train loss on 125 batch: 0.064428
Train loss on 150 batch: 0.048974
Train loss on 175 batch: 0.061543
: Epoch: 36 | Training Loss: 0.069606 | Val. Loss: 0.332829 | Val. Kappa Score: 0.6248 | Estimated time: 35.58
Train loss on 25 batch: 0.066166
Train loss on 50 batch: 0.049423
Train loss on 75 batch: 0.059889
Train loss on 100 batch: 0.042575
Train loss on 125 batch: 0.042510
Train loss on 150 batch: 0.045765
Train loss on 175 batch: 0.045731
: Epoch: 37 | Training Loss: 0.050294 | Val. Loss: 0.332218 | Val. Kappa Score: 0.6250 | Estimated time: 35.51
Train loss on 25 batch: 0.041070
Train loss on 50 batch: 0.040031
Train loss on 75 batch: 0.046452
Train loss on 100 batch: 0.034439
Train loss on 125 batch: 0.032960
Train loss on 150 batch: 0.039135
Train loss on 175 batch: 0.049344
: Epoch: 38 | Training Loss: 0.040490 | Val. Loss: 0.317248 | Val. Kappa Score: 0.6261 | Estimated time: 35.36
time_estimated: 1351.18
n-epochs: 38
time_estimated: 1351.18
----------------------------------------

Experiment N: 10: 
date: 2019.08.06 12:08:10
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.033035
Train loss on 50 batch: 0.672556
Train loss on 75 batch: 0.479738
best-train-loss: 0.728443
best-valid-loss: 0.447010
best-kappa: 0.5842
: Epoch: 1 | Training Loss: 0.728443 | Val. Loss: 0.447010 | Val. Kappa Score: 0.5842 | Estimated time: 32.37
Train loss on 25 batch: 0.419599
Train loss on 50 batch: 0.379510
Train loss on 75 batch: 0.365883
best-train-loss: 0.388331
best-valid-loss: 0.338084
best-kappa: 0.6112
: Epoch: 2 | Training Loss: 0.388331 | Val. Loss: 0.338084 | Val. Kappa Score: 0.6112 | Estimated time: 33.26
Train loss on 25 batch: 0.305390
Train loss on 50 batch: 0.245509
Train loss on 75 batch: 0.272472
: Epoch: 3 | Training Loss: 0.274457 | Val. Loss: 0.575731 | Val. Kappa Score: 0.5819 | Estimated time: 32.11
Train loss on 25 batch: 0.200820
Train loss on 50 batch: 0.223065
Train loss on 75 batch: 0.268292
: Epoch: 4 | Training Loss: 0.230726 | Val. Loss: 0.388998 | Val. Kappa Score: 0.5494 | Estimated time: 32.07
Train loss on 25 batch: 0.175121
Train loss on 50 batch: 0.176872
Train loss on 75 batch: 0.239010
best-train-loss: 0.197001
best-valid-loss: 0.312177
best-kappa: 0.5702
: Epoch: 5 | Training Loss: 0.197001 | Val. Loss: 0.312177 | Val. Kappa Score: 0.5702 | Estimated time: 33.36
Train loss on 25 batch: 0.157510
Train loss on 50 batch: 0.164903
Train loss on 75 batch: 0.137788
best-train-loss: 0.153400
best-valid-loss: 0.299193
best-kappa: 0.5889
: Epoch: 6 | Training Loss: 0.153400 | Val. Loss: 0.299193 | Val. Kappa Score: 0.5889 | Estimated time: 31.87
Train loss on 25 batch: 0.132574
Train loss on 50 batch: 0.151736
Train loss on 75 batch: 0.133746
: Epoch: 7 | Training Loss: 0.139352 | Val. Loss: 0.722348 | Val. Kappa Score: 0.5511 | Estimated time: 32.09
Train loss on 25 batch: 0.148413
Train loss on 50 batch: 0.108070
Train loss on 75 batch: 0.122313
: Epoch: 8 | Training Loss: 0.126265 | Val. Loss: 0.350582 | Val. Kappa Score: 0.5612 | Estimated time: 32.22
Train loss on 25 batch: 0.189330
Train loss on 50 batch: 0.098070
Train loss on 75 batch: 0.098847
: Epoch: 9 | Training Loss: 0.128749 | Val. Loss: 0.327029 | Val. Kappa Score: 0.5706 | Estimated time: 32.74
Train loss on 25 batch: 0.065342
Train loss on 50 batch: 0.091017
Train loss on 75 batch: 0.068255
: Epoch: 10 | Training Loss: 0.074871 | Val. Loss: 0.312403 | Val. Kappa Score: 0.5807 | Estimated time: 33.35
Train loss on 25 batch: 0.055548
Train loss on 50 batch: 0.070041
Train loss on 75 batch: 0.086784
: Epoch: 11 | Training Loss: 0.070791 | Val. Loss: 0.326632 | Val. Kappa Score: 0.5871 | Estimated time: 32.39
Train loss on 25 batch: 0.124373
Train loss on 50 batch: 0.086260
Train loss on 75 batch: 0.055085
best-train-loss: 0.088573
best-valid-loss: 0.296770
best-kappa: 0.5937
: Epoch: 12 | Training Loss: 0.088573 | Val. Loss: 0.296770 | Val. Kappa Score: 0.5937 | Estimated time: 32.29
Train loss on 25 batch: 0.048577
Train loss on 50 batch: 0.044659
Train loss on 75 batch: 0.068535
: Epoch: 13 | Training Loss: 0.053924 | Val. Loss: 0.313065 | Val. Kappa Score: 0.5998 | Estimated time: 32.18
Train loss on 25 batch: 0.046295
Train loss on 50 batch: 0.049788
Train loss on 75 batch: 0.045774
: Epoch: 14 | Training Loss: 0.047286 | Val. Loss: 0.304482 | Val. Kappa Score: 0.6049 | Estimated time: 33.41
Train loss on 25 batch: 0.036474
Train loss on 50 batch: 0.059669
Train loss on 75 batch: 0.069062
best-train-loss: 0.055068
best-valid-loss: 0.295916
best-kappa: 0.6109
: Epoch: 15 | Training Loss: 0.055068 | Val. Loss: 0.295916 | Val. Kappa Score: 0.6109 | Estimated time: 32.67
Train loss on 25 batch: 0.045546
Train loss on 50 batch: 0.054214
Train loss on 75 batch: 0.041977
best-train-loss: 0.047246
best-valid-loss: 0.280199
best-kappa: 0.6161
: Epoch: 16 | Training Loss: 0.047246 | Val. Loss: 0.280199 | Val. Kappa Score: 0.6161 | Estimated time: 33.36
Train loss on 25 batch: 0.042283
Train loss on 50 batch: 0.034154
Train loss on 75 batch: 0.040119
: Epoch: 17 | Training Loss: 0.038852 | Val. Loss: 0.292898 | Val. Kappa Score: 0.6191 | Estimated time: 33.26
Train loss on 25 batch: 0.042683
Train loss on 50 batch: 0.043121
Train loss on 75 batch: 0.039591
: Epoch: 18 | Training Loss: 0.041798 | Val. Loss: 0.301506 | Val. Kappa Score: 0.6225 | Estimated time: 32.68
Train loss on 25 batch: 0.039334
Train loss on 50 batch: 0.040189
Train loss on 75 batch: 0.038095
: Epoch: 19 | Training Loss: 0.039206 | Val. Loss: 0.309924 | Val. Kappa Score: 0.6245 | Estimated time: 32.23
Train loss on 25 batch: 0.033488
Train loss on 50 batch: 0.035980
Train loss on 75 batch: 0.031603
: Epoch: 20 | Training Loss: 0.033690 | Val. Loss: 0.285868 | Val. Kappa Score: 0.6274 | Estimated time: 33.18
Train loss on 25 batch: 0.036671
Train loss on 50 batch: 0.023389
Train loss on 75 batch: 0.043173
: Epoch: 21 | Training Loss: 0.034411 | Val. Loss: 0.301597 | Val. Kappa Score: 0.6297 | Estimated time: 32.62
Train loss on 25 batch: 0.026410
Train loss on 50 batch: 0.033703
Train loss on 75 batch: 0.033768
best-train-loss: 0.031294
best-valid-loss: 0.272691
best-kappa: 0.6325
: Epoch: 22 | Training Loss: 0.031294 | Val. Loss: 0.272691 | Val. Kappa Score: 0.6325 | Estimated time: 32.99
Train loss on 25 batch: 0.028551
Train loss on 50 batch: 0.031791
Train loss on 75 batch: 0.023134
: Epoch: 23 | Training Loss: 0.027825 | Val. Loss: 0.288000 | Val. Kappa Score: 0.6356 | Estimated time: 33.38
Train loss on 25 batch: 0.019495
Train loss on 50 batch: 0.028447
Train loss on 75 batch: 0.028091
: Epoch: 24 | Training Loss: 0.025344 | Val. Loss: 0.276456 | Val. Kappa Score: 0.6380 | Estimated time: 31.98
Train loss on 25 batch: 0.028770
Train loss on 50 batch: 0.028544
Train loss on 75 batch: 0.029283
: Epoch: 25 | Training Loss: 0.028866 | Val. Loss: 0.294930 | Val. Kappa Score: 0.6394 | Estimated time: 33.31
Train loss on 25 batch: 0.032512
Train loss on 50 batch: 0.029502
Train loss on 75 batch: 0.033167
: Epoch: 26 | Training Loss: 0.031727 | Val. Loss: 0.279267 | Val. Kappa Score: 0.6409 | Estimated time: 33.02
Train loss on 25 batch: 0.020894
Train loss on 50 batch: 0.024272
Train loss on 75 batch: 0.046246
: Epoch: 27 | Training Loss: 0.030471 | Val. Loss: 0.285871 | Val. Kappa Score: 0.6422 | Estimated time: 32.57
Train loss on 25 batch: 0.037997
Train loss on 50 batch: 0.030977
Train loss on 75 batch: 0.041188
: Epoch: 28 | Training Loss: 0.036721 | Val. Loss: 0.314161 | Val. Kappa Score: 0.6427 | Estimated time: 32.27
Train loss on 25 batch: 0.047043
Train loss on 50 batch: 0.039702
Train loss on 75 batch: 0.041396
: Epoch: 29 | Training Loss: 0.042714 | Val. Loss: 0.326668 | Val. Kappa Score: 0.6437 | Estimated time: 33.50
Train loss on 25 batch: 0.040231
Train loss on 50 batch: 0.046619
Train loss on 75 batch: 0.046471
: Epoch: 30 | Training Loss: 0.044440 | Val. Loss: 0.315133 | Val. Kappa Score: 0.6442 | Estimated time: 32.26
Train loss on 25 batch: 0.035838
Train loss on 50 batch: 0.043594
Train loss on 75 batch: 0.037239
: Epoch: 31 | Training Loss: 0.038890 | Val. Loss: 0.310364 | Val. Kappa Score: 0.6451 | Estimated time: 33.13
Train loss on 25 batch: 0.036804
Train loss on 50 batch: 0.044202
Train loss on 75 batch: 0.061987
: Epoch: 32 | Training Loss: 0.047665 | Val. Loss: 0.314591 | Val. Kappa Score: 0.6450 | Estimated time: 33.30
Train loss on 25 batch: 0.039351
Train loss on 50 batch: 0.028409
Train loss on 75 batch: 0.046541
: Epoch: 33 | Training Loss: 0.038100 | Val. Loss: 0.305135 | Val. Kappa Score: 0.6462 | Estimated time: 32.56
Train loss on 25 batch: 0.028853
Train loss on 50 batch: 0.030635
Train loss on 75 batch: 0.036170
: Epoch: 34 | Training Loss: 0.031886 | Val. Loss: 0.320649 | Val. Kappa Score: 0.6475 | Estimated time: 32.93
Train loss on 25 batch: 0.037940
Train loss on 50 batch: 0.028545
Train loss on 75 batch: 0.035917
: Epoch: 35 | Training Loss: 0.034134 | Val. Loss: 0.276645 | Val. Kappa Score: 0.6491 | Estimated time: 33.06
Train loss on 25 batch: 0.031873
Train loss on 50 batch: 0.028363
Train loss on 75 batch: 0.032422
: Epoch: 36 | Training Loss: 0.030886 | Val. Loss: 0.282624 | Val. Kappa Score: 0.6503 | Estimated time: 32.65
Train loss on 25 batch: 0.026285
Train loss on 50 batch: 0.044257
Train loss on 75 batch: 0.027041
: Epoch: 37 | Training Loss: 0.032528 | Val. Loss: 0.289733 | Val. Kappa Score: 0.6514 | Estimated time: 32.84
time_estimated: 1212.47
n-epochs: 37
time_estimated: 1212.47
----------------------------------------

Experiment N: 11: 
date: 2019.08.06 12:28:23
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 48
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.814683
Train loss on 50 batch: 0.545827
best-train-loss: 0.680255
best-valid-loss: 0.961047
best-kappa: 0.1495
: Epoch: 1 | Training Loss: 0.680255 | Val. Loss: 0.961047 | Val. Kappa Score: 0.1495 | Estimated time: 34.42
Train loss on 25 batch: 0.375683
Train loss on 50 batch: 0.283472
best-train-loss: 0.329578
best-valid-loss: 0.566058
best-kappa: 0.3051
: Epoch: 2 | Training Loss: 0.329578 | Val. Loss: 0.566058 | Val. Kappa Score: 0.3051 | Estimated time: 34.36
Train loss on 25 batch: 0.335558
Train loss on 50 batch: 0.237242
: Epoch: 3 | Training Loss: 0.286400 | Val. Loss: 0.674728 | Val. Kappa Score: 0.3002 | Estimated time: 34.70
Train loss on 25 batch: 0.220242
Train loss on 50 batch: 0.291579
best-train-loss: 0.255910
best-valid-loss: 0.381877
best-kappa: 0.3752
: Epoch: 4 | Training Loss: 0.255910 | Val. Loss: 0.381877 | Val. Kappa Score: 0.3752 | Estimated time: 34.95
Train loss on 25 batch: 0.232481
Train loss on 50 batch: 0.189156
: Epoch: 5 | Training Loss: 0.210819 | Val. Loss: 0.391257 | Val. Kappa Score: 0.4240 | Estimated time: 34.18
Train loss on 25 batch: 0.162147
Train loss on 50 batch: 0.176025
best-train-loss: 0.169086
best-valid-loss: 0.310336
best-kappa: 0.4614
: Epoch: 6 | Training Loss: 0.169086 | Val. Loss: 0.310336 | Val. Kappa Score: 0.4614 | Estimated time: 33.45
Train loss on 25 batch: 0.133004
Train loss on 50 batch: 0.120451
: Epoch: 7 | Training Loss: 0.126728 | Val. Loss: 0.320477 | Val. Kappa Score: 0.4870 | Estimated time: 33.61
Train loss on 25 batch: 0.181395
Train loss on 50 batch: 0.153069
: Epoch: 8 | Training Loss: 0.167232 | Val. Loss: 0.333334 | Val. Kappa Score: 0.5094 | Estimated time: 35.06
Train loss on 25 batch: 0.221781
Train loss on 50 batch: 0.117031
: Epoch: 9 | Training Loss: 0.169406 | Val. Loss: 0.348678 | Val. Kappa Score: 0.5236 | Estimated time: 34.29
Train loss on 25 batch: 0.209325
Train loss on 50 batch: 0.177079
: Epoch: 10 | Training Loss: 0.193202 | Val. Loss: 0.353613 | Val. Kappa Score: 0.5355 | Estimated time: 33.47
Train loss on 25 batch: 0.165212
Train loss on 50 batch: 0.133111
: Epoch: 11 | Training Loss: 0.149161 | Val. Loss: 0.322855 | Val. Kappa Score: 0.5440 | Estimated time: 33.95
Train loss on 25 batch: 0.146119
Train loss on 50 batch: 0.094677
: Epoch: 12 | Training Loss: 0.120398 | Val. Loss: 0.348022 | Val. Kappa Score: 0.5521 | Estimated time: 34.67
Train loss on 25 batch: 0.358709
Train loss on 50 batch: 0.170103
: Epoch: 13 | Training Loss: 0.264406 | Val. Loss: 0.383327 | Val. Kappa Score: 0.5570 | Estimated time: 33.75
Train loss on 25 batch: 0.266208
Train loss on 50 batch: 0.218869
: Epoch: 14 | Training Loss: 0.242538 | Val. Loss: 0.328686 | Val. Kappa Score: 0.5620 | Estimated time: 33.29
Train loss on 25 batch: 0.159895
Train loss on 50 batch: 0.132347
: Epoch: 15 | Training Loss: 0.146121 | Val. Loss: 0.381858 | Val. Kappa Score: 0.5646 | Estimated time: 32.81
Train loss on 25 batch: 0.151804
Train loss on 50 batch: 0.115051
: Epoch: 16 | Training Loss: 0.133427 | Val. Loss: 0.389338 | Val. Kappa Score: 0.5681 | Estimated time: 34.39
Train loss on 25 batch: 0.262342
Train loss on 50 batch: 0.117857
: Epoch: 17 | Training Loss: 0.190100 | Val. Loss: 0.343622 | Val. Kappa Score: 0.5726 | Estimated time: 33.91
Train loss on 25 batch: 0.103067
Train loss on 50 batch: 0.083471
: Epoch: 18 | Training Loss: 0.093269 | Val. Loss: 0.382722 | Val. Kappa Score: 0.5731 | Estimated time: 32.80
Train loss on 25 batch: 0.135326
Train loss on 50 batch: 0.088237
: Epoch: 19 | Training Loss: 0.111781 | Val. Loss: 0.318856 | Val. Kappa Score: 0.5779 | Estimated time: 35.14
Train loss on 25 batch: 0.132945
Train loss on 50 batch: 0.120687
: Epoch: 20 | Training Loss: 0.126816 | Val. Loss: 0.426375 | Val. Kappa Score: 0.5800 | Estimated time: 34.96
Train loss on 25 batch: 0.155912
Train loss on 50 batch: 0.093277
best-train-loss: 0.124594
best-valid-loss: 0.304088
best-kappa: 0.5833
: Epoch: 21 | Training Loss: 0.124594 | Val. Loss: 0.304088 | Val. Kappa Score: 0.5833 | Estimated time: 32.99
Train loss on 25 batch: 0.089095
Train loss on 50 batch: 0.079115
: Epoch: 22 | Training Loss: 0.084105 | Val. Loss: 0.349368 | Val. Kappa Score: 0.5862 | Estimated time: 33.17
Train loss on 25 batch: 0.141380
Train loss on 50 batch: 0.083265
: Epoch: 23 | Training Loss: 0.112323 | Val. Loss: 0.356668 | Val. Kappa Score: 0.5884 | Estimated time: 34.25
Train loss on 25 batch: 0.047843
Train loss on 50 batch: 0.049722
: Epoch: 24 | Training Loss: 0.048782 | Val. Loss: 0.334013 | Val. Kappa Score: 0.5903 | Estimated time: 34.17
Train loss on 25 batch: 0.055863
Train loss on 50 batch: 0.053532
: Epoch: 25 | Training Loss: 0.054698 | Val. Loss: 0.353721 | Val. Kappa Score: 0.5896 | Estimated time: 34.52
Train loss on 25 batch: 0.103577
Train loss on 50 batch: 0.059895
: Epoch: 26 | Training Loss: 0.081736 | Val. Loss: 0.360006 | Val. Kappa Score: 0.5908 | Estimated time: 33.70
Train loss on 25 batch: 0.121765
Train loss on 50 batch: 0.084310
: Epoch: 27 | Training Loss: 0.103037 | Val. Loss: 0.330393 | Val. Kappa Score: 0.5911 | Estimated time: 34.12
Train loss on 25 batch: 0.077463
Train loss on 50 batch: 0.072327
: Epoch: 28 | Training Loss: 0.074895 | Val. Loss: 0.337739 | Val. Kappa Score: 0.5926 | Estimated time: 35.32
Train loss on 25 batch: 0.064445
Train loss on 50 batch: 0.049311
: Epoch: 29 | Training Loss: 0.056878 | Val. Loss: 0.343928 | Val. Kappa Score: 0.5937 | Estimated time: 34.48
Train loss on 25 batch: 0.131308
Train loss on 50 batch: 0.071209
: Epoch: 30 | Training Loss: 0.101259 | Val. Loss: 0.316918 | Val. Kappa Score: 0.5957 | Estimated time: 33.63
Train loss on 25 batch: 0.290618
Train loss on 50 batch: 0.121841
: Epoch: 31 | Training Loss: 0.206229 | Val. Loss: 0.371076 | Val. Kappa Score: 0.5958 | Estimated time: 34.18
Train loss on 25 batch: 0.074676
Train loss on 50 batch: 0.070175
: Epoch: 32 | Training Loss: 0.072426 | Val. Loss: 0.385449 | Val. Kappa Score: 0.5952 | Estimated time: 34.20
Train loss on 25 batch: 0.142414
Train loss on 50 batch: 0.119229
: Epoch: 33 | Training Loss: 0.130822 | Val. Loss: 0.525429 | Val. Kappa Score: 0.5942 | Estimated time: 34.35
Train loss on 25 batch: 0.231726
Train loss on 50 batch: 0.116739
: Epoch: 34 | Training Loss: 0.174233 | Val. Loss: 0.351825 | Val. Kappa Score: 0.5952 | Estimated time: 33.79
Train loss on 25 batch: 0.145388
Train loss on 50 batch: 0.129794
: Epoch: 35 | Training Loss: 0.137591 | Val. Loss: 0.336318 | Val. Kappa Score: 0.5955 | Estimated time: 33.31
Train loss on 25 batch: 0.167576
Train loss on 50 batch: 0.115413
: Epoch: 36 | Training Loss: 0.141494 | Val. Loss: 0.367162 | Val. Kappa Score: 0.5957 | Estimated time: 33.18
time_estimated: 1226.16
n-epochs: 36
time_estimated: 1226.17
----------------------------------------

Experiment N: 12: 
date: 2019.08.06 12:48:50
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
best-train-loss: 0.803977
best-valid-loss: 0.390829
best-kappa: 0.5968
: Epoch: 1 | Training Loss: 0.803977 | Val. Loss: 0.390829 | Val. Kappa Score: 0.5968 | Estimated time: 32.97
Train loss on 25 batch: 0.379721
: Epoch: 2 | Training Loss: 0.379721 | Val. Loss: 0.485985 | Val. Kappa Score: 0.5850 | Estimated time: 32.63
Train loss on 25 batch: 0.201845
: Epoch: 3 | Training Loss: 0.201845 | Val. Loss: 0.571235 | Val. Kappa Score: 0.5369 | Estimated time: 32.53
Train loss on 25 batch: 0.242747
best-train-loss: 0.242747
best-valid-loss: 0.338722
best-kappa: 0.5605
: Epoch: 4 | Training Loss: 0.242747 | Val. Loss: 0.338722 | Val. Kappa Score: 0.5605 | Estimated time: 34.13
Train loss on 25 batch: 0.126876
best-train-loss: 0.126876
best-valid-loss: 0.325506
best-kappa: 0.5749
: Epoch: 5 | Training Loss: 0.126876 | Val. Loss: 0.325506 | Val. Kappa Score: 0.5749 | Estimated time: 33.44
Train loss on 25 batch: 0.145124
best-train-loss: 0.145124
best-valid-loss: 0.291815
best-kappa: 0.5889
: Epoch: 6 | Training Loss: 0.145124 | Val. Loss: 0.291815 | Val. Kappa Score: 0.5889 | Estimated time: 32.57
Train loss on 25 batch: 0.122500
: Epoch: 7 | Training Loss: 0.122500 | Val. Loss: 0.292707 | Val. Kappa Score: 0.6006 | Estimated time: 33.00
Train loss on 25 batch: 0.125324
: Epoch: 8 | Training Loss: 0.125324 | Val. Loss: 0.324141 | Val. Kappa Score: 0.6069 | Estimated time: 33.20
Train loss on 25 batch: 0.106849
: Epoch: 9 | Training Loss: 0.106849 | Val. Loss: 0.327609 | Val. Kappa Score: 0.6126 | Estimated time: 33.78
Train loss on 25 batch: 0.091795
best-train-loss: 0.091795
best-valid-loss: 0.291556
best-kappa: 0.6183
: Epoch: 10 | Training Loss: 0.091795 | Val. Loss: 0.291556 | Val. Kappa Score: 0.6183 | Estimated time: 33.00
Train loss on 25 batch: 0.061365
: Epoch: 11 | Training Loss: 0.061365 | Val. Loss: 0.293511 | Val. Kappa Score: 0.6256 | Estimated time: 32.62
Train loss on 25 batch: 0.074632
best-train-loss: 0.074632
best-valid-loss: 0.281012
best-kappa: 0.6278
: Epoch: 12 | Training Loss: 0.074632 | Val. Loss: 0.281012 | Val. Kappa Score: 0.6278 | Estimated time: 34.18
Train loss on 25 batch: 0.041334
: Epoch: 13 | Training Loss: 0.041334 | Val. Loss: 0.306715 | Val. Kappa Score: 0.6306 | Estimated time: 32.05
Train loss on 25 batch: 0.085291
: Epoch: 14 | Training Loss: 0.085291 | Val. Loss: 0.283662 | Val. Kappa Score: 0.6336 | Estimated time: 32.82
Train loss on 25 batch: 0.048131
best-train-loss: 0.048131
best-valid-loss: 0.280068
best-kappa: 0.6343
: Epoch: 15 | Training Loss: 0.048131 | Val. Loss: 0.280068 | Val. Kappa Score: 0.6343 | Estimated time: 32.79
Train loss on 25 batch: 0.063779
: Epoch: 16 | Training Loss: 0.063779 | Val. Loss: 0.316915 | Val. Kappa Score: 0.6372 | Estimated time: 34.09
Train loss on 25 batch: 0.035310
best-train-loss: 0.035310
best-valid-loss: 0.273587
best-kappa: 0.6399
: Epoch: 17 | Training Loss: 0.035310 | Val. Loss: 0.273587 | Val. Kappa Score: 0.6399 | Estimated time: 32.58
Train loss on 25 batch: 0.037314
: Epoch: 18 | Training Loss: 0.037314 | Val. Loss: 0.293120 | Val. Kappa Score: 0.6422 | Estimated time: 32.99
Train loss on 25 batch: 0.047514
: Epoch: 19 | Training Loss: 0.047514 | Val. Loss: 0.276264 | Val. Kappa Score: 0.6437 | Estimated time: 34.45
Train loss on 25 batch: 0.036543
: Epoch: 20 | Training Loss: 0.036543 | Val. Loss: 0.286634 | Val. Kappa Score: 0.6462 | Estimated time: 32.79
Train loss on 25 batch: 0.029944
: Epoch: 21 | Training Loss: 0.029944 | Val. Loss: 0.289314 | Val. Kappa Score: 0.6471 | Estimated time: 33.32
Train loss on 25 batch: 0.029484
best-train-loss: 0.029484
best-valid-loss: 0.272962
best-kappa: 0.6485
: Epoch: 22 | Training Loss: 0.029484 | Val. Loss: 0.272962 | Val. Kappa Score: 0.6485 | Estimated time: 33.73
Train loss on 25 batch: 0.031151
: Epoch: 23 | Training Loss: 0.031151 | Val. Loss: 0.287340 | Val. Kappa Score: 0.6497 | Estimated time: 32.84
Train loss on 25 batch: 0.021981
best-train-loss: 0.021981
best-valid-loss: 0.263108
best-kappa: 0.6510
: Epoch: 24 | Training Loss: 0.021981 | Val. Loss: 0.263108 | Val. Kappa Score: 0.6510 | Estimated time: 33.18
Train loss on 25 batch: 0.032037
: Epoch: 25 | Training Loss: 0.032037 | Val. Loss: 0.288556 | Val. Kappa Score: 0.6521 | Estimated time: 33.24
Train loss on 25 batch: 0.025080
: Epoch: 26 | Training Loss: 0.025080 | Val. Loss: 0.288079 | Val. Kappa Score: 0.6532 | Estimated time: 32.43
Train loss on 25 batch: 0.022648
: Epoch: 27 | Training Loss: 0.022648 | Val. Loss: 0.289174 | Val. Kappa Score: 0.6537 | Estimated time: 32.85
Train loss on 25 batch: 0.021501
: Epoch: 28 | Training Loss: 0.021501 | Val. Loss: 0.269007 | Val. Kappa Score: 0.6544 | Estimated time: 32.69
Train loss on 25 batch: 0.023027
: Epoch: 29 | Training Loss: 0.023027 | Val. Loss: 0.295080 | Val. Kappa Score: 0.6553 | Estimated time: 32.81
Train loss on 25 batch: 0.022421
: Epoch: 30 | Training Loss: 0.022421 | Val. Loss: 0.267335 | Val. Kappa Score: 0.6561 | Estimated time: 33.14
Train loss on 25 batch: 0.020400
: Epoch: 31 | Training Loss: 0.020400 | Val. Loss: 0.273433 | Val. Kappa Score: 0.6564 | Estimated time: 33.48
Train loss on 25 batch: 0.021917
: Epoch: 32 | Training Loss: 0.021917 | Val. Loss: 0.290576 | Val. Kappa Score: 0.6574 | Estimated time: 33.16
Train loss on 25 batch: 0.023643
: Epoch: 33 | Training Loss: 0.023643 | Val. Loss: 0.279452 | Val. Kappa Score: 0.6581 | Estimated time: 32.89
Train loss on 25 batch: 0.024017
: Epoch: 34 | Training Loss: 0.024017 | Val. Loss: 0.280135 | Val. Kappa Score: 0.6590 | Estimated time: 32.90
Train loss on 25 batch: 0.019465
: Epoch: 35 | Training Loss: 0.019465 | Val. Loss: 0.279501 | Val. Kappa Score: 0.6596 | Estimated time: 33.83
Train loss on 25 batch: 0.018371
: Epoch: 36 | Training Loss: 0.018371 | Val. Loss: 0.265316 | Val. Kappa Score: 0.6601 | Estimated time: 34.00
Train loss on 25 batch: 0.017506
: Epoch: 37 | Training Loss: 0.017506 | Val. Loss: 0.274257 | Val. Kappa Score: 0.6611 | Estimated time: 33.20
Train loss on 25 batch: 0.019302
: Epoch: 38 | Training Loss: 0.019302 | Val. Loss: 0.270668 | Val. Kappa Score: 0.6616 | Estimated time: 33.53
Train loss on 25 batch: 0.020094
: Epoch: 39 | Training Loss: 0.020094 | Val. Loss: 0.268566 | Val. Kappa Score: 0.6624 | Estimated time: 32.96
time_estimated: 1294.01
n-epochs: 39
time_estimated: 1294.02
----------------------------------------

Experiment N: 13: 
date: 2019.08.06 17:06:42
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.1
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1501469.737574
best-train-loss: 1501469.737574
best-valid-loss: 276912027.416667
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1501469.737574 | Val. Loss: 276912027.416667 | Val. Kappa Score: 0.0000 | Estimated time: 33.32
Train loss on 25 batch: 14022.879218
best-train-loss: 14022.879218
best-valid-loss: 16007.081969
best-kappa: 0.0037
: Epoch: 2 | Training Loss: 14022.879218 | Val. Loss: 16007.081969 | Val. Kappa Score: 0.0037 | Estimated time: 33.89
Train loss on 25 batch: 569.782725
best-train-loss: 569.782725
best-valid-loss: 3456.416476
best-kappa: 0.0044
: Epoch: 3 | Training Loss: 569.782725 | Val. Loss: 3456.416476 | Val. Kappa Score: 0.0044 | Estimated time: 34.24
Train loss on 25 batch: 378.162007
best-train-loss: 378.162007
best-valid-loss: 96.880935
best-kappa: 0.0034
: Epoch: 4 | Training Loss: 378.162007 | Val. Loss: 96.880935 | Val. Kappa Score: 0.0034 | Estimated time: 33.61
Train loss on 25 batch: 271.764497
best-train-loss: 271.764497
best-valid-loss: 89.030222
best-kappa: 0.0029
: Epoch: 5 | Training Loss: 271.764497 | Val. Loss: 89.030222 | Val. Kappa Score: 0.0029 | Estimated time: 32.51
Train loss on 25 batch: 52.922571
: Epoch: 6 | Training Loss: 52.922571 | Val. Loss: 807.743216 | Val. Kappa Score: 0.0022 | Estimated time: 32.62
Train loss on 25 batch: 28.745110
: Epoch: 7 | Training Loss: 28.745110 | Val. Loss: 849.218712 | Val. Kappa Score: 0.0020 | Estimated time: 32.77
Train loss on 25 batch: 34.561797
: Epoch: 8 | Training Loss: 34.561797 | Val. Loss: 1617.262100 | Val. Kappa Score: -0.0006 | Estimated time: 32.72
Train loss on 25 batch: 91.349363
: Epoch: 9 | Training Loss: 91.349363 | Val. Loss: 629.526047 | Val. Kappa Score: -0.0001 | Estimated time: 34.55
Train loss on 25 batch: 70.472344
: Epoch: 10 | Training Loss: 70.472344 | Val. Loss: 257.419113 | Val. Kappa Score: -0.0015 | Estimated time: 34.03
Train loss on 25 batch: 104.284339
: Epoch: 11 | Training Loss: 104.284339 | Val. Loss: 175.038594 | Val. Kappa Score: -0.0014 | Estimated time: 31.81
Train loss on 25 batch: 166.335643
: Epoch: 12 | Training Loss: 166.335643 | Val. Loss: 332.104719 | Val. Kappa Score: -0.0012 | Estimated time: 33.76
Train loss on 25 batch: 90.649819
: Epoch: 13 | Training Loss: 90.649819 | Val. Loss: 493.712875 | Val. Kappa Score: -0.0008 | Estimated time: 33.28
Train loss on 25 batch: 26.982211
: Epoch: 14 | Training Loss: 26.982211 | Val. Loss: 1587.606243 | Val. Kappa Score: -0.0028 | Estimated time: 32.19
Train loss on 25 batch: 14.822165
: Epoch: 15 | Training Loss: 14.822165 | Val. Loss: 701.740891 | Val. Kappa Score: -0.0027 | Estimated time: 33.74
Train loss on 25 batch: 15.750485
: Epoch: 16 | Training Loss: 15.750485 | Val. Loss: 458.107105 | Val. Kappa Score: -0.0037 | Estimated time: 32.40
Train loss on 25 batch: 25.414662
: Epoch: 17 | Training Loss: 25.414662 | Val. Loss: 4869.396966 | Val. Kappa Score: -0.0034 | Estimated time: 32.53
Train loss on 25 batch: 22.712017
: Epoch: 18 | Training Loss: 22.712017 | Val. Loss: 5925.544244 | Val. Kappa Score: -0.0087 | Estimated time: 31.97
Train loss on 25 batch: 17.750865
: Epoch: 19 | Training Loss: 17.750865 | Val. Loss: 177.563741 | Val. Kappa Score: -0.0092 | Estimated time: 33.15
Train loss on 25 batch: 20.689524
: Epoch: 20 | Training Loss: 20.689524 | Val. Loss: 1617.846155 | Val. Kappa Score: -0.0088 | Estimated time: 33.00
time_estimated: 662.72
n-epochs: 20
time_estimated: 662.72
----------------------------------------

Experiment N: 14: 
date: 2019.08.06 17:17:45
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 565.437518
best-train-loss: 565.437518
best-valid-loss: 1427.031405
best-kappa: 0.0008
: Epoch: 1 | Training Loss: 565.437518 | Val. Loss: 1427.031405 | Val. Kappa Score: 0.0008 | Estimated time: 32.56
Train loss on 25 batch: 1.819539
best-train-loss: 1.819539
best-valid-loss: 2.705684
best-kappa: 0.0014
: Epoch: 2 | Training Loss: 1.819539 | Val. Loss: 2.705684 | Val. Kappa Score: 0.0014 | Estimated time: 34.30
Train loss on 25 batch: 1.755171
best-train-loss: 1.755171
best-valid-loss: 1.881704
best-kappa: 0.0023
: Epoch: 3 | Training Loss: 1.755171 | Val. Loss: 1.881704 | Val. Kappa Score: 0.0023 | Estimated time: 33.15
Train loss on 25 batch: 1.754033
: Epoch: 4 | Training Loss: 1.754033 | Val. Loss: 2.771486 | Val. Kappa Score: 0.0017 | Estimated time: 33.44
Train loss on 25 batch: 1.716532
best-train-loss: 1.716532
best-valid-loss: 1.695288
best-kappa: 0.0018
: Epoch: 5 | Training Loss: 1.716532 | Val. Loss: 1.695288 | Val. Kappa Score: 0.0018 | Estimated time: 33.07
Train loss on 25 batch: 1.700191
: Epoch: 6 | Training Loss: 1.700191 | Val. Loss: 1.797325 | Val. Kappa Score: 0.0021 | Estimated time: 32.03
Train loss on 25 batch: 1.670468
: Epoch: 7 | Training Loss: 1.670468 | Val. Loss: 10.883893 | Val. Kappa Score: 0.0049 | Estimated time: 32.87
Train loss on 25 batch: 1.299944
: Epoch: 8 | Training Loss: 1.299944 | Val. Loss: 2.329141 | Val. Kappa Score: 0.0047 | Estimated time: 32.55
Train loss on 25 batch: 1.221308
: Epoch: 9 | Training Loss: 1.221308 | Val. Loss: 9.842020 | Val. Kappa Score: 0.0465 | Estimated time: 34.00
Train loss on 25 batch: 0.838417
: Epoch: 10 | Training Loss: 0.838417 | Val. Loss: 1.760334 | Val. Kappa Score: 0.0759 | Estimated time: 32.17
Train loss on 25 batch: 0.951877
best-train-loss: 0.951877
best-valid-loss: 1.152940
best-kappa: 0.1003
: Epoch: 11 | Training Loss: 0.951877 | Val. Loss: 1.152940 | Val. Kappa Score: 0.1003 | Estimated time: 32.79
Train loss on 25 batch: 0.867629
best-train-loss: 0.867629
best-valid-loss: 0.915662
best-kappa: 0.1288
: Epoch: 12 | Training Loss: 0.867629 | Val. Loss: 0.915662 | Val. Kappa Score: 0.1288 | Estimated time: 32.61
Train loss on 25 batch: 0.737531
: Epoch: 13 | Training Loss: 0.737531 | Val. Loss: 20.079642 | Val. Kappa Score: 0.1264 | Estimated time: 33.47
Train loss on 25 batch: 0.888808
: Epoch: 14 | Training Loss: 0.888808 | Val. Loss: 6.021222 | Val. Kappa Score: 0.1273 | Estimated time: 32.33
Train loss on 25 batch: 0.740671
: Epoch: 15 | Training Loss: 0.740671 | Val. Loss: 2.743202 | Val. Kappa Score: 0.1196 | Estimated time: 34.02
Train loss on 25 batch: 0.843243
: Epoch: 16 | Training Loss: 0.843243 | Val. Loss: 0.948600 | Val. Kappa Score: 0.1257 | Estimated time: 33.50
Train loss on 25 batch: 0.776834
best-train-loss: 0.776834
best-valid-loss: 0.774293
best-kappa: 0.1488
: Epoch: 17 | Training Loss: 0.776834 | Val. Loss: 0.774293 | Val. Kappa Score: 0.1488 | Estimated time: 32.62
Train loss on 25 batch: 0.754228
: Epoch: 18 | Training Loss: 0.754228 | Val. Loss: 1.027692 | Val. Kappa Score: 0.1664 | Estimated time: 32.80
Train loss on 25 batch: 0.896604
: Epoch: 19 | Training Loss: 0.896604 | Val. Loss: 0.806259 | Val. Kappa Score: 0.1797 | Estimated time: 33.47
Train loss on 25 batch: 0.732581
: Epoch: 20 | Training Loss: 0.732581 | Val. Loss: 1.047734 | Val. Kappa Score: 0.1907 | Estimated time: 33.01
Train loss on 25 batch: 0.802728
: Epoch: 21 | Training Loss: 0.802728 | Val. Loss: 0.777357 | Val. Kappa Score: 0.2044 | Estimated time: 33.39
Train loss on 25 batch: 0.793040
best-train-loss: 0.793040
best-valid-loss: 0.682687
best-kappa: 0.2187
: Epoch: 22 | Training Loss: 0.793040 | Val. Loss: 0.682687 | Val. Kappa Score: 0.2187 | Estimated time: 33.19
Train loss on 25 batch: 0.732040
: Epoch: 23 | Training Loss: 0.732040 | Val. Loss: 2.820202 | Val. Kappa Score: 0.2294 | Estimated time: 33.05
Train loss on 25 batch: 0.701317
: Epoch: 24 | Training Loss: 0.701317 | Val. Loss: 0.787681 | Val. Kappa Score: 0.2378 | Estimated time: 32.11
Train loss on 25 batch: 0.618972
: Epoch: 25 | Training Loss: 0.618972 | Val. Loss: 1.343285 | Val. Kappa Score: 0.2369 | Estimated time: 35.00
Train loss on 25 batch: 0.677040
: Epoch: 26 | Training Loss: 0.677040 | Val. Loss: 0.888941 | Val. Kappa Score: 0.2343 | Estimated time: 32.88
Train loss on 25 batch: 0.633484
best-train-loss: 0.633484
best-valid-loss: 0.631014
best-kappa: 0.2409
: Epoch: 27 | Training Loss: 0.633484 | Val. Loss: 0.631014 | Val. Kappa Score: 0.2409 | Estimated time: 33.54
Train loss on 25 batch: 0.590179
: Epoch: 28 | Training Loss: 0.590179 | Val. Loss: 0.641613 | Val. Kappa Score: 0.2500 | Estimated time: 32.69
Train loss on 25 batch: 0.572938
: Epoch: 29 | Training Loss: 0.572938 | Val. Loss: 1.355900 | Val. Kappa Score: 0.2440 | Estimated time: 32.99
Train loss on 25 batch: 0.595287
: Epoch: 30 | Training Loss: 0.595287 | Val. Loss: 2.533014 | Val. Kappa Score: 0.2371 | Estimated time: 33.47
Train loss on 25 batch: 0.613830
: Epoch: 31 | Training Loss: 0.613830 | Val. Loss: 2.456170 | Val. Kappa Score: 0.2320 | Estimated time: 33.14
Train loss on 25 batch: 0.614636
: Epoch: 32 | Training Loss: 0.614636 | Val. Loss: 2.465002 | Val. Kappa Score: 0.2260 | Estimated time: 33.83
Train loss on 25 batch: 0.554927
: Epoch: 33 | Training Loss: 0.554927 | Val. Loss: 2.215456 | Val. Kappa Score: 0.2227 | Estimated time: 33.38
Train loss on 25 batch: 0.617739
best-train-loss: 0.617739
best-valid-loss: 0.619181
best-kappa: 0.2312
: Epoch: 34 | Training Loss: 0.617739 | Val. Loss: 0.619181 | Val. Kappa Score: 0.2312 | Estimated time: 33.33
Train loss on 25 batch: 0.523845
: Epoch: 35 | Training Loss: 0.523845 | Val. Loss: 0.636527 | Val. Kappa Score: 0.2351 | Estimated time: 32.21
Train loss on 25 batch: 0.602536
: Epoch: 36 | Training Loss: 0.602536 | Val. Loss: 0.737577 | Val. Kappa Score: 0.2357 | Estimated time: 34.22
Train loss on 25 batch: 0.539079
: Epoch: 37 | Training Loss: 0.539079 | Val. Loss: 0.677379 | Val. Kappa Score: 0.2405 | Estimated time: 32.71
Train loss on 25 batch: 0.568987
: Epoch: 38 | Training Loss: 0.568987 | Val. Loss: 0.668087 | Val. Kappa Score: 0.2489 | Estimated time: 33.97
Train loss on 25 batch: 0.530185
best-train-loss: 0.530185
best-valid-loss: 0.542625
best-kappa: 0.2552
: Epoch: 39 | Training Loss: 0.530185 | Val. Loss: 0.542625 | Val. Kappa Score: 0.2552 | Estimated time: 32.82
Train loss on 25 batch: 0.569569
: Epoch: 40 | Training Loss: 0.569569 | Val. Loss: 0.743731 | Val. Kappa Score: 0.2605 | Estimated time: 34.74
Train loss on 25 batch: 0.518973
: Epoch: 41 | Training Loss: 0.518973 | Val. Loss: 0.935072 | Val. Kappa Score: 0.2632 | Estimated time: 32.42
Train loss on 25 batch: 0.560605
: Epoch: 42 | Training Loss: 0.560605 | Val. Loss: 0.590035 | Val. Kappa Score: 0.2701 | Estimated time: 33.00
Train loss on 25 batch: 0.555194
: Epoch: 43 | Training Loss: 0.555194 | Val. Loss: 0.941169 | Val. Kappa Score: 0.2740 | Estimated time: 33.62
Train loss on 25 batch: 0.499115
: Epoch: 44 | Training Loss: 0.499115 | Val. Loss: 1.129056 | Val. Kappa Score: 0.2715 | Estimated time: 32.96
Train loss on 25 batch: 0.518665
: Epoch: 45 | Training Loss: 0.518665 | Val. Loss: 0.550182 | Val. Kappa Score: 0.2779 | Estimated time: 33.33
Train loss on 25 batch: 0.485138
: Epoch: 46 | Training Loss: 0.485138 | Val. Loss: 3.365442 | Val. Kappa Score: 0.2714 | Estimated time: 32.15
Train loss on 25 batch: 0.542039
: Epoch: 47 | Training Loss: 0.542039 | Val. Loss: 0.768995 | Val. Kappa Score: 0.2750 | Estimated time: 33.36
Train loss on 25 batch: 0.466971
best-train-loss: 0.466971
best-valid-loss: 0.530520
best-kappa: 0.2794
: Epoch: 48 | Training Loss: 0.466971 | Val. Loss: 0.530520 | Val. Kappa Score: 0.2794 | Estimated time: 32.40
Train loss on 25 batch: 0.528619
: Epoch: 49 | Training Loss: 0.528619 | Val. Loss: 2.456328 | Val. Kappa Score: 0.2753 | Estimated time: 35.06
Train loss on 25 batch: 0.485646
: Epoch: 50 | Training Loss: 0.485646 | Val. Loss: 0.587727 | Val. Kappa Score: 0.2804 | Estimated time: 32.91
Train loss on 25 batch: 0.499375
: Epoch: 51 | Training Loss: 0.499375 | Val. Loss: 0.738908 | Val. Kappa Score: 0.2824 | Estimated time: 32.95
Train loss on 25 batch: 0.509685
: Epoch: 52 | Training Loss: 0.509685 | Val. Loss: 2.738435 | Val. Kappa Score: 0.2780 | Estimated time: 32.88
Train loss on 25 batch: 0.506619
: Epoch: 53 | Training Loss: 0.506619 | Val. Loss: 0.734277 | Val. Kappa Score: 0.2822 | Estimated time: 32.73
Train loss on 25 batch: 0.467220
: Epoch: 54 | Training Loss: 0.467220 | Val. Loss: 1.114997 | Val. Kappa Score: 0.2805 | Estimated time: 33.36
Train loss on 25 batch: 0.443397
: Epoch: 55 | Training Loss: 0.443397 | Val. Loss: 0.588383 | Val. Kappa Score: 0.2848 | Estimated time: 32.34
Train loss on 25 batch: 0.473542
: Epoch: 56 | Training Loss: 0.473542 | Val. Loss: 0.625553 | Val. Kappa Score: 0.2894 | Estimated time: 34.25
Train loss on 25 batch: 0.425698
: Epoch: 57 | Training Loss: 0.425698 | Val. Loss: 0.592318 | Val. Kappa Score: 0.2937 | Estimated time: 34.25
Train loss on 25 batch: 0.478618
: Epoch: 58 | Training Loss: 0.478618 | Val. Loss: 0.748399 | Val. Kappa Score: 0.2959 | Estimated time: 32.87
Train loss on 25 batch: 0.473314
: Epoch: 59 | Training Loss: 0.473314 | Val. Loss: 0.638847 | Val. Kappa Score: 0.3002 | Estimated time: 32.53
Train loss on 25 batch: 0.423068
: Epoch: 60 | Training Loss: 0.423068 | Val. Loss: 0.597526 | Val. Kappa Score: 0.3024 | Estimated time: 32.26
Train loss on 25 batch: 0.404120
: Epoch: 61 | Training Loss: 0.404120 | Val. Loss: 0.542137 | Val. Kappa Score: 0.3062 | Estimated time: 32.25
Train loss on 25 batch: 0.456671
: Epoch: 62 | Training Loss: 0.456671 | Val. Loss: 1.240913 | Val. Kappa Score: 0.3047 | Estimated time: 33.50
Train loss on 25 batch: 0.452251
: Epoch: 63 | Training Loss: 0.452251 | Val. Loss: 0.536603 | Val. Kappa Score: 0.3089 | Estimated time: 33.16
time_estimated: 2089.43
n-epochs: 63
time_estimated: 2089.44
----------------------------------------

Experiment N: 15: 
date: 2019.08.06 17:52:35
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 16.572708
best-train-loss: 16.572708
best-valid-loss: 2.211785
best-kappa: 0.0019
: Epoch: 1 | Training Loss: 16.572708 | Val. Loss: 2.211785 | Val. Kappa Score: 0.0019 | Estimated time: 32.80
Train loss on 25 batch: 1.664521
best-train-loss: 1.664521
best-valid-loss: 1.425080
best-kappa: 0.0009
: Epoch: 2 | Training Loss: 1.664521 | Val. Loss: 1.425080 | Val. Kappa Score: 0.0009 | Estimated time: 32.79
Train loss on 25 batch: 1.115163
best-train-loss: 1.115163
best-valid-loss: 0.819112
best-kappa: 0.1469
: Epoch: 3 | Training Loss: 1.115163 | Val. Loss: 0.819112 | Val. Kappa Score: 0.1469 | Estimated time: 32.45
Train loss on 25 batch: 0.616895
best-train-loss: 0.616895
best-valid-loss: 0.680846
best-kappa: 0.1850
: Epoch: 4 | Training Loss: 0.616895 | Val. Loss: 0.680846 | Val. Kappa Score: 0.1850 | Estimated time: 33.03
Train loss on 25 batch: 0.565537
: Epoch: 5 | Training Loss: 0.565537 | Val. Loss: 1.149044 | Val. Kappa Score: 0.1886 | Estimated time: 32.88
Train loss on 25 batch: 0.479429
best-train-loss: 0.479429
best-valid-loss: 0.569493
best-kappa: 0.2360
: Epoch: 6 | Training Loss: 0.479429 | Val. Loss: 0.569493 | Val. Kappa Score: 0.2360 | Estimated time: 32.92
Train loss on 25 batch: 0.418283
: Epoch: 7 | Training Loss: 0.418283 | Val. Loss: 20.110529 | Val. Kappa Score: 0.2230 | Estimated time: 33.13
Train loss on 25 batch: 0.451673
best-train-loss: 0.451673
best-valid-loss: 0.466364
best-kappa: 0.2648
: Epoch: 8 | Training Loss: 0.451673 | Val. Loss: 0.466364 | Val. Kappa Score: 0.2648 | Estimated time: 32.86
Train loss on 25 batch: 0.397275
best-train-loss: 0.397275
best-valid-loss: 0.453505
best-kappa: 0.2894
: Epoch: 9 | Training Loss: 0.397275 | Val. Loss: 0.453505 | Val. Kappa Score: 0.2894 | Estimated time: 33.72
Train loss on 25 batch: 0.369650
best-train-loss: 0.369650
best-valid-loss: 0.424396
best-kappa: 0.3103
: Epoch: 10 | Training Loss: 0.369650 | Val. Loss: 0.424396 | Val. Kappa Score: 0.3103 | Estimated time: 32.42
Train loss on 25 batch: 0.328325
: Epoch: 11 | Training Loss: 0.328325 | Val. Loss: 2.019929 | Val. Kappa Score: 0.3094 | Estimated time: 32.35
Train loss on 25 batch: 0.360993
best-train-loss: 0.360993
best-valid-loss: 0.397969
best-kappa: 0.3302
: Epoch: 12 | Training Loss: 0.360993 | Val. Loss: 0.397969 | Val. Kappa Score: 0.3302 | Estimated time: 34.16
Train loss on 25 batch: 0.291776
: Epoch: 13 | Training Loss: 0.291776 | Val. Loss: 0.414417 | Val. Kappa Score: 0.3544 | Estimated time: 33.48
Train loss on 25 batch: 0.330413
: Epoch: 14 | Training Loss: 0.330413 | Val. Loss: 0.432543 | Val. Kappa Score: 0.3707 | Estimated time: 33.53
Train loss on 25 batch: 0.274025
best-train-loss: 0.274025
best-valid-loss: 0.381596
best-kappa: 0.3868
: Epoch: 15 | Training Loss: 0.274025 | Val. Loss: 0.381596 | Val. Kappa Score: 0.3868 | Estimated time: 33.17
Train loss on 25 batch: 0.279486
: Epoch: 16 | Training Loss: 0.279486 | Val. Loss: 0.448051 | Val. Kappa Score: 0.3998 | Estimated time: 32.08
Train loss on 25 batch: 0.223632
: Epoch: 17 | Training Loss: 0.223632 | Val. Loss: 0.413717 | Val. Kappa Score: 0.4120 | Estimated time: 32.81
Train loss on 25 batch: 0.247363
: Epoch: 18 | Training Loss: 0.247363 | Val. Loss: 0.728103 | Val. Kappa Score: 0.4153 | Estimated time: 32.98
Train loss on 25 batch: 0.349443
best-train-loss: 0.349443
best-valid-loss: 0.371761
best-kappa: 0.4253
: Epoch: 19 | Training Loss: 0.349443 | Val. Loss: 0.371761 | Val. Kappa Score: 0.4253 | Estimated time: 33.46
Train loss on 25 batch: 0.255605
best-train-loss: 0.255605
best-valid-loss: 0.342242
best-kappa: 0.4346
: Epoch: 20 | Training Loss: 0.255605 | Val. Loss: 0.342242 | Val. Kappa Score: 0.4346 | Estimated time: 33.55
Train loss on 25 batch: 0.192893
: Epoch: 21 | Training Loss: 0.192893 | Val. Loss: 0.353688 | Val. Kappa Score: 0.4441 | Estimated time: 33.19
Train loss on 25 batch: 0.200118
: Epoch: 22 | Training Loss: 0.200118 | Val. Loss: 0.464044 | Val. Kappa Score: 0.4505 | Estimated time: 32.88
Train loss on 25 batch: 0.178147
: Epoch: 23 | Training Loss: 0.178147 | Val. Loss: 0.422182 | Val. Kappa Score: 0.4568 | Estimated time: 34.41
Train loss on 25 batch: 0.156615
: Epoch: 24 | Training Loss: 0.156615 | Val. Loss: 0.366466 | Val. Kappa Score: 0.4632 | Estimated time: 32.25
Train loss on 25 batch: 0.139067
: Epoch: 25 | Training Loss: 0.139067 | Val. Loss: 0.391348 | Val. Kappa Score: 0.4690 | Estimated time: 34.13
Train loss on 25 batch: 0.161774
: Epoch: 26 | Training Loss: 0.161774 | Val. Loss: 0.376513 | Val. Kappa Score: 0.4740 | Estimated time: 32.87
Train loss on 25 batch: 0.121044
: Epoch: 27 | Training Loss: 0.121044 | Val. Loss: 0.368570 | Val. Kappa Score: 0.4788 | Estimated time: 34.23
Train loss on 25 batch: 0.135668
: Epoch: 28 | Training Loss: 0.135668 | Val. Loss: 0.492453 | Val. Kappa Score: 0.4826 | Estimated time: 32.89
Train loss on 25 batch: 0.126176
: Epoch: 29 | Training Loss: 0.126176 | Val. Loss: 0.394368 | Val. Kappa Score: 0.4867 | Estimated time: 33.10
Train loss on 25 batch: 0.104323
: Epoch: 30 | Training Loss: 0.104323 | Val. Loss: 0.397007 | Val. Kappa Score: 0.4915 | Estimated time: 32.86
Train loss on 25 batch: 0.123811
: Epoch: 31 | Training Loss: 0.123811 | Val. Loss: 0.373053 | Val. Kappa Score: 0.4955 | Estimated time: 33.68
Train loss on 25 batch: 0.092373
best-train-loss: 0.092373
best-valid-loss: 0.340865
best-kappa: 0.4991
: Epoch: 32 | Training Loss: 0.092373 | Val. Loss: 0.340865 | Val. Kappa Score: 0.4991 | Estimated time: 34.03
Train loss on 25 batch: 0.111238
: Epoch: 33 | Training Loss: 0.111238 | Val. Loss: 0.485343 | Val. Kappa Score: 0.5016 | Estimated time: 33.13
Train loss on 25 batch: 0.121419
: Epoch: 34 | Training Loss: 0.121419 | Val. Loss: 0.353608 | Val. Kappa Score: 0.5044 | Estimated time: 33.37
Train loss on 25 batch: 0.088347
: Epoch: 35 | Training Loss: 0.088347 | Val. Loss: 0.430532 | Val. Kappa Score: 0.5072 | Estimated time: 33.20
Train loss on 25 batch: 0.115336
: Epoch: 36 | Training Loss: 0.115336 | Val. Loss: 0.364010 | Val. Kappa Score: 0.5101 | Estimated time: 33.02
Train loss on 25 batch: 0.114800
: Epoch: 37 | Training Loss: 0.114800 | Val. Loss: 0.355130 | Val. Kappa Score: 0.5135 | Estimated time: 32.67
Train loss on 25 batch: 0.090438
best-train-loss: 0.090438
best-valid-loss: 0.328554
best-kappa: 0.5167
: Epoch: 38 | Training Loss: 0.090438 | Val. Loss: 0.328554 | Val. Kappa Score: 0.5167 | Estimated time: 33.53
Train loss on 25 batch: 0.072167
: Epoch: 39 | Training Loss: 0.072167 | Val. Loss: 0.362755 | Val. Kappa Score: 0.5190 | Estimated time: 33.21
Train loss on 25 batch: 0.070371
: Epoch: 40 | Training Loss: 0.070371 | Val. Loss: 0.367129 | Val. Kappa Score: 0.5212 | Estimated time: 33.71
Train loss on 25 batch: 0.070664
: Epoch: 41 | Training Loss: 0.070664 | Val. Loss: 0.346277 | Val. Kappa Score: 0.5238 | Estimated time: 33.16
Train loss on 25 batch: 0.062402
: Epoch: 42 | Training Loss: 0.062402 | Val. Loss: 0.360592 | Val. Kappa Score: 0.5263 | Estimated time: 33.60
Train loss on 25 batch: 0.065303
: Epoch: 43 | Training Loss: 0.065303 | Val. Loss: 0.349816 | Val. Kappa Score: 0.5289 | Estimated time: 33.12
Train loss on 25 batch: 0.065501
: Epoch: 44 | Training Loss: 0.065501 | Val. Loss: 0.331957 | Val. Kappa Score: 0.5314 | Estimated time: 32.98
Train loss on 25 batch: 0.048340
: Epoch: 45 | Training Loss: 0.048340 | Val. Loss: 0.338499 | Val. Kappa Score: 0.5330 | Estimated time: 33.04
Train loss on 25 batch: 0.059520
best-train-loss: 0.059520
best-valid-loss: 0.324779
best-kappa: 0.5353
: Epoch: 46 | Training Loss: 0.059520 | Val. Loss: 0.324779 | Val. Kappa Score: 0.5353 | Estimated time: 33.48
Train loss on 25 batch: 0.063817
: Epoch: 47 | Training Loss: 0.063817 | Val. Loss: 0.350952 | Val. Kappa Score: 0.5370 | Estimated time: 32.36
Train loss on 25 batch: 0.055001
: Epoch: 48 | Training Loss: 0.055001 | Val. Loss: 0.416482 | Val. Kappa Score: 0.5383 | Estimated time: 32.98
Train loss on 25 batch: 0.062867
: Epoch: 49 | Training Loss: 0.062867 | Val. Loss: 0.349092 | Val. Kappa Score: 0.5402 | Estimated time: 33.43
Train loss on 25 batch: 0.065382
: Epoch: 50 | Training Loss: 0.065382 | Val. Loss: 0.387261 | Val. Kappa Score: 0.5418 | Estimated time: 32.59
Train loss on 25 batch: 0.068314
: Epoch: 51 | Training Loss: 0.068314 | Val. Loss: 0.506610 | Val. Kappa Score: 0.5430 | Estimated time: 33.47
Train loss on 25 batch: 0.088168
: Epoch: 52 | Training Loss: 0.088168 | Val. Loss: 0.401777 | Val. Kappa Score: 0.5438 | Estimated time: 33.40
Train loss on 25 batch: 0.073713
: Epoch: 53 | Training Loss: 0.073713 | Val. Loss: 0.338953 | Val. Kappa Score: 0.5455 | Estimated time: 35.07
Train loss on 25 batch: 0.080527
: Epoch: 54 | Training Loss: 0.080527 | Val. Loss: 0.381920 | Val. Kappa Score: 0.5470 | Estimated time: 33.45
Train loss on 25 batch: 0.063637
: Epoch: 55 | Training Loss: 0.063637 | Val. Loss: 0.364552 | Val. Kappa Score: 0.5489 | Estimated time: 33.21
Train loss on 25 batch: 0.075299
: Epoch: 56 | Training Loss: 0.075299 | Val. Loss: 0.442266 | Val. Kappa Score: 0.5502 | Estimated time: 33.03
Train loss on 25 batch: 0.055633
: Epoch: 57 | Training Loss: 0.055633 | Val. Loss: 0.348953 | Val. Kappa Score: 0.5515 | Estimated time: 33.36
Train loss on 25 batch: 0.054944
: Epoch: 58 | Training Loss: 0.054944 | Val. Loss: 1.406535 | Val. Kappa Score: 0.5529 | Estimated time: 32.75
Train loss on 25 batch: 0.076422
: Epoch: 59 | Training Loss: 0.076422 | Val. Loss: 0.352944 | Val. Kappa Score: 0.5547 | Estimated time: 31.81
Train loss on 25 batch: 0.047673
: Epoch: 60 | Training Loss: 0.047673 | Val. Loss: 0.438460 | Val. Kappa Score: 0.5558 | Estimated time: 32.50
Train loss on 25 batch: 0.052507
: Epoch: 61 | Training Loss: 0.052507 | Val. Loss: 0.438578 | Val. Kappa Score: 0.5562 | Estimated time: 32.02
time_estimated: 2023.55
n-epochs: 61
time_estimated: 2023.55
----------------------------------------

Experiment N: 16: 
date: 2019.08.06 18:26:20
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 4.471930
best-train-loss: 4.471930
best-valid-loss: 0.762785
best-kappa: 0.3133
: Epoch: 1 | Training Loss: 4.471930 | Val. Loss: 0.762785 | Val. Kappa Score: 0.3133 | Estimated time: 33.14
Train loss on 25 batch: 0.618924
best-train-loss: 0.618924
best-valid-loss: 0.645157
best-kappa: 0.3296
: Epoch: 2 | Training Loss: 0.618924 | Val. Loss: 0.645157 | Val. Kappa Score: 0.3296 | Estimated time: 33.03
Train loss on 25 batch: 0.409257
best-train-loss: 0.409257
best-valid-loss: 0.416951
best-kappa: 0.4082
: Epoch: 3 | Training Loss: 0.409257 | Val. Loss: 0.416951 | Val. Kappa Score: 0.4082 | Estimated time: 33.71
Train loss on 25 batch: 0.319192
: Epoch: 4 | Training Loss: 0.319192 | Val. Loss: 0.525202 | Val. Kappa Score: 0.4007 | Estimated time: 33.17
Train loss on 25 batch: 0.272051
: Epoch: 5 | Training Loss: 0.272051 | Val. Loss: 0.469346 | Val. Kappa Score: 0.4075 | Estimated time: 32.92
Train loss on 25 batch: 0.275666
: Epoch: 6 | Training Loss: 0.275666 | Val. Loss: 0.540225 | Val. Kappa Score: 0.4028 | Estimated time: 32.59
Train loss on 25 batch: 0.225210
best-train-loss: 0.225210
best-valid-loss: 0.320932
best-kappa: 0.4367
: Epoch: 7 | Training Loss: 0.225210 | Val. Loss: 0.320932 | Val. Kappa Score: 0.4367 | Estimated time: 34.07
Train loss on 25 batch: 0.177421
: Epoch: 8 | Training Loss: 0.177421 | Val. Loss: 0.426824 | Val. Kappa Score: 0.4546 | Estimated time: 32.85
Train loss on 25 batch: 0.204452
: Epoch: 9 | Training Loss: 0.204452 | Val. Loss: 0.550403 | Val. Kappa Score: 0.4628 | Estimated time: 33.48
Train loss on 25 batch: 0.171373
: Epoch: 10 | Training Loss: 0.171373 | Val. Loss: 0.342037 | Val. Kappa Score: 0.4799 | Estimated time: 33.92
Train loss on 25 batch: 0.123201
: Epoch: 11 | Training Loss: 0.123201 | Val. Loss: 0.407602 | Val. Kappa Score: 0.4920 | Estimated time: 33.57
Train loss on 25 batch: 0.165794
: Epoch: 12 | Training Loss: 0.165794 | Val. Loss: 0.356060 | Val. Kappa Score: 0.4971 | Estimated time: 33.85
Train loss on 25 batch: 0.118488
: Epoch: 13 | Training Loss: 0.118488 | Val. Loss: 0.556641 | Val. Kappa Score: 0.5000 | Estimated time: 33.50
Train loss on 25 batch: 0.134135
: Epoch: 14 | Training Loss: 0.134135 | Val. Loss: 0.419712 | Val. Kappa Score: 0.5085 | Estimated time: 32.35
Train loss on 25 batch: 0.106273
: Epoch: 15 | Training Loss: 0.106273 | Val. Loss: 0.338518 | Val. Kappa Score: 0.5135 | Estimated time: 33.30
Train loss on 25 batch: 0.119143
: Epoch: 16 | Training Loss: 0.119143 | Val. Loss: 0.352539 | Val. Kappa Score: 0.5204 | Estimated time: 32.84
Train loss on 25 batch: 0.065458
: Epoch: 17 | Training Loss: 0.065458 | Val. Loss: 0.341221 | Val. Kappa Score: 0.5280 | Estimated time: 32.79
Train loss on 25 batch: 0.094949
: Epoch: 18 | Training Loss: 0.094949 | Val. Loss: 0.378038 | Val. Kappa Score: 0.5356 | Estimated time: 32.24
Train loss on 25 batch: 0.142735
best-train-loss: 0.142735
best-valid-loss: 0.314636
best-kappa: 0.5399
: Epoch: 19 | Training Loss: 0.142735 | Val. Loss: 0.314636 | Val. Kappa Score: 0.5399 | Estimated time: 33.58
Train loss on 25 batch: 0.077217
: Epoch: 20 | Training Loss: 0.077217 | Val. Loss: 0.325599 | Val. Kappa Score: 0.5462 | Estimated time: 32.38
Train loss on 25 batch: 0.050225
: Epoch: 21 | Training Loss: 0.050225 | Val. Loss: 0.335817 | Val. Kappa Score: 0.5502 | Estimated time: 33.13
Train loss on 25 batch: 0.072422
: Epoch: 22 | Training Loss: 0.072422 | Val. Loss: 0.318667 | Val. Kappa Score: 0.5536 | Estimated time: 33.69
Train loss on 25 batch: 0.054870
: Epoch: 23 | Training Loss: 0.054870 | Val. Loss: 0.339214 | Val. Kappa Score: 0.5586 | Estimated time: 33.42
Train loss on 25 batch: 0.049617
: Epoch: 24 | Training Loss: 0.049617 | Val. Loss: 0.331819 | Val. Kappa Score: 0.5609 | Estimated time: 32.36
Train loss on 25 batch: 0.048606
: Epoch: 25 | Training Loss: 0.048606 | Val. Loss: 0.354378 | Val. Kappa Score: 0.5641 | Estimated time: 33.54
Train loss on 25 batch: 0.064756
: Epoch: 26 | Training Loss: 0.064756 | Val. Loss: 0.347903 | Val. Kappa Score: 0.5661 | Estimated time: 32.56
Train loss on 25 batch: 0.045195
: Epoch: 27 | Training Loss: 0.045195 | Val. Loss: 0.325046 | Val. Kappa Score: 0.5676 | Estimated time: 34.18
Train loss on 25 batch: 0.047810
best-train-loss: 0.047810
best-valid-loss: 0.311975
best-kappa: 0.5705
: Epoch: 28 | Training Loss: 0.047810 | Val. Loss: 0.311975 | Val. Kappa Score: 0.5705 | Estimated time: 32.10
Train loss on 25 batch: 0.037648
: Epoch: 29 | Training Loss: 0.037648 | Val. Loss: 0.330734 | Val. Kappa Score: 0.5731 | Estimated time: 33.46
Train loss on 25 batch: 0.045136
: Epoch: 30 | Training Loss: 0.045136 | Val. Loss: 0.322187 | Val. Kappa Score: 0.5748 | Estimated time: 33.76
Train loss on 25 batch: 0.044336
: Epoch: 31 | Training Loss: 0.044336 | Val. Loss: 0.313391 | Val. Kappa Score: 0.5762 | Estimated time: 33.89
Train loss on 25 batch: 0.042988
: Epoch: 32 | Training Loss: 0.042988 | Val. Loss: 0.312211 | Val. Kappa Score: 0.5773 | Estimated time: 32.50
Train loss on 25 batch: 0.040963
: Epoch: 33 | Training Loss: 0.040963 | Val. Loss: 0.355207 | Val. Kappa Score: 0.5785 | Estimated time: 33.02
Train loss on 25 batch: 0.039327
: Epoch: 34 | Training Loss: 0.039327 | Val. Loss: 0.327204 | Val. Kappa Score: 0.5806 | Estimated time: 32.51
Train loss on 25 batch: 0.028871
: Epoch: 35 | Training Loss: 0.028871 | Val. Loss: 0.322929 | Val. Kappa Score: 0.5823 | Estimated time: 32.80
Train loss on 25 batch: 0.037803
: Epoch: 36 | Training Loss: 0.037803 | Val. Loss: 0.340711 | Val. Kappa Score: 0.5833 | Estimated time: 34.34
Train loss on 25 batch: 0.046102
: Epoch: 37 | Training Loss: 0.046102 | Val. Loss: 0.313782 | Val. Kappa Score: 0.5844 | Estimated time: 32.43
Train loss on 25 batch: 0.046988
: Epoch: 38 | Training Loss: 0.046988 | Val. Loss: 0.356571 | Val. Kappa Score: 0.5862 | Estimated time: 34.10
Train loss on 25 batch: 0.043728
best-train-loss: 0.043728
best-valid-loss: 0.305871
best-kappa: 0.5880
: Epoch: 39 | Training Loss: 0.043728 | Val. Loss: 0.305871 | Val. Kappa Score: 0.5880 | Estimated time: 32.57
Train loss on 25 batch: 0.029486
: Epoch: 40 | Training Loss: 0.029486 | Val. Loss: 0.333057 | Val. Kappa Score: 0.5888 | Estimated time: 33.92
Train loss on 25 batch: 0.044529
: Epoch: 41 | Training Loss: 0.044529 | Val. Loss: 0.323224 | Val. Kappa Score: 0.5901 | Estimated time: 33.24
Train loss on 25 batch: 0.042832
: Epoch: 42 | Training Loss: 0.042832 | Val. Loss: 0.317626 | Val. Kappa Score: 0.5910 | Estimated time: 33.07
Train loss on 25 batch: 0.032038
: Epoch: 43 | Training Loss: 0.032038 | Val. Loss: 0.321287 | Val. Kappa Score: 0.5925 | Estimated time: 33.01
Train loss on 25 batch: 0.035593
: Epoch: 44 | Training Loss: 0.035593 | Val. Loss: 0.324963 | Val. Kappa Score: 0.5937 | Estimated time: 33.02
Train loss on 25 batch: 0.041476
: Epoch: 45 | Training Loss: 0.041476 | Val. Loss: 0.316208 | Val. Kappa Score: 0.5945 | Estimated time: 32.64
Train loss on 25 batch: 0.036754
: Epoch: 46 | Training Loss: 0.036754 | Val. Loss: 0.364961 | Val. Kappa Score: 0.5940 | Estimated time: 32.06
Train loss on 25 batch: 0.044010
: Epoch: 47 | Training Loss: 0.044010 | Val. Loss: 0.327717 | Val. Kappa Score: 0.5949 | Estimated time: 33.58
Train loss on 25 batch: 0.033451
: Epoch: 48 | Training Loss: 0.033451 | Val. Loss: 0.336981 | Val. Kappa Score: 0.5957 | Estimated time: 32.40
Train loss on 25 batch: 0.037183
: Epoch: 49 | Training Loss: 0.037183 | Val. Loss: 0.319441 | Val. Kappa Score: 0.5974 | Estimated time: 35.06
Train loss on 25 batch: 0.040602
: Epoch: 50 | Training Loss: 0.040602 | Val. Loss: 0.349685 | Val. Kappa Score: 0.5981 | Estimated time: 33.66
Train loss on 25 batch: 0.031752
: Epoch: 51 | Training Loss: 0.031752 | Val. Loss: 0.390572 | Val. Kappa Score: 0.5983 | Estimated time: 33.69
Train loss on 25 batch: 0.037863
: Epoch: 52 | Training Loss: 0.037863 | Val. Loss: 0.326983 | Val. Kappa Score: 0.5991 | Estimated time: 32.56
Train loss on 25 batch: 0.038539
: Epoch: 53 | Training Loss: 0.038539 | Val. Loss: 0.329161 | Val. Kappa Score: 0.6001 | Estimated time: 33.95
Train loss on 25 batch: 0.057260
: Epoch: 54 | Training Loss: 0.057260 | Val. Loss: 0.326028 | Val. Kappa Score: 0.6000 | Estimated time: 33.59
time_estimated: 1793.97
n-epochs: 54
time_estimated: 1793.97
----------------------------------------

Experiment N: 17: 
date: 2019.08.06 18:56:14
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.824839
best-train-loss: 0.824839
best-valid-loss: 0.405668
best-kappa: 0.5916
: Epoch: 1 | Training Loss: 0.824839 | Val. Loss: 0.405668 | Val. Kappa Score: 0.5916 | Estimated time: 32.97
Train loss on 25 batch: 0.362361
best-train-loss: 0.362361
best-valid-loss: 0.343433
best-kappa: 0.6077
: Epoch: 2 | Training Loss: 0.362361 | Val. Loss: 0.343433 | Val. Kappa Score: 0.6077 | Estimated time: 33.67
Train loss on 25 batch: 0.189849
: Epoch: 3 | Training Loss: 0.189849 | Val. Loss: 0.348169 | Val. Kappa Score: 0.6189 | Estimated time: 33.39
Train loss on 25 batch: 0.214436
best-train-loss: 0.214436
best-valid-loss: 0.340047
best-kappa: 0.6237
: Epoch: 4 | Training Loss: 0.214436 | Val. Loss: 0.340047 | Val. Kappa Score: 0.6237 | Estimated time: 32.66
Train loss on 25 batch: 0.122397
: Epoch: 5 | Training Loss: 0.122397 | Val. Loss: 0.366420 | Val. Kappa Score: 0.6239 | Estimated time: 33.18
Train loss on 25 batch: 0.130806
best-train-loss: 0.130806
best-valid-loss: 0.301720
best-kappa: 0.6279
: Epoch: 6 | Training Loss: 0.130806 | Val. Loss: 0.301720 | Val. Kappa Score: 0.6279 | Estimated time: 31.79
Train loss on 25 batch: 0.122309
best-train-loss: 0.122309
best-valid-loss: 0.297233
best-kappa: 0.6305
: Epoch: 7 | Training Loss: 0.122309 | Val. Loss: 0.297233 | Val. Kappa Score: 0.6305 | Estimated time: 34.07
Train loss on 25 batch: 0.116948
: Epoch: 8 | Training Loss: 0.116948 | Val. Loss: 0.313430 | Val. Kappa Score: 0.6343 | Estimated time: 32.56
Train loss on 25 batch: 0.117305
: Epoch: 9 | Training Loss: 0.117305 | Val. Loss: 0.346912 | Val. Kappa Score: 0.6386 | Estimated time: 33.44
Train loss on 25 batch: 0.088687
: Epoch: 10 | Training Loss: 0.088687 | Val. Loss: 0.348525 | Val. Kappa Score: 0.6397 | Estimated time: 32.58
Train loss on 25 batch: 0.057919
: Epoch: 11 | Training Loss: 0.057919 | Val. Loss: 0.312861 | Val. Kappa Score: 0.6426 | Estimated time: 32.77
Train loss on 25 batch: 0.072453
best-train-loss: 0.072453
best-valid-loss: 0.288837
best-kappa: 0.6450
: Epoch: 12 | Training Loss: 0.072453 | Val. Loss: 0.288837 | Val. Kappa Score: 0.6450 | Estimated time: 33.83
Train loss on 25 batch: 0.039949
: Epoch: 13 | Training Loss: 0.039949 | Val. Loss: 0.305192 | Val. Kappa Score: 0.6456 | Estimated time: 33.78
Train loss on 25 batch: 0.064097
: Epoch: 14 | Training Loss: 0.064097 | Val. Loss: 0.295412 | Val. Kappa Score: 0.6474 | Estimated time: 32.34
Train loss on 25 batch: 0.042199
best-train-loss: 0.042199
best-valid-loss: 0.279948
best-kappa: 0.6479
: Epoch: 15 | Training Loss: 0.042199 | Val. Loss: 0.279948 | Val. Kappa Score: 0.6479 | Estimated time: 32.64
Train loss on 25 batch: 0.055807
: Epoch: 16 | Training Loss: 0.055807 | Val. Loss: 0.298330 | Val. Kappa Score: 0.6481 | Estimated time: 32.90
Train loss on 25 batch: 0.031564
best-train-loss: 0.031564
best-valid-loss: 0.272891
best-kappa: 0.6490
: Epoch: 17 | Training Loss: 0.031564 | Val. Loss: 0.272891 | Val. Kappa Score: 0.6490 | Estimated time: 32.29
Train loss on 25 batch: 0.045025
: Epoch: 18 | Training Loss: 0.045025 | Val. Loss: 0.294954 | Val. Kappa Score: 0.6494 | Estimated time: 32.16
Train loss on 25 batch: 0.058277
best-train-loss: 0.058277
best-valid-loss: 0.272671
best-kappa: 0.6504
: Epoch: 19 | Training Loss: 0.058277 | Val. Loss: 0.272671 | Val. Kappa Score: 0.6504 | Estimated time: 33.58
Train loss on 25 batch: 0.048270
: Epoch: 20 | Training Loss: 0.048270 | Val. Loss: 0.281791 | Val. Kappa Score: 0.6504 | Estimated time: 32.33
Train loss on 25 batch: 0.032271
: Epoch: 21 | Training Loss: 0.032271 | Val. Loss: 0.292180 | Val. Kappa Score: 0.6515 | Estimated time: 32.78
Train loss on 25 batch: 0.036057
: Epoch: 22 | Training Loss: 0.036057 | Val. Loss: 0.293129 | Val. Kappa Score: 0.6516 | Estimated time: 33.20
Train loss on 25 batch: 0.034743
: Epoch: 23 | Training Loss: 0.034743 | Val. Loss: 0.289687 | Val. Kappa Score: 0.6520 | Estimated time: 33.35
Train loss on 25 batch: 0.025477
best-train-loss: 0.025477
best-valid-loss: 0.272018
best-kappa: 0.6524
: Epoch: 24 | Training Loss: 0.025477 | Val. Loss: 0.272018 | Val. Kappa Score: 0.6524 | Estimated time: 33.17
Train loss on 25 batch: 0.029787
: Epoch: 25 | Training Loss: 0.029787 | Val. Loss: 0.297669 | Val. Kappa Score: 0.6525 | Estimated time: 34.78
Train loss on 25 batch: 0.028651
: Epoch: 26 | Training Loss: 0.028651 | Val. Loss: 0.311429 | Val. Kappa Score: 0.6531 | Estimated time: 33.19
Train loss on 25 batch: 0.026208
: Epoch: 27 | Training Loss: 0.026208 | Val. Loss: 0.286280 | Val. Kappa Score: 0.6532 | Estimated time: 34.77
Train loss on 25 batch: 0.021757
best-train-loss: 0.021757
best-valid-loss: 0.271831
best-kappa: 0.6542
: Epoch: 28 | Training Loss: 0.021757 | Val. Loss: 0.271831 | Val. Kappa Score: 0.6542 | Estimated time: 33.86
Train loss on 25 batch: 0.022493
: Epoch: 29 | Training Loss: 0.022493 | Val. Loss: 0.287038 | Val. Kappa Score: 0.6547 | Estimated time: 32.98
Train loss on 25 batch: 0.022713
: Epoch: 30 | Training Loss: 0.022713 | Val. Loss: 0.281319 | Val. Kappa Score: 0.6552 | Estimated time: 32.71
Train loss on 25 batch: 0.019801
: Epoch: 31 | Training Loss: 0.019801 | Val. Loss: 0.281890 | Val. Kappa Score: 0.6556 | Estimated time: 33.49
Train loss on 25 batch: 0.018795
: Epoch: 32 | Training Loss: 0.018795 | Val. Loss: 0.283015 | Val. Kappa Score: 0.6559 | Estimated time: 32.85
Train loss on 25 batch: 0.022767
: Epoch: 33 | Training Loss: 0.022767 | Val. Loss: 0.291620 | Val. Kappa Score: 0.6559 | Estimated time: 33.07
Train loss on 25 batch: 0.022825
best-train-loss: 0.022825
best-valid-loss: 0.270066
best-kappa: 0.6568
: Epoch: 34 | Training Loss: 0.022825 | Val. Loss: 0.270066 | Val. Kappa Score: 0.6568 | Estimated time: 32.86
Train loss on 25 batch: 0.021298
: Epoch: 35 | Training Loss: 0.021298 | Val. Loss: 0.289879 | Val. Kappa Score: 0.6571 | Estimated time: 34.66
Train loss on 25 batch: 0.019411
: Epoch: 36 | Training Loss: 0.019411 | Val. Loss: 0.280583 | Val. Kappa Score: 0.6574 | Estimated time: 34.48
Train loss on 25 batch: 0.016912
: Epoch: 37 | Training Loss: 0.016912 | Val. Loss: 0.275013 | Val. Kappa Score: 0.6577 | Estimated time: 32.83
Train loss on 25 batch: 0.020479
best-train-loss: 0.020479
best-valid-loss: 0.268941
best-kappa: 0.6578
: Epoch: 38 | Training Loss: 0.020479 | Val. Loss: 0.268941 | Val. Kappa Score: 0.6578 | Estimated time: 34.44
Train loss on 25 batch: 0.019457
: Epoch: 39 | Training Loss: 0.019457 | Val. Loss: 0.274519 | Val. Kappa Score: 0.6580 | Estimated time: 34.25
Train loss on 25 batch: 0.017429
: Epoch: 40 | Training Loss: 0.017429 | Val. Loss: 0.275970 | Val. Kappa Score: 0.6583 | Estimated time: 34.29
Train loss on 25 batch: 0.023892
: Epoch: 41 | Training Loss: 0.023892 | Val. Loss: 0.279523 | Val. Kappa Score: 0.6587 | Estimated time: 34.07
Train loss on 25 batch: 0.017658
: Epoch: 42 | Training Loss: 0.017658 | Val. Loss: 0.273725 | Val. Kappa Score: 0.6594 | Estimated time: 33.60
Train loss on 25 batch: 0.016002
: Epoch: 43 | Training Loss: 0.016002 | Val. Loss: 0.294840 | Val. Kappa Score: 0.6595 | Estimated time: 34.47
Train loss on 25 batch: 0.022803
: Epoch: 44 | Training Loss: 0.022803 | Val. Loss: 0.273633 | Val. Kappa Score: 0.6599 | Estimated time: 33.05
Train loss on 25 batch: 0.015998
: Epoch: 45 | Training Loss: 0.015998 | Val. Loss: 0.279744 | Val. Kappa Score: 0.6602 | Estimated time: 32.20
Train loss on 25 batch: 0.019651
best-train-loss: 0.019651
best-valid-loss: 0.259806
best-kappa: 0.6612
: Epoch: 46 | Training Loss: 0.019651 | Val. Loss: 0.259806 | Val. Kappa Score: 0.6612 | Estimated time: 33.08
Train loss on 25 batch: 0.021721
: Epoch: 47 | Training Loss: 0.021721 | Val. Loss: 0.281545 | Val. Kappa Score: 0.6614 | Estimated time: 34.05
Train loss on 25 batch: 0.013968
: Epoch: 48 | Training Loss: 0.013968 | Val. Loss: 0.301597 | Val. Kappa Score: 0.6617 | Estimated time: 33.46
Train loss on 25 batch: 0.017547
: Epoch: 49 | Training Loss: 0.017547 | Val. Loss: 0.266403 | Val. Kappa Score: 0.6623 | Estimated time: 33.75
Train loss on 25 batch: 0.022931
: Epoch: 50 | Training Loss: 0.022931 | Val. Loss: 0.278311 | Val. Kappa Score: 0.6630 | Estimated time: 32.43
Train loss on 25 batch: 0.016108
: Epoch: 51 | Training Loss: 0.016108 | Val. Loss: 0.280952 | Val. Kappa Score: 0.6633 | Estimated time: 33.69
Train loss on 25 batch: 0.016975
: Epoch: 52 | Training Loss: 0.016975 | Val. Loss: 0.288600 | Val. Kappa Score: 0.6632 | Estimated time: 34.45
Train loss on 25 batch: 0.018916
: Epoch: 53 | Training Loss: 0.018916 | Val. Loss: 0.275726 | Val. Kappa Score: 0.6638 | Estimated time: 34.35
Train loss on 25 batch: 0.027349
: Epoch: 54 | Training Loss: 0.027349 | Val. Loss: 0.268011 | Val. Kappa Score: 0.6646 | Estimated time: 33.26
Train loss on 25 batch: 0.016092
: Epoch: 55 | Training Loss: 0.016092 | Val. Loss: 0.308457 | Val. Kappa Score: 0.6651 | Estimated time: 32.90
Train loss on 25 batch: 0.024925
: Epoch: 56 | Training Loss: 0.024925 | Val. Loss: 0.280511 | Val. Kappa Score: 0.6654 | Estimated time: 33.97
Train loss on 25 batch: 0.016759
: Epoch: 57 | Training Loss: 0.016759 | Val. Loss: 0.276725 | Val. Kappa Score: 0.6657 | Estimated time: 33.30
Train loss on 25 batch: 0.019363
: Epoch: 58 | Training Loss: 0.019363 | Val. Loss: 0.285309 | Val. Kappa Score: 0.6660 | Estimated time: 32.23
Train loss on 25 batch: 0.018201
: Epoch: 59 | Training Loss: 0.018201 | Val. Loss: 0.280885 | Val. Kappa Score: 0.6666 | Estimated time: 32.97
Train loss on 25 batch: 0.015847
: Epoch: 60 | Training Loss: 0.015847 | Val. Loss: 0.271338 | Val. Kappa Score: 0.6669 | Estimated time: 32.56
Train loss on 25 batch: 0.012882
: Epoch: 61 | Training Loss: 0.012882 | Val. Loss: 0.282708 | Val. Kappa Score: 0.6675 | Estimated time: 32.35
time_estimated: 2032.91
n-epochs: 61
time_estimated: 2032.91
----------------------------------------

Experiment N: 18: 
date: 2019.08.06 19:30:08
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-05
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.085614
best-train-loss: 1.085614
best-valid-loss: 0.483086
best-kappa: 0.5623
: Epoch: 1 | Training Loss: 1.085614 | Val. Loss: 0.483086 | Val. Kappa Score: 0.5623 | Estimated time: 33.00
Train loss on 25 batch: 0.277485
best-train-loss: 0.277485
best-valid-loss: 0.355314
best-kappa: 0.5838
: Epoch: 2 | Training Loss: 0.277485 | Val. Loss: 0.355314 | Val. Kappa Score: 0.5838 | Estimated time: 34.82
Train loss on 25 batch: 0.202602
: Epoch: 3 | Training Loss: 0.202602 | Val. Loss: 0.378039 | Val. Kappa Score: 0.5957 | Estimated time: 33.59
Train loss on 25 batch: 0.132811
: Epoch: 4 | Training Loss: 0.132811 | Val. Loss: 0.404918 | Val. Kappa Score: 0.5785 | Estimated time: 33.00
Train loss on 25 batch: 0.109566
: Epoch: 5 | Training Loss: 0.109566 | Val. Loss: 0.359149 | Val. Kappa Score: 0.5892 | Estimated time: 33.36
Train loss on 25 batch: 0.126743
best-train-loss: 0.126743
best-valid-loss: 0.321024
best-kappa: 0.5945
: Epoch: 6 | Training Loss: 0.126743 | Val. Loss: 0.321024 | Val. Kappa Score: 0.5945 | Estimated time: 32.22
Train loss on 25 batch: 0.126697
: Epoch: 7 | Training Loss: 0.126697 | Val. Loss: 0.326118 | Val. Kappa Score: 0.6036 | Estimated time: 33.33
Train loss on 25 batch: 0.084931
: Epoch: 8 | Training Loss: 0.084931 | Val. Loss: 0.366813 | Val. Kappa Score: 0.6061 | Estimated time: 32.96
Train loss on 25 batch: 0.130297
: Epoch: 9 | Training Loss: 0.130297 | Val. Loss: 0.342911 | Val. Kappa Score: 0.6131 | Estimated time: 33.40
Train loss on 25 batch: 0.088921
: Epoch: 10 | Training Loss: 0.088921 | Val. Loss: 0.376913 | Val. Kappa Score: 0.6162 | Estimated time: 33.99
Train loss on 25 batch: 0.058591
: Epoch: 11 | Training Loss: 0.058591 | Val. Loss: 0.387902 | Val. Kappa Score: 0.6178 | Estimated time: 32.38
Train loss on 25 batch: 0.104543
: Epoch: 12 | Training Loss: 0.104543 | Val. Loss: 0.336364 | Val. Kappa Score: 0.6170 | Estimated time: 34.04
Train loss on 25 batch: 0.053653
: Epoch: 13 | Training Loss: 0.053653 | Val. Loss: 0.341278 | Val. Kappa Score: 0.6158 | Estimated time: 32.94
Train loss on 25 batch: 0.073827
: Epoch: 14 | Training Loss: 0.073827 | Val. Loss: 0.349503 | Val. Kappa Score: 0.6172 | Estimated time: 31.45
Train loss on 25 batch: 0.050444
: Epoch: 15 | Training Loss: 0.050444 | Val. Loss: 0.328745 | Val. Kappa Score: 0.6188 | Estimated time: 33.02
Train loss on 25 batch: 0.075106
: Epoch: 16 | Training Loss: 0.075106 | Val. Loss: 0.357028 | Val. Kappa Score: 0.6202 | Estimated time: 33.20
Train loss on 25 batch: 0.039344
: Epoch: 17 | Training Loss: 0.039344 | Val. Loss: 0.323728 | Val. Kappa Score: 0.6222 | Estimated time: 32.79
Train loss on 25 batch: 0.058558
: Epoch: 18 | Training Loss: 0.058558 | Val. Loss: 0.326288 | Val. Kappa Score: 0.6231 | Estimated time: 33.01
Train loss on 25 batch: 0.096347
best-train-loss: 0.096347
best-valid-loss: 0.294837
best-kappa: 0.6228
: Epoch: 19 | Training Loss: 0.096347 | Val. Loss: 0.294837 | Val. Kappa Score: 0.6228 | Estimated time: 33.68
Train loss on 25 batch: 0.068165
: Epoch: 20 | Training Loss: 0.068165 | Val. Loss: 0.322963 | Val. Kappa Score: 0.6237 | Estimated time: 33.81
Train loss on 25 batch: 0.043555
: Epoch: 21 | Training Loss: 0.043555 | Val. Loss: 0.305460 | Val. Kappa Score: 0.6244 | Estimated time: 33.70
Train loss on 25 batch: 0.045732
: Epoch: 22 | Training Loss: 0.045732 | Val. Loss: 0.299668 | Val. Kappa Score: 0.6259 | Estimated time: 33.25
Train loss on 25 batch: 0.036366
: Epoch: 23 | Training Loss: 0.036366 | Val. Loss: 0.312628 | Val. Kappa Score: 0.6280 | Estimated time: 34.06
Train loss on 25 batch: 0.032833
: Epoch: 24 | Training Loss: 0.032833 | Val. Loss: 0.296885 | Val. Kappa Score: 0.6290 | Estimated time: 32.98
Train loss on 25 batch: 0.029191
: Epoch: 25 | Training Loss: 0.029191 | Val. Loss: 0.347644 | Val. Kappa Score: 0.6302 | Estimated time: 34.17
Train loss on 25 batch: 0.049216
: Epoch: 26 | Training Loss: 0.049216 | Val. Loss: 0.316457 | Val. Kappa Score: 0.6315 | Estimated time: 32.65
Train loss on 25 batch: 0.029589
: Epoch: 27 | Training Loss: 0.029589 | Val. Loss: 0.300921 | Val. Kappa Score: 0.6318 | Estimated time: 33.28
Train loss on 25 batch: 0.033669
: Epoch: 28 | Training Loss: 0.033669 | Val. Loss: 0.296198 | Val. Kappa Score: 0.6328 | Estimated time: 32.24
Train loss on 25 batch: 0.027324
: Epoch: 29 | Training Loss: 0.027324 | Val. Loss: 0.299614 | Val. Kappa Score: 0.6340 | Estimated time: 32.91
Train loss on 25 batch: 0.028812
: Epoch: 30 | Training Loss: 0.028812 | Val. Loss: 0.310718 | Val. Kappa Score: 0.6345 | Estimated time: 33.19
Train loss on 25 batch: 0.028599
best-train-loss: 0.028599
best-valid-loss: 0.292182
best-kappa: 0.6353
: Epoch: 31 | Training Loss: 0.028599 | Val. Loss: 0.292182 | Val. Kappa Score: 0.6353 | Estimated time: 34.48
Train loss on 25 batch: 0.028180
: Epoch: 32 | Training Loss: 0.028180 | Val. Loss: 0.294325 | Val. Kappa Score: 0.6358 | Estimated time: 32.75
Train loss on 25 batch: 0.025472
: Epoch: 33 | Training Loss: 0.025472 | Val. Loss: 0.305566 | Val. Kappa Score: 0.6364 | Estimated time: 33.69
Train loss on 25 batch: 0.029552
best-train-loss: 0.029552
best-valid-loss: 0.288143
best-kappa: 0.6374
: Epoch: 34 | Training Loss: 0.029552 | Val. Loss: 0.288143 | Val. Kappa Score: 0.6374 | Estimated time: 32.90
Train loss on 25 batch: 0.020863
: Epoch: 35 | Training Loss: 0.020863 | Val. Loss: 0.303355 | Val. Kappa Score: 0.6378 | Estimated time: 33.26
Train loss on 25 batch: 0.024605
: Epoch: 36 | Training Loss: 0.024605 | Val. Loss: 0.302734 | Val. Kappa Score: 0.6379 | Estimated time: 34.37
Train loss on 25 batch: 0.022630
: Epoch: 37 | Training Loss: 0.022630 | Val. Loss: 0.295810 | Val. Kappa Score: 0.6388 | Estimated time: 33.51
Train loss on 25 batch: 0.022653
: Epoch: 38 | Training Loss: 0.022653 | Val. Loss: 0.290809 | Val. Kappa Score: 0.6392 | Estimated time: 32.05
Train loss on 25 batch: 0.025336
: Epoch: 39 | Training Loss: 0.025336 | Val. Loss: 0.303709 | Val. Kappa Score: 0.6395 | Estimated time: 34.09
Train loss on 25 batch: 0.019269
: Epoch: 40 | Training Loss: 0.019269 | Val. Loss: 0.305625 | Val. Kappa Score: 0.6402 | Estimated time: 33.05
Train loss on 25 batch: 0.029943
: Epoch: 41 | Training Loss: 0.029943 | Val. Loss: 0.301409 | Val. Kappa Score: 0.6407 | Estimated time: 34.22
Train loss on 25 batch: 0.024515
: Epoch: 42 | Training Loss: 0.024515 | Val. Loss: 0.306754 | Val. Kappa Score: 0.6411 | Estimated time: 33.24
Train loss on 25 batch: 0.018686
: Epoch: 43 | Training Loss: 0.018686 | Val. Loss: 0.310768 | Val. Kappa Score: 0.6416 | Estimated time: 33.99
Train loss on 25 batch: 0.025032
: Epoch: 44 | Training Loss: 0.025032 | Val. Loss: 0.297232 | Val. Kappa Score: 0.6423 | Estimated time: 33.02
Train loss on 25 batch: 0.022206
: Epoch: 45 | Training Loss: 0.022206 | Val. Loss: 0.291449 | Val. Kappa Score: 0.6429 | Estimated time: 32.31
Train loss on 25 batch: 0.023965
best-train-loss: 0.023965
best-valid-loss: 0.279988
best-kappa: 0.6435
: Epoch: 46 | Training Loss: 0.023965 | Val. Loss: 0.279988 | Val. Kappa Score: 0.6435 | Estimated time: 32.62
Train loss on 25 batch: 0.020484
: Epoch: 47 | Training Loss: 0.020484 | Val. Loss: 0.309904 | Val. Kappa Score: 0.6440 | Estimated time: 32.55
Train loss on 25 batch: 0.018724
: Epoch: 48 | Training Loss: 0.018724 | Val. Loss: 0.311028 | Val. Kappa Score: 0.6443 | Estimated time: 33.02
Train loss on 25 batch: 0.019836
: Epoch: 49 | Training Loss: 0.019836 | Val. Loss: 0.289882 | Val. Kappa Score: 0.6449 | Estimated time: 34.95
Train loss on 25 batch: 0.023363
: Epoch: 50 | Training Loss: 0.023363 | Val. Loss: 0.300043 | Val. Kappa Score: 0.6457 | Estimated time: 32.32
Train loss on 25 batch: 0.014945
: Epoch: 51 | Training Loss: 0.014945 | Val. Loss: 0.312224 | Val. Kappa Score: 0.6464 | Estimated time: 33.61
Train loss on 25 batch: 0.014532
: Epoch: 52 | Training Loss: 0.014532 | Val. Loss: 0.293506 | Val. Kappa Score: 0.6468 | Estimated time: 33.22
Train loss on 25 batch: 0.017851
: Epoch: 53 | Training Loss: 0.017851 | Val. Loss: 0.308854 | Val. Kappa Score: 0.6477 | Estimated time: 35.01
Train loss on 25 batch: 0.023887
: Epoch: 54 | Training Loss: 0.023887 | Val. Loss: 0.291663 | Val. Kappa Score: 0.6482 | Estimated time: 32.79
Train loss on 25 batch: 0.015589
: Epoch: 55 | Training Loss: 0.015589 | Val. Loss: 0.320523 | Val. Kappa Score: 0.6486 | Estimated time: 33.47
Train loss on 25 batch: 0.017208
: Epoch: 56 | Training Loss: 0.017208 | Val. Loss: 0.305056 | Val. Kappa Score: 0.6490 | Estimated time: 33.08
Train loss on 25 batch: 0.014124
: Epoch: 57 | Training Loss: 0.014124 | Val. Loss: 0.280478 | Val. Kappa Score: 0.6496 | Estimated time: 33.03
Train loss on 25 batch: 0.015984
: Epoch: 58 | Training Loss: 0.015984 | Val. Loss: 0.295825 | Val. Kappa Score: 0.6500 | Estimated time: 32.89
Train loss on 25 batch: 0.017478
: Epoch: 59 | Training Loss: 0.017478 | Val. Loss: 0.292483 | Val. Kappa Score: 0.6500 | Estimated time: 32.64
Train loss on 25 batch: 0.015787
: Epoch: 60 | Training Loss: 0.015787 | Val. Loss: 0.307186 | Val. Kappa Score: 0.6500 | Estimated time: 32.30
Train loss on 25 batch: 0.012396
: Epoch: 61 | Training Loss: 0.012396 | Val. Loss: 0.291844 | Val. Kappa Score: 0.6503 | Estimated time: 32.32
time_estimated: 2028.09
n-epochs: 61
time_estimated: 2028.10
----------------------------------------

Experiment N: 19: 
date: 2019.08.06 20:03:57
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.322996
best-train-loss: 1.322996
best-valid-loss: 0.454647
best-kappa: 0.5413
: Epoch: 1 | Training Loss: 1.322996 | Val. Loss: 0.454647 | Val. Kappa Score: 0.5413 | Estimated time: 34.03
Train loss on 25 batch: 0.357060
best-train-loss: 0.357060
best-valid-loss: 0.387202
best-kappa: 0.5633
: Epoch: 2 | Training Loss: 0.357060 | Val. Loss: 0.387202 | Val. Kappa Score: 0.5633 | Estimated time: 33.27
Train loss on 25 batch: 0.260095
: Epoch: 3 | Training Loss: 0.260095 | Val. Loss: 0.428596 | Val. Kappa Score: 0.5714 | Estimated time: 33.39
Train loss on 25 batch: 0.185459
best-train-loss: 0.185459
best-valid-loss: 0.339170
best-kappa: 0.5830
: Epoch: 4 | Training Loss: 0.185459 | Val. Loss: 0.339170 | Val. Kappa Score: 0.5830 | Estimated time: 32.54
Train loss on 25 batch: 0.121849
: Epoch: 5 | Training Loss: 0.121849 | Val. Loss: 0.407340 | Val. Kappa Score: 0.5927 | Estimated time: 33.43
Train loss on 25 batch: 0.125770
: Epoch: 6 | Training Loss: 0.125770 | Val. Loss: 0.349864 | Val. Kappa Score: 0.5963 | Estimated time: 32.70
Train loss on 25 batch: 0.109824
: Epoch: 7 | Training Loss: 0.109824 | Val. Loss: 0.345894 | Val. Kappa Score: 0.6023 | Estimated time: 33.14
Train loss on 25 batch: 0.079316
best-train-loss: 0.079316
best-valid-loss: 0.331172
best-kappa: 0.6062
: Epoch: 8 | Training Loss: 0.079316 | Val. Loss: 0.331172 | Val. Kappa Score: 0.6062 | Estimated time: 32.71
Train loss on 25 batch: 0.095214
: Epoch: 9 | Training Loss: 0.095214 | Val. Loss: 0.347170 | Val. Kappa Score: 0.6100 | Estimated time: 33.19
Train loss on 25 batch: 0.082577
: Epoch: 10 | Training Loss: 0.082577 | Val. Loss: 0.352212 | Val. Kappa Score: 0.6107 | Estimated time: 32.35
Train loss on 25 batch: 0.072973
: Epoch: 11 | Training Loss: 0.072973 | Val. Loss: 0.353868 | Val. Kappa Score: 0.6127 | Estimated time: 32.86
Train loss on 25 batch: 0.074249
: Epoch: 12 | Training Loss: 0.074249 | Val. Loss: 0.352804 | Val. Kappa Score: 0.6138 | Estimated time: 33.58
Train loss on 25 batch: 0.065590
: Epoch: 13 | Training Loss: 0.065590 | Val. Loss: 0.343393 | Val. Kappa Score: 0.6139 | Estimated time: 33.60
Train loss on 25 batch: 0.061793
: Epoch: 14 | Training Loss: 0.061793 | Val. Loss: 0.351140 | Val. Kappa Score: 0.6151 | Estimated time: 32.47
Train loss on 25 batch: 0.062998
: Epoch: 15 | Training Loss: 0.062998 | Val. Loss: 0.342895 | Val. Kappa Score: 0.6146 | Estimated time: 34.06
Train loss on 25 batch: 0.070985
: Epoch: 16 | Training Loss: 0.070985 | Val. Loss: 0.344554 | Val. Kappa Score: 0.6141 | Estimated time: 32.44
Train loss on 25 batch: 0.040930
: Epoch: 17 | Training Loss: 0.040930 | Val. Loss: 0.384201 | Val. Kappa Score: 0.6154 | Estimated time: 33.11
Train loss on 25 batch: 0.080081
: Epoch: 18 | Training Loss: 0.080081 | Val. Loss: 0.428124 | Val. Kappa Score: 0.6152 | Estimated time: 32.76
Train loss on 25 batch: 0.114319
: Epoch: 19 | Training Loss: 0.114319 | Val. Loss: 0.348232 | Val. Kappa Score: 0.6158 | Estimated time: 34.29
Train loss on 25 batch: 0.049233
: Epoch: 20 | Training Loss: 0.049233 | Val. Loss: 0.332730 | Val. Kappa Score: 0.6162 | Estimated time: 34.72
Train loss on 25 batch: 0.038421
: Epoch: 21 | Training Loss: 0.038421 | Val. Loss: 0.334162 | Val. Kappa Score: 0.6164 | Estimated time: 33.62
Train loss on 25 batch: 0.062311
: Epoch: 22 | Training Loss: 0.062311 | Val. Loss: 0.341061 | Val. Kappa Score: 0.6168 | Estimated time: 33.96
Train loss on 25 batch: 0.052260
: Epoch: 23 | Training Loss: 0.052260 | Val. Loss: 0.342782 | Val. Kappa Score: 0.6171 | Estimated time: 33.56
time_estimated: 766.31
n-epochs: 23
time_estimated: 766.32
----------------------------------------

LR: 0.00015, BATCH_SIZE: 64, P_HORIZONTALFLIP=0.1 

Experiment N: 20: 
date: 2019.08.06 21:08:37
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
best-train-loss: 0.803977
best-valid-loss: 0.390829
best-kappa: 0.5968
: Epoch: 1 | Training Loss: 0.803977 | Val. Loss: 0.390829 | Val. Kappa Score: 0.5968 | Estimated time: 33.65
Train loss on 25 batch: 0.379721
: Epoch: 2 | Training Loss: 0.379721 | Val. Loss: 0.485985 | Val. Kappa Score: 0.5850 | Estimated time: 33.85
Train loss on 25 batch: 0.201845
: Epoch: 3 | Training Loss: 0.201845 | Val. Loss: 0.571235 | Val. Kappa Score: 0.5369 | Estimated time: 34.87
Train loss on 25 batch: 0.242747
best-train-loss: 0.242747
best-valid-loss: 0.338722
best-kappa: 0.5605
: Epoch: 4 | Training Loss: 0.242747 | Val. Loss: 0.338722 | Val. Kappa Score: 0.5605 | Estimated time: 32.91
Train loss on 25 batch: 0.126876
best-train-loss: 0.126876
best-valid-loss: 0.325506
best-kappa: 0.5749
: Epoch: 5 | Training Loss: 0.126876 | Val. Loss: 0.325506 | Val. Kappa Score: 0.5749 | Estimated time: 33.18
Train loss on 25 batch: 0.145124
best-train-loss: 0.145124
best-valid-loss: 0.291815
best-kappa: 0.5889
: Epoch: 6 | Training Loss: 0.145124 | Val. Loss: 0.291815 | Val. Kappa Score: 0.5889 | Estimated time: 32.71
Train loss on 25 batch: 0.122500
: Epoch: 7 | Training Loss: 0.122500 | Val. Loss: 0.292707 | Val. Kappa Score: 0.6006 | Estimated time: 33.31
Train loss on 25 batch: 0.125324
: Epoch: 8 | Training Loss: 0.125324 | Val. Loss: 0.324141 | Val. Kappa Score: 0.6069 | Estimated time: 32.77
Train loss on 25 batch: 0.106849
: Epoch: 9 | Training Loss: 0.106849 | Val. Loss: 0.327609 | Val. Kappa Score: 0.6126 | Estimated time: 34.31
Train loss on 25 batch: 0.091795
best-train-loss: 0.091795
best-valid-loss: 0.291556
best-kappa: 0.6183
: Epoch: 10 | Training Loss: 0.091795 | Val. Loss: 0.291556 | Val. Kappa Score: 0.6183 | Estimated time: 32.45
Train loss on 25 batch: 0.061365
: Epoch: 11 | Training Loss: 0.061365 | Val. Loss: 0.293511 | Val. Kappa Score: 0.6256 | Estimated time: 31.99
Train loss on 25 batch: 0.074632
best-train-loss: 0.074632
best-valid-loss: 0.281012
best-kappa: 0.6278
: Epoch: 12 | Training Loss: 0.074632 | Val. Loss: 0.281012 | Val. Kappa Score: 0.6278 | Estimated time: 34.35
Train loss on 25 batch: 0.041334
: Epoch: 13 | Training Loss: 0.041334 | Val. Loss: 0.306715 | Val. Kappa Score: 0.6306 | Estimated time: 32.97
Train loss on 25 batch: 0.085291
: Epoch: 14 | Training Loss: 0.085291 | Val. Loss: 0.283662 | Val. Kappa Score: 0.6336 | Estimated time: 32.73
Train loss on 25 batch: 0.048131
best-train-loss: 0.048131
best-valid-loss: 0.280068
best-kappa: 0.6343
: Epoch: 15 | Training Loss: 0.048131 | Val. Loss: 0.280068 | Val. Kappa Score: 0.6343 | Estimated time: 32.94
Train loss on 25 batch: 0.063779
: Epoch: 16 | Training Loss: 0.063779 | Val. Loss: 0.316915 | Val. Kappa Score: 0.6372 | Estimated time: 33.40
Train loss on 25 batch: 0.035310
best-train-loss: 0.035310
best-valid-loss: 0.273587
best-kappa: 0.6399
: Epoch: 17 | Training Loss: 0.035310 | Val. Loss: 0.273587 | Val. Kappa Score: 0.6399 | Estimated time: 33.23
Train loss on 25 batch: 0.037314
: Epoch: 18 | Training Loss: 0.037314 | Val. Loss: 0.293120 | Val. Kappa Score: 0.6422 | Estimated time: 33.96
Train loss on 25 batch: 0.047514
: Epoch: 19 | Training Loss: 0.047514 | Val. Loss: 0.276264 | Val. Kappa Score: 0.6437 | Estimated time: 34.45
Train loss on 25 batch: 0.036543
: Epoch: 20 | Training Loss: 0.036543 | Val. Loss: 0.286634 | Val. Kappa Score: 0.6462 | Estimated time: 33.28
Train loss on 25 batch: 0.029944
: Epoch: 21 | Training Loss: 0.029944 | Val. Loss: 0.289314 | Val. Kappa Score: 0.6471 | Estimated time: 33.11
Train loss on 25 batch: 0.029484
best-train-loss: 0.029484
best-valid-loss: 0.272962
best-kappa: 0.6485
: Epoch: 22 | Training Loss: 0.029484 | Val. Loss: 0.272962 | Val. Kappa Score: 0.6485 | Estimated time: 33.71
Train loss on 25 batch: 0.031151
: Epoch: 23 | Training Loss: 0.031151 | Val. Loss: 0.287340 | Val. Kappa Score: 0.6497 | Estimated time: 34.12
Train loss on 25 batch: 0.021981
best-train-loss: 0.021981
best-valid-loss: 0.263108
best-kappa: 0.6510
: Epoch: 24 | Training Loss: 0.021981 | Val. Loss: 0.263108 | Val. Kappa Score: 0.6510 | Estimated time: 34.56
Train loss on 25 batch: 0.032037
: Epoch: 25 | Training Loss: 0.032037 | Val. Loss: 0.288556 | Val. Kappa Score: 0.6521 | Estimated time: 35.08
Train loss on 25 batch: 0.025080
: Epoch: 26 | Training Loss: 0.025080 | Val. Loss: 0.288079 | Val. Kappa Score: 0.6532 | Estimated time: 34.30
Train loss on 25 batch: 0.022648
: Epoch: 27 | Training Loss: 0.022648 | Val. Loss: 0.289174 | Val. Kappa Score: 0.6537 | Estimated time: 34.50
Train loss on 25 batch: 0.021501
: Epoch: 28 | Training Loss: 0.021501 | Val. Loss: 0.269007 | Val. Kappa Score: 0.6544 | Estimated time: 33.94
Train loss on 25 batch: 0.023027
: Epoch: 29 | Training Loss: 0.023027 | Val. Loss: 0.295080 | Val. Kappa Score: 0.6553 | Estimated time: 33.60
Train loss on 25 batch: 0.022421
: Epoch: 30 | Training Loss: 0.022421 | Val. Loss: 0.267335 | Val. Kappa Score: 0.6561 | Estimated time: 33.31
Train loss on 25 batch: 0.020400
: Epoch: 31 | Training Loss: 0.020400 | Val. Loss: 0.273433 | Val. Kappa Score: 0.6564 | Estimated time: 34.00
Train loss on 25 batch: 0.021917
: Epoch: 32 | Training Loss: 0.021917 | Val. Loss: 0.290576 | Val. Kappa Score: 0.6574 | Estimated time: 34.09
Train loss on 25 batch: 0.023643
: Epoch: 33 | Training Loss: 0.023643 | Val. Loss: 0.279452 | Val. Kappa Score: 0.6581 | Estimated time: 34.99
Train loss on 25 batch: 0.024017
: Epoch: 34 | Training Loss: 0.024017 | Val. Loss: 0.280135 | Val. Kappa Score: 0.6590 | Estimated time: 33.91
Train loss on 25 batch: 0.019465
: Epoch: 35 | Training Loss: 0.019465 | Val. Loss: 0.279501 | Val. Kappa Score: 0.6596 | Estimated time: 34.69
Train loss on 25 batch: 0.018371
: Epoch: 36 | Training Loss: 0.018371 | Val. Loss: 0.265316 | Val. Kappa Score: 0.6601 | Estimated time: 35.62
Train loss on 25 batch: 0.017506
: Epoch: 37 | Training Loss: 0.017506 | Val. Loss: 0.274257 | Val. Kappa Score: 0.6611 | Estimated time: 34.29
Train loss on 25 batch: 0.019302
: Epoch: 38 | Training Loss: 0.019302 | Val. Loss: 0.270668 | Val. Kappa Score: 0.6616 | Estimated time: 34.25
Train loss on 25 batch: 0.020094
: Epoch: 39 | Training Loss: 0.020094 | Val. Loss: 0.268566 | Val. Kappa Score: 0.6624 | Estimated time: 34.38
time_estimated: 1318.98
n-epochs: 39
time_estimated: 1318.98
----------------------------------------


LR: 0.00015, BATCH_SIZE: 64, P_HORIZONTALFLIP=0.2 

Experiment N: 21: 
date: 2019.08.06 21:30:37
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
best-train-loss: 0.803977
best-valid-loss: 0.390829
best-kappa: 0.5968
: Epoch: 1 | Training Loss: 0.803977 | Val. Loss: 0.390829 | Val. Kappa Score: 0.5968 | Estimated time: 33.52
Train loss on 25 batch: 0.379721
: Epoch: 2 | Training Loss: 0.379721 | Val. Loss: 0.485985 | Val. Kappa Score: 0.5850 | Estimated time: 34.98
Train loss on 25 batch: 0.201845
: Epoch: 3 | Training Loss: 0.201845 | Val. Loss: 0.571235 | Val. Kappa Score: 0.5369 | Estimated time: 34.32
Train loss on 25 batch: 0.242747
best-train-loss: 0.242747
best-valid-loss: 0.338722
best-kappa: 0.5605
: Epoch: 4 | Training Loss: 0.242747 | Val. Loss: 0.338722 | Val. Kappa Score: 0.5605 | Estimated time: 33.35
Train loss on 25 batch: 0.126876
best-train-loss: 0.126876
best-valid-loss: 0.325506
best-kappa: 0.5749
: Epoch: 5 | Training Loss: 0.126876 | Val. Loss: 0.325506 | Val. Kappa Score: 0.5749 | Estimated time: 35.51
Train loss on 25 batch: 0.145124
best-train-loss: 0.145124
best-valid-loss: 0.291815
best-kappa: 0.5889
: Epoch: 6 | Training Loss: 0.145124 | Val. Loss: 0.291815 | Val. Kappa Score: 0.5889 | Estimated time: 33.95
Train loss on 25 batch: 0.122500
: Epoch: 7 | Training Loss: 0.122500 | Val. Loss: 0.292707 | Val. Kappa Score: 0.6006 | Estimated time: 34.67
Train loss on 25 batch: 0.125324
: Epoch: 8 | Training Loss: 0.125324 | Val. Loss: 0.324141 | Val. Kappa Score: 0.6069 | Estimated time: 33.68
Train loss on 25 batch: 0.106849
: Epoch: 9 | Training Loss: 0.106849 | Val. Loss: 0.327609 | Val. Kappa Score: 0.6126 | Estimated time: 34.47
Train loss on 25 batch: 0.091795
best-train-loss: 0.091795
best-valid-loss: 0.291556
best-kappa: 0.6183
: Epoch: 10 | Training Loss: 0.091795 | Val. Loss: 0.291556 | Val. Kappa Score: 0.6183 | Estimated time: 34.83
Train loss on 25 batch: 0.061365
: Epoch: 11 | Training Loss: 0.061365 | Val. Loss: 0.293511 | Val. Kappa Score: 0.6256 | Estimated time: 32.94
Train loss on 25 batch: 0.074632
best-train-loss: 0.074632
best-valid-loss: 0.281012
best-kappa: 0.6278
: Epoch: 12 | Training Loss: 0.074632 | Val. Loss: 0.281012 | Val. Kappa Score: 0.6278 | Estimated time: 33.74
Train loss on 25 batch: 0.041334
: Epoch: 13 | Training Loss: 0.041334 | Val. Loss: 0.306715 | Val. Kappa Score: 0.6306 | Estimated time: 33.84
Train loss on 25 batch: 0.085291
: Epoch: 14 | Training Loss: 0.085291 | Val. Loss: 0.283662 | Val. Kappa Score: 0.6336 | Estimated time: 33.04
Train loss on 25 batch: 0.048131
best-train-loss: 0.048131
best-valid-loss: 0.280068
best-kappa: 0.6343
: Epoch: 15 | Training Loss: 0.048131 | Val. Loss: 0.280068 | Val. Kappa Score: 0.6343 | Estimated time: 34.25
Train loss on 25 batch: 0.063779
: Epoch: 16 | Training Loss: 0.063779 | Val. Loss: 0.316915 | Val. Kappa Score: 0.6372 | Estimated time: 33.49
Train loss on 25 batch: 0.035310
best-train-loss: 0.035310
best-valid-loss: 0.273587
best-kappa: 0.6399
: Epoch: 17 | Training Loss: 0.035310 | Val. Loss: 0.273587 | Val. Kappa Score: 0.6399 | Estimated time: 33.30
Train loss on 25 batch: 0.037314
: Epoch: 18 | Training Loss: 0.037314 | Val. Loss: 0.293120 | Val. Kappa Score: 0.6422 | Estimated time: 32.95
Train loss on 25 batch: 0.047514
: Epoch: 19 | Training Loss: 0.047514 | Val. Loss: 0.276264 | Val. Kappa Score: 0.6437 | Estimated time: 33.15
Train loss on 25 batch: 0.036543
: Epoch: 20 | Training Loss: 0.036543 | Val. Loss: 0.286634 | Val. Kappa Score: 0.6462 | Estimated time: 33.51
Train loss on 25 batch: 0.029944
: Epoch: 21 | Training Loss: 0.029944 | Val. Loss: 0.289314 | Val. Kappa Score: 0.6471 | Estimated time: 32.87
Train loss on 25 batch: 0.029484
best-train-loss: 0.029484
best-valid-loss: 0.272962
best-kappa: 0.6485
: Epoch: 22 | Training Loss: 0.029484 | Val. Loss: 0.272962 | Val. Kappa Score: 0.6485 | Estimated time: 33.70
Train loss on 25 batch: 0.031151
: Epoch: 23 | Training Loss: 0.031151 | Val. Loss: 0.287340 | Val. Kappa Score: 0.6497 | Estimated time: 33.57
Train loss on 25 batch: 0.021981
best-train-loss: 0.021981
best-valid-loss: 0.263108
best-kappa: 0.6510
: Epoch: 24 | Training Loss: 0.021981 | Val. Loss: 0.263108 | Val. Kappa Score: 0.6510 | Estimated time: 34.28
Train loss on 25 batch: 0.032037
: Epoch: 25 | Training Loss: 0.032037 | Val. Loss: 0.288556 | Val. Kappa Score: 0.6521 | Estimated time: 34.05
Train loss on 25 batch: 0.025080
: Epoch: 26 | Training Loss: 0.025080 | Val. Loss: 0.288079 | Val. Kappa Score: 0.6532 | Estimated time: 33.57
Train loss on 25 batch: 0.022648
: Epoch: 27 | Training Loss: 0.022648 | Val. Loss: 0.289174 | Val. Kappa Score: 0.6537 | Estimated time: 33.08
Train loss on 25 batch: 0.021501
: Epoch: 28 | Training Loss: 0.021501 | Val. Loss: 0.269007 | Val. Kappa Score: 0.6544 | Estimated time: 32.78
Train loss on 25 batch: 0.023027
: Epoch: 29 | Training Loss: 0.023027 | Val. Loss: 0.295080 | Val. Kappa Score: 0.6553 | Estimated time: 34.24
Train loss on 25 batch: 0.022421
: Epoch: 30 | Training Loss: 0.022421 | Val. Loss: 0.267335 | Val. Kappa Score: 0.6561 | Estimated time: 34.81
Train loss on 25 batch: 0.020400
: Epoch: 31 | Training Loss: 0.020400 | Val. Loss: 0.273433 | Val. Kappa Score: 0.6564 | Estimated time: 34.74
Train loss on 25 batch: 0.021917
: Epoch: 32 | Training Loss: 0.021917 | Val. Loss: 0.290576 | Val. Kappa Score: 0.6574 | Estimated time: 34.63
Train loss on 25 batch: 0.023643
: Epoch: 33 | Training Loss: 0.023643 | Val. Loss: 0.279452 | Val. Kappa Score: 0.6581 | Estimated time: 32.61
Train loss on 25 batch: 0.024017
: Epoch: 34 | Training Loss: 0.024017 | Val. Loss: 0.280135 | Val. Kappa Score: 0.6590 | Estimated time: 33.36
Train loss on 25 batch: 0.019465
: Epoch: 35 | Training Loss: 0.019465 | Val. Loss: 0.279501 | Val. Kappa Score: 0.6596 | Estimated time: 34.15
Train loss on 25 batch: 0.018371
: Epoch: 36 | Training Loss: 0.018371 | Val. Loss: 0.265316 | Val. Kappa Score: 0.6601 | Estimated time: 35.13
Train loss on 25 batch: 0.017506
: Epoch: 37 | Training Loss: 0.017506 | Val. Loss: 0.274257 | Val. Kappa Score: 0.6611 | Estimated time: 33.27
Train loss on 25 batch: 0.019302
: Epoch: 38 | Training Loss: 0.019302 | Val. Loss: 0.270668 | Val. Kappa Score: 0.6616 | Estimated time: 33.30
Train loss on 25 batch: 0.020094
: Epoch: 39 | Training Loss: 0.020094 | Val. Loss: 0.268566 | Val. Kappa Score: 0.6624 | Estimated time: 33.70
time_estimated: 1320.60
n-epochs: 39
time_estimated: 1320.61
----------------------------------------

Experiment N: 22: 
date: 2019.08.06 21:52:38
data-type: new_comp
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
----------------------------------------

Experiment N: 22: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.3


: 
date: 2019.08.06 22:00:46
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
best-train-loss: 0.803977
best-valid-loss: 0.390829
best-kappa: 0.8513
: Epoch: 1 | Training Loss: 0.803977 | Val. Loss: 0.390829 | Val. Kappa Score: 0.8513 | Estimated time: 32.37
Train loss on 25 batch: 0.379721
: Epoch: 2 | Training Loss: 0.379721 | Val. Loss: 0.485985 | Val. Kappa Score: 0.8305 | Estimated time: 34.04
Train loss on 25 batch: 0.201845
: Epoch: 3 | Training Loss: 0.201845 | Val. Loss: 0.571235 | Val. Kappa Score: 0.8147 | Estimated time: 33.04
Train loss on 25 batch: 0.242747
best-train-loss: 0.242747
best-valid-loss: 0.338722
best-kappa: 0.8290
: Epoch: 4 | Training Loss: 0.242747 | Val. Loss: 0.338722 | Val. Kappa Score: 0.8290 | Estimated time: 33.17
Train loss on 25 batch: 0.126876
best-train-loss: 0.126876
best-valid-loss: 0.325506
best-kappa: 0.8386
: Epoch: 5 | Training Loss: 0.126876 | Val. Loss: 0.325506 | Val. Kappa Score: 0.8386 | Estimated time: 33.28
Train loss on 25 batch: 0.145124
best-train-loss: 0.145124
best-valid-loss: 0.291815
best-kappa: 0.8483
: Epoch: 6 | Training Loss: 0.145124 | Val. Loss: 0.291815 | Val. Kappa Score: 0.8483 | Estimated time: 33.57
Train loss on 25 batch: 0.122500
: Epoch: 7 | Training Loss: 0.122500 | Val. Loss: 0.292707 | Val. Kappa Score: 0.8547 | Estimated time: 33.04
Train loss on 25 batch: 0.125324
: Epoch: 8 | Training Loss: 0.125324 | Val. Loss: 0.324141 | Val. Kappa Score: 0.8575 | Estimated time: 33.17
Train loss on 25 batch: 0.106849
: Epoch: 9 | Training Loss: 0.106849 | Val. Loss: 0.327609 | Val. Kappa Score: 0.8590 | Estimated time: 34.08
Train loss on 25 batch: 0.091795
best-train-loss: 0.091795
best-valid-loss: 0.291556
best-kappa: 0.8618
: Epoch: 10 | Training Loss: 0.091795 | Val. Loss: 0.291556 | Val. Kappa Score: 0.8618 | Estimated time: 33.62
Train loss on 25 batch: 0.061365
: Epoch: 11 | Training Loss: 0.061365 | Val. Loss: 0.293511 | Val. Kappa Score: 0.8648 | Estimated time: 33.68
Train loss on 25 batch: 0.074632
best-train-loss: 0.074632
best-valid-loss: 0.281012
best-kappa: 0.8674
: Epoch: 12 | Training Loss: 0.074632 | Val. Loss: 0.281012 | Val. Kappa Score: 0.8674 | Estimated time: 34.67
Train loss on 25 batch: 0.041334
: Epoch: 13 | Training Loss: 0.041334 | Val. Loss: 0.306715 | Val. Kappa Score: 0.8691 | Estimated time: 35.82
Train loss on 25 batch: 0.085291
: Epoch: 14 | Training Loss: 0.085291 | Val. Loss: 0.283662 | Val. Kappa Score: 0.8708 | Estimated time: 33.86
Train loss on 25 batch: 0.048131
best-train-loss: 0.048131
best-valid-loss: 0.280068
best-kappa: 0.8724
: Epoch: 15 | Training Loss: 0.048131 | Val. Loss: 0.280068 | Val. Kappa Score: 0.8724 | Estimated time: 33.07
Train loss on 25 batch: 0.063779
: Epoch: 16 | Training Loss: 0.063779 | Val. Loss: 0.316915 | Val. Kappa Score: 0.8731 | Estimated time: 34.14
Train loss on 25 batch: 0.035310
best-train-loss: 0.035310
best-valid-loss: 0.273587
best-kappa: 0.8745
: Epoch: 17 | Training Loss: 0.035310 | Val. Loss: 0.273587 | Val. Kappa Score: 0.8745 | Estimated time: 33.61
Train loss on 25 batch: 0.037314
: Epoch: 18 | Training Loss: 0.037314 | Val. Loss: 0.293120 | Val. Kappa Score: 0.8754 | Estimated time: 33.43
Train loss on 25 batch: 0.047514
: Epoch: 19 | Training Loss: 0.047514 | Val. Loss: 0.276264 | Val. Kappa Score: 0.8766 | Estimated time: 33.37
Train loss on 25 batch: 0.036543
: Epoch: 20 | Training Loss: 0.036543 | Val. Loss: 0.286634 | Val. Kappa Score: 0.8772 | Estimated time: 33.04
Train loss on 25 batch: 0.029944
: Epoch: 21 | Training Loss: 0.029944 | Val. Loss: 0.289314 | Val. Kappa Score: 0.8776 | Estimated time: 33.82
Train loss on 25 batch: 0.029484
best-train-loss: 0.029484
best-valid-loss: 0.272962
best-kappa: 0.8786
: Epoch: 22 | Training Loss: 0.029484 | Val. Loss: 0.272962 | Val. Kappa Score: 0.8786 | Estimated time: 34.46
Train loss on 25 batch: 0.031151
: Epoch: 23 | Training Loss: 0.031151 | Val. Loss: 0.287340 | Val. Kappa Score: 0.8787 | Estimated time: 33.98
Train loss on 25 batch: 0.021981
best-train-loss: 0.021981
best-valid-loss: 0.263108
best-kappa: 0.8797
: Epoch: 24 | Training Loss: 0.021981 | Val. Loss: 0.263108 | Val. Kappa Score: 0.8797 | Estimated time: 33.92
Train loss on 25 batch: 0.032037
: Epoch: 25 | Training Loss: 0.032037 | Val. Loss: 0.288556 | Val. Kappa Score: 0.8803 | Estimated time: 35.56
Train loss on 25 batch: 0.025080
: Epoch: 26 | Training Loss: 0.025080 | Val. Loss: 0.288079 | Val. Kappa Score: 0.8808 | Estimated time: 32.83
Train loss on 25 batch: 0.022648
: Epoch: 27 | Training Loss: 0.022648 | Val. Loss: 0.289174 | Val. Kappa Score: 0.8814 | Estimated time: 35.02
Train loss on 25 batch: 0.021501
: Epoch: 28 | Training Loss: 0.021501 | Val. Loss: 0.269007 | Val. Kappa Score: 0.8819 | Estimated time: 34.33
Train loss on 25 batch: 0.023027
: Epoch: 29 | Training Loss: 0.023027 | Val. Loss: 0.295080 | Val. Kappa Score: 0.8819 | Estimated time: 34.57
Train loss on 25 batch: 0.022421
: Epoch: 30 | Training Loss: 0.022421 | Val. Loss: 0.267335 | Val. Kappa Score: 0.8823 | Estimated time: 33.43
Train loss on 25 batch: 0.020400
: Epoch: 31 | Training Loss: 0.020400 | Val. Loss: 0.273433 | Val. Kappa Score: 0.8825 | Estimated time: 34.02
Train loss on 25 batch: 0.021917
: Epoch: 32 | Training Loss: 0.021917 | Val. Loss: 0.290576 | Val. Kappa Score: 0.8828 | Estimated time: 33.14
Train loss on 25 batch: 0.023643
: Epoch: 33 | Training Loss: 0.023643 | Val. Loss: 0.279452 | Val. Kappa Score: 0.8832 | Estimated time: 34.39
Train loss on 25 batch: 0.024017
: Epoch: 34 | Training Loss: 0.024017 | Val. Loss: 0.280135 | Val. Kappa Score: 0.8836 | Estimated time: 32.55
Train loss on 25 batch: 0.019465
: Epoch: 35 | Training Loss: 0.019465 | Val. Loss: 0.279501 | Val. Kappa Score: 0.8841 | Estimated time: 33.43
Train loss on 25 batch: 0.018371
: Epoch: 36 | Training Loss: 0.018371 | Val. Loss: 0.265316 | Val. Kappa Score: 0.8845 | Estimated time: 34.05
Train loss on 25 batch: 0.017506
: Epoch: 37 | Training Loss: 0.017506 | Val. Loss: 0.274257 | Val. Kappa Score: 0.8848 | Estimated time: 33.77
Train loss on 25 batch: 0.019302
: Epoch: 38 | Training Loss: 0.019302 | Val. Loss: 0.270668 | Val. Kappa Score: 0.8851 | Estimated time: 33.54
Train loss on 25 batch: 0.020094
: Epoch: 39 | Training Loss: 0.020094 | Val. Loss: 0.268566 | Val. Kappa Score: 0.8854 | Estimated time: 34.56
time_estimated: 1318.70
n-epochs: 39
time_estimated: 1318.70
----------------------------------------

Experiment N: 23: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 22:22:46
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
----------------------------------------

Experiment N: 23: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 22:24:52
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
----------------------------------------

Experiment N: 23: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 22:28:37
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 44599361
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 0.803977
best-train-loss: 0.803977
best-valid-loss: 1.546088
best-kappa: 0.3728
: Epoch: 1 | Training Loss: 0.803977 | Val. Loss: 1.546088 | Val. Kappa Score: 0.3728 | Estimated time: 33.50
Train loss on 25 batch: 0.379721
: Epoch: 2 | Training Loss: 0.379721 | Val. Loss: 2.482053 | Val. Kappa Score: 0.2130 | Estimated time: 33.87
Train loss on 25 batch: 0.201845
: Epoch: 3 | Training Loss: 0.201845 | Val. Loss: 2.283976 | Val. Kappa Score: 0.1738 | Estimated time: 34.51
Train loss on 25 batch: 0.242747
: Epoch: 4 | Training Loss: 0.242747 | Val. Loss: 2.579941 | Val. Kappa Score: 0.1304 | Estimated time: 33.60
Train loss on 25 batch: 0.126876
: Epoch: 5 | Training Loss: 0.126876 | Val. Loss: 2.124558 | Val. Kappa Score: 0.1241 | Estimated time: 33.27
Train loss on 25 batch: 0.145124
: Epoch: 6 | Training Loss: 0.145124 | Val. Loss: 1.662666 | Val. Kappa Score: 0.1482 | Estimated time: 32.82
Train loss on 25 batch: 0.122500
: Epoch: 7 | Training Loss: 0.122500 | Val. Loss: 2.031932 | Val. Kappa Score: 0.1422 | Estimated time: 33.91
Train loss on 25 batch: 0.125324
: Epoch: 8 | Training Loss: 0.125324 | Val. Loss: 2.416032 | Val. Kappa Score: 0.1288 | Estimated time: 33.56
Train loss on 25 batch: 0.106849
: Epoch: 9 | Training Loss: 0.106849 | Val. Loss: 2.270378 | Val. Kappa Score: 0.1215 | Estimated time: 33.99
Train loss on 25 batch: 0.091795
: Epoch: 10 | Training Loss: 0.091795 | Val. Loss: 2.419114 | Val. Kappa Score: 0.1143 | Estimated time: 34.76
Train loss on 25 batch: 0.061365
: Epoch: 11 | Training Loss: 0.061365 | Val. Loss: 2.224733 | Val. Kappa Score: 0.1146 | Estimated time: 32.74
----------------------------------------

Experiment N: 24: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 22:35:19
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2099201
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
Train loss on 25 batch: 1.192151
best-train-loss: 1.192151
best-valid-loss: 0.626517
best-kappa: 0.7430
: Epoch: 1 | Training Loss: 1.192151 | Val. Loss: 0.626517 | Val. Kappa Score: 0.7430 | Estimated time: 30.53
Train loss on 25 batch: 0.589128
best-train-loss: 0.589128
best-valid-loss: 0.510737
best-kappa: 0.7686
: Epoch: 2 | Training Loss: 0.589128 | Val. Loss: 0.510737 | Val. Kappa Score: 0.7686 | Estimated time: 30.25
Train loss on 25 batch: 0.503587
: Epoch: 3 | Training Loss: 0.503587 | Val. Loss: 0.779688 | Val. Kappa Score: 0.7507 | Estimated time: 30.67
Train loss on 25 batch: 0.544394
: Epoch: 4 | Training Loss: 0.544394 | Val. Loss: 0.520552 | Val. Kappa Score: 0.7610 | Estimated time: 30.72
Train loss on 25 batch: 0.477591
best-train-loss: 0.477591
best-valid-loss: 0.500420
best-kappa: 0.7685
: Epoch: 5 | Training Loss: 0.477591 | Val. Loss: 0.500420 | Val. Kappa Score: 0.7685 | Estimated time: 30.96
Train loss on 25 batch: 0.469743
best-train-loss: 0.469743
best-valid-loss: 0.468454
best-kappa: 0.7757
: Epoch: 6 | Training Loss: 0.469743 | Val. Loss: 0.468454 | Val. Kappa Score: 0.7757 | Estimated time: 30.22
Train loss on 25 batch: 0.581968
: Epoch: 7 | Training Loss: 0.581968 | Val. Loss: 0.720084 | Val. Kappa Score: 0.7685 | Estimated time: 30.47
Train loss on 25 batch: 0.532306
: Epoch: 8 | Training Loss: 0.532306 | Val. Loss: 0.472501 | Val. Kappa Score: 0.7741 | Estimated time: 30.51
Train loss on 25 batch: 0.550260
: Epoch: 9 | Training Loss: 0.550260 | Val. Loss: 0.500357 | Val. Kappa Score: 0.7776 | Estimated time: 30.92
Train loss on 25 batch: 0.475427
: Epoch: 10 | Training Loss: 0.475427 | Val. Loss: 0.567488 | Val. Kappa Score: 0.7772 | Estimated time: 29.56
Train loss on 25 batch: 0.593866
: Epoch: 11 | Training Loss: 0.593866 | Val. Loss: 0.583241 | Val. Kappa Score: 0.7772 | Estimated time: 30.64
Train loss on 25 batch: 0.487587
: Epoch: 12 | Training Loss: 0.487587 | Val. Loss: 0.490523 | Val. Kappa Score: 0.7793 | Estimated time: 30.33
Train loss on 25 batch: 0.422141
best-train-loss: 0.422141
best-valid-loss: 0.462343
best-kappa: 0.7821
: Epoch: 13 | Training Loss: 0.422141 | Val. Loss: 0.462343 | Val. Kappa Score: 0.7821 | Estimated time: 30.10
Train loss on 25 batch: 0.467255
: Epoch: 14 | Training Loss: 0.467255 | Val. Loss: 0.580079 | Val. Kappa Score: 0.7816 | Estimated time: 30.82
Train loss on 25 batch: 0.450797
: Epoch: 15 | Training Loss: 0.450797 | Val. Loss: 0.530000 | Val. Kappa Score: 0.7824 | Estimated time: 30.30
Train loss on 25 batch: 0.583044
: Epoch: 16 | Training Loss: 0.583044 | Val. Loss: 0.473787 | Val. Kappa Score: 0.7844 | Estimated time: 31.12
Train loss on 25 batch: 0.410124
: Epoch: 17 | Training Loss: 0.410124 | Val. Loss: 0.483425 | Val. Kappa Score: 0.7862 | Estimated time: 30.71
Train loss on 25 batch: 0.454796
: Epoch: 18 | Training Loss: 0.454796 | Val. Loss: 0.480738 | Val. Kappa Score: 0.7875 | Estimated time: 29.97
Train loss on 25 batch: 0.508821
: Epoch: 19 | Training Loss: 0.508821 | Val. Loss: 0.501964 | Val. Kappa Score: 0.7880 | Estimated time: 30.95
Train loss on 25 batch: 0.509849
: Epoch: 20 | Training Loss: 0.509849 | Val. Loss: 0.589493 | Val. Kappa Score: 0.7870 | Estimated time: 31.96
Train loss on 25 batch: 0.487269
: Epoch: 21 | Training Loss: 0.487269 | Val. Loss: 0.522785 | Val. Kappa Score: 0.7874 | Estimated time: 30.92
Train loss on 25 batch: 0.476660
: Epoch: 22 | Training Loss: 0.476660 | Val. Loss: 0.477201 | Val. Kappa Score: 0.7885 | Estimated time: 31.37
Train loss on 25 batch: 0.433678
: Epoch: 23 | Training Loss: 0.433678 | Val. Loss: 0.541157 | Val. Kappa Score: 0.7882 | Estimated time: 31.23
Train loss on 25 batch: 0.446078
: Epoch: 24 | Training Loss: 0.446078 | Val. Loss: 0.481937 | Val. Kappa Score: 0.7891 | Estimated time: 30.87
Train loss on 25 batch: 0.455435
: Epoch: 25 | Training Loss: 0.455435 | Val. Loss: 0.499689 | Val. Kappa Score: 0.7901 | Estimated time: 30.65
Train loss on 25 batch: 0.450024
: Epoch: 26 | Training Loss: 0.450024 | Val. Loss: 0.578428 | Val. Kappa Score: 0.7898 | Estimated time: 29.70
Train loss on 25 batch: 0.451756
: Epoch: 27 | Training Loss: 0.451756 | Val. Loss: 0.512698 | Val. Kappa Score: 0.7903 | Estimated time: 31.30
Train loss on 25 batch: 0.433575
best-train-loss: 0.433575
best-valid-loss: 0.456696
best-kappa: 0.7914
: Epoch: 28 | Training Loss: 0.433575 | Val. Loss: 0.456696 | Val. Kappa Score: 0.7914 | Estimated time: 29.75
Train loss on 25 batch: 0.418585
: Epoch: 29 | Training Loss: 0.418585 | Val. Loss: 0.464280 | Val. Kappa Score: 0.7923 | Estimated time: 30.70
Train loss on 25 batch: 0.409046
: Epoch: 30 | Training Loss: 0.409046 | Val. Loss: 0.469754 | Val. Kappa Score: 0.7929 | Estimated time: 31.84
Train loss on 25 batch: 0.470812
: Epoch: 31 | Training Loss: 0.470812 | Val. Loss: 0.496041 | Val. Kappa Score: 0.7932 | Estimated time: 31.12
Train loss on 25 batch: 0.482952
: Epoch: 32 | Training Loss: 0.482952 | Val. Loss: 0.482741 | Val. Kappa Score: 0.7938 | Estimated time: 31.24
Train loss on 25 batch: 0.426414
: Epoch: 33 | Training Loss: 0.426414 | Val. Loss: 0.557124 | Val. Kappa Score: 0.7930 | Estimated time: 30.42
Train loss on 25 batch: 0.418614
: Epoch: 34 | Training Loss: 0.418614 | Val. Loss: 0.470571 | Val. Kappa Score: 0.7934 | Estimated time: 30.15
Train loss on 25 batch: 0.392833
: Epoch: 35 | Training Loss: 0.392833 | Val. Loss: 0.483000 | Val. Kappa Score: 0.7940 | Estimated time: 29.73
Train loss on 25 batch: 0.421003
best-train-loss: 0.421003
best-valid-loss: 0.451074
best-kappa: 0.7950
: Epoch: 36 | Training Loss: 0.421003 | Val. Loss: 0.451074 | Val. Kappa Score: 0.7950 | Estimated time: 31.44
Train loss on 25 batch: 0.462073
: Epoch: 37 | Training Loss: 0.462073 | Val. Loss: 0.456961 | Val. Kappa Score: 0.7959 | Estimated time: 30.90
Train loss on 25 batch: 0.437195
: Epoch: 38 | Training Loss: 0.437195 | Val. Loss: 0.460289 | Val. Kappa Score: 0.7966 | Estimated time: 29.74
Train loss on 25 batch: 0.407252
: Epoch: 39 | Training Loss: 0.407252 | Val. Loss: 0.455246 | Val. Kappa Score: 0.7974 | Estimated time: 30.98
Train loss on 25 batch: 0.503422
: Epoch: 40 | Training Loss: 0.503422 | Val. Loss: 0.456124 | Val. Kappa Score: 0.7980 | Estimated time: 29.79
Train loss on 25 batch: 0.387173
: Epoch: 41 | Training Loss: 0.387173 | Val. Loss: 0.479410 | Val. Kappa Score: 0.7984 | Estimated time: 30.10
Train loss on 25 batch: 0.450443
: Epoch: 42 | Training Loss: 0.450443 | Val. Loss: 0.491322 | Val. Kappa Score: 0.7987 | Estimated time: 29.76
Train loss on 25 batch: 0.479420
: Epoch: 43 | Training Loss: 0.479420 | Val. Loss: 0.456121 | Val. Kappa Score: 0.7993 | Estimated time: 31.19
Train loss on 25 batch: 0.390875
best-train-loss: 0.390875
best-valid-loss: 0.448205
best-kappa: 0.7998
: Epoch: 44 | Training Loss: 0.390875 | Val. Loss: 0.448205 | Val. Kappa Score: 0.7998 | Estimated time: 30.18
Train loss on 25 batch: 0.397545
: Epoch: 45 | Training Loss: 0.397545 | Val. Loss: 0.457586 | Val. Kappa Score: 0.8003 | Estimated time: 30.89
Train loss on 25 batch: 0.392608
: Epoch: 46 | Training Loss: 0.392608 | Val. Loss: 0.472185 | Val. Kappa Score: 0.8005 | Estimated time: 29.68
Train loss on 25 batch: 0.439237
: Epoch: 47 | Training Loss: 0.439237 | Val. Loss: 0.480459 | Val. Kappa Score: 0.8008 | Estimated time: 30.13
Train loss on 25 batch: 0.378730
: Epoch: 48 | Training Loss: 0.378730 | Val. Loss: 0.475684 | Val. Kappa Score: 0.8012 | Estimated time: 30.71
Train loss on 25 batch: 0.452586
: Epoch: 49 | Training Loss: 0.452586 | Val. Loss: 0.478496 | Val. Kappa Score: 0.8015 | Estimated time: 30.26
Train loss on 25 batch: 0.409348
: Epoch: 50 | Training Loss: 0.409348 | Val. Loss: 0.457736 | Val. Kappa Score: 0.8018 | Estimated time: 30.26
Train loss on 25 batch: 0.417652
: Epoch: 51 | Training Loss: 0.417652 | Val. Loss: 0.634056 | Val. Kappa Score: 0.8012 | Estimated time: 30.56
Train loss on 25 batch: 0.387949
: Epoch: 52 | Training Loss: 0.387949 | Val. Loss: 0.454407 | Val. Kappa Score: 0.8018 | Estimated time: 30.05
Train loss on 25 batch: 0.428988
: Epoch: 53 | Training Loss: 0.428988 | Val. Loss: 0.462934 | Val. Kappa Score: 0.8021 | Estimated time: 30.50
Train loss on 25 batch: 0.418762
: Epoch: 54 | Training Loss: 0.418762 | Val. Loss: 0.456888 | Val. Kappa Score: 0.8026 | Estimated time: 30.49
Train loss on 25 batch: 0.408136
: Epoch: 55 | Training Loss: 0.408136 | Val. Loss: 0.475273 | Val. Kappa Score: 0.8031 | Estimated time: 30.74
Train loss on 25 batch: 0.416415
: Epoch: 56 | Training Loss: 0.416415 | Val. Loss: 0.462249 | Val. Kappa Score: 0.8036 | Estimated time: 29.93
Train loss on 25 batch: 0.395631
: Epoch: 57 | Training Loss: 0.395631 | Val. Loss: 0.498858 | Val. Kappa Score: 0.8037 | Estimated time: 30.72
Train loss on 25 batch: 0.477766
: Epoch: 58 | Training Loss: 0.477766 | Val. Loss: 0.496647 | Val. Kappa Score: 0.8037 | Estimated time: 29.90
Train loss on 25 batch: 0.395667
: Epoch: 59 | Training Loss: 0.395667 | Val. Loss: 0.450360 | Val. Kappa Score: 0.8042 | Estimated time: 29.36
time_estimated: 1802.03
n-epochs: 59
time_estimated: 1802.03
----------------------------------------

Experiment N: 25: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 23:37:58
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2049
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.888584
best-train-loss: 1.888584
best-valid-loss: 1.164908
best-kappa: 0.3242
: Epoch: 1 | Training Loss: 1.888584 | Val. Loss: 1.164908 | Val. Kappa Score: 0.3242 | Estimated time: 45.19
Train loss on 25 batch: 1.014303
best-train-loss: 1.014303
best-valid-loss: 0.819868
best-kappa: 0.4523
: Epoch: 2 | Training Loss: 1.014303 | Val. Loss: 0.819868 | Val. Kappa Score: 0.4523 | Estimated time: 46.32
Train loss on 25 batch: 0.743796
best-train-loss: 0.743796
best-valid-loss: 0.745440
best-kappa: 0.5188
: Epoch: 3 | Training Loss: 0.743796 | Val. Loss: 0.745440 | Val. Kappa Score: 0.5188 | Estimated time: 46.54
Train loss on 25 batch: 0.672269
best-train-loss: 0.672269
best-valid-loss: 0.657003
best-kappa: 0.5663
: Epoch: 4 | Training Loss: 0.672269 | Val. Loss: 0.657003 | Val. Kappa Score: 0.5663 | Estimated time: 45.70
Train loss on 25 batch: 0.629417
: Epoch: 5 | Training Loss: 0.629417 | Val. Loss: 0.677713 | Val. Kappa Score: 0.5967 | Estimated time: 47.27
Train loss on 25 batch: 0.591957
best-train-loss: 0.591957
best-valid-loss: 0.625705
best-kappa: 0.6187
: Epoch: 6 | Training Loss: 0.591957 | Val. Loss: 0.625705 | Val. Kappa Score: 0.6187 | Estimated time: 45.00
Train loss on 25 batch: 0.604455
best-train-loss: 0.604455
best-valid-loss: 0.608685
best-kappa: 0.6345
: Epoch: 7 | Training Loss: 0.604455 | Val. Loss: 0.608685 | Val. Kappa Score: 0.6345 | Estimated time: 47.17
Train loss on 25 batch: 0.563399
best-train-loss: 0.563399
best-valid-loss: 0.584753
best-kappa: 0.6491
: Epoch: 8 | Training Loss: 0.563399 | Val. Loss: 0.584753 | Val. Kappa Score: 0.6491 | Estimated time: 46.06
Train loss on 25 batch: 0.602009
: Epoch: 9 | Training Loss: 0.602009 | Val. Loss: 0.614375 | Val. Kappa Score: 0.6600 | Estimated time: 46.12
Train loss on 25 batch: 0.566437
: Epoch: 10 | Training Loss: 0.566437 | Val. Loss: 0.592099 | Val. Kappa Score: 0.6690 | Estimated time: 46.69
Train loss on 25 batch: 0.550729
best-train-loss: 0.550729
best-valid-loss: 0.578151
best-kappa: 0.6774
: Epoch: 11 | Training Loss: 0.550729 | Val. Loss: 0.578151 | Val. Kappa Score: 0.6774 | Estimated time: 45.81
Train loss on 25 batch: 0.543704
best-train-loss: 0.543704
best-valid-loss: 0.574344
best-kappa: 0.6841
: Epoch: 12 | Training Loss: 0.543704 | Val. Loss: 0.574344 | Val. Kappa Score: 0.6841 | Estimated time: 45.84
Train loss on 25 batch: 0.500405
best-train-loss: 0.500405
best-valid-loss: 0.556140
best-kappa: 0.6903
: Epoch: 13 | Training Loss: 0.500405 | Val. Loss: 0.556140 | Val. Kappa Score: 0.6903 | Estimated time: 46.11
Train loss on 25 batch: 0.573483
: Epoch: 14 | Training Loss: 0.573483 | Val. Loss: 0.564038 | Val. Kappa Score: 0.6956 | Estimated time: 46.32
Train loss on 25 batch: 0.509555
best-train-loss: 0.509555
best-valid-loss: 0.551465
best-kappa: 0.7007
: Epoch: 15 | Training Loss: 0.509555 | Val. Loss: 0.551465 | Val. Kappa Score: 0.7007 | Estimated time: 46.43
Train loss on 25 batch: 0.517235
: Epoch: 16 | Training Loss: 0.517235 | Val. Loss: 0.559731 | Val. Kappa Score: 0.7053 | Estimated time: 46.49
Train loss on 25 batch: 0.494094
----------------------------------------

Experiment N: 26: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.06 23:52:23
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2049
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.893575
best-train-loss: 1.893575
best-valid-loss: 1.159661
best-kappa: 0.3287
: Epoch: 1 | Training Loss: 1.893575 | Val. Loss: 1.159661 | Val. Kappa Score: 0.3287 | Estimated time: 45.97
Train loss on 25 batch: 1.001991
best-train-loss: 1.001991
best-valid-loss: 0.819160
best-kappa: 0.4573
: Epoch: 2 | Training Loss: 1.001991 | Val. Loss: 0.819160 | Val. Kappa Score: 0.4573 | Estimated time: 46.30
Train loss on 25 batch: 0.753767
best-train-loss: 0.753767
best-valid-loss: 0.741803
best-kappa: 0.5236
: Epoch: 3 | Training Loss: 0.753767 | Val. Loss: 0.741803 | Val. Kappa Score: 0.5236 | Estimated time: 47.14
Train loss on 25 batch: 0.672745
best-train-loss: 0.672745
best-valid-loss: 0.656920
best-kappa: 0.5710
: Epoch: 4 | Training Loss: 0.672745 | Val. Loss: 0.656920 | Val. Kappa Score: 0.5710 | Estimated time: 44.38
Train loss on 25 batch: 0.615832
: Epoch: 5 | Training Loss: 0.615832 | Val. Loss: 0.676557 | Val. Kappa Score: 0.6012 | Estimated time: 47.42
Train loss on 25 batch: 0.595656
best-train-loss: 0.595656
best-valid-loss: 0.624318
best-kappa: 0.6235
: Epoch: 6 | Training Loss: 0.595656 | Val. Loss: 0.624318 | Val. Kappa Score: 0.6235 | Estimated time: 46.01
Train loss on 25 batch: 0.603839
best-train-loss: 0.603839
best-valid-loss: 0.610593
best-kappa: 0.6401
: Epoch: 7 | Training Loss: 0.603839 | Val. Loss: 0.610593 | Val. Kappa Score: 0.6401 | Estimated time: 45.91
Train loss on 25 batch: 0.557256
best-train-loss: 0.557256
best-valid-loss: 0.585202
best-kappa: 0.6547
: Epoch: 8 | Training Loss: 0.557256 | Val. Loss: 0.585202 | Val. Kappa Score: 0.6547 | Estimated time: 46.85
Train loss on 25 batch: 0.594702
: Epoch: 9 | Training Loss: 0.594702 | Val. Loss: 0.615722 | Val. Kappa Score: 0.6655 | Estimated time: 46.95
Train loss on 25 batch: 0.544330
: Epoch: 10 | Training Loss: 0.544330 | Val. Loss: 0.597204 | Val. Kappa Score: 0.6739 | Estimated time: 46.60
Train loss on 25 batch: 0.553069
best-train-loss: 0.553069
best-valid-loss: 0.577537
best-kappa: 0.6828
: Epoch: 11 | Training Loss: 0.553069 | Val. Loss: 0.577537 | Val. Kappa Score: 0.6828 | Estimated time: 45.24
Train loss on 25 batch: 0.535476
best-train-loss: 0.535476
best-valid-loss: 0.572178
best-kappa: 0.6906
: Epoch: 12 | Training Loss: 0.535476 | Val. Loss: 0.572178 | Val. Kappa Score: 0.6906 | Estimated time: 47.11
Train loss on 25 batch: 0.490784
best-train-loss: 0.490784
best-valid-loss: 0.555430
best-kappa: 0.6972
: Epoch: 13 | Training Loss: 0.490784 | Val. Loss: 0.555430 | Val. Kappa Score: 0.6972 | Estimated time: 46.58
Train loss on 25 batch: 0.566320
: Epoch: 14 | Training Loss: 0.566320 | Val. Loss: 0.565182 | Val. Kappa Score: 0.7024 | Estimated time: 46.58
Train loss on 25 batch: 0.508041
best-train-loss: 0.508041
best-valid-loss: 0.553628
best-kappa: 0.7075
: Epoch: 15 | Training Loss: 0.508041 | Val. Loss: 0.553628 | Val. Kappa Score: 0.7075 | Estimated time: 46.63
Train loss on 25 batch: 0.507557
: Epoch: 16 | Training Loss: 0.507557 | Val. Loss: 0.565260 | Val. Kappa Score: 0.7120 | Estimated time: 45.53
Train loss on 25 batch: 0.476460
: Epoch: 17 | Training Loss: 0.476460 | Val. Loss: 0.586928 | Val. Kappa Score: 0.7152 | Estimated time: 48.51
Train loss on 25 batch: 0.510798
: Epoch: 18 | Training Loss: 0.510798 | Val. Loss: 0.602747 | Val. Kappa Score: 0.7179 | Estimated time: 47.27
Train loss on 25 batch: 0.524239
best-train-loss: 0.524239
best-valid-loss: 0.550296
best-kappa: 0.7208
: Epoch: 19 | Training Loss: 0.524239 | Val. Loss: 0.550296 | Val. Kappa Score: 0.7208 | Estimated time: 47.92
Train loss on 25 batch: 0.492133
best-train-loss: 0.492133
best-valid-loss: 0.527778
best-kappa: 0.7246
: Epoch: 20 | Training Loss: 0.492133 | Val. Loss: 0.527778 | Val. Kappa Score: 0.7246 | Estimated time: 49.05
Train loss on 25 batch: 0.470115
best-train-loss: 0.470115
best-valid-loss: 0.527472
best-kappa: 0.7276
: Epoch: 21 | Training Loss: 0.470115 | Val. Loss: 0.527472 | Val. Kappa Score: 0.7276 | Estimated time: 47.35
Train loss on 25 batch: 0.474002
best-train-loss: 0.474002
best-valid-loss: 0.524585
best-kappa: 0.7308
: Epoch: 22 | Training Loss: 0.474002 | Val. Loss: 0.524585 | Val. Kappa Score: 0.7308 | Estimated time: 46.44
Train loss on 25 batch: 0.462786
: Epoch: 23 | Training Loss: 0.462786 | Val. Loss: 0.541862 | Val. Kappa Score: 0.7330 | Estimated time: 46.63
Train loss on 25 batch: 0.469304
best-train-loss: 0.469304
best-valid-loss: 0.519460
best-kappa: 0.7355
: Epoch: 24 | Training Loss: 0.469304 | Val. Loss: 0.519460 | Val. Kappa Score: 0.7355 | Estimated time: 46.99
Train loss on 25 batch: 0.432368
: Epoch: 25 | Training Loss: 0.432368 | Val. Loss: 0.551196 | Val. Kappa Score: 0.7375 | Estimated time: 48.50
Train loss on 25 batch: 0.473167
: Epoch: 26 | Training Loss: 0.473167 | Val. Loss: 0.533637 | Val. Kappa Score: 0.7399 | Estimated time: 46.04
Train loss on 25 batch: 0.473630
: Epoch: 27 | Training Loss: 0.473630 | Val. Loss: 0.528041 | Val. Kappa Score: 0.7418 | Estimated time: 46.27
Train loss on 25 batch: 0.441653
: Epoch: 28 | Training Loss: 0.441653 | Val. Loss: 0.542760 | Val. Kappa Score: 0.7434 | Estimated time: 46.42
Train loss on 25 batch: 0.407707
best-train-loss: 0.407707
best-valid-loss: 0.516501
best-kappa: 0.7451
: Epoch: 29 | Training Loss: 0.407707 | Val. Loss: 0.516501 | Val. Kappa Score: 0.7451 | Estimated time: 47.34
Train loss on 25 batch: 0.437624
: Epoch: 30 | Training Loss: 0.437624 | Val. Loss: 0.523489 | Val. Kappa Score: 0.7467 | Estimated time: 45.45
Train loss on 25 batch: 0.449143
: Epoch: 31 | Training Loss: 0.449143 | Val. Loss: 0.524458 | Val. Kappa Score: 0.7482 | Estimated time: 46.11
Train loss on 25 batch: 0.445838
: Epoch: 32 | Training Loss: 0.445838 | Val. Loss: 0.537108 | Val. Kappa Score: 0.7496 | Estimated time: 47.08
Train loss on 25 batch: 0.430573
: Epoch: 33 | Training Loss: 0.430573 | Val. Loss: 0.561643 | Val. Kappa Score: 0.7507 | Estimated time: 46.36
Train loss on 25 batch: 0.442980
: Epoch: 34 | Training Loss: 0.442980 | Val. Loss: 0.523220 | Val. Kappa Score: 0.7520 | Estimated time: 45.71
Train loss on 25 batch: 0.373710
: Epoch: 35 | Training Loss: 0.373710 | Val. Loss: 0.555441 | Val. Kappa Score: 0.7529 | Estimated time: 45.21
Train loss on 25 batch: 0.433935
: Epoch: 36 | Training Loss: 0.433935 | Val. Loss: 0.549939 | Val. Kappa Score: 0.7541 | Estimated time: 46.13
Train loss on 25 batch: 0.413908
: Epoch: 37 | Training Loss: 0.413908 | Val. Loss: 0.522867 | Val. Kappa Score: 0.7552 | Estimated time: 47.53
Train loss on 25 batch: 0.426568
: Epoch: 38 | Training Loss: 0.426568 | Val. Loss: 0.531867 | Val. Kappa Score: 0.7561 | Estimated time: 47.45
Train loss on 25 batch: 0.412177
best-train-loss: 0.412177
best-valid-loss: 0.514918
best-kappa: 0.7571
: Epoch: 39 | Training Loss: 0.412177 | Val. Loss: 0.514918 | Val. Kappa Score: 0.7571 | Estimated time: 47.56
Train loss on 25 batch: 0.412393
best-train-loss: 0.412393
best-valid-loss: 0.511997
best-kappa: 0.7583
: Epoch: 40 | Training Loss: 0.412393 | Val. Loss: 0.511997 | Val. Kappa Score: 0.7583 | Estimated time: 47.89
Train loss on 25 batch: 0.407443
: Epoch: 41 | Training Loss: 0.407443 | Val. Loss: 0.517526 | Val. Kappa Score: 0.7594 | Estimated time: 47.30
Train loss on 25 batch: 0.398594
: Epoch: 42 | Training Loss: 0.398594 | Val. Loss: 0.519276 | Val. Kappa Score: 0.7602 | Estimated time: 46.31
Train loss on 25 batch: 0.409601
: Epoch: 43 | Training Loss: 0.409601 | Val. Loss: 0.512482 | Val. Kappa Score: 0.7609 | Estimated time: 47.01
Train loss on 25 batch: 0.408557
: Epoch: 44 | Training Loss: 0.408557 | Val. Loss: 0.516753 | Val. Kappa Score: 0.7613 | Estimated time: 47.06
Train loss on 25 batch: 0.387226
: Epoch: 45 | Training Loss: 0.387226 | Val. Loss: 0.529028 | Val. Kappa Score: 0.7620 | Estimated time: 44.65
Train loss on 25 batch: 0.391803
: Epoch: 46 | Training Loss: 0.391803 | Val. Loss: 0.513432 | Val. Kappa Score: 0.7629 | Estimated time: 46.08
Train loss on 25 batch: 0.423694
: Epoch: 47 | Training Loss: 0.423694 | Val. Loss: 0.512640 | Val. Kappa Score: 0.7635 | Estimated time: 46.95
Train loss on 25 batch: 0.386349
: Epoch: 48 | Training Loss: 0.386349 | Val. Loss: 0.525016 | Val. Kappa Score: 0.7641 | Estimated time: 46.45
Train loss on 25 batch: 0.417040
best-train-loss: 0.417040
best-valid-loss: 0.501232
best-kappa: 0.7649
: Epoch: 49 | Training Loss: 0.417040 | Val. Loss: 0.501232 | Val. Kappa Score: 0.7649 | Estimated time: 47.35
Train loss on 25 batch: 0.397932
: Epoch: 50 | Training Loss: 0.397932 | Val. Loss: 0.502828 | Val. Kappa Score: 0.7658 | Estimated time: 47.04
Train loss on 25 batch: 0.419052
: Epoch: 51 | Training Loss: 0.419052 | Val. Loss: 0.532959 | Val. Kappa Score: 0.7661 | Estimated time: 46.89
Train loss on 25 batch: 0.380912
: Epoch: 52 | Training Loss: 0.380912 | Val. Loss: 0.517397 | Val. Kappa Score: 0.7667 | Estimated time: 45.62
Train loss on 25 batch: 0.393060
: Epoch: 53 | Training Loss: 0.393060 | Val. Loss: 0.510527 | Val. Kappa Score: 0.7673 | Estimated time: 47.82
Train loss on 25 batch: 0.391069
: Epoch: 54 | Training Loss: 0.391069 | Val. Loss: 0.508963 | Val. Kappa Score: 0.7680 | Estimated time: 45.82
Train loss on 25 batch: 0.394717
: Epoch: 55 | Training Loss: 0.394717 | Val. Loss: 0.531224 | Val. Kappa Score: 0.7683 | Estimated time: 45.91
Train loss on 25 batch: 0.381738
: Epoch: 56 | Training Loss: 0.381738 | Val. Loss: 0.513092 | Val. Kappa Score: 0.7690 | Estimated time: 46.98
Train loss on 25 batch: 0.367479
: Epoch: 57 | Training Loss: 0.367479 | Val. Loss: 0.517995 | Val. Kappa Score: 0.7695 | Estimated time: 45.59
Train loss on 25 batch: 0.377847
: Epoch: 58 | Training Loss: 0.377847 | Val. Loss: 0.510720 | Val. Kappa Score: 0.7700 | Estimated time: 46.19
Train loss on 25 batch: 0.407333
: Epoch: 59 | Training Loss: 0.407333 | Val. Loss: 0.512136 | Val. Kappa Score: 0.7705 | Estimated time: 47.21
Train loss on 25 batch: 0.374952
best-train-loss: 0.374952
best-valid-loss: 0.498419
best-kappa: 0.7711
: Epoch: 60 | Training Loss: 0.374952 | Val. Loss: 0.498419 | Val. Kappa Score: 0.7711 | Estimated time: 45.94
Train loss on 25 batch: 0.366902
: Epoch: 61 | Training Loss: 0.366902 | Val. Loss: 0.499012 | Val. Kappa Score: 0.7716 | Estimated time: 46.69
Train loss on 25 batch: 0.393433
: Epoch: 62 | Training Loss: 0.393433 | Val. Loss: 0.520332 | Val. Kappa Score: 0.7721 | Estimated time: 45.61
Train loss on 25 batch: 0.352610
best-train-loss: 0.352610
best-valid-loss: 0.494150
best-kappa: 0.7726
: Epoch: 63 | Training Loss: 0.352610 | Val. Loss: 0.494150 | Val. Kappa Score: 0.7726 | Estimated time: 47.26
Train loss on 25 batch: 0.378472
: Epoch: 64 | Training Loss: 0.378472 | Val. Loss: 0.497697 | Val. Kappa Score: 0.7729 | Estimated time: 47.21
Train loss on 25 batch: 0.387570
: Epoch: 65 | Training Loss: 0.387570 | Val. Loss: 0.507176 | Val. Kappa Score: 0.7734 | Estimated time: 47.05
Train loss on 25 batch: 0.351847
: Epoch: 66 | Training Loss: 0.351847 | Val. Loss: 0.510441 | Val. Kappa Score: 0.7738 | Estimated time: 46.63
Train loss on 25 batch: 0.371589
: Epoch: 67 | Training Loss: 0.371589 | Val. Loss: 0.520280 | Val. Kappa Score: 0.7741 | Estimated time: 47.00
Train loss on 25 batch: 0.377776
: Epoch: 68 | Training Loss: 0.377776 | Val. Loss: 0.509082 | Val. Kappa Score: 0.7745 | Estimated time: 49.13
Train loss on 25 batch: 0.366939
: Epoch: 69 | Training Loss: 0.366939 | Val. Loss: 0.515093 | Val. Kappa Score: 0.7749 | Estimated time: 46.61
Train loss on 25 batch: 0.374326
: Epoch: 70 | Training Loss: 0.374326 | Val. Loss: 0.502817 | Val. Kappa Score: 0.7752 | Estimated time: 45.11
Train loss on 25 batch: 0.376443
: Epoch: 71 | Training Loss: 0.376443 | Val. Loss: 0.499154 | Val. Kappa Score: 0.7755 | Estimated time: 46.40
Train loss on 25 batch: 0.395678
: Epoch: 72 | Training Loss: 0.395678 | Val. Loss: 0.495860 | Val. Kappa Score: 0.7759 | Estimated time: 47.41
Train loss on 25 batch: 0.390212
: Epoch: 73 | Training Loss: 0.390212 | Val. Loss: 0.502701 | Val. Kappa Score: 0.7763 | Estimated time: 46.57
Train loss on 25 batch: 0.348192
: Epoch: 74 | Training Loss: 0.348192 | Val. Loss: 0.513451 | Val. Kappa Score: 0.7766 | Estimated time: 46.51
Train loss on 25 batch: 0.369366
: Epoch: 75 | Training Loss: 0.369366 | Val. Loss: 0.495202 | Val. Kappa Score: 0.7772 | Estimated time: 47.10
Train loss on 25 batch: 0.337152
: Epoch: 76 | Training Loss: 0.337152 | Val. Loss: 0.504129 | Val. Kappa Score: 0.7775 | Estimated time: 45.60
Train loss on 25 batch: 0.352418
: Epoch: 77 | Training Loss: 0.352418 | Val. Loss: 0.502045 | Val. Kappa Score: 0.7778 | Estimated time: 45.19
Train loss on 25 batch: 0.368737
: Epoch: 78 | Training Loss: 0.368737 | Val. Loss: 0.494322 | Val. Kappa Score: 0.7782 | Estimated time: 45.72
time_estimated: 3647.06
n-epochs: 78
time_estimated: 3647.07
----------------------------------------

Experiment N: 27: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 01:40:35
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2099201
n-epochs: 100
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.246808
best-train-loss: 1.246808
best-valid-loss: 0.812442
best-kappa: 0.6774
: Epoch: 1 | Training Loss: 1.246808 | Val. Loss: 0.812442 | Val. Kappa Score: 0.6774 | Estimated time: 159.00
Train loss on 25 batch: 0.645072
best-train-loss: 0.645072
best-valid-loss: 0.628426
best-kappa: 0.7053
: Epoch: 2 | Training Loss: 0.645072 | Val. Loss: 0.628426 | Val. Kappa Score: 0.7053 | Estimated time: 160.38
Train loss on 25 batch: 0.527239
: Epoch: 3 | Training Loss: 0.527239 | Val. Loss: 1.126450 | Val. Kappa Score: 0.6724 | Estimated time: 159.44
Train loss on 25 batch: 0.601821
best-train-loss: 0.601821
best-valid-loss: 0.583472
best-kappa: 0.6904
: Epoch: 4 | Training Loss: 0.601821 | Val. Loss: 0.583472 | Val. Kappa Score: 0.6904 | Estimated time: 162.18
Train loss on 25 batch: 0.521420
best-train-loss: 0.521420
best-valid-loss: 0.560641
best-kappa: 0.7050
: Epoch: 5 | Training Loss: 0.521420 | Val. Loss: 0.560641 | Val. Kappa Score: 0.7050 | Estimated time: 157.77
Train loss on 25 batch: 0.558795
: Epoch: 6 | Training Loss: 0.558795 | Val. Loss: 0.661156 | Val. Kappa Score: 0.7092 | Estimated time: 157.21
Train loss on 25 batch: 0.591664
best-train-loss: 0.591664
best-valid-loss: 0.544901
best-kappa: 0.7174
: Epoch: 7 | Training Loss: 0.591664 | Val. Loss: 0.544901 | Val. Kappa Score: 0.7174 | Estimated time: 158.03
Train loss on 25 batch: 0.565910
best-train-loss: 0.565910
best-valid-loss: 0.529179
best-kappa: 0.7258
: Epoch: 8 | Training Loss: 0.565910 | Val. Loss: 0.529179 | Val. Kappa Score: 0.7258 | Estimated time: 156.66
Train loss on 25 batch: 0.601850
: Epoch: 9 | Training Loss: 0.601850 | Val. Loss: 0.552813 | Val. Kappa Score: 0.7319 | Estimated time: 157.30
Train loss on 25 batch: 0.549835
: Epoch: 10 | Training Loss: 0.549835 | Val. Loss: 0.580138 | Val. Kappa Score: 0.7337 | Estimated time: 157.15
Train loss on 25 batch: 0.631293
: Epoch: 11 | Training Loss: 0.631293 | Val. Loss: 0.726161 | Val. Kappa Score: 0.7314 | Estimated time: 157.24
Train loss on 25 batch: 0.567393
: Epoch: 12 | Training Loss: 0.567393 | Val. Loss: 0.577929 | Val. Kappa Score: 0.7344 | Estimated time: 157.84
Train loss on 25 batch: 0.501630
: Epoch: 13 | Training Loss: 0.501630 | Val. Loss: 0.536530 | Val. Kappa Score: 0.7389 | Estimated time: 157.48
Train loss on 25 batch: 0.525644
: Epoch: 14 | Training Loss: 0.525644 | Val. Loss: 0.765141 | Val. Kappa Score: 0.7357 | Estimated time: 158.83
----------------------------------------

Experiment N: 28: 



EXPERIMENT WITH BATCH_SIZE: 128, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 02:19:27
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2099201
n-epochs: 100
batch-size: 128
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
best-train-loss: nan
best-valid-loss: 0.838298
best-kappa: 0.5452
: Epoch: 1 | Training Loss: nan | Val. Loss: 0.838298 | Val. Kappa Score: 0.5452 | Estimated time: 165.43
----------------------------------------

Experiment N: 29: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 02:23:27
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 15
parameters-amount: 2099201
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.414613
Train loss on 50 batch: 0.867927
Train loss on 75 batch: 0.653192
best-train-loss: 0.978578
best-valid-loss: 0.666618
best-kappa: 0.7101
: Epoch: 1 | Training Loss: 0.978578 | Val. Loss: 0.666618 | Val. Kappa Score: 0.7101 | Estimated time: 162.60
Train loss on 25 batch: 0.630063
Train loss on 50 batch: 0.543287
Train loss on 75 batch: 0.784843
: Epoch: 2 | Training Loss: 0.652731 | Val. Loss: 0.792840 | Val. Kappa Score: 0.6957 | Estimated time: 163.99
Train loss on 25 batch: 0.612846
Train loss on 50 batch: 0.592921
Train loss on 75 batch: 0.637367
: Epoch: 3 | Training Loss: 0.614378 | Val. Loss: 0.672414 | Val. Kappa Score: 0.7060 | Estimated time: 160.94
Train loss on 25 batch: 0.506997
Train loss on 50 batch: 0.542676
Train loss on 75 batch: 0.594876
: Epoch: 4 | Training Loss: 0.548183 | Val. Loss: 0.691849 | Val. Kappa Score: 0.7108 | Estimated time: 161.99
Train loss on 25 batch: 0.570584
Train loss on 50 batch: 0.531558
Train loss on 75 batch: 0.818120
: Epoch: 5 | Training Loss: 0.640087 | Val. Loss: 0.866575 | Val. Kappa Score: 0.7054 | Estimated time: 161.35
Train loss on 25 batch: 0.588324
Train loss on 50 batch: 0.632080
Train loss on 75 batch: 0.657895
best-train-loss: 0.626100
best-valid-loss: 0.594541
best-kappa: 0.7125
: Epoch: 6 | Training Loss: 0.626100 | Val. Loss: 0.594541 | Val. Kappa Score: 0.7125 | Estimated time: 161.18
Train loss on 25 batch: 0.531183
Train loss on 50 batch: 0.667984
Train loss on 75 batch: 0.627450
best-train-loss: 0.608872
best-valid-loss: 0.526155
best-kappa: 0.7211
: Epoch: 7 | Training Loss: 0.608872 | Val. Loss: 0.526155 | Val. Kappa Score: 0.7211 | Estimated time: 160.95
Train loss on 25 batch: 0.713364
Train loss on 50 batch: 0.581997
Train loss on 75 batch: 0.582067
: Epoch: 8 | Training Loss: 0.625809 | Val. Loss: 0.588184 | Val. Kappa Score: 0.7265 | Estimated time: 161.41
Train loss on 25 batch: 0.772879
Train loss on 50 batch: 0.534851
Train loss on 75 batch: 0.591808
: Epoch: 9 | Training Loss: 0.633179 | Val. Loss: 0.543906 | Val. Kappa Score: 0.7327 | Estimated time: 161.58
Train loss on 25 batch: 0.631687
Train loss on 50 batch: 0.658805
Train loss on 75 batch: 0.617307
: Epoch: 10 | Training Loss: 0.635933 | Val. Loss: 0.704635 | Val. Kappa Score: 0.7311 | Estimated time: 161.62
Train loss on 25 batch: 0.478076
Train loss on 50 batch: 0.592035
Train loss on 75 batch: 0.647105
: Epoch: 11 | Training Loss: 0.572405 | Val. Loss: 0.711560 | Val. Kappa Score: 0.7301 | Estimated time: 160.62
Train loss on 25 batch: 0.791575
Train loss on 50 batch: 0.578115
Train loss on 75 batch: 0.615243
: Epoch: 12 | Training Loss: 0.661644 | Val. Loss: 0.558790 | Val. Kappa Score: 0.7326 | Estimated time: 161.59
Train loss on 25 batch: 0.491613
Train loss on 50 batch: 0.500123
Train loss on 75 batch: 0.557266
best-train-loss: 0.516334
best-valid-loss: 0.520799
best-kappa: 0.7373
: Epoch: 13 | Training Loss: 0.516334 | Val. Loss: 0.520799 | Val. Kappa Score: 0.7373 | Estimated time: 162.58
Train loss on 25 batch: 0.620871
Train loss on 50 batch: 0.578856
Train loss on 75 batch: 0.477678
: Epoch: 14 | Training Loss: 0.559135 | Val. Loss: 0.556571 | Val. Kappa Score: 0.7403 | Estimated time: 161.43
Train loss on 25 batch: 0.507916
Train loss on 50 batch: 0.614232
Train loss on 75 batch: 0.650092
: Epoch: 15 | Training Loss: 0.590747 | Val. Loss: 0.675752 | Val. Kappa Score: 0.7391 | Estimated time: 160.67
Train loss on 25 batch: 0.532117
Train loss on 50 batch: 0.633002
Train loss on 75 batch: 0.541499
: Epoch: 16 | Training Loss: 0.568873 | Val. Loss: 0.576064 | Val. Kappa Score: 0.7408 | Estimated time: 161.63
Train loss on 25 batch: 0.555460
Train loss on 50 batch: 0.505599
Train loss on 75 batch: 0.588886
: Epoch: 17 | Training Loss: 0.549982 | Val. Loss: 0.527556 | Val. Kappa Score: 0.7431 | Estimated time: 161.43
Train loss on 25 batch: 0.590504
Train loss on 50 batch: 0.542343
Train loss on 75 batch: 0.559914
: Epoch: 18 | Training Loss: 0.564254 | Val. Loss: 0.542225 | Val. Kappa Score: 0.7441 | Estimated time: 161.30
Train loss on 25 batch: 0.590798
Train loss on 50 batch: 0.516364
Train loss on 75 batch: 0.485926
: Epoch: 19 | Training Loss: 0.531029 | Val. Loss: 0.619495 | Val. Kappa Score: 0.7451 | Estimated time: 161.08
Train loss on 25 batch: 0.544606
Train loss on 50 batch: 0.556844
Train loss on 75 batch: 0.506970
: Epoch: 20 | Training Loss: 0.536140 | Val. Loss: 0.525813 | Val. Kappa Score: 0.7474 | Estimated time: 162.28
Train loss on 25 batch: 0.508587
Train loss on 50 batch: 0.550236
Train loss on 75 batch: 0.522260
: Epoch: 21 | Training Loss: 0.527028 | Val. Loss: 0.661951 | Val. Kappa Score: 0.7466 | Estimated time: 160.72
Train loss on 25 batch: 0.565495
Train loss on 50 batch: 0.568311
Train loss on 75 batch: 0.534353
best-train-loss: 0.556053
best-valid-loss: 0.518320
best-kappa: 0.7483
: Epoch: 22 | Training Loss: 0.556053 | Val. Loss: 0.518320 | Val. Kappa Score: 0.7483 | Estimated time: 160.44
Train loss on 25 batch: 0.584693
Train loss on 50 batch: 0.509192
Train loss on 75 batch: 0.513185
: Epoch: 23 | Training Loss: 0.535690 | Val. Loss: 0.528060 | Val. Kappa Score: 0.7491 | Estimated time: 161.24
Train loss on 25 batch: 0.539590
Train loss on 50 batch: 0.499738
Train loss on 75 batch: 0.450987
: Epoch: 24 | Training Loss: 0.496772 | Val. Loss: 0.525976 | Val. Kappa Score: 0.7505 | Estimated time: 161.54
Train loss on 25 batch: 0.547216
Train loss on 50 batch: 0.473240
Train loss on 75 batch: 0.572791
: Epoch: 25 | Training Loss: 0.531082 | Val. Loss: 0.577638 | Val. Kappa Score: 0.7508 | Estimated time: 160.79
Train loss on 25 batch: 0.541387
Train loss on 50 batch: 0.579225
Train loss on 75 batch: 0.505385
: Epoch: 26 | Training Loss: 0.541999 | Val. Loss: 0.626950 | Val. Kappa Score: 0.7512 | Estimated time: 162.19
Train loss on 25 batch: 0.555712
Train loss on 50 batch: 0.588297
Train loss on 75 batch: 0.546675
: Epoch: 27 | Training Loss: 0.563561 | Val. Loss: 0.649973 | Val. Kappa Score: 0.7508 | Estimated time: 161.69
Train loss on 25 batch: 0.566413
Train loss on 50 batch: 0.517708
Train loss on 75 batch: 0.543641
: Epoch: 28 | Training Loss: 0.542587 | Val. Loss: 0.593255 | Val. Kappa Score: 0.7513 | Estimated time: 161.10
Train loss on 25 batch: 0.484428
Train loss on 50 batch: 0.534937
Train loss on 75 batch: 0.562314
: Epoch: 29 | Training Loss: 0.527226 | Val. Loss: 0.616006 | Val. Kappa Score: 0.7513 | Estimated time: 161.67
Train loss on 25 batch: 0.584112
Train loss on 50 batch: 0.468097
Train loss on 75 batch: 0.568794
: Epoch: 30 | Training Loss: 0.540335 | Val. Loss: 0.564808 | Val. Kappa Score: 0.7521 | Estimated time: 161.70
Train loss on 25 batch: 0.518675
Train loss on 50 batch: 0.597184
Train loss on 75 batch: 0.535128
best-train-loss: 0.550329
best-valid-loss: 0.505825
best-kappa: 0.7533
: Epoch: 31 | Training Loss: 0.550329 | Val. Loss: 0.505825 | Val. Kappa Score: 0.7533 | Estimated time: 162.76
Train loss on 25 batch: 0.551804
Train loss on 50 batch: 0.550517
Train loss on 75 batch: 0.489116
: Epoch: 32 | Training Loss: 0.530479 | Val. Loss: 0.645953 | Val. Kappa Score: 0.7531 | Estimated time: 160.55
Train loss on 25 batch: 0.582102
Train loss on 50 batch: 0.457461
Train loss on 75 batch: 0.601936
: Epoch: 33 | Training Loss: 0.547166 | Val. Loss: 0.525081 | Val. Kappa Score: 0.7540 | Estimated time: 161.66
Train loss on 25 batch: 0.541454
Train loss on 50 batch: 0.482938
Train loss on 75 batch: 0.542046
: Epoch: 34 | Training Loss: 0.522146 | Val. Loss: 0.577358 | Val. Kappa Score: 0.7544 | Estimated time: 160.84
Train loss on 25 batch: 0.404326
Train loss on 50 batch: 0.500038
Train loss on 75 batch: 0.630598
: Epoch: 35 | Training Loss: 0.511654 | Val. Loss: 0.511220 | Val. Kappa Score: 0.7556 | Estimated time: 161.49
Train loss on 25 batch: 0.483866
Train loss on 50 batch: 0.597481
Train loss on 75 batch: 0.562958
: Epoch: 36 | Training Loss: 0.548101 | Val. Loss: 0.517698 | Val. Kappa Score: 0.7562 | Estimated time: 160.90
Train loss on 25 batch: 0.498697
Train loss on 50 batch: 0.490480
Train loss on 75 batch: 0.590995
: Epoch: 37 | Training Loss: 0.526724 | Val. Loss: 0.506821 | Val. Kappa Score: 0.7571 | Estimated time: 160.96
Train loss on 25 batch: 0.506132
Train loss on 50 batch: 0.650839
Train loss on 75 batch: 0.545368
: Epoch: 38 | Training Loss: 0.567446 | Val. Loss: 0.588697 | Val. Kappa Score: 0.7571 | Estimated time: 161.77
Train loss on 25 batch: 0.494768
Train loss on 50 batch: 0.517944
Train loss on 75 batch: 0.512681
best-train-loss: 0.508464
best-valid-loss: 0.495793
best-kappa: 0.7583
: Epoch: 39 | Training Loss: 0.508464 | Val. Loss: 0.495793 | Val. Kappa Score: 0.7583 | Estimated time: 161.98
Train loss on 25 batch: 0.519736
Train loss on 50 batch: 0.462940
Train loss on 75 batch: 0.508935
: Epoch: 40 | Training Loss: 0.497204 | Val. Loss: 0.721723 | Val. Kappa Score: 0.7573 | Estimated time: 161.32
Train loss on 25 batch: 0.569911
Train loss on 50 batch: 0.496473
Train loss on 75 batch: 0.521112
: Epoch: 41 | Training Loss: 0.529165 | Val. Loss: 0.520759 | Val. Kappa Score: 0.7582 | Estimated time: 161.31
Train loss on 25 batch: 0.548230
Train loss on 50 batch: 0.497013
Train loss on 75 batch: 0.503227
: Epoch: 42 | Training Loss: 0.516157 | Val. Loss: 0.571272 | Val. Kappa Score: 0.7585 | Estimated time: 161.63
Train loss on 25 batch: 0.540720
Train loss on 50 batch: 0.483697
Train loss on 75 batch: 0.529449
: Epoch: 43 | Training Loss: 0.517956 | Val. Loss: 0.636605 | Val. Kappa Score: 0.7583 | Estimated time: 162.82
Train loss on 25 batch: 0.573047
Train loss on 50 batch: 0.438244
Train loss on 75 batch: 0.519535
best-train-loss: 0.510275
best-valid-loss: 0.494965
best-kappa: 0.7594
: Epoch: 44 | Training Loss: 0.510275 | Val. Loss: 0.494965 | Val. Kappa Score: 0.7594 | Estimated time: 162.47
Train loss on 25 batch: 0.453315
Train loss on 50 batch: 0.523196
Train loss on 75 batch: 0.561808
best-train-loss: 0.512773
best-valid-loss: 0.494758
best-kappa: 0.7604
: Epoch: 45 | Training Loss: 0.512773 | Val. Loss: 0.494758 | Val. Kappa Score: 0.7604 | Estimated time: 162.24
Train loss on 25 batch: 0.539516
Train loss on 50 batch: 0.501018
Train loss on 75 batch: 0.501590
: Epoch: 46 | Training Loss: 0.514042 | Val. Loss: 0.502593 | Val. Kappa Score: 0.7614 | Estimated time: 161.62
Train loss on 25 batch: 0.576110
Train loss on 50 batch: 0.583607
Train loss on 75 batch: 0.564584
: Epoch: 47 | Training Loss: 0.574767 | Val. Loss: 0.503881 | Val. Kappa Score: 0.7621 | Estimated time: 161.23
Train loss on 25 batch: 0.518072
Train loss on 50 batch: 0.503861
Train loss on 75 batch: 0.526259
: Epoch: 48 | Training Loss: 0.516064 | Val. Loss: 0.502238 | Val. Kappa Score: 0.7626 | Estimated time: 161.77
Train loss on 25 batch: 0.618523
Train loss on 50 batch: 0.569643
Train loss on 75 batch: 0.495668
best-train-loss: 0.561278
best-valid-loss: 0.489829
best-kappa: 0.7634
: Epoch: 49 | Training Loss: 0.561278 | Val. Loss: 0.489829 | Val. Kappa Score: 0.7634 | Estimated time: 162.29
Train loss on 25 batch: 0.531008
Train loss on 50 batch: 0.557352
Train loss on 75 batch: 0.630285
: Epoch: 50 | Training Loss: 0.572882 | Val. Loss: 0.573341 | Val. Kappa Score: 0.7637 | Estimated time: 161.12
Train loss on 25 batch: 0.495209
Train loss on 50 batch: 0.589567
Train loss on 75 batch: 0.471178
: Epoch: 51 | Training Loss: 0.518652 | Val. Loss: 0.583055 | Val. Kappa Score: 0.7639 | Estimated time: 161.09
Train loss on 25 batch: 0.488477
Train loss on 50 batch: 0.461244
Train loss on 75 batch: 0.610081
: Epoch: 52 | Training Loss: 0.519934 | Val. Loss: 0.655936 | Val. Kappa Score: 0.7634 | Estimated time: 161.45
Train loss on 25 batch: 0.539466
Train loss on 50 batch: 0.535336
Train loss on 75 batch: 0.477866
: Epoch: 53 | Training Loss: 0.517556 | Val. Loss: 0.513854 | Val. Kappa Score: 0.7641 | Estimated time: 162.46
Train loss on 25 batch: 0.534809
Train loss on 50 batch: 0.527436
Train loss on 75 batch: 0.483405
best-train-loss: 0.515217
best-valid-loss: 0.489125
best-kappa: 0.7648
: Epoch: 54 | Training Loss: 0.515217 | Val. Loss: 0.489125 | Val. Kappa Score: 0.7648 | Estimated time: 161.43
Train loss on 25 batch: 0.513929
Train loss on 50 batch: 0.441587
Train loss on 75 batch: 0.470291
: Epoch: 55 | Training Loss: 0.475269 | Val. Loss: 0.492420 | Val. Kappa Score: 0.7654 | Estimated time: 161.11
Train loss on 25 batch: 0.581756
Train loss on 50 batch: 0.493322
Train loss on 75 batch: 0.479691
: Epoch: 56 | Training Loss: 0.518257 | Val. Loss: 0.494010 | Val. Kappa Score: 0.7659 | Estimated time: 161.36
Train loss on 25 batch: 0.501918
Train loss on 50 batch: 0.473039
Train loss on 75 batch: 0.480237
best-train-loss: 0.485065
best-valid-loss: 0.485729
best-kappa: 0.7666
: Epoch: 57 | Training Loss: 0.485065 | Val. Loss: 0.485729 | Val. Kappa Score: 0.7666 | Estimated time: 160.32
Train loss on 25 batch: 0.519042
Train loss on 50 batch: 0.532640
Train loss on 75 batch: 0.519891
: Epoch: 58 | Training Loss: 0.523858 | Val. Loss: 0.560473 | Val. Kappa Score: 0.7667 | Estimated time: 160.59
Train loss on 25 batch: 0.520397
Train loss on 50 batch: 0.529778
Train loss on 75 batch: 0.545653
: Epoch: 59 | Training Loss: 0.531943 | Val. Loss: 0.504282 | Val. Kappa Score: 0.7672 | Estimated time: 162.87
Train loss on 25 batch: 0.465591
Train loss on 50 batch: 0.529388
Train loss on 75 batch: 0.504198
: Epoch: 60 | Training Loss: 0.499726 | Val. Loss: 0.574378 | Val. Kappa Score: 0.7673 | Estimated time: 161.55
Train loss on 25 batch: 0.456062
Train loss on 50 batch: 0.488047
Train loss on 75 batch: 0.521330
: Epoch: 61 | Training Loss: 0.488480 | Val. Loss: 0.496089 | Val. Kappa Score: 0.7678 | Estimated time: 162.14
Train loss on 25 batch: 0.515198
Train loss on 50 batch: 0.545293
Train loss on 75 batch: 0.536573
: Epoch: 62 | Training Loss: 0.532355 | Val. Loss: 0.521453 | Val. Kappa Score: 0.7682 | Estimated time: 161.13
Train loss on 25 batch: 0.454762
Train loss on 50 batch: 0.444325
Train loss on 75 batch: 0.532828
: Epoch: 63 | Training Loss: 0.477305 | Val. Loss: 0.548946 | Val. Kappa Score: 0.7684 | Estimated time: 162.10
Train loss on 25 batch: 0.486349
Train loss on 50 batch: 0.522827
Train loss on 75 batch: 0.504758
: Epoch: 64 | Training Loss: 0.504644 | Val. Loss: 0.600561 | Val. Kappa Score: 0.7684 | Estimated time: 162.42
Train loss on 25 batch: 0.506760
Train loss on 50 batch: 0.487234
Train loss on 75 batch: 0.496548
: Epoch: 65 | Training Loss: 0.496848 | Val. Loss: 0.592231 | Val. Kappa Score: 0.7681 | Estimated time: 161.77
Train loss on 25 batch: 0.576040
Train loss on 50 batch: 0.465970
Train loss on 75 batch: 0.594922
: Epoch: 66 | Training Loss: 0.545644 | Val. Loss: 0.629869 | Val. Kappa Score: 0.7679 | Estimated time: 160.09
Train loss on 25 batch: 0.463552
Train loss on 50 batch: 0.577622
Train loss on 75 batch: 0.492772
: Epoch: 67 | Training Loss: 0.511315 | Val. Loss: 0.507584 | Val. Kappa Score: 0.7682 | Estimated time: 160.65
Train loss on 25 batch: 0.480031
Train loss on 50 batch: 0.490851
Train loss on 75 batch: 0.511407
: Epoch: 68 | Training Loss: 0.494096 | Val. Loss: 0.516882 | Val. Kappa Score: 0.7686 | Estimated time: 161.25
Train loss on 25 batch: 0.572546
Train loss on 50 batch: 0.471496
Train loss on 75 batch: 0.563511
: Epoch: 69 | Training Loss: 0.535851 | Val. Loss: 0.669926 | Val. Kappa Score: 0.7682 | Estimated time: 162.10
Train loss on 25 batch: 0.541879
Train loss on 50 batch: 0.472362
Train loss on 75 batch: 0.507475
: Epoch: 70 | Training Loss: 0.507239 | Val. Loss: 0.527726 | Val. Kappa Score: 0.7684 | Estimated time: 160.71
Train loss on 25 batch: 0.432126
Train loss on 50 batch: 0.573660
Train loss on 75 batch: 0.444905
: Epoch: 71 | Training Loss: 0.483564 | Val. Loss: 0.530964 | Val. Kappa Score: 0.7687 | Estimated time: 161.92
Train loss on 25 batch: 0.511677
Train loss on 50 batch: 0.540324
Train loss on 75 batch: 0.502882
: Epoch: 72 | Training Loss: 0.518294 | Val. Loss: 0.534840 | Val. Kappa Score: 0.7689 | Estimated time: 161.32
time_estimated: 11631.53
n-epochs: 72
time_estimated: 11631.53
----------------------------------------

Experiment N: 30: 



EXPERIMENT WITH BATCH_SIZE: 512, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 08:39:59
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 2099201
n-epochs: 50
batch-size: 512
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 30: 



EXPERIMENT WITH BATCH_SIZE: 512, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 08:44:40
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 2099201
n-epochs: 50
batch-size: 512
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
best-train-loss: 2.464634
best-valid-loss: 2.461174
best-kappa: 0.0038
: Epoch: 1 | Training Loss: 2.464634 | Val. Loss: 2.461174 | Val. Kappa Score: 0.0038 | Estimated time: 231.84
----------------------------------------

Experiment N: 31: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 08:49:26
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 2099201
n-epochs: 50
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.255194
best-train-loss: 0.935698
best-valid-loss: 0.897476
best-kappa: 0.6499
: Epoch: 1 | Training Loss: 0.935698 | Val. Loss: 0.897476 | Val. Kappa Score: 0.6499 | Estimated time: 162.89
Train loss on 25 batch: 0.630085
best-train-loss: 0.658462
best-valid-loss: 0.602823
best-kappa: 0.6959
: Epoch: 2 | Training Loss: 0.658462 | Val. Loss: 0.602823 | Val. Kappa Score: 0.6959 | Estimated time: 160.75
----------------------------------------

Experiment N: 32: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 08:57:43
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 2099201
n-epochs: 50
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.257221
----------------------------------------

Experiment N: 32: 



EXPERIMENT WITH BATCH_SIZE: 64, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 09:00:31
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 50
batch-size: 64
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 32: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 09:02:11
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 50
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.105246
Train loss on 50 batch: 0.717290
Train loss on 75 batch: 0.514134
best-train-loss: 0.708996
best-valid-loss: 0.491059
best-kappa: 0.8256
: Epoch: 1 | Training Loss: 0.708996 | Val. Loss: 0.491059 | Val. Kappa Score: 0.8256 | Estimated time: 164.17
Train loss on 25 batch: 0.475188
Train loss on 50 batch: 0.454825
Train loss on 75 batch: 0.438383
: Epoch: 2 | Training Loss: 0.444460 | Val. Loss: 0.513161 | Val. Kappa Score: 0.8204 | Estimated time: 163.31
Train loss on 25 batch: 0.371115
Train loss on 50 batch: 0.335004
Train loss on 75 batch: 0.408027
: Epoch: 3 | Training Loss: 0.354911 | Val. Loss: 0.539343 | Val. Kappa Score: 0.8121 | Estimated time: 162.49
Train loss on 25 batch: 0.311651
Train loss on 50 batch: 0.314690
Train loss on 75 batch: 0.340406
best-train-loss: 0.319960
best-valid-loss: 0.331489
best-kappa: 0.8305
: Epoch: 4 | Training Loss: 0.319960 | Val. Loss: 0.331489 | Val. Kappa Score: 0.8305 | Estimated time: 163.57
Train loss on 25 batch: 0.295855
Train loss on 50 batch: 0.246637
Train loss on 75 batch: 0.391871
best-train-loss: 0.307368
best-valid-loss: 0.330757
best-kappa: 0.8385
: Epoch: 5 | Training Loss: 0.307368 | Val. Loss: 0.330757 | Val. Kappa Score: 0.8385 | Estimated time: 162.71
Train loss on 25 batch: 0.287136
Train loss on 50 batch: 0.302822
Train loss on 75 batch: 0.303182
best-train-loss: 0.287832
best-valid-loss: 0.307223
best-kappa: 0.8468
: Epoch: 6 | Training Loss: 0.287832 | Val. Loss: 0.307223 | Val. Kappa Score: 0.8468 | Estimated time: 163.05
Train loss on 25 batch: 0.247293
Train loss on 50 batch: 0.312034
Train loss on 75 batch: 0.263912
: Epoch: 7 | Training Loss: 0.295760 | Val. Loss: 0.405427 | Val. Kappa Score: 0.8483 | Estimated time: 163.16
Train loss on 25 batch: 0.274944
Train loss on 50 batch: 0.231816
Train loss on 75 batch: 0.243294
best-train-loss: 0.258266
best-valid-loss: 0.283733
best-kappa: 0.8532
: Epoch: 8 | Training Loss: 0.258266 | Val. Loss: 0.283733 | Val. Kappa Score: 0.8532 | Estimated time: 163.82
Train loss on 25 batch: 0.319502
Train loss on 50 batch: 0.262622
Train loss on 75 batch: 0.252682
: Epoch: 9 | Training Loss: 0.268553 | Val. Loss: 0.323582 | Val. Kappa Score: 0.8552 | Estimated time: 162.69
Train loss on 25 batch: 0.223386
Train loss on 50 batch: 0.238874
Train loss on 75 batch: 0.260509
best-train-loss: 0.231398
best-valid-loss: 0.267906
best-kappa: 0.8593
: Epoch: 10 | Training Loss: 0.231398 | Val. Loss: 0.267906 | Val. Kappa Score: 0.8593 | Estimated time: 163.77
Train loss on 25 batch: 0.192802
Train loss on 50 batch: 0.297354
Train loss on 75 batch: 0.234261
best-train-loss: 0.243467
best-valid-loss: 0.266023
best-kappa: 0.8627
: Epoch: 11 | Training Loss: 0.243467 | Val. Loss: 0.266023 | Val. Kappa Score: 0.8627 | Estimated time: 163.50
Train loss on 25 batch: 0.275077
Train loss on 50 batch: 0.199956
Train loss on 75 batch: 0.212336
: Epoch: 12 | Training Loss: 0.225411 | Val. Loss: 0.279700 | Val. Kappa Score: 0.8661 | Estimated time: 162.84
Train loss on 25 batch: 0.177843
Train loss on 50 batch: 0.191272
Train loss on 75 batch: 0.220533
: Epoch: 13 | Training Loss: 0.203626 | Val. Loss: 0.309382 | Val. Kappa Score: 0.8670 | Estimated time: 163.42
Train loss on 25 batch: 0.196340
Train loss on 50 batch: 0.248056
Train loss on 75 batch: 0.223074
best-train-loss: 0.208437
best-valid-loss: 0.265281
best-kappa: 0.8690
: Epoch: 14 | Training Loss: 0.208437 | Val. Loss: 0.265281 | Val. Kappa Score: 0.8690 | Estimated time: 161.83
Train loss on 25 batch: 0.177759
Train loss on 50 batch: 0.207775
Train loss on 75 batch: 0.214889
: Epoch: 15 | Training Loss: 0.198013 | Val. Loss: 0.326417 | Val. Kappa Score: 0.8694 | Estimated time: 162.89
Train loss on 25 batch: 0.182898
Train loss on 50 batch: 0.226590
Train loss on 75 batch: 0.195372
: Epoch: 16 | Training Loss: 0.199629 | Val. Loss: 0.293573 | Val. Kappa Score: 0.8710 | Estimated time: 164.25
Train loss on 25 batch: 0.177178
Train loss on 50 batch: 0.152677
Train loss on 75 batch: 0.190405
: Epoch: 17 | Training Loss: 0.171996 | Val. Loss: 0.470874 | Val. Kappa Score: 0.8707 | Estimated time: 162.67
Train loss on 25 batch: 0.191400
Train loss on 50 batch: 0.174828
Train loss on 75 batch: 0.202743
: Epoch: 18 | Training Loss: 0.196773 | Val. Loss: 0.304757 | Val. Kappa Score: 0.8719 | Estimated time: 164.35
Train loss on 25 batch: 0.196609
Train loss on 50 batch: 0.212524
Train loss on 75 batch: 0.181197
best-train-loss: 0.195692
best-valid-loss: 0.254439
best-kappa: 0.8735
: Epoch: 19 | Training Loss: 0.195692 | Val. Loss: 0.254439 | Val. Kappa Score: 0.8735 | Estimated time: 162.89
Train loss on 25 batch: 0.166807
Train loss on 50 batch: 0.198814
Train loss on 75 batch: 0.185534
: Epoch: 20 | Training Loss: 0.175124 | Val. Loss: 0.255348 | Val. Kappa Score: 0.8752 | Estimated time: 162.92
Train loss on 25 batch: 0.155361
Train loss on 50 batch: 0.153891
Train loss on 75 batch: 0.166573
: Epoch: 21 | Training Loss: 0.149358 | Val. Loss: 0.291031 | Val. Kappa Score: 0.8762 | Estimated time: 163.08
Train loss on 25 batch: 0.152010
Train loss on 50 batch: 0.149857
Train loss on 75 batch: 0.169132
: Epoch: 22 | Training Loss: 0.155871 | Val. Loss: 0.328718 | Val. Kappa Score: 0.8768 | Estimated time: 162.93
Train loss on 25 batch: 0.153852
Train loss on 50 batch: 0.174895
Train loss on 75 batch: 0.153917
: Epoch: 23 | Training Loss: 0.160526 | Val. Loss: 0.281125 | Val. Kappa Score: 0.8775 | Estimated time: 163.08
Train loss on 25 batch: 0.148736
Train loss on 50 batch: 0.154616
Train loss on 75 batch: 0.123641
: Epoch: 24 | Training Loss: 0.139926 | Val. Loss: 0.285444 | Val. Kappa Score: 0.8782 | Estimated time: 163.75
Train loss on 25 batch: 0.122907
Train loss on 50 batch: 0.117088
Train loss on 75 batch: 0.137522
: Epoch: 25 | Training Loss: 0.134086 | Val. Loss: 0.296358 | Val. Kappa Score: 0.8785 | Estimated time: 163.28
Train loss on 25 batch: 0.160829
Train loss on 50 batch: 0.167484
Train loss on 75 batch: 0.148614
: Epoch: 26 | Training Loss: 0.154324 | Val. Loss: 0.285114 | Val. Kappa Score: 0.8788 | Estimated time: 163.24
Train loss on 25 batch: 0.119070
Train loss on 50 batch: 0.137119
Train loss on 75 batch: 0.167608
: Epoch: 27 | Training Loss: 0.150364 | Val. Loss: 0.286806 | Val. Kappa Score: 0.8796 | Estimated time: 163.05
time_estimated: 4407.88
n-epochs: 27
time_estimated: 4407.89
----------------------------------------

Experiment N: 33: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 15:19:31
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 50
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.146999
Train loss on 50 batch: 0.751952
Train loss on 75 batch: 0.534349
best-train-loss: 0.740291
best-valid-loss: 0.564104
best-kappa: 0.7923
: Epoch: 1 | Training Loss: 0.740291 | Val. Loss: 0.564104 | Val. Kappa Score: 0.7923 | Estimated time: 163.29
Train loss on 25 batch: 0.528780
Train loss on 50 batch: 0.458651
Train loss on 75 batch: 0.468566
best-train-loss: 0.474930
best-valid-loss: 0.428611
best-kappa: 0.8212
: Epoch: 2 | Training Loss: 0.474930 | Val. Loss: 0.428611 | Val. Kappa Score: 0.8212 | Estimated time: 163.52
Train loss on 25 batch: 0.408960
Train loss on 50 batch: 0.339445
Train loss on 75 batch: 0.378834
best-train-loss: 0.354820
best-valid-loss: 0.374150
best-kappa: 0.8319
: Epoch: 3 | Training Loss: 0.354820 | Val. Loss: 0.374150 | Val. Kappa Score: 0.8319 | Estimated time: 162.74
Train loss on 25 batch: 0.298999
Train loss on 50 batch: 0.307430
Train loss on 75 batch: 0.362620
best-train-loss: 0.322112
best-valid-loss: 0.320513
best-kappa: 0.8453
: Epoch: 4 | Training Loss: 0.322112 | Val. Loss: 0.320513 | Val. Kappa Score: 0.8453 | Estimated time: 163.87
Train loss on 25 batch: 0.308002
Train loss on 50 batch: 0.271679
Train loss on 75 batch: 0.404189
best-train-loss: 0.329830
best-valid-loss: 0.310606
best-kappa: 0.8524
: Epoch: 5 | Training Loss: 0.329830 | Val. Loss: 0.310606 | Val. Kappa Score: 0.8524 | Estimated time: 163.22
Train loss on 25 batch: 0.283388
Train loss on 50 batch: 0.315885
Train loss on 75 batch: 0.309523
: Epoch: 6 | Training Loss: 0.293143 | Val. Loss: 0.346479 | Val. Kappa Score: 0.8553 | Estimated time: 163.56
Train loss on 25 batch: 0.283695
Train loss on 50 batch: 0.334791
Train loss on 75 batch: 0.284492
: Epoch: 7 | Training Loss: 0.327031 | Val. Loss: 0.448132 | Val. Kappa Score: 0.8548 | Estimated time: 162.39
Train loss on 25 batch: 0.295911
Train loss on 50 batch: 0.243731
Train loss on 75 batch: 0.255957
best-train-loss: 0.275113
best-valid-loss: 0.286735
best-kappa: 0.8583
: Epoch: 8 | Training Loss: 0.275113 | Val. Loss: 0.286735 | Val. Kappa Score: 0.8583 | Estimated time: 161.81
Train loss on 25 batch: 0.319222
Train loss on 50 batch: 0.287605
Train loss on 75 batch: 0.254641
: Epoch: 9 | Training Loss: 0.275998 | Val. Loss: 0.320426 | Val. Kappa Score: 0.8588 | Estimated time: 163.76
Train loss on 25 batch: 0.228789
Train loss on 50 batch: 0.272534
Train loss on 75 batch: 0.254410
: Epoch: 10 | Training Loss: 0.250551 | Val. Loss: 0.299264 | Val. Kappa Score: 0.8609 | Estimated time: 163.61
Train loss on 25 batch: 0.215853
Train loss on 50 batch: 0.296134
Train loss on 75 batch: 0.238646
: Epoch: 11 | Training Loss: 0.255676 | Val. Loss: 0.339289 | Val. Kappa Score: 0.8638 | Estimated time: 162.68
Train loss on 25 batch: 0.300963
Train loss on 50 batch: 0.215143
Train loss on 75 batch: 0.236013
best-train-loss: 0.246165
best-valid-loss: 0.283747
best-kappa: 0.8660
: Epoch: 12 | Training Loss: 0.246165 | Val. Loss: 0.283747 | Val. Kappa Score: 0.8660 | Estimated time: 162.85
Train loss on 25 batch: 0.191769
Train loss on 50 batch: 0.202512
Train loss on 75 batch: 0.235759
: Epoch: 13 | Training Loss: 0.216496 | Val. Loss: 0.289698 | Val. Kappa Score: 0.8683 | Estimated time: 163.02
Train loss on 25 batch: 0.210726
Train loss on 50 batch: 0.247083
Train loss on 75 batch: 0.229173
: Epoch: 14 | Training Loss: 0.218004 | Val. Loss: 0.284375 | Val. Kappa Score: 0.8697 | Estimated time: 162.85
Train loss on 25 batch: 0.193062
Train loss on 50 batch: 0.218018
Train loss on 75 batch: 0.231814
: Epoch: 15 | Training Loss: 0.211060 | Val. Loss: 0.304522 | Val. Kappa Score: 0.8702 | Estimated time: 163.52
Train loss on 25 batch: 0.193537
Train loss on 50 batch: 0.250929
Train loss on 75 batch: 0.232765
: Epoch: 16 | Training Loss: 0.223746 | Val. Loss: 0.309768 | Val. Kappa Score: 0.8715 | Estimated time: 162.50
Train loss on 25 batch: 0.178894
Train loss on 50 batch: 0.162305
Train loss on 75 batch: 0.187055
: Epoch: 17 | Training Loss: 0.174271 | Val. Loss: 0.303025 | Val. Kappa Score: 0.8728 | Estimated time: 163.85
Train loss on 25 batch: 0.181677
Train loss on 50 batch: 0.191842
Train loss on 75 batch: 0.242713
best-train-loss: 0.209605
best-valid-loss: 0.274007
best-kappa: 0.8743
: Epoch: 18 | Training Loss: 0.209605 | Val. Loss: 0.274007 | Val. Kappa Score: 0.8743 | Estimated time: 162.81
Train loss on 25 batch: 0.195675
Train loss on 50 batch: 0.178907
Train loss on 75 batch: 0.177483
best-train-loss: 0.186261
best-valid-loss: 0.255677
best-kappa: 0.8760
: Epoch: 19 | Training Loss: 0.186261 | Val. Loss: 0.255677 | Val. Kappa Score: 0.8760 | Estimated time: 163.80
Train loss on 25 batch: 0.164399
Train loss on 50 batch: 0.188836
Train loss on 75 batch: 0.193913
: Epoch: 20 | Training Loss: 0.177080 | Val. Loss: 0.301027 | Val. Kappa Score: 0.8773 | Estimated time: 163.48
Train loss on 25 batch: 0.146181
Train loss on 50 batch: 0.146898
Train loss on 75 batch: 0.175143
: Epoch: 21 | Training Loss: 0.156368 | Val. Loss: 0.306681 | Val. Kappa Score: 0.8777 | Estimated time: 162.54
Train loss on 25 batch: 0.170367
Train loss on 50 batch: 0.163083
Train loss on 75 batch: 0.165574
: Epoch: 22 | Training Loss: 0.162705 | Val. Loss: 0.299681 | Val. Kappa Score: 0.8783 | Estimated time: 162.38
Train loss on 25 batch: 0.145613
Train loss on 50 batch: 0.177849
Train loss on 75 batch: 0.164997
: Epoch: 23 | Training Loss: 0.159375 | Val. Loss: 0.282615 | Val. Kappa Score: 0.8790 | Estimated time: 162.91
Train loss on 25 batch: 0.142939
Train loss on 50 batch: 0.158372
Train loss on 75 batch: 0.143223
: Epoch: 24 | Training Loss: 0.146381 | Val. Loss: 0.276226 | Val. Kappa Score: 0.8797 | Estimated time: 163.70
Train loss on 25 batch: 0.136122
Train loss on 50 batch: 0.126709
Train loss on 75 batch: 0.155886
: Epoch: 25 | Training Loss: 0.146798 | Val. Loss: 0.346290 | Val. Kappa Score: 0.8787 | Estimated time: 163.17
Train loss on 25 batch: 0.149392
Train loss on 50 batch: 0.152602
Train loss on 75 batch: 0.128420
: Epoch: 26 | Training Loss: 0.148650 | Val. Loss: 0.309556 | Val. Kappa Score: 0.8786 | Estimated time: 162.56
Train loss on 25 batch: 0.125352
Train loss on 50 batch: 0.158379
Train loss on 75 batch: 0.174946
: Epoch: 27 | Training Loss: 0.164307 | Val. Loss: 0.263918 | Val. Kappa Score: 0.8795 | Estimated time: 163.17
time_estimated: 4404.76
n-epochs: 27
time_estimated: 4404.76
----------------------------------------

Experiment N: 34: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 16:36:39
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 50
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.149963
Train loss on 50 batch: 0.803961
Train loss on 75 batch: 0.566577
best-train-loss: 0.734979
best-valid-loss: 0.379500
best-kappa: 0.8574
: Epoch: 1 | Training Loss: 0.734979 | Val. Loss: 0.379500 | Val. Kappa Score: 0.8574 | Estimated time: 163.39
Train loss on 25 batch: 0.453781
Train loss on 50 batch: 0.463398
Train loss on 75 batch: 0.416397
: Epoch: 2 | Training Loss: 0.440033 | Val. Loss: 0.414716 | Val. Kappa Score: 0.8446 | Estimated time: 163.40
Train loss on 25 batch: 0.380628
Train loss on 50 batch: 0.350186
Train loss on 75 batch: 0.408985
: Epoch: 3 | Training Loss: 0.363849 | Val. Loss: 0.439160 | Val. Kappa Score: 0.8387 | Estimated time: 166.42
Train loss on 25 batch: 0.297024
Train loss on 50 batch: 0.330918
Train loss on 75 batch: 0.364169
best-train-loss: 0.326128
best-valid-loss: 0.344507
best-kappa: 0.8481
: Epoch: 4 | Training Loss: 0.326128 | Val. Loss: 0.344507 | Val. Kappa Score: 0.8481 | Estimated time: 161.42
Train loss on 25 batch: 0.329028
Train loss on 50 batch: 0.274335
Train loss on 75 batch: 0.412660
best-train-loss: 0.338208
best-valid-loss: 0.329149
best-kappa: 0.8520
: Epoch: 5 | Training Loss: 0.338208 | Val. Loss: 0.329149 | Val. Kappa Score: 0.8520 | Estimated time: 156.13
Train loss on 25 batch: 0.305233
Train loss on 50 batch: 0.320519
Train loss on 75 batch: 0.322755
best-train-loss: 0.310639
best-valid-loss: 0.284727
best-kappa: 0.8585
: Epoch: 6 | Training Loss: 0.310639 | Val. Loss: 0.284727 | Val. Kappa Score: 0.8585 | Estimated time: 157.11
Train loss on 25 batch: 0.287964
Train loss on 50 batch: 0.311781
Train loss on 75 batch: 0.276133
: Epoch: 7 | Training Loss: 0.308164 | Val. Loss: 0.516914 | Val. Kappa Score: 0.8500 | Estimated time: 156.56
Train loss on 25 batch: 0.274145
Train loss on 50 batch: 0.236636
Train loss on 75 batch: 0.274091
: Epoch: 8 | Training Loss: 0.276510 | Val. Loss: 0.352726 | Val. Kappa Score: 0.8520 | Estimated time: 155.64
Train loss on 25 batch: 0.316499
Train loss on 50 batch: 0.269450
Train loss on 75 batch: 0.250317
: Epoch: 9 | Training Loss: 0.268324 | Val. Loss: 0.340816 | Val. Kappa Score: 0.8549 | Estimated time: 155.10
Train loss on 25 batch: 0.231323
Train loss on 50 batch: 0.260274
Train loss on 75 batch: 0.240238
: Epoch: 10 | Training Loss: 0.240122 | Val. Loss: 0.293124 | Val. Kappa Score: 0.8577 | Estimated time: 156.20
Train loss on 25 batch: 0.224910
Train loss on 50 batch: 0.306025
Train loss on 75 batch: 0.253012
: Epoch: 11 | Training Loss: 0.260754 | Val. Loss: 0.316971 | Val. Kappa Score: 0.8593 | Estimated time: 156.89
Train loss on 25 batch: 0.289842
Train loss on 50 batch: 0.224491
Train loss on 75 batch: 0.207197
: Epoch: 12 | Training Loss: 0.238747 | Val. Loss: 0.296169 | Val. Kappa Score: 0.8614 | Estimated time: 157.22
Train loss on 25 batch: 0.200622
Train loss on 50 batch: 0.183821
Train loss on 75 batch: 0.239754
: Epoch: 13 | Training Loss: 0.211349 | Val. Loss: 0.308573 | Val. Kappa Score: 0.8631 | Estimated time: 155.85
Train loss on 25 batch: 0.205894
Train loss on 50 batch: 0.253268
Train loss on 75 batch: 0.221512
: Epoch: 14 | Training Loss: 0.211420 | Val. Loss: 0.285136 | Val. Kappa Score: 0.8645 | Estimated time: 155.32
time_estimated: 2217.21
n-epochs: 14
time_estimated: 2217.22
----------------------------------------

Experiment N: 34: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4


: 
date: 2019.08.07 19:09:56
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 44599361
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.146999
Train loss on 50 batch: 0.751952
Train loss on 75 batch: 0.534349
best-train-loss: 0.740291
best-valid-loss: 0.564104
best-kappa: 0.7923
: Epoch: 1 | Training Loss: 0.740291 | Val. Loss: 0.564104 | Val. Kappa Score: 0.7923 | Estimated time: 171.63
Train loss on 25 batch: 0.528780
Train loss on 50 batch: 0.458651
Train loss on 75 batch: 0.468566
best-train-loss: 0.474930
best-valid-loss: 0.428611
best-kappa: 0.8212
: Epoch: 2 | Training Loss: 0.474930 | Val. Loss: 0.428611 | Val. Kappa Score: 0.8212 | Estimated time: 169.50
Train loss on 25 batch: 0.408960
Train loss on 50 batch: 0.339445
Train loss on 75 batch: 0.378834
best-train-loss: 0.354820
best-valid-loss: 0.374150
best-kappa: 0.8319
: Epoch: 3 | Training Loss: 0.354820 | Val. Loss: 0.374150 | Val. Kappa Score: 0.8319 | Estimated time: 165.14
Train loss on 25 batch: 0.298999
Train loss on 50 batch: 0.307430
Train loss on 75 batch: 0.362620
best-train-loss: 0.322112
best-valid-loss: 0.320513
best-kappa: 0.8453
: Epoch: 4 | Training Loss: 0.322112 | Val. Loss: 0.320513 | Val. Kappa Score: 0.8453 | Estimated time: 165.95
Train loss on 25 batch: 0.308002
Train loss on 50 batch: 0.271679
Train loss on 75 batch: 0.404189
best-train-loss: 0.329830
best-valid-loss: 0.310606
best-kappa: 0.8524
: Epoch: 5 | Training Loss: 0.329830 | Val. Loss: 0.310606 | Val. Kappa Score: 0.8524 | Estimated time: 165.68
Train loss on 25 batch: 0.283388
Train loss on 50 batch: 0.315885
Train loss on 75 batch: 0.309523
: Epoch: 6 | Training Loss: 0.293143 | Val. Loss: 0.346479 | Val. Kappa Score: 0.8553 | Estimated time: 165.42
Train loss on 25 batch: 0.283695
Train loss on 50 batch: 0.334791
Train loss on 75 batch: 0.284492
: Epoch: 7 | Training Loss: 0.327031 | Val. Loss: 0.448132 | Val. Kappa Score: 0.8548 | Estimated time: 165.88
Train loss on 25 batch: 0.295911
Train loss on 50 batch: 0.243731
Train loss on 75 batch: 0.255957
best-train-loss: 0.275113
best-valid-loss: 0.286735
best-kappa: 0.8583
: Epoch: 8 | Training Loss: 0.275113 | Val. Loss: 0.286735 | Val. Kappa Score: 0.8583 | Estimated time: 165.83
Train loss on 25 batch: 0.319222
Train loss on 50 batch: 0.287605
Train loss on 75 batch: 0.254641
: Epoch: 9 | Training Loss: 0.275998 | Val. Loss: 0.320426 | Val. Kappa Score: 0.8588 | Estimated time: 170.99
Train loss on 25 batch: 0.228789
Train loss on 50 batch: 0.272534
Train loss on 75 batch: 0.254410
: Epoch: 10 | Training Loss: 0.250551 | Val. Loss: 0.299264 | Val. Kappa Score: 0.8609 | Estimated time: 171.08
Train loss on 25 batch: 0.215853
Train loss on 50 batch: 0.296134
Train loss on 75 batch: 0.238646
: Epoch: 11 | Training Loss: 0.255676 | Val. Loss: 0.339289 | Val. Kappa Score: 0.8638 | Estimated time: 171.39
Train loss on 25 batch: 0.300963
Train loss on 50 batch: 0.215143
Train loss on 75 batch: 0.236013
best-train-loss: 0.246165
best-valid-loss: 0.283747
best-kappa: 0.8660
: Epoch: 12 | Training Loss: 0.246165 | Val. Loss: 0.283747 | Val. Kappa Score: 0.8660 | Estimated time: 168.24
Train loss on 25 batch: 0.191769
Train loss on 50 batch: 0.202512
Train loss on 75 batch: 0.235759
: Epoch: 13 | Training Loss: 0.216496 | Val. Loss: 0.289698 | Val. Kappa Score: 0.8683 | Estimated time: 163.01
Train loss on 25 batch: 0.210726
Train loss on 50 batch: 0.247083
Train loss on 75 batch: 0.229173
: Epoch: 14 | Training Loss: 0.218004 | Val. Loss: 0.284375 | Val. Kappa Score: 0.8697 | Estimated time: 162.40
Train loss on 25 batch: 0.193062
Train loss on 50 batch: 0.218018
Train loss on 75 batch: 0.231814
: Epoch: 15 | Training Loss: 0.211060 | Val. Loss: 0.304522 | Val. Kappa Score: 0.8702 | Estimated time: 162.98
Train loss on 25 batch: 0.193537
Train loss on 50 batch: 0.250929
Train loss on 75 batch: 0.232765
: Epoch: 16 | Training Loss: 0.223746 | Val. Loss: 0.309768 | Val. Kappa Score: 0.8715 | Estimated time: 163.38
Train loss on 25 batch: 0.178894
Train loss on 50 batch: 0.162305
Train loss on 75 batch: 0.187055
: Epoch: 17 | Training Loss: 0.174271 | Val. Loss: 0.303025 | Val. Kappa Score: 0.8728 | Estimated time: 162.93
Train loss on 25 batch: 0.181677
Train loss on 50 batch: 0.191842
Train loss on 75 batch: 0.242713
best-train-loss: 0.209605
best-valid-loss: 0.274007
best-kappa: 0.8743
: Epoch: 18 | Training Loss: 0.209605 | Val. Loss: 0.274007 | Val. Kappa Score: 0.8743 | Estimated time: 162.74
Train loss on 25 batch: 0.195675
Train loss on 50 batch: 0.178907
Train loss on 75 batch: 0.177483
best-train-loss: 0.186261
best-valid-loss: 0.255677
best-kappa: 0.8760
: Epoch: 19 | Training Loss: 0.186261 | Val. Loss: 0.255677 | Val. Kappa Score: 0.8760 | Estimated time: 163.29
Train loss on 25 batch: 0.164399
Train loss on 50 batch: 0.188836
Train loss on 75 batch: 0.193913
: Epoch: 20 | Training Loss: 0.177080 | Val. Loss: 0.301027 | Val. Kappa Score: 0.8773 | Estimated time: 163.11
Train loss on 25 batch: 0.146181
Train loss on 50 batch: 0.146898
Train loss on 75 batch: 0.175143
: Epoch: 21 | Training Loss: 0.156368 | Val. Loss: 0.306681 | Val. Kappa Score: 0.8777 | Estimated time: 161.84
Train loss on 25 batch: 0.170367
Train loss on 50 batch: 0.163083
Train loss on 75 batch: 0.165574
: Epoch: 22 | Training Loss: 0.162705 | Val. Loss: 0.299681 | Val. Kappa Score: 0.8783 | Estimated time: 161.62
Train loss on 25 batch: 0.145613
Train loss on 50 batch: 0.177849
Train loss on 75 batch: 0.164997
: Epoch: 23 | Training Loss: 0.159375 | Val. Loss: 0.282615 | Val. Kappa Score: 0.8790 | Estimated time: 162.65
Train loss on 25 batch: 0.142939
Train loss on 50 batch: 0.158372
Train loss on 75 batch: 0.143223
: Epoch: 24 | Training Loss: 0.146381 | Val. Loss: 0.276226 | Val. Kappa Score: 0.8797 | Estimated time: 163.09
Train loss on 25 batch: 0.136122
Train loss on 50 batch: 0.126709
Train loss on 75 batch: 0.155886
: Epoch: 25 | Training Loss: 0.146798 | Val. Loss: 0.346290 | Val. Kappa Score: 0.8787 | Estimated time: 162.01
Train loss on 25 batch: 0.149392
Train loss on 50 batch: 0.152602
Train loss on 75 batch: 0.128420
: Epoch: 26 | Training Loss: 0.148650 | Val. Loss: 0.309556 | Val. Kappa Score: 0.8786 | Estimated time: 163.39
Train loss on 25 batch: 0.125352
Train loss on 50 batch: 0.158379
Train loss on 75 batch: 0.174946
: Epoch: 27 | Training Loss: 0.164307 | Val. Loss: 0.263918 | Val. Kappa Score: 0.8795 | Estimated time: 163.19
Train loss on 25 batch: 0.130994
Train loss on 50 batch: 0.146068
Train loss on 75 batch: 0.137123
: Epoch: 28 | Training Loss: 0.137597 | Val. Loss: 0.288078 | Val. Kappa Score: 0.8798 | Estimated time: 163.28
Train loss on 25 batch: 0.136317
Train loss on 50 batch: 0.135736
Train loss on 75 batch: 0.111003
: Epoch: 29 | Training Loss: 0.134588 | Val. Loss: 0.292843 | Val. Kappa Score: 0.8796 | Estimated time: 163.17
Train loss on 25 batch: 0.101527
Train loss on 50 batch: 0.116795
Train loss on 75 batch: 0.163152
: Epoch: 30 | Training Loss: 0.126132 | Val. Loss: 0.270598 | Val. Kappa Score: 0.8801 | Estimated time: 163.42
Train loss on 25 batch: 0.134951
Train loss on 50 batch: 0.159048
Train loss on 75 batch: 0.127643
: Epoch: 31 | Training Loss: 0.138623 | Val. Loss: 0.324569 | Val. Kappa Score: 0.8804 | Estimated time: 163.73
Train loss on 25 batch: 0.132250
Train loss on 50 batch: 0.153671
Train loss on 75 batch: 0.147211
: Epoch: 32 | Training Loss: 0.138548 | Val. Loss: 0.279637 | Val. Kappa Score: 0.8807 | Estimated time: 163.48
Train loss on 25 batch: 0.128184
Train loss on 50 batch: 0.125672
Train loss on 75 batch: 0.155947
: Epoch: 33 | Training Loss: 0.131643 | Val. Loss: 0.317702 | Val. Kappa Score: 0.8806 | Estimated time: 163.48
Train loss on 25 batch: 0.116648
Train loss on 50 batch: 0.113282
Train loss on 75 batch: 0.110087
: Epoch: 34 | Training Loss: 0.112009 | Val. Loss: 0.296930 | Val. Kappa Score: 0.8806 | Estimated time: 162.02
Train loss on 25 batch: 0.114331
Train loss on 50 batch: 0.120935
Train loss on 75 batch: 0.168668
: Epoch: 35 | Training Loss: 0.133614 | Val. Loss: 0.293035 | Val. Kappa Score: 0.8809 | Estimated time: 163.58
Train loss on 25 batch: 0.119006
Train loss on 50 batch: 0.108531
Train loss on 75 batch: 0.098171
: Epoch: 36 | Training Loss: 0.112840 | Val. Loss: 0.282917 | Val. Kappa Score: 0.8809 | Estimated time: 163.31
Train loss on 25 batch: 0.122692
Train loss on 50 batch: 0.105209
Train loss on 75 batch: 0.120648
: Epoch: 37 | Training Loss: 0.120433 | Val. Loss: 0.264634 | Val. Kappa Score: 0.8813 | Estimated time: 162.38
Train loss on 25 batch: 0.125792
Train loss on 50 batch: 0.108052
Train loss on 75 batch: 0.131414
: Epoch: 38 | Training Loss: 0.120165 | Val. Loss: 0.307212 | Val. Kappa Score: 0.8815 | Estimated time: 162.38
Train loss on 25 batch: 0.128384
Train loss on 50 batch: 0.107624
Train loss on 75 batch: 0.096538
: Epoch: 39 | Training Loss: 0.107210 | Val. Loss: 0.290512 | Val. Kappa Score: 0.8814 | Estimated time: 162.04
Train loss on 25 batch: 0.093189
Train loss on 50 batch: 0.111850
Train loss on 75 batch: 0.108769
: Epoch: 40 | Training Loss: 0.107073 | Val. Loss: 0.276774 | Val. Kappa Score: 0.8818 | Estimated time: 162.56
Train loss on 25 batch: 0.091953
Train loss on 50 batch: 0.093635
Train loss on 75 batch: 0.101938
: Epoch: 41 | Training Loss: 0.094583 | Val. Loss: 0.314669 | Val. Kappa Score: 0.8818 | Estimated time: 162.76
Train loss on 25 batch: 0.085501
Train loss on 50 batch: 0.087721
Train loss on 75 batch: 0.114385
: Epoch: 42 | Training Loss: 0.098297 | Val. Loss: 0.289064 | Val. Kappa Score: 0.8820 | Estimated time: 162.58
Train loss on 25 batch: 0.088295
Train loss on 50 batch: 0.102492
Train loss on 75 batch: 0.099031
: Epoch: 43 | Training Loss: 0.097370 | Val. Loss: 0.275256 | Val. Kappa Score: 0.8824 | Estimated time: 162.83
Train loss on 25 batch: 0.092878
Train loss on 50 batch: 0.102971
Train loss on 75 batch: 0.107317
: Epoch: 44 | Training Loss: 0.104850 | Val. Loss: 0.293453 | Val. Kappa Score: 0.8824 | Estimated time: 163.03
Train loss on 25 batch: 0.099176
Train loss on 50 batch: 0.101581
Train loss on 75 batch: 0.100616
: Epoch: 45 | Training Loss: 0.103423 | Val. Loss: 0.260618 | Val. Kappa Score: 0.8828 | Estimated time: 164.43
Train loss on 25 batch: 0.088393
Train loss on 50 batch: 0.100988
Train loss on 75 batch: 0.090765
: Epoch: 46 | Training Loss: 0.088965 | Val. Loss: 0.309236 | Val. Kappa Score: 0.8831 | Estimated time: 163.14
Train loss on 25 batch: 0.077195
Train loss on 50 batch: 0.085003
Train loss on 75 batch: 0.085181
: Epoch: 47 | Training Loss: 0.081304 | Val. Loss: 0.301504 | Val. Kappa Score: 0.8832 | Estimated time: 162.68
Train loss on 25 batch: 0.071187
Train loss on 50 batch: 0.067498
Train loss on 75 batch: 0.090475
: Epoch: 48 | Training Loss: 0.079325 | Val. Loss: 0.296875 | Val. Kappa Score: 0.8833 | Estimated time: 162.21
Train loss on 25 batch: 0.102618
Train loss on 50 batch: 0.101680
Train loss on 75 batch: 0.110367
: Epoch: 49 | Training Loss: 0.101430 | Val. Loss: 0.298367 | Val. Kappa Score: 0.8834 | Estimated time: 163.71
Train loss on 25 batch: 0.079594
Train loss on 50 batch: 0.104163
Train loss on 75 batch: 0.081654
: Epoch: 50 | Training Loss: 0.086403 | Val. Loss: 0.334521 | Val. Kappa Score: 0.8832 | Estimated time: 162.19
Train loss on 25 batch: 0.075199
Train loss on 50 batch: 0.081898
Train loss on 75 batch: 0.065496
: Epoch: 51 | Training Loss: 0.074537 | Val. Loss: 0.287025 | Val. Kappa Score: 0.8833 | Estimated time: 163.13
Train loss on 25 batch: 0.056614
Train loss on 50 batch: 0.069083
Train loss on 75 batch: 0.084724
: Epoch: 52 | Training Loss: 0.078304 | Val. Loss: 0.281038 | Val. Kappa Score: 0.8836 | Estimated time: 163.17
Train loss on 25 batch: 0.078522
Train loss on 50 batch: 0.074614
Train loss on 75 batch: 0.079705
: Epoch: 53 | Training Loss: 0.080675 | Val. Loss: 0.326475 | Val. Kappa Score: 0.8836 | Estimated time: 164.68
Train loss on 25 batch: 0.077902
Train loss on 50 batch: 0.088982
Train loss on 75 batch: 0.071247
: Epoch: 54 | Training Loss: 0.078381 | Val. Loss: 0.281174 | Val. Kappa Score: 0.8839 | Estimated time: 163.73
Train loss on 25 batch: 0.071464
Train loss on 50 batch: 0.075468
Train loss on 75 batch: 0.069564
: Epoch: 55 | Training Loss: 0.074121 | Val. Loss: 0.322769 | Val. Kappa Score: 0.8839 | Estimated time: 161.65
Train loss on 25 batch: 0.071146
Train loss on 50 batch: 0.071887
Train loss on 75 batch: 0.058579
: Epoch: 56 | Training Loss: 0.070229 | Val. Loss: 0.267643 | Val. Kappa Score: 0.8841 | Estimated time: 161.81
Train loss on 25 batch: 0.092779
Train loss on 50 batch: 0.075596
Train loss on 75 batch: 0.086585
: Epoch: 57 | Training Loss: 0.082027 | Val. Loss: 0.309667 | Val. Kappa Score: 0.8841 | Estimated time: 161.65
Train loss on 25 batch: 0.073783
Train loss on 50 batch: 0.075125
Train loss on 75 batch: 0.067397
: Epoch: 58 | Training Loss: 0.073974 | Val. Loss: 0.273186 | Val. Kappa Score: 0.8843 | Estimated time: 161.83
Train loss on 25 batch: 0.075765
Train loss on 50 batch: 0.081015
Train loss on 75 batch: 0.083086
: Epoch: 59 | Training Loss: 0.076361 | Val. Loss: 0.322403 | Val. Kappa Score: 0.8841 | Estimated time: 163.19
Train loss on 25 batch: 0.057738
Train loss on 50 batch: 0.061127
Train loss on 75 batch: 0.073921
: Epoch: 60 | Training Loss: 0.064723 | Val. Loss: 0.265981 | Val. Kappa Score: 0.8844 | Estimated time: 162.96
Train loss on 25 batch: 0.056112
Train loss on 50 batch: 0.056173
Train loss on 75 batch: 0.076435
: Epoch: 61 | Training Loss: 0.063502 | Val. Loss: 0.275751 | Val. Kappa Score: 0.8846 | Estimated time: 162.01
Train loss on 25 batch: 0.087728
Train loss on 50 batch: 0.068513
Train loss on 75 batch: 0.070529
: Epoch: 62 | Training Loss: 0.074761 | Val. Loss: 0.284587 | Val. Kappa Score: 0.8847 | Estimated time: 162.29
Train loss on 25 batch: 0.062017
Train loss on 50 batch: 0.059807
Train loss on 75 batch: 0.071496
: Epoch: 63 | Training Loss: 0.065912 | Val. Loss: 0.287927 | Val. Kappa Score: 0.8848 | Estimated time: 164.04
Train loss on 25 batch: 0.063483
Train loss on 50 batch: 0.059082
Train loss on 75 batch: 0.054855
: Epoch: 64 | Training Loss: 0.061840 | Val. Loss: 0.282324 | Val. Kappa Score: 0.8850 | Estimated time: 162.97
Train loss on 25 batch: 0.075288
Train loss on 50 batch: 0.054211
Train loss on 75 batch: 0.071973
: Epoch: 65 | Training Loss: 0.067735 | Val. Loss: 0.294581 | Val. Kappa Score: 0.8851 | Estimated time: 164.79
Train loss on 25 batch: 0.060931
Train loss on 50 batch: 0.050118
Train loss on 75 batch: 0.071551
: Epoch: 66 | Training Loss: 0.062225 | Val. Loss: 0.321638 | Val. Kappa Score: 0.8848 | Estimated time: 162.40
Train loss on 25 batch: 0.065105
Train loss on 50 batch: 0.082082
Train loss on 75 batch: 0.083973
: Epoch: 67 | Training Loss: 0.076704 | Val. Loss: 0.529670 | Val. Kappa Score: 0.8831 | Estimated time: 162.79
Train loss on 25 batch: 0.057843
Train loss on 50 batch: 0.062232
Train loss on 75 batch: 0.076271
: Epoch: 68 | Training Loss: 0.064931 | Val. Loss: 0.290673 | Val. Kappa Score: 0.8831 | Estimated time: 161.77
Train loss on 25 batch: 0.070921
Train loss on 50 batch: 0.088399
Train loss on 75 batch: 0.072297
: Epoch: 69 | Training Loss: 0.075953 | Val. Loss: 0.291309 | Val. Kappa Score: 0.8833 | Estimated time: 162.72
Train loss on 25 batch: 0.080417
Train loss on 50 batch: 0.081654
Train loss on 75 batch: 0.056292
: Epoch: 70 | Training Loss: 0.073321 | Val. Loss: 0.282195 | Val. Kappa Score: 0.8833 | Estimated time: 162.42
Train loss on 25 batch: 0.067198
Train loss on 50 batch: 0.063187
Train loss on 75 batch: 0.065314
: Epoch: 71 | Training Loss: 0.068390 | Val. Loss: 0.282222 | Val. Kappa Score: 0.8836 | Estimated time: 163.28
Train loss on 25 batch: 0.088428
Train loss on 50 batch: 0.066619
Train loss on 75 batch: 0.060135
: Epoch: 72 | Training Loss: 0.066330 | Val. Loss: 0.275542 | Val. Kappa Score: 0.8837 | Estimated time: 162.83
Train loss on 25 batch: 0.076652
Train loss on 50 batch: 0.075952
Train loss on 75 batch: 0.065746
: Epoch: 73 | Training Loss: 0.071257 | Val. Loss: 0.303465 | Val. Kappa Score: 0.8837 | Estimated time: 163.53
time_estimated: 11959.07
n-epochs: 73
time_estimated: 11959.07
----------------------------------------

Experiment N: 35: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.08 01:02:16
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 5320317
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.154734
Train loss on 50 batch: 0.808981
Train loss on 75 batch: 0.561245
best-train-loss: 0.746522
best-valid-loss: 0.693261
best-kappa: 0.7183
: Epoch: 1 | Training Loss: 0.746522 | Val. Loss: 0.693261 | Val. Kappa Score: 0.7183 | Estimated time: 151.49
Train loss on 25 batch: 0.479711
Train loss on 50 batch: 0.452915
Train loss on 75 batch: 0.481492
best-train-loss: 0.470470
best-valid-loss: 0.452932
best-kappa: 0.7693
: Epoch: 2 | Training Loss: 0.470470 | Val. Loss: 0.452932 | Val. Kappa Score: 0.7693 | Estimated time: 152.68
Train loss on 25 batch: 0.440089
Train loss on 50 batch: 0.426008
Train loss on 75 batch: 0.439899
best-train-loss: 0.436524
best-valid-loss: 0.428677
best-kappa: 0.7995
: Epoch: 3 | Training Loss: 0.436524 | Val. Loss: 0.428677 | Val. Kappa Score: 0.7995 | Estimated time: 151.87
Train loss on 25 batch: 0.355782
Train loss on 50 batch: 0.361567
Train loss on 75 batch: 0.437708
best-train-loss: 0.378581
best-valid-loss: 0.400969
best-kappa: 0.8167
: Epoch: 4 | Training Loss: 0.378581 | Val. Loss: 0.400969 | Val. Kappa Score: 0.8167 | Estimated time: 152.16
Train loss on 25 batch: 0.316625
Train loss on 50 batch: 0.307968
Train loss on 75 batch: 0.431339
: Epoch: 5 | Training Loss: 0.351166 | Val. Loss: 0.402908 | Val. Kappa Score: 0.8258 | Estimated time: 152.03
Train loss on 25 batch: 0.346630
Train loss on 50 batch: 0.322499
Train loss on 75 batch: 0.318936
best-train-loss: 0.312470
best-valid-loss: 0.350377
best-kappa: 0.8333
: Epoch: 6 | Training Loss: 0.312470 | Val. Loss: 0.350377 | Val. Kappa Score: 0.8333 | Estimated time: 153.71
Train loss on 25 batch: 0.291099
Train loss on 50 batch: 0.350192
Train loss on 75 batch: 0.322507
: Epoch: 7 | Training Loss: 0.329182 | Val. Loss: 0.372207 | Val. Kappa Score: 0.8383 | Estimated time: 152.51
Train loss on 25 batch: 0.322977
Train loss on 50 batch: 0.257809
Train loss on 75 batch: 0.274018
best-train-loss: 0.289132
best-valid-loss: 0.343497
best-kappa: 0.8414
: Epoch: 8 | Training Loss: 0.289132 | Val. Loss: 0.343497 | Val. Kappa Score: 0.8414 | Estimated time: 152.27
Train loss on 25 batch: 0.352149
Train loss on 50 batch: 0.268316
Train loss on 75 batch: 0.244111
best-train-loss: 0.281704
best-valid-loss: 0.335544
best-kappa: 0.8454
: Epoch: 9 | Training Loss: 0.281704 | Val. Loss: 0.335544 | Val. Kappa Score: 0.8454 | Estimated time: 152.47
Train loss on 25 batch: 0.249611
Train loss on 50 batch: 0.287819
Train loss on 75 batch: 0.302091
best-train-loss: 0.271199
best-valid-loss: 0.323462
best-kappa: 0.8492
: Epoch: 10 | Training Loss: 0.271199 | Val. Loss: 0.323462 | Val. Kappa Score: 0.8492 | Estimated time: 151.85
Train loss on 25 batch: 0.202655
Train loss on 50 batch: 0.282626
Train loss on 75 batch: 0.231167
: Epoch: 11 | Training Loss: 0.246079 | Val. Loss: 0.351006 | Val. Kappa Score: 0.8518 | Estimated time: 152.16
Train loss on 25 batch: 0.241799
Train loss on 50 batch: 0.234924
Train loss on 75 batch: 0.203355
: Epoch: 12 | Training Loss: 0.230209 | Val. Loss: 0.338533 | Val. Kappa Score: 0.8540 | Estimated time: 151.96
Train loss on 25 batch: 0.199105
Train loss on 50 batch: 0.186426
Train loss on 75 batch: 0.271004
: Epoch: 13 | Training Loss: 0.229429 | Val. Loss: 0.362368 | Val. Kappa Score: 0.8560 | Estimated time: 152.42
Train loss on 25 batch: 0.198192
Train loss on 50 batch: 0.244897
Train loss on 75 batch: 0.188606
: Epoch: 14 | Training Loss: 0.201722 | Val. Loss: 0.349592 | Val. Kappa Score: 0.8560 | Estimated time: 151.95
Train loss on 25 batch: 0.184299
Train loss on 50 batch: 0.193759
Train loss on 75 batch: 0.224507
: Epoch: 15 | Training Loss: 0.197694 | Val. Loss: 0.336553 | Val. Kappa Score: 0.8574 | Estimated time: 151.84
Train loss on 25 batch: 0.191040
Train loss on 50 batch: 0.222023
Train loss on 75 batch: 0.167496
best-train-loss: 0.192970
best-valid-loss: 0.312298
best-kappa: 0.8593
: Epoch: 16 | Training Loss: 0.192970 | Val. Loss: 0.312298 | Val. Kappa Score: 0.8593 | Estimated time: 152.17
Train loss on 25 batch: 0.179988
Train loss on 50 batch: 0.165259
Train loss on 75 batch: 0.195969
: Epoch: 17 | Training Loss: 0.175886 | Val. Loss: 0.335107 | Val. Kappa Score: 0.8604 | Estimated time: 152.09
Train loss on 25 batch: 0.164526
Train loss on 50 batch: 0.147910
Train loss on 75 batch: 0.178615
: Epoch: 18 | Training Loss: 0.165917 | Val. Loss: 0.336489 | Val. Kappa Score: 0.8609 | Estimated time: 152.46
Train loss on 25 batch: 0.182669
Train loss on 50 batch: 0.159634
Train loss on 75 batch: 0.162763
: Epoch: 19 | Training Loss: 0.171729 | Val. Loss: 0.330403 | Val. Kappa Score: 0.8622 | Estimated time: 152.51
Train loss on 25 batch: 0.151075
Train loss on 50 batch: 0.189954
Train loss on 75 batch: 0.185019
best-train-loss: 0.167965
best-valid-loss: 0.309367
best-kappa: 0.8632
: Epoch: 20 | Training Loss: 0.167965 | Val. Loss: 0.309367 | Val. Kappa Score: 0.8632 | Estimated time: 151.88
Train loss on 25 batch: 0.165469
Train loss on 50 batch: 0.142677
Train loss on 75 batch: 0.156515
best-train-loss: 0.147883
best-valid-loss: 0.285261
best-kappa: 0.8643
: Epoch: 21 | Training Loss: 0.147883 | Val. Loss: 0.285261 | Val. Kappa Score: 0.8643 | Estimated time: 151.27
Train loss on 25 batch: 0.144335
Train loss on 50 batch: 0.139042
Train loss on 75 batch: 0.140238
: Epoch: 22 | Training Loss: 0.141200 | Val. Loss: 0.295619 | Val. Kappa Score: 0.8654 | Estimated time: 151.46
Train loss on 25 batch: 0.124101
Train loss on 50 batch: 0.159819
Train loss on 75 batch: 0.114653
: Epoch: 23 | Training Loss: 0.136909 | Val. Loss: 0.302620 | Val. Kappa Score: 0.8665 | Estimated time: 152.06
Train loss on 25 batch: 0.117118
Train loss on 50 batch: 0.132750
Train loss on 75 batch: 0.123212
: Epoch: 24 | Training Loss: 0.125827 | Val. Loss: 0.315462 | Val. Kappa Score: 0.8673 | Estimated time: 152.62
Train loss on 25 batch: 0.134727
Train loss on 50 batch: 0.125228
Train loss on 75 batch: 0.133324
: Epoch: 25 | Training Loss: 0.134542 | Val. Loss: 0.330775 | Val. Kappa Score: 0.8678 | Estimated time: 152.28
Train loss on 25 batch: 0.125642
Train loss on 50 batch: 0.151882
Train loss on 75 batch: 0.154539
: Epoch: 26 | Training Loss: 0.139981 | Val. Loss: 0.313581 | Val. Kappa Score: 0.8679 | Estimated time: 152.65
Train loss on 25 batch: 0.129726
Train loss on 50 batch: 0.109137
Train loss on 75 batch: 0.145763
: Epoch: 27 | Training Loss: 0.135291 | Val. Loss: 0.314332 | Val. Kappa Score: 0.8686 | Estimated time: 152.07
Train loss on 25 batch: 0.131554
Train loss on 50 batch: 0.126626
Train loss on 75 batch: 0.141491
: Epoch: 28 | Training Loss: 0.127253 | Val. Loss: 0.325212 | Val. Kappa Score: 0.8692 | Estimated time: 152.80
Train loss on 25 batch: 0.110777
Train loss on 50 batch: 0.110249
Train loss on 75 batch: 0.102590
: Epoch: 29 | Training Loss: 0.110835 | Val. Loss: 0.310421 | Val. Kappa Score: 0.8695 | Estimated time: 153.03
time_estimated: 4415.18
n-epochs: 29
time_estimated: 4415.19
----------------------------------------

Experiment N: 36: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.08 02:15:52
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 7825953
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.189894
Train loss on 50 batch: 0.787558
Train loss on 75 batch: 0.603356
best-train-loss: 0.771727
best-valid-loss: 1.596958
best-kappa: 0.3791
: Epoch: 1 | Training Loss: 0.771727 | Val. Loss: 1.596958 | Val. Kappa Score: 0.3791 | Estimated time: 151.85
Train loss on 25 batch: 0.526284
Train loss on 50 batch: 0.488465
Train loss on 75 batch: 0.484228
best-train-loss: 0.514052
best-valid-loss: 0.697665
best-kappa: 0.5504
: Epoch: 2 | Training Loss: 0.514052 | Val. Loss: 0.697665 | Val. Kappa Score: 0.5504 | Estimated time: 153.25
Train loss on 25 batch: 0.459100
Train loss on 50 batch: 0.439482
Train loss on 75 batch: 0.468488
: Epoch: 3 | Training Loss: 0.462439 | Val. Loss: 0.732410 | Val. Kappa Score: 0.6062 | Estimated time: 153.01
Train loss on 25 batch: 0.407260
Train loss on 50 batch: 0.375925
Train loss on 75 batch: 0.448390
best-train-loss: 0.401260
best-valid-loss: 0.504049
best-kappa: 0.6562
: Epoch: 4 | Training Loss: 0.401260 | Val. Loss: 0.504049 | Val. Kappa Score: 0.6562 | Estimated time: 153.14
Train loss on 25 batch: 0.332234
Train loss on 50 batch: 0.305476
Train loss on 75 batch: 0.464791
best-train-loss: 0.347994
best-valid-loss: 0.473948
best-kappa: 0.6874
: Epoch: 5 | Training Loss: 0.347994 | Val. Loss: 0.473948 | Val. Kappa Score: 0.6874 | Estimated time: 152.22
Train loss on 25 batch: 0.328714
Train loss on 50 batch: 0.350445
Train loss on 75 batch: 0.334522
best-train-loss: 0.322923
best-valid-loss: 0.409598
best-kappa: 0.7127
: Epoch: 6 | Training Loss: 0.322923 | Val. Loss: 0.409598 | Val. Kappa Score: 0.7127 | Estimated time: 153.52
Train loss on 25 batch: 0.285693
Train loss on 50 batch: 0.349541
Train loss on 75 batch: 0.294356
best-train-loss: 0.324898
best-valid-loss: 0.405941
best-kappa: 0.7304
: Epoch: 7 | Training Loss: 0.324898 | Val. Loss: 0.405941 | Val. Kappa Score: 0.7304 | Estimated time: 152.43
Train loss on 25 batch: 0.309576
Train loss on 50 batch: 0.232737
Train loss on 75 batch: 0.266623
best-train-loss: 0.271725
best-valid-loss: 0.358898
best-kappa: 0.7456
: Epoch: 8 | Training Loss: 0.271725 | Val. Loss: 0.358898 | Val. Kappa Score: 0.7456 | Estimated time: 152.11
Train loss on 25 batch: 0.330078
Train loss on 50 batch: 0.276778
Train loss on 75 batch: 0.240064
: Epoch: 9 | Training Loss: 0.275727 | Val. Loss: 0.376994 | Val. Kappa Score: 0.7561 | Estimated time: 152.15
Train loss on 25 batch: 0.219735
Train loss on 50 batch: 0.262425
Train loss on 75 batch: 0.298008
: Epoch: 10 | Training Loss: 0.265497 | Val. Loss: 0.394445 | Val. Kappa Score: 0.7650 | Estimated time: 152.81
Train loss on 25 batch: 0.207707
Train loss on 50 batch: 0.257725
Train loss on 75 batch: 0.245733
: Epoch: 11 | Training Loss: 0.240286 | Val. Loss: 0.389183 | Val. Kappa Score: 0.7724 | Estimated time: 152.97
Train loss on 25 batch: 0.249583
Train loss on 50 batch: 0.231925
Train loss on 75 batch: 0.196703
best-train-loss: 0.233067
best-valid-loss: 0.349389
best-kappa: 0.7814
: Epoch: 12 | Training Loss: 0.233067 | Val. Loss: 0.349389 | Val. Kappa Score: 0.7814 | Estimated time: 151.58
Train loss on 25 batch: 0.189894
Train loss on 50 batch: 0.179131
Train loss on 75 batch: 0.254539
: Epoch: 13 | Training Loss: 0.224616 | Val. Loss: 0.353834 | Val. Kappa Score: 0.7880 | Estimated time: 152.14
Train loss on 25 batch: 0.201468
Train loss on 50 batch: 0.242301
Train loss on 75 batch: 0.201790
: Epoch: 14 | Training Loss: 0.208246 | Val. Loss: 0.356368 | Val. Kappa Score: 0.7929 | Estimated time: 151.66
Train loss on 25 batch: 0.170392
Train loss on 50 batch: 0.184280
Train loss on 75 batch: 0.194300
: Epoch: 15 | Training Loss: 0.189819 | Val. Loss: 0.358042 | Val. Kappa Score: 0.7976 | Estimated time: 152.31
Train loss on 25 batch: 0.177670
Train loss on 50 batch: 0.226845
Train loss on 75 batch: 0.192114
best-train-loss: 0.188381
best-valid-loss: 0.310495
best-kappa: 0.8032
: Epoch: 16 | Training Loss: 0.188381 | Val. Loss: 0.310495 | Val. Kappa Score: 0.8032 | Estimated time: 152.51
Train loss on 25 batch: 0.178320
Train loss on 50 batch: 0.154110
Train loss on 75 batch: 0.193634
: Epoch: 17 | Training Loss: 0.168960 | Val. Loss: 0.322639 | Val. Kappa Score: 0.8076 | Estimated time: 152.86
Train loss on 25 batch: 0.174165
Train loss on 50 batch: 0.163513
Train loss on 75 batch: 0.174595
: Epoch: 18 | Training Loss: 0.171262 | Val. Loss: 0.391202 | Val. Kappa Score: 0.8094 | Estimated time: 152.32
Train loss on 25 batch: 0.150441
Train loss on 50 batch: 0.146875
Train loss on 75 batch: 0.160152
: Epoch: 19 | Training Loss: 0.158426 | Val. Loss: 0.333319 | Val. Kappa Score: 0.8123 | Estimated time: 152.59
Train loss on 25 batch: 0.151082
Train loss on 50 batch: 0.172755
Train loss on 75 batch: 0.165330
: Epoch: 20 | Training Loss: 0.159561 | Val. Loss: 0.384497 | Val. Kappa Score: 0.8140 | Estimated time: 152.34
Train loss on 25 batch: 0.155304
Train loss on 50 batch: 0.136582
Train loss on 75 batch: 0.147484
: Epoch: 21 | Training Loss: 0.142445 | Val. Loss: 0.345887 | Val. Kappa Score: 0.8163 | Estimated time: 152.90
Train loss on 25 batch: 0.148714
Train loss on 50 batch: 0.129982
Train loss on 75 batch: 0.152357
: Epoch: 22 | Training Loss: 0.146543 | Val. Loss: 0.335905 | Val. Kappa Score: 0.8189 | Estimated time: 151.23
Train loss on 25 batch: 0.129600
Train loss on 50 batch: 0.146971
Train loss on 75 batch: 0.119342
: Epoch: 23 | Training Loss: 0.132119 | Val. Loss: 0.323709 | Val. Kappa Score: 0.8211 | Estimated time: 152.41
Train loss on 25 batch: 0.117296
Train loss on 50 batch: 0.134463
Train loss on 75 batch: 0.131825
: Epoch: 24 | Training Loss: 0.129987 | Val. Loss: 0.330248 | Val. Kappa Score: 0.8233 | Estimated time: 153.88
time_estimated: 3660.66
n-epochs: 24
time_estimated: 3660.67
----------------------------------------

Experiment N: 37: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.08 03:16:52
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 9144835
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.261033
Train loss on 50 batch: 0.834301
Train loss on 75 batch: 0.627501
best-train-loss: 0.822522
best-valid-loss: 1.106235
best-kappa: 0.5801
: Epoch: 1 | Training Loss: 0.822522 | Val. Loss: 1.106235 | Val. Kappa Score: 0.5801 | Estimated time: 152.49
Train loss on 25 batch: 0.506227
Train loss on 50 batch: 0.461913
Train loss on 75 batch: 0.508432
best-train-loss: 0.492121
best-valid-loss: 0.462707
best-kappa: 0.6985
: Epoch: 2 | Training Loss: 0.492121 | Val. Loss: 0.462707 | Val. Kappa Score: 0.6985 | Estimated time: 153.58
Train loss on 25 batch: 0.467728
Train loss on 50 batch: 0.416511
Train loss on 75 batch: 0.440357
: Epoch: 3 | Training Loss: 0.442862 | Val. Loss: 0.471204 | Val. Kappa Score: 0.7390 | Estimated time: 152.05
Train loss on 25 batch: 0.347846
Train loss on 50 batch: 0.374033
Train loss on 75 batch: 0.482878
best-train-loss: 0.392245
best-valid-loss: 0.462550
best-kappa: 0.7630
: Epoch: 4 | Training Loss: 0.392245 | Val. Loss: 0.462550 | Val. Kappa Score: 0.7630 | Estimated time: 152.31
Train loss on 25 batch: 0.352791
Train loss on 50 batch: 0.299363
Train loss on 75 batch: 0.443784
best-train-loss: 0.346760
best-valid-loss: 0.385540
best-kappa: 0.7817
: Epoch: 5 | Training Loss: 0.346760 | Val. Loss: 0.385540 | Val. Kappa Score: 0.7817 | Estimated time: 152.43
Train loss on 25 batch: 0.343838
Train loss on 50 batch: 0.356664
Train loss on 75 batch: 0.356312
best-train-loss: 0.329007
best-valid-loss: 0.344322
best-kappa: 0.7956
: Epoch: 6 | Training Loss: 0.329007 | Val. Loss: 0.344322 | Val. Kappa Score: 0.7956 | Estimated time: 152.29
Train loss on 25 batch: 0.272791
Train loss on 50 batch: 0.346542
Train loss on 75 batch: 0.299821
best-train-loss: 0.320847
best-valid-loss: 0.331594
best-kappa: 0.8077
: Epoch: 7 | Training Loss: 0.320847 | Val. Loss: 0.331594 | Val. Kappa Score: 0.8077 | Estimated time: 152.32
Train loss on 25 batch: 0.319524
Train loss on 50 batch: 0.253856
Train loss on 75 batch: 0.285223
: Epoch: 8 | Training Loss: 0.282617 | Val. Loss: 0.355936 | Val. Kappa Score: 0.8126 | Estimated time: 151.85
Train loss on 25 batch: 0.312649
Train loss on 50 batch: 0.272508
Train loss on 75 batch: 0.237560
: Epoch: 9 | Training Loss: 0.264342 | Val. Loss: 0.355536 | Val. Kappa Score: 0.8179 | Estimated time: 152.14
Train loss on 25 batch: 0.227522
Train loss on 50 batch: 0.262340
Train loss on 75 batch: 0.259392
: Epoch: 10 | Training Loss: 0.244886 | Val. Loss: 0.339191 | Val. Kappa Score: 0.8226 | Estimated time: 153.08
Train loss on 25 batch: 0.212480
Train loss on 50 batch: 0.263305
Train loss on 75 batch: 0.237370
best-train-loss: 0.241640
best-valid-loss: 0.315824
best-kappa: 0.8279
: Epoch: 11 | Training Loss: 0.241640 | Val. Loss: 0.315824 | Val. Kappa Score: 0.8279 | Estimated time: 152.22
Train loss on 25 batch: 0.254435
Train loss on 50 batch: 0.218678
Train loss on 75 batch: 0.202167
best-train-loss: 0.227576
best-valid-loss: 0.313955
best-kappa: 0.8331
: Epoch: 12 | Training Loss: 0.227576 | Val. Loss: 0.313955 | Val. Kappa Score: 0.8331 | Estimated time: 152.53
Train loss on 25 batch: 0.187566
Train loss on 50 batch: 0.169158
Train loss on 75 batch: 0.255642
: Epoch: 13 | Training Loss: 0.219928 | Val. Loss: 0.324176 | Val. Kappa Score: 0.8367 | Estimated time: 152.84
Train loss on 25 batch: 0.221399
Train loss on 50 batch: 0.246734
Train loss on 75 batch: 0.178751
: Epoch: 14 | Training Loss: 0.206220 | Val. Loss: 0.315459 | Val. Kappa Score: 0.8396 | Estimated time: 152.22
Train loss on 25 batch: 0.164845
Train loss on 50 batch: 0.183416
Train loss on 75 batch: 0.196439
: Epoch: 15 | Training Loss: 0.185141 | Val. Loss: 0.315625 | Val. Kappa Score: 0.8424 | Estimated time: 152.55
Train loss on 25 batch: 0.174704
Train loss on 50 batch: 0.213847
Train loss on 75 batch: 0.166526
best-train-loss: 0.177507
best-valid-loss: 0.307954
best-kappa: 0.8453
: Epoch: 16 | Training Loss: 0.177507 | Val. Loss: 0.307954 | Val. Kappa Score: 0.8453 | Estimated time: 152.97
Train loss on 25 batch: 0.160901
Train loss on 50 batch: 0.154063
Train loss on 75 batch: 0.177731
: Epoch: 17 | Training Loss: 0.162224 | Val. Loss: 0.315061 | Val. Kappa Score: 0.8469 | Estimated time: 153.27
Train loss on 25 batch: 0.147781
Train loss on 50 batch: 0.149574
Train loss on 75 batch: 0.167980
: Epoch: 18 | Training Loss: 0.157240 | Val. Loss: 0.349081 | Val. Kappa Score: 0.8479 | Estimated time: 152.78
Train loss on 25 batch: 0.183663
Train loss on 50 batch: 0.146919
Train loss on 75 batch: 0.141427
: Epoch: 19 | Training Loss: 0.162094 | Val. Loss: 0.325271 | Val. Kappa Score: 0.8493 | Estimated time: 152.55
Train loss on 25 batch: 0.154040
Train loss on 50 batch: 0.161690
Train loss on 75 batch: 0.165123
: Epoch: 20 | Training Loss: 0.154714 | Val. Loss: 0.356352 | Val. Kappa Score: 0.8496 | Estimated time: 152.19
Train loss on 25 batch: 0.156146
Train loss on 50 batch: 0.126935
Train loss on 75 batch: 0.135054
: Epoch: 21 | Training Loss: 0.138965 | Val. Loss: 0.318061 | Val. Kappa Score: 0.8507 | Estimated time: 152.56
Train loss on 25 batch: 0.123207
Train loss on 50 batch: 0.124476
Train loss on 75 batch: 0.142924
best-train-loss: 0.129978
best-valid-loss: 0.284721
best-kappa: 0.8528
: Epoch: 22 | Training Loss: 0.129978 | Val. Loss: 0.284721 | Val. Kappa Score: 0.8528 | Estimated time: 151.34
Train loss on 25 batch: 0.112856
Train loss on 50 batch: 0.124421
Train loss on 75 batch: 0.117363
: Epoch: 23 | Training Loss: 0.118993 | Val. Loss: 0.294373 | Val. Kappa Score: 0.8541 | Estimated time: 152.43
Train loss on 25 batch: 0.101044
Train loss on 50 batch: 0.132017
Train loss on 75 batch: 0.107362
: Epoch: 24 | Training Loss: 0.112016 | Val. Loss: 0.312635 | Val. Kappa Score: 0.8552 | Estimated time: 151.95
Train loss on 25 batch: 0.110126
Train loss on 50 batch: 0.115089
Train loss on 75 batch: 0.117557
: Epoch: 25 | Training Loss: 0.117266 | Val. Loss: 0.323981 | Val. Kappa Score: 0.8561 | Estimated time: 152.15
Train loss on 25 batch: 0.121459
Train loss on 50 batch: 0.117476
Train loss on 75 batch: 0.118416
: Epoch: 26 | Training Loss: 0.119313 | Val. Loss: 0.329532 | Val. Kappa Score: 0.8568 | Estimated time: 153.19
Train loss on 25 batch: 0.104232
Train loss on 50 batch: 0.114432
Train loss on 75 batch: 0.127190
: Epoch: 27 | Training Loss: 0.122831 | Val. Loss: 0.307025 | Val. Kappa Score: 0.8577 | Estimated time: 153.20
Train loss on 25 batch: 0.108180
Train loss on 50 batch: 0.112072
Train loss on 75 batch: 0.108633
: Epoch: 28 | Training Loss: 0.110160 | Val. Loss: 0.311309 | Val. Kappa Score: 0.8587 | Estimated time: 153.83
Train loss on 25 batch: 0.116332
Train loss on 50 batch: 0.094533
Train loss on 75 batch: 0.090816
: Epoch: 29 | Training Loss: 0.102591 | Val. Loss: 0.315989 | Val. Kappa Score: 0.8594 | Estimated time: 153.33
Train loss on 25 batch: 0.086633
Train loss on 50 batch: 0.104638
Train loss on 75 batch: 0.113085
: Epoch: 30 | Training Loss: 0.101121 | Val. Loss: 0.305765 | Val. Kappa Score: 0.8600 | Estimated time: 153.45
time_estimated: 4578.67
n-epochs: 30
time_estimated: 4578.68
----------------------------------------

Experiment N: 38: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.08 08:03:14
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 12271145
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.357332
Train loss on 50 batch: 0.866302
Train loss on 75 batch: 0.688150
best-train-loss: 0.876822
best-valid-loss: 1.706852
best-kappa: 0.4041
: Epoch: 1 | Training Loss: 0.876822 | Val. Loss: 1.706852 | Val. Kappa Score: 0.4041 | Estimated time: 153.12
Train loss on 25 batch: 0.515397
Train loss on 50 batch: 0.520237
Train loss on 75 batch: 0.513997
best-train-loss: 0.507890
best-valid-loss: 0.688727
best-kappa: 0.5643
: Epoch: 2 | Training Loss: 0.507890 | Val. Loss: 0.688727 | Val. Kappa Score: 0.5643 | Estimated time: 153.88
Train loss on 25 batch: 0.491472
Train loss on 50 batch: 0.410590
Train loss on 75 batch: 0.451440
best-train-loss: 0.447727
best-valid-loss: 0.575835
best-kappa: 0.6383
: Epoch: 3 | Training Loss: 0.447727 | Val. Loss: 0.575835 | Val. Kappa Score: 0.6383 | Estimated time: 153.10
Train loss on 25 batch: 0.399995
Train loss on 50 batch: 0.351723
Train loss on 75 batch: 0.469655
best-train-loss: 0.401175
best-valid-loss: 0.437677
best-kappa: 0.6913
: Epoch: 4 | Training Loss: 0.401175 | Val. Loss: 0.437677 | Val. Kappa Score: 0.6913 | Estimated time: 153.17
Train loss on 25 batch: 0.325830
Train loss on 50 batch: 0.288471
Train loss on 75 batch: 0.440197
: Epoch: 5 | Training Loss: 0.344391 | Val. Loss: 0.438677 | Val. Kappa Score: 0.7181 | Estimated time: 152.63
Train loss on 25 batch: 0.323553
Train loss on 50 batch: 0.377533
Train loss on 75 batch: 0.333412
best-train-loss: 0.322412
best-valid-loss: 0.382656
best-kappa: 0.7409
: Epoch: 6 | Training Loss: 0.322412 | Val. Loss: 0.382656 | Val. Kappa Score: 0.7409 | Estimated time: 154.22
Train loss on 25 batch: 0.285200
Train loss on 50 batch: 0.356176
Train loss on 75 batch: 0.296839
best-train-loss: 0.327825
best-valid-loss: 0.357224
best-kappa: 0.7579
: Epoch: 7 | Training Loss: 0.327825 | Val. Loss: 0.357224 | Val. Kappa Score: 0.7579 | Estimated time: 153.13
Train loss on 25 batch: 0.327362
Train loss on 50 batch: 0.258768
Train loss on 75 batch: 0.301319
: Epoch: 8 | Training Loss: 0.295882 | Val. Loss: 0.375934 | Val. Kappa Score: 0.7695 | Estimated time: 152.57
Train loss on 25 batch: 0.371581
Train loss on 50 batch: 0.266154
Train loss on 75 batch: 0.257010
: Epoch: 9 | Training Loss: 0.286948 | Val. Loss: 0.374003 | Val. Kappa Score: 0.7790 | Estimated time: 152.96
Train loss on 25 batch: 0.270520
Train loss on 50 batch: 0.298268
Train loss on 75 batch: 0.295387
best-train-loss: 0.279032
best-valid-loss: 0.333421
best-kappa: 0.7878
: Epoch: 10 | Training Loss: 0.279032 | Val. Loss: 0.333421 | Val. Kappa Score: 0.7878 | Estimated time: 153.54
Train loss on 25 batch: 0.216610
Train loss on 50 batch: 0.245219
Train loss on 75 batch: 0.238183
: Epoch: 11 | Training Loss: 0.242191 | Val. Loss: 0.358146 | Val. Kappa Score: 0.7948 | Estimated time: 153.09
Train loss on 25 batch: 0.242058
Train loss on 50 batch: 0.206442
Train loss on 75 batch: 0.210072
best-train-loss: 0.228026
best-valid-loss: 0.314989
best-kappa: 0.8027
: Epoch: 12 | Training Loss: 0.228026 | Val. Loss: 0.314989 | Val. Kappa Score: 0.8027 | Estimated time: 152.67
Train loss on 25 batch: 0.190814
Train loss on 50 batch: 0.188914
Train loss on 75 batch: 0.254832
: Epoch: 13 | Training Loss: 0.231092 | Val. Loss: 0.385296 | Val. Kappa Score: 0.8081 | Estimated time: 154.06
Train loss on 25 batch: 0.199839
Train loss on 50 batch: 0.233937
Train loss on 75 batch: 0.188591
: Epoch: 14 | Training Loss: 0.197390 | Val. Loss: 0.319136 | Val. Kappa Score: 0.8124 | Estimated time: 154.61
Train loss on 25 batch: 0.170629
Train loss on 50 batch: 0.225502
Train loss on 75 batch: 0.174334
: Epoch: 15 | Training Loss: 0.190769 | Val. Loss: 0.345808 | Val. Kappa Score: 0.8151 | Estimated time: 156.23
Train loss on 25 batch: 0.199477
Train loss on 50 batch: 0.205625
Train loss on 75 batch: 0.174498
best-train-loss: 0.187836
best-valid-loss: 0.308892
best-kappa: 0.8197
: Epoch: 16 | Training Loss: 0.187836 | Val. Loss: 0.308892 | Val. Kappa Score: 0.8197 | Estimated time: 156.55
Train loss on 25 batch: 0.158829
Train loss on 50 batch: 0.150817
Train loss on 75 batch: 0.173486
: Epoch: 17 | Training Loss: 0.161583 | Val. Loss: 0.318345 | Val. Kappa Score: 0.8233 | Estimated time: 154.42
Train loss on 25 batch: 0.162721
Train loss on 50 batch: 0.160439
Train loss on 75 batch: 0.185640
: Epoch: 18 | Training Loss: 0.166557 | Val. Loss: 0.336540 | Val. Kappa Score: 0.8255 | Estimated time: 155.79
Train loss on 25 batch: 0.161142
Train loss on 50 batch: 0.161831
Train loss on 75 batch: 0.126364
: Epoch: 19 | Training Loss: 0.149777 | Val. Loss: 0.314147 | Val. Kappa Score: 0.8289 | Estimated time: 157.96
Train loss on 25 batch: 0.117782
Train loss on 50 batch: 0.161844
Train loss on 75 batch: 0.154461
: Epoch: 20 | Training Loss: 0.136525 | Val. Loss: 0.346232 | Val. Kappa Score: 0.8309 | Estimated time: 157.09
Train loss on 25 batch: 0.135218
Train loss on 50 batch: 0.115283
Train loss on 75 batch: 0.154692
: Epoch: 21 | Training Loss: 0.133776 | Val. Loss: 0.361166 | Val. Kappa Score: 0.8325 | Estimated time: 158.20
Train loss on 25 batch: 0.128325
Train loss on 50 batch: 0.122729
Train loss on 75 batch: 0.136961
: Epoch: 22 | Training Loss: 0.131978 | Val. Loss: 0.346983 | Val. Kappa Score: 0.8344 | Estimated time: 155.89
Train loss on 25 batch: 0.116565
Train loss on 50 batch: 0.154765
Train loss on 75 batch: 0.112413
: Epoch: 23 | Training Loss: 0.125342 | Val. Loss: 0.317310 | Val. Kappa Score: 0.8364 | Estimated time: 156.80
Train loss on 25 batch: 0.103091
Train loss on 50 batch: 0.110280
Train loss on 75 batch: 0.107595
best-train-loss: 0.110840
best-valid-loss: 0.294957
best-kappa: 0.8387
: Epoch: 24 | Training Loss: 0.110840 | Val. Loss: 0.294957 | Val. Kappa Score: 0.8387 | Estimated time: 156.10
Train loss on 25 batch: 0.116369
Train loss on 50 batch: 0.106698
Train loss on 75 batch: 0.111084
: Epoch: 25 | Training Loss: 0.114182 | Val. Loss: 0.306993 | Val. Kappa Score: 0.8406 | Estimated time: 154.97
Train loss on 25 batch: 0.118002
Train loss on 50 batch: 0.125882
Train loss on 75 batch: 0.102948
: Epoch: 26 | Training Loss: 0.111298 | Val. Loss: 0.359609 | Val. Kappa Score: 0.8415 | Estimated time: 157.82
Train loss on 25 batch: 0.097247
Train loss on 50 batch: 0.107026
Train loss on 75 batch: 0.136389
: Epoch: 27 | Training Loss: 0.123495 | Val. Loss: 0.324487 | Val. Kappa Score: 0.8428 | Estimated time: 156.44
Train loss on 25 batch: 0.123224
Train loss on 50 batch: 0.102960
Train loss on 75 batch: 0.117453
: Epoch: 28 | Training Loss: 0.106411 | Val. Loss: 0.325224 | Val. Kappa Score: 0.8440 | Estimated time: 155.75
Train loss on 25 batch: 0.084148
Train loss on 50 batch: 0.093927
Train loss on 75 batch: 0.091292
: Epoch: 29 | Training Loss: 0.094512 | Val. Loss: 0.342017 | Val. Kappa Score: 0.8450 | Estimated time: 155.83
Train loss on 25 batch: 0.089022
Train loss on 50 batch: 0.107950
Train loss on 75 batch: 0.118675
: Epoch: 30 | Training Loss: 0.101522 | Val. Loss: 0.350443 | Val. Kappa Score: 0.8454 | Estimated time: 156.17
Train loss on 25 batch: 0.080352
Train loss on 50 batch: 0.103804
Train loss on 75 batch: 0.080910
: Epoch: 31 | Training Loss: 0.092221 | Val. Loss: 0.308097 | Val. Kappa Score: 0.8467 | Estimated time: 157.18
Train loss on 25 batch: 0.093528
Train loss on 50 batch: 0.103849
Train loss on 75 batch: 0.109520
best-train-loss: 0.093035
best-valid-loss: 0.288652
best-kappa: 0.8480
: Epoch: 32 | Training Loss: 0.093035 | Val. Loss: 0.288652 | Val. Kappa Score: 0.8480 | Estimated time: 155.28
Train loss on 25 batch: 0.094933
Train loss on 50 batch: 0.095042
Train loss on 75 batch: 0.123926
: Epoch: 33 | Training Loss: 0.108321 | Val. Loss: 0.297381 | Val. Kappa Score: 0.8492 | Estimated time: 156.03
Train loss on 25 batch: 0.089211
Train loss on 50 batch: 0.084037
Train loss on 75 batch: 0.082971
: Epoch: 34 | Training Loss: 0.084303 | Val. Loss: 0.299969 | Val. Kappa Score: 0.8502 | Estimated time: 154.50
Train loss on 25 batch: 0.071621
Train loss on 50 batch: 0.080983
Train loss on 75 batch: 0.115146
: Epoch: 35 | Training Loss: 0.088666 | Val. Loss: 0.291041 | Val. Kappa Score: 0.8512 | Estimated time: 157.34
Train loss on 25 batch: 0.081932
Train loss on 50 batch: 0.075163
Train loss on 75 batch: 0.084340
best-train-loss: 0.081768
best-valid-loss: 0.288204
best-kappa: 0.8522
: Epoch: 36 | Training Loss: 0.081768 | Val. Loss: 0.288204 | Val. Kappa Score: 0.8522 | Estimated time: 157.70
Train loss on 25 batch: 0.067564
Train loss on 50 batch: 0.079089
Train loss on 75 batch: 0.074755
: Epoch: 37 | Training Loss: 0.078481 | Val. Loss: 0.314947 | Val. Kappa Score: 0.8528 | Estimated time: 154.78
Train loss on 25 batch: 0.076563
Train loss on 50 batch: 0.064410
Train loss on 75 batch: 0.074126
: Epoch: 38 | Training Loss: 0.073968 | Val. Loss: 0.295920 | Val. Kappa Score: 0.8536 | Estimated time: 154.72
Train loss on 25 batch: 0.077609
Train loss on 50 batch: 0.072503
Train loss on 75 batch: 0.077768
: Epoch: 39 | Training Loss: 0.074716 | Val. Loss: 0.302526 | Val. Kappa Score: 0.8544 | Estimated time: 156.16
Train loss on 25 batch: 0.079145
Train loss on 50 batch: 0.077575
Train loss on 75 batch: 0.075595
: Epoch: 40 | Training Loss: 0.075737 | Val. Loss: 0.315881 | Val. Kappa Score: 0.8552 | Estimated time: 155.26
Train loss on 25 batch: 0.072476
Train loss on 50 batch: 0.071433
Train loss on 75 batch: 0.073407
: Epoch: 41 | Training Loss: 0.071843 | Val. Loss: 0.325698 | Val. Kappa Score: 0.8558 | Estimated time: 154.61
Train loss on 25 batch: 0.071754
Train loss on 50 batch: 0.073154
Train loss on 75 batch: 0.082284
: Epoch: 42 | Training Loss: 0.076626 | Val. Loss: 0.322520 | Val. Kappa Score: 0.8562 | Estimated time: 155.32
Train loss on 25 batch: 0.066136
Train loss on 50 batch: 0.071368
Train loss on 75 batch: 0.065038
: Epoch: 43 | Training Loss: 0.072188 | Val. Loss: 0.324834 | Val. Kappa Score: 0.8567 | Estimated time: 155.08
Train loss on 25 batch: 0.083521
Train loss on 50 batch: 0.072661
Train loss on 75 batch: 0.067720
: Epoch: 44 | Training Loss: 0.072956 | Val. Loss: 0.322737 | Val. Kappa Score: 0.8572 | Estimated time: 155.54
time_estimated: 6829.12
n-epochs: 44
time_estimated: 6829.13
----------------------------------------

Experiment N: 39: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b4


: 
date: 2019.08.08 14:12:38
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 19385673
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.660315
Train loss on 50 batch: 0.776820
Train loss on 75 batch: 0.888625
Train loss on 100 batch: 0.749810
Train loss on 125 batch: 0.585193
Train loss on 150 batch: 0.577075
Train loss on 175 batch: 0.523450
best-train-loss: 0.828792
best-valid-loss: 0.871564
best-kappa: 0.6658
: Epoch: 1 | Training Loss: 0.828792 | Val. Loss: 0.871564 | Val. Kappa Score: 0.6658 | Estimated time: 157.53
Train loss on 25 batch: 0.471219
Train loss on 50 batch: 0.547505
Train loss on 75 batch: 0.503352
Train loss on 100 batch: 0.425276
Train loss on 125 batch: 0.514483
Train loss on 150 batch: 0.487920
Train loss on 175 batch: 0.524392
best-train-loss: 0.512047
best-valid-loss: 0.531413
best-kappa: 0.7319
: Epoch: 2 | Training Loss: 0.512047 | Val. Loss: 0.531413 | Val. Kappa Score: 0.7319 | Estimated time: 158.05
Train loss on 25 batch: 0.432489
Train loss on 50 batch: 0.458623
Train loss on 75 batch: 0.470080
Train loss on 100 batch: 0.535995
Train loss on 125 batch: 0.513042
Train loss on 150 batch: 0.480320
Train loss on 175 batch: 0.400603
: Epoch: 3 | Training Loss: 0.467860 | Val. Loss: 0.552874 | Val. Kappa Score: 0.7469 | Estimated time: 156.55
Train loss on 25 batch: 0.356732
Train loss on 50 batch: 0.435942
Train loss on 75 batch: 0.399447
Train loss on 100 batch: 0.370122
Train loss on 125 batch: 0.481164
Train loss on 150 batch: 0.400558
Train loss on 175 batch: 0.293374
best-train-loss: 0.385309
best-valid-loss: 0.332574
best-kappa: 0.7760
: Epoch: 4 | Training Loss: 0.385309 | Val. Loss: 0.332574 | Val. Kappa Score: 0.7760 | Estimated time: 156.15
Train loss on 25 batch: 0.358785
Train loss on 50 batch: 0.392171
Train loss on 75 batch: 0.248138
Train loss on 100 batch: 0.350170
Train loss on 125 batch: 0.494850
Train loss on 150 batch: 0.377472
Train loss on 175 batch: 0.359449
best-train-loss: 0.368679
best-valid-loss: 0.323261
best-kappa: 0.7966
: Epoch: 5 | Training Loss: 0.368679 | Val. Loss: 0.323261 | Val. Kappa Score: 0.7966 | Estimated time: 156.05
Train loss on 25 batch: 0.325223
Train loss on 50 batch: 0.329849
Train loss on 75 batch: 0.278596
Train loss on 100 batch: 0.374215
Train loss on 125 batch: 0.326835
Train loss on 150 batch: 0.312817
Train loss on 175 batch: 0.272238
: Epoch: 6 | Training Loss: 0.309627 | Val. Loss: 0.337701 | Val. Kappa Score: 0.8090 | Estimated time: 157.22
Train loss on 25 batch: 0.294791
Train loss on 50 batch: 0.298757
Train loss on 75 batch: 0.340840
Train loss on 100 batch: 0.262421
Train loss on 125 batch: 0.227814
Train loss on 150 batch: 0.318128
Train loss on 175 batch: 0.402588
: Epoch: 7 | Training Loss: 0.313571 | Val. Loss: 0.323355 | Val. Kappa Score: 0.8173 | Estimated time: 157.47
Train loss on 25 batch: 0.257273
Train loss on 50 batch: 0.271355
Train loss on 75 batch: 0.202211
Train loss on 100 batch: 0.263836
Train loss on 125 batch: 0.326640
Train loss on 150 batch: 0.296668
Train loss on 175 batch: 0.290480
best-train-loss: 0.282808
best-valid-loss: 0.314358
best-kappa: 0.8238
: Epoch: 8 | Training Loss: 0.282808 | Val. Loss: 0.314358 | Val. Kappa Score: 0.8238 | Estimated time: 155.54
Train loss on 25 batch: 0.317397
Train loss on 50 batch: 0.281745
Train loss on 75 batch: 0.281504
Train loss on 100 batch: 0.266152
Train loss on 125 batch: 0.231917
Train loss on 150 batch: 0.206806
Train loss on 175 batch: 0.210991
best-train-loss: 0.252287
best-valid-loss: 0.306223
best-kappa: 0.8291
: Epoch: 9 | Training Loss: 0.252287 | Val. Loss: 0.306223 | Val. Kappa Score: 0.8291 | Estimated time: 156.84
Train loss on 25 batch: 0.232040
Train loss on 50 batch: 0.236157
Train loss on 75 batch: 0.241084
Train loss on 100 batch: 0.218015
Train loss on 125 batch: 0.273985
Train loss on 150 batch: 0.249666
Train loss on 175 batch: 0.212911
best-train-loss: 0.261040
best-valid-loss: 0.301839
best-kappa: 0.8331
: Epoch: 10 | Training Loss: 0.261040 | Val. Loss: 0.301839 | Val. Kappa Score: 0.8331 | Estimated time: 156.19
Train loss on 25 batch: 0.196262
Train loss on 50 batch: 0.174729
Train loss on 75 batch: 0.243558
Train loss on 100 batch: 0.287865
Train loss on 125 batch: 0.177523
Train loss on 150 batch: 0.210766
Train loss on 175 batch: 0.239191
: Epoch: 11 | Training Loss: 0.224329 | Val. Loss: 0.331192 | Val. Kappa Score: 0.8365 | Estimated time: 156.43
Train loss on 25 batch: 0.259661
Train loss on 50 batch: 0.250488
Train loss on 75 batch: 0.215113
Train loss on 100 batch: 0.199822
Train loss on 125 batch: 0.196806
Train loss on 150 batch: 0.210683
Train loss on 175 batch: 0.196946
best-train-loss: 0.283551
best-valid-loss: 0.297708
best-kappa: 0.8400
: Epoch: 12 | Training Loss: 0.283551 | Val. Loss: 0.297708 | Val. Kappa Score: 0.8400 | Estimated time: 155.92
Train loss on 25 batch: 0.179035
Train loss on 50 batch: 0.172724
Train loss on 75 batch: 0.194094
Train loss on 100 batch: 0.202184
Train loss on 125 batch: 0.233163
Train loss on 150 batch: 0.225161
Train loss on 175 batch: 0.241172
: Epoch: 13 | Training Loss: 0.257303 | Val. Loss: 0.316464 | Val. Kappa Score: 0.8424 | Estimated time: 156.91
Train loss on 25 batch: 0.227406
Train loss on 50 batch: 0.147306
Train loss on 75 batch: 0.206958
Train loss on 100 batch: 0.213323
Train loss on 125 batch: 0.199496
Train loss on 150 batch: 0.181668
Train loss on 175 batch: 0.127418
best-train-loss: 0.201790
best-valid-loss: 0.269436
best-kappa: 0.8448
: Epoch: 14 | Training Loss: 0.201790 | Val. Loss: 0.269436 | Val. Kappa Score: 0.8448 | Estimated time: 156.83
Train loss on 25 batch: 0.158400
Train loss on 50 batch: 0.194364
Train loss on 75 batch: 0.176073
Train loss on 100 batch: 0.187145
Train loss on 125 batch: 0.173267
Train loss on 150 batch: 0.160515
Train loss on 175 batch: 0.190799
: Epoch: 15 | Training Loss: 0.180220 | Val. Loss: 0.292854 | Val. Kappa Score: 0.8461 | Estimated time: 156.13
Train loss on 25 batch: 0.144844
Train loss on 50 batch: 0.171228
Train loss on 75 batch: 0.157914
Train loss on 100 batch: 0.162616
Train loss on 125 batch: 0.208096
Train loss on 150 batch: 0.166496
Train loss on 175 batch: 0.171282
: Epoch: 16 | Training Loss: 0.249282 | Val. Loss: 0.291700 | Val. Kappa Score: 0.8485 | Estimated time: 156.33
Train loss on 25 batch: 0.186008
Train loss on 50 batch: 0.171072
Train loss on 75 batch: 0.161452
Train loss on 100 batch: 0.143668
Train loss on 125 batch: 0.164808
Train loss on 150 batch: 0.170434
Train loss on 175 batch: 0.211978
: Epoch: 17 | Training Loss: 0.173127 | Val. Loss: 0.362434 | Val. Kappa Score: 0.8493 | Estimated time: 156.61
Train loss on 25 batch: 0.167134
Train loss on 50 batch: 0.134135
Train loss on 75 batch: 0.126425
Train loss on 100 batch: 0.106247
Train loss on 125 batch: 0.193779
Train loss on 150 batch: 0.233425
Train loss on 175 batch: 0.144656
: Epoch: 18 | Training Loss: 0.177991 | Val. Loss: 0.298884 | Val. Kappa Score: 0.8511 | Estimated time: 157.00
Train loss on 25 batch: 0.181352
Train loss on 50 batch: 0.157785
Train loss on 75 batch: 0.232156
Train loss on 100 batch: 0.157779
Train loss on 125 batch: 0.196830
Train loss on 150 batch: 0.139920
Train loss on 175 batch: 0.115964
: Epoch: 19 | Training Loss: 0.176476 | Val. Loss: 0.339214 | Val. Kappa Score: 0.8519 | Estimated time: 157.04
Train loss on 25 batch: 0.135417
Train loss on 50 batch: 0.145931
Train loss on 75 batch: 0.138015
Train loss on 100 batch: 0.127885
Train loss on 125 batch: 0.136467
Train loss on 150 batch: 0.119489
Train loss on 175 batch: 0.100701
: Epoch: 20 | Training Loss: 0.135213 | Val. Loss: 0.287359 | Val. Kappa Score: 0.8528 | Estimated time: 156.66
Train loss on 25 batch: 0.148214
Train loss on 50 batch: 0.124601
Train loss on 75 batch: 0.126452
Train loss on 100 batch: 0.123051
Train loss on 125 batch: 0.131732
Train loss on 150 batch: 0.170551
Train loss on 175 batch: 0.126027
: Epoch: 21 | Training Loss: 0.133006 | Val. Loss: 0.300620 | Val. Kappa Score: 0.8535 | Estimated time: 156.37
Train loss on 25 batch: 0.117883
Train loss on 50 batch: 0.127908
Train loss on 75 batch: 0.124934
Train loss on 100 batch: 0.121621
Train loss on 125 batch: 0.102328
Train loss on 150 batch: 0.130896
Train loss on 175 batch: 0.118894
: Epoch: 22 | Training Loss: 0.135739 | Val. Loss: 0.312487 | Val. Kappa Score: 0.8549 | Estimated time: 155.39
time_estimated: 3445.98
n-epochs: 22
time_estimated: 3445.99
----------------------------------------

Experiment N: 40: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.08 15:10:05
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 30439985
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.504458
Train loss on 50 batch: 0.808886
Train loss on 75 batch: 0.900111
Train loss on 100 batch: 0.712008
Train loss on 125 batch: 0.614412
Train loss on 150 batch: 0.661827
Train loss on 175 batch: 0.580201
best-train-loss: 0.811818
best-valid-loss: 0.826811
best-kappa: 0.7108
: Epoch: 1 | Training Loss: 0.811818 | Val. Loss: 0.826811 | Val. Kappa Score: 0.7108 | Estimated time: 157.25
Train loss on 25 batch: 0.491248
Train loss on 50 batch: 0.549391
Train loss on 75 batch: 0.524688
Train loss on 100 batch: 0.390000
Train loss on 125 batch: 0.522569
Train loss on 150 batch: 0.471390
Train loss on 175 batch: 0.515695
best-train-loss: 0.497590
best-valid-loss: 0.518800
best-kappa: 0.7510
: Epoch: 2 | Training Loss: 0.497590 | Val. Loss: 0.518800 | Val. Kappa Score: 0.7510 | Estimated time: 158.34
Train loss on 25 batch: 0.454629
Train loss on 50 batch: 0.442039
Train loss on 75 batch: 0.470146
Train loss on 100 batch: 0.509216
Train loss on 125 batch: 0.499172
Train loss on 150 batch: 0.426698
Train loss on 175 batch: 0.388257
: Epoch: 3 | Training Loss: 0.443430 | Val. Loss: 0.552826 | Val. Kappa Score: 0.7566 | Estimated time: 158.18
Train loss on 25 batch: 0.314672
Train loss on 50 batch: 0.404017
Train loss on 75 batch: 0.386973
Train loss on 100 batch: 0.324708
Train loss on 125 batch: 0.426843
Train loss on 150 batch: 0.349164
Train loss on 175 batch: 0.329017
best-train-loss: 0.368630
best-valid-loss: 0.346535
best-kappa: 0.7839
: Epoch: 4 | Training Loss: 0.368630 | Val. Loss: 0.346535 | Val. Kappa Score: 0.7839 | Estimated time: 157.29
Train loss on 25 batch: 0.378483
Train loss on 50 batch: 0.363894
Train loss on 75 batch: 0.290666
Train loss on 100 batch: 0.317049
Train loss on 125 batch: 0.497487
Train loss on 150 batch: 0.373044
Train loss on 175 batch: 0.362742
best-train-loss: 0.359452
best-valid-loss: 0.340989
best-kappa: 0.7993
: Epoch: 5 | Training Loss: 0.359452 | Val. Loss: 0.340989 | Val. Kappa Score: 0.7993 | Estimated time: 157.00
Train loss on 25 batch: 0.279587
Train loss on 50 batch: 0.327641
Train loss on 75 batch: 0.292419
Train loss on 100 batch: 0.405151
Train loss on 125 batch: 0.294708
Train loss on 150 batch: 0.303167
Train loss on 175 batch: 0.270601
: Epoch: 6 | Training Loss: 0.302550 | Val. Loss: 0.375028 | Val. Kappa Score: 0.8089 | Estimated time: 158.33
Train loss on 25 batch: 0.283834
Train loss on 50 batch: 0.284368
Train loss on 75 batch: 0.317975
Train loss on 100 batch: 0.235623
Train loss on 125 batch: 0.245270
Train loss on 150 batch: 0.287785
Train loss on 175 batch: 0.414018
: Epoch: 7 | Training Loss: 0.304439 | Val. Loss: 0.359559 | Val. Kappa Score: 0.8157 | Estimated time: 158.07
Train loss on 25 batch: 0.249682
Train loss on 50 batch: 0.244643
Train loss on 75 batch: 0.192999
Train loss on 100 batch: 0.301739
Train loss on 125 batch: 0.343685
Train loss on 150 batch: 0.234480
Train loss on 175 batch: 0.271542
best-train-loss: 0.267709
best-valid-loss: 0.308451
best-kappa: 0.8243
: Epoch: 8 | Training Loss: 0.267709 | Val. Loss: 0.308451 | Val. Kappa Score: 0.8243 | Estimated time: 156.81
Train loss on 25 batch: 0.253105
Train loss on 50 batch: 0.217059
Train loss on 75 batch: 0.227894
Train loss on 100 batch: 0.214992
Train loss on 125 batch: 0.222194
Train loss on 150 batch: 0.210841
Train loss on 175 batch: 0.232627
: Epoch: 9 | Training Loss: 0.236790 | Val. Loss: 0.333327 | Val. Kappa Score: 0.8287 | Estimated time: 156.73
Train loss on 25 batch: 0.214419
Train loss on 50 batch: 0.226979
Train loss on 75 batch: 0.273027
Train loss on 100 batch: 0.193907
Train loss on 125 batch: 0.232960
Train loss on 150 batch: 0.261359
Train loss on 175 batch: 0.235419
: Epoch: 10 | Training Loss: 0.231892 | Val. Loss: 0.393743 | Val. Kappa Score: 0.8297 | Estimated time: 156.09
Train loss on 25 batch: 0.167652
Train loss on 50 batch: 0.195999
Train loss on 75 batch: 0.197001
Train loss on 100 batch: 0.224019
Train loss on 125 batch: 0.182079
Train loss on 150 batch: 0.222726
Train loss on 175 batch: 0.238567
: Epoch: 11 | Training Loss: 0.221808 | Val. Loss: 0.328791 | Val. Kappa Score: 0.8328 | Estimated time: 156.81
Train loss on 25 batch: 0.233211
Train loss on 50 batch: 0.212087
Train loss on 75 batch: 0.222257
Train loss on 100 batch: 0.195182
Train loss on 125 batch: 0.193265
Train loss on 150 batch: 0.169441
Train loss on 175 batch: 0.198692
best-train-loss: 0.302664
best-valid-loss: 0.296666
best-kappa: 0.8362
: Epoch: 12 | Training Loss: 0.302664 | Val. Loss: 0.296666 | Val. Kappa Score: 0.8362 | Estimated time: 157.24
Train loss on 25 batch: 0.183756
Train loss on 50 batch: 0.155662
Train loss on 75 batch: 0.153794
Train loss on 100 batch: 0.174592
Train loss on 125 batch: 0.247717
Train loss on 150 batch: 0.228183
Train loss on 175 batch: 0.265897
: Epoch: 13 | Training Loss: 0.241369 | Val. Loss: 0.357051 | Val. Kappa Score: 0.8382 | Estimated time: 156.60
Train loss on 25 batch: 0.189900
Train loss on 50 batch: 0.143178
Train loss on 75 batch: 0.194142
Train loss on 100 batch: 0.220277
Train loss on 125 batch: 0.218069
Train loss on 150 batch: 0.150561
Train loss on 175 batch: 0.168777
: Epoch: 14 | Training Loss: 0.180188 | Val. Loss: 0.325924 | Val. Kappa Score: 0.8406 | Estimated time: 157.02
Train loss on 25 batch: 0.141538
Train loss on 50 batch: 0.177217
Train loss on 75 batch: 0.181321
Train loss on 100 batch: 0.168461
Train loss on 125 batch: 0.199318
Train loss on 150 batch: 0.166158
Train loss on 175 batch: 0.155856
best-train-loss: 0.181096
best-valid-loss: 0.289946
best-kappa: 0.8437
: Epoch: 15 | Training Loss: 0.181096 | Val. Loss: 0.289946 | Val. Kappa Score: 0.8437 | Estimated time: 156.92
Train loss on 25 batch: 0.130763
Train loss on 50 batch: 0.152272
Train loss on 75 batch: 0.161338
Train loss on 100 batch: 0.187948
Train loss on 125 batch: 0.194182
Train loss on 150 batch: 0.152266
Train loss on 175 batch: 0.126179
: Epoch: 16 | Training Loss: 0.240454 | Val. Loss: 0.315766 | Val. Kappa Score: 0.8457 | Estimated time: 158.39
Train loss on 25 batch: 0.215455
Train loss on 50 batch: 0.172628
Train loss on 75 batch: 0.133834
Train loss on 100 batch: 0.162770
Train loss on 125 batch: 0.157087
Train loss on 150 batch: 0.155442
Train loss on 175 batch: 0.174321
: Epoch: 17 | Training Loss: 0.164459 | Val. Loss: 0.313358 | Val. Kappa Score: 0.8484 | Estimated time: 156.86
Train loss on 25 batch: 0.134297
Train loss on 50 batch: 0.129097
Train loss on 75 batch: 0.104918
Train loss on 100 batch: 0.123265
Train loss on 125 batch: 0.186751
Train loss on 150 batch: 0.181486
Train loss on 175 batch: 0.136235
: Epoch: 18 | Training Loss: 0.156477 | Val. Loss: 0.311538 | Val. Kappa Score: 0.8498 | Estimated time: 157.70
Train loss on 25 batch: 0.221445
Train loss on 50 batch: 0.134459
Train loss on 75 batch: 0.157366
Train loss on 100 batch: 0.118096
Train loss on 125 batch: 0.156996
Train loss on 150 batch: 0.114436
Train loss on 175 batch: 0.144441
: Epoch: 19 | Training Loss: 0.151431 | Val. Loss: 0.361100 | Val. Kappa Score: 0.8506 | Estimated time: 157.09
Train loss on 25 batch: 0.111526
Train loss on 50 batch: 0.110585
Train loss on 75 batch: 0.117228
Train loss on 100 batch: 0.127361
Train loss on 125 batch: 0.125553
Train loss on 150 batch: 0.106966
Train loss on 175 batch: 0.113966
best-train-loss: 0.118862
best-valid-loss: 0.289617
best-kappa: 0.8518
: Epoch: 20 | Training Loss: 0.118862 | Val. Loss: 0.289617 | Val. Kappa Score: 0.8518 | Estimated time: 156.94
Train loss on 25 batch: 0.115438
Train loss on 50 batch: 0.105162
Train loss on 75 batch: 0.109878
Train loss on 100 batch: 0.093649
Train loss on 125 batch: 0.116475
Train loss on 150 batch: 0.129671
Train loss on 175 batch: 0.110968
: Epoch: 21 | Training Loss: 0.112392 | Val. Loss: 0.312652 | Val. Kappa Score: 0.8524 | Estimated time: 157.62
Train loss on 25 batch: 0.091867
Train loss on 50 batch: 0.120187
Train loss on 75 batch: 0.093923
Train loss on 100 batch: 0.107740
Train loss on 125 batch: 0.106019
Train loss on 150 batch: 0.107976
Train loss on 175 batch: 0.108686
: Epoch: 22 | Training Loss: 0.109134 | Val. Loss: 0.315675 | Val. Kappa Score: 0.8533 | Estimated time: 156.33
Train loss on 25 batch: 0.108253
Train loss on 50 batch: 0.163434
Train loss on 75 batch: 0.093469
Train loss on 100 batch: 0.112781
Train loss on 125 batch: 0.122316
Train loss on 150 batch: 0.074995
Train loss on 175 batch: 0.116994
: Epoch: 23 | Training Loss: 0.118522 | Val. Loss: 0.296112 | Val. Kappa Score: 0.8550 | Estimated time: 157.06
Train loss on 25 batch: 0.096457
Train loss on 50 batch: 0.116362
Train loss on 75 batch: 0.108543
Train loss on 100 batch: 0.091437
Train loss on 125 batch: 0.091329
Train loss on 150 batch: 0.102685
Train loss on 175 batch: 0.075903
best-train-loss: 0.095233
best-valid-loss: 0.282250
best-kappa: 0.8564
: Epoch: 24 | Training Loss: 0.095233 | Val. Loss: 0.282250 | Val. Kappa Score: 0.8564 | Estimated time: 157.35
Train loss on 25 batch: 0.111036
Train loss on 50 batch: 0.088028
Train loss on 75 batch: 0.087418
Train loss on 100 batch: 0.109757
Train loss on 125 batch: 0.091603
Train loss on 150 batch: 0.123224
Train loss on 175 batch: 0.114548
: Epoch: 25 | Training Loss: 0.113010 | Val. Loss: 0.298901 | Val. Kappa Score: 0.8578 | Estimated time: 158.41
Train loss on 25 batch: 0.114627
Train loss on 50 batch: 0.094646
Train loss on 75 batch: 0.091028
Train loss on 100 batch: 0.094422
Train loss on 125 batch: 0.088957
Train loss on 150 batch: 0.106097
Train loss on 175 batch: 0.100597
: Epoch: 26 | Training Loss: 0.104323 | Val. Loss: 0.325067 | Val. Kappa Score: 0.8582 | Estimated time: 157.55
Train loss on 25 batch: 0.086560
Train loss on 50 batch: 0.086073
Train loss on 75 batch: 0.090601
Train loss on 100 batch: 0.084825
Train loss on 125 batch: 0.106343
Train loss on 150 batch: 0.133783
Train loss on 175 batch: 0.167720
: Epoch: 27 | Training Loss: 0.114300 | Val. Loss: 0.306519 | Val. Kappa Score: 0.8591 | Estimated time: 157.95
Train loss on 25 batch: 0.087408
Train loss on 50 batch: 0.096525
Train loss on 75 batch: 0.113453
Train loss on 100 batch: 0.094974
Train loss on 125 batch: 0.097687
Train loss on 150 batch: 0.113775
Train loss on 175 batch: 0.086925
: Epoch: 28 | Training Loss: 0.112943 | Val. Loss: 0.305060 | Val. Kappa Score: 0.8599 | Estimated time: 155.91
Train loss on 25 batch: 0.073046
Train loss on 50 batch: 0.105062
Train loss on 75 batch: 0.089535
Train loss on 100 batch: 0.099449
Train loss on 125 batch: 0.081594
Train loss on 150 batch: 0.096480
Train loss on 175 batch: 0.075029
: Epoch: 29 | Training Loss: 0.111460 | Val. Loss: 0.322220 | Val. Kappa Score: 0.8600 | Estimated time: 156.25
Train loss on 25 batch: 0.093748
Train loss on 50 batch: 0.091507
Train loss on 75 batch: 0.080280
Train loss on 100 batch: 0.089102
Train loss on 125 batch: 0.100206
Train loss on 150 batch: 0.108467
Train loss on 175 batch: 0.086373
: Epoch: 30 | Training Loss: 0.197649 | Val. Loss: 0.291256 | Val. Kappa Score: 0.8603 | Estimated time: 157.08
Train loss on 25 batch: 0.083897
Train loss on 50 batch: 0.073308
Train loss on 75 batch: 0.091613
Train loss on 100 batch: 0.114162
Train loss on 125 batch: 0.094345
Train loss on 150 batch: 0.104508
Train loss on 175 batch: 0.102651
: Epoch: 31 | Training Loss: 0.096076 | Val. Loss: 0.333402 | Val. Kappa Score: 0.8604 | Estimated time: 158.53
Train loss on 25 batch: 0.095892
Train loss on 50 batch: 0.086103
Train loss on 75 batch: 0.086320
Train loss on 100 batch: 0.080804
Train loss on 125 batch: 0.080458
Train loss on 150 batch: 0.092929
Train loss on 175 batch: 0.059369
: Epoch: 32 | Training Loss: 0.091961 | Val. Loss: 0.294264 | Val. Kappa Score: 0.8610 | Estimated time: 156.08
time_estimated: 5032.83
n-epochs: 32
time_estimated: 5032.84
----------------------------------------

Experiment N: 41: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.00015, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.08 19:23:20
data-type: new_comp_quadratic_kappa
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.00015
    weight_decay: 0
)
early-stopping-patience: 8
parameters-amount: 5320317
n-epochs: 100
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 25 batch: 1.154734
Train loss on 50 batch: 0.808981
Train loss on 75 batch: 0.561245
best-train-loss: 0.746522
best-valid-loss: 0.693261
best-kappa: 0.7183
: Epoch: 1 | Training Loss: 0.746522 | Val. Loss: 0.693261 | Val. Kappa Score: 0.7183 | Estimated time: 152.13
Train loss on 25 batch: 0.479711
Train loss on 50 batch: 0.452915
Train loss on 75 batch: 0.481492
best-train-loss: 0.470470
best-valid-loss: 0.452932
best-kappa: 0.7693
: Epoch: 2 | Training Loss: 0.470470 | Val. Loss: 0.452932 | Val. Kappa Score: 0.7693 | Estimated time: 155.69
Train loss on 25 batch: 0.440089
Train loss on 50 batch: 0.426008
Train loss on 75 batch: 0.439899
----------------------------------------


Experiment N: 42: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.09 00:29:38
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 5
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.050137
Train loss on 100 batch: 0.913875
Train loss on 150 batch: 0.837324
Train loss on 200 batch: 0.829271
Train loss on 250 batch: 0.810331
Train loss on 300 batch: 0.710067
Train loss on 350 batch: 0.681715
Train loss on 400 batch: 0.717311
Train loss on 450 batch: 0.776837
Train loss on 500 batch: 0.608999
Train loss on 550 batch: 0.652806
Train loss on 600 batch: 0.604379
Train loss on 650 batch: 0.630548
Train loss on 700 batch: 0.697402
Train loss on 750 batch: 0.638873
Train loss on 800 batch: 0.697432
Train loss on 850 batch: 0.543871
Train loss on 900 batch: 0.650418
Train loss on 950 batch: 0.676328
Train loss on 1000 batch: 0.570581
Train loss on 1050 batch: 0.630829
Train loss on 1100 batch: 0.606591
Train loss on 1150 batch: 0.600555
Train loss on 1200 batch: 0.695832
Train loss on 1250 batch: 0.551008
Train loss on 1300 batch: 0.659821
Train loss on 1350 batch: 0.658144
Train loss on 1400 batch: 0.580000
Train loss on 1450 batch: 0.669614
Train loss on 1500 batch: 0.585747
Train loss on 1550 batch: 0.573751
Train loss on 1600 batch: 0.581926
Train loss on 1650 batch: 0.551664
best-train-loss: 0.671643
best-valid-loss: 0.664923
best-kappa: nan
: Epoch: 1 | Training Loss: 0.671643 | Val. Loss: 0.664923 | Val. Kappa Score: nan | Estimated time: 1431.15
Train loss on 50 batch: 0.601026
Train loss on 100 batch: 0.542722
Train loss on 150 batch: 0.519354
Train loss on 200 batch: 0.590357
Train loss on 250 batch: 0.648544
Train loss on 300 batch: 0.499687
Train loss on 350 batch: 0.612402
Train loss on 400 batch: 0.515811
Train loss on 450 batch: 0.578602
Train loss on 500 batch: 0.543461
Train loss on 550 batch: 0.510180
Train loss on 600 batch: 0.592086
Train loss on 650 batch: 0.522434
Train loss on 700 batch: 0.629367
Train loss on 750 batch: 0.595614
Train loss on 800 batch: 0.557658
Train loss on 850 batch: 0.562567
Train loss on 900 batch: 0.613457
Train loss on 950 batch: 0.646636
Train loss on 1000 batch: 0.563990
Train loss on 1050 batch: 0.531388
Train loss on 1100 batch: 0.498357
Train loss on 1150 batch: 0.549563
Train loss on 1200 batch: 0.528601
Train loss on 1250 batch: 0.551988
Train loss on 1300 batch: 0.574165
Train loss on 1350 batch: 0.483330
Train loss on 1400 batch: 0.479055
Train loss on 1450 batch: 0.552402
Train loss on 1500 batch: 0.510959
Train loss on 1550 batch: 0.587864
Train loss on 1600 batch: 0.561210
Train loss on 1650 batch: 0.583361
best-train-loss: 0.560169
best-valid-loss: 0.490862
best-kappa: nan
: Epoch: 2 | Training Loss: 0.560169 | Val. Loss: 0.490862 | Val. Kappa Score: nan | Estimated time: 1423.30
Train loss on 50 batch: 0.539530
Train loss on 100 batch: 0.509044
Train loss on 150 batch: 0.553400
Train loss on 200 batch: 0.463707
Train loss on 250 batch: 0.436023
Train loss on 300 batch: 0.521480
Train loss on 350 batch: 0.490732
Train loss on 400 batch: 0.539021
Train loss on 450 batch: 0.546186
Train loss on 500 batch: 0.441612
Train loss on 550 batch: 0.517843
Train loss on 600 batch: 0.554587
Train loss on 650 batch: 0.486049
Train loss on 700 batch: 0.506338
Train loss on 750 batch: 0.557851
Train loss on 800 batch: 0.580512
Train loss on 850 batch: 0.486272
Train loss on 900 batch: 0.498387
Train loss on 950 batch: 0.570056
Train loss on 1000 batch: 0.523226
Train loss on 1050 batch: 0.566607
Train loss on 1100 batch: 0.502157
Train loss on 1150 batch: 0.482424
Train loss on 1200 batch: 0.513517
Train loss on 1250 batch: 0.512998
Train loss on 1300 batch: 0.542364
Train loss on 1350 batch: 0.513366
Train loss on 1400 batch: 0.505472
Train loss on 1450 batch: 0.496102
Train loss on 1500 batch: 0.514962
Train loss on 1550 batch: 0.501439
Train loss on 1600 batch: 0.504979
Train loss on 1650 batch: 0.479527
: Epoch: 3 | Training Loss: 0.514045 | Val. Loss: 0.518067 | Val. Kappa Score: nan | Estimated time: 1423.88
Train loss on 50 batch: 0.498683
Train loss on 100 batch: 0.537078
Train loss on 150 batch: 0.472671
Train loss on 200 batch: 0.510190
Train loss on 250 batch: 0.460199
Train loss on 300 batch: 0.501042
Train loss on 350 batch: 0.528917
Train loss on 400 batch: 0.498012
Train loss on 450 batch: 0.508885
Train loss on 500 batch: 0.499464
Train loss on 550 batch: 0.461082
Train loss on 600 batch: 0.467462
Train loss on 650 batch: 0.470009
Train loss on 700 batch: 0.485346
Train loss on 750 batch: 0.491765
Train loss on 800 batch: 0.456206
Train loss on 850 batch: 0.477212
Train loss on 900 batch: 0.488216
Train loss on 950 batch: 0.503976
Train loss on 1000 batch: 0.512979
Train loss on 1050 batch: 0.496916
Train loss on 1100 batch: 0.512985
Train loss on 1150 batch: 0.504242
Train loss on 1200 batch: 0.457604
Train loss on 1250 batch: 0.523951
Train loss on 1300 batch: 0.455897
Train loss on 1350 batch: 0.516647
Train loss on 1400 batch: 0.447918
Train loss on 1450 batch: 0.515219
Train loss on 1500 batch: 0.511949
Train loss on 1550 batch: 0.452047
Train loss on 1600 batch: 0.426832
Train loss on 1650 batch: 0.502063
best-train-loss: 0.490668
best-valid-loss: 0.478448
best-kappa: nan
: Epoch: 4 | Training Loss: 0.490668 | Val. Loss: 0.478448 | Val. Kappa Score: nan | Estimated time: 1420.58
Train loss on 50 batch: 0.471042
Train loss on 100 batch: 0.442517
Train loss on 150 batch: 0.459227
Train loss on 200 batch: 0.496516
Train loss on 250 batch: 0.440599
Train loss on 300 batch: 0.414402
Train loss on 350 batch: 0.441165
Train loss on 400 batch: 0.461264
Train loss on 450 batch: 0.494685
Train loss on 500 batch: 0.470283
Train loss on 550 batch: 0.454699
Train loss on 600 batch: 0.402624
Train loss on 650 batch: 0.430832
Train loss on 700 batch: 0.449615
Train loss on 750 batch: 0.447146
Train loss on 800 batch: 0.389299
Train loss on 850 batch: 0.525511
Train loss on 900 batch: 0.489876
Train loss on 950 batch: 0.506616
Train loss on 1000 batch: 0.525143
Train loss on 1050 batch: 0.539495
Train loss on 1100 batch: 0.531597
Train loss on 1150 batch: 0.417099
Train loss on 1200 batch: 0.479977
Train loss on 1250 batch: 0.504548
Train loss on 1300 batch: 0.471386
Train loss on 1350 batch: 0.400624
Train loss on 1400 batch: 0.514267
Train loss on 1450 batch: 0.460048
Train loss on 1500 batch: 0.496379
Train loss on 1550 batch: 0.493008
Train loss on 1600 batch: 0.551755
Train loss on 1650 batch: 0.486625
best-train-loss: 0.471183
best-valid-loss: 0.475933
best-kappa: nan
: Epoch: 5 | Training Loss: 0.471183 | Val. Loss: 0.475933 | Val. Kappa Score: nan | Estimated time: 1421.35
Train loss on 50 batch: 0.533308
Train loss on 100 batch: 0.392888
Train loss on 150 batch: 0.482167
Train loss on 200 batch: 0.451631
Train loss on 250 batch: 0.382828
Train loss on 300 batch: 0.418837
Train loss on 350 batch: 0.472476
Train loss on 400 batch: 0.420323
Train loss on 450 batch: 0.497422
Train loss on 500 batch: 0.476983
Train loss on 550 batch: 0.468208
Train loss on 600 batch: 0.390079
Train loss on 650 batch: 0.385724
Train loss on 700 batch: 0.475832
Train loss on 750 batch: 0.426387
Train loss on 800 batch: 0.473013
Train loss on 850 batch: 0.440136
Train loss on 900 batch: 0.452720
Train loss on 950 batch: 0.415900
Train loss on 1000 batch: 0.370888
Train loss on 1050 batch: 0.454187
Train loss on 1100 batch: 0.511071
Train loss on 1150 batch: 0.423746
Train loss on 1200 batch: 0.481878
Train loss on 1250 batch: 0.481902
Train loss on 1300 batch: 0.444629
Train loss on 1350 batch: 0.439042
Train loss on 1400 batch: 0.503766
Train loss on 1450 batch: 0.474146
Train loss on 1500 batch: 0.496522
Train loss on 1550 batch: 0.449607
Train loss on 1600 batch: 0.425084
Train loss on 1650 batch: 0.402607
best-train-loss: 0.450053
best-valid-loss: 0.434366
best-kappa: nan
: Epoch: 6 | Training Loss: 0.450053 | Val. Loss: 0.434366 | Val. Kappa Score: nan | Estimated time: 1418.52
Train loss on 50 batch: 0.461854
Train loss on 100 batch: 0.448815
Train loss on 150 batch: 0.480919
Train loss on 200 batch: 0.413940
Train loss on 250 batch: 0.412467
Train loss on 300 batch: 0.458661
Train loss on 350 batch: 0.444775
Train loss on 400 batch: 0.477385
Train loss on 450 batch: 0.407407
Train loss on 500 batch: 0.477099
Train loss on 550 batch: 0.476514
Train loss on 600 batch: 0.484051
Train loss on 650 batch: 0.556918
Train loss on 700 batch: 0.461672
Train loss on 750 batch: 0.386333
Train loss on 800 batch: 0.401689
Train loss on 850 batch: 0.399391
Train loss on 900 batch: 0.462152
Train loss on 950 batch: 0.414091
Train loss on 1000 batch: 0.373932
Train loss on 1050 batch: 0.456773
Train loss on 1100 batch: 0.510601
Train loss on 1150 batch: 0.484106
Train loss on 1200 batch: 0.429241
Train loss on 1250 batch: 0.457909
Train loss on 1300 batch: 0.475708
Train loss on 1350 batch: 0.415309
Train loss on 1400 batch: 0.520391
Train loss on 1450 batch: 0.399038
Train loss on 1500 batch: 0.447264
Train loss on 1550 batch: 0.325269
Train loss on 1600 batch: 0.416492
Train loss on 1650 batch: 0.488739
: Epoch: 7 | Training Loss: 0.446485 | Val. Loss: 0.457226 | Val. Kappa Score: nan | Estimated time: 1420.31
Train loss on 50 batch: 0.447825
Train loss on 100 batch: 0.396340
Train loss on 150 batch: 0.503671
Train loss on 200 batch: 0.371764
Train loss on 250 batch: 0.454460
Train loss on 300 batch: 0.447896
Train loss on 350 batch: 0.377410
Train loss on 400 batch: 0.414226
Train loss on 450 batch: 0.419502
Train loss on 500 batch: 0.325017
Train loss on 550 batch: 0.411337
Train loss on 600 batch: 0.416709
Train loss on 650 batch: 0.437136
Train loss on 700 batch: 0.426820
Train loss on 750 batch: 0.429683
Train loss on 800 batch: 0.510207
Train loss on 850 batch: 0.445468
Train loss on 900 batch: 0.412325
Train loss on 950 batch: 0.476123
Train loss on 1000 batch: 0.393412
Train loss on 1050 batch: 0.438855
Train loss on 1100 batch: 0.473552
Train loss on 1150 batch: 0.476706
Train loss on 1200 batch: 0.483378
Train loss on 1250 batch: 0.437758
Train loss on 1300 batch: 0.454362
Train loss on 1350 batch: 0.461714
Train loss on 1400 batch: 0.452227
Train loss on 1450 batch: 0.383813
Train loss on 1500 batch: 0.446386
Train loss on 1550 batch: 0.427650
Train loss on 1600 batch: 0.437812
Train loss on 1650 batch: 0.376275
: Epoch: 8 | Training Loss: 0.430156 | Val. Loss: 0.500339 | Val. Kappa Score: nan | Estimated time: 1421.66
Train loss on 50 batch: 0.386871
Train loss on 100 batch: 0.375310
Train loss on 150 batch: 0.440726
Train loss on 200 batch: 0.388874
Train loss on 250 batch: 0.483757
Train loss on 300 batch: 0.456218
Train loss on 350 batch: 0.420576
Train loss on 400 batch: 0.416978
Train loss on 450 batch: 0.359144
Train loss on 500 batch: 0.429537
Train loss on 550 batch: 0.480533
Train loss on 600 batch: 0.450627
Train loss on 650 batch: 0.367800
Train loss on 700 batch: 0.465977
Train loss on 750 batch: 0.441546
Train loss on 800 batch: 0.454200
Train loss on 850 batch: 0.386857
Train loss on 900 batch: 0.367547
Train loss on 950 batch: 0.370434
Train loss on 1000 batch: 0.376002
Train loss on 1050 batch: 0.432419
Train loss on 1100 batch: 0.468999
Train loss on 1150 batch: 0.393790
Train loss on 1200 batch: 0.468576
Train loss on 1250 batch: 0.427427
Train loss on 1300 batch: 0.400249
Train loss on 1350 batch: 0.401089
Train loss on 1400 batch: 0.351028
Train loss on 1450 batch: 0.350162
Train loss on 1500 batch: 0.507597
Train loss on 1550 batch: 0.424641
Train loss on 1600 batch: 0.452281
Train loss on 1650 batch: 0.419095
best-train-loss: 0.419599
best-valid-loss: 0.423766
best-kappa: nan
: Epoch: 9 | Training Loss: 0.419599 | Val. Loss: 0.423766 | Val. Kappa Score: nan | Estimated time: 1422.19
Train loss on 50 batch: 0.404267
Train loss on 100 batch: 0.441513
Train loss on 150 batch: 0.371846
Train loss on 200 batch: 0.426574
Train loss on 250 batch: 0.416542
Train loss on 300 batch: 0.405491
Train loss on 350 batch: 0.390706
Train loss on 400 batch: 0.461579
Train loss on 450 batch: 0.405125
Train loss on 500 batch: 0.410360
Train loss on 550 batch: 0.446015
Train loss on 600 batch: 0.462339
Train loss on 650 batch: 0.393691
Train loss on 700 batch: 0.437890
Train loss on 750 batch: 0.408157
Train loss on 800 batch: 0.456286
Train loss on 850 batch: 0.350629
Train loss on 900 batch: 0.407047
Train loss on 950 batch: 0.469280
Train loss on 1000 batch: 0.454278
Train loss on 1050 batch: 0.363767
Train loss on 1100 batch: 0.406071
Train loss on 1150 batch: 0.495211
Train loss on 1200 batch: 0.402217
Train loss on 1250 batch: 0.419891
Train loss on 1300 batch: 0.385566
Train loss on 1350 batch: 0.376509
Train loss on 1400 batch: 0.482540
Train loss on 1450 batch: 0.442453
Train loss on 1500 batch: 0.394510
Train loss on 1550 batch: 0.404403
Train loss on 1600 batch: 0.411594
Train loss on 1650 batch: 0.372292
: Epoch: 10 | Training Loss: 0.416059 | Val. Loss: 0.466383 | Val. Kappa Score: nan | Estimated time: 1420.97
Train loss on 50 batch: 0.373967
Train loss on 100 batch: 0.398400
Train loss on 150 batch: 0.496717
Train loss on 200 batch: 0.376224
Train loss on 250 batch: 0.402908
Train loss on 300 batch: 0.346972
Train loss on 350 batch: 0.351271
Train loss on 400 batch: 0.368703
Train loss on 450 batch: 0.401985
Train loss on 500 batch: 0.374047
Train loss on 550 batch: 0.433611
Train loss on 600 batch: 0.431322
Train loss on 650 batch: 0.396702
Train loss on 700 batch: 0.468955
Train loss on 750 batch: 0.497301
Train loss on 800 batch: 0.428014
Train loss on 850 batch: 0.430599
Train loss on 900 batch: 0.423246
Train loss on 950 batch: 0.410123
Train loss on 1000 batch: 0.445854
Train loss on 1050 batch: 0.407582
Train loss on 1100 batch: 0.405681
Train loss on 1150 batch: 0.334798
Train loss on 1200 batch: 0.366835
Train loss on 1250 batch: 0.385535
Train loss on 1300 batch: 0.419114
Train loss on 1350 batch: 0.385237
Train loss on 1400 batch: 0.363997
Train loss on 1450 batch: 0.401865
Train loss on 1500 batch: 0.458697
Train loss on 1550 batch: 0.442617
Train loss on 1600 batch: 0.397902
Train loss on 1650 batch: 0.381435
: Epoch: 11 | Training Loss: 0.404884 | Val. Loss: 0.522141 | Val. Kappa Score: nan | Estimated time: 1420.78
Train loss on 50 batch: 0.357373
Train loss on 100 batch: 0.393727
Train loss on 150 batch: 0.321054
Train loss on 200 batch: 0.429256
Train loss on 250 batch: 0.380955
Train loss on 300 batch: 0.414523
Train loss on 350 batch: 0.406702
Train loss on 400 batch: 0.387060
Train loss on 450 batch: 0.369063
Train loss on 500 batch: 0.361505
Train loss on 550 batch: 0.340206
Train loss on 600 batch: 0.381952
Train loss on 650 batch: 0.394215
Train loss on 700 batch: 0.412479
Train loss on 750 batch: 0.404025
Train loss on 800 batch: 0.387492
Train loss on 850 batch: 0.352386
Train loss on 900 batch: 0.356926
Train loss on 950 batch: 0.417223
Train loss on 1000 batch: 0.404327
Train loss on 1050 batch: 0.413521
Train loss on 1100 batch: 0.371617
Train loss on 1150 batch: 0.408661
Train loss on 1200 batch: 0.367661
Train loss on 1250 batch: 0.421918
Train loss on 1300 batch: 0.409813
Train loss on 1350 batch: 0.429474
Train loss on 1400 batch: 0.431008
Train loss on 1450 batch: 0.404254
Train loss on 1500 batch: 0.415521
Train loss on 1550 batch: 0.417644
Train loss on 1600 batch: 0.431434
Train loss on 1650 batch: 0.399597
: Epoch: 12 | Training Loss: 0.394699 | Val. Loss: 0.467024 | Val. Kappa Score: nan | Estimated time: 1421.21
Train loss on 50 batch: 0.373804
Train loss on 100 batch: 0.418215
Train loss on 150 batch: 0.431983
Train loss on 200 batch: 0.462631
Train loss on 250 batch: 0.340932
Train loss on 300 batch: 0.426359
Train loss on 350 batch: 0.434764
Train loss on 400 batch: 0.427698
Train loss on 450 batch: 0.370409
Train loss on 500 batch: 0.339288
Train loss on 550 batch: 0.386794
Train loss on 600 batch: 0.334794
Train loss on 650 batch: 0.422806
Train loss on 700 batch: 0.396419
Train loss on 750 batch: 0.367905
Train loss on 800 batch: 0.410492
Train loss on 850 batch: 0.394025
Train loss on 900 batch: 0.425607
Train loss on 950 batch: 0.365769
Train loss on 1000 batch: 0.379731
Train loss on 1050 batch: 0.389379
Train loss on 1100 batch: 0.324049
Train loss on 1150 batch: 0.374276
Train loss on 1200 batch: 0.423411
Train loss on 1250 batch: 0.372296
Train loss on 1300 batch: 0.423763
Train loss on 1350 batch: 0.336668
Train loss on 1400 batch: 0.448793
Train loss on 1450 batch: 0.442140
Train loss on 1500 batch: 0.370853
Train loss on 1550 batch: 0.429816
Train loss on 1600 batch: 0.417196
Train loss on 1650 batch: 0.439703
: Epoch: 13 | Training Loss: 0.395501 | Val. Loss: 0.443728 | Val. Kappa Score: nan | Estimated time: 1421.52
Train loss on 50 batch: 0.361524
Train loss on 100 batch: 0.417339
Train loss on 150 batch: 0.443341
Train loss on 200 batch: 0.370149
Train loss on 250 batch: 0.368993
Train loss on 300 batch: 0.459961
Train loss on 350 batch: 0.367712
Train loss on 400 batch: 0.424897
Train loss on 450 batch: 0.319628
Train loss on 500 batch: 0.365766
Train loss on 550 batch: 0.352713
Train loss on 600 batch: 0.430782
Train loss on 650 batch: 0.397510
Train loss on 700 batch: 0.403039
Train loss on 750 batch: 0.343338
Train loss on 800 batch: 0.373365
Train loss on 850 batch: 0.405053
Train loss on 900 batch: 0.394380
Train loss on 950 batch: 0.374170
Train loss on 1000 batch: 0.357844
Train loss on 1050 batch: 0.375433
Train loss on 1100 batch: 0.403621
Train loss on 1150 batch: 0.430018
Train loss on 1200 batch: 0.395055
Train loss on 1250 batch: 0.346098
Train loss on 1300 batch: 0.381656
Train loss on 1350 batch: 0.407239
Train loss on 1400 batch: 0.331606
Train loss on 1450 batch: 0.417566
Train loss on 1500 batch: 0.379472
Train loss on 1550 batch: 0.388542
Train loss on 1600 batch: 0.354191
Train loss on 1650 batch: 0.348632
: Epoch: 14 | Training Loss: 0.385748 | Val. Loss: 0.436421 | Val. Kappa Score: nan | Estimated time: 1421.82
time_estimated: 19910.01
n-epochs: 14
time_estimated: 19910.02
----------------------------------------


Experiment N: 43: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.09 08:22:38
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 5
parameters-amount: 30439985
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.281597
Train loss on 100 batch: 0.876998
Train loss on 150 batch: 0.874745
Train loss on 200 batch: 0.774051
Train loss on 250 batch: 0.786803
Train loss on 300 batch: 0.694030
Train loss on 350 batch: 0.727299
Train loss on 400 batch: 0.769369
Train loss on 450 batch: 0.748732
Train loss on 500 batch: 0.679065
Train loss on 550 batch: 0.686920
Train loss on 600 batch: 0.624727
Train loss on 650 batch: 0.661364
Train loss on 700 batch: 0.730229
Train loss on 750 batch: 0.679172
Train loss on 800 batch: 0.708575
Train loss on 850 batch: 0.589110
Train loss on 900 batch: 0.675226
Train loss on 950 batch: 0.689908
Train loss on 1000 batch: 0.646259
Train loss on 1050 batch: 0.678602
Train loss on 1100 batch: 0.673867
Train loss on 1150 batch: 0.609942
Train loss on 1200 batch: 0.682754
Train loss on 1250 batch: 0.652802
Train loss on 1300 batch: 0.750691
Train loss on 1350 batch: 0.697968
Train loss on 1400 batch: 0.591684
Train loss on 1450 batch: 0.677056
Train loss on 1500 batch: 0.636404
Train loss on 1550 batch: 0.653196
Train loss on 1600 batch: 0.597810
Train loss on 1650 batch: 0.605234
best-train-loss: 0.705852
best-valid-loss: 0.716046
best-kappa: nan
: Epoch: 1 | Training Loss: 0.705852 | Val. Loss: 0.716046 | Val. Kappa Score: nan | Estimated time: 1440.90
Train loss on 50 batch: 0.659242
Train loss on 100 batch: 0.574792
Train loss on 150 batch: 0.583923
Train loss on 200 batch: 0.641633
Train loss on 250 batch: 0.663785
Train loss on 300 batch: 0.492254
Train loss on 350 batch: 0.631499
Train loss on 400 batch: 0.561076
Train loss on 450 batch: 0.567309
Train loss on 500 batch: 0.569172
Train loss on 550 batch: 0.540374
Train loss on 600 batch: 0.564597
Train loss on 650 batch: 0.534193
Train loss on 700 batch: 0.565961
Train loss on 750 batch: 0.633973
Train loss on 800 batch: 0.606775
Train loss on 850 batch: 0.594482
Train loss on 900 batch: 0.623684
Train loss on 950 batch: 0.696721
Train loss on 1000 batch: 0.622902
Train loss on 1050 batch: 0.587201
Train loss on 1100 batch: 0.512918
Train loss on 1150 batch: 0.548666
Train loss on 1200 batch: 0.574901
Train loss on 1250 batch: 0.532880
Train loss on 1300 batch: 0.591259
Train loss on 1350 batch: 0.534998
Train loss on 1400 batch: 0.500025
Train loss on 1450 batch: 0.563779
Train loss on 1500 batch: 0.534925
Train loss on 1550 batch: 0.622134
Train loss on 1600 batch: 0.568668
Train loss on 1650 batch: 0.572497
best-train-loss: 0.581523
best-valid-loss: 0.534035
best-kappa: nan
: Epoch: 2 | Training Loss: 0.581523 | Val. Loss: 0.534035 | Val. Kappa Score: nan | Estimated time: 1427.38
Train loss on 50 batch: 0.569044
Train loss on 100 batch: 0.577430
Train loss on 150 batch: 0.591733
Train loss on 200 batch: 0.496244
Train loss on 250 batch: 0.465230
Train loss on 300 batch: 0.578744
Train loss on 350 batch: 0.531325
Train loss on 400 batch: 0.564028
Train loss on 450 batch: 0.560148
Train loss on 500 batch: 0.466650
Train loss on 550 batch: 0.525800
Train loss on 600 batch: 0.584777
Train loss on 650 batch: 0.509001
Train loss on 700 batch: 0.528746
Train loss on 750 batch: 0.625952
Train loss on 800 batch: 0.618434
Train loss on 850 batch: 0.544592
Train loss on 900 batch: 0.548572
Train loss on 950 batch: 0.617663
Train loss on 1000 batch: 0.566896
Train loss on 1050 batch: 0.607024
Train loss on 1100 batch: 0.528930
Train loss on 1150 batch: 0.514754
Train loss on 1200 batch: 0.484383
Train loss on 1250 batch: 0.540387
Train loss on 1300 batch: 0.554321
Train loss on 1350 batch: 0.568225
Train loss on 1400 batch: 0.553887
Train loss on 1450 batch: 0.528070
Train loss on 1500 batch: 0.557328
Train loss on 1550 batch: 0.543757
Train loss on 1600 batch: 0.515804
Train loss on 1650 batch: 0.536898
best-train-loss: 0.548469
best-valid-loss: 0.517829
best-kappa: nan
: Epoch: 3 | Training Loss: 0.548469 | Val. Loss: 0.517829 | Val. Kappa Score: nan | Estimated time: 1420.41
Train loss on 50 batch: 0.552611
Train loss on 100 batch: 0.540070
Train loss on 150 batch: 0.503852
Train loss on 200 batch: 0.482718
Train loss on 250 batch: 0.496887
Train loss on 300 batch: 0.562557
Train loss on 350 batch: 0.544982
Train loss on 400 batch: 0.574345
Train loss on 450 batch: 0.517761
Train loss on 500 batch: 0.542999
Train loss on 550 batch: 0.488904
Train loss on 600 batch: 0.487029
Train loss on 650 batch: 0.505700
Train loss on 700 batch: 0.479068
Train loss on 750 batch: 0.502180
Train loss on 800 batch: 0.516685
Train loss on 850 batch: 0.517218
Train loss on 900 batch: 0.505733
Train loss on 950 batch: 0.542608
Train loss on 1000 batch: 0.512721
Train loss on 1050 batch: 0.537706
Train loss on 1100 batch: 0.548759
Train loss on 1150 batch: 0.512333
Train loss on 1200 batch: 0.483066
Train loss on 1250 batch: 0.523028
Train loss on 1300 batch: 0.500313
Train loss on 1350 batch: 0.552265
Train loss on 1400 batch: 0.461193
Train loss on 1450 batch: 0.536701
Train loss on 1500 batch: 0.538616
Train loss on 1550 batch: 0.462159
Train loss on 1600 batch: 0.461094
Train loss on 1650 batch: 0.494331
: Epoch: 4 | Training Loss: 0.517605 | Val. Loss: 0.585969 | Val. Kappa Score: nan | Estimated time: 1422.70
Train loss on 50 batch: 0.533113
Train loss on 100 batch: 0.450862
Train loss on 150 batch: 0.518917
Train loss on 200 batch: 0.473798
Train loss on 250 batch: 0.473951
Train loss on 300 batch: 0.456212
Train loss on 350 batch: 0.448461
Train loss on 400 batch: 0.468121
Train loss on 450 batch: 0.502713
Train loss on 500 batch: 0.494167
Train loss on 550 batch: 0.508417
Train loss on 600 batch: 0.472629
Train loss on 650 batch: 0.467993
Train loss on 700 batch: 0.481085
Train loss on 750 batch: 0.488987
Train loss on 800 batch: 0.448386
Train loss on 850 batch: 0.563665
Train loss on 900 batch: 0.530185
Train loss on 950 batch: 0.522296
Train loss on 1000 batch: 0.515283
Train loss on 1050 batch: 0.607025
Train loss on 1100 batch: 0.559077
Train loss on 1150 batch: 0.407937
Train loss on 1200 batch: 0.510104
Train loss on 1250 batch: 0.558587
Train loss on 1300 batch: 0.501648
Train loss on 1350 batch: 0.420988
Train loss on 1400 batch: 0.530793
Train loss on 1450 batch: 0.478874
Train loss on 1500 batch: 0.503905
Train loss on 1550 batch: 0.517613
Train loss on 1600 batch: 0.568223
Train loss on 1650 batch: 0.541772
best-train-loss: 0.501269
best-valid-loss: 0.497449
best-kappa: nan
: Epoch: 5 | Training Loss: 0.501269 | Val. Loss: 0.497449 | Val. Kappa Score: nan | Estimated time: 1420.81
Train loss on 50 batch: 0.577380
Train loss on 100 batch: 0.391738
Train loss on 150 batch: 0.483743
Train loss on 200 batch: 0.458200
Train loss on 250 batch: 0.404968
Train loss on 300 batch: 0.484829
Train loss on 350 batch: 0.498448
Train loss on 400 batch: 0.418785
Train loss on 450 batch: 0.567723
Train loss on 500 batch: 0.528309
Train loss on 550 batch: 0.503483
Train loss on 600 batch: 0.406162
Train loss on 650 batch: 0.418591
Train loss on 700 batch: 0.490749
Train loss on 750 batch: 0.497070
Train loss on 800 batch: 0.482192
Train loss on 850 batch: 0.485292
Train loss on 900 batch: 0.455434
Train loss on 950 batch: 0.453673
Train loss on 1000 batch: 0.387895
Train loss on 1050 batch: 0.471346
Train loss on 1100 batch: 0.553944
Train loss on 1150 batch: 0.459294
Train loss on 1200 batch: 0.468647
Train loss on 1250 batch: 0.519397
Train loss on 1300 batch: 0.519961
Train loss on 1350 batch: 0.460486
Train loss on 1400 batch: 0.579824
Train loss on 1450 batch: 0.544220
Train loss on 1500 batch: 0.554445
Train loss on 1550 batch: 0.482503
Train loss on 1600 batch: 0.459089
Train loss on 1650 batch: 0.474029
: Epoch: 6 | Training Loss: 0.483660 | Val. Loss: 0.542931 | Val. Kappa Score: nan | Estimated time: 1420.35
Train loss on 50 batch: 0.510262
Train loss on 100 batch: 0.493813
Train loss on 150 batch: 0.511831
Train loss on 200 batch: 0.433351
Train loss on 250 batch: 0.450310
Train loss on 300 batch: 0.486195
Train loss on 350 batch: 0.482772
Train loss on 400 batch: 0.504821
Train loss on 450 batch: 0.416283
Train loss on 500 batch: 0.487013
Train loss on 550 batch: 0.494572
Train loss on 600 batch: 0.524254
Train loss on 650 batch: 0.538387
Train loss on 700 batch: 0.465662
Train loss on 750 batch: 0.387914
Train loss on 800 batch: 0.423760
Train loss on 850 batch: 0.437932
Train loss on 900 batch: 0.498911
Train loss on 950 batch: 0.437746
Train loss on 1000 batch: 0.365221
Train loss on 1050 batch: 0.460003
Train loss on 1100 batch: 0.509699
Train loss on 1150 batch: 0.482745
Train loss on 1200 batch: 0.503714
Train loss on 1250 batch: 0.492453
Train loss on 1300 batch: 0.512545
Train loss on 1350 batch: 0.407477
Train loss on 1400 batch: 0.557401
Train loss on 1450 batch: 0.443433
Train loss on 1500 batch: 0.460800
Train loss on 1550 batch: 0.395558
Train loss on 1600 batch: 0.413819
Train loss on 1650 batch: 0.481287
: Epoch: 7 | Training Loss: 0.467920 | Val. Loss: 0.516253 | Val. Kappa Score: nan | Estimated time: 1421.14
Train loss on 50 batch: 0.465916
Train loss on 100 batch: 0.437414
Train loss on 150 batch: 0.525437
Train loss on 200 batch: 0.423973
Train loss on 250 batch: 0.514628
Train loss on 300 batch: 0.479636
Train loss on 350 batch: 0.410011
Train loss on 400 batch: 0.456926
Train loss on 450 batch: 0.476197
Train loss on 500 batch: 0.381431
Train loss on 550 batch: 0.388218
Train loss on 600 batch: 0.438810
Train loss on 650 batch: 0.433782
Train loss on 700 batch: 0.481071
Train loss on 750 batch: 0.421618
Train loss on 800 batch: 0.530188
Train loss on 850 batch: 0.464555
Train loss on 900 batch: 0.480924
Train loss on 950 batch: 0.525460
Train loss on 1000 batch: 0.442406
Train loss on 1050 batch: 0.455028
Train loss on 1100 batch: 0.468070
Train loss on 1150 batch: 0.497041
Train loss on 1200 batch: 0.481936
Train loss on 1250 batch: 0.482174
Train loss on 1300 batch: 0.526424
Train loss on 1350 batch: 0.487513
Train loss on 1400 batch: 0.481487
Train loss on 1450 batch: 0.402669
Train loss on 1500 batch: 0.517449
Train loss on 1550 batch: 0.522325
Train loss on 1600 batch: 0.445251
Train loss on 1650 batch: 0.446619
: Epoch: 8 | Training Loss: 0.465285 | Val. Loss: 0.585353 | Val. Kappa Score: nan | Estimated time: 1421.07
Train loss on 50 batch: 0.420199
Train loss on 100 batch: 0.418160
Train loss on 150 batch: 0.482041
Train loss on 200 batch: 0.419952
Train loss on 250 batch: 0.496668
Train loss on 300 batch: 0.514544
Train loss on 350 batch: 0.443773
Train loss on 400 batch: 0.475223
Train loss on 450 batch: 0.388484
Train loss on 500 batch: 0.459035
Train loss on 550 batch: 0.452941
Train loss on 600 batch: 0.498163
Train loss on 650 batch: 0.374376
Train loss on 700 batch: 0.501847
Train loss on 750 batch: 0.481438
Train loss on 800 batch: 0.479677
Train loss on 850 batch: 0.420838
Train loss on 900 batch: 0.403276
Train loss on 950 batch: 0.407932
Train loss on 1000 batch: 0.420432
Train loss on 1050 batch: 0.463742
Train loss on 1100 batch: 0.491423
Train loss on 1150 batch: 0.421686
Train loss on 1200 batch: 0.532780
Train loss on 1250 batch: 0.447481
Train loss on 1300 batch: 0.429925
Train loss on 1350 batch: 0.425242
Train loss on 1400 batch: 0.390619
Train loss on 1450 batch: 0.416188
Train loss on 1500 batch: 0.536322
Train loss on 1550 batch: 0.471712
Train loss on 1600 batch: 0.484301
Train loss on 1650 batch: 0.476429
best-train-loss: 0.453285
best-valid-loss: 0.466799
best-kappa: nan
: Epoch: 9 | Training Loss: 0.453285 | Val. Loss: 0.466799 | Val. Kappa Score: nan | Estimated time: 1421.24
Train loss on 50 batch: 0.453198
Train loss on 100 batch: 0.494032
Train loss on 150 batch: 0.400244
Train loss on 200 batch: 0.439028
Train loss on 250 batch: 0.430234
Train loss on 300 batch: 0.437601
Train loss on 350 batch: 0.462004
Train loss on 400 batch: 0.455643
Train loss on 450 batch: 0.423496
Train loss on 500 batch: 0.396514
Train loss on 550 batch: 0.432196
Train loss on 600 batch: 0.470826
Train loss on 650 batch: 0.375120
Train loss on 700 batch: 0.483827
Train loss on 750 batch: 0.419502
Train loss on 800 batch: 0.466986
Train loss on 850 batch: 0.368678
Train loss on 900 batch: 0.426624
Train loss on 950 batch: 0.482803
Train loss on 1000 batch: 0.446307
Train loss on 1050 batch: 0.392588
Train loss on 1100 batch: 0.429843
Train loss on 1150 batch: 0.518862
Train loss on 1200 batch: 0.443035
Train loss on 1250 batch: 0.461956
Train loss on 1300 batch: 0.410155
Train loss on 1350 batch: 0.463502
Train loss on 1400 batch: 0.492188
Train loss on 1450 batch: 0.444876
Train loss on 1500 batch: 0.382720
Train loss on 1550 batch: 0.416136
Train loss on 1600 batch: 0.469189
Train loss on 1650 batch: 0.394829
best-train-loss: 0.438270
best-valid-loss: 0.438461
best-kappa: nan
: Epoch: 10 | Training Loss: 0.438270 | Val. Loss: 0.438461 | Val. Kappa Score: nan | Estimated time: 1421.00
Train loss on 50 batch: 0.383643
Train loss on 100 batch: 0.392580
Train loss on 150 batch: 0.475503
Train loss on 200 batch: 0.441016
Train loss on 250 batch: 0.424335
Train loss on 300 batch: 0.369247
Train loss on 350 batch: 0.366002
Train loss on 400 batch: 0.437208
Train loss on 450 batch: 0.466700
Train loss on 500 batch: 0.417114
Train loss on 550 batch: 0.435340
Train loss on 600 batch: 0.432833
Train loss on 650 batch: 0.422535
Train loss on 700 batch: 0.476496
Train loss on 750 batch: 0.514963
Train loss on 800 batch: 0.468223
Train loss on 850 batch: 0.474497
Train loss on 900 batch: 0.413234
Train loss on 950 batch: 0.404797
Train loss on 1000 batch: 0.479515
Train loss on 1050 batch: 0.410979
Train loss on 1100 batch: 0.438743
Train loss on 1150 batch: 0.353475
Train loss on 1200 batch: 0.401282
Train loss on 1250 batch: 0.377294
Train loss on 1300 batch: 0.436441
Train loss on 1350 batch: 0.433013
Train loss on 1400 batch: 0.373312
Train loss on 1450 batch: 0.416030
Train loss on 1500 batch: 0.503552
Train loss on 1550 batch: 0.431090
Train loss on 1600 batch: 0.444050
Train loss on 1650 batch: 0.370507
best-train-loss: 0.425971
best-valid-loss: 0.428019
best-kappa: nan
: Epoch: 11 | Training Loss: 0.425971 | Val. Loss: 0.428019 | Val. Kappa Score: nan | Estimated time: 1434.19
Train loss on 50 batch: 0.363254
Train loss on 100 batch: 0.431772
Train loss on 150 batch: 0.360212
Train loss on 200 batch: 0.451053
Train loss on 250 batch: 0.436905
Train loss on 300 batch: 0.448193
Train loss on 350 batch: 0.419198
Train loss on 400 batch: 0.370117
Train loss on 450 batch: 0.394743
Train loss on 500 batch: 0.392038
Train loss on 550 batch: 0.377593
Train loss on 600 batch: 0.402211
Train loss on 650 batch: 0.387279
Train loss on 700 batch: 0.427346
Train loss on 750 batch: 0.460287
Train loss on 800 batch: 0.402530
Train loss on 850 batch: 0.386392
Train loss on 900 batch: 0.348555
Train loss on 950 batch: 0.455704
Train loss on 1000 batch: 0.457218
Train loss on 1050 batch: 0.435389
Train loss on 1100 batch: 0.386010
Train loss on 1150 batch: 0.422537
Train loss on 1200 batch: 0.455214
Train loss on 1250 batch: 0.482647
Train loss on 1300 batch: 0.413803
Train loss on 1350 batch: 0.386793
Train loss on 1400 batch: 0.488532
Train loss on 1450 batch: 0.465809
Train loss on 1500 batch: 0.458848
Train loss on 1550 batch: 0.401347
Train loss on 1600 batch: 0.437922
Train loss on 1650 batch: 0.375213
best-train-loss: 0.418169
best-valid-loss: 0.395915
best-kappa: nan
: Epoch: 12 | Training Loss: 0.418169 | Val. Loss: 0.395915 | Val. Kappa Score: nan | Estimated time: 1421.55
Train loss on 50 batch: 0.390569
Train loss on 100 batch: 0.459314
Train loss on 150 batch: 0.444779
Train loss on 200 batch: 0.471681
Train loss on 250 batch: 0.367930
Train loss on 300 batch: 0.423724
Train loss on 350 batch: 0.421129
Train loss on 400 batch: 0.366703
Train loss on 450 batch: 0.391481
Train loss on 500 batch: 0.365782
Train loss on 550 batch: 0.404579
Train loss on 600 batch: 0.347873
Train loss on 650 batch: 0.427613
Train loss on 700 batch: 0.435972
Train loss on 750 batch: 0.394560
Train loss on 800 batch: 0.421513
Train loss on 850 batch: 0.423081
Train loss on 900 batch: 0.416488
Train loss on 950 batch: 0.387105
Train loss on 1000 batch: 0.421858
Train loss on 1050 batch: 0.393222
Train loss on 1100 batch: 0.360578
Train loss on 1150 batch: 0.398250
Train loss on 1200 batch: 0.463661
Train loss on 1250 batch: 0.424100
Train loss on 1300 batch: 0.429222
Train loss on 1350 batch: 0.357951
Train loss on 1400 batch: 0.438833
Train loss on 1450 batch: 0.470608
Train loss on 1500 batch: 0.395937
Train loss on 1550 batch: 0.455630
Train loss on 1600 batch: 0.437991
Train loss on 1650 batch: 0.439080
: Epoch: 13 | Training Loss: 0.412493 | Val. Loss: 0.402284 | Val. Kappa Score: nan | Estimated time: 1419.68
Train loss on 50 batch: 0.362136
Train loss on 100 batch: 0.482404
Train loss on 150 batch: 0.455844
Train loss on 200 batch: 0.431709
Train loss on 250 batch: 0.400814
Train loss on 300 batch: 0.441190
Train loss on 350 batch: 0.408419
Train loss on 400 batch: 0.463079
Train loss on 450 batch: 0.328597
Train loss on 500 batch: 0.378705
Train loss on 550 batch: 0.370264
Train loss on 600 batch: 0.427211
Train loss on 650 batch: 0.433782
Train loss on 700 batch: 0.497438
Train loss on 750 batch: 0.391606
Train loss on 800 batch: 0.411833
Train loss on 850 batch: 0.463758
Train loss on 900 batch: 0.400520
Train loss on 950 batch: 0.438869
Train loss on 1000 batch: 0.367520
Train loss on 1050 batch: 0.375514
Train loss on 1100 batch: 0.407902
Train loss on 1150 batch: 0.465292
Train loss on 1200 batch: 0.416230
Train loss on 1250 batch: 0.393919
Train loss on 1300 batch: 0.406942
Train loss on 1350 batch: 0.435848
Train loss on 1400 batch: 0.383511
Train loss on 1450 batch: 0.379964
Train loss on 1500 batch: 0.383914
Train loss on 1550 batch: 0.366922
Train loss on 1600 batch: 0.369258
Train loss on 1650 batch: 0.355440
: Epoch: 14 | Training Loss: 0.411189 | Val. Loss: 0.529756 | Val. Kappa Score: nan | Estimated time: 1419.87
Train loss on 50 batch: 0.326282
Train loss on 100 batch: 0.392203
Train loss on 150 batch: 0.360561
Train loss on 200 batch: 0.352205
Train loss on 250 batch: 0.438951
Train loss on 300 batch: 0.408350
Train loss on 350 batch: 0.375329
Train loss on 400 batch: 0.405455
Train loss on 450 batch: 0.401331
Train loss on 500 batch: 0.420394
Train loss on 550 batch: 0.392611
Train loss on 600 batch: 0.402241
Train loss on 650 batch: 0.413031
Train loss on 700 batch: 0.423949
Train loss on 750 batch: 0.430726
Train loss on 800 batch: 0.433020
Train loss on 850 batch: 0.381209
Train loss on 900 batch: 0.363258
Train loss on 950 batch: 0.429544
Train loss on 1000 batch: 0.382612
Train loss on 1050 batch: 0.361135
Train loss on 1100 batch: 0.418237
Train loss on 1150 batch: 0.446575
Train loss on 1200 batch: 0.359728
Train loss on 1250 batch: 0.409703
Train loss on 1300 batch: 0.444937
Train loss on 1350 batch: 0.361462
Train loss on 1400 batch: 0.416696
Train loss on 1450 batch: 0.359422
Train loss on 1500 batch: 0.425380
Train loss on 1550 batch: 0.438844
Train loss on 1600 batch: 0.410282
Train loss on 1650 batch: 0.409061
: Epoch: 15 | Training Loss: 0.401823 | Val. Loss: 0.422862 | Val. Kappa Score: nan | Estimated time: 1420.40
Train loss on 50 batch: 0.370733
Train loss on 100 batch: 0.377435
Train loss on 150 batch: 0.362736
Train loss on 200 batch: 0.382784
Train loss on 250 batch: 0.397593
Train loss on 300 batch: 0.426502
Train loss on 350 batch: 0.380812
Train loss on 400 batch: 0.451063
Train loss on 450 batch: 0.387366
Train loss on 500 batch: 0.361395
Train loss on 550 batch: 0.393855
Train loss on 600 batch: 0.413102
Train loss on 650 batch: 0.330589
Train loss on 700 batch: 0.388507
Train loss on 750 batch: 0.458166
Train loss on 800 batch: 0.400130
Train loss on 850 batch: 0.369878
Train loss on 900 batch: 0.363444
Train loss on 950 batch: 0.339349
Train loss on 1000 batch: 0.425041
Train loss on 1050 batch: 0.361684
Train loss on 1100 batch: 0.413159
Train loss on 1150 batch: 0.450865
Train loss on 1200 batch: 0.392675
Train loss on 1250 batch: 0.451285
Train loss on 1300 batch: 0.401799
Train loss on 1350 batch: 0.398625
Train loss on 1400 batch: 0.404256
Train loss on 1450 batch: 0.363042
Train loss on 1500 batch: 0.353483
Train loss on 1550 batch: 0.415061
Train loss on 1600 batch: 0.378259
Train loss on 1650 batch: 0.430576
: Epoch: 16 | Training Loss: 0.393927 | Val. Loss: 0.422026 | Val. Kappa Score: nan | Estimated time: 1420.16
Train loss on 50 batch: 0.384137
Train loss on 100 batch: 0.355401
Train loss on 150 batch: 0.375944
Train loss on 200 batch: 0.373524
Train loss on 250 batch: 0.484975
Train loss on 300 batch: 0.406042
Train loss on 350 batch: 0.412299
Train loss on 400 batch: 0.417439
Train loss on 450 batch: 0.427632
Train loss on 500 batch: 0.402717
Train loss on 550 batch: 0.359765
Train loss on 600 batch: 0.353864
Train loss on 650 batch: 0.375579
Train loss on 700 batch: 0.366896
Train loss on 750 batch: 0.334273
Train loss on 800 batch: 0.345760
Train loss on 850 batch: 0.359736
Train loss on 900 batch: 0.423661
Train loss on 950 batch: 0.422601
Train loss on 1000 batch: 0.457204
Train loss on 1050 batch: 0.332396
Train loss on 1100 batch: 0.408479
Train loss on 1150 batch: 0.429926
Train loss on 1200 batch: 0.397821
Train loss on 1250 batch: 0.376604
Train loss on 1300 batch: 0.371483
Train loss on 1350 batch: 0.409802
Train loss on 1400 batch: 0.386604
Train loss on 1450 batch: 0.433282
Train loss on 1500 batch: 0.391745
Train loss on 1550 batch: 0.351455
Train loss on 1600 batch: 0.435465
Train loss on 1650 batch: 0.372452
: Epoch: 17 | Training Loss: 0.392625 | Val. Loss: 0.458499 | Val. Kappa Score: nan | Estimated time: 1418.73
time_estimated: 24192.81
n-epochs: 17
time_estimated: 24192.82
----------------------------------------

Experiment N: 44: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.09 17:40:21
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 5
parameters-amount: 30442033
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.161228
Train loss on 100 batch: 1.005456
Train loss on 150 batch: 0.908739
Train loss on 200 batch: 0.895918
Train loss on 250 batch: 0.851471
Train loss on 300 batch: 0.753605
Train loss on 350 batch: 0.739536
Train loss on 400 batch: 0.785962
Train loss on 450 batch: 0.822090
Train loss on 500 batch: 0.763409
Train loss on 550 batch: 0.734488
Train loss on 600 batch: 0.756982
Train loss on 650 batch: 0.768175
Train loss on 700 batch: 0.855914
Train loss on 750 batch: 0.809775
Train loss on 800 batch: 0.885095
Train loss on 850 batch: 0.748811
Train loss on 900 batch: 0.923605
Train loss on 950 batch: 0.936108
Train loss on 1000 batch: 0.683815
Train loss on 1050 batch: 0.889829
Train loss on 1100 batch: 0.841950
Train loss on 1150 batch: 0.883740
Train loss on 1200 batch: 0.912427
Train loss on 1250 batch: 0.828133
Train loss on 1300 batch: 0.955723
Train loss on 1350 batch: 0.888214
Train loss on 1400 batch: 0.728429
Train loss on 1450 batch: 0.818556
Train loss on 1500 batch: 0.812804
Train loss on 1550 batch: 0.774263
Train loss on 1600 batch: 0.699247
Train loss on 1650 batch: 0.679645
best-train-loss: 0.861007
best-valid-loss: 0.669974
best-kappa: 0.4754
: Epoch: 1 | Training Loss: 0.861007 | Val. Loss: 0.669974 | Val. Kappa Score: 0.4754 | Estimated time: 1443.69
Train loss on 50 batch: 0.816232
Train loss on 100 batch: 0.753572
Train loss on 150 batch: 0.841277
Train loss on 200 batch: 0.826660
Train loss on 250 batch: 0.887769
Train loss on 300 batch: 0.992804
Train loss on 350 batch: 0.855980
Train loss on 400 batch: 0.800177
Train loss on 450 batch: 0.882879
Train loss on 500 batch: 0.804211
Train loss on 550 batch: 0.704610
Train loss on 600 batch: 0.780203
Train loss on 650 batch: 0.816453
Train loss on 700 batch: 0.935922
Train loss on 750 batch: 0.853544
Train loss on 800 batch: 0.737425
Train loss on 850 batch: 0.741568
Train loss on 900 batch: 0.845026
Train loss on 950 batch: 0.783795
Train loss on 1000 batch: 0.777898
Train loss on 1050 batch: 0.733826
Train loss on 1100 batch: 0.610366
Train loss on 1150 batch: 0.748276
Train loss on 1200 batch: 0.850672
Train loss on 1250 batch: 0.793303
Train loss on 1300 batch: 0.691398
Train loss on 1350 batch: 0.726147
Train loss on 1400 batch: 0.675063
Train loss on 1450 batch: 0.685588
Train loss on 1500 batch: 0.669503
Train loss on 1550 batch: 0.764623
Train loss on 1600 batch: 0.719785
Train loss on 1650 batch: 0.729327
: Epoch: 2 | Training Loss: 0.782331 | Val. Loss: 1.015364 | Val. Kappa Score: 0.4817 | Estimated time: 1434.17
Train loss on 50 batch: 0.763732
Train loss on 100 batch: 0.640549
Train loss on 150 batch: 0.700870
Train loss on 200 batch: 0.674541
Train loss on 250 batch: 0.620539
Train loss on 300 batch: 0.743525
Train loss on 350 batch: 0.653741
Train loss on 400 batch: 0.760992
Train loss on 450 batch: 0.701440
Train loss on 500 batch: 0.672871
Train loss on 550 batch: 0.707428
Train loss on 600 batch: 0.696987
Train loss on 650 batch: 0.571842
Train loss on 700 batch: 0.641039
Train loss on 750 batch: 0.721309
Train loss on 800 batch: 0.707093
Train loss on 850 batch: 0.686791
Train loss on 900 batch: 0.670777
Train loss on 950 batch: 0.759003
Train loss on 1000 batch: 0.694290
Train loss on 1050 batch: 0.736096
Train loss on 1100 batch: 0.688700
Train loss on 1150 batch: 0.655694
Train loss on 1200 batch: 0.711431
Train loss on 1250 batch: 0.671354
Train loss on 1300 batch: 0.681429
Train loss on 1350 batch: 0.713702
Train loss on 1400 batch: 0.754222
Train loss on 1450 batch: 0.711036
Train loss on 1500 batch: 0.816086
Train loss on 1550 batch: 0.740277
Train loss on 1600 batch: 0.657506
Train loss on 1650 batch: 0.703605
: Epoch: 3 | Training Loss: 0.700275 | Val. Loss: 7.753335 | Val. Kappa Score: nan | Estimated time: 1418.45
Train loss on 50 batch: 0.699043
Train loss on 100 batch: 0.751158
Train loss on 150 batch: 0.677103
Train loss on 200 batch: 0.724095
Train loss on 250 batch: 0.697627
Train loss on 300 batch: 0.765867
Train loss on 350 batch: 0.715497
Train loss on 400 batch: 0.729623
Train loss on 450 batch: 0.727593
Train loss on 500 batch: 0.729061
Train loss on 550 batch: 0.664187
Train loss on 600 batch: 0.687396
Train loss on 650 batch: 0.685495
Train loss on 700 batch: 0.670971
Train loss on 750 batch: 0.735317
Train loss on 800 batch: 0.692047
Train loss on 850 batch: 0.694627
Train loss on 900 batch: 0.650949
Train loss on 950 batch: 0.765801
Train loss on 1000 batch: 0.772672
Train loss on 1050 batch: 0.718787
Train loss on 1100 batch: 0.710991
Train loss on 1150 batch: 0.703982
Train loss on 1200 batch: 0.661069
Train loss on 1250 batch: 0.733003
Train loss on 1300 batch: 0.684830
Train loss on 1350 batch: 0.701115
Train loss on 1400 batch: 0.684085
Train loss on 1450 batch: 0.768563
Train loss on 1500 batch: 0.769242
Train loss on 1550 batch: 0.638636
Train loss on 1600 batch: 0.616184
Train loss on 1650 batch: 0.783244
: Epoch: 4 | Training Loss: 0.713187 | Val. Loss: 0.705629 | Val. Kappa Score: nan | Estimated time: 1420.05
Train loss on 50 batch: 0.736055
Train loss on 100 batch: 0.636768
Train loss on 150 batch: 0.686684
Train loss on 200 batch: 0.646709
Train loss on 250 batch: 0.685064
Train loss on 300 batch: 0.777680
Train loss on 350 batch: 0.620628
Train loss on 400 batch: 0.625786
Train loss on 450 batch: 0.663168
Train loss on 500 batch: 0.673557
Train loss on 550 batch: 0.639798
Train loss on 600 batch: 0.620354
Train loss on 650 batch: 0.604575
Train loss on 700 batch: 0.635612
Train loss on 750 batch: 0.606451
Train loss on 800 batch: 0.610723
Train loss on 850 batch: 0.738227
Train loss on 900 batch: 0.634821
Train loss on 950 batch: 0.675593
Train loss on 1000 batch: 0.698469
Train loss on 1050 batch: 0.729940
Train loss on 1100 batch: 0.682644
Train loss on 1150 batch: 0.602280
Train loss on 1200 batch: 0.744207
Train loss on 1250 batch: 0.676438
Train loss on 1300 batch: 0.701908
Train loss on 1350 batch: 0.553752
Train loss on 1400 batch: 0.703066
Train loss on 1450 batch: 0.616087
Train loss on 1500 batch: 0.625290
Train loss on 1550 batch: 0.667699
Train loss on 1600 batch: 0.635366
Train loss on 1650 batch: 0.655990
best-train-loss: 0.659752
best-valid-loss: 0.566328
best-kappa: nan
: Epoch: 5 | Training Loss: 0.659752 | Val. Loss: 0.566328 | Val. Kappa Score: nan | Estimated time: 1419.50
Train loss on 50 batch: 0.627980
Train loss on 100 batch: 0.565078
Train loss on 150 batch: 0.649988
Train loss on 200 batch: 0.618614
Train loss on 250 batch: 0.483860
Train loss on 300 batch: 0.611792
Train loss on 350 batch: 0.661648
Train loss on 400 batch: 0.562023
Train loss on 450 batch: 0.701881
Train loss on 500 batch: 0.673378
Train loss on 550 batch: 0.649048
Train loss on 600 batch: 0.548616
Train loss on 650 batch: 0.582178
Train loss on 700 batch: 0.632298
Train loss on 750 batch: 0.576168
Train loss on 800 batch: 0.632218
Train loss on 850 batch: 0.631986
Train loss on 900 batch: 0.589257
Train loss on 950 batch: 0.598228
Train loss on 1000 batch: 0.510499
Train loss on 1050 batch: 0.610954
Train loss on 1100 batch: 0.723094
Train loss on 1150 batch: 0.643028
Train loss on 1200 batch: 0.658886
Train loss on 1250 batch: 0.621701
Train loss on 1300 batch: 0.691419
Train loss on 1350 batch: 0.588411
Train loss on 1400 batch: 0.628678
Train loss on 1450 batch: 0.720475
Train loss on 1500 batch: 0.643712
Train loss on 1550 batch: 0.559969
Train loss on 1600 batch: 0.607356
Train loss on 1650 batch: 0.540974
: Epoch: 6 | Training Loss: 0.618574 | Val. Loss: 0.603869 | Val. Kappa Score: nan | Estimated time: 1420.16
Train loss on 50 batch: 0.615468
Train loss on 100 batch: 0.665229
Train loss on 150 batch: 0.625172
Train loss on 200 batch: 0.590226
Train loss on 250 batch: 0.597798
Train loss on 300 batch: 0.623967
Train loss on 350 batch: 0.621762
Train loss on 400 batch: 0.658580
Train loss on 450 batch: 0.549514
Train loss on 500 batch: 0.578355
Train loss on 550 batch: 0.615359
Train loss on 600 batch: 0.666001
Train loss on 650 batch: 0.684669
Train loss on 700 batch: 0.563008
Train loss on 750 batch: 0.480978
Train loss on 800 batch: 0.539466
Train loss on 850 batch: 0.557469
Train loss on 900 batch: 0.605720
Train loss on 950 batch: 0.558604
Train loss on 1000 batch: 0.484925
Train loss on 1050 batch: 0.592304
Train loss on 1100 batch: 0.644944
Train loss on 1150 batch: 0.651857
Train loss on 1200 batch: 0.588733
Train loss on 1250 batch: 0.620294
Train loss on 1300 batch: 0.628954
Train loss on 1350 batch: 0.591178
Train loss on 1400 batch: 0.698480
Train loss on 1450 batch: 0.542450
Train loss on 1500 batch: 0.578117
Train loss on 1550 batch: 0.453770
Train loss on 1600 batch: 0.498748
Train loss on 1650 batch: 0.616324
best-train-loss: 0.590537
best-valid-loss: 0.508177
best-kappa: nan
: Epoch: 7 | Training Loss: 0.590537 | Val. Loss: 0.508177 | Val. Kappa Score: nan | Estimated time: 1419.05
Train loss on 50 batch: 0.608754
Train loss on 100 batch: 0.535869
Train loss on 150 batch: 0.650653
Train loss on 200 batch: 0.533706
Train loss on 250 batch: 0.626410
Train loss on 300 batch: 0.547567
Train loss on 350 batch: 0.496310
Train loss on 400 batch: 0.596836
Train loss on 450 batch: 0.574036
Train loss on 500 batch: 0.528304
Train loss on 550 batch: 0.512015
Train loss on 600 batch: 0.515515
Train loss on 650 batch: 0.523527
Train loss on 700 batch: 0.561918
Train loss on 750 batch: 0.540239
Train loss on 800 batch: 0.617044
Train loss on 850 batch: 0.539657
Train loss on 900 batch: 0.534487
Train loss on 950 batch: 0.603538
Train loss on 1000 batch: 0.546654
Train loss on 1050 batch: 0.572322
Train loss on 1100 batch: 0.548472
Train loss on 1150 batch: 0.605183
Train loss on 1200 batch: 0.567661
Train loss on 1250 batch: 0.536133
Train loss on 1300 batch: 0.618824
Train loss on 1350 batch: 0.556739
Train loss on 1400 batch: 0.565908
Train loss on 1450 batch: 0.515518
Train loss on 1500 batch: 0.609148
Train loss on 1550 batch: 0.526308
Train loss on 1600 batch: 0.541247
Train loss on 1650 batch: 0.542763
: Epoch: 8 | Training Loss: 0.558578 | Val. Loss: 0.540796 | Val. Kappa Score: nan | Estimated time: 1432.08
Train loss on 50 batch: 0.536673
Train loss on 100 batch: 0.497947
Train loss on 150 batch: 0.578107
Train loss on 200 batch: 0.540554
Train loss on 250 batch: 0.664356
Train loss on 300 batch: 0.572536
Train loss on 350 batch: 0.536205
Train loss on 400 batch: 0.578291
Train loss on 450 batch: 0.525380
Train loss on 500 batch: 0.598825
Train loss on 550 batch: 0.603089
Train loss on 600 batch: 0.554854
Train loss on 650 batch: 0.553927
Train loss on 700 batch: 0.689382
Train loss on 750 batch: 0.552852
Train loss on 800 batch: 0.608065
Train loss on 850 batch: 0.521692
Train loss on 900 batch: 0.504875
Train loss on 950 batch: 0.517730
Train loss on 1000 batch: 0.519750
Train loss on 1050 batch: 0.544890
Train loss on 1100 batch: 0.577256
Train loss on 1150 batch: 0.527006
Train loss on 1200 batch: 0.596260
Train loss on 1250 batch: 0.544814
Train loss on 1300 batch: 0.500740
Train loss on 1350 batch: 0.498183
Train loss on 1400 batch: 0.444811
Train loss on 1450 batch: 0.509825
Train loss on 1500 batch: 0.600344
Train loss on 1550 batch: 0.502435
Train loss on 1600 batch: 0.542499
Train loss on 1650 batch: 0.535267
: Epoch: 9 | Training Loss: 0.551362 | Val. Loss: 0.519691 | Val. Kappa Score: nan | Estimated time: 1418.32
Train loss on 50 batch: 0.531739
Train loss on 100 batch: 0.579335
Train loss on 150 batch: 0.500533
Train loss on 200 batch: 0.516537
Train loss on 250 batch: 0.514305
Train loss on 300 batch: 0.550269
Train loss on 350 batch: 0.558165
Train loss on 400 batch: 0.571882
Train loss on 450 batch: 0.541196
Train loss on 500 batch: 0.522769
Train loss on 550 batch: 0.617764
Train loss on 600 batch: 0.563969
Train loss on 650 batch: 0.496242
Train loss on 700 batch: 0.557588
Train loss on 750 batch: 0.498253
Train loss on 800 batch: 0.555779
Train loss on 850 batch: 0.479923
Train loss on 900 batch: 0.494744
Train loss on 950 batch: 0.607124
Train loss on 1000 batch: 0.540805
Train loss on 1050 batch: 0.489820
Train loss on 1100 batch: 0.524974
Train loss on 1150 batch: 0.612076
Train loss on 1200 batch: 0.524033
Train loss on 1250 batch: 0.525812
Train loss on 1300 batch: 0.485970
Train loss on 1350 batch: 0.538843
Train loss on 1400 batch: 0.599962
Train loss on 1450 batch: 0.511890
Train loss on 1500 batch: 0.536915
Train loss on 1550 batch: 0.487127
Train loss on 1600 batch: 0.539685
Train loss on 1650 batch: 0.436754
: Epoch: 10 | Training Loss: 0.533165 | Val. Loss: 0.534068 | Val. Kappa Score: nan | Estimated time: 1417.77
Train loss on 50 batch: 0.460433
Train loss on 100 batch: 0.523001
Train loss on 150 batch: 0.553420
Train loss on 200 batch: 0.481670
Train loss on 250 batch: 0.507531
Train loss on 300 batch: 0.439821
Train loss on 350 batch: 0.470058
Train loss on 400 batch: 0.517098
Train loss on 450 batch: 0.495911
Train loss on 500 batch: 0.445710
Train loss on 550 batch: 0.553981
Train loss on 600 batch: 0.550266
Train loss on 650 batch: 0.501668
Train loss on 700 batch: 0.575632
Train loss on 750 batch: 0.608109
Train loss on 800 batch: 0.528212
Train loss on 850 batch: 0.554158
Train loss on 900 batch: 0.506753
Train loss on 950 batch: 0.513159
Train loss on 1000 batch: 0.549334
Train loss on 1050 batch: 0.504332
Train loss on 1100 batch: 0.512072
Train loss on 1150 batch: 0.441535
Train loss on 1200 batch: 0.494398
Train loss on 1250 batch: 0.428308
Train loss on 1300 batch: 0.504723
Train loss on 1350 batch: 0.521153
Train loss on 1400 batch: 0.490198
Train loss on 1450 batch: 0.537765
Train loss on 1500 batch: 0.553214
Train loss on 1550 batch: 0.544891
Train loss on 1600 batch: 0.530534
Train loss on 1650 batch: 0.458685
best-train-loss: 0.509679
best-valid-loss: 0.495711
best-kappa: nan
: Epoch: 11 | Training Loss: 0.509679 | Val. Loss: 0.495711 | Val. Kappa Score: nan | Estimated time: 1417.31
Train loss on 50 batch: 0.434656
Train loss on 100 batch: 0.521558
Train loss on 150 batch: 0.463050
Train loss on 200 batch: 0.495553
Train loss on 250 batch: 0.513199
Train loss on 300 batch: 0.517456
Train loss on 350 batch: 0.493396
Train loss on 400 batch: 0.462927
Train loss on 450 batch: 0.476733
Train loss on 500 batch: 0.508430
Train loss on 550 batch: 0.446833
Train loss on 600 batch: 0.505804
Train loss on 650 batch: 0.488244
Train loss on 700 batch: 0.521908
Train loss on 750 batch: 0.518953
Train loss on 800 batch: 0.501553
Train loss on 850 batch: 0.484684
Train loss on 900 batch: 0.448550
Train loss on 950 batch: 0.572676
Train loss on 1000 batch: 0.509644
Train loss on 1050 batch: 0.511558
Train loss on 1100 batch: 0.490171
Train loss on 1150 batch: 0.502570
Train loss on 1200 batch: 0.494810
Train loss on 1250 batch: 0.571121
Train loss on 1300 batch: 0.502644
Train loss on 1350 batch: 0.501299
Train loss on 1400 batch: 0.537414
Train loss on 1450 batch: 0.514112
Train loss on 1500 batch: 0.533740
Train loss on 1550 batch: 0.489830
Train loss on 1600 batch: 0.517392
Train loss on 1650 batch: 0.492934
best-train-loss: 0.502139
best-valid-loss: 0.483919
best-kappa: nan
: Epoch: 12 | Training Loss: 0.502139 | Val. Loss: 0.483919 | Val. Kappa Score: nan | Estimated time: 1415.27
Train loss on 50 batch: 0.460439
Train loss on 100 batch: 0.516202
Train loss on 150 batch: 0.480815
Train loss on 200 batch: 0.572100
Train loss on 250 batch: 0.447524
Train loss on 300 batch: 0.514871
Train loss on 350 batch: 0.527364
Train loss on 400 batch: 0.464101
Train loss on 450 batch: 0.518402
Train loss on 500 batch: 0.412038
Train loss on 550 batch: 0.456886
Train loss on 600 batch: 0.427368
Train loss on 650 batch: 0.473757
Train loss on 700 batch: 0.472252
Train loss on 750 batch: 0.467969
Train loss on 800 batch: 0.555717
Train loss on 850 batch: 0.518504
Train loss on 900 batch: 0.521187
Train loss on 950 batch: 0.480077
Train loss on 1000 batch: 0.487788
Train loss on 1050 batch: 0.454309
Train loss on 1100 batch: 0.463415
Train loss on 1150 batch: 0.485534
Train loss on 1200 batch: 0.531150
Train loss on 1250 batch: 0.512568
Train loss on 1300 batch: 0.597888
Train loss on 1350 batch: 0.437995
Train loss on 1400 batch: 0.556408
Train loss on 1450 batch: 0.515040
Train loss on 1500 batch: 0.487787
Train loss on 1550 batch: 0.508522
Train loss on 1600 batch: 0.481908
Train loss on 1650 batch: 0.528686
: Epoch: 13 | Training Loss: 0.494159 | Val. Loss: 0.543826 | Val. Kappa Score: nan | Estimated time: 1417.92
Train loss on 50 batch: 0.452383
Train loss on 100 batch: 0.558782
Train loss on 150 batch: 0.542632
Train loss on 200 batch: 0.468304
Train loss on 250 batch: 0.436798
Train loss on 300 batch: 0.544956
Train loss on 350 batch: 0.469347
Train loss on 400 batch: 0.514071
Train loss on 450 batch: 0.406594
Train loss on 500 batch: 0.483644
Train loss on 550 batch: 0.448945
Train loss on 600 batch: 0.517924
Train loss on 650 batch: 0.544623
Train loss on 700 batch: 0.491448
Train loss on 750 batch: 0.464556
Train loss on 800 batch: 0.479257
Train loss on 850 batch: 0.532727
Train loss on 900 batch: 0.486298
Train loss on 950 batch: 0.546366
Train loss on 1000 batch: 0.463360
Train loss on 1050 batch: 0.463405
Train loss on 1100 batch: 0.483277
Train loss on 1150 batch: 0.505304
Train loss on 1200 batch: 0.438002
Train loss on 1250 batch: 0.446719
Train loss on 1300 batch: 0.458984
Train loss on 1350 batch: 0.558105
Train loss on 1400 batch: 0.476822
Train loss on 1450 batch: 0.488350
Train loss on 1500 batch: 0.484730
Train loss on 1550 batch: 0.463278
Train loss on 1600 batch: 0.448198
Train loss on 1650 batch: 0.461695
: Epoch: 14 | Training Loss: 0.488495 | Val. Loss: 0.847646 | Val. Kappa Score: nan | Estimated time: 1416.69
Train loss on 50 batch: 0.406762
Train loss on 100 batch: 0.488094
Train loss on 150 batch: 0.448574
Train loss on 200 batch: 0.444622
Train loss on 250 batch: 0.497002
Train loss on 300 batch: 0.500840
Train loss on 350 batch: 0.458275
Train loss on 400 batch: 0.578581
Train loss on 450 batch: 0.464327
Train loss on 500 batch: 0.486793
Train loss on 550 batch: 0.506700
Train loss on 600 batch: 0.460428
Train loss on 650 batch: 0.492510
Train loss on 700 batch: 0.459417
Train loss on 750 batch: 0.501181
Train loss on 800 batch: 0.455988
Train loss on 850 batch: 0.480018
Train loss on 900 batch: 0.427655
Train loss on 950 batch: 0.497412
Train loss on 1000 batch: 0.457736
Train loss on 1050 batch: 0.461899
Train loss on 1100 batch: 0.541671
Train loss on 1150 batch: 0.523687
Train loss on 1200 batch: 0.394333
Train loss on 1250 batch: 0.452812
Train loss on 1300 batch: 0.519659
Train loss on 1350 batch: 0.458004
Train loss on 1400 batch: 0.489953
Train loss on 1450 batch: 0.406458
Train loss on 1500 batch: 0.506455
Train loss on 1550 batch: 0.507535
Train loss on 1600 batch: 0.487105
Train loss on 1650 batch: 0.486477
best-train-loss: 0.479491
best-valid-loss: 0.473623
best-kappa: nan
: Epoch: 15 | Training Loss: 0.479491 | Val. Loss: 0.473623 | Val. Kappa Score: nan | Estimated time: 1417.93
Train loss on 50 batch: 0.434166
Train loss on 100 batch: 0.520448
Train loss on 150 batch: 0.487204
Train loss on 200 batch: 0.472526
Train loss on 250 batch: 0.486290
Train loss on 300 batch: 0.523014
Train loss on 350 batch: 0.478670
Train loss on 400 batch: 0.489875
Train loss on 450 batch: 0.439670
Train loss on 500 batch: 0.435701
Train loss on 550 batch: 0.500520
Train loss on 600 batch: 0.509793
Train loss on 650 batch: 0.450994
Train loss on 700 batch: 0.420727
Train loss on 750 batch: 0.502235
Train loss on 800 batch: 0.437171
Train loss on 850 batch: 0.407711
Train loss on 900 batch: 0.428091
Train loss on 950 batch: 0.431551
Train loss on 1000 batch: 0.464438
Train loss on 1050 batch: 0.452845
Train loss on 1100 batch: 0.521817
Train loss on 1150 batch: 0.549821
Train loss on 1200 batch: 0.505163
Train loss on 1250 batch: 0.513080
Train loss on 1300 batch: 0.495012
Train loss on 1350 batch: 0.461535
Train loss on 1400 batch: 0.482229
Train loss on 1450 batch: 0.464779
Train loss on 1500 batch: 0.387831
Train loss on 1550 batch: 0.523852
Train loss on 1600 batch: 0.448795
Train loss on 1650 batch: 0.495240
best-train-loss: 0.473644
best-valid-loss: 0.461441
best-kappa: nan
: Epoch: 16 | Training Loss: 0.473644 | Val. Loss: 0.461441 | Val. Kappa Score: nan | Estimated time: 1419.81
Train loss on 50 batch: 0.438205
Train loss on 100 batch: 0.463096
Train loss on 150 batch: 0.430401
Train loss on 200 batch: 0.446853
Train loss on 250 batch: 0.537504
Train loss on 300 batch: 0.479080
Train loss on 350 batch: 0.466647
Train loss on 400 batch: 0.485562
Train loss on 450 batch: 0.525736
Train loss on 500 batch: 0.442198
Train loss on 550 batch: 0.456525
Train loss on 600 batch: 0.428639
Train loss on 650 batch: 0.437222
Train loss on 700 batch: 0.454445
Train loss on 750 batch: 0.402683
Train loss on 800 batch: 0.450678
Train loss on 850 batch: 0.418930
Train loss on 900 batch: 0.488922
Train loss on 950 batch: 0.483644
Train loss on 1000 batch: 0.517760
Train loss on 1050 batch: 0.398902
Train loss on 1100 batch: 0.462544
Train loss on 1150 batch: 0.471880
Train loss on 1200 batch: 0.443195
Train loss on 1250 batch: 0.445161
Train loss on 1300 batch: 0.413781
Train loss on 1350 batch: 0.495807
Train loss on 1400 batch: 0.430387
Train loss on 1450 batch: 0.453996
Train loss on 1500 batch: 0.472556
Train loss on 1550 batch: 0.455634
Train loss on 1600 batch: 0.502362
Train loss on 1650 batch: 0.420768
best-train-loss: 0.459823
best-valid-loss: 0.452141
best-kappa: nan
: Epoch: 17 | Training Loss: 0.459823 | Val. Loss: 0.452141 | Val. Kappa Score: nan | Estimated time: 1418.66
Train loss on 50 batch: 0.449240
Train loss on 100 batch: 0.482706
Train loss on 150 batch: 0.432898
Train loss on 200 batch: 0.416332
Train loss on 250 batch: 0.460899
Train loss on 300 batch: 0.479483
Train loss on 350 batch: 0.453808
Train loss on 400 batch: 0.500560
Train loss on 450 batch: 0.523226
Train loss on 500 batch: 0.440185
Train loss on 550 batch: 0.464464
Train loss on 600 batch: 0.430694
Train loss on 650 batch: 0.471401
Train loss on 700 batch: 0.480668
Train loss on 750 batch: 0.446014
Train loss on 800 batch: 0.532630
Train loss on 850 batch: 0.427058
Train loss on 900 batch: 0.466127
Train loss on 950 batch: 0.442472
Train loss on 1000 batch: 0.418783
Train loss on 1050 batch: 0.487583
Train loss on 1100 batch: 0.433828
Train loss on 1150 batch: 0.561820
Train loss on 1200 batch: 0.519770
Train loss on 1250 batch: 0.412796
Train loss on 1300 batch: 0.561732
Train loss on 1350 batch: 0.429356
Train loss on 1400 batch: 0.395200
Train loss on 1450 batch: 0.428180
Train loss on 1500 batch: 0.450533
Train loss on 1550 batch: 0.427761
Train loss on 1600 batch: 0.478601
Train loss on 1650 batch: 0.474738
: Epoch: 18 | Training Loss: 0.462545 | Val. Loss: 0.459394 | Val. Kappa Score: nan | Estimated time: 1420.96
Train loss on 50 batch: 0.423867
Train loss on 100 batch: 0.356419
Train loss on 150 batch: 0.453054
Train loss on 200 batch: 0.460742
Train loss on 250 batch: 0.438000
Train loss on 300 batch: 0.377015
Train loss on 350 batch: 0.527975
Train loss on 400 batch: 0.481836
Train loss on 450 batch: 0.447442
Train loss on 500 batch: 0.447443
Train loss on 550 batch: 0.605529
Train loss on 600 batch: 0.470940
Train loss on 650 batch: 0.459315
Train loss on 700 batch: 0.454914
Train loss on 750 batch: 0.450855
Train loss on 800 batch: 0.435382
Train loss on 850 batch: 0.485649
Train loss on 900 batch: 0.546411
Train loss on 950 batch: 0.485863
Train loss on 1000 batch: 0.424100
Train loss on 1050 batch: 0.416621
Train loss on 1100 batch: 0.402705
Train loss on 1150 batch: 0.536710
Train loss on 1200 batch: 0.402850
Train loss on 1250 batch: 0.491309
Train loss on 1300 batch: 0.419989
Train loss on 1350 batch: 0.431698
Train loss on 1400 batch: 0.473577
Train loss on 1450 batch: 0.468466
Train loss on 1500 batch: 0.435036
Train loss on 1550 batch: 0.420126
Train loss on 1600 batch: 0.455835
Train loss on 1650 batch: 0.506708
: Epoch: 19 | Training Loss: 0.454936 | Val. Loss: 0.458340 | Val. Kappa Score: nan | Estimated time: 1427.25
Train loss on 50 batch: 0.432318
Train loss on 100 batch: 0.449234
Train loss on 150 batch: 0.430118
Train loss on 200 batch: 0.471481
Train loss on 250 batch: 0.369033
Train loss on 300 batch: 0.500023
Train loss on 350 batch: 0.450392
Train loss on 400 batch: 0.496801
Train loss on 450 batch: 0.388294
Train loss on 500 batch: 0.479934
Train loss on 550 batch: 0.423126
Train loss on 600 batch: 0.392693
Train loss on 650 batch: 0.462048
Train loss on 700 batch: 0.454209
Train loss on 750 batch: 0.501268
Train loss on 800 batch: 0.464952
Train loss on 850 batch: 0.429883
Train loss on 900 batch: 0.416530
Train loss on 950 batch: 0.436872
Train loss on 1000 batch: 0.443578
Train loss on 1050 batch: 0.409827
Train loss on 1100 batch: 0.434701
Train loss on 1150 batch: 0.457528
Train loss on 1200 batch: 0.456603
Train loss on 1250 batch: 0.361408
Train loss on 1300 batch: 0.453479
Train loss on 1350 batch: 0.410063
Train loss on 1400 batch: 0.517949
Train loss on 1450 batch: 0.427888
Train loss on 1500 batch: 0.497545
Train loss on 1550 batch: 0.439912
Train loss on 1600 batch: 0.436487
Train loss on 1650 batch: 0.482821
best-train-loss: 0.443240
best-valid-loss: 0.450287
best-kappa: nan
: Epoch: 20 | Training Loss: 0.443240 | Val. Loss: 0.450287 | Val. Kappa Score: nan | Estimated time: 1429.13
Train loss on 50 batch: 0.413422
Train loss on 100 batch: 0.426159
Train loss on 150 batch: 0.485111
Train loss on 200 batch: 0.464206
Train loss on 250 batch: 0.428798
Train loss on 300 batch: 0.424041
Train loss on 350 batch: 0.458932
Train loss on 400 batch: 0.446863
Train loss on 450 batch: 0.413223
Train loss on 500 batch: 0.424373
Train loss on 550 batch: 0.459910
Train loss on 600 batch: 0.476382
Train loss on 650 batch: 0.430931
Train loss on 700 batch: 0.483588
Train loss on 750 batch: 0.424236
Train loss on 800 batch: 0.419715
Train loss on 850 batch: 0.421948
Train loss on 900 batch: 0.393230
Train loss on 950 batch: 0.438904
Train loss on 1000 batch: 0.465212
Train loss on 1050 batch: 0.482042
Train loss on 1100 batch: 0.469262
Train loss on 1150 batch: 0.448277
Train loss on 1200 batch: 0.444362
Train loss on 1250 batch: 0.445698
Train loss on 1300 batch: 0.404808
Train loss on 1350 batch: 0.440261
Train loss on 1400 batch: 0.464907
Train loss on 1450 batch: 0.491443
Train loss on 1500 batch: 0.473028
Train loss on 1550 batch: 0.465224
Train loss on 1600 batch: 0.427488
Train loss on 1650 batch: 0.423156
: Epoch: 21 | Training Loss: 0.444721 | Val. Loss: 0.488664 | Val. Kappa Score: nan | Estimated time: 1418.90
Train loss on 50 batch: 0.485232
Train loss on 100 batch: 0.443614
Train loss on 150 batch: 0.465320
Train loss on 200 batch: 0.396572
Train loss on 250 batch: 0.431525
Train loss on 300 batch: 0.461074
Train loss on 350 batch: 0.379132
Train loss on 400 batch: 0.457331
Train loss on 450 batch: 0.442662
Train loss on 500 batch: 0.401151
Train loss on 550 batch: 0.439405
Train loss on 600 batch: 0.427570
Train loss on 650 batch: 0.452540
Train loss on 700 batch: 0.505897
Train loss on 750 batch: 0.379416
Train loss on 800 batch: 0.469361
Train loss on 850 batch: 0.424367
Train loss on 900 batch: 0.473923
Train loss on 950 batch: 0.418581
Train loss on 1000 batch: 0.351300
Train loss on 1050 batch: 0.475010
Train loss on 1100 batch: 0.490347
Train loss on 1150 batch: 0.483480
Train loss on 1200 batch: 0.499423
Train loss on 1250 batch: 0.423085
Train loss on 1300 batch: 0.480467
Train loss on 1350 batch: 0.478878
Train loss on 1400 batch: 0.403928
Train loss on 1450 batch: 0.453469
Train loss on 1500 batch: 0.466240
Train loss on 1550 batch: 0.478092
Train loss on 1600 batch: 0.481361
Train loss on 1650 batch: 0.468934
: Epoch: 22 | Training Loss: 0.446900 | Val. Loss: 0.456127 | Val. Kappa Score: nan | Estimated time: 1419.68
Train loss on 50 batch: 0.381241
Train loss on 100 batch: 0.360656
Train loss on 150 batch: 0.406203
Train loss on 200 batch: 0.394550
Train loss on 250 batch: 0.439943
Train loss on 300 batch: 0.467829
Train loss on 350 batch: 0.394895
Train loss on 400 batch: 0.414530
Train loss on 450 batch: 0.377388
Train loss on 500 batch: 0.462351
Train loss on 550 batch: 0.408064
Train loss on 600 batch: 0.404956
Train loss on 650 batch: 0.414695
Train loss on 700 batch: 0.394371
Train loss on 750 batch: 0.382542
Train loss on 800 batch: 0.438666
Train loss on 850 batch: 0.463147
Train loss on 900 batch: 0.396345
Train loss on 950 batch: 0.467983
Train loss on 1000 batch: 0.387815
Train loss on 1050 batch: 0.430918
Train loss on 1100 batch: 0.485099
Train loss on 1150 batch: 0.482892
Train loss on 1200 batch: 0.421923
Train loss on 1250 batch: 0.494367
Train loss on 1300 batch: 0.424738
Train loss on 1350 batch: 0.461382
Train loss on 1400 batch: 0.475168
Train loss on 1450 batch: 0.469482
Train loss on 1500 batch: 0.535897
Train loss on 1550 batch: 0.439386
Train loss on 1600 batch: 0.379523
Train loss on 1650 batch: 0.457532
best-train-loss: 0.430589
best-valid-loss: 0.433836
best-kappa: nan
: Epoch: 23 | Training Loss: 0.430589 | Val. Loss: 0.433836 | Val. Kappa Score: nan | Estimated time: 1436.59
Train loss on 50 batch: 0.507637
Train loss on 100 batch: 0.432688
Train loss on 150 batch: 0.374357
Train loss on 200 batch: 0.399532
Train loss on 250 batch: 0.456307
Train loss on 300 batch: 0.480970
Train loss on 350 batch: 0.409426
Train loss on 400 batch: 0.441842
Train loss on 450 batch: 0.443417
Train loss on 500 batch: 0.395983
Train loss on 550 batch: 0.408186
Train loss on 600 batch: 0.446702
Train loss on 650 batch: 0.409699
Train loss on 700 batch: 0.403261
Train loss on 750 batch: 0.386965
Train loss on 800 batch: 0.422251
Train loss on 850 batch: 0.445402
Train loss on 900 batch: 0.412490
Train loss on 950 batch: 0.398401
Train loss on 1000 batch: 0.416035
Train loss on 1050 batch: 0.406181
Train loss on 1100 batch: 0.379245
Train loss on 1150 batch: 0.464793
Train loss on 1200 batch: 0.429174
Train loss on 1250 batch: 0.405948
Train loss on 1300 batch: 0.451398
Train loss on 1350 batch: 0.413879
Train loss on 1400 batch: 0.439174
Train loss on 1450 batch: 0.465039
Train loss on 1500 batch: 0.453788
Train loss on 1550 batch: 0.479597
Train loss on 1600 batch: 0.460655
Train loss on 1650 batch: 0.481217
best-train-loss: 0.430944
best-valid-loss: 0.428189
best-kappa: nan
: Epoch: 24 | Training Loss: 0.430944 | Val. Loss: 0.428189 | Val. Kappa Score: nan | Estimated time: 1414.84
Train loss on 50 batch: 0.433390
Train loss on 100 batch: 0.429519
Train loss on 150 batch: 0.494929
Train loss on 200 batch: 0.501392
Train loss on 250 batch: 0.433824
Train loss on 300 batch: 0.355500
Train loss on 350 batch: 0.430371
Train loss on 400 batch: 0.449007
Train loss on 450 batch: 0.455132
Train loss on 500 batch: 0.360765
Train loss on 550 batch: 0.412978
Train loss on 600 batch: 0.433519
Train loss on 650 batch: 0.421164
Train loss on 700 batch: 0.438981
Train loss on 750 batch: 0.500161
Train loss on 800 batch: 0.384523
Train loss on 850 batch: 0.446763
Train loss on 900 batch: 0.419489
Train loss on 950 batch: 0.403680
Train loss on 1000 batch: 0.402812
Train loss on 1050 batch: 0.417203
Train loss on 1100 batch: 0.408337
Train loss on 1150 batch: 0.418889
Train loss on 1200 batch: 0.471631
Train loss on 1250 batch: 0.413070
Train loss on 1300 batch: 0.415795
Train loss on 1350 batch: 0.462600
Train loss on 1400 batch: 0.439607
Train loss on 1450 batch: 0.405276
Train loss on 1500 batch: 0.468961
Train loss on 1550 batch: 0.405935
Train loss on 1600 batch: 0.411649
Train loss on 1650 batch: 0.401571
: Epoch: 25 | Training Loss: 0.428641 | Val. Loss: 0.480511 | Val. Kappa Score: nan | Estimated time: 1421.83
time_estimated: 35557.61
----------------------------------------


Experiment N: 45: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.10 04:36:38
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 5
parameters-amount: 28346929
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.329098
Train loss on 100 batch: 1.127712
Train loss on 150 batch: 0.995014
Train loss on 200 batch: 1.005502
Train loss on 250 batch: 0.883335
Train loss on 300 batch: 0.851711
Train loss on 350 batch: 0.822922
Train loss on 400 batch: 0.903930
Train loss on 450 batch: 0.844875
Train loss on 500 batch: 0.792751
Train loss on 550 batch: 0.841797
Train loss on 600 batch: 0.757193
Train loss on 650 batch: 0.793636
Train loss on 700 batch: 0.852516
Train loss on 750 batch: 0.826033
Train loss on 800 batch: 0.802445
Train loss on 850 batch: 0.734974
Train loss on 900 batch: 0.807100
Train loss on 950 batch: 0.828757
Train loss on 1000 batch: 0.697329
Train loss on 1050 batch: 0.807207
Train loss on 1100 batch: 0.774521
Train loss on 1150 batch: 0.765132
Train loss on 1200 batch: 0.768089
Train loss on 1250 batch: 0.701324
Train loss on 1300 batch: 0.845854
Train loss on 1350 batch: 0.798552
Train loss on 1400 batch: 0.742146
Train loss on 1450 batch: 0.766799
Train loss on 1500 batch: 0.737365
Train loss on 1550 batch: 0.835061
Train loss on 1600 batch: 0.740741
Train loss on 1650 batch: 0.698892
best-train-loss: 0.830214
best-valid-loss: 5.224530
best-kappa: 0.4221
: Epoch: 1 | Training Loss: 0.830214 | Val. Loss: 5.224530 | Val. Kappa Score: 0.4221 | Estimated time: 1419.53
Train loss on 50 batch: 0.758071
Train loss on 100 batch: 0.730050
Train loss on 150 batch: 0.709600
Train loss on 200 batch: 0.794097
Train loss on 250 batch: 0.749088
Train loss on 300 batch: 0.630162
Train loss on 350 batch: 0.730537
Train loss on 400 batch: 0.665634
Train loss on 450 batch: 0.798690
Train loss on 500 batch: 0.720590
Train loss on 550 batch: 0.659631
Train loss on 600 batch: 0.682018
Train loss on 650 batch: 0.638472
Train loss on 700 batch: 0.789883
Train loss on 750 batch: 0.780153
Train loss on 800 batch: 0.719816
Train loss on 850 batch: 0.747171
Train loss on 900 batch: 0.846750
Train loss on 950 batch: 0.862409
Train loss on 1000 batch: 0.776884
Train loss on 1050 batch: 0.721659
Train loss on 1100 batch: 0.625957
Train loss on 1150 batch: 0.760756
Train loss on 1200 batch: 0.744927
Train loss on 1250 batch: 0.710307
Train loss on 1300 batch: 0.847967
Train loss on 1350 batch: 0.760723
Train loss on 1400 batch: 0.686268
Train loss on 1450 batch: 0.774650
Train loss on 1500 batch: 0.676284
Train loss on 1550 batch: 0.808446
Train loss on 1600 batch: 0.763936
Train loss on 1650 batch: 0.808264
best-train-loss: 0.743100
best-valid-loss: 0.717535
best-kappa: 0.4386
: Epoch: 2 | Training Loss: 0.743100 | Val. Loss: 0.717535 | Val. Kappa Score: 0.4386 | Estimated time: 1415.23
Train loss on 50 batch: 0.793922
Train loss on 100 batch: 0.738141
Train loss on 150 batch: 0.714097
Train loss on 200 batch: 0.680482
Train loss on 250 batch: 0.625435
Train loss on 300 batch: 0.745573
Train loss on 350 batch: 0.705999
Train loss on 400 batch: 0.712482
Train loss on 450 batch: 0.753436
Train loss on 500 batch: 0.668387
Train loss on 550 batch: 0.794791
Train loss on 600 batch: 0.832505
Train loss on 650 batch: 0.696939
Train loss on 700 batch: 0.700260
Train loss on 750 batch: 0.734979
Train loss on 800 batch: 0.713007
Train loss on 850 batch: 0.710352
Train loss on 900 batch: 0.724313
Train loss on 950 batch: 0.739147
Train loss on 1000 batch: 0.722176
Train loss on 1050 batch: 0.710307
Train loss on 1100 batch: 0.691172
Train loss on 1150 batch: 0.692143
Train loss on 1200 batch: 0.693682
Train loss on 1250 batch: 0.652790
Train loss on 1300 batch: 0.752172
Train loss on 1350 batch: 0.688847
Train loss on 1400 batch: 0.704549
Train loss on 1450 batch: 0.658968
Train loss on 1500 batch: 0.649206
Train loss on 1550 batch: 0.730314
Train loss on 1600 batch: 0.661543
Train loss on 1650 batch: 0.690027
best-train-loss: 0.713434
best-valid-loss: 0.562319
best-kappa: 0.4741
: Epoch: 3 | Training Loss: 0.713434 | Val. Loss: 0.562319 | Val. Kappa Score: 0.4741 | Estimated time: 1415.11
Train loss on 50 batch: 0.732153
Train loss on 100 batch: 0.686958
Train loss on 150 batch: 0.680426
Train loss on 200 batch: 0.661569
Train loss on 250 batch: 0.666880
Train loss on 300 batch: 0.702163
Train loss on 350 batch: 0.667573
Train loss on 400 batch: 0.706841
Train loss on 450 batch: 0.696408
Train loss on 500 batch: 0.746941
Train loss on 550 batch: 0.640946
Train loss on 600 batch: 0.633646
Train loss on 650 batch: 0.654988
Train loss on 700 batch: 0.650678
Train loss on 750 batch: 0.649090
Train loss on 800 batch: 0.691827
Train loss on 850 batch: 0.670686
Train loss on 900 batch: 0.623523
Train loss on 950 batch: 0.680516
Train loss on 1000 batch: 0.705453
Train loss on 1050 batch: 0.676724
Train loss on 1100 batch: 0.704905
Train loss on 1150 batch: 0.661062
Train loss on 1200 batch: 0.641583
Train loss on 1250 batch: 0.686777
Train loss on 1300 batch: 0.634606
Train loss on 1350 batch: 0.715190
Train loss on 1400 batch: 0.588571
Train loss on 1450 batch: 0.673344
Train loss on 1500 batch: 0.667627
Train loss on 1550 batch: 0.579488
Train loss on 1600 batch: 0.567726
Train loss on 1650 batch: 0.652052
: Epoch: 4 | Training Loss: 0.669831 | Val. Loss: 0.656604 | Val. Kappa Score: 0.4640 | Estimated time: 1414.25
Train loss on 50 batch: 0.656477
Train loss on 100 batch: 0.588809
Train loss on 150 batch: 0.561666
Train loss on 200 batch: 0.627329
Train loss on 250 batch: 0.592942
Train loss on 300 batch: 0.624607
Train loss on 350 batch: 0.656174
Train loss on 400 batch: 0.633037
Train loss on 450 batch: 0.655261
Train loss on 500 batch: 0.631397
Train loss on 550 batch: 0.643774
Train loss on 600 batch: 0.545955
Train loss on 650 batch: 0.554943
Train loss on 700 batch: 0.587068
Train loss on 750 batch: 0.591381
Train loss on 800 batch: 0.600950
Train loss on 850 batch: 0.667754
Train loss on 900 batch: 0.619092
Train loss on 950 batch: 0.691451
Train loss on 1000 batch: 0.675097
Train loss on 1050 batch: 0.654927
Train loss on 1100 batch: 0.683315
Train loss on 1150 batch: 0.551956
Train loss on 1200 batch: 0.656243
Train loss on 1250 batch: 0.625618
Train loss on 1300 batch: 0.615689
Train loss on 1350 batch: 0.476883
Train loss on 1400 batch: 0.670078
Train loss on 1450 batch: 0.581569
Train loss on 1500 batch: 0.594108
Train loss on 1550 batch: 0.668621
Train loss on 1600 batch: 0.639195
Train loss on 1650 batch: 0.656559
best-train-loss: 0.619676
best-valid-loss: 0.529984
best-kappa: 0.4926
: Epoch: 5 | Training Loss: 0.619676 | Val. Loss: 0.529984 | Val. Kappa Score: 0.4926 | Estimated time: 1413.58
Train loss on 50 batch: 0.656510
Train loss on 100 batch: 0.507184
Train loss on 150 batch: 0.638559
Train loss on 200 batch: 0.577649
Train loss on 250 batch: 0.509722
Train loss on 300 batch: 0.587116
Train loss on 350 batch: 0.606640
Train loss on 400 batch: 0.578677
Train loss on 450 batch: 0.651934
Train loss on 500 batch: 0.621101
Train loss on 550 batch: 0.635644
Train loss on 600 batch: 0.566645
Train loss on 650 batch: 0.542685
Train loss on 700 batch: 0.664369
Train loss on 750 batch: 0.569365
Train loss on 800 batch: 0.628768
Train loss on 850 batch: 0.585459
Train loss on 900 batch: 0.574386
Train loss on 950 batch: 0.565592
Train loss on 1000 batch: 0.481921
Train loss on 1050 batch: 0.558969
Train loss on 1100 batch: 0.656533
Train loss on 1150 batch: 0.644797
Train loss on 1200 batch: 0.617683
Train loss on 1250 batch: 0.636505
Train loss on 1300 batch: 0.623527
Train loss on 1350 batch: 0.553598
Train loss on 1400 batch: 0.692513
Train loss on 1450 batch: 0.652853
Train loss on 1500 batch: 0.640874
Train loss on 1550 batch: 0.565238
Train loss on 1600 batch: 0.586516
Train loss on 1650 batch: 0.533046
: Epoch: 6 | Training Loss: 0.597812 | Val. Loss: 0.711814 | Val. Kappa Score: nan | Estimated time: 1415.41
Train loss on 50 batch: 0.603903
Train loss on 100 batch: 0.618205
Train loss on 150 batch: 0.613634
Train loss on 200 batch: 0.538679
Train loss on 250 batch: 0.563206
Train loss on 300 batch: 0.567975
Train loss on 350 batch: 0.547767
Train loss on 400 batch: 0.617265
Train loss on 450 batch: 0.524006
Train loss on 500 batch: 0.539759
Train loss on 550 batch: 0.577231
Train loss on 600 batch: 0.601620
Train loss on 650 batch: 0.655924
Train loss on 700 batch: 0.512910
Train loss on 750 batch: 0.519658
Train loss on 800 batch: 0.536394
Train loss on 850 batch: 0.525429
Train loss on 900 batch: 0.593070
Train loss on 950 batch: 0.524507
Train loss on 1000 batch: 0.472970
Train loss on 1050 batch: 0.555033
Train loss on 1100 batch: 0.612419
Train loss on 1150 batch: 0.611275
Train loss on 1200 batch: 0.612910
Train loss on 1250 batch: 0.618864
Train loss on 1300 batch: 0.612578
Train loss on 1350 batch: 0.583699
Train loss on 1400 batch: 0.681728
Train loss on 1450 batch: 0.528244
Train loss on 1500 batch: 0.602998
Train loss on 1550 batch: 0.470120
Train loss on 1600 batch: 0.510844
Train loss on 1650 batch: 0.601591
best-train-loss: 0.570493
best-valid-loss: 0.490561
best-kappa: nan
: Epoch: 7 | Training Loss: 0.570493 | Val. Loss: 0.490561 | Val. Kappa Score: nan | Estimated time: 1416.66
Train loss on 50 batch: 0.579210
Train loss on 100 batch: 0.530685
Train loss on 150 batch: 0.596619
Train loss on 200 batch: 0.481128
Train loss on 250 batch: 0.598464
Train loss on 300 batch: 0.605073
Train loss on 350 batch: 0.510524
Train loss on 400 batch: 0.575839
Train loss on 450 batch: 0.556152
Train loss on 500 batch: 0.526550
Train loss on 550 batch: 0.510671
Train loss on 600 batch: 0.548308
Train loss on 650 batch: 0.552925
Train loss on 700 batch: 0.505110
Train loss on 750 batch: 0.576508
Train loss on 800 batch: 0.608193
Train loss on 850 batch: 0.509557
Train loss on 900 batch: 0.552174
Train loss on 950 batch: 0.562782
Train loss on 1000 batch: 0.522306
Train loss on 1050 batch: 0.566002
Train loss on 1100 batch: 0.585123
Train loss on 1150 batch: 0.596055
Train loss on 1200 batch: 0.616027
Train loss on 1250 batch: 0.532220
Train loss on 1300 batch: 0.606340
Train loss on 1350 batch: 0.571091
Train loss on 1400 batch: 0.566864
Train loss on 1450 batch: 0.483615
Train loss on 1500 batch: 0.577053
Train loss on 1550 batch: 0.550456
Train loss on 1600 batch: 0.515005
Train loss on 1650 batch: 0.520872
: Epoch: 8 | Training Loss: 0.552855 | Val. Loss: 0.568209 | Val. Kappa Score: nan | Estimated time: 1413.58
Train loss on 50 batch: 0.483358
Train loss on 100 batch: 0.538735
Train loss on 150 batch: 0.565544
Train loss on 200 batch: 0.512153
Train loss on 250 batch: 0.584109
Train loss on 300 batch: 0.529985
Train loss on 350 batch: 0.484722
Train loss on 400 batch: 0.551053
Train loss on 450 batch: 0.506280
Train loss on 500 batch: 0.573400
Train loss on 550 batch: 0.607867
Train loss on 600 batch: 0.532518
Train loss on 650 batch: 0.530304
Train loss on 700 batch: 0.694038
Train loss on 750 batch: 0.537140
Train loss on 800 batch: 0.578072
Train loss on 850 batch: 0.521403
Train loss on 900 batch: 0.469420
Train loss on 950 batch: 0.501221
Train loss on 1000 batch: 0.533380
Train loss on 1050 batch: 0.592920
Train loss on 1100 batch: 0.582795
Train loss on 1150 batch: 0.487481
Train loss on 1200 batch: 0.588573
Train loss on 1250 batch: 0.561117
Train loss on 1300 batch: 0.497425
Train loss on 1350 batch: 0.478349
Train loss on 1400 batch: 0.426093
Train loss on 1450 batch: 0.509105
Train loss on 1500 batch: 0.594271
Train loss on 1550 batch: 0.514787
Train loss on 1600 batch: 0.563123
Train loss on 1650 batch: 0.534844
best-train-loss: 0.537763
best-valid-loss: 0.474907
best-kappa: nan
: Epoch: 9 | Training Loss: 0.537763 | Val. Loss: 0.474907 | Val. Kappa Score: nan | Estimated time: 1416.67
Train loss on 50 batch: 0.475267
Train loss on 100 batch: 0.577373
Train loss on 150 batch: 0.511643
Train loss on 200 batch: 0.529556
Train loss on 250 batch: 0.503212
Train loss on 300 batch: 0.524870
Train loss on 350 batch: 0.501876
Train loss on 400 batch: 0.547597
Train loss on 450 batch: 0.529564
Train loss on 500 batch: 0.495729
Train loss on 550 batch: 0.576930
Train loss on 600 batch: 0.568911
Train loss on 650 batch: 0.477858
Train loss on 700 batch: 0.540072
Train loss on 750 batch: 0.489536
Train loss on 800 batch: 0.549200
Train loss on 850 batch: 0.467727
Train loss on 900 batch: 0.481127
Train loss on 950 batch: 0.604444
Train loss on 1000 batch: 0.514737
Train loss on 1050 batch: 0.462962
Train loss on 1100 batch: 0.509268
Train loss on 1150 batch: 0.560768
Train loss on 1200 batch: 0.484034
Train loss on 1250 batch: 0.537100
Train loss on 1300 batch: 0.485733
Train loss on 1350 batch: 0.500151
Train loss on 1400 batch: 0.545631
Train loss on 1450 batch: 0.519772
Train loss on 1500 batch: 0.529105
Train loss on 1550 batch: 0.492587
Train loss on 1600 batch: 0.532638
Train loss on 1650 batch: 0.445464
best-train-loss: 0.516158
best-valid-loss: 0.449281
best-kappa: nan
: Epoch: 10 | Training Loss: 0.516158 | Val. Loss: 0.449281 | Val. Kappa Score: nan | Estimated time: 1415.80
Train loss on 50 batch: 0.474065
Train loss on 100 batch: 0.493276
Train loss on 150 batch: 0.498487
Train loss on 200 batch: 0.462712
Train loss on 250 batch: 0.508836
Train loss on 300 batch: 0.428381
Train loss on 350 batch: 0.448890
Train loss on 400 batch: 0.505807
Train loss on 450 batch: 0.494006
Train loss on 500 batch: 0.463206
Train loss on 550 batch: 0.545779
Train loss on 600 batch: 0.505696
Train loss on 650 batch: 0.490798
Train loss on 700 batch: 0.553737
Train loss on 750 batch: 0.603680
Train loss on 800 batch: 0.515837
Train loss on 850 batch: 0.559704
Train loss on 900 batch: 0.503440
Train loss on 950 batch: 0.498605
Train loss on 1000 batch: 0.567235
Train loss on 1050 batch: 0.521133
Train loss on 1100 batch: 0.496152
Train loss on 1150 batch: 0.440541
Train loss on 1200 batch: 0.480156
Train loss on 1250 batch: 0.414967
Train loss on 1300 batch: 0.518144
Train loss on 1350 batch: 0.523316
Train loss on 1400 batch: 0.436524
Train loss on 1450 batch: 0.514597
Train loss on 1500 batch: 0.545415
Train loss on 1550 batch: 0.474806
Train loss on 1600 batch: 0.484502
Train loss on 1650 batch: 0.474003
: Epoch: 11 | Training Loss: 0.497887 | Val. Loss: 0.453261 | Val. Kappa Score: nan | Estimated time: 1414.50
Train loss on 50 batch: 0.439555
Train loss on 100 batch: 0.504958
Train loss on 150 batch: 0.443312
Train loss on 200 batch: 0.478536
Train loss on 250 batch: 0.500928
Train loss on 300 batch: 0.515036
Train loss on 350 batch: 0.502196
Train loss on 400 batch: 0.446230
Train loss on 450 batch: 0.429570
Train loss on 500 batch: 0.466507
Train loss on 550 batch: 0.461840
Train loss on 600 batch: 0.474046
Train loss on 650 batch: 0.474656
Train loss on 700 batch: 0.522275
Train loss on 750 batch: 0.495250
Train loss on 800 batch: 0.503070
Train loss on 850 batch: 0.467057
Train loss on 900 batch: 0.441545
Train loss on 950 batch: 0.533280
Train loss on 1000 batch: 0.504905
Train loss on 1050 batch: 0.487301
Train loss on 1100 batch: 0.464634
Train loss on 1150 batch: 0.499856
Train loss on 1200 batch: 0.489248
Train loss on 1250 batch: 0.535370
Train loss on 1300 batch: 0.492344
Train loss on 1350 batch: 0.475681
Train loss on 1400 batch: 0.545381
Train loss on 1450 batch: 0.513780
Train loss on 1500 batch: 0.481255
Train loss on 1550 batch: 0.452484
Train loss on 1600 batch: 0.478327
Train loss on 1650 batch: 0.462820
: Epoch: 12 | Training Loss: 0.484506 | Val. Loss: 0.674924 | Val. Kappa Score: nan | Estimated time: 1414.17
Train loss on 50 batch: 0.458419
Train loss on 100 batch: 0.502951
Train loss on 150 batch: 0.478733
Train loss on 200 batch: 0.557822
Train loss on 250 batch: 0.449597
Train loss on 300 batch: 0.493046
Train loss on 350 batch: 0.548967
Train loss on 400 batch: 0.453254
Train loss on 450 batch: 0.463083
Train loss on 500 batch: 0.417635
Train loss on 550 batch: 0.462520
Train loss on 600 batch: 0.422208
Train loss on 650 batch: 0.444604
Train loss on 700 batch: 0.460592
Train loss on 750 batch: 0.440738
Train loss on 800 batch: 0.515281
Train loss on 850 batch: 0.463126
Train loss on 900 batch: 0.542400
Train loss on 950 batch: 0.478747
Train loss on 1000 batch: 0.484514
Train loss on 1050 batch: 0.451286
Train loss on 1100 batch: 0.419354
Train loss on 1150 batch: 0.474722
Train loss on 1200 batch: 0.543135
Train loss on 1250 batch: 0.523642
Train loss on 1300 batch: 0.557638
Train loss on 1350 batch: 0.425446
Train loss on 1400 batch: 0.557891
Train loss on 1450 batch: 0.507589
Train loss on 1500 batch: 0.476975
Train loss on 1550 batch: 0.478015
Train loss on 1600 batch: 0.453288
Train loss on 1650 batch: 0.495847
: Epoch: 13 | Training Loss: 0.481210 | Val. Loss: 0.496764 | Val. Kappa Score: nan | Estimated time: 1415.06
Train loss on 50 batch: 0.440142
Train loss on 100 batch: 0.514054
Train loss on 150 batch: 0.544817
Train loss on 200 batch: 0.440986
Train loss on 250 batch: 0.424374
Train loss on 300 batch: 0.565875
Train loss on 350 batch: 0.460632
Train loss on 400 batch: 0.509125
Train loss on 450 batch: 0.388609
Train loss on 500 batch: 0.475158
Train loss on 550 batch: 0.427602
Train loss on 600 batch: 0.523891
Train loss on 650 batch: 0.500415
Train loss on 700 batch: 0.492144
Train loss on 750 batch: 0.475053
Train loss on 800 batch: 0.478038
Train loss on 850 batch: 0.492316
Train loss on 900 batch: 0.464861
Train loss on 950 batch: 0.525931
Train loss on 1000 batch: 0.469461
Train loss on 1050 batch: 0.457823
Train loss on 1100 batch: 0.494458
Train loss on 1150 batch: 0.483110
Train loss on 1200 batch: 0.451494
Train loss on 1250 batch: 0.439141
Train loss on 1300 batch: 0.441772
Train loss on 1350 batch: 0.513882
Train loss on 1400 batch: 0.451581
Train loss on 1450 batch: 0.509179
Train loss on 1500 batch: 0.477869
Train loss on 1550 batch: 0.470625
Train loss on 1600 batch: 0.427655
Train loss on 1650 batch: 0.484166
: Epoch: 14 | Training Loss: 0.476958 | Val. Loss: 0.541919 | Val. Kappa Score: nan | Estimated time: 1416.28
Train loss on 50 batch: 0.370968
Train loss on 100 batch: 0.451031
Train loss on 150 batch: 0.414049
Train loss on 200 batch: 0.417092
Train loss on 250 batch: 0.464858
Train loss on 300 batch: 0.442069
Train loss on 350 batch: 0.422997
Train loss on 400 batch: 0.520361
Train loss on 450 batch: 0.464318
Train loss on 500 batch: 0.478924
Train loss on 550 batch: 0.508977
Train loss on 600 batch: 0.473165
Train loss on 650 batch: 0.481181
Train loss on 700 batch: 0.442963
Train loss on 750 batch: 0.482859
Train loss on 800 batch: 0.462755
Train loss on 850 batch: 0.434137
Train loss on 900 batch: 0.414045
Train loss on 950 batch: 0.466500
Train loss on 1000 batch: 0.437236
Train loss on 1050 batch: 0.446684
Train loss on 1100 batch: 0.507264
Train loss on 1150 batch: 0.471133
Train loss on 1200 batch: 0.423999
Train loss on 1250 batch: 0.419376
Train loss on 1300 batch: 0.482976
Train loss on 1350 batch: 0.448721
Train loss on 1400 batch: 0.491109
Train loss on 1450 batch: 0.438882
Train loss on 1500 batch: 0.496145
Train loss on 1550 batch: 0.475676
Train loss on 1600 batch: 0.461764
Train loss on 1650 batch: 0.455690
: Epoch: 15 | Training Loss: 0.459132 | Val. Loss: 0.500965 | Val. Kappa Score: nan | Estimated time: 1414.89
time_estimated: 21231.45
n-epochs: 15
time_estimated: 21231.47
----------------------------------------

Experiment N: 46: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.10 12:28:42
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
early-stopping-patience: 5
parameters-amount: 28346929
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.208775
Train loss on 100 batch: 0.976244
Train loss on 150 batch: 0.875205
Train loss on 200 batch: 0.885676
Train loss on 250 batch: 0.860672
Train loss on 300 batch: 0.809950
Train loss on 350 batch: 0.815256
Train loss on 400 batch: 0.938785
Train loss on 450 batch: 0.927184
Train loss on 500 batch: 0.843293
Train loss on 550 batch: 0.840706
Train loss on 600 batch: 0.736688
Train loss on 650 batch: 0.779249
Train loss on 700 batch: 0.855445
Train loss on 750 batch: 0.868591
Train loss on 800 batch: 0.884104
Train loss on 850 batch: 0.744144
Train loss on 900 batch: 0.875097
Train loss on 950 batch: 0.865262
Train loss on 1000 batch: 0.722707
Train loss on 1050 batch: 0.951106
Train loss on 1100 batch: 0.892112
Train loss on 1150 batch: 0.987458
Train loss on 1200 batch: 0.907720
Train loss on 1250 batch: 0.823383
Train loss on 1300 batch: 0.931427
Train loss on 1350 batch: 0.865570
Train loss on 1400 batch: 0.847512
Train loss on 1450 batch: 0.862569
Train loss on 1500 batch: 0.751543
Train loss on 1550 batch: 0.766563
Train loss on 1600 batch: 0.737667
Train loss on 1650 batch: 0.715864
best-train-loss: 0.856866
best-valid-loss: 0.839957
best-kappa: 0.4322
: Epoch: 1 | Training Loss: 0.856866 | Val. Loss: 0.839957 | Val. Kappa Score: 0.4322 | Estimated time: 1423.96
Train loss on 50 batch: 0.801716
Train loss on 100 batch: 0.724467
Train loss on 150 batch: 0.687671
Train loss on 200 batch: 0.783155
Train loss on 250 batch: 0.747439
Train loss on 300 batch: 0.621189
Train loss on 350 batch: 0.798394
Train loss on 400 batch: 0.689391
Train loss on 450 batch: 0.767748
Train loss on 500 batch: 0.809767
Train loss on 550 batch: 0.744041
Train loss on 600 batch: 0.755333
Train loss on 650 batch: 0.690571
Train loss on 700 batch: 0.814194
Train loss on 750 batch: 0.841726
Train loss on 800 batch: 0.734028
Train loss on 850 batch: 0.742311
Train loss on 900 batch: 0.775218
Train loss on 950 batch: 0.896477
Train loss on 1000 batch: 0.795316
Train loss on 1050 batch: 0.721960
Train loss on 1100 batch: 0.626139
Train loss on 1150 batch: 0.760258
Train loss on 1200 batch: 0.742868
Train loss on 1250 batch: 0.734380
Train loss on 1300 batch: 0.747680
Train loss on 1350 batch: 0.686724
Train loss on 1400 batch: 0.662785
Train loss on 1450 batch: 0.679672
Train loss on 1500 batch: 0.646106
Train loss on 1550 batch: 0.833937
Train loss on 1600 batch: 0.739667
Train loss on 1650 batch: 0.731400
: Epoch: 2 | Training Loss: 0.743600 | Val. Loss: 1.367510 | Val. Kappa Score: 0.4494 | Estimated time: 1469.88
Train loss on 50 batch: 0.795887
Train loss on 100 batch: 0.672446
Train loss on 150 batch: 0.728364
Train loss on 200 batch: 0.695511
Train loss on 250 batch: 0.557571
Train loss on 300 batch: 0.744661
Train loss on 350 batch: 0.647470
Train loss on 400 batch: 0.709114
Train loss on 450 batch: 0.658798
Train loss on 500 batch: 0.653630
Train loss on 550 batch: 0.704172
Train loss on 600 batch: 0.738604
Train loss on 650 batch: 0.574044
Train loss on 700 batch: 0.663779
Train loss on 750 batch: 0.709286
Train loss on 800 batch: 0.715715
Train loss on 850 batch: 0.713958
Train loss on 900 batch: 0.711374
Train loss on 950 batch: 0.776224
Train loss on 1000 batch: 0.711858
Train loss on 1050 batch: 0.690251
Train loss on 1100 batch: 0.665975
Train loss on 1150 batch: 0.668427
Train loss on 1200 batch: 0.729826
Train loss on 1250 batch: 0.713186
Train loss on 1300 batch: 0.736687
Train loss on 1350 batch: 0.716351
Train loss on 1400 batch: 0.713652
Train loss on 1450 batch: 0.659360
Train loss on 1500 batch: 0.703927
Train loss on 1550 batch: 0.756919
Train loss on 1600 batch: 0.665479
Train loss on 1650 batch: 0.693171
: Epoch: 3 | Training Loss: 0.699490 | Val. Loss: 8.975485 | Val. Kappa Score: 0.3323 | Estimated time: 1455.36
Train loss on 50 batch: 0.743513
Train loss on 100 batch: 0.720455
Train loss on 150 batch: 0.703201
Train loss on 200 batch: 0.674474
Train loss on 250 batch: 0.638748
Train loss on 300 batch: 0.694733
Train loss on 350 batch: 0.643864
Train loss on 400 batch: 0.688233
Train loss on 450 batch: 0.681187
Train loss on 500 batch: 0.720363
Train loss on 550 batch: 0.695915
Train loss on 600 batch: 0.703065
Train loss on 650 batch: 0.667621
Train loss on 700 batch: 0.644065
Train loss on 750 batch: 0.636514
Train loss on 800 batch: 0.703939
Train loss on 850 batch: 0.662788
Train loss on 900 batch: 0.616672
----------------------------------------

Experiment N: 47: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.006, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.10 21:12:27
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.006
    lr: 0.006
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95f979e8>
early-stopping-patience: 5
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.527347
Train loss on 100 batch: 1.262985
Train loss on 150 batch: 1.052425
Train loss on 200 batch: 1.197711
Train loss on 250 batch: 1.107384
Train loss on 300 batch: 1.089655
Train loss on 350 batch: 1.129813
Train loss on 400 batch: 1.153687
Train loss on 450 batch: 1.123394
Train loss on 500 batch: 1.045880
Train loss on 550 batch: 1.093411
Train loss on 600 batch: 1.087997
Train loss on 650 batch: 0.952567
Train loss on 700 batch: 1.075323
Train loss on 750 batch: 1.081295
Train loss on 800 batch: 1.127764
Train loss on 850 batch: 0.943640
Train loss on 900 batch: 1.081801
Train loss on 950 batch: 1.004322
Train loss on 1000 batch: 0.897877
Train loss on 1050 batch: 1.099762
Train loss on 1100 batch: 0.959830
Train loss on 1150 batch: 1.002231
Train loss on 1200 batch: 1.071024
Train loss on 1250 batch: 0.994002
Train loss on 1300 batch: 1.174390
Train loss on 1350 batch: 1.062614
Train loss on 1400 batch: 1.121080
Train loss on 1450 batch: 1.205530
Train loss on 1500 batch: 1.066048
Train loss on 1550 batch: 1.021687
Train loss on 1600 batch: 0.977474
Train loss on 1650 batch: 0.961469
best-train-loss: 1.079804
best-valid-loss: 1.176087
best-kappa: nan
: Epoch: 1 | Training Loss: 1.079804 | Val. Loss: 1.176087 | Val. Kappa Score: nan | Estimated time: 1412.91
Train loss on 50 batch: 1.140050
Train loss on 100 batch: 0.974815
Train loss on 150 batch: 0.977704
Train loss on 200 batch: 1.059097
Train loss on 250 batch: 1.059239
Train loss on 300 batch: 0.850027
Train loss on 350 batch: 0.944337
Train loss on 400 batch: 0.885395
Train loss on 450 batch: 0.913879
Train loss on 500 batch: 0.862314
Train loss on 550 batch: 0.802539
Train loss on 600 batch: 0.947170
Train loss on 650 batch: 0.865813
Train loss on 700 batch: 0.964153
Train loss on 750 batch: 0.887214
Train loss on 800 batch: 0.889089
Train loss on 850 batch: 0.873924
Train loss on 900 batch: 0.898723
Train loss on 950 batch: 1.018255
Train loss on 1000 batch: 0.883147
Train loss on 1050 batch: 0.812358
Train loss on 1100 batch: 0.729207
Train loss on 1150 batch: 0.841446
Train loss on 1200 batch: 0.794788
Train loss on 1250 batch: 0.839433
Train loss on 1300 batch: 0.896092
Train loss on 1350 batch: 0.772666
Train loss on 1400 batch: 0.829154
Train loss on 1450 batch: 0.807416
Train loss on 1500 batch: 0.821024
Train loss on 1550 batch: 0.917433
Train loss on 1600 batch: 0.821705
Train loss on 1650 batch: 0.824872
best-train-loss: 0.890118
best-valid-loss: 1.036369
best-kappa: nan
: Epoch: 2 | Training Loss: 0.890118 | Val. Loss: 1.036369 | Val. Kappa Score: nan | Estimated time: 1415.49
Train loss on 50 batch: 0.863499
Train loss on 100 batch: 0.783998
Train loss on 150 batch: 0.786483
Train loss on 200 batch: 0.762852
Train loss on 250 batch: 0.678464
Train loss on 300 batch: 0.816881
Train loss on 350 batch: 0.697249
Train loss on 400 batch: 0.746367
Train loss on 450 batch: 0.729189
Train loss on 500 batch: 0.729456
Train loss on 550 batch: 0.764178
Train loss on 600 batch: 0.784708
Train loss on 650 batch: 0.634035
Train loss on 700 batch: 0.708112
Train loss on 750 batch: 0.821588
Train loss on 800 batch: 0.799521
Train loss on 850 batch: 0.739935
Train loss on 900 batch: 0.756729
Train loss on 950 batch: 0.775374
Train loss on 1000 batch: 0.774956
Train loss on 1050 batch: 0.816842
Train loss on 1100 batch: 0.732354
Train loss on 1150 batch: 0.643509
Train loss on 1200 batch: 0.725348
Train loss on 1250 batch: 0.724051
Train loss on 1300 batch: 0.824798
Train loss on 1350 batch: 0.777636
Train loss on 1400 batch: 0.771320
Train loss on 1450 batch: 0.693915
Train loss on 1500 batch: 0.726910
Train loss on 1550 batch: 0.724820
Train loss on 1600 batch: 0.626244
Train loss on 1650 batch: 0.679128
best-train-loss: 0.745114
best-valid-loss: 0.720569
best-kappa: nan
: Epoch: 3 | Training Loss: 0.745114 | Val. Loss: 0.720569 | Val. Kappa Score: nan | Estimated time: 1414.27
Train loss on 50 batch: 0.682185
Train loss on 100 batch: 0.667463
Train loss on 150 batch: 0.639829
Train loss on 200 batch: 0.623949
Train loss on 250 batch: 0.608131
Train loss on 300 batch: 0.696359
Train loss on 350 batch: 0.634240
Train loss on 400 batch: 0.659781
Train loss on 450 batch: 0.657614
Train loss on 500 batch: 0.667227
Train loss on 550 batch: 0.631433
Train loss on 600 batch: 0.672290
Train loss on 650 batch: 0.650414
Train loss on 700 batch: 0.637787
Train loss on 750 batch: 0.674969
Train loss on 800 batch: 0.636549
Train loss on 850 batch: 0.651286
Train loss on 900 batch: 0.594663
Train loss on 950 batch: 0.697948
Train loss on 1000 batch: 0.649113
Train loss on 1050 batch: 0.618750
Train loss on 1100 batch: 0.657656
Train loss on 1150 batch: 0.666953
Train loss on 1200 batch: 0.592825
Train loss on 1250 batch: 0.671735
Train loss on 1300 batch: 0.604227
Train loss on 1350 batch: 0.634843
Train loss on 1400 batch: 0.579376
Train loss on 1450 batch: 0.599084
Train loss on 1500 batch: 0.699152
Train loss on 1550 batch: 0.576854
Train loss on 1600 batch: 0.571781
Train loss on 1650 batch: 0.655927
best-train-loss: 0.642468
best-valid-loss: 0.673667
best-kappa: nan
: Epoch: 4 | Training Loss: 0.642468 | Val. Loss: 0.673667 | Val. Kappa Score: nan | Estimated time: 1432.69
Train loss on 50 batch: 0.576350
Train loss on 100 batch: 0.581053
Train loss on 150 batch: 0.526916
Train loss on 200 batch: 0.602382
Train loss on 250 batch: 0.510379
Train loss on 300 batch: 0.576725
Train loss on 350 batch: 0.534835
Train loss on 400 batch: 0.545653
Train loss on 450 batch: 0.589097
Train loss on 500 batch: 0.565419
Train loss on 550 batch: 0.550543
Train loss on 600 batch: 0.504648
Train loss on 650 batch: 0.546860
Train loss on 700 batch: 0.547606
Train loss on 750 batch: 0.514977
Train loss on 800 batch: 0.503944
Train loss on 850 batch: 0.626957
Train loss on 900 batch: 0.549464
Train loss on 950 batch: 0.599565
Train loss on 1000 batch: 0.655384
Train loss on 1050 batch: 0.613052
Train loss on 1100 batch: 0.611683
Train loss on 1150 batch: 0.490810
Train loss on 1200 batch: 0.616985
Train loss on 1250 batch: 0.601687
Train loss on 1300 batch: 0.597691
Train loss on 1350 batch: 0.457026
Train loss on 1400 batch: 0.616506
Train loss on 1450 batch: 0.544772
Train loss on 1500 batch: 0.563843
Train loss on 1550 batch: 0.585555
Train loss on 1600 batch: 0.625594
Train loss on 1650 batch: 0.557917
best-train-loss: 0.566693
best-valid-loss: 0.585826
best-kappa: nan
: Epoch: 5 | Training Loss: 0.566693 | Val. Loss: 0.585826 | Val. Kappa Score: nan | Estimated time: 1428.21
Train loss on 50 batch: 0.586378
Train loss on 100 batch: 0.500569
Train loss on 150 batch: 0.619217
Train loss on 200 batch: 0.530107
Train loss on 250 batch: 0.451003
Train loss on 300 batch: 0.504714
Train loss on 350 batch: 0.562005
Train loss on 400 batch: 0.500231
Train loss on 450 batch: 0.657487
Train loss on 500 batch: 0.582484
Train loss on 550 batch: 0.588868
Train loss on 600 batch: 0.515863
Train loss on 650 batch: 0.518005
Train loss on 700 batch: 0.551638
Train loss on 750 batch: 0.530579
Train loss on 800 batch: 0.551560
Train loss on 850 batch: 0.603451
Train loss on 900 batch: 0.530245
Train loss on 950 batch: 0.544802
Train loss on 1000 batch: 0.447867
Train loss on 1050 batch: 0.537464
Train loss on 1100 batch: 0.623146
Train loss on 1150 batch: 0.543914
Train loss on 1200 batch: 0.565561
Train loss on 1250 batch: 0.588810
Train loss on 1300 batch: 0.586129
Train loss on 1350 batch: 0.490019
Train loss on 1400 batch: 0.567353
Train loss on 1450 batch: 0.588648
Train loss on 1500 batch: 0.578638
Train loss on 1550 batch: 0.540945
Train loss on 1600 batch: 0.590299
Train loss on 1650 batch: 0.500672
best-train-loss: 0.553108
best-valid-loss: 0.566219
best-kappa: nan
: Epoch: 6 | Training Loss: 0.553108 | Val. Loss: 0.566219 | Val. Kappa Score: nan | Estimated time: 1413.93
Train loss on 50 batch: 0.576992
Train loss on 100 batch: 0.573947
Train loss on 150 batch: 0.549199
Train loss on 200 batch: 0.537607
Train loss on 250 batch: 0.523911
Train loss on 300 batch: 0.601433
Train loss on 350 batch: 0.524685
Train loss on 400 batch: 0.579680
Train loss on 450 batch: 0.515235
Train loss on 500 batch: 0.543994
Train loss on 550 batch: 0.548642
Train loss on 600 batch: 0.607448
Train loss on 650 batch: 0.633841
Train loss on 700 batch: 0.539915
Train loss on 750 batch: 0.480195
Train loss on 800 batch: 0.495232
Train loss on 850 batch: 0.499434
Train loss on 900 batch: 0.552683
Train loss on 950 batch: 0.517189
Train loss on 1000 batch: 0.455201
Train loss on 1050 batch: 0.531234
Train loss on 1100 batch: 0.596766
Train loss on 1150 batch: 0.597433
Train loss on 1200 batch: 0.529817
Train loss on 1250 batch: 0.544783
Train loss on 1300 batch: 0.587619
Train loss on 1350 batch: 0.525665
Train loss on 1400 batch: 0.640842
Train loss on 1450 batch: 0.534478
Train loss on 1500 batch: 0.526672
Train loss on 1550 batch: 0.431790
Train loss on 1600 batch: 0.495956
Train loss on 1650 batch: 0.586165
best-train-loss: 0.543704
best-valid-loss: 0.519596
best-kappa: nan
: Epoch: 7 | Training Loss: 0.543704 | Val. Loss: 0.519596 | Val. Kappa Score: nan | Estimated time: 1413.96
Train loss on 50 batch: 0.546127
Train loss on 100 batch: 0.547901
Train loss on 150 batch: 0.643195
Train loss on 200 batch: 0.526221
Train loss on 250 batch: 0.633107
Train loss on 300 batch: 0.592310
Train loss on 350 batch: 0.554527
Train loss on 400 batch: 0.617260
Train loss on 450 batch: 0.544591
Train loss on 500 batch: 0.526131
Train loss on 550 batch: 0.517335
Train loss on 600 batch: 0.538065
Train loss on 650 batch: 0.576349
Train loss on 700 batch: 0.603181
Train loss on 750 batch: 0.553208
Train loss on 800 batch: 0.686998
Train loss on 850 batch: 0.556761
Train loss on 900 batch: 0.593557
Train loss on 950 batch: 0.621581
Train loss on 1000 batch: 0.540291
Train loss on 1050 batch: 0.562051
Train loss on 1100 batch: 0.569810
Train loss on 1150 batch: 0.630807
Train loss on 1200 batch: 0.571555
Train loss on 1250 batch: 0.580067
Train loss on 1300 batch: 0.599428
Train loss on 1350 batch: 0.571256
Train loss on 1400 batch: 0.571926
Train loss on 1450 batch: 0.540951
Train loss on 1500 batch: 0.589004
Train loss on 1550 batch: 0.589199
Train loss on 1600 batch: 0.550373
Train loss on 1650 batch: 0.518464
: Epoch: 8 | Training Loss: 0.573436 | Val. Loss: 0.569325 | Val. Kappa Score: nan | Estimated time: 1415.78
Train loss on 50 batch: 0.554842
Train loss on 100 batch: 0.584439
Train loss on 150 batch: 0.666881
Train loss on 200 batch: 0.609342
Train loss on 250 batch: 0.700100
Train loss on 300 batch: 0.635542
Train loss on 350 batch: 0.562149
Train loss on 400 batch: 0.637138
Train loss on 450 batch: 0.547360
Train loss on 500 batch: 0.616079
Train loss on 550 batch: 0.641873
Train loss on 600 batch: 0.640665
Train loss on 650 batch: 0.583383
Train loss on 700 batch: 0.699214
Train loss on 750 batch: 0.636399
Train loss on 800 batch: 0.695053
Train loss on 850 batch: 0.596743
Train loss on 900 batch: 0.514810
Train loss on 950 batch: 0.512887
Train loss on 1000 batch: 0.570961
Train loss on 1050 batch: 0.613696
Train loss on 1100 batch: 0.657857
Train loss on 1150 batch: 0.541847
Train loss on 1200 batch: 0.634990
Train loss on 1250 batch: 0.577900
Train loss on 1300 batch: 0.613003
Train loss on 1350 batch: 0.512684
Train loss on 1400 batch: 0.557994
Train loss on 1450 batch: 0.544266
Train loss on 1500 batch: 0.698123
Train loss on 1550 batch: 0.574618
Train loss on 1600 batch: 0.648328
Train loss on 1650 batch: 0.610804
: Epoch: 9 | Training Loss: 0.605200 | Val. Loss: 0.605527 | Val. Kappa Score: nan | Estimated time: 1420.14
Train loss on 50 batch: 0.602326
Train loss on 100 batch: 0.701482
Train loss on 150 batch: 0.657644
Train loss on 200 batch: 0.638819
Train loss on 250 batch: 0.604292
Train loss on 300 batch: 0.615575
Train loss on 350 batch: 0.625452
Train loss on 400 batch: 0.636007
Train loss on 450 batch: 0.623634
Train loss on 500 batch: 0.624364
Train loss on 550 batch: 0.692312
Train loss on 600 batch: 0.690055
Train loss on 650 batch: 0.657778
Train loss on 700 batch: 0.677183
Train loss on 750 batch: 0.571910
Train loss on 800 batch: 0.703331
Train loss on 850 batch: 0.541748
Train loss on 900 batch: 0.583132
Train loss on 950 batch: 0.727820
Train loss on 1000 batch: 0.604169
Train loss on 1050 batch: 0.588630
Train loss on 1100 batch: 0.620561
Train loss on 1150 batch: 0.710128
Train loss on 1200 batch: 0.614690
Train loss on 1250 batch: 0.560125
Train loss on 1300 batch: 0.589805
Train loss on 1350 batch: 0.611500
Train loss on 1400 batch: 0.719012
Train loss on 1450 batch: 0.613568
Train loss on 1500 batch: 0.592202
Train loss on 1550 batch: 0.589106
Train loss on 1600 batch: 0.608385
Train loss on 1650 batch: 0.556325
: Epoch: 10 | Training Loss: 0.627644 | Val. Loss: 0.599103 | Val. Kappa Score: nan | Estimated time: 1420.05
Train loss on 50 batch: 0.551830
Train loss on 100 batch: 0.655103
Train loss on 150 batch: 0.623082
Train loss on 200 batch: 0.615882
Train loss on 250 batch: 0.607659
Train loss on 300 batch: 0.530095
Train loss on 350 batch: 0.574410
Train loss on 400 batch: 0.579063
Train loss on 450 batch: 0.588437
Train loss on 500 batch: 0.547907
Train loss on 550 batch: 0.679265
Train loss on 600 batch: 0.650217
Train loss on 650 batch: 0.597640
Train loss on 700 batch: 0.740401
Train loss on 750 batch: 0.721595
Train loss on 800 batch: 0.637574
Train loss on 850 batch: 0.639366
Train loss on 900 batch: 0.632376
Train loss on 950 batch: 0.637846
Train loss on 1000 batch: 0.703985
Train loss on 1050 batch: 0.618377
Train loss on 1100 batch: 0.627830
Train loss on 1150 batch: 0.555211
Train loss on 1200 batch: 0.550972
Train loss on 1250 batch: 0.533434
Train loss on 1300 batch: 0.597407
Train loss on 1350 batch: 0.577053
Train loss on 1400 batch: 0.578026
Train loss on 1450 batch: 0.619000
Train loss on 1500 batch: 0.663928
Train loss on 1550 batch: 0.655026
Train loss on 1600 batch: 0.642196
Train loss on 1650 batch: 0.563196
: Epoch: 11 | Training Loss: 0.612250 | Val. Loss: 0.635679 | Val. Kappa Score: nan | Estimated time: 1421.85
Train loss on 50 batch: 0.507224
Train loss on 100 batch: 0.565200
Train loss on 150 batch: 0.564120
Train loss on 200 batch: 0.590304
Train loss on 250 batch: 0.706880
Train loss on 300 batch: 0.654918
Train loss on 350 batch: 0.565524
Train loss on 400 batch: 0.575819
Train loss on 450 batch: 0.539355
Train loss on 500 batch: 0.573603
Train loss on 550 batch: 0.567183
Train loss on 600 batch: 0.531006
Train loss on 650 batch: 0.555360
Train loss on 700 batch: 0.612366
Train loss on 750 batch: 0.617263
Train loss on 800 batch: 0.610281
Train loss on 850 batch: 0.567386
Train loss on 900 batch: 0.508961
Train loss on 950 batch: 0.641928
Train loss on 1000 batch: 0.600329
Train loss on 1050 batch: 0.625103
Train loss on 1100 batch: 0.541433
Train loss on 1150 batch: 0.597373
Train loss on 1200 batch: 0.570429
Train loss on 1250 batch: 0.659952
Train loss on 1300 batch: 0.614223
Train loss on 1350 batch: 0.591175
Train loss on 1400 batch: 0.646518
Train loss on 1450 batch: 0.585316
Train loss on 1500 batch: 0.686431
Train loss on 1550 batch: 0.597360
Train loss on 1600 batch: 0.591502
Train loss on 1650 batch: 0.567257
: Epoch: 12 | Training Loss: 0.593395 | Val. Loss: 0.609084 | Val. Kappa Score: nan | Estimated time: 1414.87
time_estimated: 17024.89
n-epochs: 12
time_estimated: 17024.91
----------------------------------------

Experiment N: 48: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.003, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.11 15:06:48
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb975bfac8>
early-stopping-patience: 7
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.561875
Train loss on 100 batch: 0.614548
Train loss on 150 batch: 0.584864
Train loss on 200 batch: 0.617624
Train loss on 250 batch: 0.631751
Train loss on 300 batch: 0.563783
Train loss on 350 batch: 0.547708
Train loss on 400 batch: 0.577527
Train loss on 450 batch: 0.651570
Train loss on 500 batch: 0.549056
Train loss on 550 batch: 0.527593
Train loss on 600 batch: 0.492355
Train loss on 650 batch: 0.574032
Train loss on 700 batch: 0.597396
Train loss on 750 batch: 0.562199
Train loss on 800 batch: 0.615015
Train loss on 850 batch: 0.551230
Train loss on 900 batch: 0.661890
Train loss on 950 batch: 0.650285
Train loss on 1000 batch: 0.550303
Train loss on 1050 batch: 0.602835
Train loss on 1100 batch: 0.551152
Train loss on 1150 batch: 0.590306
Train loss on 1200 batch: 0.581181
Train loss on 1250 batch: 0.567419
Train loss on 1300 batch: 0.614630
Train loss on 1350 batch: 0.612131
Train loss on 1400 batch: 0.532854
Train loss on 1450 batch: 0.663082
Train loss on 1500 batch: 0.538830
Train loss on 1550 batch: 0.554235
Train loss on 1600 batch: 0.484975
Train loss on 1650 batch: 0.516973
best-train-loss: 0.577896
best-valid-loss: 0.685317
best-kappa: 0.3629
: Epoch: 1 | Training Loss: 0.577896 | Val. Loss: 0.685317 | Val. Kappa Score: 0.3629 | LR: 0.003000 | Estimated time: 1426.89
Train loss on 50 batch: 0.576946
Train loss on 100 batch: 0.494287
Train loss on 150 batch: 0.552969
Train loss on 200 batch: 0.628624
Train loss on 250 batch: 0.585181
Train loss on 300 batch: 0.451756
Train loss on 350 batch: 0.574843
Train loss on 400 batch: 0.528977
Train loss on 450 batch: 0.515084
Train loss on 500 batch: 0.498868
Train loss on 550 batch: 0.491605
Train loss on 600 batch: 0.547905
Train loss on 650 batch: 0.520656
Train loss on 700 batch: 0.572063
Train loss on 750 batch: 0.622450
Train loss on 800 batch: 0.550089
Train loss on 850 batch: 0.592808
Train loss on 900 batch: 0.593963
Train loss on 950 batch: 0.666585
Train loss on 1000 batch: 0.590887
Train loss on 1050 batch: 0.581545
Train loss on 1100 batch: 0.495580
Train loss on 1150 batch: 0.547402
Train loss on 1200 batch: 0.557016
Train loss on 1250 batch: 0.548386
Train loss on 1300 batch: 0.554063
Train loss on 1350 batch: 0.512699
Train loss on 1400 batch: 0.532545
Train loss on 1450 batch: 0.579127
Train loss on 1500 batch: 0.551334
Train loss on 1550 batch: 0.618583
Train loss on 1600 batch: 0.627564
Train loss on 1650 batch: 0.632226
best-train-loss: 0.562403
best-valid-loss: 0.582504
best-kappa: nan
: Epoch: 2 | Training Loss: 0.562403 | Val. Loss: 0.582504 | Val. Kappa Score: nan | LR: 0.003000 | Estimated time: 1426.39
Train loss on 50 batch: 0.533140
Train loss on 100 batch: 0.589837
Train loss on 150 batch: 0.584168
Train loss on 200 batch: 0.517887
Train loss on 250 batch: 0.463996
Train loss on 300 batch: 0.572442
Train loss on 350 batch: 0.561827
Train loss on 400 batch: 0.560677
Train loss on 450 batch: 0.580147
Train loss on 500 batch: 0.688008
Train loss on 550 batch: 0.667644
Train loss on 600 batch: 0.662423
Train loss on 650 batch: 0.492674
Train loss on 700 batch: 0.551131
Train loss on 750 batch: 0.643571
Train loss on 800 batch: 0.660057
Train loss on 850 batch: 0.596974
Train loss on 900 batch: 0.611488
Train loss on 950 batch: 0.631763
Train loss on 1000 batch: 0.632874
Train loss on 1050 batch: 0.609872
Train loss on 1100 batch: 0.581408
Train loss on 1150 batch: 0.529225
Train loss on 1200 batch: 0.516313
Train loss on 1250 batch: 0.572039
Train loss on 1300 batch: 0.554144
Train loss on 1350 batch: 0.521645
Train loss on 1400 batch: 0.568376
Train loss on 1450 batch: 0.535648
Train loss on 1500 batch: 0.553456
Train loss on 1550 batch: 0.514068
Train loss on 1600 batch: 0.529821
Train loss on 1650 batch: 0.525907
: Epoch: 3 | Training Loss: 0.572773 | Val. Loss: 0.679139 | Val. Kappa Score: nan | LR: 0.003000 | Estimated time: 1425.77
Train loss on 50 batch: 0.555498
Train loss on 100 batch: 0.564435
Train loss on 150 batch: 0.514846
Train loss on 200 batch: 0.513327
Train loss on 250 batch: 0.531521
Train loss on 300 batch: 0.604615
Train loss on 350 batch: 0.587806
Train loss on 400 batch: 0.635277
Train loss on 450 batch: 0.610333
Train loss on 500 batch: 0.588027
Train loss on 550 batch: 0.516396
Train loss on 600 batch: 0.530928
Train loss on 650 batch: 0.522300
Train loss on 700 batch: 0.529521
Train loss on 750 batch: 0.588400
Train loss on 800 batch: 0.555941
Train loss on 850 batch: 0.521891
Train loss on 900 batch: 0.536314
Train loss on 950 batch: 0.586874
Train loss on 1000 batch: 0.541242
Train loss on 1050 batch: 0.555719
Train loss on 1100 batch: 0.586895
Train loss on 1150 batch: 0.577851
Train loss on 1200 batch: 0.477349
Train loss on 1250 batch: 0.540924
Train loss on 1300 batch: 0.498653
Train loss on 1350 batch: 0.547796
Train loss on 1400 batch: 0.479996
Train loss on 1450 batch: 0.536804
Train loss on 1500 batch: 0.566240
Train loss on 1550 batch: 0.484416
Train loss on 1600 batch: 0.452486
Train loss on 1650 batch: 0.512623
best-train-loss: 0.544703
best-valid-loss: 0.575419
best-kappa: nan
: Epoch: 4 | Training Loss: 0.544703 | Val. Loss: 0.575419 | Val. Kappa Score: nan | LR: 0.003000 | Estimated time: 1427.44
Train loss on 50 batch: 0.549843
Train loss on 100 batch: 0.486931
Train loss on 150 batch: 0.481178
Train loss on 200 batch: 0.528823
Train loss on 250 batch: 0.461982
Train loss on 300 batch: 0.485341
Train loss on 350 batch: 0.466173
Train loss on 400 batch: 0.482234
Train loss on 450 batch: 0.526513
Train loss on 500 batch: 0.489769
Train loss on 550 batch: 0.522035
Train loss on 600 batch: 0.445634
Train loss on 650 batch: 0.437232
Train loss on 700 batch: 0.455625
Train loss on 750 batch: 0.478773
Train loss on 800 batch: 0.431303
Train loss on 850 batch: 0.592956
Train loss on 900 batch: 0.563881
Train loss on 950 batch: 0.530022
Train loss on 1000 batch: 0.549763
Train loss on 1050 batch: 0.603978
Train loss on 1100 batch: 0.584448
Train loss on 1150 batch: 0.469262
Train loss on 1200 batch: 0.555006
Train loss on 1250 batch: 0.531925
Train loss on 1300 batch: 0.508606
Train loss on 1350 batch: 0.434118
Train loss on 1400 batch: 0.550060
Train loss on 1450 batch: 0.530850
Train loss on 1500 batch: 0.502846
----------------------------------------

Experiment N: 49: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.003, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.11 17:45:02
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e8fe80>
early-stopping-patience: 7
parameters-amount: 28342833
n-epochs: 25
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.561875
Train loss on 100 batch: 0.614548
Train loss on 150 batch: 0.584864
Train loss on 200 batch: 0.617624
Train loss on 250 batch: 0.631751
Train loss on 300 batch: 0.563783
Train loss on 350 batch: 0.547708
Train loss on 400 batch: 0.577527
Train loss on 450 batch: 0.651570
Train loss on 500 batch: 0.549056
Train loss on 550 batch: 0.527593
Train loss on 600 batch: 0.492355
Train loss on 650 batch: 0.574032
Train loss on 700 batch: 0.597396
Train loss on 750 batch: 0.562199
Train loss on 800 batch: 0.615015
Train loss on 850 batch: 0.551230
Train loss on 900 batch: 0.661890
Train loss on 950 batch: 0.650285
Train loss on 1000 batch: 0.550303
Train loss on 1050 batch: 0.602835
Train loss on 1100 batch: 0.551152
Train loss on 1150 batch: 0.590306
Train loss on 1200 batch: 0.581181
Train loss on 1250 batch: 0.567419
Train loss on 1300 batch: 0.614630
Train loss on 1350 batch: 0.612131
Train loss on 1400 batch: 0.532854
Train loss on 1450 batch: 0.663082
Train loss on 1500 batch: 0.538830
Train loss on 1550 batch: 0.554235
Train loss on 1600 batch: 0.484975
Train loss on 1650 batch: 0.516973
best-train-loss: 0.577896
best-valid-loss: 0.685317
best-kappa: 0.3629
: Epoch: 1 | Training Loss: 0.577896 | Val. Loss: 0.685317 | Val. Kappa Score: 0.3629 | LR: 0.003000 | Estimated time: 474.42
Train loss on 50 batch: 0.576946
----------------------------------------

Experiment N: 50: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.003, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.11 17:56:08
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e8fe48>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 30
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.561875
Train loss on 100 batch: 0.614548
Train loss on 150 batch: 0.584864
Train loss on 200 batch: 0.617624
Train loss on 250 batch: 0.631751
Train loss on 300 batch: 0.563783
Train loss on 350 batch: 0.547708
Train loss on 400 batch: 0.577527
Train loss on 450 batch: 0.651570
Train loss on 500 batch: 0.549056
Train loss on 550 batch: 0.527593
Train loss on 600 batch: 0.492355
Train loss on 650 batch: 0.574032
Train loss on 700 batch: 0.597396
Train loss on 750 batch: 0.562199
Train loss on 800 batch: 0.615015
Train loss on 850 batch: 0.551230
Train loss on 900 batch: 0.661890
Train loss on 950 batch: 0.650285
Train loss on 1000 batch: 0.550303
Train loss on 1050 batch: 0.602835
Train loss on 1100 batch: 0.551152
Train loss on 1150 batch: 0.590306
Train loss on 1200 batch: 0.581181
Train loss on 1250 batch: 0.567419
Train loss on 1300 batch: 0.614630
Train loss on 1350 batch: 0.612131
Train loss on 1400 batch: 0.532854
Train loss on 1450 batch: 0.663082
Train loss on 1500 batch: 0.538830
Train loss on 1550 batch: 0.554235
Train loss on 1600 batch: 0.484975
Train loss on 1650 batch: 0.516973
best-train-loss: 0.577896
best-valid-loss: 0.685317
best-kappa: 0.3629
: Epoch: 1 | Training Loss: 0.577896 | Val. Loss: 0.685317 | Val. Kappa Score: 0.3629 | LR: 0.003000 | Estimated time: 465.85
Train loss on 50 batch: 0.576946
Train loss on 100 batch: 0.494287
Train loss on 150 batch: 0.552969
Train loss on 200 batch: 0.628624
Train loss on 250 batch: 0.585181
Train loss on 300 batch: 0.451756
Train loss on 350 batch: 0.574843
Train loss on 400 batch: 0.528977
Train loss on 450 batch: 0.515084
----------------------------------------

Experiment N: 51: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.003, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.11 18:06:15
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.003
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e8feb8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 30
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.561875
Train loss on 100 batch: 0.614548
Train loss on 150 batch: 0.584864
Train loss on 200 batch: 0.617624
Train loss on 250 batch: 0.631751
Train loss on 300 batch: 0.563783
Train loss on 350 batch: 0.547708
Train loss on 400 batch: 0.577527
Train loss on 450 batch: 0.651570
Train loss on 500 batch: 0.549056
Train loss on 550 batch: 0.527593
Train loss on 600 batch: 0.492355
Train loss on 650 batch: 0.574032
Train loss on 700 batch: 0.597396
Train loss on 750 batch: 0.562199
Train loss on 800 batch: 0.615015
Train loss on 850 batch: 0.551230
Train loss on 900 batch: 0.661890
Train loss on 950 batch: 0.650285
Train loss on 1000 batch: 0.550303
Train loss on 1050 batch: 0.602835
Train loss on 1100 batch: 0.551152
Train loss on 1150 batch: 0.590306
Train loss on 1200 batch: 0.581181
Train loss on 1250 batch: 0.567419
Train loss on 1300 batch: 0.614630
Train loss on 1350 batch: 0.612131
Train loss on 1400 batch: 0.532854
Train loss on 1450 batch: 0.663082
Train loss on 1500 batch: 0.538830
Train loss on 1550 batch: 0.554235
Train loss on 1600 batch: 0.484975
Train loss on 1650 batch: 0.516973
best-train-loss: 0.577896
best-valid-loss: 0.685317
best-kappa: 0.3629
: Epoch: 1 | Training Loss: 0.577896 | Val. Loss: 0.685317 | Val. Kappa Score: 0.3629 | LR: 0.003000 | Estimated time: 465.49
Train loss on 50 batch: 0.576946
Train loss on 100 batch: 0.494287
Train loss on 150 batch: 0.552969
Train loss on 200 batch: 0.628624
Train loss on 250 batch: 0.585181
Train loss on 300 batch: 0.451756
Train loss on 350 batch: 0.574843
Train loss on 400 batch: 0.528977
Train loss on 450 batch: 0.515084
Train loss on 500 batch: 0.498868
Train loss on 550 batch: 0.491605
Train loss on 600 batch: 0.547905
Train loss on 650 batch: 0.520656
Train loss on 700 batch: 0.572063
Train loss on 750 batch: 0.622450
Train loss on 800 batch: 0.550089
Train loss on 850 batch: 0.592808
Train loss on 900 batch: 0.593963
Train loss on 950 batch: 0.666585
Train loss on 1000 batch: 0.590887
Train loss on 1050 batch: 0.581545
Train loss on 1100 batch: 0.495580
Train loss on 1150 batch: 0.547402
Train loss on 1200 batch: 0.557016
Train loss on 1250 batch: 0.548386
Train loss on 1300 batch: 0.554063
Train loss on 1350 batch: 0.512699
Train loss on 1400 batch: 0.532545
Train loss on 1450 batch: 0.579127
Train loss on 1500 batch: 0.551334
Train loss on 1550 batch: 0.618583
Train loss on 1600 batch: 0.627564
Train loss on 1650 batch: 0.632226
best-train-loss: 0.562403
best-valid-loss: 0.582504
best-kappa: 0.4672
: Epoch: 2 | Training Loss: 0.562403 | Val. Loss: 0.582504 | Val. Kappa Score: 0.4672 | LR: 0.003000 | Estimated time: 461.39
Train loss on 50 batch: 0.533140
Train loss on 100 batch: 0.589837
Train loss on 150 batch: 0.584168
Train loss on 200 batch: 0.517887
Train loss on 250 batch: 0.463996
Train loss on 300 batch: 0.572442
Train loss on 350 batch: 0.561827
Train loss on 400 batch: 0.560677
Train loss on 450 batch: 0.580147
Train loss on 500 batch: 0.688008
Train loss on 550 batch: 0.667644
Train loss on 600 batch: 0.662423
Train loss on 650 batch: 0.492674
Train loss on 700 batch: 0.551131
Train loss on 750 batch: 0.643571
Train loss on 800 batch: 0.660057
Train loss on 850 batch: 0.596974
Train loss on 900 batch: 0.611488
Train loss on 950 batch: 0.631763
Train loss on 1000 batch: 0.632874
Train loss on 1050 batch: 0.609872
Train loss on 1100 batch: 0.581408
Train loss on 1150 batch: 0.529225
Train loss on 1200 batch: 0.516313
Train loss on 1250 batch: 0.572039
Train loss on 1300 batch: 0.554144
Train loss on 1350 batch: 0.521645
Train loss on 1400 batch: 0.568376
Train loss on 1450 batch: 0.535648
Train loss on 1500 batch: 0.553456
Train loss on 1550 batch: 0.514068
Train loss on 1600 batch: 0.529821
Train loss on 1650 batch: 0.525907
: Epoch: 3 | Training Loss: 0.572773 | Val. Loss: 0.679139 | Val. Kappa Score: 0.4938 | LR: 0.003000 | Estimated time: 461.98
Train loss on 50 batch: 0.555498
Train loss on 100 batch: 0.564435
Train loss on 150 batch: 0.514846
Train loss on 200 batch: 0.513327
Train loss on 250 batch: 0.531521
Train loss on 300 batch: 0.604615
Train loss on 350 batch: 0.587806
Train loss on 400 batch: 0.635277
Train loss on 450 batch: 0.610333
Train loss on 500 batch: 0.588027
Train loss on 550 batch: 0.516396
Train loss on 600 batch: 0.530928
Train loss on 650 batch: 0.522300
Train loss on 700 batch: 0.529521
Train loss on 750 batch: 0.588400
Train loss on 800 batch: 0.555941
Train loss on 850 batch: 0.521891
Train loss on 900 batch: 0.536314
Train loss on 950 batch: 0.586874
Train loss on 1000 batch: 0.541242
Train loss on 1050 batch: 0.555719
Train loss on 1100 batch: 0.586895
Train loss on 1150 batch: 0.577851
Train loss on 1200 batch: 0.477349
Train loss on 1250 batch: 0.540924
Train loss on 1300 batch: 0.498653
Train loss on 1350 batch: 0.547796
Train loss on 1400 batch: 0.479996
Train loss on 1450 batch: 0.536804
Train loss on 1500 batch: 0.566240
Train loss on 1550 batch: 0.484416
Train loss on 1600 batch: 0.452486
Train loss on 1650 batch: 0.512623
best-train-loss: 0.544703
best-valid-loss: 0.575419
best-kappa: 0.5174
: Epoch: 4 | Training Loss: 0.544703 | Val. Loss: 0.575419 | Val. Kappa Score: 0.5174 | LR: 0.003000 | Estimated time: 461.39
Train loss on 50 batch: 0.549843
Train loss on 100 batch: 0.486931
Train loss on 150 batch: 0.481178
Train loss on 200 batch: 0.528823
Train loss on 250 batch: 0.461982
Train loss on 300 batch: 0.485341
Train loss on 350 batch: 0.466173
Train loss on 400 batch: 0.482234
Train loss on 450 batch: 0.526513
Train loss on 500 batch: 0.489769
Train loss on 550 batch: 0.522035
Train loss on 600 batch: 0.445634
Train loss on 650 batch: 0.437232
Train loss on 700 batch: 0.455625
Train loss on 750 batch: 0.478773
Train loss on 800 batch: 0.431303
Train loss on 850 batch: 0.592956
Train loss on 900 batch: 0.563881
Train loss on 950 batch: 0.530022
Train loss on 1000 batch: 0.549763
Train loss on 1050 batch: 0.603978
Train loss on 1100 batch: 0.584448
Train loss on 1150 batch: 0.469262
Train loss on 1200 batch: 0.555006
Train loss on 1250 batch: 0.531925
Train loss on 1300 batch: 0.508606
Train loss on 1350 batch: 0.434118
Train loss on 1400 batch: 0.550060
Train loss on 1450 batch: 0.530850
Train loss on 1500 batch: 0.502846
Train loss on 1550 batch: 0.558237
Train loss on 1600 batch: 0.588029
Train loss on 1650 batch: 0.548417
best-train-loss: 0.512631
best-valid-loss: 0.503407
best-kappa: 0.5400
: Epoch: 5 | Training Loss: 0.512631 | Val. Loss: 0.503407 | Val. Kappa Score: 0.5400 | LR: 0.003000 | Estimated time: 461.91
Train loss on 50 batch: 0.576558
Train loss on 100 batch: 0.424716
Train loss on 150 batch: 0.536783
Train loss on 200 batch: 0.524350
Train loss on 250 batch: 0.464357
Train loss on 300 batch: 0.505743
Train loss on 350 batch: 0.541028
Train loss on 400 batch: 0.454609
Train loss on 450 batch: 0.597378
Train loss on 500 batch: 0.513385
Train loss on 550 batch: 0.552836
Train loss on 600 batch: 0.475686
Train loss on 650 batch: 0.443778
Train loss on 700 batch: 0.520067
Train loss on 750 batch: 0.484038
Train loss on 800 batch: 0.519005
Train loss on 850 batch: 0.493200
Train loss on 900 batch: 0.438605
Train loss on 950 batch: 0.484824
Train loss on 1000 batch: 0.423116
Train loss on 1050 batch: 0.485419
Train loss on 1100 batch: 0.542436
Train loss on 1150 batch: 0.499212
Train loss on 1200 batch: 0.522435
Train loss on 1250 batch: 0.507306
Train loss on 1300 batch: 0.485979
Train loss on 1350 batch: 0.434418
Train loss on 1400 batch: 0.523342
Train loss on 1450 batch: 0.550262
Train loss on 1500 batch: 0.582938
Train loss on 1550 batch: 0.495241
Train loss on 1600 batch: 0.482952
Train loss on 1650 batch: 0.453644
: Epoch: 6 | Training Loss: 0.501704 | Val. Loss: 0.724397 | Val. Kappa Score: 0.5501 | LR: 0.003000 | Estimated time: 461.53
Train loss on 50 batch: 0.500467
Train loss on 100 batch: 0.538371
Train loss on 150 batch: 0.541363
Train loss on 200 batch: 0.455613
Train loss on 250 batch: 0.482328
Train loss on 300 batch: 0.533926
Train loss on 350 batch: 0.543256
Train loss on 400 batch: 0.589795
Train loss on 450 batch: 0.463780
Train loss on 500 batch: 0.554136
Train loss on 550 batch: 0.556914
Train loss on 600 batch: 0.493814
Train loss on 650 batch: 0.583882
Train loss on 700 batch: 0.539380
Train loss on 750 batch: 0.445695
Train loss on 800 batch: 0.456083
Train loss on 850 batch: 0.474263
Train loss on 900 batch: 0.498904
Train loss on 950 batch: 0.473707
Train loss on 1000 batch: 0.454602
Train loss on 1050 batch: 0.544432
Train loss on 1100 batch: 0.628216
Train loss on 1150 batch: 0.575900
Train loss on 1200 batch: 0.471418
Train loss on 1250 batch: 0.500686
Train loss on 1300 batch: 0.525259
Train loss on 1350 batch: 0.497088
Train loss on 1400 batch: 0.575853
Train loss on 1450 batch: 0.471222
Train loss on 1500 batch: 0.469742
Train loss on 1550 batch: 0.380892
Train loss on 1600 batch: 0.426580
Train loss on 1650 batch: 0.508681
: Epoch: 7 | Training Loss: 0.505981 | Val. Loss: 0.629172 | Val. Kappa Score: 0.5507 | LR: 0.003000 | Estimated time: 461.42
Train loss on 50 batch: 0.474853
Train loss on 100 batch: 0.499024
Train loss on 150 batch: 0.532153
Train loss on 200 batch: 0.426939
Train loss on 250 batch: 0.526795
Train loss on 300 batch: 0.472851
Train loss on 350 batch: 0.478894
Train loss on 400 batch: 0.487257
Train loss on 450 batch: 0.470953
Train loss on 500 batch: 0.436241
Train loss on 550 batch: 0.419339
Train loss on 600 batch: 0.479496
Train loss on 650 batch: 0.480256
Train loss on 700 batch: 0.469849
Train loss on 750 batch: 0.456180
Train loss on 800 batch: 0.566850
Train loss on 850 batch: 0.467944
Train loss on 900 batch: 0.477293
Train loss on 950 batch: 0.542971
Train loss on 1000 batch: 0.445028
Train loss on 1050 batch: 0.474737
Train loss on 1100 batch: 0.511539
Train loss on 1150 batch: 0.577477
Train loss on 1200 batch: 0.536041
Train loss on 1250 batch: 0.498006
Train loss on 1300 batch: 0.520183
Train loss on 1350 batch: 0.519101
Train loss on 1400 batch: 0.506320
Train loss on 1450 batch: 0.460814
Train loss on 1500 batch: 0.501439
Train loss on 1550 batch: 0.464214
Train loss on 1600 batch: 0.459625
Train loss on 1650 batch: 0.384425
: Epoch: 8 | Training Loss: 0.484257 | Val. Loss: 0.652569 | Val. Kappa Score: 0.5509 | LR: 0.001500 | Estimated time: 461.63
Train loss on 50 batch: 0.421732
Train loss on 100 batch: 0.426667
Train loss on 150 batch: 0.474011
Train loss on 200 batch: 0.426539
Train loss on 250 batch: 0.505797
Train loss on 300 batch: 0.426307
Train loss on 350 batch: 0.384592
Train loss on 400 batch: 0.416537
Train loss on 450 batch: 0.374452
Train loss on 500 batch: 0.462574
Train loss on 550 batch: 0.473438
Train loss on 600 batch: 0.455457
Train loss on 650 batch: 0.370779
Train loss on 700 batch: 0.499515
Train loss on 750 batch: 0.436833
Train loss on 800 batch: 0.434075
Train loss on 850 batch: 0.433783
Train loss on 900 batch: 0.372601
Train loss on 950 batch: 0.366877
Train loss on 1000 batch: 0.398045
Train loss on 1050 batch: 0.485959
Train loss on 1100 batch: 0.491065
Train loss on 1150 batch: 0.404838
Train loss on 1200 batch: 0.455366
Train loss on 1250 batch: 0.444003
Train loss on 1300 batch: 0.399407
Train loss on 1350 batch: 0.407630
Train loss on 1400 batch: 0.377269
Train loss on 1450 batch: 0.376189
Train loss on 1500 batch: 0.493946
Train loss on 1550 batch: 0.408821
Train loss on 1600 batch: 0.433636
Train loss on 1650 batch: 0.451848
best-train-loss: 0.430409
best-valid-loss: 0.462852
best-kappa: 0.5632
: Epoch: 9 | Training Loss: 0.430409 | Val. Loss: 0.462852 | Val. Kappa Score: 0.5632 | LR: 0.001500 | Estimated time: 461.65
Train loss on 50 batch: 0.410522
Train loss on 100 batch: 0.505597
Train loss on 150 batch: 0.373430
Train loss on 200 batch: 0.410083
Train loss on 250 batch: 0.408943
Train loss on 300 batch: 0.394166
Train loss on 350 batch: 0.419843
Train loss on 400 batch: 0.456311
Train loss on 450 batch: 0.416015
Train loss on 500 batch: 0.392931
Train loss on 550 batch: 0.425115
Train loss on 600 batch: 0.458977
Train loss on 650 batch: 0.405953
Train loss on 700 batch: 0.462424
Train loss on 750 batch: 0.385072
Train loss on 800 batch: 0.436011
Train loss on 850 batch: 0.369688
Train loss on 900 batch: 0.436589
Train loss on 950 batch: 0.487243
Train loss on 1000 batch: 0.463508
Train loss on 1050 batch: 0.390553
Train loss on 1100 batch: 0.403599
Train loss on 1150 batch: 0.500608
Train loss on 1200 batch: 0.426274
Train loss on 1250 batch: 0.430576
Train loss on 1300 batch: 0.395354
Train loss on 1350 batch: 0.419024
Train loss on 1400 batch: 0.436060
Train loss on 1450 batch: 0.422566
Train loss on 1500 batch: 0.447555
Train loss on 1550 batch: 0.434149
Train loss on 1600 batch: 0.423507
Train loss on 1650 batch: 0.358478
best-train-loss: 0.423830
best-valid-loss: 0.442886
best-kappa: 0.5754
: Epoch: 10 | Training Loss: 0.423830 | Val. Loss: 0.442886 | Val. Kappa Score: 0.5754 | LR: 0.001500 | Estimated time: 462.01
Train loss on 50 batch: 0.414730
Train loss on 100 batch: 0.419021
Train loss on 150 batch: 0.452992
Train loss on 200 batch: 0.372096
Train loss on 250 batch: 0.444589
Train loss on 300 batch: 0.342886
Train loss on 350 batch: 0.358391
Train loss on 400 batch: 0.397287
Train loss on 450 batch: 0.402856
Train loss on 500 batch: 0.396299
Train loss on 550 batch: 0.439280
Train loss on 600 batch: 0.430047
Train loss on 650 batch: 0.423762
Train loss on 700 batch: 0.454194
Train loss on 750 batch: 0.515818
Train loss on 800 batch: 0.437655
Train loss on 850 batch: 0.464174
Train loss on 900 batch: 0.421976
Train loss on 950 batch: 0.399205
Train loss on 1000 batch: 0.421942
Train loss on 1050 batch: 0.434064
Train loss on 1100 batch: 0.416506
Train loss on 1150 batch: 0.353972
Train loss on 1200 batch: 0.366965
Train loss on 1250 batch: 0.405055
Train loss on 1300 batch: 0.421618
Train loss on 1350 batch: 0.395885
Train loss on 1400 batch: 0.411295
Train loss on 1450 batch: 0.415831
Train loss on 1500 batch: 0.487382
Train loss on 1550 batch: 0.437569
Train loss on 1600 batch: 0.389233
Train loss on 1650 batch: 0.365602
: Epoch: 11 | Training Loss: 0.414821 | Val. Loss: 0.515864 | Val. Kappa Score: 0.5838 | LR: 0.001500 | Estimated time: 461.30
Train loss on 50 batch: 0.372841
Train loss on 100 batch: 0.406205
Train loss on 150 batch: 0.349280
Train loss on 200 batch: 0.424337
Train loss on 250 batch: 0.406994
Train loss on 300 batch: 0.405829
Train loss on 350 batch: 0.368869
Train loss on 400 batch: 0.383359
Train loss on 450 batch: 0.378509
Train loss on 500 batch: 0.395843
Train loss on 550 batch: 0.357309
Train loss on 600 batch: 0.390145
Train loss on 650 batch: 0.384272
Train loss on 700 batch: 0.435959
Train loss on 750 batch: 0.404850
Train loss on 800 batch: 0.405774
Train loss on 850 batch: 0.385455
Train loss on 900 batch: 0.344430
Train loss on 950 batch: 0.451573
Train loss on 1000 batch: 0.421855
Train loss on 1050 batch: 0.413228
Train loss on 1100 batch: 0.380481
Train loss on 1150 batch: 0.409365
Train loss on 1200 batch: 0.408239
Train loss on 1250 batch: 0.442668
Train loss on 1300 batch: 0.425230
Train loss on 1350 batch: 0.406922
Train loss on 1400 batch: 0.441928
Train loss on 1450 batch: 0.420905
Train loss on 1500 batch: 0.408911
Train loss on 1550 batch: 0.421882
Train loss on 1600 batch: 0.403396
Train loss on 1650 batch: 0.402377
: Epoch: 12 | Training Loss: 0.402701 | Val. Loss: 0.450343 | Val. Kappa Score: 0.5913 | LR: 0.001500 | Estimated time: 462.06
Train loss on 50 batch: 0.376037
Train loss on 100 batch: 0.411988
Train loss on 150 batch: 0.394248
Train loss on 200 batch: 0.472537
Train loss on 250 batch: 0.374760
Train loss on 300 batch: 0.418359
Train loss on 350 batch: 0.461916
Train loss on 400 batch: 0.399229
Train loss on 450 batch: 0.385383
Train loss on 500 batch: 0.345177
Train loss on 550 batch: 0.418784
Train loss on 600 batch: 0.362373
Train loss on 650 batch: 0.402504
Train loss on 700 batch: 0.425774
Train loss on 750 batch: 0.401780
Train loss on 800 batch: 0.424243
Train loss on 850 batch: 0.426574
Train loss on 900 batch: 0.433908
Train loss on 950 batch: 0.390395
Train loss on 1000 batch: 0.424596
Train loss on 1050 batch: 0.404943
Train loss on 1100 batch: 0.341349
Train loss on 1150 batch: 0.388375
Train loss on 1200 batch: 0.444196
Train loss on 1250 batch: 0.391273
Train loss on 1300 batch: 0.452089
Train loss on 1350 batch: 0.396794
Train loss on 1400 batch: 0.454864
Train loss on 1450 batch: 0.431439
Train loss on 1500 batch: 0.396256
Train loss on 1550 batch: 0.422575
Train loss on 1600 batch: 0.397873
Train loss on 1650 batch: 0.456675
: Epoch: 13 | Training Loss: 0.409404 | Val. Loss: 0.455691 | Val. Kappa Score: 0.5996 | LR: 0.000750 | Estimated time: 461.83
Train loss on 50 batch: 0.367892
Train loss on 100 batch: 0.405490
Train loss on 150 batch: 0.428850
Train loss on 200 batch: 0.361525
Train loss on 250 batch: 0.368724
Train loss on 300 batch: 0.416412
Train loss on 350 batch: 0.343662
Train loss on 400 batch: 0.406368
Train loss on 450 batch: 0.324926
Train loss on 500 batch: 0.366470
Train loss on 550 batch: 0.324342
Train loss on 600 batch: 0.407692
Train loss on 650 batch: 0.383401
Train loss on 700 batch: 0.360336
Train loss on 750 batch: 0.370700
Train loss on 800 batch: 0.376341
Train loss on 850 batch: 0.380895
Train loss on 900 batch: 0.384035
Train loss on 950 batch: 0.392130
Train loss on 1000 batch: 0.354148
Train loss on 1050 batch: 0.343111
Train loss on 1100 batch: 0.395790
Train loss on 1150 batch: 0.408695
Train loss on 1200 batch: 0.363457
Train loss on 1250 batch: 0.350467
Train loss on 1300 batch: 0.339666
Train loss on 1350 batch: 0.404466
Train loss on 1400 batch: 0.333341
Train loss on 1450 batch: 0.371416
Train loss on 1500 batch: 0.377791
Train loss on 1550 batch: 0.347710
Train loss on 1600 batch: 0.341264
Train loss on 1650 batch: 0.341201
best-train-loss: 0.371471
best-valid-loss: 0.427563
best-kappa: 0.6066
: Epoch: 14 | Training Loss: 0.371471 | Val. Loss: 0.427563 | Val. Kappa Score: 0.6066 | LR: 0.000750 | Estimated time: 461.94
Train loss on 50 batch: 0.280143
Train loss on 100 batch: 0.366266
Train loss on 150 batch: 0.332560
Train loss on 200 batch: 0.332856
Train loss on 250 batch: 0.377590
Train loss on 300 batch: 0.363129
Train loss on 350 batch: 0.359927
Train loss on 400 batch: 0.404456
Train loss on 450 batch: 0.369239
Train loss on 500 batch: 0.378146
Train loss on 550 batch: 0.402306
Train loss on 600 batch: 0.398899
Train loss on 650 batch: 0.405741
Train loss on 700 batch: 0.383760
Train loss on 750 batch: 0.354752
Train loss on 800 batch: 0.356473
Train loss on 850 batch: 0.385293
Train loss on 900 batch: 0.327626
Train loss on 950 batch: 0.360109
Train loss on 1000 batch: 0.347181
Train loss on 1050 batch: 0.360669
Train loss on 1100 batch: 0.396674
Train loss on 1150 batch: 0.399005
Train loss on 1200 batch: 0.311293
Train loss on 1250 batch: 0.381413
Train loss on 1300 batch: 0.370942
Train loss on 1350 batch: 0.322867
Train loss on 1400 batch: 0.385304
Train loss on 1450 batch: 0.340034
Train loss on 1500 batch: 0.380134
Train loss on 1550 batch: 0.408163
Train loss on 1600 batch: 0.345036
Train loss on 1650 batch: 0.384418
best-train-loss: 0.367248
best-valid-loss: 0.415758
best-kappa: 0.6124
: Epoch: 15 | Training Loss: 0.367248 | Val. Loss: 0.415758 | Val. Kappa Score: 0.6124 | LR: 0.000750 | Estimated time: 461.40
Train loss on 50 batch: 0.324714
Train loss on 100 batch: 0.367251
Train loss on 150 batch: 0.343443
Train loss on 200 batch: 0.362530
Train loss on 250 batch: 0.367431
Train loss on 300 batch: 0.406625
Train loss on 350 batch: 0.357792
Train loss on 400 batch: 0.431786
Train loss on 450 batch: 0.340925
Train loss on 500 batch: 0.306803
Train loss on 550 batch: 0.371442
Train loss on 600 batch: 0.411341
Train loss on 650 batch: 0.338068
Train loss on 700 batch: 0.355511
Train loss on 750 batch: 0.374173
Train loss on 800 batch: 0.347701
Train loss on 850 batch: 0.317890
Train loss on 900 batch: 0.352765
Train loss on 950 batch: 0.321763
Train loss on 1000 batch: 0.415469
Train loss on 1050 batch: 0.339628
Train loss on 1100 batch: 0.386302
Train loss on 1150 batch: 0.398799
Train loss on 1200 batch: 0.374415
Train loss on 1250 batch: 0.381836
Train loss on 1300 batch: 0.342271
Train loss on 1350 batch: 0.325330
Train loss on 1400 batch: 0.388289
Train loss on 1450 batch: 0.324583
Train loss on 1500 batch: 0.314951
Train loss on 1550 batch: 0.374334
Train loss on 1600 batch: 0.347577
Train loss on 1650 batch: 0.388753
: Epoch: 16 | Training Loss: 0.360693 | Val. Loss: 0.417115 | Val. Kappa Score: 0.6194 | LR: 0.000750 | Estimated time: 461.74
Train loss on 50 batch: 0.318631
Train loss on 100 batch: 0.333553
Train loss on 150 batch: 0.332227
Train loss on 200 batch: 0.297899
Train loss on 250 batch: 0.451812
Train loss on 300 batch: 0.363919
Train loss on 350 batch: 0.347115
Train loss on 400 batch: 0.375798
Train loss on 450 batch: 0.382703
Train loss on 500 batch: 0.314008
Train loss on 550 batch: 0.349082
Train loss on 600 batch: 0.360537
Train loss on 650 batch: 0.341578
Train loss on 700 batch: 0.363031
Train loss on 750 batch: 0.326269
Train loss on 800 batch: 0.343327
Train loss on 850 batch: 0.319586
Train loss on 900 batch: 0.398634
Train loss on 950 batch: 0.352477
Train loss on 1000 batch: 0.372237
Train loss on 1050 batch: 0.298220
Train loss on 1100 batch: 0.348611
Train loss on 1150 batch: 0.355794
Train loss on 1200 batch: 0.362847
Train loss on 1250 batch: 0.361835
Train loss on 1300 batch: 0.310591
Train loss on 1350 batch: 0.372275
Train loss on 1400 batch: 0.336067
Train loss on 1450 batch: 0.368828
Train loss on 1500 batch: 0.377551
Train loss on 1550 batch: 0.320777
Train loss on 1600 batch: 0.410086
Train loss on 1650 batch: 0.338849
: Epoch: 17 | Training Loss: 0.352850 | Val. Loss: 0.747544 | Val. Kappa Score: 0.6262 | LR: 0.000750 | Estimated time: 461.23
Train loss on 50 batch: 0.292022
Train loss on 100 batch: 0.387440
Train loss on 150 batch: 0.329754
Train loss on 200 batch: 0.318599
Train loss on 250 batch: 0.371768
Train loss on 300 batch: 0.370470
Train loss on 350 batch: 0.331989
Train loss on 400 batch: 0.366933
Train loss on 450 batch: 0.359570
Train loss on 500 batch: 0.335877
Train loss on 550 batch: 0.366142
Train loss on 600 batch: 0.315695
Train loss on 650 batch: 0.395171
Train loss on 700 batch: 0.329419
Train loss on 750 batch: 0.360210
Train loss on 800 batch: 0.392663
Train loss on 850 batch: 0.313303
Train loss on 900 batch: 0.331334
Train loss on 950 batch: 0.330704
Train loss on 1000 batch: 0.325652
Train loss on 1050 batch: 0.338555
Train loss on 1100 batch: 0.293728
Train loss on 1150 batch: 0.451626
Train loss on 1200 batch: 0.398593
Train loss on 1250 batch: 0.254075
Train loss on 1300 batch: 0.415980
Train loss on 1350 batch: 0.302262
Train loss on 1400 batch: 0.319516
Train loss on 1450 batch: 0.331351
Train loss on 1500 batch: 0.340412
Train loss on 1550 batch: 0.322824
Train loss on 1600 batch: 0.333368
Train loss on 1650 batch: 0.348755
best-train-loss: 0.344931
best-valid-loss: 0.372471
best-kappa: 0.6318
: Epoch: 18 | Training Loss: 0.344931 | Val. Loss: 0.372471 | Val. Kappa Score: 0.6318 | LR: 0.000750 | Estimated time: 461.38
Train loss on 50 batch: 0.299765
Train loss on 100 batch: 0.277475
Train loss on 150 batch: 0.381936
Train loss on 200 batch: 0.355188
Train loss on 250 batch: 0.302947
Train loss on 300 batch: 0.340701
Train loss on 350 batch: 0.390822
Train loss on 400 batch: 0.361618
Train loss on 450 batch: 0.337706
Train loss on 500 batch: 0.313888
Train loss on 550 batch: 0.473861
Train loss on 600 batch: 0.342348
Train loss on 650 batch: 0.380786
Train loss on 700 batch: 0.367188
Train loss on 750 batch: 0.357518
Train loss on 800 batch: 0.343947
Train loss on 850 batch: 0.373166
Train loss on 900 batch: 0.454262
Train loss on 950 batch: 0.350943
Train loss on 1000 batch: 0.320006
Train loss on 1050 batch: 0.318045
Train loss on 1100 batch: 0.317130
Train loss on 1150 batch: 0.356903
Train loss on 1200 batch: 0.288987
Train loss on 1250 batch: 0.336885
Train loss on 1300 batch: 0.365073
Train loss on 1350 batch: 0.322493
Train loss on 1400 batch: 0.341310
Train loss on 1450 batch: 0.357945
Train loss on 1500 batch: 0.326499
Train loss on 1550 batch: 0.354512
Train loss on 1600 batch: 0.344656
Train loss on 1650 batch: 0.361401
: Epoch: 19 | Training Loss: 0.347120 | Val. Loss: 0.430760 | Val. Kappa Score: 0.6360 | LR: 0.000750 | Estimated time: 461.54
Train loss on 50 batch: 0.336482
Train loss on 100 batch: 0.362863
Train loss on 150 batch: 0.289170
Train loss on 200 batch: 0.377018
Train loss on 250 batch: 0.312399
Train loss on 300 batch: 0.344378
Train loss on 350 batch: 0.325543
Train loss on 400 batch: 0.399195
Train loss on 450 batch: 0.316052
Train loss on 500 batch: 0.373682
Train loss on 550 batch: 0.335246
Train loss on 600 batch: 0.299468
Train loss on 650 batch: 0.374457
Train loss on 700 batch: 0.341988
Train loss on 750 batch: 0.364041
Train loss on 800 batch: 0.353519
Train loss on 850 batch: 0.311967
Train loss on 900 batch: 0.303268
Train loss on 950 batch: 0.332459
Train loss on 1000 batch: 0.364087
Train loss on 1050 batch: 0.344117
Train loss on 1100 batch: 0.366510
Train loss on 1150 batch: 0.388524
Train loss on 1200 batch: 0.385018
Train loss on 1250 batch: 0.308856
Train loss on 1300 batch: 0.336375
Train loss on 1350 batch: 0.370821
Train loss on 1400 batch: 0.379484
Train loss on 1450 batch: 0.340243
Train loss on 1500 batch: 0.389632
Train loss on 1550 batch: 0.340915
Train loss on 1600 batch: 0.331502
Train loss on 1650 batch: 0.354672
: Epoch: 20 | Training Loss: 0.345640 | Val. Loss: 0.394865 | Val. Kappa Score: 0.6399 | LR: 0.000750 | Estimated time: 461.31
Train loss on 50 batch: 0.303430
Train loss on 100 batch: 0.290834
Train loss on 150 batch: 0.385624
Train loss on 200 batch: 0.322750
Train loss on 250 batch: 0.343046
Train loss on 300 batch: 0.285126
Train loss on 350 batch: 0.357615
Train loss on 400 batch: 0.323939
Train loss on 450 batch: 0.344227
Train loss on 500 batch: 0.298361
Train loss on 550 batch: 0.309736
Train loss on 600 batch: 0.383779
Train loss on 650 batch: 0.340754
Train loss on 700 batch: 0.368589
Train loss on 750 batch: 0.296870
Train loss on 800 batch: 0.321260
Train loss on 850 batch: 0.348405
Train loss on 900 batch: 0.299561
Train loss on 950 batch: 0.349080
Train loss on 1000 batch: 0.333214
Train loss on 1050 batch: 0.353455
Train loss on 1100 batch: 0.371583
Train loss on 1150 batch: 0.348075
Train loss on 1200 batch: 0.345195
Train loss on 1250 batch: 0.319157
Train loss on 1300 batch: 0.316323
Train loss on 1350 batch: 0.310971
Train loss on 1400 batch: 0.336122
Train loss on 1450 batch: 0.395013
Train loss on 1500 batch: 0.346421
Train loss on 1550 batch: 0.374462
Train loss on 1600 batch: 0.310381
Train loss on 1650 batch: 0.351164
: Epoch: 21 | Training Loss: 0.335445 | Val. Loss: 0.375355 | Val. Kappa Score: 0.6446 | LR: 0.000375 | Estimated time: 461.57
Train loss on 50 batch: 0.327939
Train loss on 100 batch: 0.290927
Train loss on 150 batch: 0.358878
Train loss on 200 batch: 0.313507
Train loss on 250 batch: 0.324129
Train loss on 300 batch: 0.334905
Train loss on 350 batch: 0.285005
Train loss on 400 batch: 0.354516
Train loss on 450 batch: 0.304931
Train loss on 500 batch: 0.303656
Train loss on 550 batch: 0.313989
Train loss on 600 batch: 0.294136
Train loss on 650 batch: 0.333427
Train loss on 700 batch: 0.364795
Train loss on 750 batch: 0.275186
Train loss on 800 batch: 0.376369
Train loss on 850 batch: 0.302547
Train loss on 900 batch: 0.313671
Train loss on 950 batch: 0.303968
Train loss on 1000 batch: 0.275115
Train loss on 1050 batch: 0.345435
Train loss on 1100 batch: 0.327585
Train loss on 1150 batch: 0.334828
Train loss on 1200 batch: 0.352744
Train loss on 1250 batch: 0.327708
Train loss on 1300 batch: 0.344076
Train loss on 1350 batch: 0.335336
Train loss on 1400 batch: 0.322505
Train loss on 1450 batch: 0.362562
Train loss on 1500 batch: 0.333743
Train loss on 1550 batch: 0.334592
Train loss on 1600 batch: 0.352473
Train loss on 1650 batch: 0.350081
best-train-loss: 0.325928
best-valid-loss: 0.371598
best-kappa: 0.6486
: Epoch: 22 | Training Loss: 0.325928 | Val. Loss: 0.371598 | Val. Kappa Score: 0.6486 | LR: 0.000375 | Estimated time: 462.00
Train loss on 50 batch: 0.307079
Train loss on 100 batch: 0.260218
Train loss on 150 batch: 0.309457
Train loss on 200 batch: 0.284488
Train loss on 250 batch: 0.307543
Train loss on 300 batch: 0.338056
Train loss on 350 batch: 0.288140
Train loss on 400 batch: 0.296532
Train loss on 450 batch: 0.268840
Train loss on 500 batch: 0.317418
Train loss on 550 batch: 0.326029
Train loss on 600 batch: 0.289786
Train loss on 650 batch: 0.344042
Train loss on 700 batch: 0.332716
Train loss on 750 batch: 0.280497
Train loss on 800 batch: 0.293637
Train loss on 850 batch: 0.317432
Train loss on 900 batch: 0.314177
Train loss on 950 batch: 0.351898
Train loss on 1000 batch: 0.324952
Train loss on 1050 batch: 0.345973
Train loss on 1100 batch: 0.351843
Train loss on 1150 batch: 0.337867
Train loss on 1200 batch: 0.308408
Train loss on 1250 batch: 0.348869
Train loss on 1300 batch: 0.335437
Train loss on 1350 batch: 0.362067
Train loss on 1400 batch: 0.330029
Train loss on 1450 batch: 0.353108
Train loss on 1500 batch: 0.353958
Train loss on 1550 batch: 0.313117
Train loss on 1600 batch: 0.300819
Train loss on 1650 batch: 0.322831
best-train-loss: 0.319156
best-valid-loss: 0.365001
best-kappa: 0.6527
: Epoch: 23 | Training Loss: 0.319156 | Val. Loss: 0.365001 | Val. Kappa Score: 0.6527 | LR: 0.000375 | Estimated time: 461.61
Train loss on 50 batch: 0.362218
Train loss on 100 batch: 0.341833
Train loss on 150 batch: 0.298419
Train loss on 200 batch: 0.303544
Train loss on 250 batch: 0.319557
Train loss on 300 batch: 0.350311
Train loss on 350 batch: 0.298433
Train loss on 400 batch: 0.327517
Train loss on 450 batch: 0.340012
Train loss on 500 batch: 0.307701
Train loss on 550 batch: 0.298720
Train loss on 600 batch: 0.328462
Train loss on 650 batch: 0.280977
Train loss on 700 batch: 0.298881
Train loss on 750 batch: 0.287644
Train loss on 800 batch: 0.297715
Train loss on 850 batch: 0.316676
Train loss on 900 batch: 0.315164
Train loss on 950 batch: 0.294645
Train loss on 1000 batch: 0.290010
Train loss on 1050 batch: 0.279124
Train loss on 1100 batch: 0.275487
Train loss on 1150 batch: 0.343336
Train loss on 1200 batch: 0.306746
Train loss on 1250 batch: 0.305148
Train loss on 1300 batch: 0.337735
Train loss on 1350 batch: 0.318865
Train loss on 1400 batch: 0.313870
Train loss on 1450 batch: 0.369028
Train loss on 1500 batch: 0.315495
Train loss on 1550 batch: 0.363828
Train loss on 1600 batch: 0.327580
Train loss on 1650 batch: 0.320855
best-train-loss: 0.315344
best-valid-loss: 0.359602
best-kappa: 0.6564
: Epoch: 24 | Training Loss: 0.315344 | Val. Loss: 0.359602 | Val. Kappa Score: 0.6564 | LR: 0.000375 | Estimated time: 461.09
Train loss on 50 batch: 0.298826
Train loss on 100 batch: 0.307397
Train loss on 150 batch: 0.375200
Train loss on 200 batch: 0.348355
Train loss on 250 batch: 0.320799
Train loss on 300 batch: 0.268604
Train loss on 350 batch: 0.313666
Train loss on 400 batch: 0.298608
Train loss on 450 batch: 0.295899
Train loss on 500 batch: 0.276343
Train loss on 550 batch: 0.313900
Train loss on 600 batch: 0.301365
Train loss on 650 batch: 0.316309
Train loss on 700 batch: 0.305933
Train loss on 750 batch: 0.347279
Train loss on 800 batch: 0.246089
Train loss on 850 batch: 0.319695
Train loss on 900 batch: 0.310838
Train loss on 950 batch: 0.300254
Train loss on 1000 batch: 0.286433
Train loss on 1050 batch: 0.334387
Train loss on 1100 batch: 0.299562
Train loss on 1150 batch: 0.288406
Train loss on 1200 batch: 0.385737
Train loss on 1250 batch: 0.306394
Train loss on 1300 batch: 0.270458
Train loss on 1350 batch: 0.350423
Train loss on 1400 batch: 0.343462
Train loss on 1450 batch: 0.283604
Train loss on 1500 batch: 0.332618
Train loss on 1550 batch: 0.273777
Train loss on 1600 batch: 0.330449
Train loss on 1650 batch: 0.281288
: Epoch: 25 | Training Loss: 0.309937 | Val. Loss: 0.365731 | Val. Kappa Score: 0.6593 | LR: 0.000375 | Estimated time: 461.40
Train loss on 50 batch: 0.293139
Train loss on 100 batch: 0.288328
Train loss on 150 batch: 0.292786
Train loss on 200 batch: 0.271634
Train loss on 250 batch: 0.293939
Train loss on 300 batch: 0.328082
Train loss on 350 batch: 0.318936
Train loss on 400 batch: 0.296454
Train loss on 450 batch: 0.340395
Train loss on 500 batch: 0.296676
Train loss on 550 batch: 0.269115
Train loss on 600 batch: 0.321607
Train loss on 650 batch: 0.327798
Train loss on 700 batch: 0.255753
Train loss on 750 batch: 0.292048
Train loss on 800 batch: 0.333919
Train loss on 850 batch: 0.272027
Train loss on 900 batch: 0.326355
Train loss on 950 batch: 0.308624
Train loss on 1000 batch: 0.300640
Train loss on 1050 batch: 0.337027
Train loss on 1100 batch: 0.333923
Train loss on 1150 batch: 0.315200
Train loss on 1200 batch: 0.319351
Train loss on 1250 batch: 0.329334
Train loss on 1300 batch: 0.354631
Train loss on 1350 batch: 0.288351
Train loss on 1400 batch: 0.318633
Train loss on 1450 batch: 0.270324
Train loss on 1500 batch: 0.307417
Train loss on 1550 batch: 0.295240
Train loss on 1600 batch: 0.325072
Train loss on 1650 batch: 0.340044
: Epoch: 26 | Training Loss: 0.307651 | Val. Loss: 0.361412 | Val. Kappa Score: 0.6623 | LR: 0.000375 | Estimated time: 461.29
Train loss on 50 batch: 0.259842
Train loss on 100 batch: 0.271208
Train loss on 150 batch: 0.339820
Train loss on 200 batch: 0.304125
Train loss on 250 batch: 0.341185
Train loss on 300 batch: 0.293287
Train loss on 350 batch: 0.263463
Train loss on 400 batch: 0.317702
Train loss on 450 batch: 0.269467
Train loss on 500 batch: 0.314502
Train loss on 550 batch: 0.324385
Train loss on 600 batch: 0.267604
Train loss on 650 batch: 0.333047
Train loss on 700 batch: 0.363703
Train loss on 750 batch: 0.351725
Train loss on 800 batch: 0.318608
Train loss on 850 batch: 0.257293
Train loss on 900 batch: 0.334277
Train loss on 950 batch: 0.354485
Train loss on 1000 batch: 0.290861
Train loss on 1050 batch: 0.295617
Train loss on 1100 batch: 0.344659
Train loss on 1150 batch: 0.323329
Train loss on 1200 batch: 0.288826
Train loss on 1250 batch: 0.338351
Train loss on 1300 batch: 0.349527
Train loss on 1350 batch: 0.300938
Train loss on 1400 batch: 0.261290
Train loss on 1450 batch: 0.327713
Train loss on 1500 batch: 0.322589
Train loss on 1550 batch: 0.300550
Train loss on 1600 batch: 0.322074
Train loss on 1650 batch: 0.271922
: Epoch: 27 | Training Loss: 0.308988 | Val. Loss: 0.362523 | Val. Kappa Score: 0.6643 | LR: 0.000188 | Estimated time: 461.26
Train loss on 50 batch: 0.263879
Train loss on 100 batch: 0.291357
Train loss on 150 batch: 0.342950
Train loss on 200 batch: 0.319293
Train loss on 250 batch: 0.287646
Train loss on 300 batch: 0.277123
Train loss on 350 batch: 0.260434
Train loss on 400 batch: 0.318307
Train loss on 450 batch: 0.351503
Train loss on 500 batch: 0.286143
Train loss on 550 batch: 0.302866
Train loss on 600 batch: 0.291272
Train loss on 650 batch: 0.294993
Train loss on 700 batch: 0.296445
Train loss on 750 batch: 0.365751
Train loss on 800 batch: 0.331582
Train loss on 850 batch: 0.302895
Train loss on 900 batch: 0.346580
Train loss on 950 batch: 0.306145
Train loss on 1000 batch: 0.296186
Train loss on 1050 batch: 0.298683
Train loss on 1100 batch: 0.276655
Train loss on 1150 batch: 0.296485
Train loss on 1200 batch: 0.302026
Train loss on 1250 batch: 0.297687
Train loss on 1300 batch: 0.323651
Train loss on 1350 batch: 0.278319
Train loss on 1400 batch: 0.385547
Train loss on 1450 batch: 0.280257
Train loss on 1500 batch: 0.301397
Train loss on 1550 batch: 0.300609
Train loss on 1600 batch: 0.279847
Train loss on 1650 batch: 0.288207
best-train-loss: 0.303921
best-valid-loss: 0.350907
best-kappa: 0.6668
: Epoch: 28 | Training Loss: 0.303921 | Val. Loss: 0.350907 | Val. Kappa Score: 0.6668 | LR: 0.000188 | Estimated time: 461.44
Train loss on 50 batch: 0.272846
Train loss on 100 batch: 0.300753
Train loss on 150 batch: 0.282556
Train loss on 200 batch: 0.324471
Train loss on 250 batch: 0.310295
Train loss on 300 batch: 0.280513
Train loss on 350 batch: 0.252675
Train loss on 400 batch: 0.305376
Train loss on 450 batch: 0.310644
Train loss on 500 batch: 0.287727
Train loss on 550 batch: 0.273346
Train loss on 600 batch: 0.301617
Train loss on 650 batch: 0.259230
Train loss on 700 batch: 0.338655
Train loss on 750 batch: 0.313145
Train loss on 800 batch: 0.279166
Train loss on 850 batch: 0.330471
Train loss on 900 batch: 0.333334
Train loss on 950 batch: 0.286262
Train loss on 1000 batch: 0.336766
Train loss on 1050 batch: 0.284373
Train loss on 1100 batch: 0.332033
Train loss on 1150 batch: 0.274075
Train loss on 1200 batch: 0.342399
Train loss on 1250 batch: 0.290394
Train loss on 1300 batch: 0.300629
Train loss on 1350 batch: 0.279089
Train loss on 1400 batch: 0.285962
Train loss on 1450 batch: 0.310498
Train loss on 1500 batch: 0.309968
Train loss on 1550 batch: 0.275266
Train loss on 1600 batch: 0.292159
Train loss on 1650 batch: 0.276874
: Epoch: 29 | Training Loss: 0.296638 | Val. Loss: 0.358282 | Val. Kappa Score: 0.6694 | LR: 0.000188 | Estimated time: 461.16
Train loss on 50 batch: 0.312483
Train loss on 100 batch: 0.259188
Train loss on 150 batch: 0.289472
Train loss on 200 batch: 0.316315
Train loss on 250 batch: 0.317249
Train loss on 300 batch: 0.278729
Train loss on 350 batch: 0.273478
Train loss on 400 batch: 0.291519
Train loss on 450 batch: 0.331127
Train loss on 500 batch: 0.269856
Train loss on 550 batch: 0.298612
Train loss on 600 batch: 0.338927
Train loss on 650 batch: 0.269281
Train loss on 700 batch: 0.253632
Train loss on 750 batch: 0.260152
Train loss on 800 batch: 0.313069
Train loss on 850 batch: 0.312325
Train loss on 900 batch: 0.282573
Train loss on 950 batch: 0.304082
Train loss on 1000 batch: 0.284574
Train loss on 1050 batch: 0.262215
Train loss on 1100 batch: 0.291090
Train loss on 1150 batch: 0.341758
Train loss on 1200 batch: 0.303048
Train loss on 1250 batch: 0.296534
Train loss on 1300 batch: 0.290738
Train loss on 1350 batch: 0.285294
Train loss on 1400 batch: 0.329622
Train loss on 1450 batch: 0.326197
Train loss on 1500 batch: 0.302488
Train loss on 1550 batch: 0.262246
Train loss on 1600 batch: 0.289655
Train loss on 1650 batch: 0.370496
best-train-loss: 0.297677
best-valid-loss: 0.344714
best-kappa: 0.6718
: Epoch: 30 | Training Loss: 0.297677 | Val. Loss: 0.344714 | Val. Kappa Score: 0.6718 | LR: 0.000188 | Estimated time: 461.51
time_estimated: 13852.03
----------------------------------------

Experiment N: 52: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0003, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.12 00:10:31
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0003
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e8fe80>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 30
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.326372
Train loss on 100 batch: 0.312899
Train loss on 150 batch: 0.299845
Train loss on 200 batch: 0.300944
Train loss on 250 batch: 0.309515
Train loss on 300 batch: 0.302992
Train loss on 350 batch: 0.339198
Train loss on 400 batch: 0.285360
Train loss on 450 batch: 0.334446
Train loss on 500 batch: 0.295129
Train loss on 550 batch: 0.295321
Train loss on 600 batch: 0.265123
Train loss on 650 batch: 0.265804
Train loss on 700 batch: 0.273656
Train loss on 750 batch: 0.295813
Train loss on 800 batch: 0.286399
Train loss on 850 batch: 0.262216
Train loss on 900 batch: 0.303850
Train loss on 950 batch: 0.347048
Train loss on 1000 batch: 0.261975
Train loss on 1050 batch: 0.301876
Train loss on 1100 batch: 0.297655
Train loss on 1150 batch: 0.293897
Train loss on 1200 batch: 0.307359
Train loss on 1250 batch: 0.301032
Train loss on 1300 batch: 0.303244
Train loss on 1350 batch: 0.308944
Train loss on 1400 batch: 0.317414
Train loss on 1450 batch: 0.315139
Train loss on 1500 batch: 0.273261
Train loss on 1550 batch: 0.304876
Train loss on 1600 batch: 0.258988
Train loss on 1650 batch: 0.263254
best-train-loss: 0.297375
best-valid-loss: 0.358518
best-kappa: 0.7377
: Epoch: 1 | Training Loss: 0.297375 | Val. Loss: 0.358518 | Val. Kappa Score: 0.7377 | LR: 0.000300 | Estimated time: 482.84
Train loss on 50 batch: 0.317673
Train loss on 100 batch: 0.255782
Train loss on 150 batch: 0.264004
Train loss on 200 batch: 0.356689
Train loss on 250 batch: 0.331927
Train loss on 300 batch: 0.224165
Train loss on 350 batch: 0.323956
Train loss on 400 batch: 0.292873
Train loss on 450 batch: 0.301467
Train loss on 500 batch: 0.276441
Train loss on 550 batch: 0.268523
Train loss on 600 batch: 0.300877
Train loss on 650 batch: 0.302417
Train loss on 700 batch: 0.264063
Train loss on 750 batch: 0.326712
Train loss on 800 batch: 0.337714
Train loss on 850 batch: 0.300657
Train loss on 900 batch: 0.347229
Train loss on 950 batch: 0.322116
Train loss on 1000 batch: 0.287507
Train loss on 1050 batch: 0.323510
Train loss on 1100 batch: 0.266120
Train loss on 1150 batch: 0.289938
Train loss on 1200 batch: 0.279589
Train loss on 1250 batch: 0.293502
Train loss on 1300 batch: 0.278328
Train loss on 1350 batch: 0.264916
Train loss on 1400 batch: 0.272957
Train loss on 1450 batch: 0.278417
Train loss on 1500 batch: 0.272154
Train loss on 1550 batch: 0.319335
Train loss on 1600 batch: 0.312111
Train loss on 1650 batch: 0.294830
: Epoch: 2 | Training Loss: 0.296450 | Val. Loss: 0.366291 | Val. Kappa Score: 0.7363 | LR: 0.000300 | Estimated time: 470.82
Train loss on 50 batch: 0.271109
Train loss on 100 batch: 0.289313
Train loss on 150 batch: 0.317286
Train loss on 200 batch: 0.258604
Train loss on 250 batch: 0.252990
Train loss on 300 batch: 0.310440
Train loss on 350 batch: 0.293402
Train loss on 400 batch: 0.314926
Train loss on 450 batch: 0.314490
Train loss on 500 batch: 0.250186
Train loss on 550 batch: 0.301133
Train loss on 600 batch: 0.294510
Train loss on 650 batch: 0.256398
Train loss on 700 batch: 0.289861
Train loss on 750 batch: 0.311639
Train loss on 800 batch: 0.359226
Train loss on 850 batch: 0.311304
Train loss on 900 batch: 0.285649
Train loss on 950 batch: 0.329797
Train loss on 1000 batch: 0.311369
Train loss on 1050 batch: 0.302812
Train loss on 1100 batch: 0.282835
Train loss on 1150 batch: 0.252552
Train loss on 1200 batch: 0.293481
Train loss on 1250 batch: 0.290111
Train loss on 1300 batch: 0.281816
Train loss on 1350 batch: 0.291925
Train loss on 1400 batch: 0.317423
Train loss on 1450 batch: 0.256495
Train loss on 1500 batch: 0.280326
Train loss on 1550 batch: 0.296893
Train loss on 1600 batch: 0.314427
Train loss on 1650 batch: 0.277646
: Epoch: 3 | Training Loss: 0.292391 | Val. Loss: 0.358747 | Val. Kappa Score: 0.7382 | LR: 0.000300 | Estimated time: 499.35
Train loss on 50 batch: 0.296300
Train loss on 100 batch: 0.301942
Train loss on 150 batch: 0.284007
Train loss on 200 batch: 0.251192
Train loss on 250 batch: 0.299157
Train loss on 300 batch: 0.277278
Train loss on 350 batch: 0.320510
Train loss on 400 batch: 0.311561
Train loss on 450 batch: 0.314941
Train loss on 500 batch: 0.301771
Train loss on 550 batch: 0.261608
Train loss on 600 batch: 0.249313
Train loss on 650 batch: 0.328114
Train loss on 700 batch: 0.316117
Train loss on 750 batch: 0.281203
Train loss on 800 batch: 0.301854
Train loss on 850 batch: 0.305010
Train loss on 900 batch: 0.316300
Train loss on 950 batch: 0.319199
Train loss on 1000 batch: 0.273856
Train loss on 1050 batch: 0.271990
Train loss on 1100 batch: 0.300694
Train loss on 1150 batch: 0.269935
Train loss on 1200 batch: 0.290153
Train loss on 1250 batch: 0.281732
Train loss on 1300 batch: 0.303639
Train loss on 1350 batch: 0.340341
Train loss on 1400 batch: 0.278761
Train loss on 1450 batch: 0.295070
Train loss on 1500 batch: 0.301389
Train loss on 1550 batch: 0.262662
Train loss on 1600 batch: 0.266819
Train loss on 1650 batch: 0.294642
best-train-loss: 0.293171
best-valid-loss: 0.356866
best-kappa: 0.7385
: Epoch: 4 | Training Loss: 0.293171 | Val. Loss: 0.356866 | Val. Kappa Score: 0.7385 | LR: 0.000300 | Estimated time: 495.66
Train loss on 50 batch: 0.314496
Train loss on 100 batch: 0.296405
Train loss on 150 batch: 0.280537
Train loss on 200 batch: 0.280554
Train loss on 250 batch: 0.256703
Train loss on 300 batch: 0.295842
Train loss on 350 batch: 0.282063
Train loss on 400 batch: 0.258756
Train loss on 450 batch: 0.317384
Train loss on 500 batch: 0.258460
Train loss on 550 batch: 0.302377
Train loss on 600 batch: 0.251533
Train loss on 650 batch: 0.271031
Train loss on 700 batch: 0.258030
Train loss on 750 batch: 0.300977
Train loss on 800 batch: 0.263990
Train loss on 850 batch: 0.323983
Train loss on 900 batch: 0.279123
Train loss on 950 batch: 0.299765
Train loss on 1000 batch: 0.316813
Train loss on 1050 batch: 0.317409
Train loss on 1100 batch: 0.324115
Train loss on 1150 batch: 0.260280
Train loss on 1200 batch: 0.301256
Train loss on 1250 batch: 0.311127
Train loss on 1300 batch: 0.305564
Train loss on 1350 batch: 0.255651
Train loss on 1400 batch: 0.305322
Train loss on 1450 batch: 0.275206
Train loss on 1500 batch: 0.290662
Train loss on 1550 batch: 0.293399
Train loss on 1600 batch: 0.317770
Train loss on 1650 batch: 0.320943
best-train-loss: 0.289939
best-valid-loss: 0.354099
best-kappa: 0.7402
: Epoch: 5 | Training Loss: 0.289939 | Val. Loss: 0.354099 | Val. Kappa Score: 0.7402 | LR: 0.000300 | Estimated time: 470.91
Train loss on 50 batch: 0.342185
Train loss on 100 batch: 0.221531
Train loss on 150 batch: 0.284672
Train loss on 200 batch: 0.283841
Train loss on 250 batch: 0.246291
Train loss on 300 batch: 0.268930
Train loss on 350 batch: 0.297575
Train loss on 400 batch: 0.261415
Train loss on 450 batch: 0.329513
Train loss on 500 batch: 0.300223
Train loss on 550 batch: 0.318893
Train loss on 600 batch: 0.254617
Train loss on 650 batch: 0.258703
Train loss on 700 batch: 0.284461
Train loss on 750 batch: 0.310061
Train loss on 800 batch: 0.274002
Train loss on 850 batch: 0.280490
Train loss on 900 batch: 0.287598
Train loss on 950 batch: 0.232263
Train loss on 1000 batch: 0.225303
Train loss on 1050 batch: 0.283240
Train loss on 1100 batch: 0.340347
Train loss on 1150 batch: 0.280612
Train loss on 1200 batch: 0.327463
Train loss on 1250 batch: 0.287216
Train loss on 1300 batch: 0.282896
Train loss on 1350 batch: 0.287922
Train loss on 1400 batch: 0.301859
Train loss on 1450 batch: 0.282145
Train loss on 1500 batch: 0.306979
Train loss on 1550 batch: 0.307219
Train loss on 1600 batch: 0.280980
Train loss on 1650 batch: 0.279636
: Epoch: 6 | Training Loss: 0.285119 | Val. Loss: 0.368312 | Val. Kappa Score: 0.7402 | LR: 0.000300 | Estimated time: 481.36
Train loss on 50 batch: 0.300000
Train loss on 100 batch: 0.303469
Train loss on 150 batch: 0.303671
Train loss on 200 batch: 0.259718
Train loss on 250 batch: 0.287582
Train loss on 300 batch: 0.274249
Train loss on 350 batch: 0.292663
Train loss on 400 batch: 0.322660
Train loss on 450 batch: 0.253733
Train loss on 500 batch: 0.285401
Train loss on 550 batch: 0.321995
Train loss on 600 batch: 0.301058
Train loss on 650 batch: 0.304205
Train loss on 700 batch: 0.285441
Train loss on 750 batch: 0.247889
Train loss on 800 batch: 0.271700
Train loss on 850 batch: 0.230372
Train loss on 900 batch: 0.287028
Train loss on 950 batch: 0.274691
Train loss on 1000 batch: 0.252956
Train loss on 1050 batch: 0.276556
Train loss on 1100 batch: 0.345673
Train loss on 1150 batch: 0.277347
Train loss on 1200 batch: 0.269385
Train loss on 1250 batch: 0.249749
Train loss on 1300 batch: 0.286218
Train loss on 1350 batch: 0.266159
Train loss on 1400 batch: 0.324307
Train loss on 1450 batch: 0.236240
Train loss on 1500 batch: 0.279419
Train loss on 1550 batch: 0.232282
Train loss on 1600 batch: 0.249411
Train loss on 1650 batch: 0.294075
best-train-loss: 0.280097
best-valid-loss: 0.352909
best-kappa: 0.7404
: Epoch: 7 | Training Loss: 0.280097 | Val. Loss: 0.352909 | Val. Kappa Score: 0.7404 | LR: 0.000300 | Estimated time: 462.42
Train loss on 50 batch: 0.306935
Train loss on 100 batch: 0.244364
Train loss on 150 batch: 0.336265
Train loss on 200 batch: 0.254365
Train loss on 250 batch: 0.293009
Train loss on 300 batch: 0.314996
Train loss on 350 batch: 0.288198
Train loss on 400 batch: 0.277355
Train loss on 450 batch: 0.286312
Train loss on 500 batch: 0.236396
Train loss on 550 batch: 0.249932
Train loss on 600 batch: 0.304984
Train loss on 650 batch: 0.308644
Train loss on 700 batch: 0.286815
Train loss on 750 batch: 0.286492
Train loss on 800 batch: 0.323019
Train loss on 850 batch: 0.280350
Train loss on 900 batch: 0.293548
Train loss on 950 batch: 0.307269
Train loss on 1000 batch: 0.269660
Train loss on 1050 batch: 0.269126
Train loss on 1100 batch: 0.309419
Train loss on 1150 batch: 0.302022
Train loss on 1200 batch: 0.271433
Train loss on 1250 batch: 0.301329
Train loss on 1300 batch: 0.294614
Train loss on 1350 batch: 0.303053
Train loss on 1400 batch: 0.298129
Train loss on 1450 batch: 0.289480
Train loss on 1500 batch: 0.307300
Train loss on 1550 batch: 0.291908
Train loss on 1600 batch: 0.247144
Train loss on 1650 batch: 0.234630
: Epoch: 8 | Training Loss: 0.285759 | Val. Loss: 0.359000 | Val. Kappa Score: 0.7406 | LR: 0.000300 | Estimated time: 462.47
Train loss on 50 batch: 0.248149
Train loss on 100 batch: 0.267215
Train loss on 150 batch: 0.331680
Train loss on 200 batch: 0.255970
Train loss on 250 batch: 0.289294
Train loss on 300 batch: 0.310456
Train loss on 350 batch: 0.259294
Train loss on 400 batch: 0.267994
Train loss on 450 batch: 0.270367
Train loss on 500 batch: 0.310606
Train loss on 550 batch: 0.315346
Train loss on 600 batch: 0.289093
Train loss on 650 batch: 0.241144
Train loss on 700 batch: 0.305212
Train loss on 750 batch: 0.273541
Train loss on 800 batch: 0.305150
Train loss on 850 batch: 0.248653
Train loss on 900 batch: 0.240487
Train loss on 950 batch: 0.224781
Train loss on 1000 batch: 0.272895
Train loss on 1050 batch: 0.289452
Train loss on 1100 batch: 0.324975
Train loss on 1150 batch: 0.281534
Train loss on 1200 batch: 0.337555
Train loss on 1250 batch: 0.312456
Train loss on 1300 batch: 0.272807
Train loss on 1350 batch: 0.252405
Train loss on 1400 batch: 0.248302
Train loss on 1450 batch: 0.247009
Train loss on 1500 batch: 0.288288
Train loss on 1550 batch: 0.286714
Train loss on 1600 batch: 0.281419
Train loss on 1650 batch: 0.273014
: Epoch: 9 | Training Loss: 0.280440 | Val. Loss: 0.353911 | Val. Kappa Score: 0.7407 | LR: 0.000300 | Estimated time: 461.50
Train loss on 50 batch: 0.268889
Train loss on 100 batch: 0.308112
Train loss on 150 batch: 0.246425
Train loss on 200 batch: 0.288615
Train loss on 250 batch: 0.302821
Train loss on 300 batch: 0.275454
Train loss on 350 batch: 0.296678
Train loss on 400 batch: 0.321246
Train loss on 450 batch: 0.245429
Train loss on 500 batch: 0.253239
Train loss on 550 batch: 0.245064
Train loss on 600 batch: 0.331886
Train loss on 650 batch: 0.249657
Train loss on 700 batch: 0.325081
Train loss on 750 batch: 0.266329
Train loss on 800 batch: 0.288802
Train loss on 850 batch: 0.260918
Train loss on 900 batch: 0.287509
Train loss on 950 batch: 0.309580
Train loss on 1000 batch: 0.314941
Train loss on 1050 batch: 0.273712
Train loss on 1100 batch: 0.250709
Train loss on 1150 batch: 0.324344
Train loss on 1200 batch: 0.233581
Train loss on 1250 batch: 0.299322
Train loss on 1300 batch: 0.220727
Train loss on 1350 batch: 0.257363
Train loss on 1400 batch: 0.308907
Train loss on 1450 batch: 0.301639
Train loss on 1500 batch: 0.281210
Train loss on 1550 batch: 0.288507
Train loss on 1600 batch: 0.261898
Train loss on 1650 batch: 0.270571
best-train-loss: 0.280158
best-valid-loss: 0.350274
best-kappa: 0.7403
: Epoch: 10 | Training Loss: 0.280158 | Val. Loss: 0.350274 | Val. Kappa Score: 0.7403 | LR: 0.000300 | Estimated time: 461.26
Train loss on 50 batch: 0.251402
Train loss on 100 batch: 0.275552
Train loss on 150 batch: 0.302292
Train loss on 200 batch: 0.255203
Train loss on 250 batch: 0.268680
Train loss on 300 batch: 0.253428
Train loss on 350 batch: 0.221980
Train loss on 400 batch: 0.254941
Train loss on 450 batch: 0.296097
Train loss on 500 batch: 0.272066
Train loss on 550 batch: 0.276809
Train loss on 600 batch: 0.264606
Train loss on 650 batch: 0.263142
Train loss on 700 batch: 0.291919
Train loss on 750 batch: 0.335518
Train loss on 800 batch: 0.289811
Train loss on 850 batch: 0.307183
Train loss on 900 batch: 0.275011
Train loss on 950 batch: 0.255067
Train loss on 1000 batch: 0.262961
Train loss on 1050 batch: 0.286498
Train loss on 1100 batch: 0.291162
Train loss on 1150 batch: 0.252929
Train loss on 1200 batch: 0.241591
Train loss on 1250 batch: 0.254586
Train loss on 1300 batch: 0.283037
Train loss on 1350 batch: 0.258571
Train loss on 1400 batch: 0.267572
Train loss on 1450 batch: 0.278865
Train loss on 1500 batch: 0.318055
Train loss on 1550 batch: 0.294766
Train loss on 1600 batch: 0.296511
Train loss on 1650 batch: 0.269089
best-train-loss: 0.274765
best-valid-loss: 0.348087
best-kappa: 0.7403
: Epoch: 11 | Training Loss: 0.274765 | Val. Loss: 0.348087 | Val. Kappa Score: 0.7403 | LR: 0.000300 | Estimated time: 477.20
Train loss on 50 batch: 0.274474
Train loss on 100 batch: 0.246073
Train loss on 150 batch: 0.227861
Train loss on 200 batch: 0.319347
Train loss on 250 batch: 0.211766
Train loss on 300 batch: 0.280511
Train loss on 350 batch: 0.257774
Train loss on 400 batch: 0.256804
Train loss on 450 batch: 0.265067
Train loss on 500 batch: 0.261150
Train loss on 550 batch: 0.263192
Train loss on 600 batch: 0.251833
Train loss on 650 batch: 0.254245
Train loss on 700 batch: 0.295454
Train loss on 750 batch: 0.268783
Train loss on 800 batch: 0.278073
Train loss on 850 batch: 0.237980
Train loss on 900 batch: 0.258670
Train loss on 950 batch: 0.276932
Train loss on 1000 batch: 0.294100
Train loss on 1050 batch: 0.267545
Train loss on 1100 batch: 0.264137
Train loss on 1150 batch: 0.265324
Train loss on 1200 batch: 0.253524
Train loss on 1250 batch: 0.273895
Train loss on 1300 batch: 0.302332
Train loss on 1350 batch: 0.266718
Train loss on 1400 batch: 0.318199
Train loss on 1450 batch: 0.284884
Train loss on 1500 batch: 0.308186
Train loss on 1550 batch: 0.244127
Train loss on 1600 batch: 0.274147
Train loss on 1650 batch: 0.279225
: Epoch: 12 | Training Loss: 0.271021 | Val. Loss: 0.349024 | Val. Kappa Score: 0.7406 | LR: 0.000300 | Estimated time: 464.31
Train loss on 50 batch: 0.275371
Train loss on 100 batch: 0.278173
Train loss on 150 batch: 0.296211
Train loss on 200 batch: 0.322610
Train loss on 250 batch: 0.249703
Train loss on 300 batch: 0.300169
Train loss on 350 batch: 0.293054
Train loss on 400 batch: 0.265541
Train loss on 450 batch: 0.257583
Train loss on 500 batch: 0.230043
Train loss on 550 batch: 0.286150
Train loss on 600 batch: 0.229083
Train loss on 650 batch: 0.253606
Train loss on 700 batch: 0.281307
Train loss on 750 batch: 0.279228
Train loss on 800 batch: 0.271110
Train loss on 850 batch: 0.253899
Train loss on 900 batch: 0.221777
Train loss on 950 batch: 0.265700
Train loss on 1000 batch: 0.265269
Train loss on 1050 batch: 0.273722
Train loss on 1100 batch: 0.241755
Train loss on 1150 batch: 0.270606
Train loss on 1200 batch: 0.289208
Train loss on 1250 batch: 0.274792
Train loss on 1300 batch: 0.281830
Train loss on 1350 batch: 0.220852
Train loss on 1400 batch: 0.308728
Train loss on 1450 batch: 0.332265
Train loss on 1500 batch: 0.276500
Train loss on 1550 batch: 0.284464
Train loss on 1600 batch: 0.279528
Train loss on 1650 batch: 0.326608
: Epoch: 13 | Training Loss: 0.272813 | Val. Loss: 0.357814 | Val. Kappa Score: 0.7405 | LR: 0.000300 | Estimated time: 463.33
Train loss on 50 batch: 0.252074
Train loss on 100 batch: 0.278201
Train loss on 150 batch: 0.295531
Train loss on 200 batch: 0.271491
Train loss on 250 batch: 0.277490
Train loss on 300 batch: 0.311699
Train loss on 350 batch: 0.233070
Train loss on 400 batch: 0.275356
Train loss on 450 batch: 0.234237
Train loss on 500 batch: 0.272002
Train loss on 550 batch: 0.242116
Train loss on 600 batch: 0.308036
Train loss on 650 batch: 0.272266
Train loss on 700 batch: 0.262896
Train loss on 750 batch: 0.256391
Train loss on 800 batch: 0.279897
Train loss on 850 batch: 0.308821
Train loss on 900 batch: 0.291167
Train loss on 950 batch: 0.290506
Train loss on 1000 batch: 0.284126
Train loss on 1050 batch: 0.276444
Train loss on 1100 batch: 0.281216
Train loss on 1150 batch: 0.282901
Train loss on 1200 batch: 0.271633
Train loss on 1250 batch: 0.274497
Train loss on 1300 batch: 0.264872
Train loss on 1350 batch: 0.293423
Train loss on 1400 batch: 0.230570
Train loss on 1450 batch: 0.269413
Train loss on 1500 batch: 0.271882
Train loss on 1550 batch: 0.272466
Train loss on 1600 batch: 0.263343
Train loss on 1650 batch: 0.256648
: Epoch: 14 | Training Loss: 0.272197 | Val. Loss: 0.352000 | Val. Kappa Score: 0.7411 | LR: 0.000150 | Estimated time: 482.91
Train loss on 50 batch: 0.198739
Train loss on 100 batch: 0.277440
Train loss on 150 batch: 0.252511
Train loss on 200 batch: 0.245912
Train loss on 250 batch: 0.256363
Train loss on 300 batch: 0.269564
Train loss on 350 batch: 0.283330
Train loss on 400 batch: 0.284786
Train loss on 450 batch: 0.247358
Train loss on 500 batch: 0.270719
Train loss on 550 batch: 0.292210
Train loss on 600 batch: 0.259217
Train loss on 650 batch: 0.286690
Train loss on 700 batch: 0.240858
Train loss on 750 batch: 0.264072
Train loss on 800 batch: 0.253456
Train loss on 850 batch: 0.281336
Train loss on 900 batch: 0.230607
Train loss on 950 batch: 0.283954
Train loss on 1000 batch: 0.264269
Train loss on 1050 batch: 0.262224
Train loss on 1100 batch: 0.277831
Train loss on 1150 batch: 0.307109
Train loss on 1200 batch: 0.226925
Train loss on 1250 batch: 0.273664
Train loss on 1300 batch: 0.283401
Train loss on 1350 batch: 0.250237
Train loss on 1400 batch: 0.297130
Train loss on 1450 batch: 0.244106
Train loss on 1500 batch: 0.265015
Train loss on 1550 batch: 0.291527
Train loss on 1600 batch: 0.248958
Train loss on 1650 batch: 0.269624
best-train-loss: 0.266346
best-valid-loss: 0.345790
best-kappa: 0.7412
: Epoch: 15 | Training Loss: 0.266346 | Val. Loss: 0.345790 | Val. Kappa Score: 0.7412 | LR: 0.000150 | Estimated time: 507.12
Train loss on 50 batch: 0.237208
Train loss on 100 batch: 0.268025
Train loss on 150 batch: 0.237837
Train loss on 200 batch: 0.249891
Train loss on 250 batch: 0.277550
Train loss on 300 batch: 0.313494
Train loss on 350 batch: 0.279380
Train loss on 400 batch: 0.303749
Train loss on 450 batch: 0.203807
Train loss on 500 batch: 0.235487
Train loss on 550 batch: 0.246338
Train loss on 600 batch: 0.308898
Train loss on 650 batch: 0.220457
Train loss on 700 batch: 0.275604
Train loss on 750 batch: 0.295329
Train loss on 800 batch: 0.266711
Train loss on 850 batch: 0.246760
Train loss on 900 batch: 0.249983
Train loss on 950 batch: 0.214019
Train loss on 1000 batch: 0.269622
Train loss on 1050 batch: 0.239582
Train loss on 1100 batch: 0.289141
Train loss on 1150 batch: 0.293417
Train loss on 1200 batch: 0.301911
Train loss on 1250 batch: 0.282852
Train loss on 1300 batch: 0.271278
Train loss on 1350 batch: 0.251165
Train loss on 1400 batch: 0.307532
Train loss on 1450 batch: 0.222440
Train loss on 1500 batch: 0.210915
Train loss on 1550 batch: 0.281467
Train loss on 1600 batch: 0.259785
Train loss on 1650 batch: 0.287124
: Epoch: 16 | Training Loss: 0.263963 | Val. Loss: 0.346616 | Val. Kappa Score: 0.7417 | LR: 0.000150 | Estimated time: 491.41
Train loss on 50 batch: 0.240549
Train loss on 100 batch: 0.247656
Train loss on 150 batch: 0.240552
Train loss on 200 batch: 0.237482
Train loss on 250 batch: 0.319685
Train loss on 300 batch: 0.275092
Train loss on 350 batch: 0.242828
Train loss on 400 batch: 0.259004
Train loss on 450 batch: 0.269624
Train loss on 500 batch: 0.240781
Train loss on 550 batch: 0.247651
Train loss on 600 batch: 0.265430
Train loss on 650 batch: 0.249690
Train loss on 700 batch: 0.240936
Train loss on 750 batch: 0.212652
Train loss on 800 batch: 0.225519
Train loss on 850 batch: 0.243737
Train loss on 900 batch: 0.286699
Train loss on 950 batch: 0.259630
Train loss on 1000 batch: 0.282252
Train loss on 1050 batch: 0.213783
Train loss on 1100 batch: 0.260476
Train loss on 1150 batch: 0.263351
Train loss on 1200 batch: 0.248003
Train loss on 1250 batch: 0.253887
Train loss on 1300 batch: 0.230392
Train loss on 1350 batch: 0.255872
Train loss on 1400 batch: 0.254075
Train loss on 1450 batch: 0.279549
Train loss on 1500 batch: 0.255423
Train loss on 1550 batch: 0.228381
Train loss on 1600 batch: 0.335427
Train loss on 1650 batch: 0.263329
: Epoch: 17 | Training Loss: 0.256173 | Val. Loss: 0.351251 | Val. Kappa Score: 0.7426 | LR: 0.000150 | Estimated time: 491.55
Train loss on 50 batch: 0.238630
Train loss on 100 batch: 0.307740
Train loss on 150 batch: 0.256588
Train loss on 200 batch: 0.242856
Train loss on 250 batch: 0.252752
Train loss on 300 batch: 0.268194
Train loss on 350 batch: 0.253421
Train loss on 400 batch: 0.287314
Train loss on 450 batch: 0.246996
Train loss on 500 batch: 0.246091
Train loss on 550 batch: 0.262814
Train loss on 600 batch: 0.216989
Train loss on 650 batch: 0.310790
Train loss on 700 batch: 0.242948
Train loss on 750 batch: 0.283035
Train loss on 800 batch: 0.322706
Train loss on 850 batch: 0.246143
Train loss on 900 batch: 0.238868
Train loss on 950 batch: 0.256342
Train loss on 1000 batch: 0.253062
Train loss on 1050 batch: 0.262932
Train loss on 1100 batch: 0.203587
Train loss on 1150 batch: 0.324003
Train loss on 1200 batch: 0.247311
Train loss on 1250 batch: 0.204455
Train loss on 1300 batch: 0.291644
Train loss on 1350 batch: 0.240502
Train loss on 1400 batch: 0.217830
Train loss on 1450 batch: 0.232308
Train loss on 1500 batch: 0.255109
Train loss on 1550 batch: 0.211743
Train loss on 1600 batch: 0.253483
Train loss on 1650 batch: 0.258958
: Epoch: 18 | Training Loss: 0.255135 | Val. Loss: 0.349296 | Val. Kappa Score: 0.7432 | LR: 0.000075 | Estimated time: 467.80
Train loss on 50 batch: 0.226302
Train loss on 100 batch: 0.204814
Train loss on 150 batch: 0.292276
Train loss on 200 batch: 0.271778
Train loss on 250 batch: 0.226908
Train loss on 300 batch: 0.234924
Train loss on 350 batch: 0.307766
Train loss on 400 batch: 0.241926
Train loss on 450 batch: 0.253579
Train loss on 500 batch: 0.205885
Train loss on 550 batch: 0.362135
Train loss on 600 batch: 0.257694
Train loss on 650 batch: 0.265799
Train loss on 700 batch: 0.273392
Train loss on 750 batch: 0.257789
Train loss on 800 batch: 0.267958
Train loss on 850 batch: 0.263482
Train loss on 900 batch: 0.323174
Train loss on 950 batch: 0.244155
Train loss on 1000 batch: 0.215894
Train loss on 1050 batch: 0.247085
Train loss on 1100 batch: 0.243518
Train loss on 1150 batch: 0.276383
Train loss on 1200 batch: 0.188506
Train loss on 1250 batch: 0.230471
Train loss on 1300 batch: 0.284759
Train loss on 1350 batch: 0.248552
Train loss on 1400 batch: 0.258130
Train loss on 1450 batch: 0.249892
Train loss on 1500 batch: 0.219348
Train loss on 1550 batch: 0.249361
Train loss on 1600 batch: 0.254428
Train loss on 1650 batch: 0.236002
: Epoch: 19 | Training Loss: 0.252774 | Val. Loss: 0.345829 | Val. Kappa Score: 0.7433 | LR: 0.000075 | Estimated time: 461.77
Train loss on 50 batch: 0.260072
Train loss on 100 batch: 0.256996
Train loss on 150 batch: 0.214573
Train loss on 200 batch: 0.249742
Train loss on 250 batch: 0.249643
Train loss on 300 batch: 0.243677
Train loss on 350 batch: 0.243938
Train loss on 400 batch: 0.292691
Train loss on 450 batch: 0.221906
Train loss on 500 batch: 0.259674
Train loss on 550 batch: 0.253273
Train loss on 600 batch: 0.235480
Train loss on 650 batch: 0.232991
Train loss on 700 batch: 0.236643
Train loss on 750 batch: 0.257489
Train loss on 800 batch: 0.262279
Train loss on 850 batch: 0.260391
Train loss on 900 batch: 0.235184
Train loss on 950 batch: 0.226003
Train loss on 1000 batch: 0.241136
Train loss on 1050 batch: 0.240383
Train loss on 1100 batch: 0.263565
Train loss on 1150 batch: 0.294940
Train loss on 1200 batch: 0.270294
Train loss on 1250 batch: 0.226422
Train loss on 1300 batch: 0.227514
Train loss on 1350 batch: 0.257119
Train loss on 1400 batch: 0.270524
Train loss on 1450 batch: 0.232308
Train loss on 1500 batch: 0.278281
Train loss on 1550 batch: 0.248668
Train loss on 1600 batch: 0.238721
Train loss on 1650 batch: 0.237106
best-train-loss: 0.248263
best-valid-loss: 0.345340
best-kappa: 0.7439
: Epoch: 20 | Training Loss: 0.248263 | Val. Loss: 0.345340 | Val. Kappa Score: 0.7439 | LR: 0.000075 | Estimated time: 462.09
Train loss on 50 batch: 0.241621
Train loss on 100 batch: 0.221899
Train loss on 150 batch: 0.313440
Train loss on 200 batch: 0.253901
Train loss on 250 batch: 0.240971
Train loss on 300 batch: 0.210013
Train loss on 350 batch: 0.260902
Train loss on 400 batch: 0.232627
Train loss on 450 batch: 0.233666
Train loss on 500 batch: 0.236267
Train loss on 550 batch: 0.237902
Train loss on 600 batch: 0.288117
Train loss on 650 batch: 0.255846
Train loss on 700 batch: 0.299088
Train loss on 750 batch: 0.233477
Train loss on 800 batch: 0.230319
Train loss on 850 batch: 0.269961
Train loss on 900 batch: 0.220317
Train loss on 950 batch: 0.243276
Train loss on 1000 batch: 0.238745
Train loss on 1050 batch: 0.280034
Train loss on 1100 batch: 0.276456
Train loss on 1150 batch: 0.273068
Train loss on 1200 batch: 0.262651
Train loss on 1250 batch: 0.246554
Train loss on 1300 batch: 0.229709
Train loss on 1350 batch: 0.220721
Train loss on 1400 batch: 0.252657
Train loss on 1450 batch: 0.297068
Train loss on 1500 batch: 0.250403
Train loss on 1550 batch: 0.275906
Train loss on 1600 batch: 0.236993
Train loss on 1650 batch: 0.243759
best-train-loss: 0.250710
best-valid-loss: 0.344407
best-kappa: 0.7445
: Epoch: 21 | Training Loss: 0.250710 | Val. Loss: 0.344407 | Val. Kappa Score: 0.7445 | LR: 0.000075 | Estimated time: 461.84
Train loss on 50 batch: 0.241792
Train loss on 100 batch: 0.232761
Train loss on 150 batch: 0.291927
Train loss on 200 batch: 0.231334
Train loss on 250 batch: 0.255877
Train loss on 300 batch: 0.264190
Train loss on 350 batch: 0.221069
Train loss on 400 batch: 0.266204
Train loss on 450 batch: 0.250287
Train loss on 500 batch: 0.239156
Train loss on 550 batch: 0.242242
Train loss on 600 batch: 0.243744
Train loss on 650 batch: 0.244660
Train loss on 700 batch: 0.279772
Train loss on 750 batch: 0.219688
Train loss on 800 batch: 0.306853
Train loss on 850 batch: 0.229191
Train loss on 900 batch: 0.251928
Train loss on 950 batch: 0.252069
Train loss on 1000 batch: 0.216281
Train loss on 1050 batch: 0.258537
Train loss on 1100 batch: 0.268473
Train loss on 1150 batch: 0.245151
Train loss on 1200 batch: 0.271015
Train loss on 1250 batch: 0.260473
Train loss on 1300 batch: 0.268722
Train loss on 1350 batch: 0.258517
Train loss on 1400 batch: 0.252773
Train loss on 1450 batch: 0.277453
Train loss on 1500 batch: 0.266200
Train loss on 1550 batch: 0.256085
Train loss on 1600 batch: 0.269748
Train loss on 1650 batch: 0.268651
best-train-loss: 0.254533
best-valid-loss: 0.343003
best-kappa: 0.7446
: Epoch: 22 | Training Loss: 0.254533 | Val. Loss: 0.343003 | Val. Kappa Score: 0.7446 | LR: 0.000075 | Estimated time: 461.12
Train loss on 50 batch: 0.247777
Train loss on 100 batch: 0.198466
Train loss on 150 batch: 0.234006
Train loss on 200 batch: 0.222095
Train loss on 250 batch: 0.236704
Train loss on 300 batch: 0.251533
Train loss on 350 batch: 0.225566
Train loss on 400 batch: 0.255474
Train loss on 450 batch: 0.207150
Train loss on 500 batch: 0.248610
Train loss on 550 batch: 0.246238
Train loss on 600 batch: 0.246207
Train loss on 650 batch: 0.260867
Train loss on 700 batch: 0.265683
Train loss on 750 batch: 0.244129
Train loss on 800 batch: 0.216756
Train loss on 850 batch: 0.219515
Train loss on 900 batch: 0.262969
Train loss on 950 batch: 0.264113
Train loss on 1000 batch: 0.269613
Train loss on 1050 batch: 0.270799
Train loss on 1100 batch: 0.272707
Train loss on 1150 batch: 0.277189
Train loss on 1200 batch: 0.238969
Train loss on 1250 batch: 0.267480
Train loss on 1300 batch: 0.282130
Train loss on 1350 batch: 0.255746
Train loss on 1400 batch: 0.264587
Train loss on 1450 batch: 0.275003
Train loss on 1500 batch: 0.274609
Train loss on 1550 batch: 0.247482
Train loss on 1600 batch: 0.244725
Train loss on 1650 batch: 0.251953
: Epoch: 23 | Training Loss: 0.250198 | Val. Loss: 0.348731 | Val. Kappa Score: 0.7450 | LR: 0.000075 | Estimated time: 461.38
Train loss on 50 batch: 0.275204
Train loss on 100 batch: 0.278927
Train loss on 150 batch: 0.230941
Train loss on 200 batch: 0.244276
Train loss on 250 batch: 0.269603
Train loss on 300 batch: 0.256137
Train loss on 350 batch: 0.240389
Train loss on 400 batch: 0.268311
Train loss on 450 batch: 0.274726
Train loss on 500 batch: 0.228036
Train loss on 550 batch: 0.244270
Train loss on 600 batch: 0.251692
Train loss on 650 batch: 0.223842
Train loss on 700 batch: 0.246240
Train loss on 750 batch: 0.223668
Train loss on 800 batch: 0.233092
Train loss on 850 batch: 0.233733
Train loss on 900 batch: 0.260849
Train loss on 950 batch: 0.237364
Train loss on 1000 batch: 0.229042
Train loss on 1050 batch: 0.224179
Train loss on 1100 batch: 0.215417
Train loss on 1150 batch: 0.274367
Train loss on 1200 batch: 0.231270
Train loss on 1250 batch: 0.238377
Train loss on 1300 batch: 0.264049
Train loss on 1350 batch: 0.236911
Train loss on 1400 batch: 0.245362
Train loss on 1450 batch: 0.299339
Train loss on 1500 batch: 0.250263
Train loss on 1550 batch: 0.292182
Train loss on 1600 batch: 0.243181
Train loss on 1650 batch: 0.243888
: Epoch: 24 | Training Loss: 0.247852 | Val. Loss: 0.343843 | Val. Kappa Score: 0.7448 | LR: 0.000075 | Estimated time: 462.27
Train loss on 50 batch: 0.229079
Train loss on 100 batch: 0.248364
Train loss on 150 batch: 0.313138
Train loss on 200 batch: 0.262153
Train loss on 250 batch: 0.262445
Train loss on 300 batch: 0.224746
Train loss on 350 batch: 0.247047
Train loss on 400 batch: 0.241695
Train loss on 450 batch: 0.229066
Train loss on 500 batch: 0.233783
Train loss on 550 batch: 0.228286
Train loss on 600 batch: 0.254063
Train loss on 650 batch: 0.248565
Train loss on 700 batch: 0.237226
Train loss on 750 batch: 0.280452
Train loss on 800 batch: 0.194255
Train loss on 850 batch: 0.246910
Train loss on 900 batch: 0.258562
Train loss on 950 batch: 0.245579
Train loss on 1000 batch: 0.227895
Train loss on 1050 batch: 0.265847
Train loss on 1100 batch: 0.236143
Train loss on 1150 batch: 0.229401
Train loss on 1200 batch: 0.276077
Train loss on 1250 batch: 0.252815
Train loss on 1300 batch: 0.207202
Train loss on 1350 batch: 0.266829
Train loss on 1400 batch: 0.263599
Train loss on 1450 batch: 0.236326
Train loss on 1500 batch: 0.248844
Train loss on 1550 batch: 0.219503
Train loss on 1600 batch: 0.279542
Train loss on 1650 batch: 0.219034
: Epoch: 25 | Training Loss: 0.246160 | Val. Loss: 0.347172 | Val. Kappa Score: 0.7448 | LR: 0.000037 | Estimated time: 461.66
Train loss on 50 batch: 0.254941
Train loss on 100 batch: 0.233437
Train loss on 150 batch: 0.230505
Train loss on 200 batch: 0.213680
Train loss on 250 batch: 0.252295
Train loss on 300 batch: 0.266948
Train loss on 350 batch: 0.265306
Train loss on 400 batch: 0.233437
Train loss on 450 batch: 0.287133
Train loss on 500 batch: 0.237742
Train loss on 550 batch: 0.217256
Train loss on 600 batch: 0.260947
Train loss on 650 batch: 0.267023
Train loss on 700 batch: 0.192065
Train loss on 750 batch: 0.257636
Train loss on 800 batch: 0.254251
Train loss on 850 batch: 0.216548
Train loss on 900 batch: 0.258221
Train loss on 950 batch: 0.251282
Train loss on 1000 batch: 0.237664
Train loss on 1050 batch: 0.255476
Train loss on 1100 batch: 0.264875
Train loss on 1150 batch: 0.247770
Train loss on 1200 batch: 0.230944
Train loss on 1250 batch: 0.272863
Train loss on 1300 batch: 0.263372
Train loss on 1350 batch: 0.231708
Train loss on 1400 batch: 0.262303
Train loss on 1450 batch: 0.225565
Train loss on 1500 batch: 0.253911
Train loss on 1550 batch: 0.226822
Train loss on 1600 batch: 0.261271
Train loss on 1650 batch: 0.267675
: Epoch: 26 | Training Loss: 0.247264 | Val. Loss: 0.345712 | Val. Kappa Score: 0.7452 | LR: 0.000037 | Estimated time: 461.63
Train loss on 50 batch: 0.202214
Train loss on 100 batch: 0.207400
Train loss on 150 batch: 0.267243
Train loss on 200 batch: 0.236295
Train loss on 250 batch: 0.283052
Train loss on 300 batch: 0.258720
Train loss on 350 batch: 0.212690
Train loss on 400 batch: 0.255464
Train loss on 450 batch: 0.215011
Train loss on 500 batch: 0.255322
Train loss on 550 batch: 0.262013
Train loss on 600 batch: 0.221863
Train loss on 650 batch: 0.260130
Train loss on 700 batch: 0.271120
Train loss on 750 batch: 0.279315
Train loss on 800 batch: 0.265336
Train loss on 850 batch: 0.208599
Train loss on 900 batch: 0.250967
Train loss on 950 batch: 0.296095
Train loss on 1000 batch: 0.222078
Train loss on 1050 batch: 0.258403
Train loss on 1100 batch: 0.269963
Train loss on 1150 batch: 0.260205
Train loss on 1200 batch: 0.237147
Train loss on 1250 batch: 0.289769
Train loss on 1300 batch: 0.265734
Train loss on 1350 batch: 0.247686
Train loss on 1400 batch: 0.217044
Train loss on 1450 batch: 0.272520
Train loss on 1500 batch: 0.249783
Train loss on 1550 batch: 0.239752
Train loss on 1600 batch: 0.257347
Train loss on 1650 batch: 0.216931
: Epoch: 27 | Training Loss: 0.248730 | Val. Loss: 0.344999 | Val. Kappa Score: 0.7449 | LR: 0.000037 | Estimated time: 461.77
Train loss on 50 batch: 0.228322
Train loss on 100 batch: 0.235212
Train loss on 150 batch: 0.283810
Train loss on 200 batch: 0.279338
Train loss on 250 batch: 0.234987
Train loss on 300 batch: 0.237111
Train loss on 350 batch: 0.215048
Train loss on 400 batch: 0.260069
Train loss on 450 batch: 0.287193
Train loss on 500 batch: 0.239165
Train loss on 550 batch: 0.254960
Train loss on 600 batch: 0.241760
Train loss on 650 batch: 0.244006
Train loss on 700 batch: 0.250214
Train loss on 750 batch: 0.297432
Train loss on 800 batch: 0.272499
Train loss on 850 batch: 0.256749
Train loss on 900 batch: 0.310696
Train loss on 950 batch: 0.241875
Train loss on 1000 batch: 0.245891
Train loss on 1050 batch: 0.244868
Train loss on 1100 batch: 0.214462
Train loss on 1150 batch: 0.249456
Train loss on 1200 batch: 0.265385
Train loss on 1250 batch: 0.253528
Train loss on 1300 batch: 0.275832
Train loss on 1350 batch: 0.231566
Train loss on 1400 batch: 0.325657
Train loss on 1450 batch: 0.261937
Train loss on 1500 batch: 0.249914
Train loss on 1550 batch: 0.242471
Train loss on 1600 batch: 0.232857
Train loss on 1650 batch: 0.228178
: Epoch: 28 | Training Loss: 0.254133 | Val. Loss: 0.343149 | Val. Kappa Score: 0.7446 | LR: 0.000019 | Estimated time: 461.48
Train loss on 50 batch: 0.219306
Train loss on 100 batch: 0.254149
Train loss on 150 batch: 0.235324
Train loss on 200 batch: 0.268766
Train loss on 250 batch: 0.268435
Train loss on 300 batch: 0.253331
Train loss on 350 batch: 0.214119
Train loss on 400 batch: 0.274186
Train loss on 450 batch: 0.255253
Train loss on 500 batch: 0.227689
Train loss on 550 batch: 0.226494
Train loss on 600 batch: 0.249802
Train loss on 650 batch: 0.210007
Train loss on 700 batch: 0.288633
Train loss on 750 batch: 0.263750
Train loss on 800 batch: 0.214762
Train loss on 850 batch: 0.264877
Train loss on 900 batch: 0.272246
Train loss on 950 batch: 0.243511
Train loss on 1000 batch: 0.271183
Train loss on 1050 batch: 0.250430
Train loss on 1100 batch: 0.284636
Train loss on 1150 batch: 0.226502
Train loss on 1200 batch: 0.275496
Train loss on 1250 batch: 0.236631
Train loss on 1300 batch: 0.247119
Train loss on 1350 batch: 0.226884
Train loss on 1400 batch: 0.232820
Train loss on 1450 batch: 0.246727
Train loss on 1500 batch: 0.267924
Train loss on 1550 batch: 0.209831
Train loss on 1600 batch: 0.238229
Train loss on 1650 batch: 0.240045
: Epoch: 29 | Training Loss: 0.246295 | Val. Loss: 0.345237 | Val. Kappa Score: 0.7449 | LR: 0.000019 | Estimated time: 461.53
Train loss on 50 batch: 0.268883
Train loss on 100 batch: 0.234868
Train loss on 150 batch: 0.242221
Train loss on 200 batch: 0.252471
Train loss on 250 batch: 0.266788
Train loss on 300 batch: 0.240928
Train loss on 350 batch: 0.222139
Train loss on 400 batch: 0.244912
Train loss on 450 batch: 0.272185
Train loss on 500 batch: 0.228290
Train loss on 550 batch: 0.251682
Train loss on 600 batch: 0.290346
Train loss on 650 batch: 0.232601
Train loss on 700 batch: 0.230034
Train loss on 750 batch: 0.217451
Train loss on 800 batch: 0.264755
Train loss on 850 batch: 0.295114
Train loss on 900 batch: 0.243499
Train loss on 950 batch: 0.253658
Train loss on 1000 batch: 0.218429
Train loss on 1050 batch: 0.207024
Train loss on 1100 batch: 0.254308
Train loss on 1150 batch: 0.302637
Train loss on 1200 batch: 0.252453
Train loss on 1250 batch: 0.248089
Train loss on 1300 batch: 0.261101
Train loss on 1350 batch: 0.252053
Train loss on 1400 batch: 0.276754
Train loss on 1450 batch: 0.249384
Train loss on 1500 batch: 0.259180
Train loss on 1550 batch: 0.228958
Train loss on 1600 batch: 0.230287
Train loss on 1650 batch: 0.321531
: Epoch: 30 | Training Loss: 0.251749 | Val. Loss: 0.343092 | Val. Kappa Score: 0.7448 | LR: 0.000019 | Estimated time: 462.31
time_estimated: 14136.30
n-epochs: 30
time_estimated: 14136.31
----------------------------------------


Experiment N: 53: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 08:40:11
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb9604e198>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.762108
best-train-loss: 0.645765
best-valid-loss: 0.506492
best-kappa: 0.8156
: Epoch: 1 | Training Loss: 0.645765 | Val. Loss: 0.506492 | Val. Kappa Score: 0.8156 | LR: 0.001000 | Estimated time: 160.80
Train loss on 50 batch: 0.436343
: Epoch: 2 | Training Loss: 0.439075 | Val. Loss: 0.566086 | Val. Kappa Score: 0.8302 | LR: 0.001000 | Estimated time: 161.86
Train loss on 50 batch: 0.351893
: Epoch: 3 | Training Loss: 0.412589 | Val. Loss: 0.642432 | Val. Kappa Score: 0.8313 | LR: 0.001000 | Estimated time: 159.14
Train loss on 50 batch: 0.392140
best-train-loss: 0.388871
best-valid-loss: 0.413565
best-kappa: 0.8301
: Epoch: 4 | Training Loss: 0.388871 | Val. Loss: 0.413565 | Val. Kappa Score: 0.8301 | LR: 0.001000 | Estimated time: 161.02
Train loss on 50 batch: 0.310240
best-train-loss: 0.314701
best-valid-loss: 0.332942
best-kappa: 0.8411
: Epoch: 5 | Training Loss: 0.314701 | Val. Loss: 0.332942 | Val. Kappa Score: 0.8411 | LR: 0.000100 | Estimated time: 160.43
Train loss on 50 batch: 0.268602
best-train-loss: 0.251013
best-valid-loss: 0.283422
best-kappa: 0.8501
: Epoch: 6 | Training Loss: 0.251013 | Val. Loss: 0.283422 | Val. Kappa Score: 0.8501 | LR: 0.000100 | Estimated time: 159.11
Train loss on 50 batch: 0.215733
best-train-loss: 0.218907
best-valid-loss: 0.276173
best-kappa: 0.8556
: Epoch: 7 | Training Loss: 0.218907 | Val. Loss: 0.276173 | Val. Kappa Score: 0.8556 | LR: 0.000100 | Estimated time: 158.80
Train loss on 50 batch: 0.210564
best-train-loss: 0.223504
best-valid-loss: 0.245058
best-kappa: 0.8605
: Epoch: 8 | Training Loss: 0.223504 | Val. Loss: 0.245058 | Val. Kappa Score: 0.8605 | LR: 0.000100 | Estimated time: 159.73
Train loss on 50 batch: 0.201041
best-train-loss: 0.204020
best-valid-loss: 0.244385
best-kappa: 0.8656
: Epoch: 9 | Training Loss: 0.204020 | Val. Loss: 0.244385 | Val. Kappa Score: 0.8656 | LR: 0.000100 | Estimated time: 160.58
Train loss on 50 batch: 0.206082
: Epoch: 10 | Training Loss: 0.193786 | Val. Loss: 0.259581 | Val. Kappa Score: 0.8690 | LR: 0.000010 | Estimated time: 158.11
Train loss on 50 batch: 0.179596
: Epoch: 11 | Training Loss: 0.190711 | Val. Loss: 0.250339 | Val. Kappa Score: 0.8725 | LR: 0.000010 | Estimated time: 158.66
Train loss on 50 batch: 0.191573
: Epoch: 12 | Training Loss: 0.183473 | Val. Loss: 0.252429 | Val. Kappa Score: 0.8753 | LR: 0.000010 | Estimated time: 159.05
Train loss on 50 batch: 0.189625
: Epoch: 13 | Training Loss: 0.201003 | Val. Loss: 0.253442 | Val. Kappa Score: 0.8777 | LR: 0.000010 | Estimated time: 158.17
Train loss on 50 batch: 0.200212
: Epoch: 14 | Training Loss: 0.200242 | Val. Loss: 0.252494 | Val. Kappa Score: 0.8793 | LR: 0.000010 | Estimated time: 159.23
Train loss on 50 batch: 0.187192
: Epoch: 15 | Training Loss: 0.190265 | Val. Loss: 0.252225 | Val. Kappa Score: 0.8807 | LR: 0.000001 | Estimated time: 158.83
Train loss on 50 batch: 0.175103
: Epoch: 16 | Training Loss: 0.175667 | Val. Loss: 0.248606 | Val. Kappa Score: 0.8819 | LR: 0.000001 | Estimated time: 158.50
Train loss on 50 batch: 0.195009
: Epoch: 17 | Training Loss: 0.174903 | Val. Loss: 0.254564 | Val. Kappa Score: 0.8828 | LR: 0.000001 | Estimated time: 159.50
time_estimated: 2711.85
n-epochs: 17
time_estimated: 2711.86
----------------------------------------

Experiment N: 54: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 09:25:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.01
    lr: 0.01
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb9604e0b8>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.597549
best-train-loss: 1.244693
best-valid-loss: 7921770.742857
best-kappa: 0.0322
: Epoch: 1 | Training Loss: 1.244693 | Val. Loss: 7921770.742857 | Val. Kappa Score: 0.0322 | LR: 0.010000 | Estimated time: 158.63
Train loss on 50 batch: 0.697826
best-train-loss: 0.648624
best-valid-loss: 2.302743
best-kappa: -0.0318
: Epoch: 2 | Training Loss: 0.648624 | Val. Loss: 2.302743 | Val. Kappa Score: -0.0318 | LR: 0.010000 | Estimated time: 160.72
Train loss on 50 batch: 0.556071
: Epoch: 3 | Training Loss: 0.603880 | Val. Loss: 7.125535 | Val. Kappa Score: -0.0907 | LR: 0.010000 | Estimated time: 159.81
Train loss on 50 batch: 0.564758
best-train-loss: 0.551304
best-valid-loss: 0.901500
best-kappa: 0.0933
: Epoch: 4 | Training Loss: 0.551304 | Val. Loss: 0.901500 | Val. Kappa Score: 0.0933 | LR: 0.010000 | Estimated time: 160.19
Train loss on 50 batch: 0.499920
best-train-loss: 0.520886
best-valid-loss: 0.541258
best-kappa: 0.2383
: Epoch: 5 | Training Loss: 0.520886 | Val. Loss: 0.541258 | Val. Kappa Score: 0.2383 | LR: 0.001000 | Estimated time: 159.49
Train loss on 50 batch: 0.415796
best-train-loss: 0.398092
best-valid-loss: 0.396679
best-kappa: 0.3415
: Epoch: 6 | Training Loss: 0.398092 | Val. Loss: 0.396679 | Val. Kappa Score: 0.3415 | LR: 0.001000 | Estimated time: 157.75
Train loss on 50 batch: 0.346193
best-train-loss: 0.349011
best-valid-loss: 0.345571
best-kappa: 0.4178
: Epoch: 7 | Training Loss: 0.349011 | Val. Loss: 0.345571 | Val. Kappa Score: 0.4178 | LR: 0.001000 | Estimated time: 159.13
Train loss on 50 batch: 0.337692
best-train-loss: 0.358087
best-valid-loss: 0.320224
best-kappa: 0.4759
: Epoch: 8 | Training Loss: 0.358087 | Val. Loss: 0.320224 | Val. Kappa Score: 0.4759 | LR: 0.001000 | Estimated time: 159.47
Train loss on 50 batch: 0.341979
best-train-loss: 0.344383
best-valid-loss: 0.314655
best-kappa: 0.5204
: Epoch: 9 | Training Loss: 0.344383 | Val. Loss: 0.314655 | Val. Kappa Score: 0.5204 | LR: 0.001000 | Estimated time: 159.43
Train loss on 50 batch: 0.329770
: Epoch: 10 | Training Loss: 0.321652 | Val. Loss: 0.317312 | Val. Kappa Score: 0.5567 | LR: 0.000100 | Estimated time: 158.19
Train loss on 50 batch: 0.319322
: Epoch: 11 | Training Loss: 0.326084 | Val. Loss: 0.316185 | Val. Kappa Score: 0.5867 | LR: 0.000100 | Estimated time: 159.20
Train loss on 50 batch: 0.313374
best-train-loss: 0.327911
best-valid-loss: 0.309481
best-kappa: 0.6118
: Epoch: 12 | Training Loss: 0.327911 | Val. Loss: 0.309481 | Val. Kappa Score: 0.6118 | LR: 0.000100 | Estimated time: 158.72
Train loss on 50 batch: 0.308355
: Epoch: 13 | Training Loss: 0.329106 | Val. Loss: 0.313038 | Val. Kappa Score: 0.6329 | LR: 0.000100 | Estimated time: 158.58
Train loss on 50 batch: 0.343935
best-train-loss: 0.325548
best-valid-loss: 0.302748
best-kappa: 0.6507
: Epoch: 14 | Training Loss: 0.325548 | Val. Loss: 0.302748 | Val. Kappa Score: 0.6507 | LR: 0.000100 | Estimated time: 159.38
Train loss on 50 batch: 0.314364
: Epoch: 15 | Training Loss: 0.323224 | Val. Loss: 0.314543 | Val. Kappa Score: 0.6661 | LR: 0.000010 | Estimated time: 158.92
Train loss on 50 batch: 0.306934
: Epoch: 16 | Training Loss: 0.300616 | Val. Loss: 0.307513 | Val. Kappa Score: 0.6796 | LR: 0.000010 | Estimated time: 158.29
Train loss on 50 batch: 0.354853
: Epoch: 17 | Training Loss: 0.308822 | Val. Loss: 0.311598 | Val. Kappa Score: 0.6911 | LR: 0.000010 | Estimated time: 160.31
Train loss on 50 batch: 0.311274
: Epoch: 18 | Training Loss: 0.292021 | Val. Loss: 0.308681 | Val. Kappa Score: 0.7019 | LR: 0.000010 | Estimated time: 159.19
Train loss on 50 batch: 0.320747
: Epoch: 19 | Training Loss: 0.306439 | Val. Loss: 0.303489 | Val. Kappa Score: 0.7114 | LR: 0.000010 | Estimated time: 163.78
Train loss on 50 batch: 0.311955
best-train-loss: 0.311250
best-valid-loss: 0.302265
best-kappa: 0.7202
: Epoch: 20 | Training Loss: 0.311250 | Val. Loss: 0.302265 | Val. Kappa Score: 0.7202 | LR: 0.000001 | Estimated time: 163.79
Train loss on 50 batch: 0.286689
: Epoch: 21 | Training Loss: 0.300232 | Val. Loss: 0.303500 | Val. Kappa Score: 0.7281 | LR: 0.000001 | Estimated time: 163.65
Train loss on 50 batch: 0.349150
: Epoch: 22 | Training Loss: 0.320357 | Val. Loss: 0.305366 | Val. Kappa Score: 0.7352 | LR: 0.000001 | Estimated time: 164.53
Train loss on 50 batch: 0.315010
: Epoch: 23 | Training Loss: 0.318707 | Val. Loss: 0.313680 | Val. Kappa Score: 0.7417 | LR: 0.000001 | Estimated time: 165.85
Train loss on 50 batch: 0.323293
: Epoch: 24 | Training Loss: 0.311098 | Val. Loss: 0.310363 | Val. Kappa Score: 0.7476 | LR: 0.000001 | Estimated time: 161.70
Train loss on 50 batch: 0.296878
: Epoch: 25 | Training Loss: 0.341885 | Val. Loss: 0.304537 | Val. Kappa Score: 0.7530 | LR: 0.000000 | Estimated time: 160.65
Train loss on 50 batch: 0.305685
: Epoch: 26 | Training Loss: 0.326310 | Val. Loss: 0.307082 | Val. Kappa Score: 0.7580 | LR: 0.000000 | Estimated time: 160.66
Train loss on 50 batch: 0.319407
: Epoch: 27 | Training Loss: 0.306006 | Val. Loss: 0.307119 | Val. Kappa Score: 0.7629 | LR: 0.000000 | Estimated time: 160.37
Train loss on 50 batch: 0.324533
: Epoch: 28 | Training Loss: 0.329895 | Val. Loss: 0.306866 | Val. Kappa Score: 0.7671 | LR: 0.000000 | Estimated time: 160.39
time_estimated: 4491.30
n-epochs: 28
time_estimated: 4491.31
----------------------------------------

Experiment N: 55: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.1, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 10:40:14
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.1
    lr: 0.1
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb8c06ee10>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 23.404686
best-train-loss: 13.439208
best-valid-loss: 93994595995914832.000000
best-kappa: 0.0143
: Epoch: 1 | Training Loss: 13.439208 | Val. Loss: 93994595995914832.000000 | Val. Kappa Score: 0.0143 | LR: 0.100000 | Estimated time: 158.68
Train loss on 50 batch: 1.766623
best-train-loss: 1.648243
best-valid-loss: 29812486.171429
best-kappa: 0.0147
: Epoch: 2 | Training Loss: 1.648243 | Val. Loss: 29812486.171429 | Val. Kappa Score: 0.0147 | LR: 0.100000 | Estimated time: 160.31
Train loss on 50 batch: 1.369762
best-train-loss: 1.510003
best-valid-loss: 126.403537
best-kappa: 0.0195
: Epoch: 3 | Training Loss: 1.510003 | Val. Loss: 126.403537 | Val. Kappa Score: 0.0195 | LR: 0.100000 | Estimated time: 159.42
Train loss on 50 batch: 1.387148
best-train-loss: 1.330722
best-valid-loss: 9.132373
best-kappa: 0.0110
: Epoch: 4 | Training Loss: 1.330722 | Val. Loss: 9.132373 | Val. Kappa Score: 0.0110 | LR: 0.100000 | Estimated time: 159.83
Train loss on 50 batch: 1.011491
best-train-loss: 1.088055
best-valid-loss: 1.088020
best-kappa: 0.1297
: Epoch: 5 | Training Loss: 1.088055 | Val. Loss: 1.088020 | Val. Kappa Score: 0.1297 | LR: 0.010000 | Estimated time: 159.09
Train loss on 50 batch: 0.947732
: Epoch: 6 | Training Loss: 0.874043 | Val. Loss: 1.257117 | Val. Kappa Score: 0.2097 | LR: 0.010000 | Estimated time: 159.82
Train loss on 50 batch: 0.843077
best-train-loss: 0.825139
best-valid-loss: 0.725563
best-kappa: 0.2781
: Epoch: 7 | Training Loss: 0.825139 | Val. Loss: 0.725563 | Val. Kappa Score: 0.2781 | LR: 0.010000 | Estimated time: 160.52
Train loss on 50 batch: 0.817396
: Epoch: 8 | Training Loss: 0.855123 | Val. Loss: 0.737261 | Val. Kappa Score: 0.3310 | LR: 0.010000 | Estimated time: 159.74
Train loss on 50 batch: 0.793824
best-train-loss: 0.812011
best-valid-loss: 0.643439
best-kappa: 0.3757
: Epoch: 9 | Training Loss: 0.812011 | Val. Loss: 0.643439 | Val. Kappa Score: 0.3757 | LR: 0.010000 | Estimated time: 159.83
Train loss on 50 batch: 0.753451
: Epoch: 10 | Training Loss: 0.741067 | Val. Loss: 0.754480 | Val. Kappa Score: 0.4076 | LR: 0.001000 | Estimated time: 158.35
Train loss on 50 batch: 0.725734
best-train-loss: 0.734760
best-valid-loss: 0.635850
best-kappa: 0.4375
: Epoch: 11 | Training Loss: 0.734760 | Val. Loss: 0.635850 | Val. Kappa Score: 0.4375 | LR: 0.001000 | Estimated time: 158.91
Train loss on 50 batch: 0.720793
best-train-loss: 0.734672
best-valid-loss: 0.606610
best-kappa: 0.4637
: Epoch: 12 | Training Loss: 0.734672 | Val. Loss: 0.606610 | Val. Kappa Score: 0.4637 | LR: 0.001000 | Estimated time: 159.19
Train loss on 50 batch: 0.690421
: Epoch: 13 | Training Loss: 0.756228 | Val. Loss: 0.608821 | Val. Kappa Score: 0.4856 | LR: 0.001000 | Estimated time: 158.57
Train loss on 50 batch: 0.740598
best-train-loss: 0.720483
best-valid-loss: 0.600900
best-kappa: 0.5050
: Epoch: 14 | Training Loss: 0.720483 | Val. Loss: 0.600900 | Val. Kappa Score: 0.5050 | LR: 0.001000 | Estimated time: 159.26
Train loss on 50 batch: 0.705249
: Epoch: 15 | Training Loss: 0.730184 | Val. Loss: 0.608321 | Val. Kappa Score: 0.5221 | LR: 0.000100 | Estimated time: 159.38
Train loss on 50 batch: 0.679351
best-train-loss: 0.696837
best-valid-loss: 0.596176
best-kappa: 0.5370
: Epoch: 16 | Training Loss: 0.696837 | Val. Loss: 0.596176 | Val. Kappa Score: 0.5370 | LR: 0.000100 | Estimated time: 158.92
Train loss on 50 batch: 0.757253
best-train-loss: 0.692775
best-valid-loss: 0.594017
best-kappa: 0.5496
: Epoch: 17 | Training Loss: 0.692775 | Val. Loss: 0.594017 | Val. Kappa Score: 0.5496 | LR: 0.000100 | Estimated time: 159.61
Train loss on 50 batch: 0.728499
: Epoch: 18 | Training Loss: 0.704561 | Val. Loss: 0.602745 | Val. Kappa Score: 0.5606 | LR: 0.000100 | Estimated time: 159.98
Train loss on 50 batch: 0.717675
: Epoch: 19 | Training Loss: 0.716156 | Val. Loss: 0.599822 | Val. Kappa Score: 0.5710 | LR: 0.000100 | Estimated time: 158.79
Train loss on 50 batch: 0.743890
: Epoch: 20 | Training Loss: 0.698216 | Val. Loss: 0.596164 | Val. Kappa Score: 0.5803 | LR: 0.000010 | Estimated time: 158.50
Train loss on 50 batch: 0.682576
: Epoch: 21 | Training Loss: 0.697626 | Val. Loss: 0.604397 | Val. Kappa Score: 0.5886 | LR: 0.000010 | Estimated time: 159.24
Train loss on 50 batch: 0.762020
: Epoch: 22 | Training Loss: 0.728676 | Val. Loss: 0.598764 | Val. Kappa Score: 0.5960 | LR: 0.000010 | Estimated time: 159.66
Train loss on 50 batch: 0.690384
: Epoch: 23 | Training Loss: 0.723033 | Val. Loss: 0.620804 | Val. Kappa Score: 0.6028 | LR: 0.000010 | Estimated time: 159.14
Train loss on 50 batch: 0.739349
: Epoch: 24 | Training Loss: 0.709650 | Val. Loss: 0.608121 | Val. Kappa Score: 0.6091 | LR: 0.000010 | Estimated time: 159.54
Train loss on 50 batch: 0.658480
best-train-loss: 0.742122
best-valid-loss: 0.589543
best-kappa: 0.6151
: Epoch: 25 | Training Loss: 0.742122 | Val. Loss: 0.589543 | Val. Kappa Score: 0.6151 | LR: 0.000001 | Estimated time: 159.12
Train loss on 50 batch: 0.727167
: Epoch: 26 | Training Loss: 0.713095 | Val. Loss: 0.594782 | Val. Kappa Score: 0.6207 | LR: 0.000001 | Estimated time: 159.04
Train loss on 50 batch: 0.725143
: Epoch: 27 | Training Loss: 0.702775 | Val. Loss: 0.592206 | Val. Kappa Score: 0.6259 | LR: 0.000001 | Estimated time: 159.59
Train loss on 50 batch: 0.698313
: Epoch: 28 | Training Loss: 0.780151 | Val. Loss: 0.594954 | Val. Kappa Score: 0.6310 | LR: 0.000001 | Estimated time: 159.34
Train loss on 50 batch: 0.682085
: Epoch: 29 | Training Loss: 0.737363 | Val. Loss: 0.602270 | Val. Kappa Score: 0.6351 | LR: 0.000001 | Estimated time: 159.40
Train loss on 50 batch: 0.681395
: Epoch: 30 | Training Loss: 0.698686 | Val. Loss: 0.594161 | Val. Kappa Score: 0.6391 | LR: 0.000000 | Estimated time: 159.26
time_estimated: 4780.65
----------------------------------------

Experiment N: 56: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.0001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 11:59:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb8c11ca20>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.386819
best-train-loss: 1.001567
best-valid-loss: 1.012098
best-kappa: 0.5749
: Epoch: 1 | Training Loss: 1.001567 | Val. Loss: 1.012098 | Val. Kappa Score: 0.5749 | LR: 0.000100 | Estimated time: 159.08
Train loss on 50 batch: 0.502778
best-train-loss: 0.493592
best-valid-loss: 0.497907
best-kappa: 0.6888
: Epoch: 2 | Training Loss: 0.493592 | Val. Loss: 0.497907 | Val. Kappa Score: 0.6888 | LR: 0.000100 | Estimated time: 160.82
Train loss on 50 batch: 0.408881
best-train-loss: 0.414320
best-valid-loss: 0.382692
best-kappa: 0.7444
: Epoch: 3 | Training Loss: 0.414320 | Val. Loss: 0.382692 | Val. Kappa Score: 0.7444 | LR: 0.000100 | Estimated time: 158.53
Train loss on 50 batch: 0.363523
: Epoch: 4 | Training Loss: 0.381865 | Val. Loss: 0.422296 | Val. Kappa Score: 0.7676 | LR: 0.000100 | Estimated time: 160.39
Train loss on 50 batch: 0.339630
best-train-loss: 0.359302
best-valid-loss: 0.382575
best-kappa: 0.7830
: Epoch: 5 | Training Loss: 0.359302 | Val. Loss: 0.382575 | Val. Kappa Score: 0.7830 | LR: 0.000010 | Estimated time: 159.19
Train loss on 50 batch: 0.357035
best-train-loss: 0.336932
best-valid-loss: 0.357646
best-kappa: 0.7955
: Epoch: 6 | Training Loss: 0.336932 | Val. Loss: 0.357646 | Val. Kappa Score: 0.7955 | LR: 0.000010 | Estimated time: 158.65
Train loss on 50 batch: 0.304531
: Epoch: 7 | Training Loss: 0.298026 | Val. Loss: 0.375657 | Val. Kappa Score: 0.8029 | LR: 0.000010 | Estimated time: 159.89
Train loss on 50 batch: 0.307615
: Epoch: 8 | Training Loss: 0.328178 | Val. Loss: 0.359068 | Val. Kappa Score: 0.8094 | LR: 0.000010 | Estimated time: 159.96
Train loss on 50 batch: 0.287503
: Epoch: 9 | Training Loss: 0.293537 | Val. Loss: 0.372810 | Val. Kappa Score: 0.8140 | LR: 0.000010 | Estimated time: 159.87
Train loss on 50 batch: 0.310462
: Epoch: 10 | Training Loss: 0.297527 | Val. Loss: 0.368652 | Val. Kappa Score: 0.8181 | LR: 0.000001 | Estimated time: 159.03
Train loss on 50 batch: 0.308865
: Epoch: 11 | Training Loss: 0.303582 | Val. Loss: 0.366154 | Val. Kappa Score: 0.8219 | LR: 0.000001 | Estimated time: 159.05
Train loss on 50 batch: 0.309304
: Epoch: 12 | Training Loss: 0.311090 | Val. Loss: 0.360884 | Val. Kappa Score: 0.8251 | LR: 0.000001 | Estimated time: 158.40
Train loss on 50 batch: 0.295200
: Epoch: 13 | Training Loss: 0.326024 | Val. Loss: 0.366064 | Val. Kappa Score: 0.8275 | LR: 0.000001 | Estimated time: 158.76
Train loss on 50 batch: 0.316230
: Epoch: 14 | Training Loss: 0.310343 | Val. Loss: 0.362908 | Val. Kappa Score: 0.8292 | LR: 0.000001 | Estimated time: 159.91
time_estimated: 2231.79
n-epochs: 14
time_estimated: 2231.80
----------------------------------------

Experiment N: 57: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 1e-05, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 12:37:07
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 1e-05
    lr: 1e-05
    weight_decay: 0
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb8c11c860>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.790167
best-train-loss: 2.591088
best-valid-loss: 2.715662
best-kappa: 0.0506
: Epoch: 1 | Training Loss: 2.591088 | Val. Loss: 2.715662 | Val. Kappa Score: 0.0506 | LR: 0.000010 | Estimated time: 158.61
Train loss on 50 batch: 1.990368
best-train-loss: 1.839609
best-valid-loss: 2.094465
best-kappa: 0.1668
: Epoch: 2 | Training Loss: 1.839609 | Val. Loss: 2.094465 | Val. Kappa Score: 0.1668 | LR: 0.000010 | Estimated time: 160.71
Train loss on 50 batch: 1.227363
best-train-loss: 1.264786
best-valid-loss: 1.482337
best-kappa: 0.2747
: Epoch: 3 | Training Loss: 1.264786 | Val. Loss: 1.482337 | Val. Kappa Score: 0.2747 | LR: 0.000010 | Estimated time: 159.09
Train loss on 50 batch: 1.024241
best-train-loss: 0.937128
best-valid-loss: 1.106223
best-kappa: 0.3562
: Epoch: 4 | Training Loss: 0.937128 | Val. Loss: 1.106223 | Val. Kappa Score: 0.3562 | LR: 0.000010 | Estimated time: 160.04
Train loss on 50 batch: 0.788382
best-train-loss: 0.787914
best-valid-loss: 0.909995
best-kappa: 0.4172
: Epoch: 5 | Training Loss: 0.787914 | Val. Loss: 0.909995 | Val. Kappa Score: 0.4172 | LR: 0.000001 | Estimated time: 160.08
Train loss on 50 batch: 0.793501
best-train-loss: 0.716406
best-valid-loss: 0.897285
best-kappa: 0.4577
: Epoch: 6 | Training Loss: 0.716406 | Val. Loss: 0.897285 | Val. Kappa Score: 0.4577 | LR: 0.000001 | Estimated time: 158.22
Train loss on 50 batch: 0.735427
: Epoch: 7 | Training Loss: 0.713623 | Val. Loss: 0.918774 | Val. Kappa Score: 0.4845 | LR: 0.000001 | Estimated time: 159.85
Train loss on 50 batch: 0.709013
: Epoch: 8 | Training Loss: 0.731346 | Val. Loss: 0.912217 | Val. Kappa Score: 0.5054 | LR: 0.000001 | Estimated time: 160.00
Train loss on 50 batch: 0.669379
: Epoch: 9 | Training Loss: 0.704465 | Val. Loss: 0.925894 | Val. Kappa Score: 0.5218 | LR: 0.000001 | Estimated time: 159.26
Train loss on 50 batch: 0.681709
best-train-loss: 0.659074
best-valid-loss: 0.889375
best-kappa: 0.5360
: Epoch: 10 | Training Loss: 0.659074 | Val. Loss: 0.889375 | Val. Kappa Score: 0.5360 | LR: 0.000000 | Estimated time: 158.99
Train loss on 50 batch: 0.701662
: Epoch: 11 | Training Loss: 0.665732 | Val. Loss: 0.902394 | Val. Kappa Score: 0.5479 | LR: 0.000000 | Estimated time: 159.47
Train loss on 50 batch: 0.672420
: Epoch: 12 | Training Loss: 0.693977 | Val. Loss: 0.901785 | Val. Kappa Score: 0.5574 | LR: 0.000000 | Estimated time: 158.78
Train loss on 50 batch: 0.654050
best-train-loss: 0.708938
best-valid-loss: 0.880424
best-kappa: 0.5653
: Epoch: 13 | Training Loss: 0.708938 | Val. Loss: 0.880424 | Val. Kappa Score: 0.5653 | LR: 0.000000 | Estimated time: 159.01
Train loss on 50 batch: 0.716684
: Epoch: 14 | Training Loss: 0.696789 | Val. Loss: 0.882831 | Val. Kappa Score: 0.5719 | LR: 0.000000 | Estimated time: 159.09
Train loss on 50 batch: 0.674062
: Epoch: 15 | Training Loss: 0.686112 | Val. Loss: 0.890048 | Val. Kappa Score: 0.5781 | LR: 0.000000 | Estimated time: 159.71
Train loss on 50 batch: 0.644228
: Epoch: 16 | Training Loss: 0.655279 | Val. Loss: 0.886237 | Val. Kappa Score: 0.5833 | LR: 0.000000 | Estimated time: 158.94
Train loss on 50 batch: 0.754120
best-train-loss: 0.654964
best-valid-loss: 0.880136
best-kappa: 0.5878
: Epoch: 17 | Training Loss: 0.654964 | Val. Loss: 0.880136 | Val. Kappa Score: 0.5878 | LR: 0.000000 | Estimated time: 159.30
Train loss on 50 batch: 0.710880
: Epoch: 18 | Training Loss: 0.674882 | Val. Loss: 0.881753 | Val. Kappa Score: 0.5914 | LR: 0.000000 | Estimated time: 159.81
Train loss on 50 batch: 0.665134
: Epoch: 19 | Training Loss: 0.648443 | Val. Loss: 0.893808 | Val. Kappa Score: 0.5953 | LR: 0.000000 | Estimated time: 158.80
Train loss on 50 batch: 0.679141
: Epoch: 20 | Training Loss: 0.656968 | Val. Loss: 0.882591 | Val. Kappa Score: 0.5986 | LR: 0.000000 | Estimated time: 158.61
Train loss on 50 batch: 0.612494
: Epoch: 21 | Training Loss: 0.674962 | Val. Loss: 0.892925 | Val. Kappa Score: 0.6016 | LR: 0.000000 | Estimated time: 159.73
Train loss on 50 batch: 0.714337
best-train-loss: 0.670827
best-valid-loss: 0.874041
best-kappa: 0.6045
: Epoch: 22 | Training Loss: 0.670827 | Val. Loss: 0.874041 | Val. Kappa Score: 0.6045 | LR: 0.000000 | Estimated time: 159.86
Train loss on 50 batch: 0.632869
: Epoch: 23 | Training Loss: 0.703310 | Val. Loss: 0.913217 | Val. Kappa Score: 0.6068 | LR: 0.000000 | Estimated time: 158.64
Train loss on 50 batch: 0.696184
: Epoch: 24 | Training Loss: 0.678849 | Val. Loss: 0.894901 | Val. Kappa Score: 0.6090 | LR: 0.000000 | Estimated time: 159.19
Train loss on 50 batch: 0.624688
best-train-loss: 0.741418
best-valid-loss: 0.870457
best-kappa: 0.6114
: Epoch: 25 | Training Loss: 0.741418 | Val. Loss: 0.870457 | Val. Kappa Score: 0.6114 | LR: 0.000000 | Estimated time: 159.37
Train loss on 50 batch: 0.671142
best-train-loss: 0.654287
best-valid-loss: 0.860943
best-kappa: 0.6136
: Epoch: 26 | Training Loss: 0.654287 | Val. Loss: 0.860943 | Val. Kappa Score: 0.6136 | LR: 0.000000 | Estimated time: 159.55
Train loss on 50 batch: 0.677618
: Epoch: 27 | Training Loss: 0.671523 | Val. Loss: 0.870013 | Val. Kappa Score: 0.6157 | LR: 0.000000 | Estimated time: 159.45
Train loss on 50 batch: 0.708464
: Epoch: 28 | Training Loss: 0.714407 | Val. Loss: 0.880156 | Val. Kappa Score: 0.6178 | LR: 0.000000 | Estimated time: 160.15
Train loss on 50 batch: 0.622236
: Epoch: 29 | Training Loss: 0.685078 | Val. Loss: 0.893461 | Val. Kappa Score: 0.6191 | LR: 0.000000 | Estimated time: 159.57
Train loss on 50 batch: 0.680911
: Epoch: 30 | Training Loss: 0.696102 | Val. Loss: 0.877954 | Val. Kappa Score: 0.6207 | LR: 0.000000 | Estimated time: 159.75
time_estimated: 4782.32
----------------------------------------

Experiment N: 58: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 16:37:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb9604a240>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.766954
Train loss on 100 batch: 0.474173
best-train-loss: 0.583686
best-valid-loss: 0.459770
best-kappa: 0.8640
: Epoch: 1 | Training Loss: 0.583686 | Val. Loss: 0.459770 | Val. Kappa Score: 0.8640 | LR: 0.001000 | Estimated time: 158.44
Train loss on 50 batch: 0.392925
Train loss on 100 batch: 0.433649
best-train-loss: 0.355612
best-valid-loss: 0.371058
best-kappa: 0.8649
: Epoch: 2 | Training Loss: 0.355612 | Val. Loss: 0.371058 | Val. Kappa Score: 0.8649 | LR: 0.001000 | Estimated time: 157.32
Train loss on 50 batch: 0.387042
Train loss on 100 batch: 0.329189
: Epoch: 3 | Training Loss: 0.364468 | Val. Loss: 0.500311 | Val. Kappa Score: 0.8682 | LR: 0.001000 | Estimated time: 157.72
Train loss on 50 batch: 0.333762
Train loss on 100 batch: 0.297834
: Epoch: 4 | Training Loss: 0.369577 | Val. Loss: 0.376058 | Val. Kappa Score: 0.8733 | LR: 0.001000 | Estimated time: 156.98
Train loss on 50 batch: 0.251503
Train loss on 100 batch: 0.349805
best-train-loss: 0.294004
best-valid-loss: 0.312197
best-kappa: 0.8775
: Epoch: 5 | Training Loss: 0.294004 | Val. Loss: 0.312197 | Val. Kappa Score: 0.8775 | LR: 0.000100 | Estimated time: 157.91
Train loss on 50 batch: 0.251050
Train loss on 100 batch: 0.214625
best-train-loss: 0.256505
best-valid-loss: 0.238560
best-kappa: 0.8806
: Epoch: 6 | Training Loss: 0.256505 | Val. Loss: 0.238560 | Val. Kappa Score: 0.8806 | LR: 0.000100 | Estimated time: 157.47
Train loss on 50 batch: 0.216728
Train loss on 100 batch: 0.206415
: Epoch: 7 | Training Loss: 0.206645 | Val. Loss: 0.247037 | Val. Kappa Score: 0.8843 | LR: 0.000100 | Estimated time: 156.73
Train loss on 50 batch: 0.206438
Train loss on 100 batch: 0.206291
: Epoch: 8 | Training Loss: 0.189219 | Val. Loss: 0.246915 | Val. Kappa Score: 0.8870 | LR: 0.000100 | Estimated time: 156.58
Train loss on 50 batch: 0.203795
Train loss on 100 batch: 0.185504
: Epoch: 9 | Training Loss: 0.200166 | Val. Loss: 0.257823 | Val. Kappa Score: 0.8876 | LR: 0.000100 | Estimated time: 158.23
Train loss on 50 batch: 0.178176
Train loss on 100 batch: 0.180148
: Epoch: 10 | Training Loss: 0.168512 | Val. Loss: 0.242041 | Val. Kappa Score: 0.8871 | LR: 0.000010 | Estimated time: 156.56
Train loss on 50 batch: 0.168949
Train loss on 100 batch: 0.156757
: Epoch: 11 | Training Loss: 0.166288 | Val. Loss: 0.250053 | Val. Kappa Score: 0.8890 | LR: 0.000010 | Estimated time: 158.04
Train loss on 50 batch: 0.175673
Train loss on 100 batch: 0.157192
: Epoch: 12 | Training Loss: 0.167642 | Val. Loss: 0.277667 | Val. Kappa Score: 0.8906 | LR: 0.000010 | Estimated time: 157.19
Train loss on 50 batch: 0.161663
Train loss on 100 batch: 0.170604
: Epoch: 13 | Training Loss: 0.168824 | Val. Loss: 0.267115 | Val. Kappa Score: 0.8913 | LR: 0.000010 | Estimated time: 156.79
Train loss on 50 batch: 0.166814
Train loss on 100 batch: 0.169120
: Epoch: 14 | Training Loss: 0.152332 | Val. Loss: 0.248097 | Val. Kappa Score: 0.8922 | LR: 0.000010 | Estimated time: 157.43
time_estimated: 2203.65
n-epochs: 14
time_estimated: 2203.67
----------------------------------------

Experiment N: 59: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 17:14:27
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.01
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb9604a160>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.554265
Train loss on 100 batch: 0.678464
best-train-loss: 0.952083
best-valid-loss: 33.367378
best-kappa: -0.0542
: Epoch: 1 | Training Loss: 0.952083 | Val. Loss: 33.367378 | Val. Kappa Score: -0.0542 | LR: 0.010000 | Estimated time: 158.15
Train loss on 50 batch: 0.525442
Train loss on 100 batch: 0.576933
best-train-loss: 0.494396
best-valid-loss: 9.405521
best-kappa: -0.0912
: Epoch: 2 | Training Loss: 0.494396 | Val. Loss: 9.405521 | Val. Kappa Score: -0.0912 | LR: 0.010000 | Estimated time: 156.82
Train loss on 50 batch: 0.524696
Train loss on 100 batch: 0.466161
best-train-loss: 0.508671
best-valid-loss: 0.966873
best-kappa: 0.1856
: Epoch: 3 | Training Loss: 0.508671 | Val. Loss: 0.966873 | Val. Kappa Score: 0.1856 | LR: 0.010000 | Estimated time: 157.53
Train loss on 50 batch: 0.477824
Train loss on 100 batch: 0.464522
best-train-loss: 0.534352
best-valid-loss: 0.581538
best-kappa: 0.3312
: Epoch: 4 | Training Loss: 0.534352 | Val. Loss: 0.581538 | Val. Kappa Score: 0.3312 | LR: 0.010000 | Estimated time: 157.07
Train loss on 50 batch: 0.422562
Train loss on 100 batch: 0.498437
best-train-loss: 0.463941
best-valid-loss: 0.479414
best-kappa: 0.4321
: Epoch: 5 | Training Loss: 0.463941 | Val. Loss: 0.479414 | Val. Kappa Score: 0.4321 | LR: 0.001000 | Estimated time: 157.94
Train loss on 50 batch: 0.399954
Train loss on 100 batch: 0.333182
best-train-loss: 0.412128
best-valid-loss: 0.298914
best-kappa: 0.5075
: Epoch: 6 | Training Loss: 0.412128 | Val. Loss: 0.298914 | Val. Kappa Score: 0.5075 | LR: 0.001000 | Estimated time: 157.42
Train loss on 50 batch: 0.339296
Train loss on 100 batch: 0.312267
best-train-loss: 0.312910
best-valid-loss: 0.281352
best-kappa: 0.5644
: Epoch: 7 | Training Loss: 0.312910 | Val. Loss: 0.281352 | Val. Kappa Score: 0.5644 | LR: 0.001000 | Estimated time: 157.03
Train loss on 50 batch: 0.326107
Train loss on 100 batch: 0.321082
: Epoch: 8 | Training Loss: 0.320725 | Val. Loss: 0.292863 | Val. Kappa Score: 0.6041 | LR: 0.001000 | Estimated time: 157.26
Train loss on 50 batch: 0.317340
Train loss on 100 batch: 0.325964
: Epoch: 9 | Training Loss: 0.341249 | Val. Loss: 0.287042 | Val. Kappa Score: 0.6354 | LR: 0.001000 | Estimated time: 157.28
Train loss on 50 batch: 0.303966
Train loss on 100 batch: 0.307992
best-train-loss: 0.304562
best-valid-loss: 0.265984
best-kappa: 0.6617
: Epoch: 10 | Training Loss: 0.304562 | Val. Loss: 0.265984 | Val. Kappa Score: 0.6617 | LR: 0.000100 | Estimated time: 157.24
Train loss on 50 batch: 0.310669
Train loss on 100 batch: 0.269470
: Epoch: 11 | Training Loss: 0.282985 | Val. Loss: 0.284230 | Val. Kappa Score: 0.6836 | LR: 0.000100 | Estimated time: 157.83
Train loss on 50 batch: 0.314795
Train loss on 100 batch: 0.277325
: Epoch: 12 | Training Loss: 0.282385 | Val. Loss: 0.290157 | Val. Kappa Score: 0.7018 | LR: 0.000100 | Estimated time: 157.52
Train loss on 50 batch: 0.298586
Train loss on 100 batch: 0.292314
: Epoch: 13 | Training Loss: 0.322522 | Val. Loss: 0.275356 | Val. Kappa Score: 0.7172 | LR: 0.000100 | Estimated time: 156.71
Train loss on 50 batch: 0.291913
Train loss on 100 batch: 0.278177
: Epoch: 14 | Training Loss: 0.270009 | Val. Loss: 0.273783 | Val. Kappa Score: 0.7302 | LR: 0.000100 | Estimated time: 157.34
Train loss on 50 batch: 0.274799
Train loss on 100 batch: 0.304954
best-train-loss: 0.284089
best-valid-loss: 0.252570
best-kappa: 0.7419
: Epoch: 15 | Training Loss: 0.284089 | Val. Loss: 0.252570 | Val. Kappa Score: 0.7419 | LR: 0.000010 | Estimated time: 157.99
Train loss on 50 batch: 0.272312
Train loss on 100 batch: 0.288950
: Epoch: 16 | Training Loss: 0.250980 | Val. Loss: 0.260936 | Val. Kappa Score: 0.7512 | LR: 0.000010 | Estimated time: 157.07
Train loss on 50 batch: 0.285467
Train loss on 100 batch: 0.273752
: Epoch: 17 | Training Loss: 0.280728 | Val. Loss: 0.256545 | Val. Kappa Score: 0.7603 | LR: 0.000010 | Estimated time: 158.24
Train loss on 50 batch: 0.287238
Train loss on 100 batch: 0.269259
: Epoch: 18 | Training Loss: 0.297641 | Val. Loss: 0.264799 | Val. Kappa Score: 0.7683 | LR: 0.000010 | Estimated time: 157.78
Train loss on 50 batch: 0.279650
Train loss on 100 batch: 0.291551
: Epoch: 19 | Training Loss: 0.289738 | Val. Loss: 0.267946 | Val. Kappa Score: 0.7755 | LR: 0.000010 | Estimated time: 157.56
Train loss on 50 batch: 0.297475
Train loss on 100 batch: 0.280211
: Epoch: 20 | Training Loss: 0.296859 | Val. Loss: 0.255412 | Val. Kappa Score: 0.7820 | LR: 0.000001 | Estimated time: 158.11
Train loss on 50 batch: 0.312697
Train loss on 100 batch: 0.251952
best-train-loss: 0.270807
best-valid-loss: 0.251306
best-kappa: 0.7880
: Epoch: 21 | Training Loss: 0.270807 | Val. Loss: 0.251306 | Val. Kappa Score: 0.7880 | LR: 0.000001 | Estimated time: 157.64
Train loss on 50 batch: 0.321909
Train loss on 100 batch: 0.243284
: Epoch: 22 | Training Loss: 0.287298 | Val. Loss: 0.255612 | Val. Kappa Score: 0.7934 | LR: 0.000001 | Estimated time: 157.18
Train loss on 50 batch: 0.302798
Train loss on 100 batch: 0.273669
: Epoch: 23 | Training Loss: 0.275532 | Val. Loss: 0.268065 | Val. Kappa Score: 0.7982 | LR: 0.000001 | Estimated time: 156.77
Train loss on 50 batch: 0.285262
Train loss on 100 batch: 0.282154
: Epoch: 24 | Training Loss: 0.284567 | Val. Loss: 0.262099 | Val. Kappa Score: 0.8028 | LR: 0.000001 | Estimated time: 157.74
Train loss on 50 batch: 0.282816
Train loss on 100 batch: 0.302707
: Epoch: 25 | Training Loss: 0.292483 | Val. Loss: 0.266704 | Val. Kappa Score: 0.8067 | LR: 0.000000 | Estimated time: 158.29
Train loss on 50 batch: 0.281617
Train loss on 100 batch: 0.284440
: Epoch: 26 | Training Loss: 0.257539 | Val. Loss: 0.257601 | Val. Kappa Score: 0.8101 | LR: 0.000000 | Estimated time: 158.74
Train loss on 50 batch: 0.285288
Train loss on 100 batch: 0.281662
: Epoch: 27 | Training Loss: 0.268618 | Val. Loss: 0.253496 | Val. Kappa Score: 0.8137 | LR: 0.000000 | Estimated time: 156.96
Train loss on 50 batch: 0.280903
Train loss on 100 batch: 0.280416
: Epoch: 28 | Training Loss: 0.303603 | Val. Loss: 0.251407 | Val. Kappa Score: 0.8170 | LR: 0.000000 | Estimated time: 158.27
Train loss on 50 batch: 0.299751
Train loss on 100 batch: 0.289402
: Epoch: 29 | Training Loss: 0.272176 | Val. Loss: 0.279508 | Val. Kappa Score: 0.8199 | LR: 0.000000 | Estimated time: 157.60
time_estimated: 4569.64
n-epochs: 29
time_estimated: 4569.66
----------------------------------------

Experiment N: 60: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.1, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 18:30:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.1
    lr: 0.1
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb96021940>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 40.688585
Train loss on 100 batch: 2.133692
best-train-loss: 15.020858
best-valid-loss: 3076870373376.000000
best-kappa: 0.0255
: Epoch: 1 | Training Loss: 15.020858 | Val. Loss: 3076870373376.000000 | Val. Kappa Score: 0.0255 | LR: 0.100000 | Estimated time: 158.38
Train loss on 50 batch: 1.978696
Train loss on 100 batch: 1.492966
best-train-loss: 1.596878
best-valid-loss: 440.287712
best-kappa: 0.0226
: Epoch: 2 | Training Loss: 1.596878 | Val. Loss: 440.287712 | Val. Kappa Score: 0.0226 | LR: 0.100000 | Estimated time: 157.37
Train loss on 50 batch: 1.629435
Train loss on 100 batch: 1.485408
best-train-loss: 1.529223
best-valid-loss: 1.994699
best-kappa: 0.0746
: Epoch: 3 | Training Loss: 1.529223 | Val. Loss: 1.994699 | Val. Kappa Score: 0.0746 | LR: 0.100000 | Estimated time: 157.71
Train loss on 50 batch: 1.230073
Train loss on 100 batch: 1.155021
best-train-loss: 1.249169
best-valid-loss: 1.016451
best-kappa: 0.1963
: Epoch: 4 | Training Loss: 1.249169 | Val. Loss: 1.016451 | Val. Kappa Score: 0.1963 | LR: 0.100000 | Estimated time: 157.93
Train loss on 50 batch: 1.415588
Train loss on 100 batch: 1.195795
: Epoch: 5 | Training Loss: 1.300213 | Val. Loss: 1.172301 | Val. Kappa Score: 0.2600 | LR: 0.010000 | Estimated time: 158.02
Train loss on 50 batch: 0.869677
Train loss on 100 batch: 0.784185
best-train-loss: 0.906983
best-valid-loss: 0.730185
best-kappa: 0.3344
: Epoch: 6 | Training Loss: 0.906983 | Val. Loss: 0.730185 | Val. Kappa Score: 0.3344 | LR: 0.010000 | Estimated time: 158.80
Train loss on 50 batch: 0.807287
Train loss on 100 batch: 0.776891
best-train-loss: 0.813457
best-valid-loss: 0.703817
best-kappa: 0.3867
: Epoch: 7 | Training Loss: 0.813457 | Val. Loss: 0.703817 | Val. Kappa Score: 0.3867 | LR: 0.010000 | Estimated time: 157.19
Train loss on 50 batch: 0.777856
Train loss on 100 batch: 0.789500
best-train-loss: 0.785472
best-valid-loss: 0.689493
best-kappa: 0.4280
: Epoch: 8 | Training Loss: 0.785472 | Val. Loss: 0.689493 | Val. Kappa Score: 0.4280 | LR: 0.010000 | Estimated time: 157.56
Train loss on 50 batch: 0.814997
Train loss on 100 batch: 0.776351
: Epoch: 9 | Training Loss: 0.808346 | Val. Loss: 0.732026 | Val. Kappa Score: 0.4605 | LR: 0.010000 | Estimated time: 158.29
Train loss on 50 batch: 0.793424
Train loss on 100 batch: 0.698775
: Epoch: 10 | Training Loss: 0.763808 | Val. Loss: 0.808167 | Val. Kappa Score: 0.4804 | LR: 0.001000 | Estimated time: 158.35
Train loss on 50 batch: 0.788073
Train loss on 100 batch: 0.652341
: Epoch: 11 | Training Loss: 0.669076 | Val. Loss: 0.729196 | Val. Kappa Score: 0.5038 | LR: 0.001000 | Estimated time: 157.74
Train loss on 50 batch: 0.771871
Train loss on 100 batch: 0.695508
best-train-loss: 0.717669
best-valid-loss: 0.687432
best-kappa: 0.5233
: Epoch: 12 | Training Loss: 0.717669 | Val. Loss: 0.687432 | Val. Kappa Score: 0.5233 | LR: 0.001000 | Estimated time: 158.30
Train loss on 50 batch: 0.723742
Train loss on 100 batch: 0.706270
best-train-loss: 0.688901
best-valid-loss: 0.662065
best-kappa: 0.5398
: Epoch: 13 | Training Loss: 0.688901 | Val. Loss: 0.662065 | Val. Kappa Score: 0.5398 | LR: 0.001000 | Estimated time: 156.57
Train loss on 50 batch: 0.704130
Train loss on 100 batch: 0.729744
: Epoch: 14 | Training Loss: 0.703986 | Val. Loss: 0.679392 | Val. Kappa Score: 0.5543 | LR: 0.001000 | Estimated time: 158.01
Train loss on 50 batch: 0.684345
Train loss on 100 batch: 0.718171
best-train-loss: 0.735857
best-valid-loss: 0.652590
best-kappa: 0.5677
: Epoch: 15 | Training Loss: 0.735857 | Val. Loss: 0.652590 | Val. Kappa Score: 0.5677 | LR: 0.000100 | Estimated time: 157.93
Train loss on 50 batch: 0.680825
Train loss on 100 batch: 0.760693
best-train-loss: 0.651953
best-valid-loss: 0.640360
best-kappa: 0.5792
: Epoch: 16 | Training Loss: 0.651953 | Val. Loss: 0.640360 | Val. Kappa Score: 0.5792 | LR: 0.000100 | Estimated time: 157.10
Train loss on 50 batch: 0.711681
Train loss on 100 batch: 0.708847
best-train-loss: 0.688329
best-valid-loss: 0.639521
best-kappa: 0.5898
: Epoch: 17 | Training Loss: 0.688329 | Val. Loss: 0.639521 | Val. Kappa Score: 0.5898 | LR: 0.000100 | Estimated time: 157.63
Train loss on 50 batch: 0.702637
Train loss on 100 batch: 0.728188
: Epoch: 18 | Training Loss: 0.741955 | Val. Loss: 0.640716 | Val. Kappa Score: 0.5990 | LR: 0.000100 | Estimated time: 158.66
Train loss on 50 batch: 0.741442
Train loss on 100 batch: 0.685050
: Epoch: 19 | Training Loss: 0.688554 | Val. Loss: 0.653243 | Val. Kappa Score: 0.6075 | LR: 0.000100 | Estimated time: 157.22
Train loss on 50 batch: 0.746408
Train loss on 100 batch: 0.676895
: Epoch: 20 | Training Loss: 0.693197 | Val. Loss: 0.649365 | Val. Kappa Score: 0.6148 | LR: 0.000010 | Estimated time: 158.22
Train loss on 50 batch: 0.731342
Train loss on 100 batch: 0.668870
best-train-loss: 0.657436
best-valid-loss: 0.625983
best-kappa: 0.6222
: Epoch: 21 | Training Loss: 0.657436 | Val. Loss: 0.625983 | Val. Kappa Score: 0.6222 | LR: 0.000010 | Estimated time: 158.17
Train loss on 50 batch: 0.744643
Train loss on 100 batch: 0.668766
: Epoch: 22 | Training Loss: 0.683155 | Val. Loss: 0.643535 | Val. Kappa Score: 0.6277 | LR: 0.000010 | Estimated time: 160.25
Train loss on 50 batch: 0.749437
Train loss on 100 batch: 0.676146
: Epoch: 23 | Training Loss: 0.659477 | Val. Loss: 0.648575 | Val. Kappa Score: 0.6331 | LR: 0.000010 | Estimated time: 159.34
Train loss on 50 batch: 0.695121
Train loss on 100 batch: 0.693263
: Epoch: 24 | Training Loss: 0.690063 | Val. Loss: 0.640367 | Val. Kappa Score: 0.6381 | LR: 0.000010 | Estimated time: 157.39
Train loss on 50 batch: 0.661242
Train loss on 100 batch: 0.771135
: Epoch: 25 | Training Loss: 0.675834 | Val. Loss: 0.671252 | Val. Kappa Score: 0.6418 | LR: 0.000001 | Estimated time: 157.84
Train loss on 50 batch: 0.722383
Train loss on 100 batch: 0.669868
: Epoch: 26 | Training Loss: 0.670899 | Val. Loss: 0.643987 | Val. Kappa Score: 0.6461 | LR: 0.000001 | Estimated time: 157.85
Train loss on 50 batch: 0.724342
Train loss on 100 batch: 0.708305
: Epoch: 27 | Training Loss: 0.740835 | Val. Loss: 0.649078 | Val. Kappa Score: 0.6504 | LR: 0.000001 | Estimated time: 157.28
Train loss on 50 batch: 0.701144
Train loss on 100 batch: 0.684021
best-train-loss: 0.733196
best-valid-loss: 0.624957
best-kappa: 0.6544
: Epoch: 28 | Training Loss: 0.733196 | Val. Loss: 0.624957 | Val. Kappa Score: 0.6544 | LR: 0.000001 | Estimated time: 159.36
Train loss on 50 batch: 0.702985
Train loss on 100 batch: 0.719899
: Epoch: 29 | Training Loss: 0.703513 | Val. Loss: 0.711685 | Val. Kappa Score: 0.6571 | LR: 0.000001 | Estimated time: 159.35
Train loss on 50 batch: 0.693363
Train loss on 100 batch: 0.716522
: Epoch: 30 | Training Loss: 0.661957 | Val. Loss: 0.656900 | Val. Kappa Score: 0.6603 | LR: 0.000000 | Estimated time: 158.66
time_estimated: 4743.16
----------------------------------------

Experiment N: 61: 



EXPERIMENT WITH BATCH_SIZE: 32, LR: 0.0001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.12 19:49:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.0001
    lr: 0.0001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7efb960219b0>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 30
batch-size: 32
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.380920
Train loss on 100 batch: 0.608192
best-train-loss: 0.870903
best-valid-loss: 0.999745
best-kappa: 0.6186
: Epoch: 1 | Training Loss: 0.870903 | Val. Loss: 0.999745 | Val. Kappa Score: 0.6186 | LR: 0.000100 | Estimated time: 158.36
Train loss on 50 batch: 0.441642
Train loss on 100 batch: 0.458852
best-train-loss: 0.435273
best-valid-loss: 0.553027
best-kappa: 0.7029
: Epoch: 2 | Training Loss: 0.435273 | Val. Loss: 0.553027 | Val. Kappa Score: 0.7029 | LR: 0.000100 | Estimated time: 158.75
Train loss on 50 batch: 0.406615
Train loss on 100 batch: 0.370867
best-train-loss: 0.390201
best-valid-loss: 0.397995
best-kappa: 0.7552
: Epoch: 3 | Training Loss: 0.390201 | Val. Loss: 0.397995 | Val. Kappa Score: 0.7552 | LR: 0.000100 | Estimated time: 156.79
Train loss on 50 batch: 0.391509
Train loss on 100 batch: 0.374926
best-train-loss: 0.449084
best-valid-loss: 0.350186
best-kappa: 0.7834
: Epoch: 4 | Training Loss: 0.449084 | Val. Loss: 0.350186 | Val. Kappa Score: 0.7834 | LR: 0.000100 | Estimated time: 157.04
Train loss on 50 batch: 0.295960
Train loss on 100 batch: 0.359956
best-train-loss: 0.322667
best-valid-loss: 0.346553
best-kappa: 0.8022
: Epoch: 5 | Training Loss: 0.322667 | Val. Loss: 0.346553 | Val. Kappa Score: 0.8022 | LR: 0.000010 | Estimated time: 157.83
Train loss on 50 batch: 0.313914
Train loss on 100 batch: 0.283761
best-train-loss: 0.343313
best-valid-loss: 0.322304
best-kappa: 0.8140
: Epoch: 6 | Training Loss: 0.343313 | Val. Loss: 0.322304 | Val. Kappa Score: 0.8140 | LR: 0.000010 | Estimated time: 157.22
Train loss on 50 batch: 0.305464
Train loss on 100 batch: 0.304686
: Epoch: 7 | Training Loss: 0.300569 | Val. Loss: 0.323520 | Val. Kappa Score: 0.8239 | LR: 0.000010 | Estimated time: 157.27
Train loss on 50 batch: 0.289682
Train loss on 100 batch: 0.300131
: Epoch: 8 | Training Loss: 0.298418 | Val. Loss: 0.324170 | Val. Kappa Score: 0.8310 | LR: 0.000010 | Estimated time: 157.24
Train loss on 50 batch: 0.317848
Train loss on 100 batch: 0.296079
: Epoch: 9 | Training Loss: 0.303366 | Val. Loss: 0.323713 | Val. Kappa Score: 0.8365 | LR: 0.000010 | Estimated time: 157.91
Train loss on 50 batch: 0.283552
Train loss on 100 batch: 0.272189
best-train-loss: 0.275299
best-valid-loss: 0.316107
best-kappa: 0.8400
: Epoch: 10 | Training Loss: 0.275299 | Val. Loss: 0.316107 | Val. Kappa Score: 0.8400 | LR: 0.000001 | Estimated time: 156.89
Train loss on 50 batch: 0.288837
Train loss on 100 batch: 0.254624
: Epoch: 11 | Training Loss: 0.264012 | Val. Loss: 0.324227 | Val. Kappa Score: 0.8443 | LR: 0.000001 | Estimated time: 157.40
Train loss on 50 batch: 0.301592
Train loss on 100 batch: 0.278713
: Epoch: 12 | Training Loss: 0.287292 | Val. Loss: 0.349307 | Val. Kappa Score: 0.8470 | LR: 0.000001 | Estimated time: 156.73
Train loss on 50 batch: 0.271613
Train loss on 100 batch: 0.275498
: Epoch: 13 | Training Loss: 0.286876 | Val. Loss: 0.357659 | Val. Kappa Score: 0.8490 | LR: 0.000001 | Estimated time: 157.32
Train loss on 50 batch: 0.294750
Train loss on 100 batch: 0.297988
: Epoch: 14 | Training Loss: 0.285637 | Val. Loss: 0.316571 | Val. Kappa Score: 0.8514 | LR: 0.000001 | Estimated time: 158.02
Train loss on 50 batch: 0.284392
Train loss on 100 batch: 0.286182
best-train-loss: 0.265420
best-valid-loss: 0.315985
best-kappa: 0.8538
: Epoch: 15 | Training Loss: 0.265420 | Val. Loss: 0.315985 | Val. Kappa Score: 0.8538 | LR: 0.000000 | Estimated time: 160.07
Train loss on 50 batch: 0.267553
Train loss on 100 batch: 0.294527
: Epoch: 16 | Training Loss: 0.264543 | Val. Loss: 0.324403 | Val. Kappa Score: 0.8559 | LR: 0.000000 | Estimated time: 158.93
Train loss on 50 batch: 0.268759
----------------------------------------


Experiment N: 62: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.12 20:43:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f9aba8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 30
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.973801
Train loss on 100 batch: 0.618467
Train loss on 150 batch: 0.546066
best-train-loss: 0.645180
best-valid-loss: 0.402921
best-kappa: 0.8347
: Epoch: 1 | Training Loss: 0.645180 | Val. Loss: 0.402921 | Val. Kappa Score: 0.8347 | LR: 0.001000 | Estimated time: 163.81
Train loss on 50 batch: 0.403439
Train loss on 100 batch: 0.392092
Train loss on 150 batch: 0.373336
best-train-loss: 0.409117
best-valid-loss: 0.371231
best-kappa: 0.8455
: Epoch: 2 | Training Loss: 0.409117 | Val. Loss: 0.371231 | Val. Kappa Score: 0.8455 | LR: 0.001000 | Estimated time: 164.46
Train loss on 50 batch: 0.371321
Train loss on 100 batch: 0.386238
Train loss on 150 batch: 0.359144
best-train-loss: 0.372362
best-valid-loss: 0.345617
best-kappa: 0.8565
: Epoch: 3 | Training Loss: 0.372362 | Val. Loss: 0.345617 | Val. Kappa Score: 0.8565 | LR: 0.001000 | Estimated time: 164.38
Train loss on 50 batch: 0.370446
Train loss on 100 batch: 0.389949
Train loss on 150 batch: 0.391898
: Epoch: 4 | Training Loss: 0.425012 | Val. Loss: 1.170515 | Val. Kappa Score: 0.8216 | LR: 0.001000 | Estimated time: 163.99
Train loss on 50 batch: 0.448551
Train loss on 100 batch: 0.465721
Train loss on 150 batch: 0.339096
: Epoch: 5 | Training Loss: 0.399315 | Val. Loss: 0.367464 | Val. Kappa Score: 0.8304 | LR: 0.001000 | Estimated time: 166.81
Train loss on 50 batch: 0.358893
Train loss on 100 batch: 0.320198
Train loss on 150 batch: 0.331102
: Epoch: 6 | Training Loss: 0.329746 | Val. Loss: 0.486286 | Val. Kappa Score: 0.8281 | LR: 0.000500 | Estimated time: 167.89
Train loss on 50 batch: 0.304146
Train loss on 100 batch: 0.247034
Train loss on 150 batch: 0.215359
best-train-loss: 0.259737
best-valid-loss: 0.284161
best-kappa: 0.8382
: Epoch: 7 | Training Loss: 0.259737 | Val. Loss: 0.284161 | Val. Kappa Score: 0.8382 | LR: 0.000500 | Estimated time: 163.87
Train loss on 50 batch: 0.192874
Train loss on 100 batch: 0.255593
Train loss on 150 batch: 0.210202
best-train-loss: 0.228527
best-valid-loss: 0.251551
best-kappa: 0.8465
: Epoch: 8 | Training Loss: 0.228527 | Val. Loss: 0.251551 | Val. Kappa Score: 0.8465 | LR: 0.000500 | Estimated time: 163.45
Train loss on 50 batch: 0.201772
Train loss on 100 batch: 0.231798
Train loss on 150 batch: 0.254675
: Epoch: 9 | Training Loss: 0.222921 | Val. Loss: 0.262564 | Val. Kappa Score: 0.8531 | LR: 0.000500 | Estimated time: 165.43
Train loss on 50 batch: 0.187501
Train loss on 100 batch: 0.228868
Train loss on 150 batch: 0.237037
: Epoch: 10 | Training Loss: 0.267096 | Val. Loss: 0.284689 | Val. Kappa Score: 0.8583 | LR: 0.000500 | Estimated time: 164.40
Train loss on 50 batch: 0.209946
Train loss on 100 batch: 0.224604
Train loss on 150 batch: 0.203510
: Epoch: 11 | Training Loss: 0.226777 | Val. Loss: 0.348296 | Val. Kappa Score: 0.8581 | LR: 0.000250 | Estimated time: 165.75
Train loss on 50 batch: 0.173337
Train loss on 100 batch: 0.171554
Train loss on 150 batch: 0.190376
: Epoch: 12 | Training Loss: 0.184713 | Val. Loss: 0.287887 | Val. Kappa Score: 0.8607 | LR: 0.000250 | Estimated time: 163.04
Train loss on 50 batch: 0.162188
Train loss on 100 batch: 0.185293
Train loss on 150 batch: 0.169925
: Epoch: 13 | Training Loss: 0.176753 | Val. Loss: 0.280698 | Val. Kappa Score: 0.8634 | LR: 0.000250 | Estimated time: 164.70
Train loss on 50 batch: 0.156088
Train loss on 100 batch: 0.153435
Train loss on 150 batch: 0.159727
: Epoch: 14 | Training Loss: 0.164782 | Val. Loss: 0.268985 | Val. Kappa Score: 0.8661 | LR: 0.000125 | Estimated time: 164.87
Train loss on 50 batch: 0.152319
Train loss on 100 batch: 0.140170
Train loss on 150 batch: 0.154907
: Epoch: 15 | Training Loss: 0.148522 | Val. Loss: 0.260365 | Val. Kappa Score: 0.8684 | LR: 0.000125 | Estimated time: 163.16
Train loss on 50 batch: 0.125025
Train loss on 100 batch: 0.124865
Train loss on 150 batch: 0.116214
: Epoch: 16 | Training Loss: 0.123594 | Val. Loss: 0.287489 | Val. Kappa Score: 0.8698 | LR: 0.000125 | Estimated time: 165.27
time_estimated: 2635.92
n-epochs: 16
time_estimated: 2635.93
----------------------------------------

Experiment N: 63: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.12 21:28:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d107320>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 30
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
Train loss on 150 batch: 0.580317
best-train-loss: 0.665603
best-valid-loss: 1.313840
best-kappa: 0.7634
: Epoch: 1 | Training Loss: 0.665603 | Val. Loss: 1.313840 | Val. Kappa Score: 0.7634 | LR: 0.001000 | Estimated time: 163.82
Train loss on 50 batch: 0.449402
Train loss on 100 batch: 0.436332
Train loss on 150 batch: 0.361186
best-train-loss: 0.433382
best-valid-loss: 0.589005
best-kappa: 0.7821
: Epoch: 2 | Training Loss: 0.433382 | Val. Loss: 0.589005 | Val. Kappa Score: 0.7821 | LR: 0.001000 | Estimated time: 163.42
Train loss on 50 batch: 0.428939
Train loss on 100 batch: 0.404851
Train loss on 150 batch: 0.359333
best-train-loss: 0.381546
best-valid-loss: 0.409963
best-kappa: 0.8099
: Epoch: 3 | Training Loss: 0.381546 | Val. Loss: 0.409963 | Val. Kappa Score: 0.8099 | LR: 0.001000 | Estimated time: 164.13
Train loss on 50 batch: 0.348709
Train loss on 100 batch: 0.432814
Train loss on 150 batch: 0.373456
: Epoch: 4 | Training Loss: 0.444343 | Val. Loss: 0.477215 | Val. Kappa Score: 0.8197 | LR: 0.001000 | Estimated time: 163.77
Train loss on 50 batch: 0.466406
Train loss on 100 batch: 0.387579
Train loss on 150 batch: 0.332170
: Epoch: 5 | Training Loss: 0.383666 | Val. Loss: 0.438406 | Val. Kappa Score: 0.8231 | LR: 0.001000 | Estimated time: 167.43
Train loss on 50 batch: 0.363705
Train loss on 100 batch: 0.325094
Train loss on 150 batch: 0.330419
best-train-loss: 0.335334
best-valid-loss: 0.319121
best-kappa: 0.8325
: Epoch: 6 | Training Loss: 0.335334 | Val. Loss: 0.319121 | Val. Kappa Score: 0.8325 | LR: 0.001000 | Estimated time: 163.72
Train loss on 50 batch: 0.321575
Train loss on 100 batch: 0.317086
Train loss on 150 batch: 0.304792
best-train-loss: 0.311302
best-valid-loss: 0.304397
best-kappa: 0.8406
: Epoch: 7 | Training Loss: 0.311302 | Val. Loss: 0.304397 | Val. Kappa Score: 0.8406 | LR: 0.001000 | Estimated time: 165.60
Train loss on 50 batch: 0.243176
Train loss on 100 batch: 0.323752
Train loss on 150 batch: 0.263664
: Epoch: 8 | Training Loss: 0.298023 | Val. Loss: 0.308798 | Val. Kappa Score: 0.8472 | LR: 0.001000 | Estimated time: 167.05
Train loss on 50 batch: 0.322637
Train loss on 100 batch: 0.305392
Train loss on 150 batch: 0.331666
: Epoch: 9 | Training Loss: 0.306835 | Val. Loss: 0.310118 | Val. Kappa Score: 0.8518 | LR: 0.001000 | Estimated time: 165.02
Train loss on 50 batch: 0.272988
Train loss on 100 batch: 0.317419
Train loss on 150 batch: 0.270124
: Epoch: 10 | Training Loss: 0.358562 | Val. Loss: 0.427910 | Val. Kappa Score: 0.8476 | LR: 0.000500 | Estimated time: 164.69
Train loss on 50 batch: 0.239867
Train loss on 100 batch: 0.239563
Train loss on 150 batch: 0.229944
best-train-loss: 0.248121
best-valid-loss: 0.282691
best-kappa: 0.8509
: Epoch: 11 | Training Loss: 0.248121 | Val. Loss: 0.282691 | Val. Kappa Score: 0.8509 | LR: 0.000500 | Estimated time: 164.74
Train loss on 50 batch: 0.183481
Train loss on 100 batch: 0.203020
Train loss on 150 batch: 0.203880
: Epoch: 12 | Training Loss: 0.200980 | Val. Loss: 0.294231 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 163.70
Train loss on 50 batch: 0.169855
Train loss on 100 batch: 0.228281
Train loss on 150 batch: 0.199570
: Epoch: 13 | Training Loss: 0.205337 | Val. Loss: 0.340016 | Val. Kappa Score: 0.8552 | LR: 0.000500 | Estimated time: 164.67
Train loss on 50 batch: 0.186955
Train loss on 100 batch: 0.192416
Train loss on 150 batch: 0.208173
best-train-loss: 0.205660
best-valid-loss: 0.257970
best-kappa: 0.8582
: Epoch: 14 | Training Loss: 0.205660 | Val. Loss: 0.257970 | Val. Kappa Score: 0.8582 | LR: 0.000500 | Estimated time: 164.75
Train loss on 50 batch: 0.221033
Train loss on 100 batch: 0.191676
Train loss on 150 batch: 0.207478
: Epoch: 15 | Training Loss: 0.206612 | Val. Loss: 0.268114 | Val. Kappa Score: 0.8606 | LR: 0.000500 | Estimated time: 164.25
Train loss on 50 batch: 0.187782
Train loss on 100 batch: 0.170692
Train loss on 150 batch: 0.153422
: Epoch: 16 | Training Loss: 0.178677 | Val. Loss: 0.269115 | Val. Kappa Score: 0.8623 | LR: 0.000500 | Estimated time: 164.64
Train loss on 50 batch: 0.193814
Train loss on 100 batch: 0.184197
Train loss on 150 batch: 0.167149
: Epoch: 17 | Training Loss: 0.182851 | Val. Loss: 0.285018 | Val. Kappa Score: 0.8641 | LR: 0.000250 | Estimated time: 164.25
Train loss on 50 batch: 0.157030
Train loss on 100 batch: 0.117172
Train loss on 150 batch: 0.166063
: Epoch: 18 | Training Loss: 0.149435 | Val. Loss: 0.282949 | Val. Kappa Score: 0.8656 | LR: 0.000250 | Estimated time: 163.29
Train loss on 50 batch: 0.114739
Train loss on 100 batch: 0.145791
Train loss on 150 batch: 0.134199
: Epoch: 19 | Training Loss: 0.134297 | Val. Loss: 0.316790 | Val. Kappa Score: 0.8669 | LR: 0.000250 | Estimated time: 164.66
Train loss on 50 batch: 0.110565
Train loss on 100 batch: 0.143119
Train loss on 150 batch: 0.134156
: Epoch: 20 | Training Loss: 0.124275 | Val. Loss: 0.295902 | Val. Kappa Score: 0.8680 | LR: 0.000125 | Estimated time: 163.85
Train loss on 50 batch: 0.119500
Train loss on 100 batch: 0.099390
Train loss on 150 batch: 0.127907
: Epoch: 21 | Training Loss: 0.136079 | Val. Loss: 0.277667 | Val. Kappa Score: 0.8695 | LR: 0.000125 | Estimated time: 163.53
Train loss on 50 batch: 0.102117
Train loss on 100 batch: 0.120021
Train loss on 150 batch: 0.106643
: Epoch: 22 | Training Loss: 0.108784 | Val. Loss: 0.287053 | Val. Kappa Score: 0.8711 | LR: 0.000125 | Estimated time: 164.86
time_estimated: 3620.77
n-epochs: 22
time_estimated: 3620.78
----------------------------------------

Experiment N: 64: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.12 22:35:51
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d101780>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
Train loss on 150 batch: 0.580317
best-train-loss: 0.665603
best-valid-loss: 1.313840
best-kappa: 0.7634
: Epoch: 1 | Training Loss: 0.665603 | Val. Loss: 1.313840 | Val. Kappa Score: 0.7634 | LR: 0.001000 | Estimated time: 165.06
Train loss on 50 batch: 0.449402
Train loss on 100 batch: 0.436332
Train loss on 150 batch: 0.361186
best-train-loss: 0.433382
best-valid-loss: 0.589005
best-kappa: 0.7821
: Epoch: 2 | Training Loss: 0.433382 | Val. Loss: 0.589005 | Val. Kappa Score: 0.7821 | LR: 0.001000 | Estimated time: 165.40
Train loss on 50 batch: 0.428939
Train loss on 100 batch: 0.404851
Train loss on 150 batch: 0.359333
best-train-loss: 0.381546
best-valid-loss: 0.409963
best-kappa: 0.8099
: Epoch: 3 | Training Loss: 0.381546 | Val. Loss: 0.409963 | Val. Kappa Score: 0.8099 | LR: 0.001000 | Estimated time: 164.19
Train loss on 50 batch: 0.348709
Train loss on 100 batch: 0.432814
Train loss on 150 batch: 0.373456
best-train-loss: 0.444343
best-valid-loss: 0.477215
best-kappa: 0.8197
: Epoch: 4 | Training Loss: 0.444343 | Val. Loss: 0.477215 | Val. Kappa Score: 0.8197 | LR: 0.000500 | Estimated time: 163.48
Train loss on 50 batch: 0.419736
Train loss on 100 batch: 0.341884
Train loss on 150 batch: 0.241203
best-train-loss: 0.324323
best-valid-loss: 0.282617
best-kappa: 0.8335
: Epoch: 5 | Training Loss: 0.324323 | Val. Loss: 0.282617 | Val. Kappa Score: 0.8335 | LR: 0.000500 | Estimated time: 167.33
Train loss on 50 batch: 0.258992
Train loss on 100 batch: 0.271299
Train loss on 150 batch: 0.262240
best-train-loss: 0.253126
best-valid-loss: 0.319724
best-kappa: 0.8404
: Epoch: 6 | Training Loss: 0.253126 | Val. Loss: 0.319724 | Val. Kappa Score: 0.8404 | LR: 0.000500 | Estimated time: 165.60
Train loss on 50 batch: 0.262011
Train loss on 100 batch: 0.249370
Train loss on 150 batch: 0.223065
best-train-loss: 0.246594
best-valid-loss: 0.281995
best-kappa: 0.8479
: Epoch: 7 | Training Loss: 0.246594 | Val. Loss: 0.281995 | Val. Kappa Score: 0.8479 | LR: 0.000250 | Estimated time: 165.15
Train loss on 50 batch: 0.200224
Train loss on 100 batch: 0.219056
Train loss on 150 batch: 0.194272
best-train-loss: 0.216106
best-valid-loss: 0.252706
best-kappa: 0.8542
: Epoch: 8 | Training Loss: 0.216106 | Val. Loss: 0.252706 | Val. Kappa Score: 0.8542 | LR: 0.000250 | Estimated time: 166.40
Train loss on 50 batch: 0.197053
Train loss on 100 batch: 0.225979
Train loss on 150 batch: 0.219555
best-train-loss: 0.204663
best-valid-loss: 0.257906
best-kappa: 0.8585
: Epoch: 9 | Training Loss: 0.204663 | Val. Loss: 0.257906 | Val. Kappa Score: 0.8585 | LR: 0.000250 | Estimated time: 166.71
Train loss on 50 batch: 0.171977
Train loss on 100 batch: 0.173218
Train loss on 150 batch: 0.204917
best-train-loss: 0.244004
best-valid-loss: 0.273210
best-kappa: 0.8616
: Epoch: 10 | Training Loss: 0.244004 | Val. Loss: 0.273210 | Val. Kappa Score: 0.8616 | LR: 0.000125 | Estimated time: 164.77
Train loss on 50 batch: 0.165223
Train loss on 100 batch: 0.176327
Train loss on 150 batch: 0.168043
best-train-loss: 0.177710
best-valid-loss: 0.262639
best-kappa: 0.8644
: Epoch: 11 | Training Loss: 0.177710 | Val. Loss: 0.262639 | Val. Kappa Score: 0.8644 | LR: 0.000125 | Estimated time: 166.65
Train loss on 50 batch: 0.126038
Train loss on 100 batch: 0.136699
Train loss on 150 batch: 0.154977
----------------------------------------

Experiment N: 65: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.12 23:09:31
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d101780>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.363705
Train loss on 100 batch: 0.325094
Train loss on 150 batch: 0.330419
best-train-loss: 0.335334
best-valid-loss: 0.319121
best-kappa: 0.8325
: Epoch: 6 | Training Loss: 0.335334 | Val. Loss: 0.319121 | Val. Kappa Score: 0.8325 | LR: 0.001000 | Estimated time: 168.03
Train loss on 50 batch: 0.321575
Train loss on 100 batch: 0.317086
Train loss on 150 batch: 0.304792
best-train-loss: 0.311302
best-valid-loss: 0.304397
best-kappa: 0.8406
: Epoch: 7 | Training Loss: 0.311302 | Val. Loss: 0.304397 | Val. Kappa Score: 0.8406 | LR: 0.001000 | Estimated time: 164.84
Train loss on 50 batch: 0.243176
Train loss on 100 batch: 0.323752
Train loss on 150 batch: 0.263664
best-train-loss: 0.298023
best-valid-loss: 0.308798
best-kappa: 0.8472
: Epoch: 8 | Training Loss: 0.298023 | Val. Loss: 0.308798 | Val. Kappa Score: 0.8472 | LR: 0.001000 | Estimated time: 164.93
Train loss on 50 batch: 0.322637
Train loss on 100 batch: 0.305392
Train loss on 150 batch: 0.331666
best-train-loss: 0.306835
best-valid-loss: 0.310118
best-kappa: 0.8518
: Epoch: 9 | Training Loss: 0.306835 | Val. Loss: 0.310118 | Val. Kappa Score: 0.8518 | LR: 0.001000 | Estimated time: 164.09
Train loss on 50 batch: 0.272988
Train loss on 100 batch: 0.317419
Train loss on 150 batch: 0.270124
: Epoch: 10 | Training Loss: 0.358562 | Val. Loss: 0.427910 | Val. Kappa Score: 0.8476 | LR: 0.001000 | Estimated time: 163.68
Train loss on 50 batch: 0.272046
Train loss on 100 batch: 0.278645
Train loss on 150 batch: 0.307655
: Epoch: 11 | Training Loss: 0.304570 | Val. Loss: 0.319394 | Val. Kappa Score: 0.8494 | LR: 0.001000 | Estimated time: 163.83
Train loss on 50 batch: 0.258306
Train loss on 100 batch: 0.263183
Train loss on 150 batch: 0.269823
best-train-loss: 0.260321
best-valid-loss: 0.306609
best-kappa: 0.8523
: Epoch: 12 | Training Loss: 0.260321 | Val. Loss: 0.306609 | Val. Kappa Score: 0.8523 | LR: 0.001000 | Estimated time: 165.23
Train loss on 50 batch: 0.208250
Train loss on 100 batch: 0.290500
Train loss on 150 batch: 0.319167
best-train-loss: 0.284776
best-valid-loss: 0.378703
best-kappa: 0.8528
: Epoch: 13 | Training Loss: 0.284776 | Val. Loss: 0.378703 | Val. Kappa Score: 0.8528 | LR: 0.001000 | Estimated time: 167.84
Train loss on 50 batch: 0.261663
Train loss on 100 batch: 0.261294
Train loss on 150 batch: 0.280391
: Epoch: 14 | Training Loss: 0.280546 | Val. Loss: 0.515201 | Val. Kappa Score: 0.8484 | LR: 0.001000 | Estimated time: 165.39
Train loss on 50 batch: 0.335216
Train loss on 100 batch: 0.243509
Train loss on 150 batch: 0.242129
: Epoch: 15 | Training Loss: 0.275564 | Val. Loss: 0.352096 | Val. Kappa Score: 0.8493 | LR: 0.001000 | Estimated time: 164.99
Train loss on 50 batch: 0.290269
Train loss on 100 batch: 0.244168
Train loss on 150 batch: 0.238977
: Epoch: 16 | Training Loss: 0.256091 | Val. Loss: 0.312212 | Val. Kappa Score: 0.8509 | LR: 0.000500 | Estimated time: 163.17
Train loss on 50 batch: 0.235253
Train loss on 100 batch: 0.216275
Train loss on 150 batch: 0.169230
best-train-loss: 0.203552
best-valid-loss: 0.277467
best-kappa: 0.8534
: Epoch: 17 | Training Loss: 0.203552 | Val. Loss: 0.277467 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 164.21
Train loss on 50 batch: 0.182528
Train loss on 100 batch: 0.157330
Train loss on 150 batch: 0.186624
best-train-loss: 0.186173
best-valid-loss: 0.299502
best-kappa: 0.8551
: Epoch: 18 | Training Loss: 0.186173 | Val. Loss: 0.299502 | Val. Kappa Score: 0.8551 | LR: 0.000500 | Estimated time: 162.91
Train loss on 50 batch: 0.160174
Train loss on 100 batch: 0.205711
Train loss on 150 batch: 0.183514
best-train-loss: 0.187755
best-valid-loss: 0.316150
best-kappa: 0.8570
: Epoch: 19 | Training Loss: 0.187755 | Val. Loss: 0.316150 | Val. Kappa Score: 0.8570 | LR: 0.000500 | Estimated time: 164.06
Train loss on 50 batch: 0.145145
Train loss on 100 batch: 0.196533
Train loss on 150 batch: 0.163986
best-train-loss: 0.165078
best-valid-loss: 0.295819
best-kappa: 0.8588
: Epoch: 20 | Training Loss: 0.165078 | Val. Loss: 0.295819 | Val. Kappa Score: 0.8588 | LR: 0.000500 | Estimated time: 162.65
Train loss on 50 batch: 0.180386
Train loss on 100 batch: 0.154446
Train loss on 150 batch: 0.195859
best-train-loss: 0.194472
best-valid-loss: 0.323905
best-kappa: 0.8599
: Epoch: 21 | Training Loss: 0.194472 | Val. Loss: 0.323905 | Val. Kappa Score: 0.8599 | LR: 0.000500 | Estimated time: 163.20
Train loss on 50 batch: 0.157356
Train loss on 100 batch: 0.165140
Train loss on 150 batch: 0.188530
best-train-loss: 0.170114
best-valid-loss: 0.293959
best-kappa: 0.8617
: Epoch: 22 | Training Loss: 0.170114 | Val. Loss: 0.293959 | Val. Kappa Score: 0.8617 | LR: 0.000500 | Estimated time: 164.61
Train loss on 50 batch: 0.143039
Train loss on 100 batch: 0.161329
Train loss on 150 batch: 0.142236
best-train-loss: 0.155823
best-valid-loss: 0.311356
best-kappa: 0.8624
: Epoch: 23 | Training Loss: 0.155823 | Val. Loss: 0.311356 | Val. Kappa Score: 0.8624 | LR: 0.000500 | Estimated time: 165.74
Train loss on 50 batch: 0.152263
Train loss on 100 batch: 0.164532
Train loss on 150 batch: 0.182704
best-train-loss: 0.235136
best-valid-loss: 0.316500
best-kappa: 0.8630
: Epoch: 24 | Training Loss: 0.235136 | Val. Loss: 0.316500 | Val. Kappa Score: 0.8630 | LR: 0.000500 | Estimated time: 163.05
Train loss on 50 batch: 0.197063
Train loss on 100 batch: 0.166273
Train loss on 150 batch: 0.203572
best-train-loss: 0.198230
best-valid-loss: 0.303275
best-kappa: 0.8638
: Epoch: 25 | Training Loss: 0.198230 | Val. Loss: 0.303275 | Val. Kappa Score: 0.8638 | LR: 0.000500 | Estimated time: 163.97
Train loss on 50 batch: 0.181240
Train loss on 100 batch: 0.146656
Train loss on 150 batch: 0.150757
best-train-loss: 0.191818
best-valid-loss: 0.373301
best-kappa: 0.8642
: Epoch: 26 | Training Loss: 0.191818 | Val. Loss: 0.373301 | Val. Kappa Score: 0.8642 | LR: 0.000500 | Estimated time: 163.28
Train loss on 50 batch: 0.180149
Train loss on 100 batch: 0.188726
Train loss on 150 batch: 0.139859
best-train-loss: 0.157592
best-valid-loss: 0.280832
best-kappa: 0.8653
: Epoch: 27 | Training Loss: 0.157592 | Val. Loss: 0.280832 | Val. Kappa Score: 0.8653 | LR: 0.000500 | Estimated time: 163.85
Train loss on 50 batch: 0.147180
Train loss on 100 batch: 0.163160
Train loss on 150 batch: 0.128185
best-train-loss: 0.142939
best-valid-loss: 0.310400
best-kappa: 0.8661
: Epoch: 28 | Training Loss: 0.142939 | Val. Loss: 0.310400 | Val. Kappa Score: 0.8661 | LR: 0.000500 | Estimated time: 163.89
Train loss on 50 batch: 0.110149
Train loss on 100 batch: 0.126408
Train loss on 150 batch: 0.117112
best-train-loss: 0.123598
best-valid-loss: 0.307811
best-kappa: 0.8666
: Epoch: 29 | Training Loss: 0.123598 | Val. Loss: 0.307811 | Val. Kappa Score: 0.8666 | LR: 0.000500 | Estimated time: 163.87
Train loss on 50 batch: 0.121628
Train loss on 100 batch: 0.125242
Train loss on 150 batch: 0.132158
best-train-loss: 0.132050
best-valid-loss: 0.272112
best-kappa: 0.8673
: Epoch: 30 | Training Loss: 0.132050 | Val. Loss: 0.272112 | Val. Kappa Score: 0.8673 | LR: 0.000500 | Estimated time: 165.71
Train loss on 50 batch: 0.111953
Train loss on 100 batch: 0.167181
Train loss on 150 batch: 0.131706
best-train-loss: 0.166754
best-valid-loss: 0.302829
best-kappa: 0.8683
: Epoch: 31 | Training Loss: 0.166754 | Val. Loss: 0.302829 | Val. Kappa Score: 0.8683 | LR: 0.000500 | Estimated time: 164.59
Train loss on 50 batch: 0.166081
Train loss on 100 batch: 0.144894
Train loss on 150 batch: 0.126671
best-train-loss: 0.146561
best-valid-loss: 0.281175
best-kappa: 0.8686
: Epoch: 32 | Training Loss: 0.146561 | Val. Loss: 0.281175 | Val. Kappa Score: 0.8686 | LR: 0.000500 | Estimated time: 163.50
Train loss on 50 batch: 0.111976
Train loss on 100 batch: 0.115901
Train loss on 150 batch: 0.120367
best-train-loss: 0.123156
best-valid-loss: 0.310624
best-kappa: 0.8691
: Epoch: 33 | Training Loss: 0.123156 | Val. Loss: 0.310624 | Val. Kappa Score: 0.8691 | LR: 0.000500 | Estimated time: 164.03
Train loss on 50 batch: 0.089150
Train loss on 100 batch: 0.127670
Train loss on 150 batch: 0.126858
best-train-loss: 0.114717
best-valid-loss: 0.331133
best-kappa: 0.8695
: Epoch: 34 | Training Loss: 0.114717 | Val. Loss: 0.331133 | Val. Kappa Score: 0.8695 | LR: 0.000500 | Estimated time: 164.34
Train loss on 50 batch: 0.106538
Train loss on 100 batch: 0.128255
Train loss on 150 batch: 0.141605
best-train-loss: 0.126782
best-valid-loss: 0.311417
best-kappa: 0.8699
: Epoch: 35 | Training Loss: 0.126782 | Val. Loss: 0.311417 | Val. Kappa Score: 0.8699 | LR: 0.000500 | Estimated time: 163.34
Train loss on 50 batch: 0.090710
Train loss on 100 batch: 0.102697
Train loss on 150 batch: 0.114083
best-train-loss: 0.112005
best-valid-loss: 0.346427
best-kappa: 0.8699
: Epoch: 36 | Training Loss: 0.112005 | Val. Loss: 0.346427 | Val. Kappa Score: 0.8699 | LR: 0.000500 | Estimated time: 163.80
Train loss on 50 batch: 0.115673
Train loss on 100 batch: 0.119710
Train loss on 150 batch: 0.098306
best-train-loss: 0.114391
best-valid-loss: 0.329570
best-kappa: 0.8702
: Epoch: 37 | Training Loss: 0.114391 | Val. Loss: 0.329570 | Val. Kappa Score: 0.8702 | LR: 0.000500 | Estimated time: 163.90
Train loss on 50 batch: 0.096435
Train loss on 100 batch: 0.095784
Train loss on 150 batch: 0.090816
best-train-loss: 0.143546
best-valid-loss: 0.324329
best-kappa: 0.8707
: Epoch: 38 | Training Loss: 0.143546 | Val. Loss: 0.324329 | Val. Kappa Score: 0.8707 | LR: 0.000500 | Estimated time: 164.67
Train loss on 50 batch: 0.178236
Train loss on 100 batch: 0.138334
Train loss on 150 batch: 0.131101
best-train-loss: 0.138331
best-valid-loss: 0.302933
best-kappa: 0.8710
: Epoch: 39 | Training Loss: 0.138331 | Val. Loss: 0.302933 | Val. Kappa Score: 0.8710 | LR: 0.000500 | Estimated time: 164.28
Train loss on 50 batch: 0.099408
Train loss on 100 batch: 0.123984
Train loss on 150 batch: 0.114014
best-train-loss: 0.105425
best-valid-loss: 0.305379
best-kappa: 0.8713
: Epoch: 40 | Training Loss: 0.105425 | Val. Loss: 0.305379 | Val. Kappa Score: 0.8713 | LR: 0.000500 | Estimated time: 164.88
Train loss on 50 batch: 0.084416
Train loss on 100 batch: 0.091032
Train loss on 150 batch: 0.085612
best-train-loss: 0.098755
best-valid-loss: 0.310353
best-kappa: 0.8716
: Epoch: 41 | Training Loss: 0.098755 | Val. Loss: 0.310353 | Val. Kappa Score: 0.8716 | LR: 0.000500 | Estimated time: 163.99
Train loss on 50 batch: 0.118337
Train loss on 100 batch: 0.101526
Train loss on 150 batch: 0.085468
best-train-loss: 0.104123
best-valid-loss: 0.306222
best-kappa: 0.8720
: Epoch: 42 | Training Loss: 0.104123 | Val. Loss: 0.306222 | Val. Kappa Score: 0.8720 | LR: 0.000500 | Estimated time: 164.80
Train loss on 50 batch: 0.092862
Train loss on 100 batch: 0.103272
Train loss on 150 batch: 0.083510
best-train-loss: 0.098512
best-valid-loss: 0.338617
best-kappa: 0.8720
: Epoch: 43 | Training Loss: 0.098512 | Val. Loss: 0.338617 | Val. Kappa Score: 0.8720 | LR: 0.000500 | Estimated time: 162.75
Train loss on 50 batch: 0.078507
Train loss on 100 batch: 0.096113
Train loss on 150 batch: 0.084534
best-train-loss: 0.085128
best-valid-loss: 0.339545
best-kappa: 0.8722
: Epoch: 44 | Training Loss: 0.085128 | Val. Loss: 0.339545 | Val. Kappa Score: 0.8722 | LR: 0.000500 | Estimated time: 162.74
Train loss on 50 batch: 0.105990
Train loss on 100 batch: 0.085699
Train loss on 150 batch: 0.088205
best-train-loss: 0.093338
best-valid-loss: 0.320582
best-kappa: 0.8725
: Epoch: 45 | Training Loss: 0.093338 | Val. Loss: 0.320582 | Val. Kappa Score: 0.8725 | LR: 0.000500 | Estimated time: 162.25
Train loss on 50 batch: 0.084632
Train loss on 100 batch: 0.079916
Train loss on 150 batch: 0.123993
best-train-loss: 0.107323
best-valid-loss: 0.327002
best-kappa: 0.8726
: Epoch: 46 | Training Loss: 0.107323 | Val. Loss: 0.327002 | Val. Kappa Score: 0.8726 | LR: 0.000500 | Estimated time: 162.88
Train loss on 50 batch: 0.150140
Train loss on 100 batch: 0.111558
Train loss on 150 batch: 0.116059
: Epoch: 47 | Training Loss: 0.134383 | Val. Loss: 0.397954 | Val. Kappa Score: 0.8723 | LR: 0.000500 | Estimated time: 163.16
Train loss on 50 batch: 0.101885
Train loss on 100 batch: 0.119789
Train loss on 150 batch: 0.094284
: Epoch: 48 | Training Loss: 0.100011 | Val. Loss: 0.325221 | Val. Kappa Score: 0.8725 | LR: 0.000500 | Estimated time: 164.00
Train loss on 50 batch: 0.071941
Train loss on 100 batch: 0.070726
Train loss on 150 batch: 0.077430
: Epoch: 49 | Training Loss: 0.101228 | Val. Loss: 0.360529 | Val. Kappa Score: 0.8723 | LR: 0.000250 | Estimated time: 162.75
Train loss on 50 batch: 0.089953
Train loss on 100 batch: 0.079446
Train loss on 150 batch: 0.087995
best-train-loss: 0.082181
best-valid-loss: 0.318168
best-kappa: 0.8726
: Epoch: 50 | Training Loss: 0.082181 | Val. Loss: 0.318168 | Val. Kappa Score: 0.8726 | LR: 0.000250 | Estimated time: 164.06
Train loss on 50 batch: 0.061260
Train loss on 100 batch: 0.066345
Train loss on 150 batch: 0.049292
best-train-loss: 0.061920
best-valid-loss: 0.302363
best-kappa: 0.8731
: Epoch: 51 | Training Loss: 0.061920 | Val. Loss: 0.302363 | Val. Kappa Score: 0.8731 | LR: 0.000250 | Estimated time: 163.96
Train loss on 50 batch: 0.059495
Train loss on 100 batch: 0.058940
Train loss on 150 batch: 0.053346
best-train-loss: 0.060185
best-valid-loss: 0.309092
best-kappa: 0.8733
: Epoch: 52 | Training Loss: 0.060185 | Val. Loss: 0.309092 | Val. Kappa Score: 0.8733 | LR: 0.000250 | Estimated time: 163.36
Train loss on 50 batch: 0.052108
Train loss on 100 batch: 0.051800
Train loss on 150 batch: 0.050157
best-train-loss: 0.059799
best-valid-loss: 0.309217
best-kappa: 0.8737
: Epoch: 53 | Training Loss: 0.059799 | Val. Loss: 0.309217 | Val. Kappa Score: 0.8737 | LR: 0.000250 | Estimated time: 162.57
Train loss on 50 batch: 0.053418
Train loss on 100 batch: 0.062629
Train loss on 150 batch: 0.044004
best-train-loss: 0.065825
best-valid-loss: 0.309166
best-kappa: 0.8741
: Epoch: 54 | Training Loss: 0.065825 | Val. Loss: 0.309166 | Val. Kappa Score: 0.8741 | LR: 0.000250 | Estimated time: 164.41
Train loss on 50 batch: 0.059791
Train loss on 100 batch: 0.051705
Train loss on 150 batch: 0.052107
best-train-loss: 0.052943
best-valid-loss: 0.305099
best-kappa: 0.8743
: Epoch: 55 | Training Loss: 0.052943 | Val. Loss: 0.305099 | Val. Kappa Score: 0.8743 | LR: 0.000250 | Estimated time: 163.66
Train loss on 50 batch: 0.053146
Train loss on 100 batch: 0.046731
Train loss on 150 batch: 0.053719
best-train-loss: 0.062873
best-valid-loss: 0.299874
best-kappa: 0.8746
: Epoch: 56 | Training Loss: 0.062873 | Val. Loss: 0.299874 | Val. Kappa Score: 0.8746 | LR: 0.000250 | Estimated time: 162.32
Train loss on 50 batch: 0.060273
Train loss on 100 batch: 0.053231
Train loss on 150 batch: 0.039822
best-train-loss: 0.053692
best-valid-loss: 0.313905
best-kappa: 0.8748
: Epoch: 57 | Training Loss: 0.053692 | Val. Loss: 0.313905 | Val. Kappa Score: 0.8748 | LR: 0.000250 | Estimated time: 162.02
Train loss on 50 batch: 0.051111
Train loss on 100 batch: 0.042206
Train loss on 150 batch: 0.042379
best-train-loss: 0.050778
best-valid-loss: 0.307604
best-kappa: 0.8750
: Epoch: 58 | Training Loss: 0.050778 | Val. Loss: 0.307604 | Val. Kappa Score: 0.8750 | LR: 0.000250 | Estimated time: 163.39
Train loss on 50 batch: 0.051886
Train loss on 100 batch: 0.038415
Train loss on 150 batch: 0.045103
best-train-loss: 0.045895
best-valid-loss: 0.298703
best-kappa: 0.8754
: Epoch: 59 | Training Loss: 0.045895 | Val. Loss: 0.298703 | Val. Kappa Score: 0.8754 | LR: 0.000250 | Estimated time: 163.62
Train loss on 50 batch: 0.042087
Train loss on 100 batch: 0.040312
Train loss on 150 batch: 0.044126
best-train-loss: 0.066335
best-valid-loss: 0.302889
best-kappa: 0.8757
: Epoch: 60 | Training Loss: 0.066335 | Val. Loss: 0.302889 | Val. Kappa Score: 0.8757 | LR: 0.000250 | Estimated time: 164.79
Train loss on 50 batch: 0.048560
Train loss on 100 batch: 0.048728
Train loss on 150 batch: 0.053616
best-train-loss: 0.050783
best-valid-loss: 0.310054
best-kappa: 0.8762
: Epoch: 61 | Training Loss: 0.050783 | Val. Loss: 0.310054 | Val. Kappa Score: 0.8762 | LR: 0.000250 | Estimated time: 164.84
Train loss on 50 batch: 0.043942
Train loss on 100 batch: 0.048065
Train loss on 150 batch: 0.048313
best-train-loss: 0.062149
best-valid-loss: 0.291270
best-kappa: 0.8766
: Epoch: 62 | Training Loss: 0.062149 | Val. Loss: 0.291270 | Val. Kappa Score: 0.8766 | LR: 0.000250 | Estimated time: 169.11
Train loss on 50 batch: 0.056379
Train loss on 100 batch: 0.044104
Train loss on 150 batch: 0.046520
best-train-loss: 0.053959
best-valid-loss: 0.313020
best-kappa: 0.8768
: Epoch: 63 | Training Loss: 0.053959 | Val. Loss: 0.313020 | Val. Kappa Score: 0.8768 | LR: 0.000250 | Estimated time: 165.35
Train loss on 50 batch: 0.043926
Train loss on 100 batch: 0.055288
Train loss on 150 batch: 0.047984
best-train-loss: 0.047916
best-valid-loss: 0.286508
best-kappa: 0.8771
: Epoch: 64 | Training Loss: 0.047916 | Val. Loss: 0.286508 | Val. Kappa Score: 0.8771 | LR: 0.000250 | Estimated time: 165.76
Train loss on 50 batch: 0.042196
Train loss on 100 batch: 0.038433
Train loss on 150 batch: 0.057011
best-train-loss: 0.044759
best-valid-loss: 0.300307
best-kappa: 0.8774
: Epoch: 65 | Training Loss: 0.044759 | Val. Loss: 0.300307 | Val. Kappa Score: 0.8774 | LR: 0.000250 | Estimated time: 165.22
Train loss on 50 batch: 0.041446
Train loss on 100 batch: 0.041254
Train loss on 150 batch: 0.043517
best-train-loss: 0.060718
best-valid-loss: 0.287870
best-kappa: 0.8776
: Epoch: 66 | Training Loss: 0.060718 | Val. Loss: 0.287870 | Val. Kappa Score: 0.8776 | LR: 0.000250 | Estimated time: 167.18
Train loss on 50 batch: 0.041685
Train loss on 100 batch: 0.033483
Train loss on 150 batch: 0.040798
best-train-loss: 0.039821
best-valid-loss: 0.316990
best-kappa: 0.8777
: Epoch: 67 | Training Loss: 0.039821 | Val. Loss: 0.316990 | Val. Kappa Score: 0.8777 | LR: 0.000250 | Estimated time: 165.48
Train loss on 50 batch: 0.036209
Train loss on 100 batch: 0.047796
Train loss on 150 batch: 0.042305
best-train-loss: 0.045241
best-valid-loss: 0.289444
best-kappa: 0.8779
: Epoch: 68 | Training Loss: 0.045241 | Val. Loss: 0.289444 | Val. Kappa Score: 0.8779 | LR: 0.000250 | Estimated time: 164.73
Train loss on 50 batch: 0.036035
Train loss on 100 batch: 0.039277
Train loss on 150 batch: 0.030849
best-train-loss: 0.034673
best-valid-loss: 0.293846
best-kappa: 0.8781
: Epoch: 69 | Training Loss: 0.034673 | Val. Loss: 0.293846 | Val. Kappa Score: 0.8781 | LR: 0.000250 | Estimated time: 165.69
Train loss on 50 batch: 0.030356
Train loss on 100 batch: 0.038754
Train loss on 150 batch: 0.037488
best-train-loss: 0.033545
best-valid-loss: 0.287384
best-kappa: 0.8783
: Epoch: 70 | Training Loss: 0.033545 | Val. Loss: 0.287384 | Val. Kappa Score: 0.8783 | LR: 0.000250 | Estimated time: 165.64
Train loss on 50 batch: 0.032092
Train loss on 100 batch: 0.033520
Train loss on 150 batch: 0.037686
best-train-loss: 0.033890
best-valid-loss: 0.294554
best-kappa: 0.8785
: Epoch: 71 | Training Loss: 0.033890 | Val. Loss: 0.294554 | Val. Kappa Score: 0.8785 | LR: 0.000250 | Estimated time: 163.87
Train loss on 50 batch: 0.029249
Train loss on 100 batch: 0.044645
Train loss on 150 batch: 0.061759
best-train-loss: 0.047497
best-valid-loss: 0.304471
best-kappa: 0.8786
: Epoch: 72 | Training Loss: 0.047497 | Val. Loss: 0.304471 | Val. Kappa Score: 0.8786 | LR: 0.000250 | Estimated time: 163.53
Train loss on 50 batch: 0.037828
Train loss on 100 batch: 0.037306
Train loss on 150 batch: 0.045029
best-train-loss: 0.079062
best-valid-loss: 0.290087
best-kappa: 0.8789
: Epoch: 73 | Training Loss: 0.079062 | Val. Loss: 0.290087 | Val. Kappa Score: 0.8789 | LR: 0.000250 | Estimated time: 164.17
Train loss on 50 batch: 0.077874
Train loss on 100 batch: 0.051648
Train loss on 150 batch: 0.044802
best-train-loss: 0.059402
best-valid-loss: 0.296921
best-kappa: 0.8791
: Epoch: 74 | Training Loss: 0.059402 | Val. Loss: 0.296921 | Val. Kappa Score: 0.8791 | LR: 0.000250 | Estimated time: 162.72
Train loss on 50 batch: 0.040550
Train loss on 100 batch: 0.037193
Train loss on 150 batch: 0.043831
best-train-loss: 0.040040
best-valid-loss: 0.310342
best-kappa: 0.8792
: Epoch: 75 | Training Loss: 0.040040 | Val. Loss: 0.310342 | Val. Kappa Score: 0.8792 | LR: 0.000250 | Estimated time: 165.02
Train loss on 50 batch: 0.033916
Train loss on 100 batch: 0.042277
Train loss on 150 batch: 0.036907
best-train-loss: 0.037332
best-valid-loss: 0.327976
best-kappa: 0.8792
: Epoch: 76 | Training Loss: 0.037332 | Val. Loss: 0.327976 | Val. Kappa Score: 0.8792 | LR: 0.000250 | Estimated time: 164.35
Train loss on 50 batch: 0.040159
Train loss on 100 batch: 0.030478
Train loss on 150 batch: 0.035768
: Epoch: 77 | Training Loss: 0.037183 | Val. Loss: 0.309225 | Val. Kappa Score: 0.8792 | LR: 0.000250 | Estimated time: 163.46
Train loss on 50 batch: 0.056720
Train loss on 100 batch: 0.026684
Train loss on 150 batch: 0.034055
best-train-loss: 0.042698
best-valid-loss: 0.298679
best-kappa: 0.8794
: Epoch: 78 | Training Loss: 0.042698 | Val. Loss: 0.298679 | Val. Kappa Score: 0.8794 | LR: 0.000250 | Estimated time: 162.58
Train loss on 50 batch: 0.032198
Train loss on 100 batch: 0.033467
Train loss on 150 batch: 0.033206
best-train-loss: 0.047445
best-valid-loss: 0.296877
best-kappa: 0.8796
: Epoch: 79 | Training Loss: 0.047445 | Val. Loss: 0.296877 | Val. Kappa Score: 0.8796 | LR: 0.000250 | Estimated time: 163.83
Train loss on 50 batch: 0.047347
Train loss on 100 batch: 0.033130
Train loss on 150 batch: 0.033678
best-train-loss: 0.056016
best-valid-loss: 0.303163
best-kappa: 0.8797
: Epoch: 80 | Training Loss: 0.056016 | Val. Loss: 0.303163 | Val. Kappa Score: 0.8797 | LR: 0.000250 | Estimated time: 162.84
Train loss on 50 batch: 0.031006
Train loss on 100 batch: 0.036904
Train loss on 150 batch: 0.040259
best-train-loss: 0.040432
best-valid-loss: 0.330151
best-kappa: 0.8798
: Epoch: 81 | Training Loss: 0.040432 | Val. Loss: 0.330151 | Val. Kappa Score: 0.8798 | LR: 0.000250 | Estimated time: 163.57
Train loss on 50 batch: 0.033855
Train loss on 100 batch: 0.032556
Train loss on 150 batch: 0.024543
best-train-loss: 0.032920
best-valid-loss: 0.316686
best-kappa: 0.8799
: Epoch: 82 | Training Loss: 0.032920 | Val. Loss: 0.316686 | Val. Kappa Score: 0.8799 | LR: 0.000250 | Estimated time: 163.11
Train loss on 50 batch: 0.028371
Train loss on 100 batch: 0.040539
Train loss on 150 batch: 0.039217
best-train-loss: 0.036363
best-valid-loss: 0.303644
best-kappa: 0.8800
: Epoch: 83 | Training Loss: 0.036363 | Val. Loss: 0.303644 | Val. Kappa Score: 0.8800 | LR: 0.000250 | Estimated time: 162.86
Train loss on 50 batch: 0.029461
Train loss on 100 batch: 0.038745
Train loss on 150 batch: 0.037264
best-train-loss: 0.036730
best-valid-loss: 0.324945
best-kappa: 0.8800
: Epoch: 84 | Training Loss: 0.036730 | Val. Loss: 0.324945 | Val. Kappa Score: 0.8800 | LR: 0.000250 | Estimated time: 163.05
Train loss on 50 batch: 0.035085
Train loss on 100 batch: 0.025078
Train loss on 150 batch: 0.030812
best-train-loss: 0.030058
best-valid-loss: 0.306379
best-kappa: 0.8802
: Epoch: 85 | Training Loss: 0.030058 | Val. Loss: 0.306379 | Val. Kappa Score: 0.8802 | LR: 0.000250 | Estimated time: 164.75
Train loss on 50 batch: 0.023529
Train loss on 100 batch: 0.026661
Train loss on 150 batch: 0.037363
best-train-loss: 0.045495
best-valid-loss: 0.288088
best-kappa: 0.8804
: Epoch: 86 | Training Loss: 0.045495 | Val. Loss: 0.288088 | Val. Kappa Score: 0.8804 | LR: 0.000250 | Estimated time: 163.23
Train loss on 50 batch: 0.032379
Train loss on 100 batch: 0.046991
Train loss on 150 batch: 0.028614
best-train-loss: 0.046282
best-valid-loss: 0.304148
best-kappa: 0.8805
: Epoch: 87 | Training Loss: 0.046282 | Val. Loss: 0.304148 | Val. Kappa Score: 0.8805 | LR: 0.000250 | Estimated time: 163.57
Train loss on 50 batch: 0.039613
Train loss on 100 batch: 0.032271
Train loss on 150 batch: 0.038341
best-train-loss: 0.037438
best-valid-loss: 0.299750
best-kappa: 0.8807
: Epoch: 88 | Training Loss: 0.037438 | Val. Loss: 0.299750 | Val. Kappa Score: 0.8807 | LR: 0.000250 | Estimated time: 164.19
Train loss on 50 batch: 0.035228
Train loss on 100 batch: 0.021490
Train loss on 150 batch: 0.036362
best-train-loss: 0.030466
best-valid-loss: 0.295220
best-kappa: 0.8808
: Epoch: 89 | Training Loss: 0.030466 | Val. Loss: 0.295220 | Val. Kappa Score: 0.8808 | LR: 0.000250 | Estimated time: 165.03
Train loss on 50 batch: 0.030929
Train loss on 100 batch: 0.029273
Train loss on 150 batch: 0.026362
best-train-loss: 0.029202
best-valid-loss: 0.294310
best-kappa: 0.8809
: Epoch: 90 | Training Loss: 0.029202 | Val. Loss: 0.294310 | Val. Kappa Score: 0.8809 | LR: 0.000250 | Estimated time: 163.79
Train loss on 50 batch: 0.029313
Train loss on 100 batch: 0.032795
Train loss on 150 batch: 0.028088
best-train-loss: 0.030408
best-valid-loss: 0.349470
best-kappa: 0.8811
: Epoch: 91 | Training Loss: 0.030408 | Val. Loss: 0.349470 | Val. Kappa Score: 0.8811 | LR: 0.000250 | Estimated time: 163.01
Train loss on 50 batch: 0.032684
Train loss on 100 batch: 0.027976
Train loss on 150 batch: 0.034678
best-train-loss: 0.032127
best-valid-loss: 0.313442
best-kappa: 0.8813
: Epoch: 92 | Training Loss: 0.032127 | Val. Loss: 0.313442 | Val. Kappa Score: 0.8813 | LR: 0.000250 | Estimated time: 163.68
Train loss on 50 batch: 0.027980
Train loss on 100 batch: 0.031324
Train loss on 150 batch: 0.038941
best-train-loss: 0.030910
best-valid-loss: 0.296284
best-kappa: 0.8814
: Epoch: 93 | Training Loss: 0.030910 | Val. Loss: 0.296284 | Val. Kappa Score: 0.8814 | LR: 0.000250 | Estimated time: 163.83
Train loss on 50 batch: 0.042115
Train loss on 100 batch: 0.025615
Train loss on 150 batch: 0.029296
: Epoch: 94 | Training Loss: 0.058198 | Val. Loss: 0.325317 | Val. Kappa Score: 0.8814 | LR: 0.000250 | Estimated time: 162.30
Train loss on 50 batch: 0.075932
Train loss on 100 batch: 0.038886
Train loss on 150 batch: 0.048034
best-train-loss: 0.068217
best-valid-loss: 0.327434
best-kappa: 0.8815
: Epoch: 95 | Training Loss: 0.068217 | Val. Loss: 0.327434 | Val. Kappa Score: 0.8815 | LR: 0.000250 | Estimated time: 164.07
Train loss on 50 batch: 0.048658
Train loss on 100 batch: 0.034901
Train loss on 150 batch: 0.051502
best-train-loss: 0.045269
best-valid-loss: 0.294427
best-kappa: 0.8816
: Epoch: 96 | Training Loss: 0.045269 | Val. Loss: 0.294427 | Val. Kappa Score: 0.8816 | LR: 0.000250 | Estimated time: 163.15
Train loss on 50 batch: 0.035019
Train loss on 100 batch: 0.037898
Train loss on 150 batch: 0.036677
best-train-loss: 0.035190
best-valid-loss: 0.315476
best-kappa: 0.8817
: Epoch: 97 | Training Loss: 0.035190 | Val. Loss: 0.315476 | Val. Kappa Score: 0.8817 | LR: 0.000250 | Estimated time: 162.93
Train loss on 50 batch: 0.037590
Train loss on 100 batch: 0.024098
Train loss on 150 batch: 0.034272
best-train-loss: 0.029829
best-valid-loss: 0.304310
best-kappa: 0.8819
: Epoch: 98 | Training Loss: 0.029829 | Val. Loss: 0.304310 | Val. Kappa Score: 0.8819 | LR: 0.000250 | Estimated time: 164.38
Train loss on 50 batch: 0.023128
Train loss on 100 batch: 0.029368
Train loss on 150 batch: 0.031191
best-train-loss: 0.032562
best-valid-loss: 0.331086
best-kappa: 0.8820
: Epoch: 99 | Training Loss: 0.032562 | Val. Loss: 0.331086 | Val. Kappa Score: 0.8820 | LR: 0.000250 | Estimated time: 163.67
Train loss on 50 batch: 0.027476
Train loss on 100 batch: 0.030240
Train loss on 150 batch: 0.031435
best-train-loss: 0.053742
best-valid-loss: 0.299521
best-kappa: 0.8821
: Epoch: 100 | Training Loss: 0.053742 | Val. Loss: 0.299521 | Val. Kappa Score: 0.8821 | LR: 0.000250 | Estimated time: 162.61
time_estimated: 16423.50
----------------------------------------

Experiment N: 66: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.13 08:23:37
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f97c50>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.058123
Train loss on 100 batch: 0.911306
Train loss on 150 batch: 0.846032
Train loss on 200 batch: 0.750000
Train loss on 250 batch: 0.799997
Train loss on 300 batch: 0.748204
Train loss on 350 batch: 0.855207
Train loss on 400 batch: 0.815170
Train loss on 450 batch: 0.838874
Train loss on 500 batch: 0.751709
Train loss on 550 batch: 0.631385
Train loss on 600 batch: 0.749550
Train loss on 650 batch: 0.827718
Train loss on 700 batch: 0.713098
Train loss on 750 batch: 0.723529
Train loss on 800 batch: 0.764862
Train loss on 850 batch: 0.734020
Train loss on 900 batch: 0.694519
Train loss on 950 batch: 0.590972
Train loss on 1000 batch: 0.671541
Train loss on 1050 batch: 0.651385
Train loss on 1100 batch: 0.686442
Train loss on 1150 batch: 0.680580
Train loss on 1200 batch: 0.697693
Train loss on 1250 batch: 0.625909
Train loss on 1300 batch: 0.631913
Train loss on 1350 batch: 0.621475
Train loss on 1400 batch: 0.664013
Train loss on 1450 batch: 0.756346
Train loss on 1500 batch: 0.680122
Train loss on 1550 batch: 0.652775
Train loss on 1600 batch: 0.723981
Train loss on 1650 batch: 0.699039
Train loss on 1700 batch: 0.608305
Train loss on 1750 batch: 0.646233
Train loss on 1800 batch: 0.631895
Train loss on 1850 batch: 0.714696
Train loss on 1900 batch: 0.701741
best-train-loss: 0.723556
best-valid-loss: 0.659867
best-kappa: 0.4645
: Epoch: 1 | Training Loss: 0.723556 | Val. Loss: 0.659867 | Val. Kappa Score: 0.4645 | LR: 0.001000 | Estimated time: 1371.17
Train loss on 50 batch: 0.613808
Train loss on 100 batch: 0.679869
Train loss on 150 batch: 0.670429
Train loss on 200 batch: 0.701877
----------------------------------------

Experiment N: 67: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.13 08:49:36
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f97cf8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.105870
Train loss on 100 batch: 0.819989
Train loss on 150 batch: 0.784737
Train loss on 200 batch: 0.679449
Train loss on 250 batch: 0.681091
Train loss on 300 batch: 0.710707
Train loss on 350 batch: 0.769015
Train loss on 400 batch: 0.738236
Train loss on 450 batch: 0.764597
Train loss on 500 batch: 0.705318
Train loss on 550 batch: 0.613511
Train loss on 600 batch: 0.643189
Train loss on 650 batch: 0.722165
Train loss on 700 batch: 0.681326
Train loss on 750 batch: 0.611471
Train loss on 800 batch: 0.630390
Train loss on 850 batch: 0.678947
Train loss on 900 batch: 0.587223
Train loss on 950 batch: 0.533098
Train loss on 1000 batch: 0.600493
Train loss on 1050 batch: 0.626574
Train loss on 1100 batch: 0.614163
Train loss on 1150 batch: 0.597807
Train loss on 1200 batch: 0.616330
Train loss on 1250 batch: 0.522703
Train loss on 1300 batch: 0.601558
Train loss on 1350 batch: 0.577399
Train loss on 1400 batch: 0.616361
Train loss on 1450 batch: 0.698418
Train loss on 1500 batch: 0.586392
Train loss on 1550 batch: 0.577102
Train loss on 1600 batch: 0.650284
Train loss on 1650 batch: 0.664136
Train loss on 1700 batch: 0.603288
Train loss on 1750 batch: 0.614834
Train loss on 1800 batch: 0.537028
Train loss on 1850 batch: 0.679963
Train loss on 1900 batch: 0.610902
best-train-loss: 0.658830
best-valid-loss: 0.738719
best-kappa: 0.4448
: Epoch: 1 | Training Loss: 0.658830 | Val. Loss: 0.738719 | Val. Kappa Score: 0.4448 | LR: 0.001000 | Estimated time: 515.28
Train loss on 50 batch: 0.569473
Train loss on 100 batch: 0.624813
Train loss on 150 batch: 0.553061
Train loss on 200 batch: 0.613984
Train loss on 250 batch: 0.548327
Train loss on 300 batch: 0.570272
Train loss on 350 batch: 0.630102
Train loss on 400 batch: 0.540615
Train loss on 450 batch: 0.506973
Train loss on 500 batch: 0.564841
Train loss on 550 batch: 0.574588
Train loss on 600 batch: 0.530424
Train loss on 650 batch: 0.494414
Train loss on 700 batch: 0.621361
Train loss on 750 batch: 0.555948
Train loss on 800 batch: 0.523952
Train loss on 850 batch: 0.580143
Train loss on 900 batch: 0.670548
Train loss on 950 batch: 0.586634
Train loss on 1000 batch: 0.536221
Train loss on 1050 batch: 0.537237
Train loss on 1100 batch: 0.617010
Train loss on 1150 batch: 0.465456
Train loss on 1200 batch: 0.512022
Train loss on 1250 batch: 0.543868
Train loss on 1300 batch: 0.600703
Train loss on 1350 batch: 0.580944
Train loss on 1400 batch: 0.507969
Train loss on 1450 batch: 0.622582
Train loss on 1500 batch: 0.619729
Train loss on 1550 batch: 0.571842
Train loss on 1600 batch: 0.530878
Train loss on 1650 batch: 0.541677
Train loss on 1700 batch: 0.643404
Train loss on 1750 batch: 0.526861
Train loss on 1800 batch: 0.538461
Train loss on 1850 batch: 0.516097
Train loss on 1900 batch: 0.483995
best-train-loss: 0.560481
best-valid-loss: 0.463692
best-kappa: 0.5395
: Epoch: 2 | Training Loss: 0.560481 | Val. Loss: 0.463692 | Val. Kappa Score: 0.5395 | LR: 0.001000 | Estimated time: 511.42
Train loss on 50 batch: 0.580255
Train loss on 100 batch: 0.589429
Train loss on 150 batch: 0.495825
Train loss on 200 batch: 0.572952
Train loss on 250 batch: 0.551408
Train loss on 300 batch: 0.444567
Train loss on 350 batch: 0.497108
Train loss on 400 batch: 0.478383
Train loss on 450 batch: 0.491427
Train loss on 500 batch: 0.570607
Train loss on 550 batch: 0.484798
Train loss on 600 batch: 0.569671
Train loss on 650 batch: 0.599432
Train loss on 700 batch: 0.548392
Train loss on 750 batch: 0.559348
Train loss on 800 batch: 0.497437
Train loss on 850 batch: 0.600505
Train loss on 900 batch: 0.503075
Train loss on 950 batch: 0.493958
Train loss on 1000 batch: 0.474300
Train loss on 1050 batch: 0.474511
Train loss on 1100 batch: 0.561475
Train loss on 1150 batch: 0.541072
Train loss on 1200 batch: 0.580646
Train loss on 1250 batch: 0.485784
Train loss on 1300 batch: 0.481741
Train loss on 1350 batch: 0.544384
Train loss on 1400 batch: 0.529124
Train loss on 1450 batch: 0.570650
Train loss on 1500 batch: 0.510127
Train loss on 1550 batch: 0.515326
Train loss on 1600 batch: 0.520872
Train loss on 1650 batch: 0.465721
Train loss on 1700 batch: 0.443166
Train loss on 1750 batch: 0.499020
Train loss on 1800 batch: 0.546061
Train loss on 1850 batch: 0.475909
Train loss on 1900 batch: 0.528618
best-train-loss: 0.523660
best-valid-loss: 0.456961
best-kappa: 0.5722
: Epoch: 3 | Training Loss: 0.523660 | Val. Loss: 0.456961 | Val. Kappa Score: 0.5722 | LR: 0.001000 | Estimated time: 510.64
Train loss on 50 batch: 0.520895
Train loss on 100 batch: 0.474083
Train loss on 150 batch: 0.504232
Train loss on 200 batch: 0.486721
Train loss on 250 batch: 0.493828
Train loss on 300 batch: 0.472207
Train loss on 350 batch: 0.606776
Train loss on 400 batch: 0.514847
Train loss on 450 batch: 0.431720
Train loss on 500 batch: 0.537358
Train loss on 550 batch: 0.488887
Train loss on 600 batch: 0.467966
Train loss on 650 batch: 0.451606
Train loss on 700 batch: 0.510197
Train loss on 750 batch: 0.459185
Train loss on 800 batch: 0.507395
Train loss on 850 batch: 0.486389
Train loss on 900 batch: 0.521469
Train loss on 950 batch: 0.497938
Train loss on 1000 batch: 0.422425
Train loss on 1050 batch: 0.563703
Train loss on 1100 batch: 0.499202
Train loss on 1150 batch: 0.534210
Train loss on 1200 batch: 0.493529
Train loss on 1250 batch: 0.428290
Train loss on 1300 batch: 0.480616
Train loss on 1350 batch: 0.437883
Train loss on 1400 batch: 0.537885
Train loss on 1450 batch: 0.543403
Train loss on 1500 batch: 0.448019
Train loss on 1550 batch: 0.515840
Train loss on 1600 batch: 0.573170
Train loss on 1650 batch: 0.515740
Train loss on 1700 batch: 0.585357
Train loss on 1750 batch: 0.489763
Train loss on 1800 batch: 0.474412
Train loss on 1850 batch: 0.494350
Train loss on 1900 batch: 0.527255
best-train-loss: 0.499060
best-valid-loss: 0.473309
best-kappa: 0.5921
: Epoch: 4 | Training Loss: 0.499060 | Val. Loss: 0.473309 | Val. Kappa Score: 0.5921 | LR: 0.001000 | Estimated time: 510.71
Train loss on 50 batch: 0.466693
Train loss on 100 batch: 0.524156
Train loss on 150 batch: 0.462583
Train loss on 200 batch: 0.522479
Train loss on 250 batch: 0.467671
Train loss on 300 batch: 0.482628
Train loss on 350 batch: 0.559154
Train loss on 400 batch: 0.482573
Train loss on 450 batch: 0.492821
Train loss on 500 batch: 0.551315
Train loss on 550 batch: 0.537248
Train loss on 600 batch: 0.509826
Train loss on 650 batch: 0.462682
Train loss on 700 batch: 0.526076
Train loss on 750 batch: 0.501392
Train loss on 800 batch: 0.518101
Train loss on 850 batch: 0.498549
Train loss on 900 batch: 0.468225
Train loss on 950 batch: 0.419476
Train loss on 1000 batch: 0.472808
Train loss on 1050 batch: 0.586140
Train loss on 1100 batch: 0.478314
Train loss on 1150 batch: 0.515775
Train loss on 1200 batch: 0.421140
Train loss on 1250 batch: 0.503954
Train loss on 1300 batch: 0.541490
Train loss on 1350 batch: 0.468007
Train loss on 1400 batch: 0.483058
Train loss on 1450 batch: 0.392385
Train loss on 1500 batch: 0.443362
Train loss on 1550 batch: 0.417666
Train loss on 1600 batch: 0.442480
Train loss on 1650 batch: 0.449287
Train loss on 1700 batch: 0.513165
Train loss on 1750 batch: 0.485740
Train loss on 1800 batch: 0.458420
Train loss on 1850 batch: 0.442815
Train loss on 1900 batch: 0.473879
best-train-loss: 0.486785
best-valid-loss: 0.441669
best-kappa: 0.6074
: Epoch: 5 | Training Loss: 0.486785 | Val. Loss: 0.441669 | Val. Kappa Score: 0.6074 | LR: 0.001000 | Estimated time: 510.76
Train loss on 50 batch: 0.499636
Train loss on 100 batch: 0.452699
Train loss on 150 batch: 0.433077
Train loss on 200 batch: 0.546497
Train loss on 250 batch: 0.412555
Train loss on 300 batch: 0.519282
Train loss on 350 batch: 0.469073
Train loss on 400 batch: 0.510035
Train loss on 450 batch: 0.495079
Train loss on 500 batch: 0.452684
Train loss on 550 batch: 0.483440
Train loss on 600 batch: 0.508285
Train loss on 650 batch: 0.471457
Train loss on 700 batch: 0.436785
Train loss on 750 batch: 0.432005
Train loss on 800 batch: 0.497929
Train loss on 850 batch: 0.437625
Train loss on 900 batch: 0.522443
Train loss on 950 batch: 0.495103
Train loss on 1000 batch: 0.468597
Train loss on 1050 batch: 0.503114
Train loss on 1100 batch: 0.460086
Train loss on 1150 batch: 0.498708
Train loss on 1200 batch: 0.419302
Train loss on 1250 batch: 0.476013
Train loss on 1300 batch: 0.495339
Train loss on 1350 batch: 0.430822
Train loss on 1400 batch: 0.476612
Train loss on 1450 batch: 0.472672
Train loss on 1500 batch: 0.488723
Train loss on 1550 batch: 0.520454
Train loss on 1600 batch: 0.490716
Train loss on 1650 batch: 0.436925
Train loss on 1700 batch: 0.389784
Train loss on 1750 batch: 0.450747
Train loss on 1800 batch: 0.395094
Train loss on 1850 batch: 0.448319
Train loss on 1900 batch: 0.477228
best-train-loss: 0.470645
best-valid-loss: 0.520216
best-kappa: 0.6170
: Epoch: 6 | Training Loss: 0.470645 | Val. Loss: 0.520216 | Val. Kappa Score: 0.6170 | LR: 0.001000 | Estimated time: 510.54
Train loss on 50 batch: 0.464256
Train loss on 100 batch: 0.479727
Train loss on 150 batch: 0.497726
Train loss on 200 batch: 0.473922
Train loss on 250 batch: 0.542747
Train loss on 300 batch: 0.520270
Train loss on 350 batch: 0.407763
Train loss on 400 batch: 0.484943
Train loss on 450 batch: 0.445551
Train loss on 500 batch: 0.421122
Train loss on 550 batch: 0.447819
Train loss on 600 batch: 0.555132
Train loss on 650 batch: 0.435268
Train loss on 700 batch: 0.429235
Train loss on 750 batch: 0.398770
Train loss on 800 batch: 0.456992
Train loss on 850 batch: 0.446832
Train loss on 900 batch: 0.460411
Train loss on 950 batch: 0.381705
Train loss on 1000 batch: 0.404003
Train loss on 1050 batch: 0.459500
Train loss on 1100 batch: 0.422315
Train loss on 1150 batch: 0.428826
Train loss on 1200 batch: 0.434554
Train loss on 1250 batch: 0.475285
Train loss on 1300 batch: 0.514665
Train loss on 1350 batch: 0.439775
Train loss on 1400 batch: 0.440490
Train loss on 1450 batch: 0.458329
Train loss on 1500 batch: 0.379364
Train loss on 1550 batch: 0.489612
Train loss on 1600 batch: 0.416327
Train loss on 1650 batch: 0.504805
Train loss on 1700 batch: 0.450922
Train loss on 1750 batch: 0.423224
Train loss on 1800 batch: 0.479380
Train loss on 1850 batch: 0.541340
Train loss on 1900 batch: 0.505137
best-train-loss: 0.457114
best-valid-loss: 0.448223
best-kappa: 0.6233
: Epoch: 7 | Training Loss: 0.457114 | Val. Loss: 0.448223 | Val. Kappa Score: 0.6233 | LR: 0.001000 | Estimated time: 510.47
Train loss on 50 batch: 0.417591
Train loss on 100 batch: 0.443219
Train loss on 150 batch: 0.528065
Train loss on 200 batch: 0.491521
Train loss on 250 batch: 0.384135
Train loss on 300 batch: 0.412196
Train loss on 350 batch: 0.377334
Train loss on 400 batch: 0.533934
Train loss on 450 batch: 0.346886
Train loss on 500 batch: 0.476107
Train loss on 550 batch: 0.474363
Train loss on 600 batch: 0.430399
Train loss on 650 batch: 0.470510
Train loss on 700 batch: 0.473649
Train loss on 750 batch: 0.451038
Train loss on 800 batch: 0.493636
Train loss on 850 batch: 0.447729
Train loss on 900 batch: 0.461559
Train loss on 950 batch: 0.435029
Train loss on 1000 batch: 0.430755
Train loss on 1050 batch: 0.454833
Train loss on 1100 batch: 0.390070
Train loss on 1150 batch: 0.539217
Train loss on 1200 batch: 0.469577
Train loss on 1250 batch: 0.432046
Train loss on 1300 batch: 0.455282
Train loss on 1350 batch: 0.436439
Train loss on 1400 batch: 0.442578
Train loss on 1450 batch: 0.426567
Train loss on 1500 batch: 0.468740
Train loss on 1550 batch: 0.419932
Train loss on 1600 batch: 0.499789
Train loss on 1650 batch: 0.480266
Train loss on 1700 batch: 0.420422
Train loss on 1750 batch: 0.467140
Train loss on 1800 batch: 0.415962
Train loss on 1850 batch: 0.455010
Train loss on 1900 batch: 0.356305
best-train-loss: 0.448141
best-valid-loss: 0.445401
best-kappa: 0.6261
: Epoch: 8 | Training Loss: 0.448141 | Val. Loss: 0.445401 | Val. Kappa Score: 0.6261 | LR: 0.001000 | Estimated time: 510.13
Train loss on 50 batch: 0.488043
Train loss on 100 batch: 0.412902
Train loss on 150 batch: 0.424173
Train loss on 200 batch: 0.425394
Train loss on 250 batch: 0.388777
Train loss on 300 batch: 0.444588
Train loss on 350 batch: 0.381960
Train loss on 400 batch: 0.503506
Train loss on 450 batch: 0.394248
Train loss on 500 batch: 0.423914
Train loss on 550 batch: 0.453067
Train loss on 600 batch: 0.470247
Train loss on 650 batch: 0.440520
Train loss on 700 batch: 0.450268
Train loss on 750 batch: 0.417264
Train loss on 800 batch: 0.463728
Train loss on 850 batch: 0.487066
Train loss on 900 batch: 0.434398
Train loss on 950 batch: 0.420308
Train loss on 1000 batch: 0.362934
Train loss on 1050 batch: 0.434439
Train loss on 1100 batch: 0.492354
Train loss on 1150 batch: 0.418486
Train loss on 1200 batch: 0.471465
Train loss on 1250 batch: 0.371279
Train loss on 1300 batch: 0.406284
Train loss on 1350 batch: 0.431771
Train loss on 1400 batch: 0.431603
Train loss on 1450 batch: 0.459733
Train loss on 1500 batch: 0.408932
Train loss on 1550 batch: 0.437929
Train loss on 1600 batch: 0.474094
Train loss on 1650 batch: 0.479604
Train loss on 1700 batch: 0.454450
Train loss on 1750 batch: 0.431139
Train loss on 1800 batch: 0.435275
Train loss on 1850 batch: 0.404819
Train loss on 1900 batch: 0.430603
best-train-loss: 0.436524
best-valid-loss: 0.434330
best-kappa: 0.6318
: Epoch: 9 | Training Loss: 0.436524 | Val. Loss: 0.434330 | Val. Kappa Score: 0.6318 | LR: 0.001000 | Estimated time: 509.84
Train loss on 50 batch: 0.422338
Train loss on 100 batch: 0.404935
Train loss on 150 batch: 0.361820
Train loss on 200 batch: 0.419961
Train loss on 250 batch: 0.427301
Train loss on 300 batch: 0.427427
Train loss on 350 batch: 0.444315
Train loss on 400 batch: 0.428991
Train loss on 450 batch: 0.371025
Train loss on 500 batch: 0.433870
Train loss on 550 batch: 0.402787
Train loss on 600 batch: 0.367016
Train loss on 650 batch: 0.448892
Train loss on 700 batch: 0.487260
Train loss on 750 batch: 0.460497
Train loss on 800 batch: 0.465271
Train loss on 850 batch: 0.377941
Train loss on 900 batch: 0.387831
Train loss on 950 batch: 0.397184
Train loss on 1000 batch: 0.385851
Train loss on 1050 batch: 0.468653
Train loss on 1100 batch: 0.410597
Train loss on 1150 batch: 0.445703
Train loss on 1200 batch: 0.426699
Train loss on 1250 batch: 0.477555
Train loss on 1300 batch: 0.452093
Train loss on 1350 batch: 0.489797
Train loss on 1400 batch: 0.525200
Train loss on 1450 batch: 0.400500
Train loss on 1500 batch: 0.511040
Train loss on 1550 batch: 0.495906
Train loss on 1600 batch: 0.491140
Train loss on 1650 batch: 0.448711
Train loss on 1700 batch: 0.399168
Train loss on 1750 batch: 0.416342
Train loss on 1800 batch: 0.438624
Train loss on 1850 batch: 0.372651
Train loss on 1900 batch: 0.447698
best-train-loss: 0.430633
best-valid-loss: 0.417924
best-kappa: 0.6374
: Epoch: 10 | Training Loss: 0.430633 | Val. Loss: 0.417924 | Val. Kappa Score: 0.6374 | LR: 0.001000 | Estimated time: 510.11
Train loss on 50 batch: 0.434940
Train loss on 100 batch: 0.418556
Train loss on 150 batch: 0.354284
Train loss on 200 batch: 0.428234
Train loss on 250 batch: 0.409404
Train loss on 300 batch: 0.320229
Train loss on 350 batch: 0.461960
Train loss on 400 batch: 0.384052
Train loss on 450 batch: 0.417194
Train loss on 500 batch: 0.453000
Train loss on 550 batch: 0.390116
Train loss on 600 batch: 0.467062
Train loss on 650 batch: 0.367575
Train loss on 700 batch: 0.511495
Train loss on 750 batch: 0.516896
Train loss on 800 batch: 0.474945
Train loss on 850 batch: 0.557364
Train loss on 900 batch: 0.464857
Train loss on 950 batch: 0.360578
Train loss on 1000 batch: 0.405977
Train loss on 1050 batch: 0.468799
Train loss on 1100 batch: 0.406700
Train loss on 1150 batch: 0.437480
Train loss on 1200 batch: 0.401174
Train loss on 1250 batch: 0.411864
Train loss on 1300 batch: 0.366427
Train loss on 1350 batch: 0.413846
Train loss on 1400 batch: 0.396541
Train loss on 1450 batch: 0.418274
Train loss on 1500 batch: 0.434656
Train loss on 1550 batch: 0.433159
Train loss on 1600 batch: 0.424835
Train loss on 1650 batch: 0.451010
Train loss on 1700 batch: 0.430765
Train loss on 1750 batch: 0.430293
Train loss on 1800 batch: 0.435749
Train loss on 1850 batch: 0.409676
Train loss on 1900 batch: 0.441354
best-train-loss: 0.426186
best-valid-loss: 0.404966
best-kappa: 0.6424
: Epoch: 11 | Training Loss: 0.426186 | Val. Loss: 0.404966 | Val. Kappa Score: 0.6424 | LR: 0.001000 | Estimated time: 510.11
Train loss on 50 batch: 0.446997
Train loss on 100 batch: 0.443940
Train loss on 150 batch: 0.438770
Train loss on 200 batch: 0.408713
Train loss on 250 batch: 0.409866
Train loss on 300 batch: 0.443837
Train loss on 350 batch: 0.349172
Train loss on 400 batch: 0.428936
Train loss on 450 batch: 0.339659
Train loss on 500 batch: 0.423134
Train loss on 550 batch: 0.446410
Train loss on 600 batch: 0.434838
Train loss on 650 batch: 0.380969
Train loss on 700 batch: 0.490765
Train loss on 750 batch: 0.414337
Train loss on 800 batch: 0.375105
Train loss on 850 batch: 0.345626
Train loss on 900 batch: 0.416911
Train loss on 950 batch: 0.386056
Train loss on 1000 batch: 0.400573
Train loss on 1050 batch: 0.425066
Train loss on 1100 batch: 0.367366
Train loss on 1150 batch: 0.426132
Train loss on 1200 batch: 0.402820
Train loss on 1250 batch: 0.399039
Train loss on 1300 batch: 0.419662
Train loss on 1350 batch: 0.384585
Train loss on 1400 batch: 0.397957
Train loss on 1450 batch: 0.453425
Train loss on 1500 batch: 0.378777
Train loss on 1550 batch: 0.408772
Train loss on 1600 batch: 0.417285
Train loss on 1650 batch: 0.423912
Train loss on 1700 batch: 0.405238
Train loss on 1750 batch: 0.364348
Train loss on 1800 batch: 0.357534
Train loss on 1850 batch: 0.446294
Train loss on 1900 batch: 0.516290
best-train-loss: 0.410538
best-valid-loss: 0.425753
best-kappa: 0.6451
: Epoch: 12 | Training Loss: 0.410538 | Val. Loss: 0.425753 | Val. Kappa Score: 0.6451 | LR: 0.001000 | Estimated time: 510.78
Train loss on 50 batch: 0.384016
Train loss on 100 batch: 0.431093
Train loss on 150 batch: 0.379142
Train loss on 200 batch: 0.404370
Train loss on 250 batch: 0.382447
Train loss on 300 batch: 0.486587
Train loss on 350 batch: 0.399379
Train loss on 400 batch: 0.463940
Train loss on 450 batch: 0.351824
Train loss on 500 batch: 0.404270
Train loss on 550 batch: 0.372961
Train loss on 600 batch: 0.430846
Train loss on 650 batch: 0.407641
Train loss on 700 batch: 0.402567
Train loss on 750 batch: 0.433778
Train loss on 800 batch: 0.468987
Train loss on 850 batch: 0.372121
Train loss on 900 batch: 0.454075
Train loss on 950 batch: 0.406039
Train loss on 1000 batch: 0.390556
Train loss on 1050 batch: 0.422443
Train loss on 1100 batch: 0.420828
Train loss on 1150 batch: 0.378961
Train loss on 1200 batch: 0.399763
Train loss on 1250 batch: 0.409036
Train loss on 1300 batch: 0.417676
Train loss on 1350 batch: 0.419354
Train loss on 1400 batch: 0.401459
Train loss on 1450 batch: 0.416063
Train loss on 1500 batch: 0.408925
Train loss on 1550 batch: 0.392013
Train loss on 1600 batch: 0.426885
Train loss on 1650 batch: 0.409396
Train loss on 1700 batch: 0.410891
Train loss on 1750 batch: 0.433656
Train loss on 1800 batch: 0.415736
Train loss on 1850 batch: 0.372165
Train loss on 1900 batch: 0.365070
best-train-loss: 0.410854
best-valid-loss: 0.391581
best-kappa: 0.6500
: Epoch: 13 | Training Loss: 0.410854 | Val. Loss: 0.391581 | Val. Kappa Score: 0.6500 | LR: 0.001000 | Estimated time: 510.08
Train loss on 50 batch: 0.454646
Train loss on 100 batch: 0.429749
Train loss on 150 batch: 0.389595
Train loss on 200 batch: 0.395789
Train loss on 250 batch: 0.391262
Train loss on 300 batch: 0.427660
Train loss on 350 batch: 0.354982
Train loss on 400 batch: 0.381245
Train loss on 450 batch: 0.410412
Train loss on 500 batch: 0.355218
Train loss on 550 batch: 0.414100
Train loss on 600 batch: 0.371629
Train loss on 650 batch: 0.432803
Train loss on 700 batch: 0.400767
Train loss on 750 batch: 0.329757
Train loss on 800 batch: 0.383906
Train loss on 850 batch: 0.390330
Train loss on 900 batch: 0.458690
Train loss on 950 batch: 0.400620
Train loss on 1000 batch: 0.421488
Train loss on 1050 batch: 0.422355
Train loss on 1100 batch: 0.385892
Train loss on 1150 batch: 0.297768
Train loss on 1200 batch: 0.393388
Train loss on 1250 batch: 0.477482
Train loss on 1300 batch: 0.435013
Train loss on 1350 batch: 0.400416
Train loss on 1400 batch: 0.442945
Train loss on 1450 batch: 0.395142
Train loss on 1500 batch: 0.358659
Train loss on 1550 batch: 0.380718
Train loss on 1600 batch: 0.360478
Train loss on 1650 batch: 0.500533
Train loss on 1700 batch: 0.416407
Train loss on 1750 batch: 0.330306
Train loss on 1800 batch: 0.494786
Train loss on 1850 batch: 0.390709
Train loss on 1900 batch: 0.472183
best-train-loss: 0.402426
best-valid-loss: 0.427775
best-kappa: 0.6526
: Epoch: 14 | Training Loss: 0.402426 | Val. Loss: 0.427775 | Val. Kappa Score: 0.6526 | LR: 0.001000 | Estimated time: 510.46
Train loss on 50 batch: 0.369845
Train loss on 100 batch: 0.395225
Train loss on 150 batch: 0.355792
Train loss on 200 batch: 0.473075
Train loss on 250 batch: 0.427400
Train loss on 300 batch: 0.380617
Train loss on 350 batch: 0.476941
Train loss on 400 batch: 0.360992
Train loss on 450 batch: 0.412136
Train loss on 500 batch: 0.357417
Train loss on 550 batch: 0.451106
Train loss on 600 batch: 0.402618
Train loss on 650 batch: 0.410590
Train loss on 700 batch: 0.353390
Train loss on 750 batch: 0.364488
Train loss on 800 batch: 0.394249
Train loss on 850 batch: 0.498943
Train loss on 900 batch: 0.439961
Train loss on 950 batch: 0.453838
Train loss on 1000 batch: 0.385853
Train loss on 1050 batch: 0.422011
Train loss on 1100 batch: 0.358598
Train loss on 1150 batch: 0.432177
Train loss on 1200 batch: 0.407468
Train loss on 1250 batch: 0.381582
Train loss on 1300 batch: 0.435959
Train loss on 1350 batch: 0.363372
Train loss on 1400 batch: 0.391504
Train loss on 1450 batch: 0.393707
Train loss on 1500 batch: 0.358684
Train loss on 1550 batch: 0.346771
Train loss on 1600 batch: 0.439402
Train loss on 1650 batch: 0.405762
Train loss on 1700 batch: 0.291374
Train loss on 1750 batch: 0.360174
Train loss on 1800 batch: 0.365339
Train loss on 1850 batch: 0.406593
Train loss on 1900 batch: 0.462795
best-train-loss: 0.398296
best-valid-loss: 0.420380
best-kappa: 0.6543
: Epoch: 15 | Training Loss: 0.398296 | Val. Loss: 0.420380 | Val. Kappa Score: 0.6543 | LR: 0.001000 | Estimated time: 510.36
Train loss on 50 batch: 0.332804
Train loss on 100 batch: 0.387852
Train loss on 150 batch: 0.444527
Train loss on 200 batch: 0.315634
Train loss on 250 batch: 0.421458
Train loss on 300 batch: 0.400951
Train loss on 350 batch: 0.435417
Train loss on 400 batch: 0.345293
Train loss on 450 batch: 0.373138
Train loss on 500 batch: 0.418684
Train loss on 550 batch: 0.392158
Train loss on 600 batch: 0.425276
Train loss on 650 batch: 0.416129
Train loss on 700 batch: 0.342990
Train loss on 750 batch: 0.406364
Train loss on 800 batch: 0.435779
Train loss on 850 batch: 0.435150
Train loss on 900 batch: 0.412941
Train loss on 950 batch: 0.407716
Train loss on 1000 batch: 0.376768
Train loss on 1050 batch: 0.384315
Train loss on 1100 batch: 0.361022
Train loss on 1150 batch: 0.390417
Train loss on 1200 batch: 0.380483
Train loss on 1250 batch: 0.325221
Train loss on 1300 batch: 0.384808
Train loss on 1350 batch: 0.367922
Train loss on 1400 batch: 0.382477
Train loss on 1450 batch: 0.348369
Train loss on 1500 batch: 0.387783
Train loss on 1550 batch: 0.440817
Train loss on 1600 batch: 0.378398
Train loss on 1650 batch: 0.401760
Train loss on 1700 batch: 0.479653
Train loss on 1750 batch: 0.388550
Train loss on 1800 batch: 0.357463
Train loss on 1850 batch: 0.363301
Train loss on 1900 batch: 0.385788
: Epoch: 16 | Training Loss: 0.391659 | Val. Loss: 0.447994 | Val. Kappa Score: 0.6525 | LR: 0.001000 | Estimated time: 510.98
Train loss on 50 batch: 0.354042
Train loss on 100 batch: 0.376806
Train loss on 150 batch: 0.444106
Train loss on 200 batch: 0.397795
Train loss on 250 batch: 0.392033
Train loss on 300 batch: 0.395802
Train loss on 350 batch: 0.429363
Train loss on 400 batch: 0.369115
Train loss on 450 batch: 0.333089
Train loss on 500 batch: 0.326231
Train loss on 550 batch: 0.374998
Train loss on 600 batch: 0.340522
Train loss on 650 batch: 0.369889
Train loss on 700 batch: 0.407018
Train loss on 750 batch: 0.405476
Train loss on 800 batch: 0.367129
Train loss on 850 batch: 0.429051
Train loss on 900 batch: 0.459462
Train loss on 950 batch: 0.422974
Train loss on 1000 batch: 0.423004
Train loss on 1050 batch: 0.411851
Train loss on 1100 batch: 0.430557
Train loss on 1150 batch: 0.385488
Train loss on 1200 batch: 0.362307
Train loss on 1250 batch: 0.344864
Train loss on 1300 batch: 0.372678
Train loss on 1350 batch: 0.377103
Train loss on 1400 batch: 0.366520
Train loss on 1450 batch: 0.504972
Train loss on 1500 batch: 0.371577
Train loss on 1550 batch: 0.385512
Train loss on 1600 batch: 0.345618
Train loss on 1650 batch: 0.373576
Train loss on 1700 batch: 0.391155
Train loss on 1750 batch: 0.402570
Train loss on 1800 batch: 0.385771
Train loss on 1850 batch: 0.378160
Train loss on 1900 batch: 0.332244
best-train-loss: 0.386639
best-valid-loss: 0.378348
best-kappa: 0.6562
: Epoch: 17 | Training Loss: 0.386639 | Val. Loss: 0.378348 | Val. Kappa Score: 0.6562 | LR: 0.001000 | Estimated time: 510.24
Train loss on 50 batch: 0.391512
Train loss on 100 batch: 0.344140
Train loss on 150 batch: 0.385477
Train loss on 200 batch: 0.380641
Train loss on 250 batch: 0.414594
Train loss on 300 batch: 0.377775
Train loss on 350 batch: 0.345458
Train loss on 400 batch: 0.350904
Train loss on 450 batch: 0.388622
Train loss on 500 batch: 0.398514
Train loss on 550 batch: 0.414309
Train loss on 600 batch: 0.420282
Train loss on 650 batch: 0.320378
Train loss on 700 batch: 0.416853
Train loss on 750 batch: 0.382952
Train loss on 800 batch: 0.355020
Train loss on 850 batch: 0.345478
Train loss on 900 batch: 0.426005
Train loss on 950 batch: 0.336171
Train loss on 1000 batch: 0.359748
Train loss on 1050 batch: 0.390568
Train loss on 1100 batch: 0.412475
Train loss on 1150 batch: 0.358461
Train loss on 1200 batch: 0.460513
Train loss on 1250 batch: 0.381422
Train loss on 1300 batch: 0.342425
Train loss on 1350 batch: 0.399377
Train loss on 1400 batch: 0.398154
Train loss on 1450 batch: 0.440527
Train loss on 1500 batch: 0.405268
Train loss on 1550 batch: 0.405824
Train loss on 1600 batch: 0.329059
Train loss on 1650 batch: 0.335740
Train loss on 1700 batch: 0.411105
Train loss on 1750 batch: 0.381820
Train loss on 1800 batch: 0.346012
Train loss on 1850 batch: 0.350279
Train loss on 1900 batch: 0.428326
: Epoch: 18 | Training Loss: 0.383516 | Val. Loss: 0.464752 | Val. Kappa Score: 0.6546 | LR: 0.001000 | Estimated time: 510.47
Train loss on 50 batch: 0.299825
Train loss on 100 batch: 0.340086
Train loss on 150 batch: 0.405163
Train loss on 200 batch: 0.377168
Train loss on 250 batch: 0.441270
Train loss on 300 batch: 0.417543
Train loss on 350 batch: 0.380278
Train loss on 400 batch: 0.397076
Train loss on 450 batch: 0.410405
Train loss on 500 batch: 0.386126
Train loss on 550 batch: 0.312600
Train loss on 600 batch: 0.421708
Train loss on 650 batch: 0.430871
Train loss on 700 batch: 0.365678
Train loss on 750 batch: 0.345869
Train loss on 800 batch: 0.359255
Train loss on 850 batch: 0.441357
Train loss on 900 batch: 0.398162
Train loss on 950 batch: 0.354713
Train loss on 1000 batch: 0.396819
Train loss on 1050 batch: 0.415542
Train loss on 1100 batch: 0.341442
Train loss on 1150 batch: 0.300127
Train loss on 1200 batch: 0.375340
Train loss on 1250 batch: 0.410990
Train loss on 1300 batch: 0.404989
Train loss on 1350 batch: 0.393568
Train loss on 1400 batch: 0.388209
Train loss on 1450 batch: 0.333936
Train loss on 1500 batch: 0.354469
Train loss on 1550 batch: 0.330668
Train loss on 1600 batch: 0.341612
Train loss on 1650 batch: 0.371345
Train loss on 1700 batch: 0.359237
Train loss on 1750 batch: 0.325883
Train loss on 1800 batch: 0.422629
Train loss on 1850 batch: 0.326174
Train loss on 1900 batch: 0.470093
best-train-loss: 0.378101
best-valid-loss: 0.367919
best-kappa: 0.6584
: Epoch: 19 | Training Loss: 0.378101 | Val. Loss: 0.367919 | Val. Kappa Score: 0.6584 | LR: 0.001000 | Estimated time: 510.65
Train loss on 50 batch: 0.310440
Train loss on 100 batch: 0.420126
Train loss on 150 batch: 0.352923
Train loss on 200 batch: 0.374248
Train loss on 250 batch: 0.388411
Train loss on 300 batch: 0.337916
Train loss on 350 batch: 0.337620
Train loss on 400 batch: 0.407761
Train loss on 450 batch: 0.408504
Train loss on 500 batch: 0.363924
Train loss on 550 batch: 0.375981
Train loss on 600 batch: 0.338104
Train loss on 650 batch: 0.435979
Train loss on 700 batch: 0.386749
Train loss on 750 batch: 0.390877
Train loss on 800 batch: 0.351205
Train loss on 850 batch: 0.445868
Train loss on 900 batch: 0.388372
Train loss on 950 batch: 0.345358
Train loss on 1000 batch: 0.346096
Train loss on 1050 batch: 0.455485
Train loss on 1100 batch: 0.376951
Train loss on 1150 batch: 0.358752
Train loss on 1200 batch: 0.371698
Train loss on 1250 batch: 0.333319
Train loss on 1300 batch: 0.359854
Train loss on 1350 batch: 0.287616
Train loss on 1400 batch: 0.397825
Train loss on 1450 batch: 0.297449
Train loss on 1500 batch: 0.395813
Train loss on 1550 batch: 0.399856
Train loss on 1600 batch: 0.399254
Train loss on 1650 batch: 0.366167
Train loss on 1700 batch: 0.377394
Train loss on 1750 batch: 0.377919
Train loss on 1800 batch: 0.363002
Train loss on 1850 batch: 0.355537
Train loss on 1900 batch: 0.417634
best-train-loss: 0.373447
best-valid-loss: 0.428261
best-kappa: 0.6610
: Epoch: 20 | Training Loss: 0.373447 | Val. Loss: 0.428261 | Val. Kappa Score: 0.6610 | LR: 0.001000 | Estimated time: 511.23
Train loss on 50 batch: 0.347127
Train loss on 100 batch: 0.337437
Train loss on 150 batch: 0.382211
Train loss on 200 batch: 0.481435
Train loss on 250 batch: 0.335121
Train loss on 300 batch: 0.383123
Train loss on 350 batch: 0.342054
Train loss on 400 batch: 0.396123
Train loss on 450 batch: 0.364869
Train loss on 500 batch: 0.287617
Train loss on 550 batch: 0.380257
Train loss on 600 batch: 0.398099
Train loss on 650 batch: 0.352613
Train loss on 700 batch: 0.381403
Train loss on 750 batch: 0.326968
Train loss on 800 batch: 0.303938
Train loss on 850 batch: 0.359899
Train loss on 900 batch: 0.487698
Train loss on 950 batch: 0.344911
Train loss on 1000 batch: 0.373199
Train loss on 1050 batch: 0.331153
Train loss on 1100 batch: 0.432951
Train loss on 1150 batch: 0.331856
Train loss on 1200 batch: 0.349960
Train loss on 1250 batch: 0.384608
Train loss on 1300 batch: 0.332545
Train loss on 1350 batch: 0.389283
Train loss on 1400 batch: 0.353973
Train loss on 1450 batch: 0.405029
Train loss on 1500 batch: 0.376681
Train loss on 1550 batch: 0.358549
Train loss on 1600 batch: 0.382080
Train loss on 1650 batch: 0.327468
Train loss on 1700 batch: 0.437038
Train loss on 1750 batch: 0.417547
Train loss on 1800 batch: 0.331058
Train loss on 1850 batch: 0.381091
Train loss on 1900 batch: 0.372243
best-train-loss: 0.371548
best-valid-loss: 0.391125
best-kappa: 0.6634
: Epoch: 21 | Training Loss: 0.371548 | Val. Loss: 0.391125 | Val. Kappa Score: 0.6634 | LR: 0.001000 | Estimated time: 510.15
Train loss on 50 batch: 0.315383
Train loss on 100 batch: 0.408081
Train loss on 150 batch: 0.449874
Train loss on 200 batch: 0.379955
Train loss on 250 batch: 0.386645
Train loss on 300 batch: 0.346367
Train loss on 350 batch: 0.296770
Train loss on 400 batch: 0.338326
Train loss on 450 batch: 0.357197
Train loss on 500 batch: 0.332470
Train loss on 550 batch: 0.302859
Train loss on 600 batch: 0.395822
Train loss on 650 batch: 0.364287
Train loss on 700 batch: 0.420518
Train loss on 750 batch: 0.390763
Train loss on 800 batch: 0.357255
Train loss on 850 batch: 0.407842
Train loss on 900 batch: 0.384028
Train loss on 950 batch: 0.306124
Train loss on 1000 batch: 0.371181
Train loss on 1050 batch: 0.376051
Train loss on 1100 batch: 0.311732
Train loss on 1150 batch: 0.418931
Train loss on 1200 batch: 0.446956
Train loss on 1250 batch: 0.295489
Train loss on 1300 batch: 0.345845
Train loss on 1350 batch: 0.347837
Train loss on 1400 batch: 0.370187
Train loss on 1450 batch: 0.362554
Train loss on 1500 batch: 0.374576
Train loss on 1550 batch: 0.373821
Train loss on 1600 batch: 0.380818
Train loss on 1650 batch: 0.344399
Train loss on 1700 batch: 0.379136
Train loss on 1750 batch: 0.317880
Train loss on 1800 batch: 0.386172
Train loss on 1850 batch: 0.408155
Train loss on 1900 batch: 0.340534
best-train-loss: 0.367311
best-valid-loss: 0.543685
best-kappa: 0.6643
: Epoch: 22 | Training Loss: 0.367311 | Val. Loss: 0.543685 | Val. Kappa Score: 0.6643 | LR: 0.001000 | Estimated time: 510.35
Train loss on 50 batch: 0.376260
Train loss on 100 batch: 0.344181
Train loss on 150 batch: 0.373123
Train loss on 200 batch: 0.362276
Train loss on 250 batch: 0.364799
Train loss on 300 batch: 0.366521
Train loss on 350 batch: 0.374973
Train loss on 400 batch: 0.381605
Train loss on 450 batch: 0.361007
Train loss on 500 batch: 0.347685
Train loss on 550 batch: 0.398201
Train loss on 600 batch: 0.400510
Train loss on 650 batch: 0.362522
Train loss on 700 batch: 0.374501
Train loss on 750 batch: 0.380031
Train loss on 800 batch: 0.361640
Train loss on 850 batch: 0.420081
Train loss on 900 batch: 0.371763
Train loss on 950 batch: 0.346153
Train loss on 1000 batch: 0.370756
Train loss on 1050 batch: 0.394259
Train loss on 1100 batch: 0.438251
Train loss on 1150 batch: 0.438374
Train loss on 1200 batch: 0.307565
Train loss on 1250 batch: 0.386677
Train loss on 1300 batch: 0.383952
Train loss on 1350 batch: 0.377088
Train loss on 1400 batch: 0.400568
Train loss on 1450 batch: 0.339014
Train loss on 1500 batch: 0.313320
Train loss on 1550 batch: 0.377528
Train loss on 1600 batch: 0.328224
Train loss on 1650 batch: 0.373742
Train loss on 1700 batch: 0.387785
Train loss on 1750 batch: 0.334425
Train loss on 1800 batch: 0.360796
Train loss on 1850 batch: 0.358294
Train loss on 1900 batch: 0.351353
best-train-loss: 0.370468
best-valid-loss: 0.380461
best-kappa: 0.6656
: Epoch: 23 | Training Loss: 0.370468 | Val. Loss: 0.380461 | Val. Kappa Score: 0.6656 | LR: 0.001000 | Estimated time: 510.74
Train loss on 50 batch: 0.310135
Train loss on 100 batch: 0.327618
Train loss on 150 batch: 0.341210
Train loss on 200 batch: 0.375864
Train loss on 250 batch: 0.320179
Train loss on 300 batch: 0.309760
Train loss on 350 batch: 0.369781
Train loss on 400 batch: 0.318326
Train loss on 450 batch: 0.365459
Train loss on 500 batch: 0.386435
Train loss on 550 batch: 0.353442
Train loss on 600 batch: 0.340287
Train loss on 650 batch: 0.365166
Train loss on 700 batch: 0.336533
Train loss on 750 batch: 0.357054
Train loss on 800 batch: 0.398376
Train loss on 850 batch: 0.350107
Train loss on 900 batch: 0.362317
Train loss on 950 batch: 0.344179
Train loss on 1000 batch: 0.331100
Train loss on 1050 batch: 0.341298
Train loss on 1100 batch: 0.355154
Train loss on 1150 batch: 0.387001
Train loss on 1200 batch: 0.426988
Train loss on 1250 batch: 0.372474
Train loss on 1300 batch: 0.442521
Train loss on 1350 batch: 0.338295
Train loss on 1400 batch: 0.315774
Train loss on 1450 batch: 0.365616
Train loss on 1500 batch: 0.431374
Train loss on 1550 batch: 0.410673
Train loss on 1600 batch: 0.416297
Train loss on 1650 batch: 0.313928
Train loss on 1700 batch: 0.433902
Train loss on 1750 batch: 0.332741
Train loss on 1800 batch: 0.382406
Train loss on 1850 batch: 0.337664
Train loss on 1900 batch: 0.331165
best-train-loss: 0.360959
best-valid-loss: 0.378489
best-kappa: 0.6679
: Epoch: 24 | Training Loss: 0.360959 | Val. Loss: 0.378489 | Val. Kappa Score: 0.6679 | LR: 0.001000 | Estimated time: 510.32
Train loss on 50 batch: 0.332796
Train loss on 100 batch: 0.373746
Train loss on 150 batch: 0.405493
Train loss on 200 batch: 0.326359
Train loss on 250 batch: 0.386713
Train loss on 300 batch: 0.371850
Train loss on 350 batch: 0.331376
Train loss on 400 batch: 0.328396
Train loss on 450 batch: 0.347439
Train loss on 500 batch: 0.346707
Train loss on 550 batch: 0.350895
Train loss on 600 batch: 0.364088
Train loss on 650 batch: 0.379620
Train loss on 700 batch: 0.337440
Train loss on 750 batch: 0.311320
Train loss on 800 batch: 0.373122
Train loss on 850 batch: 0.337181
Train loss on 900 batch: 0.314974
Train loss on 950 batch: 0.365461
Train loss on 1000 batch: 0.368854
Train loss on 1050 batch: 0.399176
Train loss on 1100 batch: 0.367848
Train loss on 1150 batch: 0.345056
Train loss on 1200 batch: 0.308930
Train loss on 1250 batch: 0.372311
Train loss on 1300 batch: 0.292127
Train loss on 1350 batch: 0.385172
Train loss on 1400 batch: 0.344167
Train loss on 1450 batch: 0.384914
Train loss on 1500 batch: 0.391126
Train loss on 1550 batch: 0.371722
Train loss on 1600 batch: 0.369644
Train loss on 1650 batch: 0.361289
Train loss on 1700 batch: 0.443593
Train loss on 1750 batch: 0.352988
Train loss on 1800 batch: 0.365405
Train loss on 1850 batch: 0.392148
Train loss on 1900 batch: 0.389959
best-train-loss: 0.359710
best-valid-loss: 0.363428
best-kappa: 0.6699
: Epoch: 25 | Training Loss: 0.359710 | Val. Loss: 0.363428 | Val. Kappa Score: 0.6699 | LR: 0.001000 | Estimated time: 510.53
Train loss on 50 batch: 0.309048
Train loss on 100 batch: 0.352909
Train loss on 150 batch: 0.308902
Train loss on 200 batch: 0.359240
Train loss on 250 batch: 0.375253
Train loss on 300 batch: 0.379527
Train loss on 350 batch: 0.335594
Train loss on 400 batch: 0.334333
Train loss on 450 batch: 0.383708
Train loss on 500 batch: 0.368198
Train loss on 550 batch: 0.327450
Train loss on 600 batch: 0.362367
Train loss on 650 batch: 0.333812
Train loss on 700 batch: 0.344282
Train loss on 750 batch: 0.323523
Train loss on 800 batch: 0.365186
Train loss on 850 batch: 0.373678
Train loss on 900 batch: 0.390073
Train loss on 950 batch: 0.360596
Train loss on 1000 batch: 0.339014
Train loss on 1050 batch: 0.358835
Train loss on 1100 batch: 0.389651
Train loss on 1150 batch: 0.368019
Train loss on 1200 batch: 0.373102
Train loss on 1250 batch: 0.348984
Train loss on 1300 batch: 0.302725
Train loss on 1350 batch: 0.420007
Train loss on 1400 batch: 0.409733
Train loss on 1450 batch: 0.355612
Train loss on 1500 batch: 0.381458
Train loss on 1550 batch: 0.346510
Train loss on 1600 batch: 0.337171
Train loss on 1650 batch: 0.397461
Train loss on 1700 batch: 0.351041
Train loss on 1750 batch: 0.373184
Train loss on 1800 batch: 0.359537
Train loss on 1850 batch: 0.327532
Train loss on 1900 batch: 0.349387
best-train-loss: 0.356903
best-valid-loss: 0.391587
best-kappa: 0.6712
: Epoch: 26 | Training Loss: 0.356903 | Val. Loss: 0.391587 | Val. Kappa Score: 0.6712 | LR: 0.001000 | Estimated time: 510.23
Train loss on 50 batch: 0.361821
Train loss on 100 batch: 0.337658
Train loss on 150 batch: 0.396897
Train loss on 200 batch: 0.391295
Train loss on 250 batch: 0.268481
Train loss on 300 batch: 0.382902
Train loss on 350 batch: 0.362100
Train loss on 400 batch: 0.338850
Train loss on 450 batch: 0.314516
Train loss on 500 batch: 0.357548
Train loss on 550 batch: 0.385876
Train loss on 600 batch: 0.331037
Train loss on 650 batch: 0.352925
Train loss on 700 batch: 0.395828
Train loss on 750 batch: 0.369965
Train loss on 800 batch: 0.381198
Train loss on 850 batch: 0.344995
Train loss on 900 batch: 0.333871
Train loss on 950 batch: 0.356398
Train loss on 1000 batch: 0.332522
Train loss on 1050 batch: 0.377869
Train loss on 1100 batch: 0.368511
Train loss on 1150 batch: 0.351102
Train loss on 1200 batch: 0.370841
Train loss on 1250 batch: 0.467143
Train loss on 1300 batch: 0.380515
Train loss on 1350 batch: 0.355549
Train loss on 1400 batch: 0.305192
Train loss on 1450 batch: 0.361868
Train loss on 1500 batch: 0.357305
Train loss on 1550 batch: 0.363676
Train loss on 1600 batch: 0.317116
Train loss on 1650 batch: 0.285324
Train loss on 1700 batch: 0.361247
Train loss on 1750 batch: 0.344990
Train loss on 1800 batch: 0.349473
Train loss on 1850 batch: 0.382757
Train loss on 1900 batch: 0.292321
: Epoch: 27 | Training Loss: 0.354226 | Val. Loss: 0.495348 | Val. Kappa Score: 0.6700 | LR: 0.001000 | Estimated time: 511.00
Train loss on 50 batch: 0.355320
Train loss on 100 batch: 0.333736
Train loss on 150 batch: 0.351453
Train loss on 200 batch: 0.290822
Train loss on 250 batch: 0.341652
Train loss on 300 batch: 0.383720
Train loss on 350 batch: 0.405411
Train loss on 400 batch: 0.318423
Train loss on 450 batch: 0.321840
Train loss on 500 batch: 0.371075
Train loss on 550 batch: 0.338325
Train loss on 600 batch: 0.378231
Train loss on 650 batch: 0.385849
Train loss on 700 batch: 0.366341
Train loss on 750 batch: 0.347227
Train loss on 800 batch: 0.353272
Train loss on 850 batch: 0.361620
Train loss on 900 batch: 0.320114
Train loss on 950 batch: 0.390872
Train loss on 1000 batch: 0.357774
Train loss on 1050 batch: 0.338717
Train loss on 1100 batch: 0.341276
Train loss on 1150 batch: 0.327415
Train loss on 1200 batch: 0.350878
Train loss on 1250 batch: 0.366106
Train loss on 1300 batch: 0.304773
Train loss on 1350 batch: 0.313717
Train loss on 1400 batch: 0.360653
Train loss on 1450 batch: 0.393840
Train loss on 1500 batch: 0.348781
Train loss on 1550 batch: 0.376404
Train loss on 1600 batch: 0.422146
Train loss on 1650 batch: 0.304807
Train loss on 1700 batch: 0.371860
Train loss on 1750 batch: 0.356244
Train loss on 1800 batch: 0.329208
Train loss on 1850 batch: 0.346573
Train loss on 1900 batch: 0.322662
: Epoch: 28 | Training Loss: 0.351347 | Val. Loss: 0.401563 | Val. Kappa Score: 0.6704 | LR: 0.001000 | Estimated time: 510.27
Train loss on 50 batch: 0.330373
Train loss on 100 batch: 0.338147
Train loss on 150 batch: 0.359051
Train loss on 200 batch: 0.294534
Train loss on 250 batch: 0.341844
Train loss on 300 batch: 0.344805
Train loss on 350 batch: 0.422806
Train loss on 400 batch: 0.367244
Train loss on 450 batch: 0.378200
Train loss on 500 batch: 0.315649
Train loss on 550 batch: 0.295869
Train loss on 600 batch: 0.347134
Train loss on 650 batch: 0.326727
Train loss on 700 batch: 0.386474
Train loss on 750 batch: 0.373387
Train loss on 800 batch: 0.407176
Train loss on 850 batch: 0.394125
Train loss on 900 batch: 0.402906
Train loss on 950 batch: 0.341445
Train loss on 1000 batch: 0.377933
Train loss on 1050 batch: 0.321159
Train loss on 1100 batch: 0.389703
Train loss on 1150 batch: 0.309217
Train loss on 1200 batch: 0.384571
Train loss on 1250 batch: 0.329884
Train loss on 1300 batch: 0.376281
Train loss on 1350 batch: 0.346729
Train loss on 1400 batch: 0.388394
Train loss on 1450 batch: 0.393851
Train loss on 1500 batch: 0.353587
Train loss on 1550 batch: 0.297043
Train loss on 1600 batch: 0.360386
Train loss on 1650 batch: 0.312410
Train loss on 1700 batch: 0.328231
Train loss on 1750 batch: 0.380611
Train loss on 1800 batch: 0.352961
Train loss on 1850 batch: 0.296328
Train loss on 1900 batch: 0.317597
best-train-loss: 0.352550
best-valid-loss: 0.384421
best-kappa: 0.6724
: Epoch: 29 | Training Loss: 0.352550 | Val. Loss: 0.384421 | Val. Kappa Score: 0.6724 | LR: 0.001000 | Estimated time: 510.22
Train loss on 50 batch: 0.347352
Train loss on 100 batch: 0.320120
Train loss on 150 batch: 0.333899
Train loss on 200 batch: 0.323154
Train loss on 250 batch: 0.385369
Train loss on 300 batch: 0.355438
Train loss on 350 batch: 0.343597
Train loss on 400 batch: 0.346697
Train loss on 450 batch: 0.386875
Train loss on 500 batch: 0.348309
Train loss on 550 batch: 0.411327
Train loss on 600 batch: 0.346104
Train loss on 650 batch: 0.370854
Train loss on 700 batch: 0.344881
Train loss on 750 batch: 0.333132
Train loss on 800 batch: 0.320925
Train loss on 850 batch: 0.378935
Train loss on 900 batch: 0.311633
Train loss on 950 batch: 0.307784
Train loss on 1000 batch: 0.420285
Train loss on 1050 batch: 0.343854
Train loss on 1100 batch: 0.373234
Train loss on 1150 batch: 0.349372
Train loss on 1200 batch: 0.416956
Train loss on 1250 batch: 0.349943
Train loss on 1300 batch: 0.331949
Train loss on 1350 batch: 0.356613
Train loss on 1400 batch: 0.357387
Train loss on 1450 batch: 0.374291
Train loss on 1500 batch: 0.359277
Train loss on 1550 batch: 0.271510
Train loss on 1600 batch: 0.350532
Train loss on 1650 batch: 0.320937
Train loss on 1700 batch: 0.384078
Train loss on 1750 batch: 0.335481
Train loss on 1800 batch: 0.315347
Train loss on 1850 batch: 0.370792
Train loss on 1900 batch: 0.321443
best-train-loss: 0.351009
best-valid-loss: 0.350285
best-kappa: 0.6746
: Epoch: 30 | Training Loss: 0.351009 | Val. Loss: 0.350285 | Val. Kappa Score: 0.6746 | LR: 0.001000 | Estimated time: 511.02
Train loss on 50 batch: 0.375893
Train loss on 100 batch: 0.375410
Train loss on 150 batch: 0.351672
Train loss on 200 batch: 0.312882
Train loss on 250 batch: 0.285707
Train loss on 300 batch: 0.343025
Train loss on 350 batch: 0.345446
Train loss on 400 batch: 0.285657
Train loss on 450 batch: 0.332044
Train loss on 500 batch: 0.371251
Train loss on 550 batch: 0.342204
Train loss on 600 batch: 0.362662
Train loss on 650 batch: 0.343389
Train loss on 700 batch: 0.362327
Train loss on 750 batch: 0.404417
Train loss on 800 batch: 0.330494
Train loss on 850 batch: 0.318227
Train loss on 900 batch: 0.343491
Train loss on 950 batch: 0.311483
Train loss on 1000 batch: 0.372269
Train loss on 1050 batch: 0.354568
Train loss on 1100 batch: 0.410820
Train loss on 1150 batch: 0.273155
Train loss on 1200 batch: 0.363541
Train loss on 1250 batch: 0.271609
Train loss on 1300 batch: 0.407874
Train loss on 1350 batch: 0.334826
Train loss on 1400 batch: 0.408011
Train loss on 1450 batch: 0.345294
Train loss on 1500 batch: 0.383473
Train loss on 1550 batch: 0.383460
Train loss on 1600 batch: 0.314672
Train loss on 1650 batch: 0.328022
Train loss on 1700 batch: 0.321004
Train loss on 1750 batch: 0.390619
Train loss on 1800 batch: 0.312361
Train loss on 1850 batch: 0.314879
Train loss on 1900 batch: 0.363901
best-train-loss: 0.347426
best-valid-loss: 0.378014
best-kappa: 0.6758
: Epoch: 31 | Training Loss: 0.347426 | Val. Loss: 0.378014 | Val. Kappa Score: 0.6758 | LR: 0.001000 | Estimated time: 510.55
Train loss on 50 batch: 0.329055
Train loss on 100 batch: 0.431948
Train loss on 150 batch: 0.355022
Train loss on 200 batch: 0.368090
Train loss on 250 batch: 0.377280
Train loss on 300 batch: 0.306191
Train loss on 350 batch: 0.373322
Train loss on 400 batch: 0.356183
Train loss on 450 batch: 0.325928
Train loss on 500 batch: 0.401934
Train loss on 550 batch: 0.346044
Train loss on 600 batch: 0.403729
Train loss on 650 batch: 0.391926
Train loss on 700 batch: 0.359234
Train loss on 750 batch: 0.322998
Train loss on 800 batch: 0.329592
Train loss on 850 batch: 0.371158
Train loss on 900 batch: 0.313199
Train loss on 950 batch: 0.373975
Train loss on 1000 batch: 0.333223
Train loss on 1050 batch: 0.423072
Train loss on 1100 batch: 0.322384
Train loss on 1150 batch: 0.339653
Train loss on 1200 batch: 0.289597
Train loss on 1250 batch: 0.368264
Train loss on 1300 batch: 0.318533
Train loss on 1350 batch: 0.373905
Train loss on 1400 batch: 0.374753
Train loss on 1450 batch: 0.308277
Train loss on 1500 batch: 0.291098
Train loss on 1550 batch: 0.383248
Train loss on 1600 batch: 0.329957
Train loss on 1650 batch: 0.318911
Train loss on 1700 batch: 0.318134
Train loss on 1750 batch: 0.306088
Train loss on 1800 batch: 0.298873
Train loss on 1850 batch: 0.352228
Train loss on 1900 batch: 0.301134
best-train-loss: 0.344981
best-valid-loss: 0.362943
best-kappa: 0.6771
: Epoch: 32 | Training Loss: 0.344981 | Val. Loss: 0.362943 | Val. Kappa Score: 0.6771 | LR: 0.001000 | Estimated time: 510.38
Train loss on 50 batch: 0.304795
Train loss on 100 batch: 0.359338
Train loss on 150 batch: 0.333224
Train loss on 200 batch: 0.359516
Train loss on 250 batch: 0.367305
Train loss on 300 batch: 0.288628
Train loss on 350 batch: 0.370602
Train loss on 400 batch: 0.309905
Train loss on 450 batch: 0.303864
Train loss on 500 batch: 0.327090
Train loss on 550 batch: 0.283131
Train loss on 600 batch: 0.392557
Train loss on 650 batch: 0.340930
Train loss on 700 batch: 0.382680
Train loss on 750 batch: 0.321114
Train loss on 800 batch: 0.340470
Train loss on 850 batch: 0.367950
Train loss on 900 batch: 0.395521
Train loss on 950 batch: 0.322989
Train loss on 1000 batch: 0.360353
Train loss on 1050 batch: 0.327651
Train loss on 1100 batch: 0.304270
Train loss on 1150 batch: 0.350107
Train loss on 1200 batch: 0.269315
Train loss on 1250 batch: 0.339752
Train loss on 1300 batch: 0.339313
Train loss on 1350 batch: 0.315268
Train loss on 1400 batch: 0.348110
Train loss on 1450 batch: 0.443336
Train loss on 1500 batch: 0.390512
Train loss on 1550 batch: 0.405240
Train loss on 1600 batch: 0.332230
Train loss on 1650 batch: 0.349082
Train loss on 1700 batch: 0.311720
Train loss on 1750 batch: 0.380615
Train loss on 1800 batch: 0.335411
Train loss on 1850 batch: 0.320119
Train loss on 1900 batch: 0.378758
best-train-loss: 0.343424
best-valid-loss: 0.380374
best-kappa: 0.6784
: Epoch: 33 | Training Loss: 0.343424 | Val. Loss: 0.380374 | Val. Kappa Score: 0.6784 | LR: 0.001000 | Estimated time: 510.11
Train loss on 50 batch: 0.308136
Train loss on 100 batch: 0.346901
Train loss on 150 batch: 0.363889
Train loss on 200 batch: 0.321889
Train loss on 250 batch: 0.248169
Train loss on 300 batch: 0.342373
Train loss on 350 batch: 0.319594
Train loss on 400 batch: 0.364807
Train loss on 450 batch: 0.314054
Train loss on 500 batch: 0.340160
Train loss on 550 batch: 0.335196
Train loss on 600 batch: 0.340344
Train loss on 650 batch: 0.358283
Train loss on 700 batch: 0.357826
Train loss on 750 batch: 0.341607
Train loss on 800 batch: 0.368710
Train loss on 850 batch: 0.374592
Train loss on 900 batch: 0.397705
Train loss on 950 batch: 0.365555
Train loss on 1000 batch: 0.409232
Train loss on 1050 batch: 0.359681
Train loss on 1100 batch: 0.428850
Train loss on 1150 batch: 0.340825
Train loss on 1200 batch: 0.335606
Train loss on 1250 batch: 0.349935
Train loss on 1300 batch: 0.302398
Train loss on 1350 batch: 0.306561
Train loss on 1400 batch: 0.306224
Train loss on 1450 batch: 0.323178
Train loss on 1500 batch: 0.299047
Train loss on 1550 batch: 0.379914
Train loss on 1600 batch: 0.312227
Train loss on 1650 batch: 0.330592
Train loss on 1700 batch: 0.333419
Train loss on 1750 batch: 0.325031
Train loss on 1800 batch: 0.347121
Train loss on 1850 batch: 0.312817
Train loss on 1900 batch: 0.308295
best-train-loss: 0.339992
best-valid-loss: 0.384320
best-kappa: 0.6797
: Epoch: 34 | Training Loss: 0.339992 | Val. Loss: 0.384320 | Val. Kappa Score: 0.6797 | LR: 0.001000 | Estimated time: 510.06
Train loss on 50 batch: 0.236377
Train loss on 100 batch: 0.314423
Train loss on 150 batch: 0.297466
Train loss on 200 batch: 0.338313
Train loss on 250 batch: 0.277873
Train loss on 300 batch: 0.332273
Train loss on 350 batch: 0.336544
Train loss on 400 batch: 0.361658
Train loss on 450 batch: 0.330883
Train loss on 500 batch: 0.310818
Train loss on 550 batch: 0.303235
Train loss on 600 batch: 0.351354
Train loss on 650 batch: 0.363396
Train loss on 700 batch: 0.331539
Train loss on 750 batch: 0.337785
Train loss on 800 batch: 0.343615
Train loss on 850 batch: 0.372289
Train loss on 900 batch: 0.363928
Train loss on 950 batch: 0.351958
Train loss on 1000 batch: 0.355467
Train loss on 1050 batch: 0.361333
Train loss on 1100 batch: 0.350795
Train loss on 1150 batch: 0.293180
Train loss on 1200 batch: 0.430205
Train loss on 1250 batch: 0.371580
Train loss on 1300 batch: 0.376509
Train loss on 1350 batch: 0.383919
Train loss on 1400 batch: 0.304501
Train loss on 1450 batch: 0.326434
Train loss on 1500 batch: 0.309448
Train loss on 1550 batch: 0.313217
Train loss on 1600 batch: 0.301236
Train loss on 1650 batch: 0.324826
Train loss on 1700 batch: 0.307353
Train loss on 1750 batch: 0.422334
Train loss on 1800 batch: 0.360850
Train loss on 1850 batch: 0.324648
Train loss on 1900 batch: 0.322350
best-train-loss: 0.335050
best-valid-loss: 0.386354
best-kappa: 0.6807
: Epoch: 35 | Training Loss: 0.335050 | Val. Loss: 0.386354 | Val. Kappa Score: 0.6807 | LR: 0.001000 | Estimated time: 510.28
Train loss on 50 batch: 0.367497
Train loss on 100 batch: 0.269084
Train loss on 150 batch: 0.363392
Train loss on 200 batch: 0.306073
Train loss on 250 batch: 0.376913
Train loss on 300 batch: 0.323428
Train loss on 350 batch: 0.341146
Train loss on 400 batch: 0.303623
Train loss on 450 batch: 0.282447
Train loss on 500 batch: 0.305949
Train loss on 550 batch: 0.356604
Train loss on 600 batch: 0.345635
Train loss on 650 batch: 0.313226
Train loss on 700 batch: 0.381990
Train loss on 750 batch: 0.290158
Train loss on 800 batch: 0.360802
Train loss on 850 batch: 0.313296
Train loss on 900 batch: 0.366878
Train loss on 950 batch: 0.290810
Train loss on 1000 batch: 0.390288
Train loss on 1050 batch: 0.333669
Train loss on 1100 batch: 0.383867
Train loss on 1150 batch: 0.332151
Train loss on 1200 batch: 0.348714
Train loss on 1250 batch: 0.315049
Train loss on 1300 batch: 0.322567
Train loss on 1350 batch: 0.290312
Train loss on 1400 batch: 0.312720
Train loss on 1450 batch: 0.314297
Train loss on 1500 batch: 0.355772
Train loss on 1550 batch: 0.310795
Train loss on 1600 batch: 0.403054
Train loss on 1650 batch: 0.309893
Train loss on 1700 batch: 0.363905
Train loss on 1750 batch: 0.313098
Train loss on 1800 batch: 0.364147
Train loss on 1850 batch: 0.307076
Train loss on 1900 batch: 0.285067
best-train-loss: 0.332821
best-valid-loss: 0.375237
best-kappa: 0.6817
: Epoch: 36 | Training Loss: 0.332821 | Val. Loss: 0.375237 | Val. Kappa Score: 0.6817 | LR: 0.001000 | Estimated time: 510.58
Train loss on 50 batch: 0.294689
Train loss on 100 batch: 0.332399
Train loss on 150 batch: 0.316562
Train loss on 200 batch: 0.310200
Train loss on 250 batch: 0.386617
Train loss on 300 batch: 0.348041
Train loss on 350 batch: 0.369172
Train loss on 400 batch: 0.318047
Train loss on 450 batch: 0.326662
Train loss on 500 batch: 0.357051
Train loss on 550 batch: 0.321354
Train loss on 600 batch: 0.322062
Train loss on 650 batch: 0.322313
Train loss on 700 batch: 0.318331
Train loss on 750 batch: 0.371774
Train loss on 800 batch: 0.369439
Train loss on 850 batch: 0.286955
Train loss on 900 batch: 0.380740
Train loss on 950 batch: 0.356809
Train loss on 1000 batch: 0.285291
Train loss on 1050 batch: 0.351921
Train loss on 1100 batch: 0.307112
Train loss on 1150 batch: 0.333979
Train loss on 1200 batch: 0.356730
Train loss on 1250 batch: 0.363302
Train loss on 1300 batch: 0.311794
Train loss on 1350 batch: 0.317138
Train loss on 1400 batch: 0.311617
Train loss on 1450 batch: 0.366332
Train loss on 1500 batch: 0.324942
Train loss on 1550 batch: 0.294460
Train loss on 1600 batch: 0.376823
Train loss on 1650 batch: 0.362390
Train loss on 1700 batch: 0.358381
Train loss on 1750 batch: 0.390757
Train loss on 1800 batch: 0.300208
Train loss on 1850 batch: 0.397360
Train loss on 1900 batch: 0.279188
best-train-loss: 0.334854
best-valid-loss: 0.397334
best-kappa: 0.6824
: Epoch: 37 | Training Loss: 0.334854 | Val. Loss: 0.397334 | Val. Kappa Score: 0.6824 | LR: 0.001000 | Estimated time: 510.72
Train loss on 50 batch: 0.334442
Train loss on 100 batch: 0.360116
Train loss on 150 batch: 0.263080
Train loss on 200 batch: 0.367250
Train loss on 250 batch: 0.303571
Train loss on 300 batch: 0.390864
Train loss on 350 batch: 0.350177
Train loss on 400 batch: 0.307578
Train loss on 450 batch: 0.356598
Train loss on 500 batch: 0.320285
Train loss on 550 batch: 0.372787
Train loss on 600 batch: 0.300275
Train loss on 650 batch: 0.324562
Train loss on 700 batch: 0.358196
Train loss on 750 batch: 0.340836
Train loss on 800 batch: 0.336440
Train loss on 850 batch: 0.268118
Train loss on 900 batch: 0.344537
Train loss on 950 batch: 0.328274
Train loss on 1000 batch: 0.362637
Train loss on 1050 batch: 0.312023
Train loss on 1100 batch: 0.360000
Train loss on 1150 batch: 0.310839
Train loss on 1200 batch: 0.325236
Train loss on 1250 batch: 0.295609
Train loss on 1300 batch: 0.333895
Train loss on 1350 batch: 0.335485
Train loss on 1400 batch: 0.347057
Train loss on 1450 batch: 0.315544
Train loss on 1500 batch: 0.308898
Train loss on 1550 batch: 0.318098
Train loss on 1600 batch: 0.401700
Train loss on 1650 batch: 0.374713
Train loss on 1700 batch: 0.316544
Train loss on 1750 batch: 0.369478
Train loss on 1800 batch: 0.320320
Train loss on 1850 batch: 0.304816
Train loss on 1900 batch: 0.300117
best-train-loss: 0.332258
best-valid-loss: 0.394720
best-kappa: 0.6829
: Epoch: 38 | Training Loss: 0.332258 | Val. Loss: 0.394720 | Val. Kappa Score: 0.6829 | LR: 0.001000 | Estimated time: 510.92
Train loss on 50 batch: 0.332375
Train loss on 100 batch: 0.279393
Train loss on 150 batch: 0.331368
Train loss on 200 batch: 0.308942
Train loss on 250 batch: 0.306733
Train loss on 300 batch: 0.266537
Train loss on 350 batch: 0.405487
Train loss on 400 batch: 0.289757
Train loss on 450 batch: 0.311313
Train loss on 500 batch: 0.360353
Train loss on 550 batch: 0.356789
Train loss on 600 batch: 0.338179
Train loss on 650 batch: 0.405421
Train loss on 700 batch: 0.365361
Train loss on 750 batch: 0.290357
Train loss on 800 batch: 0.332186
Train loss on 850 batch: 0.341161
Train loss on 900 batch: 0.387613
Train loss on 950 batch: 0.370239
Train loss on 1000 batch: 0.329306
Train loss on 1050 batch: 0.352491
Train loss on 1100 batch: 0.361157
Train loss on 1150 batch: 0.343947
Train loss on 1200 batch: 0.312964
Train loss on 1250 batch: 0.338509
Train loss on 1300 batch: 0.374113
Train loss on 1350 batch: 0.384413
Train loss on 1400 batch: 0.330045
Train loss on 1450 batch: 0.333645
Train loss on 1500 batch: 0.316247
Train loss on 1550 batch: 0.334654
Train loss on 1600 batch: 0.308075
Train loss on 1650 batch: 0.317333
Train loss on 1700 batch: 0.365593
Train loss on 1750 batch: 0.363291
Train loss on 1800 batch: 0.347635
Train loss on 1850 batch: 0.311716
Train loss on 1900 batch: 0.356209
best-train-loss: 0.337934
best-valid-loss: 0.369542
best-kappa: 0.6843
: Epoch: 39 | Training Loss: 0.337934 | Val. Loss: 0.369542 | Val. Kappa Score: 0.6843 | LR: 0.001000 | Estimated time: 510.05
Train loss on 50 batch: 0.331735
Train loss on 100 batch: 0.286082
Train loss on 150 batch: 0.298394
Train loss on 200 batch: 0.319528
Train loss on 250 batch: 0.314562
Train loss on 300 batch: 0.305226
Train loss on 350 batch: 0.335874
Train loss on 400 batch: 0.315227
Train loss on 450 batch: 0.328032
Train loss on 500 batch: 0.294056
Train loss on 550 batch: 0.328974
Train loss on 600 batch: 0.286523
Train loss on 650 batch: 0.328639
Train loss on 700 batch: 0.285795
Train loss on 750 batch: 0.287390
Train loss on 800 batch: 0.372118
Train loss on 850 batch: 0.405386
Train loss on 900 batch: 0.309610
Train loss on 950 batch: 0.345538
Train loss on 1000 batch: 0.340035
Train loss on 1050 batch: 0.303344
Train loss on 1100 batch: 0.331527
Train loss on 1150 batch: 0.353909
Train loss on 1200 batch: 0.342607
Train loss on 1250 batch: 0.345227
Train loss on 1300 batch: 0.339167
Train loss on 1350 batch: 0.353000
Train loss on 1400 batch: 0.295123
Train loss on 1450 batch: 0.366053
Train loss on 1500 batch: 0.339625
Train loss on 1550 batch: 0.302210
Train loss on 1600 batch: 0.332315
Train loss on 1650 batch: 0.359631
Train loss on 1700 batch: 0.350670
Train loss on 1750 batch: 0.357935
Train loss on 1800 batch: 0.308352
Train loss on 1850 batch: 0.359253
Train loss on 1900 batch: 0.358330
best-train-loss: 0.328616
best-valid-loss: 0.379501
best-kappa: 0.6851
: Epoch: 40 | Training Loss: 0.328616 | Val. Loss: 0.379501 | Val. Kappa Score: 0.6851 | LR: 0.001000 | Estimated time: 510.26
Train loss on 50 batch: 0.402836
Train loss on 100 batch: 0.278900
Train loss on 150 batch: 0.327754
Train loss on 200 batch: 0.293911
Train loss on 250 batch: 0.309073
Train loss on 300 batch: 0.292836
Train loss on 350 batch: 0.306569
Train loss on 400 batch: 0.317662
Train loss on 450 batch: 0.294448
Train loss on 500 batch: 0.334122
Train loss on 550 batch: 0.371706
Train loss on 600 batch: 0.336883
Train loss on 650 batch: 0.283342
Train loss on 700 batch: 0.337202
Train loss on 750 batch: 0.306247
Train loss on 800 batch: 0.352074
Train loss on 850 batch: 0.367127
Train loss on 900 batch: 0.300648
Train loss on 950 batch: 0.306239
Train loss on 1000 batch: 0.329060
Train loss on 1050 batch: 0.329578
Train loss on 1100 batch: 0.369129
Train loss on 1150 batch: 0.346316
Train loss on 1200 batch: 0.278533
Train loss on 1250 batch: 0.331652
Train loss on 1300 batch: 0.307836
Train loss on 1350 batch: 0.295980
Train loss on 1400 batch: 0.363015
Train loss on 1450 batch: 0.279260
Train loss on 1500 batch: 0.312897
Train loss on 1550 batch: 0.337360
Train loss on 1600 batch: 0.344963
Train loss on 1650 batch: 0.311029
Train loss on 1700 batch: 0.302666
Train loss on 1750 batch: 0.345386
Train loss on 1800 batch: 0.411835
Train loss on 1850 batch: 0.325274
Train loss on 1900 batch: 0.359181
: Epoch: 41 | Training Loss: 0.327094 | Val. Loss: 0.413485 | Val. Kappa Score: 0.6850 | LR: 0.001000 | Estimated time: 510.03
Train loss on 50 batch: 0.332540
Train loss on 100 batch: 0.293481
Train loss on 150 batch: 0.338419
Train loss on 200 batch: 0.372446
Train loss on 250 batch: 0.348799
Train loss on 300 batch: 0.303828
Train loss on 350 batch: 0.316484
Train loss on 400 batch: 0.336663
Train loss on 450 batch: 0.338718
Train loss on 500 batch: 0.354098
Train loss on 550 batch: 0.362175
Train loss on 600 batch: 0.287464
Train loss on 650 batch: 0.365096
Train loss on 700 batch: 0.356138
Train loss on 750 batch: 0.318975
Train loss on 800 batch: 0.352833
Train loss on 850 batch: 0.334030
Train loss on 900 batch: 0.294335
Train loss on 950 batch: 0.319777
Train loss on 1000 batch: 0.343327
Train loss on 1050 batch: 0.316864
Train loss on 1100 batch: 0.299519
Train loss on 1150 batch: 0.303716
Train loss on 1200 batch: 0.321273
Train loss on 1250 batch: 0.319953
Train loss on 1300 batch: 0.374782
Train loss on 1350 batch: 0.308306
Train loss on 1400 batch: 0.377032
Train loss on 1450 batch: 0.329025
Train loss on 1500 batch: 0.321542
Train loss on 1550 batch: 0.300604
Train loss on 1600 batch: 0.322142
Train loss on 1650 batch: 0.305830
Train loss on 1700 batch: 0.350507
Train loss on 1750 batch: 0.320676
Train loss on 1800 batch: 0.316516
Train loss on 1850 batch: 0.282185
Train loss on 1900 batch: 0.315837
: Epoch: 42 | Training Loss: 0.329308 | Val. Loss: 0.502483 | Val. Kappa Score: 0.6851 | LR: 0.001000 | Estimated time: 510.46
Train loss on 50 batch: 0.345124
Train loss on 100 batch: 0.278183
Train loss on 150 batch: 0.336914
Train loss on 200 batch: 0.329373
Train loss on 250 batch: 0.327928
Train loss on 300 batch: 0.340776
Train loss on 350 batch: 0.357313
Train loss on 400 batch: 0.293497
Train loss on 450 batch: 0.337028
Train loss on 500 batch: 0.323795
Train loss on 550 batch: 0.313632
Train loss on 600 batch: 0.338943
Train loss on 650 batch: 0.293926
Train loss on 700 batch: 0.269023
Train loss on 750 batch: 0.328348
Train loss on 800 batch: 0.335909
Train loss on 850 batch: 0.343064
Train loss on 900 batch: 0.292642
Train loss on 950 batch: 0.346589
Train loss on 1000 batch: 0.366217
Train loss on 1050 batch: 0.309729
Train loss on 1100 batch: 0.319767
Train loss on 1150 batch: 0.370462
Train loss on 1200 batch: 0.368676
Train loss on 1250 batch: 0.276475
Train loss on 1300 batch: 0.347694
Train loss on 1350 batch: 0.345975
Train loss on 1400 batch: 0.294400
Train loss on 1450 batch: 0.322954
Train loss on 1500 batch: 0.330664
Train loss on 1550 batch: 0.296724
Train loss on 1600 batch: 0.289831
Train loss on 1650 batch: 0.336444
Train loss on 1700 batch: 0.303194
Train loss on 1750 batch: 0.278686
Train loss on 1800 batch: 0.325795
Train loss on 1850 batch: 0.288858
Train loss on 1900 batch: 0.325553
best-train-loss: 0.321515
best-valid-loss: 0.386632
best-kappa: 0.6861
: Epoch: 43 | Training Loss: 0.321515 | Val. Loss: 0.386632 | Val. Kappa Score: 0.6861 | LR: 0.001000 | Estimated time: 510.67
Train loss on 50 batch: 0.281111
Train loss on 100 batch: 0.356601
Train loss on 150 batch: 0.256963
Train loss on 200 batch: 0.288115
Train loss on 250 batch: 0.303755
Train loss on 300 batch: 0.362950
Train loss on 350 batch: 0.248638
Train loss on 400 batch: 0.339373
Train loss on 450 batch: 0.331050
Train loss on 500 batch: 0.324104
Train loss on 550 batch: 0.335626
Train loss on 600 batch: 0.305657
Train loss on 650 batch: 0.312994
Train loss on 700 batch: 0.318050
Train loss on 750 batch: 0.347694
Train loss on 800 batch: 0.375114
Train loss on 850 batch: 0.300187
Train loss on 900 batch: 0.324358
Train loss on 950 batch: 0.299353
Train loss on 1000 batch: 0.323215
Train loss on 1050 batch: 0.292441
Train loss on 1100 batch: 0.323695
Train loss on 1150 batch: 0.321106
Train loss on 1200 batch: 0.309620
Train loss on 1250 batch: 0.375658
Train loss on 1300 batch: 0.307657
Train loss on 1350 batch: 0.337483
Train loss on 1400 batch: 0.313461
Train loss on 1450 batch: 0.374878
Train loss on 1500 batch: 0.314784
Train loss on 1550 batch: 0.345248
Train loss on 1600 batch: 0.347338
Train loss on 1650 batch: 0.359180
Train loss on 1700 batch: 0.346961
Train loss on 1750 batch: 0.349664
Train loss on 1800 batch: 0.317560
Train loss on 1850 batch: 0.339613
Train loss on 1900 batch: 0.312399
best-train-loss: 0.323977
best-valid-loss: 0.358220
best-kappa: 0.6871
: Epoch: 44 | Training Loss: 0.323977 | Val. Loss: 0.358220 | Val. Kappa Score: 0.6871 | LR: 0.001000 | Estimated time: 510.55
Train loss on 50 batch: 0.345286
Train loss on 100 batch: 0.287188
Train loss on 150 batch: 0.293477
Train loss on 200 batch: 0.319931
Train loss on 250 batch: 0.350340
Train loss on 300 batch: 0.324562
Train loss on 350 batch: 0.323965
Train loss on 400 batch: 0.311366
Train loss on 450 batch: 0.292052
Train loss on 500 batch: 0.388141
Train loss on 550 batch: 0.382838
Train loss on 600 batch: 0.301126
Train loss on 650 batch: 0.323912
Train loss on 700 batch: 0.290645
Train loss on 750 batch: 0.308785
Train loss on 800 batch: 0.312957
Train loss on 850 batch: 0.275757
Train loss on 900 batch: 0.306203
Train loss on 950 batch: 0.284611
Train loss on 1000 batch: 0.326853
Train loss on 1050 batch: 0.322326
Train loss on 1100 batch: 0.299738
Train loss on 1150 batch: 0.287789
Train loss on 1200 batch: 0.391626
Train loss on 1250 batch: 0.385601
Train loss on 1300 batch: 0.274178
Train loss on 1350 batch: 0.341562
Train loss on 1400 batch: 0.354246
Train loss on 1450 batch: 0.307204
Train loss on 1500 batch: 0.328902
Train loss on 1550 batch: 0.276463
Train loss on 1600 batch: 0.291082
Train loss on 1650 batch: 0.348398
Train loss on 1700 batch: 0.293412
Train loss on 1750 batch: 0.371847
Train loss on 1800 batch: 0.346977
Train loss on 1850 batch: 0.294204
Train loss on 1900 batch: 0.341470
best-train-loss: 0.322764
best-valid-loss: 0.399124
best-kappa: 0.6881
: Epoch: 45 | Training Loss: 0.322764 | Val. Loss: 0.399124 | Val. Kappa Score: 0.6881 | LR: 0.001000 | Estimated time: 510.50
Train loss on 50 batch: 0.288052
Train loss on 100 batch: 0.322107
Train loss on 150 batch: 0.417640
Train loss on 200 batch: 0.343018
Train loss on 250 batch: 0.363995
Train loss on 300 batch: 0.292677
Train loss on 350 batch: 0.307434
Train loss on 400 batch: 0.345370
Train loss on 450 batch: 0.297909
Train loss on 500 batch: 0.303242
Train loss on 550 batch: 0.286466
Train loss on 600 batch: 0.352857
Train loss on 650 batch: 0.324657
Train loss on 700 batch: 0.313753
Train loss on 750 batch: 0.276659
Train loss on 800 batch: 0.321947
Train loss on 850 batch: 0.343272
Train loss on 900 batch: 0.324649
Train loss on 950 batch: 0.349569
Train loss on 1000 batch: 0.265817
Train loss on 1050 batch: 0.291903
Train loss on 1100 batch: 0.274717
Train loss on 1150 batch: 0.255340
Train loss on 1200 batch: 0.291409
Train loss on 1250 batch: 0.213715
Train loss on 1300 batch: 0.282859
Train loss on 1350 batch: 0.337414
Train loss on 1400 batch: 0.304949
Train loss on 1450 batch: 0.293226
Train loss on 1500 batch: 0.343968
Train loss on 1550 batch: 0.344570
Train loss on 1600 batch: 0.330713
Train loss on 1650 batch: 0.349287
Train loss on 1700 batch: 0.332230
Train loss on 1750 batch: 0.304395
Train loss on 1800 batch: 0.315487
Train loss on 1850 batch: 0.340267
Train loss on 1900 batch: 0.358381
best-train-loss: 0.316426
best-valid-loss: 0.350329
best-kappa: 0.6893
: Epoch: 46 | Training Loss: 0.316426 | Val. Loss: 0.350329 | Val. Kappa Score: 0.6893 | LR: 0.001000 | Estimated time: 510.52
Train loss on 50 batch: 0.318216
Train loss on 100 batch: 0.298781
Train loss on 150 batch: 0.303448
Train loss on 200 batch: 0.336240
Train loss on 250 batch: 0.324349
Train loss on 300 batch: 0.322141
Train loss on 350 batch: 0.306294
Train loss on 400 batch: 0.310744
Train loss on 450 batch: 0.324811
Train loss on 500 batch: 0.281632
Train loss on 550 batch: 0.288093
Train loss on 600 batch: 0.345865
Train loss on 650 batch: 0.296903
Train loss on 700 batch: 0.334526
Train loss on 750 batch: 0.321391
Train loss on 800 batch: 0.307159
Train loss on 850 batch: 0.319415
Train loss on 900 batch: 0.284092
Train loss on 950 batch: 0.320932
Train loss on 1000 batch: 0.346896
Train loss on 1050 batch: 0.269700
Train loss on 1100 batch: 0.389588
Train loss on 1150 batch: 0.287525
Train loss on 1200 batch: 0.316720
Train loss on 1250 batch: 0.361834
Train loss on 1300 batch: 0.337962
Train loss on 1350 batch: 0.333205
Train loss on 1400 batch: 0.327114
Train loss on 1450 batch: 0.347083
Train loss on 1500 batch: 0.322724
Train loss on 1550 batch: 0.310707
Train loss on 1600 batch: 0.325893
Train loss on 1650 batch: 0.312926
Train loss on 1700 batch: 0.380999
Train loss on 1750 batch: 0.314154
Train loss on 1800 batch: 0.308718
Train loss on 1850 batch: 0.305536
Train loss on 1900 batch: 0.344663
best-train-loss: 0.320098
best-valid-loss: 0.339406
best-kappa: 0.6905
: Epoch: 47 | Training Loss: 0.320098 | Val. Loss: 0.339406 | Val. Kappa Score: 0.6905 | LR: 0.001000 | Estimated time: 510.42
Train loss on 50 batch: 0.306161
Train loss on 100 batch: 0.315342
Train loss on 150 batch: 0.371831
Train loss on 200 batch: 0.305077
----------------------------------------

Experiment N: 68: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.13 15:30:56
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f97cc0>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.105870
Train loss on 100 batch: 0.819989
Train loss on 150 batch: 0.784737
Train loss on 200 batch: 0.679449
Train loss on 250 batch: 0.681091
Train loss on 300 batch: 0.710707
Train loss on 350 batch: 0.769015
Train loss on 400 batch: 0.738236
Train loss on 450 batch: 0.764597
Train loss on 500 batch: 0.705318
Train loss on 550 batch: 0.613511
Train loss on 600 batch: 0.643189
Train loss on 650 batch: 0.722165
Train loss on 700 batch: 0.681326
Train loss on 750 batch: 0.611471
Train loss on 800 batch: 0.630390
Train loss on 850 batch: 0.678947
Train loss on 900 batch: 0.587223
Train loss on 950 batch: 0.533098
Train loss on 1000 batch: 0.600493
Train loss on 1050 batch: 0.626574
Train loss on 1100 batch: 0.614163
Train loss on 1150 batch: 0.597807
Train loss on 1200 batch: 0.616330
Train loss on 1250 batch: 0.522703
Train loss on 1300 batch: 0.601558
Train loss on 1350 batch: 0.577399
Train loss on 1400 batch: 0.616361
Train loss on 1450 batch: 0.698418
Train loss on 1500 batch: 0.586392
Train loss on 1550 batch: 0.577102
Train loss on 1600 batch: 0.650284
Train loss on 1650 batch: 0.664136
Train loss on 1700 batch: 0.603288
Train loss on 1750 batch: 0.614834
Train loss on 1800 batch: 0.537028
Train loss on 1850 batch: 0.679963
Train loss on 1900 batch: 0.610902
best-train-loss: 0.658830
best-valid-loss: 0.738719
best-kappa: 0.4448
: Epoch: 1 | Training Loss: 0.658830 | Val. Loss: 0.738719 | Val. Kappa Score: 0.4448 | LR: 0.001000 | Estimated time: 538.47
Train loss on 50 batch: 0.569473
Train loss on 100 batch: 0.624813
Train loss on 150 batch: 0.553061
Train loss on 200 batch: 0.613984
Train loss on 250 batch: 0.548327
Train loss on 300 batch: 0.570272
Train loss on 350 batch: 0.630102
Train loss on 400 batch: 0.540615
Train loss on 450 batch: 0.506973
Train loss on 500 batch: 0.564841
Train loss on 550 batch: 0.574588
Train loss on 600 batch: 0.530424
Train loss on 650 batch: 0.494414
Train loss on 700 batch: 0.621361
Train loss on 750 batch: 0.555948
Train loss on 800 batch: 0.523952
Train loss on 850 batch: 0.580143
Train loss on 900 batch: 0.670548
Train loss on 950 batch: 0.586634
Train loss on 1000 batch: 0.536221
Train loss on 1050 batch: 0.537237
Train loss on 1100 batch: 0.617010
Train loss on 1150 batch: 0.465456
Train loss on 1200 batch: 0.512022
Train loss on 1250 batch: 0.543868
Train loss on 1300 batch: 0.600703
Train loss on 1350 batch: 0.580944
Train loss on 1400 batch: 0.507969
Train loss on 1450 batch: 0.622582
Train loss on 1500 batch: 0.619729
Train loss on 1550 batch: 0.571842
Train loss on 1600 batch: 0.530878
Train loss on 1650 batch: 0.541677
Train loss on 1700 batch: 0.643404
Train loss on 1750 batch: 0.526861
Train loss on 1800 batch: 0.538461
Train loss on 1850 batch: 0.516097
Train loss on 1900 batch: 0.483995
best-train-loss: 0.560481
best-valid-loss: 0.463692
best-kappa: 0.5395
: Epoch: 2 | Training Loss: 0.560481 | Val. Loss: 0.463692 | Val. Kappa Score: 0.5395 | LR: 0.001000 | Estimated time: 549.01
Train loss on 50 batch: 0.580255
Train loss on 100 batch: 0.589429
Train loss on 150 batch: 0.495825
Train loss on 200 batch: 0.572952
Train loss on 250 batch: 0.551408
Train loss on 300 batch: 0.444567
Train loss on 350 batch: 0.497108
Train loss on 400 batch: 0.478383
Train loss on 450 batch: 0.491427
Train loss on 500 batch: 0.570607
Train loss on 550 batch: 0.484798
Train loss on 600 batch: 0.569671
Train loss on 650 batch: 0.599432
Train loss on 700 batch: 0.548392
Train loss on 750 batch: 0.559348
Train loss on 800 batch: 0.497437
Train loss on 850 batch: 0.600505
Train loss on 900 batch: 0.503075
Train loss on 950 batch: 0.493958
Train loss on 1000 batch: 0.474300
Train loss on 1050 batch: 0.474511
Train loss on 1100 batch: 0.561475
Train loss on 1150 batch: 0.541072
Train loss on 1200 batch: 0.580646
Train loss on 1250 batch: 0.485784
Train loss on 1300 batch: 0.481741
Train loss on 1350 batch: 0.544384
Train loss on 1400 batch: 0.529124
Train loss on 1450 batch: 0.570650
Train loss on 1500 batch: 0.510127
Train loss on 1550 batch: 0.515326
Train loss on 1600 batch: 0.520872
Train loss on 1650 batch: 0.465721
Train loss on 1700 batch: 0.443166
Train loss on 1750 batch: 0.499020
Train loss on 1800 batch: 0.546061
Train loss on 1850 batch: 0.475909
Train loss on 1900 batch: 0.528618
best-train-loss: 0.523660
best-valid-loss: 0.456961
best-kappa: 0.5722
: Epoch: 3 | Training Loss: 0.523660 | Val. Loss: 0.456961 | Val. Kappa Score: 0.5722 | LR: 0.001000 | Estimated time: 541.78
Train loss on 50 batch: 0.520895
Train loss on 100 batch: 0.474083
Train loss on 150 batch: 0.504232
Train loss on 200 batch: 0.486721
Train loss on 250 batch: 0.493828
Train loss on 300 batch: 0.472207
Train loss on 350 batch: 0.606776
Train loss on 400 batch: 0.514847
Train loss on 450 batch: 0.431720
Train loss on 500 batch: 0.537358
Train loss on 550 batch: 0.488887
Train loss on 600 batch: 0.467966
Train loss on 650 batch: 0.451606
Train loss on 700 batch: 0.510197
Train loss on 750 batch: 0.459185
Train loss on 800 batch: 0.507395
Train loss on 850 batch: 0.486389
Train loss on 900 batch: 0.521469
Train loss on 950 batch: 0.497938
Train loss on 1000 batch: 0.422425
Train loss on 1050 batch: 0.563703
Train loss on 1100 batch: 0.499202
Train loss on 1150 batch: 0.534210
Train loss on 1200 batch: 0.493529
Train loss on 1250 batch: 0.428290
Train loss on 1300 batch: 0.480616
Train loss on 1350 batch: 0.437883
Train loss on 1400 batch: 0.537885
Train loss on 1450 batch: 0.543403
Train loss on 1500 batch: 0.448019
Train loss on 1550 batch: 0.515840
Train loss on 1600 batch: 0.573170
Train loss on 1650 batch: 0.515740
Train loss on 1700 batch: 0.585357
Train loss on 1750 batch: 0.489763
Train loss on 1800 batch: 0.474412
Train loss on 1850 batch: 0.494350
Train loss on 1900 batch: 0.527255
: Epoch: 4 | Training Loss: 0.499060 | Val. Loss: 0.473309 | Val. Kappa Score: 0.5921 | LR: 0.001000 | Estimated time: 520.42
Train loss on 50 batch: 0.466693
Train loss on 100 batch: 0.524156
Train loss on 150 batch: 0.462583
Train loss on 200 batch: 0.522479
Train loss on 250 batch: 0.467671
Train loss on 300 batch: 0.482628
Train loss on 350 batch: 0.559154
Train loss on 400 batch: 0.482573
Train loss on 450 batch: 0.492821
Train loss on 500 batch: 0.551315
Train loss on 550 batch: 0.537248
Train loss on 600 batch: 0.509826
Train loss on 650 batch: 0.462682
Train loss on 700 batch: 0.526076
Train loss on 750 batch: 0.501392
Train loss on 800 batch: 0.518101
Train loss on 850 batch: 0.498549
Train loss on 900 batch: 0.468225
Train loss on 950 batch: 0.419476
Train loss on 1000 batch: 0.472808
Train loss on 1050 batch: 0.586140
Train loss on 1100 batch: 0.478314
Train loss on 1150 batch: 0.515775
Train loss on 1200 batch: 0.421140
Train loss on 1250 batch: 0.503954
Train loss on 1300 batch: 0.541490
Train loss on 1350 batch: 0.468007
Train loss on 1400 batch: 0.483058
Train loss on 1450 batch: 0.392385
Train loss on 1500 batch: 0.443362
Train loss on 1550 batch: 0.417666
Train loss on 1600 batch: 0.442480
Train loss on 1650 batch: 0.449287
Train loss on 1700 batch: 0.513165
Train loss on 1750 batch: 0.485740
Train loss on 1800 batch: 0.458420
Train loss on 1850 batch: 0.442815
Train loss on 1900 batch: 0.473879
best-train-loss: 0.486785
best-valid-loss: 0.441669
best-kappa: 0.6074
: Epoch: 5 | Training Loss: 0.486785 | Val. Loss: 0.441669 | Val. Kappa Score: 0.6074 | LR: 0.001000 | Estimated time: 511.04
Train loss on 50 batch: 0.499636
Train loss on 100 batch: 0.452699
Train loss on 150 batch: 0.433077
Train loss on 200 batch: 0.546497
Train loss on 250 batch: 0.412555
Train loss on 300 batch: 0.519282
Train loss on 350 batch: 0.469073
Train loss on 400 batch: 0.510035
Train loss on 450 batch: 0.495079
Train loss on 500 batch: 0.452684
Train loss on 550 batch: 0.483440
Train loss on 600 batch: 0.508285
Train loss on 650 batch: 0.471457
Train loss on 700 batch: 0.436785
Train loss on 750 batch: 0.432005
Train loss on 800 batch: 0.497929
Train loss on 850 batch: 0.437625
Train loss on 900 batch: 0.522443
Train loss on 950 batch: 0.495103
Train loss on 1000 batch: 0.468597
Train loss on 1050 batch: 0.503114
Train loss on 1100 batch: 0.460086
Train loss on 1150 batch: 0.498708
Train loss on 1200 batch: 0.419302
Train loss on 1250 batch: 0.476013
Train loss on 1300 batch: 0.495339
Train loss on 1350 batch: 0.430822
Train loss on 1400 batch: 0.476612
Train loss on 1450 batch: 0.472672
Train loss on 1500 batch: 0.488723
Train loss on 1550 batch: 0.520454
Train loss on 1600 batch: 0.490716
Train loss on 1650 batch: 0.436925
Train loss on 1700 batch: 0.389784
Train loss on 1750 batch: 0.450747
Train loss on 1800 batch: 0.395094
Train loss on 1850 batch: 0.448319
Train loss on 1900 batch: 0.477228
: Epoch: 6 | Training Loss: 0.470645 | Val. Loss: 0.520216 | Val. Kappa Score: 0.6170 | LR: 0.001000 | Estimated time: 510.39
Train loss on 50 batch: 0.464256
Train loss on 100 batch: 0.479727
Train loss on 150 batch: 0.497726
Train loss on 200 batch: 0.473922
Train loss on 250 batch: 0.542747
Train loss on 300 batch: 0.520270
Train loss on 350 batch: 0.407763
Train loss on 400 batch: 0.484943
Train loss on 450 batch: 0.445551
Train loss on 500 batch: 0.421122
Train loss on 550 batch: 0.447819
Train loss on 600 batch: 0.555132
Train loss on 650 batch: 0.435268
Train loss on 700 batch: 0.429235
Train loss on 750 batch: 0.398770
Train loss on 800 batch: 0.456992
Train loss on 850 batch: 0.446832
Train loss on 900 batch: 0.460411
Train loss on 950 batch: 0.381705
Train loss on 1000 batch: 0.404003
Train loss on 1050 batch: 0.459500
Train loss on 1100 batch: 0.422315
Train loss on 1150 batch: 0.428826
Train loss on 1200 batch: 0.434554
Train loss on 1250 batch: 0.475285
Train loss on 1300 batch: 0.514665
Train loss on 1350 batch: 0.439775
Train loss on 1400 batch: 0.440490
Train loss on 1450 batch: 0.458329
Train loss on 1500 batch: 0.379364
Train loss on 1550 batch: 0.489612
Train loss on 1600 batch: 0.416327
Train loss on 1650 batch: 0.504805
Train loss on 1700 batch: 0.450922
Train loss on 1750 batch: 0.423224
Train loss on 1800 batch: 0.479380
Train loss on 1850 batch: 0.541340
Train loss on 1900 batch: 0.505137
: Epoch: 7 | Training Loss: 0.457114 | Val. Loss: 0.448223 | Val. Kappa Score: 0.6233 | LR: 0.001000 | Estimated time: 510.35
Train loss on 50 batch: 0.417591
Train loss on 100 batch: 0.443219
Train loss on 150 batch: 0.528065
Train loss on 200 batch: 0.491521
Train loss on 250 batch: 0.384135
Train loss on 300 batch: 0.412196
Train loss on 350 batch: 0.377334
Train loss on 400 batch: 0.533934
Train loss on 450 batch: 0.346886
Train loss on 500 batch: 0.476107
Train loss on 550 batch: 0.474363
Train loss on 600 batch: 0.430399
Train loss on 650 batch: 0.470510
Train loss on 700 batch: 0.473649
Train loss on 750 batch: 0.451038
Train loss on 800 batch: 0.493636
Train loss on 850 batch: 0.447729
Train loss on 900 batch: 0.461559
Train loss on 950 batch: 0.435029
Train loss on 1000 batch: 0.430755
Train loss on 1050 batch: 0.454833
Train loss on 1100 batch: 0.390070
Train loss on 1150 batch: 0.539217
Train loss on 1200 batch: 0.469577
Train loss on 1250 batch: 0.432046
Train loss on 1300 batch: 0.455282
Train loss on 1350 batch: 0.436439
Train loss on 1400 batch: 0.442578
Train loss on 1450 batch: 0.426567
Train loss on 1500 batch: 0.468740
Train loss on 1550 batch: 0.419932
Train loss on 1600 batch: 0.499789
Train loss on 1650 batch: 0.480266
Train loss on 1700 batch: 0.420422
Train loss on 1750 batch: 0.467140
Train loss on 1800 batch: 0.415962
Train loss on 1850 batch: 0.455010
Train loss on 1900 batch: 0.356305
: Epoch: 8 | Training Loss: 0.448141 | Val. Loss: 0.445401 | Val. Kappa Score: 0.6261 | LR: 0.000500 | Estimated time: 510.31
Train loss on 50 batch: 0.456993
Train loss on 100 batch: 0.394576
Train loss on 150 batch: 0.396307
Train loss on 200 batch: 0.391499
Train loss on 250 batch: 0.348458
Train loss on 300 batch: 0.410915
Train loss on 350 batch: 0.346236
Train loss on 400 batch: 0.481678
Train loss on 450 batch: 0.368977
Train loss on 500 batch: 0.374829
Train loss on 550 batch: 0.393833
Train loss on 600 batch: 0.430591
Train loss on 650 batch: 0.378771
Train loss on 700 batch: 0.421826
Train loss on 750 batch: 0.349267
Train loss on 800 batch: 0.385889
Train loss on 850 batch: 0.410005
Train loss on 900 batch: 0.402348
Train loss on 950 batch: 0.366350
Train loss on 1000 batch: 0.323272
Train loss on 1050 batch: 0.381740
Train loss on 1100 batch: 0.430274
Train loss on 1150 batch: 0.394287
Train loss on 1200 batch: 0.430979
Train loss on 1250 batch: 0.312388
Train loss on 1300 batch: 0.358579
Train loss on 1350 batch: 0.398647
Train loss on 1400 batch: 0.378579
Train loss on 1450 batch: 0.423542
Train loss on 1500 batch: 0.391511
Train loss on 1550 batch: 0.382151
Train loss on 1600 batch: 0.420490
Train loss on 1650 batch: 0.417138
Train loss on 1700 batch: 0.411861
Train loss on 1750 batch: 0.389469
Train loss on 1800 batch: 0.392029
Train loss on 1850 batch: 0.370780
Train loss on 1900 batch: 0.394306
best-train-loss: 0.393632
best-valid-loss: 0.383111
best-kappa: 0.6343
: Epoch: 9 | Training Loss: 0.393632 | Val. Loss: 0.383111 | Val. Kappa Score: 0.6343 | LR: 0.000500 | Estimated time: 510.13
Train loss on 50 batch: 0.371290
Train loss on 100 batch: 0.352797
Train loss on 150 batch: 0.347535
Train loss on 200 batch: 0.378704
Train loss on 250 batch: 0.370055
Train loss on 300 batch: 0.374727
Train loss on 350 batch: 0.397072
Train loss on 400 batch: 0.415181
Train loss on 450 batch: 0.368500
Train loss on 500 batch: 0.372094
Train loss on 550 batch: 0.353193
Train loss on 600 batch: 0.344494
Train loss on 650 batch: 0.393817
Train loss on 700 batch: 0.419008
Train loss on 750 batch: 0.440050
Train loss on 800 batch: 0.425774
Train loss on 850 batch: 0.338190
Train loss on 900 batch: 0.355102
Train loss on 950 batch: 0.337291
Train loss on 1000 batch: 0.369339
Train loss on 1050 batch: 0.420983
Train loss on 1100 batch: 0.350601
Train loss on 1150 batch: 0.402546
Train loss on 1200 batch: 0.399499
Train loss on 1250 batch: 0.400568
Train loss on 1300 batch: 0.406722
Train loss on 1350 batch: 0.408251
Train loss on 1400 batch: 0.508482
Train loss on 1450 batch: 0.364981
Train loss on 1500 batch: 0.464141
Train loss on 1550 batch: 0.422198
Train loss on 1600 batch: 0.457281
Train loss on 1650 batch: 0.413220
Train loss on 1700 batch: 0.368425
Train loss on 1750 batch: 0.357311
Train loss on 1800 batch: 0.404356
Train loss on 1850 batch: 0.326399
Train loss on 1900 batch: 0.389512
best-train-loss: 0.386712
best-valid-loss: 0.374390
best-kappa: 0.6421
: Epoch: 10 | Training Loss: 0.386712 | Val. Loss: 0.374390 | Val. Kappa Score: 0.6421 | LR: 0.000500 | Estimated time: 509.63
Train loss on 50 batch: 0.388066
Train loss on 100 batch: 0.369834
Train loss on 150 batch: 0.320726
Train loss on 200 batch: 0.391808
Train loss on 250 batch: 0.357789
Train loss on 300 batch: 0.276713
Train loss on 350 batch: 0.420869
Train loss on 400 batch: 0.341654
Train loss on 450 batch: 0.384444
Train loss on 500 batch: 0.408314
Train loss on 550 batch: 0.345890
Train loss on 600 batch: 0.400309
Train loss on 650 batch: 0.339969
Train loss on 700 batch: 0.411857
Train loss on 750 batch: 0.470649
Train loss on 800 batch: 0.458569
Train loss on 850 batch: 0.468545
Train loss on 900 batch: 0.421380
Train loss on 950 batch: 0.323469
Train loss on 1000 batch: 0.329046
Train loss on 1050 batch: 0.402318
Train loss on 1100 batch: 0.346814
Train loss on 1150 batch: 0.396910
Train loss on 1200 batch: 0.356758
Train loss on 1250 batch: 0.384444
Train loss on 1300 batch: 0.341819
Train loss on 1350 batch: 0.364650
Train loss on 1400 batch: 0.371359
Train loss on 1450 batch: 0.381453
Train loss on 1500 batch: 0.346067
Train loss on 1550 batch: 0.400545
Train loss on 1600 batch: 0.371320
Train loss on 1650 batch: 0.370130
Train loss on 1700 batch: 0.380769
Train loss on 1750 batch: 0.375738
Train loss on 1800 batch: 0.406364
Train loss on 1850 batch: 0.321826
Train loss on 1900 batch: 0.391632
: Epoch: 11 | Training Loss: 0.378139 | Val. Loss: 0.378207 | Val. Kappa Score: 0.6484 | LR: 0.000500 | Estimated time: 510.29
Train loss on 50 batch: 0.416472
Train loss on 100 batch: 0.398536
Train loss on 150 batch: 0.412015
Train loss on 200 batch: 0.370910
Train loss on 250 batch: 0.388588
Train loss on 300 batch: 0.399811
Train loss on 350 batch: 0.333942
Train loss on 400 batch: 0.381471
Train loss on 450 batch: 0.302925
Train loss on 500 batch: 0.385179
Train loss on 550 batch: 0.394648
Train loss on 600 batch: 0.373005
Train loss on 650 batch: 0.355615
Train loss on 700 batch: 0.439462
Train loss on 750 batch: 0.366801
Train loss on 800 batch: 0.313602
Train loss on 850 batch: 0.314717
Train loss on 900 batch: 0.374308
Train loss on 950 batch: 0.345419
Train loss on 1000 batch: 0.356175
Train loss on 1050 batch: 0.381211
Train loss on 1100 batch: 0.358376
Train loss on 1150 batch: 0.370970
Train loss on 1200 batch: 0.357489
Train loss on 1250 batch: 0.371583
Train loss on 1300 batch: 0.375807
Train loss on 1350 batch: 0.344630
Train loss on 1400 batch: 0.363723
Train loss on 1450 batch: 0.362259
Train loss on 1500 batch: 0.363410
Train loss on 1550 batch: 0.366669
Train loss on 1600 batch: 0.382565
Train loss on 1650 batch: 0.393541
Train loss on 1700 batch: 0.392317
Train loss on 1750 batch: 0.332666
Train loss on 1800 batch: 0.327092
Train loss on 1850 batch: 0.370192
Train loss on 1900 batch: 0.421238
: Epoch: 12 | Training Loss: 0.369634 | Val. Loss: 0.402790 | Val. Kappa Score: 0.6521 | LR: 0.000500 | Estimated time: 510.25
Train loss on 50 batch: 0.330661
Train loss on 100 batch: 0.370168
Train loss on 150 batch: 0.354722
Train loss on 200 batch: 0.340408
Train loss on 250 batch: 0.352385
Train loss on 300 batch: 0.377726
Train loss on 350 batch: 0.374268
Train loss on 400 batch: 0.397676
Train loss on 450 batch: 0.314589
Train loss on 500 batch: 0.363848
Train loss on 550 batch: 0.338660
Train loss on 600 batch: 0.360886
Train loss on 650 batch: 0.365960
Train loss on 700 batch: 0.371140
Train loss on 750 batch: 0.395715
Train loss on 800 batch: 0.440614
Train loss on 850 batch: 0.338194
Train loss on 900 batch: 0.370928
Train loss on 950 batch: 0.348175
Train loss on 1000 batch: 0.349393
Train loss on 1050 batch: 0.365892
Train loss on 1100 batch: 0.378682
Train loss on 1150 batch: 0.341513
Train loss on 1200 batch: 0.351995
Train loss on 1250 batch: 0.376318
Train loss on 1300 batch: 0.368516
Train loss on 1350 batch: 0.322818
Train loss on 1400 batch: 0.383043
Train loss on 1450 batch: 0.365093
Train loss on 1500 batch: 0.377669
Train loss on 1550 batch: 0.377992
Train loss on 1600 batch: 0.355667
Train loss on 1650 batch: 0.381164
Train loss on 1700 batch: 0.373459
Train loss on 1750 batch: 0.406085
Train loss on 1800 batch: 0.361981
Train loss on 1850 batch: 0.329003
Train loss on 1900 batch: 0.325075
: Epoch: 13 | Training Loss: 0.365416 | Val. Loss: 0.460798 | Val. Kappa Score: 0.6542 | LR: 0.000250 | Estimated time: 510.69
Train loss on 50 batch: 0.359020
Train loss on 100 batch: 0.380452
Train loss on 150 batch: 0.338065
Train loss on 200 batch: 0.330160
Train loss on 250 batch: 0.367430
Train loss on 300 batch: 0.376526
Train loss on 350 batch: 0.298879
Train loss on 400 batch: 0.309836
Train loss on 450 batch: 0.323476
Train loss on 500 batch: 0.299520
Train loss on 550 batch: 0.349690
Train loss on 600 batch: 0.303555
Train loss on 650 batch: 0.387241
Train loss on 700 batch: 0.329627
Train loss on 750 batch: 0.270795
Train loss on 800 batch: 0.327735
Train loss on 850 batch: 0.351307
Train loss on 900 batch: 0.369825
Train loss on 950 batch: 0.315657
Train loss on 1000 batch: 0.338332
Train loss on 1050 batch: 0.354775
Train loss on 1100 batch: 0.323834
Train loss on 1150 batch: 0.259516
Train loss on 1200 batch: 0.299835
Train loss on 1250 batch: 0.382713
Train loss on 1300 batch: 0.381589
Train loss on 1350 batch: 0.343275
Train loss on 1400 batch: 0.381678
Train loss on 1450 batch: 0.354813
Train loss on 1500 batch: 0.316094
Train loss on 1550 batch: 0.317551
Train loss on 1600 batch: 0.289144
Train loss on 1650 batch: 0.408367
Train loss on 1700 batch: 0.353421
Train loss on 1750 batch: 0.290938
Train loss on 1800 batch: 0.396883
Train loss on 1850 batch: 0.330486
Train loss on 1900 batch: 0.391092
best-train-loss: 0.338052
best-valid-loss: 0.354461
best-kappa: 0.6604
: Epoch: 14 | Training Loss: 0.338052 | Val. Loss: 0.354461 | Val. Kappa Score: 0.6604 | LR: 0.000250 | Estimated time: 510.43
Train loss on 50 batch: 0.311265
Train loss on 100 batch: 0.280964
Train loss on 150 batch: 0.292390
Train loss on 200 batch: 0.404186
Train loss on 250 batch: 0.348517
Train loss on 300 batch: 0.297055
Train loss on 350 batch: 0.407697
Train loss on 400 batch: 0.330571
Train loss on 450 batch: 0.353329
Train loss on 500 batch: 0.308714
Train loss on 550 batch: 0.378361
Train loss on 600 batch: 0.313635
Train loss on 650 batch: 0.345927
Train loss on 700 batch: 0.287712
Train loss on 750 batch: 0.323410
Train loss on 800 batch: 0.319581
Train loss on 850 batch: 0.370986
Train loss on 900 batch: 0.376872
Train loss on 950 batch: 0.395301
Train loss on 1000 batch: 0.341855
Train loss on 1050 batch: 0.348085
Train loss on 1100 batch: 0.296338
Train loss on 1150 batch: 0.302983
Train loss on 1200 batch: 0.312269
Train loss on 1250 batch: 0.289950
Train loss on 1300 batch: 0.367593
Train loss on 1350 batch: 0.335080
Train loss on 1400 batch: 0.335858
Train loss on 1450 batch: 0.311317
Train loss on 1500 batch: 0.288872
Train loss on 1550 batch: 0.256213
Train loss on 1600 batch: 0.330091
Train loss on 1650 batch: 0.319597
Train loss on 1700 batch: 0.252593
Train loss on 1750 batch: 0.271047
Train loss on 1800 batch: 0.308776
Train loss on 1850 batch: 0.344110
Train loss on 1900 batch: 0.369484
best-train-loss: 0.326318
best-valid-loss: 0.344701
best-kappa: 0.6650
: Epoch: 15 | Training Loss: 0.326318 | Val. Loss: 0.344701 | Val. Kappa Score: 0.6650 | LR: 0.000250 | Estimated time: 510.10
Train loss on 50 batch: 0.275664
Train loss on 100 batch: 0.296618
Train loss on 150 batch: 0.399807
Train loss on 200 batch: 0.280600
Train loss on 250 batch: 0.345830
Train loss on 300 batch: 0.296825
Train loss on 350 batch: 0.289842
Train loss on 400 batch: 0.302525
Train loss on 450 batch: 0.314311
Train loss on 500 batch: 0.354237
Train loss on 550 batch: 0.317703
Train loss on 600 batch: 0.373695
Train loss on 650 batch: 0.352831
Train loss on 700 batch: 0.274177
Train loss on 750 batch: 0.303713
Train loss on 800 batch: 0.368749
Train loss on 850 batch: 0.358616
Train loss on 900 batch: 0.332575
Train loss on 950 batch: 0.355014
Train loss on 1000 batch: 0.352673
Train loss on 1050 batch: 0.349948
Train loss on 1100 batch: 0.323698
Train loss on 1150 batch: 0.306795
Train loss on 1200 batch: 0.301977
Train loss on 1250 batch: 0.281915
Train loss on 1300 batch: 0.305884
Train loss on 1350 batch: 0.304237
Train loss on 1400 batch: 0.301426
Train loss on 1450 batch: 0.262356
Train loss on 1500 batch: 0.338170
Train loss on 1550 batch: 0.362654
Train loss on 1600 batch: 0.327203
Train loss on 1650 batch: 0.306633
Train loss on 1700 batch: 0.389013
Train loss on 1750 batch: 0.322548
Train loss on 1800 batch: 0.300071
Train loss on 1850 batch: 0.315959
Train loss on 1900 batch: 0.317948
best-train-loss: 0.323606
best-valid-loss: 0.343474
best-kappa: 0.6686
: Epoch: 16 | Training Loss: 0.323606 | Val. Loss: 0.343474 | Val. Kappa Score: 0.6686 | LR: 0.000250 | Estimated time: 510.42
Train loss on 50 batch: 0.297009
Train loss on 100 batch: 0.304850
Train loss on 150 batch: 0.386144
Train loss on 200 batch: 0.351732
Train loss on 250 batch: 0.307230
Train loss on 300 batch: 0.302322
Train loss on 350 batch: 0.353521
Train loss on 400 batch: 0.329382
Train loss on 450 batch: 0.288870
Train loss on 500 batch: 0.291414
Train loss on 550 batch: 0.310261
Train loss on 600 batch: 0.278085
Train loss on 650 batch: 0.290977
Train loss on 700 batch: 0.348854
Train loss on 750 batch: 0.321369
Train loss on 800 batch: 0.305004
Train loss on 850 batch: 0.366768
Train loss on 900 batch: 0.342256
Train loss on 950 batch: 0.325606
Train loss on 1000 batch: 0.351662
Train loss on 1050 batch: 0.339760
Train loss on 1100 batch: 0.323139
Train loss on 1150 batch: 0.293991
Train loss on 1200 batch: 0.297833
Train loss on 1250 batch: 0.275738
Train loss on 1300 batch: 0.303386
Train loss on 1350 batch: 0.298846
Train loss on 1400 batch: 0.308999
Train loss on 1450 batch: 0.389129
Train loss on 1500 batch: 0.298657
Train loss on 1550 batch: 0.338853
Train loss on 1600 batch: 0.316361
Train loss on 1650 batch: 0.325988
Train loss on 1700 batch: 0.329571
Train loss on 1750 batch: 0.345115
Train loss on 1800 batch: 0.296769
Train loss on 1850 batch: 0.332495
Train loss on 1900 batch: 0.276842
: Epoch: 17 | Training Loss: 0.318793 | Val. Loss: 0.344966 | Val. Kappa Score: 0.6725 | LR: 0.000250 | Estimated time: 509.99
Train loss on 50 batch: 0.319124
Train loss on 100 batch: 0.272098
Train loss on 150 batch: 0.309956
Train loss on 200 batch: 0.299465
Train loss on 250 batch: 0.361709
Train loss on 300 batch: 0.326235
Train loss on 350 batch: 0.282663
Train loss on 400 batch: 0.307472
Train loss on 450 batch: 0.336564
Train loss on 500 batch: 0.293171
Train loss on 550 batch: 0.317197
Train loss on 600 batch: 0.335773
Train loss on 650 batch: 0.258712
Train loss on 700 batch: 0.313511
Train loss on 750 batch: 0.305552
Train loss on 800 batch: 0.308779
Train loss on 850 batch: 0.288331
Train loss on 900 batch: 0.339813
Train loss on 950 batch: 0.317922
Train loss on 1000 batch: 0.326796
Train loss on 1050 batch: 0.342406
Train loss on 1100 batch: 0.344121
Train loss on 1150 batch: 0.286620
Train loss on 1200 batch: 0.389015
Train loss on 1250 batch: 0.330944
Train loss on 1300 batch: 0.299354
Train loss on 1350 batch: 0.364952
Train loss on 1400 batch: 0.333954
Train loss on 1450 batch: 0.401981
Train loss on 1500 batch: 0.311464
Train loss on 1550 batch: 0.288570
Train loss on 1600 batch: 0.271847
Train loss on 1650 batch: 0.236523
Train loss on 1700 batch: 0.373605
Train loss on 1750 batch: 0.333771
Train loss on 1800 batch: 0.318352
Train loss on 1850 batch: 0.293075
Train loss on 1900 batch: 0.357972
: Epoch: 18 | Training Loss: 0.319788 | Val. Loss: 0.350049 | Val. Kappa Score: 0.6759 | LR: 0.000250 | Estimated time: 510.28
Train loss on 50 batch: 0.247020
Train loss on 100 batch: 0.306700
Train loss on 150 batch: 0.326008
Train loss on 200 batch: 0.303783
Train loss on 250 batch: 0.369264
Train loss on 300 batch: 0.334774
Train loss on 350 batch: 0.322192
Train loss on 400 batch: 0.276675
Train loss on 450 batch: 0.336706
Train loss on 500 batch: 0.303468
Train loss on 550 batch: 0.261055
Train loss on 600 batch: 0.352619
Train loss on 650 batch: 0.346233
Train loss on 700 batch: 0.277865
Train loss on 750 batch: 0.286511
Train loss on 800 batch: 0.293543
Train loss on 850 batch: 0.346871
Train loss on 900 batch: 0.331141
Train loss on 950 batch: 0.315168
Train loss on 1000 batch: 0.330293
Train loss on 1050 batch: 0.339414
Train loss on 1100 batch: 0.286933
Train loss on 1150 batch: 0.243975
Train loss on 1200 batch: 0.305081
Train loss on 1250 batch: 0.337197
Train loss on 1300 batch: 0.318416
Train loss on 1350 batch: 0.351400
Train loss on 1400 batch: 0.315658
Train loss on 1450 batch: 0.265959
Train loss on 1500 batch: 0.260942
Train loss on 1550 batch: 0.304227
Train loss on 1600 batch: 0.297803
Train loss on 1650 batch: 0.308865
Train loss on 1700 batch: 0.316995
Train loss on 1750 batch: 0.278594
Train loss on 1800 batch: 0.392574
Train loss on 1850 batch: 0.277940
Train loss on 1900 batch: 0.346894
: Epoch: 19 | Training Loss: 0.311751 | Val. Loss: 0.350494 | Val. Kappa Score: 0.6789 | LR: 0.000125 | Estimated time: 510.44
Train loss on 50 batch: 0.248554
Train loss on 100 batch: 0.371551
Train loss on 150 batch: 0.273732
Train loss on 200 batch: 0.305332
Train loss on 250 batch: 0.289983
Train loss on 300 batch: 0.275270
Train loss on 350 batch: 0.261731
Train loss on 400 batch: 0.319198
Train loss on 450 batch: 0.319445
Train loss on 500 batch: 0.292527
Train loss on 550 batch: 0.315275
Train loss on 600 batch: 0.263663
Train loss on 650 batch: 0.352285
Train loss on 700 batch: 0.329981
Train loss on 750 batch: 0.310803
Train loss on 800 batch: 0.286967
Train loss on 850 batch: 0.344362
Train loss on 900 batch: 0.278753
Train loss on 950 batch: 0.249783
Train loss on 1000 batch: 0.256137
Train loss on 1050 batch: 0.341676
Train loss on 1100 batch: 0.302342
Train loss on 1150 batch: 0.283542
Train loss on 1200 batch: 0.293523
Train loss on 1250 batch: 0.242301
Train loss on 1300 batch: 0.297500
Train loss on 1350 batch: 0.239056
Train loss on 1400 batch: 0.304278
Train loss on 1450 batch: 0.251966
Train loss on 1500 batch: 0.297529
Train loss on 1550 batch: 0.300481
Train loss on 1600 batch: 0.323486
Train loss on 1650 batch: 0.291266
Train loss on 1700 batch: 0.301781
Train loss on 1750 batch: 0.302725
Train loss on 1800 batch: 0.324011
Train loss on 1850 batch: 0.269746
Train loss on 1900 batch: 0.336876
best-train-loss: 0.296296
best-valid-loss: 0.336412
best-kappa: 0.6816
: Epoch: 20 | Training Loss: 0.296296 | Val. Loss: 0.336412 | Val. Kappa Score: 0.6816 | LR: 0.000125 | Estimated time: 510.03
Train loss on 50 batch: 0.284597
Train loss on 100 batch: 0.269013
Train loss on 150 batch: 0.310849
Train loss on 200 batch: 0.333430
Train loss on 250 batch: 0.239339
Train loss on 300 batch: 0.286768
Train loss on 350 batch: 0.293225
Train loss on 400 batch: 0.350690
Train loss on 450 batch: 0.276117
Train loss on 500 batch: 0.273341
Train loss on 550 batch: 0.296200
Train loss on 600 batch: 0.330969
Train loss on 650 batch: 0.260303
Train loss on 700 batch: 0.291897
Train loss on 750 batch: 0.284249
Train loss on 800 batch: 0.256858
Train loss on 850 batch: 0.287221
Train loss on 900 batch: 0.378130
Train loss on 950 batch: 0.279415
Train loss on 1000 batch: 0.279385
Train loss on 1050 batch: 0.268551
Train loss on 1100 batch: 0.315370
Train loss on 1150 batch: 0.260059
Train loss on 1200 batch: 0.316213
Train loss on 1250 batch: 0.300932
Train loss on 1300 batch: 0.270728
Train loss on 1350 batch: 0.324894
Train loss on 1400 batch: 0.275548
Train loss on 1450 batch: 0.329974
Train loss on 1500 batch: 0.260575
Train loss on 1550 batch: 0.292077
Train loss on 1600 batch: 0.301982
Train loss on 1650 batch: 0.237358
Train loss on 1700 batch: 0.388483
Train loss on 1750 batch: 0.317829
Train loss on 1800 batch: 0.244716
Train loss on 1850 batch: 0.291473
Train loss on 1900 batch: 0.284208
: Epoch: 21 | Training Loss: 0.294412 | Val. Loss: 0.345658 | Val. Kappa Score: 0.6840 | LR: 0.000125 | Estimated time: 509.79
Train loss on 50 batch: 0.262990
Train loss on 100 batch: 0.315847
Train loss on 150 batch: 0.322004
Train loss on 200 batch: 0.285495
Train loss on 250 batch: 0.273449
Train loss on 300 batch: 0.267865
Train loss on 350 batch: 0.259652
Train loss on 400 batch: 0.284535
Train loss on 450 batch: 0.321830
Train loss on 500 batch: 0.290955
Train loss on 550 batch: 0.254508
Train loss on 600 batch: 0.294882
Train loss on 650 batch: 0.297485
Train loss on 700 batch: 0.331849
Train loss on 750 batch: 0.311586
Train loss on 800 batch: 0.259219
Train loss on 850 batch: 0.322237
Train loss on 900 batch: 0.291880
Train loss on 950 batch: 0.239115
Train loss on 1000 batch: 0.301636
Train loss on 1050 batch: 0.296347
Train loss on 1100 batch: 0.274471
Train loss on 1150 batch: 0.321835
Train loss on 1200 batch: 0.353008
Train loss on 1250 batch: 0.237651
Train loss on 1300 batch: 0.271064
Train loss on 1350 batch: 0.277209
Train loss on 1400 batch: 0.314140
Train loss on 1450 batch: 0.307187
Train loss on 1500 batch: 0.312555
Train loss on 1550 batch: 0.289115
Train loss on 1600 batch: 0.275707
Train loss on 1650 batch: 0.255557
Train loss on 1700 batch: 0.273692
Train loss on 1750 batch: 0.262656
Train loss on 1800 batch: 0.319862
Train loss on 1850 batch: 0.291410
Train loss on 1900 batch: 0.277419
: Epoch: 22 | Training Loss: 0.289860 | Val. Loss: 0.336769 | Val. Kappa Score: 0.6870 | LR: 0.000125 | Estimated time: 509.72
Train loss on 50 batch: 0.259106
Train loss on 100 batch: 0.265777
Train loss on 150 batch: 0.283160
Train loss on 200 batch: 0.290671
Train loss on 250 batch: 0.275688
Train loss on 300 batch: 0.291840
Train loss on 350 batch: 0.295491
Train loss on 400 batch: 0.285429
Train loss on 450 batch: 0.295027
Train loss on 500 batch: 0.241465
Train loss on 550 batch: 0.303777
Train loss on 600 batch: 0.314576
Train loss on 650 batch: 0.271551
Train loss on 700 batch: 0.296294
Train loss on 750 batch: 0.263938
Train loss on 800 batch: 0.311751
Train loss on 850 batch: 0.339116
Train loss on 900 batch: 0.284435
Train loss on 950 batch: 0.273180
Train loss on 1000 batch: 0.297020
Train loss on 1050 batch: 0.320508
Train loss on 1100 batch: 0.358179
Train loss on 1150 batch: 0.362727
Train loss on 1200 batch: 0.260602
Train loss on 1250 batch: 0.329027
Train loss on 1300 batch: 0.291557
Train loss on 1350 batch: 0.298658
Train loss on 1400 batch: 0.314946
Train loss on 1450 batch: 0.260259
Train loss on 1500 batch: 0.256106
Train loss on 1550 batch: 0.302695
Train loss on 1600 batch: 0.243394
Train loss on 1650 batch: 0.294016
Train loss on 1700 batch: 0.304922
Train loss on 1750 batch: 0.276797
Train loss on 1800 batch: 0.310313
Train loss on 1850 batch: 0.279208
Train loss on 1900 batch: 0.279539
best-train-loss: 0.292195
best-valid-loss: 0.332179
best-kappa: 0.6893
: Epoch: 23 | Training Loss: 0.292195 | Val. Loss: 0.332179 | Val. Kappa Score: 0.6893 | LR: 0.000125 | Estimated time: 509.86
Train loss on 50 batch: 0.278334
Train loss on 100 batch: 0.253328
Train loss on 150 batch: 0.272938
Train loss on 200 batch: 0.323061
Train loss on 250 batch: 0.219353
Train loss on 300 batch: 0.234385
Train loss on 350 batch: 0.304850
Train loss on 400 batch: 0.262641
Train loss on 450 batch: 0.246500
Train loss on 500 batch: 0.287727
Train loss on 550 batch: 0.279700
Train loss on 600 batch: 0.273068
Train loss on 650 batch: 0.302319
Train loss on 700 batch: 0.267163
Train loss on 750 batch: 0.265889
Train loss on 800 batch: 0.322224
Train loss on 850 batch: 0.291426
Train loss on 900 batch: 0.311599
Train loss on 950 batch: 0.276009
Train loss on 1000 batch: 0.244972
Train loss on 1050 batch: 0.293994
Train loss on 1100 batch: 0.297701
Train loss on 1150 batch: 0.335981
Train loss on 1200 batch: 0.282313
Train loss on 1250 batch: 0.301242
Train loss on 1300 batch: 0.349948
Train loss on 1350 batch: 0.260657
Train loss on 1400 batch: 0.249731
Train loss on 1450 batch: 0.283994
Train loss on 1500 batch: 0.317675
Train loss on 1550 batch: 0.330712
Train loss on 1600 batch: 0.339302
Train loss on 1650 batch: 0.266847
Train loss on 1700 batch: 0.339629
Train loss on 1750 batch: 0.280230
Train loss on 1800 batch: 0.315915
Train loss on 1850 batch: 0.258814
Train loss on 1900 batch: 0.277224
: Epoch: 24 | Training Loss: 0.287532 | Val. Loss: 0.335320 | Val. Kappa Score: 0.6910 | LR: 0.000125 | Estimated time: 510.27
Train loss on 50 batch: 0.280225
Train loss on 100 batch: 0.301586
Train loss on 150 batch: 0.296683
Train loss on 200 batch: 0.266831
Train loss on 250 batch: 0.322323
Train loss on 300 batch: 0.242535
Train loss on 350 batch: 0.280939
Train loss on 400 batch: 0.263721
Train loss on 450 batch: 0.278423
Train loss on 500 batch: 0.282007
Train loss on 550 batch: 0.277267
Train loss on 600 batch: 0.268644
Train loss on 650 batch: 0.317238
Train loss on 700 batch: 0.273186
Train loss on 750 batch: 0.263189
Train loss on 800 batch: 0.297643
Train loss on 850 batch: 0.250888
Train loss on 900 batch: 0.251309
Train loss on 950 batch: 0.282505
Train loss on 1000 batch: 0.289576
Train loss on 1050 batch: 0.339841
Train loss on 1100 batch: 0.283911
Train loss on 1150 batch: 0.261824
Train loss on 1200 batch: 0.261315
Train loss on 1250 batch: 0.294734
Train loss on 1300 batch: 0.259528
Train loss on 1350 batch: 0.296046
Train loss on 1400 batch: 0.281976
Train loss on 1450 batch: 0.285084
Train loss on 1500 batch: 0.323754
Train loss on 1550 batch: 0.272215
Train loss on 1600 batch: 0.277885
Train loss on 1650 batch: 0.285171
Train loss on 1700 batch: 0.349170
Train loss on 1750 batch: 0.257032
Train loss on 1800 batch: 0.291440
Train loss on 1850 batch: 0.317469
Train loss on 1900 batch: 0.325805
: Epoch: 25 | Training Loss: 0.285574 | Val. Loss: 0.336543 | Val. Kappa Score: 0.6931 | LR: 0.000125 | Estimated time: 509.89
Train loss on 50 batch: 0.250331
Train loss on 100 batch: 0.273464
Train loss on 150 batch: 0.259921
Train loss on 200 batch: 0.260999
Train loss on 250 batch: 0.279340
Train loss on 300 batch: 0.290536
Train loss on 350 batch: 0.273219
Train loss on 400 batch: 0.274082
Train loss on 450 batch: 0.282197
Train loss on 500 batch: 0.324449
Train loss on 550 batch: 0.271501
Train loss on 600 batch: 0.256238
Train loss on 650 batch: 0.298133
Train loss on 700 batch: 0.300922
Train loss on 750 batch: 0.247937
Train loss on 800 batch: 0.304472
Train loss on 850 batch: 0.318577
Train loss on 900 batch: 0.301037
Train loss on 950 batch: 0.298042
Train loss on 1000 batch: 0.252097
Train loss on 1050 batch: 0.271729
Train loss on 1100 batch: 0.299097
Train loss on 1150 batch: 0.295488
Train loss on 1200 batch: 0.312396
Train loss on 1250 batch: 0.254085
Train loss on 1300 batch: 0.225797
Train loss on 1350 batch: 0.278913
Train loss on 1400 batch: 0.289660
Train loss on 1450 batch: 0.276174
Train loss on 1500 batch: 0.323300
Train loss on 1550 batch: 0.267130
Train loss on 1600 batch: 0.273535
Train loss on 1650 batch: 0.338991
Train loss on 1700 batch: 0.290292
Train loss on 1750 batch: 0.321790
Train loss on 1800 batch: 0.274693
Train loss on 1850 batch: 0.275008
Train loss on 1900 batch: 0.282369
best-train-loss: 0.282988
best-valid-loss: 0.330960
best-kappa: 0.6950
: Epoch: 26 | Training Loss: 0.282988 | Val. Loss: 0.330960 | Val. Kappa Score: 0.6950 | LR: 0.000125 | Estimated time: 512.32
Train loss on 50 batch: 0.275616
Train loss on 100 batch: 0.243588
Train loss on 150 batch: 0.316174
Train loss on 200 batch: 0.294797
Train loss on 250 batch: 0.245671
Train loss on 300 batch: 0.300268
Train loss on 350 batch: 0.267911
Train loss on 400 batch: 0.263283
Train loss on 450 batch: 0.252249
Train loss on 500 batch: 0.275015
Train loss on 550 batch: 0.291970
Train loss on 600 batch: 0.280092
Train loss on 650 batch: 0.290609
Train loss on 700 batch: 0.339133
Train loss on 750 batch: 0.265971
Train loss on 800 batch: 0.297177
Train loss on 850 batch: 0.259255
Train loss on 900 batch: 0.279495
Train loss on 950 batch: 0.293132
Train loss on 1000 batch: 0.256215
Train loss on 1050 batch: 0.311737
Train loss on 1100 batch: 0.278834
Train loss on 1150 batch: 0.294527
Train loss on 1200 batch: 0.269766
Train loss on 1250 batch: 0.340254
Train loss on 1300 batch: 0.319551
Train loss on 1350 batch: 0.250183
Train loss on 1400 batch: 0.234020
Train loss on 1450 batch: 0.304989
Train loss on 1500 batch: 0.273787
Train loss on 1550 batch: 0.236268
Train loss on 1600 batch: 0.272920
Train loss on 1650 batch: 0.248614
Train loss on 1700 batch: 0.258116
Train loss on 1750 batch: 0.259605
Train loss on 1800 batch: 0.252449
Train loss on 1850 batch: 0.287594
Train loss on 1900 batch: 0.236164
: Epoch: 27 | Training Loss: 0.276185 | Val. Loss: 0.354480 | Val. Kappa Score: 0.6963 | LR: 0.000125 | Estimated time: 512.58
Train loss on 50 batch: 0.297913
Train loss on 100 batch: 0.266354
Train loss on 150 batch: 0.288088
Train loss on 200 batch: 0.238455
Train loss on 250 batch: 0.275871
Train loss on 300 batch: 0.290227
Train loss on 350 batch: 0.323415
Train loss on 400 batch: 0.235943
Train loss on 450 batch: 0.263049
Train loss on 500 batch: 0.303115
Train loss on 550 batch: 0.259034
Train loss on 600 batch: 0.296232
Train loss on 650 batch: 0.276436
Train loss on 700 batch: 0.296357
Train loss on 750 batch: 0.266420
Train loss on 800 batch: 0.259346
Train loss on 850 batch: 0.284106
Train loss on 900 batch: 0.268770
Train loss on 950 batch: 0.298873
Train loss on 1000 batch: 0.269981
Train loss on 1050 batch: 0.279498
Train loss on 1100 batch: 0.266693
Train loss on 1150 batch: 0.239665
Train loss on 1200 batch: 0.303324
Train loss on 1250 batch: 0.285002
Train loss on 1300 batch: 0.246321
Train loss on 1350 batch: 0.250754
Train loss on 1400 batch: 0.301322
Train loss on 1450 batch: 0.280968
Train loss on 1500 batch: 0.284260
Train loss on 1550 batch: 0.287085
Train loss on 1600 batch: 0.323305
Train loss on 1650 batch: 0.253799
Train loss on 1700 batch: 0.281934
Train loss on 1750 batch: 0.298765
Train loss on 1800 batch: 0.264878
Train loss on 1850 batch: 0.270692
Train loss on 1900 batch: 0.253130
: Epoch: 28 | Training Loss: 0.277164 | Val. Loss: 0.336369 | Val. Kappa Score: 0.6980 | LR: 0.000125 | Estimated time: 510.69
Train loss on 50 batch: 0.281969
Train loss on 100 batch: 0.272684
Train loss on 150 batch: 0.306220
Train loss on 200 batch: 0.241242
Train loss on 250 batch: 0.279628
Train loss on 300 batch: 0.285048
Train loss on 350 batch: 0.277760
Train loss on 400 batch: 0.294902
Train loss on 450 batch: 0.290718
Train loss on 500 batch: 0.243891
Train loss on 550 batch: 0.247107
Train loss on 600 batch: 0.262185
Train loss on 650 batch: 0.227346
Train loss on 700 batch: 0.297942
Train loss on 750 batch: 0.279009
Train loss on 800 batch: 0.334159
Train loss on 850 batch: 0.288320
Train loss on 900 batch: 0.287262
Train loss on 950 batch: 0.292862
Train loss on 1000 batch: 0.257014
Train loss on 1050 batch: 0.258744
Train loss on 1100 batch: 0.308877
Train loss on 1150 batch: 0.247763
Train loss on 1200 batch: 0.351871
Train loss on 1250 batch: 0.280215
Train loss on 1300 batch: 0.290780
Train loss on 1350 batch: 0.280732
Train loss on 1400 batch: 0.311775
Train loss on 1450 batch: 0.298723
Train loss on 1500 batch: 0.271010
Train loss on 1550 batch: 0.265953
Train loss on 1600 batch: 0.279055
Train loss on 1650 batch: 0.256739
Train loss on 1700 batch: 0.256697
Train loss on 1750 batch: 0.314406
Train loss on 1800 batch: 0.256126
Train loss on 1850 batch: 0.247104
Train loss on 1900 batch: 0.276747
: Epoch: 29 | Training Loss: 0.278774 | Val. Loss: 0.348833 | Val. Kappa Score: 0.6999 | LR: 0.000063 | Estimated time: 510.65
Train loss on 50 batch: 0.305462
Train loss on 100 batch: 0.250188
Train loss on 150 batch: 0.255496
Train loss on 200 batch: 0.273818
Train loss on 250 batch: 0.288892
Train loss on 300 batch: 0.297253
Train loss on 350 batch: 0.293554
Train loss on 400 batch: 0.276918
Train loss on 450 batch: 0.317863
Train loss on 500 batch: 0.269998
Train loss on 550 batch: 0.320081
Train loss on 600 batch: 0.280331
Train loss on 650 batch: 0.287465
Train loss on 700 batch: 0.288346
Train loss on 750 batch: 0.276596
Train loss on 800 batch: 0.239093
Train loss on 850 batch: 0.242448
Train loss on 900 batch: 0.278686
Train loss on 950 batch: 0.218696
Train loss on 1000 batch: 0.319499
Train loss on 1050 batch: 0.256768
Train loss on 1100 batch: 0.277341
Train loss on 1150 batch: 0.293789
Train loss on 1200 batch: 0.286367
Train loss on 1250 batch: 0.259078
Train loss on 1300 batch: 0.244193
Train loss on 1350 batch: 0.244065
Train loss on 1400 batch: 0.268629
Train loss on 1450 batch: 0.299273
Train loss on 1500 batch: 0.243552
Train loss on 1550 batch: 0.198017
Train loss on 1600 batch: 0.292040
Train loss on 1650 batch: 0.272900
Train loss on 1700 batch: 0.294202
Train loss on 1750 batch: 0.226477
Train loss on 1800 batch: 0.225528
Train loss on 1850 batch: 0.270555
Train loss on 1900 batch: 0.248055
: Epoch: 30 | Training Loss: 0.271181 | Val. Loss: 0.335218 | Val. Kappa Score: 0.7014 | LR: 0.000063 | Estimated time: 510.29
Train loss on 50 batch: 0.311611
Train loss on 100 batch: 0.298667
Train loss on 150 batch: 0.281003
Train loss on 200 batch: 0.233960
Train loss on 250 batch: 0.226591
Train loss on 300 batch: 0.269078
Train loss on 350 batch: 0.279407
Train loss on 400 batch: 0.236846
Train loss on 450 batch: 0.243711
Train loss on 500 batch: 0.292979
Train loss on 550 batch: 0.252042
Train loss on 600 batch: 0.271562
Train loss on 650 batch: 0.253483
Train loss on 700 batch: 0.274902
Train loss on 750 batch: 0.261217
Train loss on 800 batch: 0.277522
Train loss on 850 batch: 0.259313
Train loss on 900 batch: 0.230745
Train loss on 950 batch: 0.236131
Train loss on 1000 batch: 0.296421
Train loss on 1050 batch: 0.282875
Train loss on 1100 batch: 0.306370
Train loss on 1150 batch: 0.231551
Train loss on 1200 batch: 0.293795
Train loss on 1250 batch: 0.210193
Train loss on 1300 batch: 0.280281
Train loss on 1350 batch: 0.264798
Train loss on 1400 batch: 0.304860
Train loss on 1450 batch: 0.247897
Train loss on 1500 batch: 0.281355
Train loss on 1550 batch: 0.273484
Train loss on 1600 batch: 0.243378
Train loss on 1650 batch: 0.246319
Train loss on 1700 batch: 0.235203
Train loss on 1750 batch: 0.262918
Train loss on 1800 batch: 0.228667
Train loss on 1850 batch: 0.251483
Train loss on 1900 batch: 0.283256
: Epoch: 31 | Training Loss: 0.263879 | Val. Loss: 0.338142 | Val. Kappa Score: 0.7025 | LR: 0.000063 | Estimated time: 510.42
Train loss on 50 batch: 0.248829
Train loss on 100 batch: 0.299430
Train loss on 150 batch: 0.281557
Train loss on 200 batch: 0.247144
Train loss on 250 batch: 0.286715
Train loss on 300 batch: 0.235245
Train loss on 350 batch: 0.249606
Train loss on 400 batch: 0.283604
Train loss on 450 batch: 0.255306
Train loss on 500 batch: 0.287782
Train loss on 550 batch: 0.257863
Train loss on 600 batch: 0.309239
Train loss on 650 batch: 0.294922
Train loss on 700 batch: 0.285595
Train loss on 750 batch: 0.255818
Train loss on 800 batch: 0.268176
Train loss on 850 batch: 0.290316
Train loss on 900 batch: 0.251366
Train loss on 950 batch: 0.293061
Train loss on 1000 batch: 0.272785
Train loss on 1050 batch: 0.309572
Train loss on 1100 batch: 0.264454
Train loss on 1150 batch: 0.228620
Train loss on 1200 batch: 0.240410
Train loss on 1250 batch: 0.313782
Train loss on 1300 batch: 0.231120
Train loss on 1350 batch: 0.268392
Train loss on 1400 batch: 0.283399
Train loss on 1450 batch: 0.244988
Train loss on 1500 batch: 0.231454
Train loss on 1550 batch: 0.267629
Train loss on 1600 batch: 0.263022
Train loss on 1650 batch: 0.250039
Train loss on 1700 batch: 0.275529
Train loss on 1750 batch: 0.235146
Train loss on 1800 batch: 0.230384
Train loss on 1850 batch: 0.263810
Train loss on 1900 batch: 0.244095
: Epoch: 32 | Training Loss: 0.264247 | Val. Loss: 0.337981 | Val. Kappa Score: 0.7033 | LR: 0.000031 | Estimated time: 510.47
Train loss on 50 batch: 0.230607
Train loss on 100 batch: 0.300335
Train loss on 150 batch: 0.250966
Train loss on 200 batch: 0.269739
Train loss on 250 batch: 0.250282
Train loss on 300 batch: 0.235908
Train loss on 350 batch: 0.282173
Train loss on 400 batch: 0.234498
Train loss on 450 batch: 0.250323
Train loss on 500 batch: 0.226371
Train loss on 550 batch: 0.222425
Train loss on 600 batch: 0.274340
Train loss on 650 batch: 0.267528
Train loss on 700 batch: 0.266942
Train loss on 750 batch: 0.244382
Train loss on 800 batch: 0.246386
Train loss on 850 batch: 0.299858
Train loss on 900 batch: 0.321206
Train loss on 950 batch: 0.236034
Train loss on 1000 batch: 0.242556
Train loss on 1050 batch: 0.243039
Train loss on 1100 batch: 0.233426
Train loss on 1150 batch: 0.267645
Train loss on 1200 batch: 0.205582
Train loss on 1250 batch: 0.240558
Train loss on 1300 batch: 0.260005
Train loss on 1350 batch: 0.236512
Train loss on 1400 batch: 0.265917
Train loss on 1450 batch: 0.331340
Train loss on 1500 batch: 0.291687
Train loss on 1550 batch: 0.291386
Train loss on 1600 batch: 0.280694
Train loss on 1650 batch: 0.292105
Train loss on 1700 batch: 0.231803
Train loss on 1750 batch: 0.285831
Train loss on 1800 batch: 0.226643
Train loss on 1850 batch: 0.245906
Train loss on 1900 batch: 0.256892
: Epoch: 33 | Training Loss: 0.258079 | Val. Loss: 0.335024 | Val. Kappa Score: 0.7045 | LR: 0.000031 | Estimated time: 509.82
Train loss on 50 batch: 0.249290
Train loss on 100 batch: 0.278055
Train loss on 150 batch: 0.277071
Train loss on 200 batch: 0.261126
Train loss on 250 batch: 0.194594
Train loss on 300 batch: 0.252739
Train loss on 350 batch: 0.241694
Train loss on 400 batch: 0.279175
Train loss on 450 batch: 0.245329
Train loss on 500 batch: 0.240263
Train loss on 550 batch: 0.265156
Train loss on 600 batch: 0.291079
Train loss on 650 batch: 0.280424
Train loss on 700 batch: 0.267694
Train loss on 750 batch: 0.257835
Train loss on 800 batch: 0.275691
Train loss on 850 batch: 0.237308
Train loss on 900 batch: 0.316249
Train loss on 950 batch: 0.292826
Train loss on 1000 batch: 0.318942
Train loss on 1050 batch: 0.247870
Train loss on 1100 batch: 0.307328
Train loss on 1150 batch: 0.254422
Train loss on 1200 batch: 0.270225
Train loss on 1250 batch: 0.299882
Train loss on 1300 batch: 0.242868
Train loss on 1350 batch: 0.241362
Train loss on 1400 batch: 0.260322
Train loss on 1450 batch: 0.246660
Train loss on 1500 batch: 0.244191
Train loss on 1550 batch: 0.290358
Train loss on 1600 batch: 0.191190
Train loss on 1650 batch: 0.214363
Train loss on 1700 batch: 0.238802
Train loss on 1750 batch: 0.234410
Train loss on 1800 batch: 0.240901
Train loss on 1850 batch: 0.204870
Train loss on 1900 batch: 0.247001
: Epoch: 34 | Training Loss: 0.258363 | Val. Loss: 0.337828 | Val. Kappa Score: 0.7058 | LR: 0.000031 | Estimated time: 510.28
time_estimated: 17463.04
n-epochs: 34
time_estimated: 17463.05
----------------------------------------

Experiment N: 69: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.13 20:44:06
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1066d8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.040166
Train loss on 100 batch: 0.813156
Train loss on 150 batch: 0.874292
Train loss on 200 batch: 0.718394
Train loss on 250 batch: 0.702066
Train loss on 300 batch: 0.720056
Train loss on 350 batch: 0.784180
Train loss on 400 batch: 0.802801
Train loss on 450 batch: 0.796892
Train loss on 500 batch: 0.660866
Train loss on 550 batch: 0.633946
Train loss on 600 batch: 0.672569
Train loss on 650 batch: 0.752248
Train loss on 700 batch: 0.699480
Train loss on 750 batch: 0.685834
Train loss on 800 batch: 0.674031
Train loss on 850 batch: 0.710888
Train loss on 900 batch: 0.606301
Train loss on 950 batch: 0.557342
Train loss on 1000 batch: 0.655720
Train loss on 1050 batch: 0.625324
Train loss on 1100 batch: 0.636277
Train loss on 1150 batch: 0.620357
Train loss on 1200 batch: 0.666292
Train loss on 1250 batch: 0.578298
Train loss on 1300 batch: 0.584593
Train loss on 1350 batch: 0.616091
Train loss on 1400 batch: 0.609819
Train loss on 1450 batch: 0.708661
Train loss on 1500 batch: 0.615388
Train loss on 1550 batch: 0.596077
Train loss on 1600 batch: 0.617242
Train loss on 1650 batch: 0.700486
Train loss on 1700 batch: 0.622738
Train loss on 1750 batch: 0.660600
Train loss on 1800 batch: 0.578881
Train loss on 1850 batch: 0.677581
Train loss on 1900 batch: 0.642796
best-train-loss: 0.681557
best-valid-loss: 0.560524
best-kappa: 0.5550
: Epoch: 1 | Training Loss: 0.681557 | Val. Loss: 0.560524 | Val. Kappa Score: 0.5550 | LR: 0.001000 | Estimated time: 512.04
Train loss on 50 batch: 0.537624
Train loss on 100 batch: 0.625167
Train loss on 150 batch: 0.635404
Train loss on 200 batch: 0.603846
Train loss on 250 batch: 0.563699
Train loss on 300 batch: 0.573028
Train loss on 350 batch: 0.624155
Train loss on 400 batch: 0.584453
Train loss on 450 batch: 0.555891
Train loss on 500 batch: 0.575236
Train loss on 550 batch: 0.582499
Train loss on 600 batch: 0.541743
Train loss on 650 batch: 0.525568
Train loss on 700 batch: 0.599005
Train loss on 750 batch: 0.578857
Train loss on 800 batch: 0.548060
Train loss on 850 batch: 0.559132
Train loss on 900 batch: 0.663950
Train loss on 950 batch: 0.621235
Train loss on 1000 batch: 0.536492
Train loss on 1050 batch: 0.543772
Train loss on 1100 batch: 0.634975
Train loss on 1150 batch: 0.473634
Train loss on 1200 batch: 0.503968
Train loss on 1250 batch: 0.594228
Train loss on 1300 batch: 0.612543
Train loss on 1350 batch: 0.585463
Train loss on 1400 batch: 0.486757
Train loss on 1450 batch: 0.582269
Train loss on 1500 batch: 0.649024
Train loss on 1550 batch: 0.611888
Train loss on 1600 batch: 0.540291
Train loss on 1650 batch: 0.530981
Train loss on 1700 batch: 0.643657
Train loss on 1750 batch: 0.565261
Train loss on 1800 batch: 0.545367
Train loss on 1850 batch: 0.490229
Train loss on 1900 batch: 0.505664
best-train-loss: 0.570318
best-valid-loss: 0.489917
best-kappa: 0.5848
: Epoch: 2 | Training Loss: 0.570318 | Val. Loss: 0.489917 | Val. Kappa Score: 0.5848 | LR: 0.001000 | Estimated time: 510.43
Train loss on 50 batch: 0.589511
Train loss on 100 batch: 0.579935
Train loss on 150 batch: 0.522349
Train loss on 200 batch: 0.585180
Train loss on 250 batch: 0.529704
Train loss on 300 batch: 0.477456
Train loss on 350 batch: 0.503675
Train loss on 400 batch: 0.554738
Train loss on 450 batch: 0.549812
Train loss on 500 batch: 0.582942
Train loss on 550 batch: 0.483895
Train loss on 600 batch: 0.582236
Train loss on 650 batch: 0.571710
Train loss on 700 batch: 0.537273
Train loss on 750 batch: 0.542301
Train loss on 800 batch: 0.541147
Train loss on 850 batch: 0.551371
Train loss on 900 batch: 0.511622
Train loss on 950 batch: 0.539018
Train loss on 1000 batch: 0.489251
Train loss on 1050 batch: 0.477255
Train loss on 1100 batch: 0.527455
Train loss on 1150 batch: 0.520264
Train loss on 1200 batch: 0.576014
Train loss on 1250 batch: 0.506630
Train loss on 1300 batch: 0.470441
Train loss on 1350 batch: 0.558710
Train loss on 1400 batch: 0.539993
Train loss on 1450 batch: 0.553655
Train loss on 1500 batch: 0.532689
Train loss on 1550 batch: 0.509064
Train loss on 1600 batch: 0.524461
Train loss on 1650 batch: 0.472432
Train loss on 1700 batch: 0.488295
Train loss on 1750 batch: 0.490791
Train loss on 1800 batch: 0.598575
Train loss on 1850 batch: 0.488003
Train loss on 1900 batch: 0.499642
: Epoch: 3 | Training Loss: 0.531796 | Val. Loss: 0.493074 | Val. Kappa Score: 0.5890 | LR: 0.001000 | Estimated time: 510.54
Train loss on 50 batch: 0.528037
Train loss on 100 batch: 0.505227
Train loss on 150 batch: 0.507561
Train loss on 200 batch: 0.533303
Train loss on 250 batch: 0.508783
Train loss on 300 batch: 0.490399
Train loss on 350 batch: 0.604720
Train loss on 400 batch: 0.522782
Train loss on 450 batch: 0.450114
Train loss on 500 batch: 0.524065
Train loss on 550 batch: 0.495160
Train loss on 600 batch: 0.511319
Train loss on 650 batch: 0.448447
Train loss on 700 batch: 0.554133
Train loss on 750 batch: 0.465400
Train loss on 800 batch: 0.559396
Train loss on 850 batch: 0.481042
Train loss on 900 batch: 0.525303
Train loss on 950 batch: 0.533754
Train loss on 1000 batch: 0.417995
Train loss on 1050 batch: 0.534003
Train loss on 1100 batch: 0.524280
Train loss on 1150 batch: 0.496210
Train loss on 1200 batch: 0.510977
Train loss on 1250 batch: 0.454230
Train loss on 1300 batch: 0.500915
Train loss on 1350 batch: 0.492739
Train loss on 1400 batch: 0.519598
Train loss on 1450 batch: 0.518993
Train loss on 1500 batch: 0.424101
Train loss on 1550 batch: 0.493149
Train loss on 1600 batch: 0.588169
Train loss on 1650 batch: 0.561431
Train loss on 1700 batch: 0.559551
Train loss on 1750 batch: 0.494039
Train loss on 1800 batch: 0.445629
Train loss on 1850 batch: 0.485985
Train loss on 1900 batch: 0.556582
best-train-loss: 0.507855
best-valid-loss: 0.453185
best-kappa: 0.6086
: Epoch: 4 | Training Loss: 0.507855 | Val. Loss: 0.453185 | Val. Kappa Score: 0.6086 | LR: 0.001000 | Estimated time: 510.48
Train loss on 50 batch: 0.446947
Train loss on 100 batch: 0.519778
Train loss on 150 batch: 0.449205
Train loss on 200 batch: 0.522591
Train loss on 250 batch: 0.461754
Train loss on 300 batch: 0.486037
Train loss on 350 batch: 0.559762
Train loss on 400 batch: 0.461465
Train loss on 450 batch: 0.497047
Train loss on 500 batch: 0.536953
Train loss on 550 batch: 0.509234
Train loss on 600 batch: 0.465961
Train loss on 650 batch: 0.440222
Train loss on 700 batch: 0.560098
Train loss on 750 batch: 0.465294
Train loss on 800 batch: 0.525467
Train loss on 850 batch: 0.521017
Train loss on 900 batch: 0.479210
Train loss on 950 batch: 0.446574
Train loss on 1000 batch: 0.449099
Train loss on 1050 batch: 0.545011
Train loss on 1100 batch: 0.447085
Train loss on 1150 batch: 0.537512
Train loss on 1200 batch: 0.450237
Train loss on 1250 batch: 0.474947
Train loss on 1300 batch: 0.570204
Train loss on 1350 batch: 0.459942
Train loss on 1400 batch: 0.473650
Train loss on 1450 batch: 0.382570
Train loss on 1500 batch: 0.468895
Train loss on 1550 batch: 0.434956
Train loss on 1600 batch: 0.469399
Train loss on 1650 batch: 0.462573
Train loss on 1700 batch: 0.537302
Train loss on 1750 batch: 0.469825
Train loss on 1800 batch: 0.468110
Train loss on 1850 batch: 0.456282
Train loss on 1900 batch: 0.465448
: Epoch: 5 | Training Loss: 0.485012 | Val. Loss: 0.467720 | Val. Kappa Score: 0.6163 | LR: 0.001000 | Estimated time: 510.38
Train loss on 50 batch: 0.524602
Train loss on 100 batch: 0.464615
Train loss on 150 batch: 0.456428
Train loss on 200 batch: 0.530533
Train loss on 250 batch: 0.409666
Train loss on 300 batch: 0.493167
Train loss on 350 batch: 0.451794
Train loss on 400 batch: 0.538841
Train loss on 450 batch: 0.523220
Train loss on 500 batch: 0.455274
Train loss on 550 batch: 0.505043
Train loss on 600 batch: 0.499504
Train loss on 650 batch: 0.472863
Train loss on 700 batch: 0.459129
Train loss on 750 batch: 0.409202
Train loss on 800 batch: 0.501380
Train loss on 850 batch: 0.443721
Train loss on 900 batch: 0.516168
Train loss on 950 batch: 0.486326
Train loss on 1000 batch: 0.479266
Train loss on 1050 batch: 0.525719
Train loss on 1100 batch: 0.448470
Train loss on 1150 batch: 0.476560
Train loss on 1200 batch: 0.406792
Train loss on 1250 batch: 0.528660
Train loss on 1300 batch: 0.481442
Train loss on 1350 batch: 0.450489
Train loss on 1400 batch: 0.484744
Train loss on 1450 batch: 0.523152
Train loss on 1500 batch: 0.471701
Train loss on 1550 batch: 0.514870
Train loss on 1600 batch: 0.474054
Train loss on 1650 batch: 0.417038
Train loss on 1700 batch: 0.400339
Train loss on 1750 batch: 0.453459
Train loss on 1800 batch: 0.441125
Train loss on 1850 batch: 0.458530
Train loss on 1900 batch: 0.478881
best-train-loss: 0.475383
best-valid-loss: 0.431824
best-kappa: 0.6267
: Epoch: 6 | Training Loss: 0.475383 | Val. Loss: 0.431824 | Val. Kappa Score: 0.6267 | LR: 0.001000 | Estimated time: 510.82
Train loss on 50 batch: 0.461399
Train loss on 100 batch: 0.495771
Train loss on 150 batch: 0.478387
Train loss on 200 batch: 0.428275
Train loss on 250 batch: 0.510235
Train loss on 300 batch: 0.532495
Train loss on 350 batch: 0.408332
Train loss on 400 batch: 0.509350
Train loss on 450 batch: 0.447105
Train loss on 500 batch: 0.401698
Train loss on 550 batch: 0.429686
Train loss on 600 batch: 0.510552
Train loss on 650 batch: 0.450366
Train loss on 700 batch: 0.457908
Train loss on 750 batch: 0.391644
Train loss on 800 batch: 0.433049
Train loss on 850 batch: 0.427723
Train loss on 900 batch: 0.483037
Train loss on 950 batch: 0.351022
Train loss on 1000 batch: 0.413983
Train loss on 1050 batch: 0.444380
Train loss on 1100 batch: 0.436439
Train loss on 1150 batch: 0.455259
Train loss on 1200 batch: 0.470809
Train loss on 1250 batch: 0.475829
Train loss on 1300 batch: 0.494068
Train loss on 1350 batch: 0.444859
Train loss on 1400 batch: 0.404900
Train loss on 1450 batch: 0.438891
Train loss on 1500 batch: 0.387532
Train loss on 1550 batch: 0.502875
Train loss on 1600 batch: 0.398681
Train loss on 1650 batch: 0.495712
Train loss on 1700 batch: 0.457049
Train loss on 1750 batch: 0.393706
Train loss on 1800 batch: 0.490196
Train loss on 1850 batch: 0.590835
Train loss on 1900 batch: 0.481240
best-train-loss: 0.453796
best-valid-loss: 0.404215
best-kappa: 0.6354
: Epoch: 7 | Training Loss: 0.453796 | Val. Loss: 0.404215 | Val. Kappa Score: 0.6354 | LR: 0.001000 | Estimated time: 510.82
Train loss on 50 batch: 0.424677
Train loss on 100 batch: 0.356319
Train loss on 150 batch: 0.498672
Train loss on 200 batch: 0.495115
Train loss on 250 batch: 0.363849
Train loss on 300 batch: 0.406517
Train loss on 350 batch: 0.406076
Train loss on 400 batch: 0.453995
Train loss on 450 batch: 0.358792
Train loss on 500 batch: 0.490304
Train loss on 550 batch: 0.470399
Train loss on 600 batch: 0.403813
Train loss on 650 batch: 0.433891
Train loss on 700 batch: 0.460834
Train loss on 750 batch: 0.445472
Train loss on 800 batch: 0.485684
Train loss on 850 batch: 0.414499
Train loss on 900 batch: 0.477966
Train loss on 950 batch: 0.383516
Train loss on 1000 batch: 0.400586
Train loss on 1050 batch: 0.442997
Train loss on 1100 batch: 0.407665
Train loss on 1150 batch: 0.500319
Train loss on 1200 batch: 0.451312
Train loss on 1250 batch: 0.439010
Train loss on 1300 batch: 0.420907
Train loss on 1350 batch: 0.455463
Train loss on 1400 batch: 0.437919
Train loss on 1450 batch: 0.420384
Train loss on 1500 batch: 0.482106
Train loss on 1550 batch: 0.449914
Train loss on 1600 batch: 0.462424
Train loss on 1650 batch: 0.476956
Train loss on 1700 batch: 0.412175
Train loss on 1750 batch: 0.448684
Train loss on 1800 batch: 0.452828
Train loss on 1850 batch: 0.460188
Train loss on 1900 batch: 0.364927
: Epoch: 8 | Training Loss: 0.437363 | Val. Loss: 0.434200 | Val. Kappa Score: 0.6402 | LR: 0.001000 | Estimated time: 510.46
Train loss on 50 batch: 0.510920
Train loss on 100 batch: 0.403183
Train loss on 150 batch: 0.442219
Train loss on 200 batch: 0.421859
Train loss on 250 batch: 0.398601
Train loss on 300 batch: 0.468104
Train loss on 350 batch: 0.391124
Train loss on 400 batch: 0.498718
Train loss on 450 batch: 0.409593
Train loss on 500 batch: 0.414141
Train loss on 550 batch: 0.459953
Train loss on 600 batch: 0.480298
Train loss on 650 batch: 0.451407
Train loss on 700 batch: 0.439628
Train loss on 750 batch: 0.424815
Train loss on 800 batch: 0.439035
Train loss on 850 batch: 0.449099
Train loss on 900 batch: 0.445314
Train loss on 950 batch: 0.422680
Train loss on 1000 batch: 0.362568
Train loss on 1050 batch: 0.429381
Train loss on 1100 batch: 0.480888
Train loss on 1150 batch: 0.407542
Train loss on 1200 batch: 0.484676
Train loss on 1250 batch: 0.372456
Train loss on 1300 batch: 0.398491
Train loss on 1350 batch: 0.425896
Train loss on 1400 batch: 0.399885
Train loss on 1450 batch: 0.464919
Train loss on 1500 batch: 0.392063
Train loss on 1550 batch: 0.467931
Train loss on 1600 batch: 0.449958
Train loss on 1650 batch: 0.472739
Train loss on 1700 batch: 0.484353
Train loss on 1750 batch: 0.414924
Train loss on 1800 batch: 0.421871
Train loss on 1850 batch: 0.391561
Train loss on 1900 batch: 0.443659
: Epoch: 9 | Training Loss: 0.435086 | Val. Loss: 0.565684 | Val. Kappa Score: 0.6411 | LR: 0.001000 | Estimated time: 510.63
Train loss on 50 batch: 0.423805
Train loss on 100 batch: 0.387967
Train loss on 150 batch: 0.384023
Train loss on 200 batch: 0.413744
Train loss on 250 batch: 0.449549
Train loss on 300 batch: 0.443361
Train loss on 350 batch: 0.431647
Train loss on 400 batch: 0.413173
Train loss on 450 batch: 0.428424
Train loss on 500 batch: 0.404560
Train loss on 550 batch: 0.398012
Train loss on 600 batch: 0.406195
Train loss on 650 batch: 0.423650
Train loss on 700 batch: 0.464659
Train loss on 750 batch: 0.447497
Train loss on 800 batch: 0.446720
Train loss on 850 batch: 0.386581
Train loss on 900 batch: 0.360800
Train loss on 950 batch: 0.378083
Train loss on 1000 batch: 0.397267
Train loss on 1050 batch: 0.445690
Train loss on 1100 batch: 0.411189
Train loss on 1150 batch: 0.424211
Train loss on 1200 batch: 0.447035
Train loss on 1250 batch: 0.465995
Train loss on 1300 batch: 0.460958
Train loss on 1350 batch: 0.486607
Train loss on 1400 batch: 0.554550
Train loss on 1450 batch: 0.395618
Train loss on 1500 batch: 0.510990
Train loss on 1550 batch: 0.452483
Train loss on 1600 batch: 0.476778
Train loss on 1650 batch: 0.466001
Train loss on 1700 batch: 0.401500
Train loss on 1750 batch: 0.435916
Train loss on 1800 batch: 0.451686
Train loss on 1850 batch: 0.350463
Train loss on 1900 batch: 0.441205
: Epoch: 10 | Training Loss: 0.429565 | Val. Loss: 0.477695 | Val. Kappa Score: 0.6423 | LR: 0.000500 | Estimated time: 510.56
Train loss on 50 batch: 0.446754
Train loss on 100 batch: 0.395137
Train loss on 150 batch: 0.339301
Train loss on 200 batch: 0.417798
Train loss on 250 batch: 0.355859
Train loss on 300 batch: 0.279443
Train loss on 350 batch: 0.428016
Train loss on 400 batch: 0.364616
Train loss on 450 batch: 0.378403
Train loss on 500 batch: 0.438018
Train loss on 550 batch: 0.360190
Train loss on 600 batch: 0.406476
Train loss on 650 batch: 0.349199
Train loss on 700 batch: 0.446892
Train loss on 750 batch: 0.481487
Train loss on 800 batch: 0.404430
Train loss on 850 batch: 0.473169
Train loss on 900 batch: 0.414477
Train loss on 950 batch: 0.303428
Train loss on 1000 batch: 0.352995
Train loss on 1050 batch: 0.413395
Train loss on 1100 batch: 0.364170
Train loss on 1150 batch: 0.379364
Train loss on 1200 batch: 0.357420
Train loss on 1250 batch: 0.399034
Train loss on 1300 batch: 0.340815
Train loss on 1350 batch: 0.385857
Train loss on 1400 batch: 0.409180
Train loss on 1450 batch: 0.384796
Train loss on 1500 batch: 0.384293
Train loss on 1550 batch: 0.369872
Train loss on 1600 batch: 0.345200
Train loss on 1650 batch: 0.365748
Train loss on 1700 batch: 0.365880
Train loss on 1750 batch: 0.380420
Train loss on 1800 batch: 0.423170
Train loss on 1850 batch: 0.320683
Train loss on 1900 batch: 0.420971
best-train-loss: 0.385217
best-valid-loss: 0.351933
best-kappa: 0.6506
: Epoch: 11 | Training Loss: 0.385217 | Val. Loss: 0.351933 | Val. Kappa Score: 0.6506 | LR: 0.000500 | Estimated time: 511.64
Train loss on 50 batch: 0.409361
Train loss on 100 batch: 0.379118
Train loss on 150 batch: 0.411943
Train loss on 200 batch: 0.368784
Train loss on 250 batch: 0.367911
Train loss on 300 batch: 0.352762
Train loss on 350 batch: 0.303057
Train loss on 400 batch: 0.348147
Train loss on 450 batch: 0.305950
Train loss on 500 batch: 0.384616
Train loss on 550 batch: 0.405067
Train loss on 600 batch: 0.378956
Train loss on 650 batch: 0.366346
Train loss on 700 batch: 0.454129
Train loss on 750 batch: 0.362299
Train loss on 800 batch: 0.326497
Train loss on 850 batch: 0.298871
Train loss on 900 batch: 0.410586
Train loss on 950 batch: 0.352966
Train loss on 1000 batch: 0.358046
Train loss on 1050 batch: 0.376159
Train loss on 1100 batch: 0.337787
Train loss on 1150 batch: 0.325174
Train loss on 1200 batch: 0.364399
Train loss on 1250 batch: 0.352013
Train loss on 1300 batch: 0.369125
Train loss on 1350 batch: 0.336291
Train loss on 1400 batch: 0.335440
Train loss on 1450 batch: 0.403380
Train loss on 1500 batch: 0.333439
Train loss on 1550 batch: 0.380213
Train loss on 1600 batch: 0.389689
Train loss on 1650 batch: 0.374983
Train loss on 1700 batch: 0.349365
Train loss on 1750 batch: 0.372110
Train loss on 1800 batch: 0.325483
Train loss on 1850 batch: 0.385610
Train loss on 1900 batch: 0.438280
: Epoch: 12 | Training Loss: 0.365303 | Val. Loss: 0.379193 | Val. Kappa Score: 0.6548 | LR: 0.000500 | Estimated time: 518.61
Train loss on 50 batch: 0.341090
Train loss on 100 batch: 0.370497
Train loss on 150 batch: 0.364099
Train loss on 200 batch: 0.357515
Train loss on 250 batch: 0.352253
Train loss on 300 batch: 0.394654
Train loss on 350 batch: 0.342606
Train loss on 400 batch: 0.414970
Train loss on 450 batch: 0.317009
Train loss on 500 batch: 0.359079
Train loss on 550 batch: 0.352804
Train loss on 600 batch: 0.362824
Train loss on 650 batch: 0.377754
Train loss on 700 batch: 0.379285
Train loss on 750 batch: 0.395835
Train loss on 800 batch: 0.402199
Train loss on 850 batch: 0.338157
Train loss on 900 batch: 0.387319
Train loss on 950 batch: 0.365177
Train loss on 1000 batch: 0.351524
Train loss on 1050 batch: 0.404986
Train loss on 1100 batch: 0.367851
Train loss on 1150 batch: 0.350303
Train loss on 1200 batch: 0.343591
Train loss on 1250 batch: 0.377857
Train loss on 1300 batch: 0.327460
Train loss on 1350 batch: 0.345735
Train loss on 1400 batch: 0.378021
Train loss on 1450 batch: 0.385056
Train loss on 1500 batch: 0.336296
Train loss on 1550 batch: 0.352073
Train loss on 1600 batch: 0.364374
Train loss on 1650 batch: 0.369887
Train loss on 1700 batch: 0.376678
Train loss on 1750 batch: 0.401691
Train loss on 1800 batch: 0.369191
Train loss on 1850 batch: 0.334037
Train loss on 1900 batch: 0.297152
: Epoch: 13 | Training Loss: 0.364426 | Val. Loss: 0.476357 | Val. Kappa Score: 0.6562 | LR: 0.000500 | Estimated time: 511.94
Train loss on 50 batch: 0.382744
Train loss on 100 batch: 0.367139
Train loss on 150 batch: 0.339426
Train loss on 200 batch: 0.339641
Train loss on 250 batch: 0.372558
Train loss on 300 batch: 0.366431
Train loss on 350 batch: 0.336038
Train loss on 400 batch: 0.328527
Train loss on 450 batch: 0.351800
Train loss on 500 batch: 0.336356
Train loss on 550 batch: 0.382393
Train loss on 600 batch: 0.319113
Train loss on 650 batch: 0.379402
Train loss on 700 batch: 0.358113
Train loss on 750 batch: 0.319225
Train loss on 800 batch: 0.353640
Train loss on 850 batch: 0.370728
Train loss on 900 batch: 0.407803
Train loss on 950 batch: 0.329967
Train loss on 1000 batch: 0.353294
Train loss on 1050 batch: 0.370209
Train loss on 1100 batch: 0.348797
Train loss on 1150 batch: 0.256809
Train loss on 1200 batch: 0.361683
Train loss on 1250 batch: 0.430198
Train loss on 1300 batch: 0.420158
Train loss on 1350 batch: 0.362323
Train loss on 1400 batch: 0.399507
Train loss on 1450 batch: 0.380681
Train loss on 1500 batch: 0.338528
Train loss on 1550 batch: 0.334386
Train loss on 1600 batch: 0.327695
Train loss on 1650 batch: 0.409088
Train loss on 1700 batch: 0.340578
Train loss on 1750 batch: 0.295505
Train loss on 1800 batch: 0.426255
Train loss on 1850 batch: 0.352568
Train loss on 1900 batch: 0.421697
: Epoch: 14 | Training Loss: 0.358492 | Val. Loss: 0.367867 | Val. Kappa Score: 0.6617 | LR: 0.000250 | Estimated time: 510.66
Train loss on 50 batch: 0.317114
Train loss on 100 batch: 0.299250
Train loss on 150 batch: 0.317797
Train loss on 200 batch: 0.405622
Train loss on 250 batch: 0.329492
Train loss on 300 batch: 0.293058
Train loss on 350 batch: 0.387886
Train loss on 400 batch: 0.316254
Train loss on 450 batch: 0.355117
Train loss on 500 batch: 0.321712
Train loss on 550 batch: 0.391357
Train loss on 600 batch: 0.313506
Train loss on 650 batch: 0.324747
Train loss on 700 batch: 0.289552
Train loss on 750 batch: 0.345042
Train loss on 800 batch: 0.308390
Train loss on 850 batch: 0.398893
Train loss on 900 batch: 0.380777
Train loss on 950 batch: 0.382935
Train loss on 1000 batch: 0.313005
Train loss on 1050 batch: 0.337655
Train loss on 1100 batch: 0.302632
Train loss on 1150 batch: 0.319395
Train loss on 1200 batch: 0.347597
Train loss on 1250 batch: 0.301357
Train loss on 1300 batch: 0.376723
Train loss on 1350 batch: 0.326263
Train loss on 1400 batch: 0.344393
Train loss on 1450 batch: 0.324334
Train loss on 1500 batch: 0.288648
Train loss on 1550 batch: 0.259546
Train loss on 1600 batch: 0.319181
Train loss on 1650 batch: 0.321448
Train loss on 1700 batch: 0.264447
Train loss on 1750 batch: 0.291057
Train loss on 1800 batch: 0.318365
Train loss on 1850 batch: 0.350218
Train loss on 1900 batch: 0.381032
: Epoch: 15 | Training Loss: 0.329607 | Val. Loss: 0.357638 | Val. Kappa Score: 0.6661 | LR: 0.000250 | Estimated time: 510.84
Train loss on 50 batch: 0.292762
Train loss on 100 batch: 0.316219
Train loss on 150 batch: 0.360030
Train loss on 200 batch: 0.262023
Train loss on 250 batch: 0.336943
Train loss on 300 batch: 0.299929
Train loss on 350 batch: 0.322510
Train loss on 400 batch: 0.300530
Train loss on 450 batch: 0.303717
Train loss on 500 batch: 0.358297
Train loss on 550 batch: 0.323783
Train loss on 600 batch: 0.382190
Train loss on 650 batch: 0.343638
Train loss on 700 batch: 0.267196
Train loss on 750 batch: 0.290271
Train loss on 800 batch: 0.346631
Train loss on 850 batch: 0.345926
Train loss on 900 batch: 0.341163
Train loss on 950 batch: 0.349751
Train loss on 1000 batch: 0.332238
Train loss on 1050 batch: 0.345288
Train loss on 1100 batch: 0.307088
Train loss on 1150 batch: 0.306030
Train loss on 1200 batch: 0.300481
Train loss on 1250 batch: 0.288583
Train loss on 1300 batch: 0.284134
Train loss on 1350 batch: 0.303972
Train loss on 1400 batch: 0.293710
Train loss on 1450 batch: 0.280711
Train loss on 1500 batch: 0.337089
Train loss on 1550 batch: 0.366985
Train loss on 1600 batch: 0.338639
Train loss on 1650 batch: 0.310474
Train loss on 1700 batch: 0.385762
Train loss on 1750 batch: 0.331027
Train loss on 1800 batch: 0.305334
Train loss on 1850 batch: 0.302768
Train loss on 1900 batch: 0.347894
best-train-loss: 0.322607
best-valid-loss: 0.340873
best-kappa: 0.6702
: Epoch: 16 | Training Loss: 0.322607 | Val. Loss: 0.340873 | Val. Kappa Score: 0.6702 | LR: 0.000250 | Estimated time: 528.04
Train loss on 50 batch: 0.313984
Train loss on 100 batch: 0.299318
Train loss on 150 batch: 0.362295
Train loss on 200 batch: 0.351712
Train loss on 250 batch: 0.297580
Train loss on 300 batch: 0.306753
Train loss on 350 batch: 0.359444
Train loss on 400 batch: 0.329871
Train loss on 450 batch: 0.302101
Train loss on 500 batch: 0.292476
Train loss on 550 batch: 0.287372
Train loss on 600 batch: 0.280935
Train loss on 650 batch: 0.294278
Train loss on 700 batch: 0.340965
Train loss on 750 batch: 0.342231
Train loss on 800 batch: 0.302631
Train loss on 850 batch: 0.383426
Train loss on 900 batch: 0.346172
Train loss on 950 batch: 0.302758
Train loss on 1000 batch: 0.341726
Train loss on 1050 batch: 0.331846
Train loss on 1100 batch: 0.322994
Train loss on 1150 batch: 0.290661
Train loss on 1200 batch: 0.321726
Train loss on 1250 batch: 0.273855
Train loss on 1300 batch: 0.292951
Train loss on 1350 batch: 0.284400
Train loss on 1400 batch: 0.299988
Train loss on 1450 batch: 0.346366
Train loss on 1500 batch: 0.318980
Train loss on 1550 batch: 0.355371
Train loss on 1600 batch: 0.299707
Train loss on 1650 batch: 0.322806
Train loss on 1700 batch: 0.331845
Train loss on 1750 batch: 0.319827
Train loss on 1800 batch: 0.300822
Train loss on 1850 batch: 0.354283
Train loss on 1900 batch: 0.257064
: Epoch: 17 | Training Loss: 0.316923 | Val. Loss: 0.361565 | Val. Kappa Score: 0.6740 | LR: 0.000250 | Estimated time: 513.60
Train loss on 50 batch: 0.282132
Train loss on 100 batch: 0.273786
Train loss on 150 batch: 0.314266
Train loss on 200 batch: 0.309053
Train loss on 250 batch: 0.327054
Train loss on 300 batch: 0.309401
Train loss on 350 batch: 0.295973
Train loss on 400 batch: 0.298885
Train loss on 450 batch: 0.342926
Train loss on 500 batch: 0.296056
Train loss on 550 batch: 0.329476
Train loss on 600 batch: 0.330584
Train loss on 650 batch: 0.256413
Train loss on 700 batch: 0.301333
Train loss on 750 batch: 0.293429
Train loss on 800 batch: 0.290905
Train loss on 850 batch: 0.279874
Train loss on 900 batch: 0.354233
Train loss on 950 batch: 0.301185
Train loss on 1000 batch: 0.292911
Train loss on 1050 batch: 0.352414
Train loss on 1100 batch: 0.362116
Train loss on 1150 batch: 0.297609
Train loss on 1200 batch: 0.359144
Train loss on 1250 batch: 0.323188
Train loss on 1300 batch: 0.300123
Train loss on 1350 batch: 0.354435
Train loss on 1400 batch: 0.345119
Train loss on 1450 batch: 0.367555
Train loss on 1500 batch: 0.312630
Train loss on 1550 batch: 0.298968
Train loss on 1600 batch: 0.264436
Train loss on 1650 batch: 0.281995
Train loss on 1700 batch: 0.358961
Train loss on 1750 batch: 0.326554
Train loss on 1800 batch: 0.301734
Train loss on 1850 batch: 0.293042
Train loss on 1900 batch: 0.323425
best-train-loss: 0.314155
best-valid-loss: 0.338425
best-kappa: 0.6771
: Epoch: 18 | Training Loss: 0.314155 | Val. Loss: 0.338425 | Val. Kappa Score: 0.6771 | LR: 0.000250 | Estimated time: 513.06
Train loss on 50 batch: 0.237632
Train loss on 100 batch: 0.302487
Train loss on 150 batch: 0.345544
Train loss on 200 batch: 0.319021
Train loss on 250 batch: 0.366361
Train loss on 300 batch: 0.324218
Train loss on 350 batch: 0.310644
Train loss on 400 batch: 0.282429
Train loss on 450 batch: 0.345250
Train loss on 500 batch: 0.316200
Train loss on 550 batch: 0.251031
Train loss on 600 batch: 0.352617
Train loss on 650 batch: 0.342698
Train loss on 700 batch: 0.279610
Train loss on 750 batch: 0.274544
Train loss on 800 batch: 0.299844
Train loss on 850 batch: 0.337821
Train loss on 900 batch: 0.339069
Train loss on 950 batch: 0.316952
Train loss on 1000 batch: 0.316396
Train loss on 1050 batch: 0.317894
Train loss on 1100 batch: 0.264505
Train loss on 1150 batch: 0.231048
Train loss on 1200 batch: 0.291502
Train loss on 1250 batch: 0.338736
Train loss on 1300 batch: 0.304822
Train loss on 1350 batch: 0.350659
Train loss on 1400 batch: 0.327261
Train loss on 1450 batch: 0.267239
Train loss on 1500 batch: 0.269058
Train loss on 1550 batch: 0.287625
Train loss on 1600 batch: 0.291622
Train loss on 1650 batch: 0.308464
Train loss on 1700 batch: 0.312772
Train loss on 1750 batch: 0.266586
Train loss on 1800 batch: 0.366972
Train loss on 1850 batch: 0.274425
Train loss on 1900 batch: 0.340286
best-train-loss: 0.307909
best-valid-loss: 0.331154
best-kappa: 0.6805
: Epoch: 19 | Training Loss: 0.307909 | Val. Loss: 0.331154 | Val. Kappa Score: 0.6805 | LR: 0.000250 | Estimated time: 517.08
Train loss on 50 batch: 0.251781
Train loss on 100 batch: 0.356036
Train loss on 150 batch: 0.284586
Train loss on 200 batch: 0.305584
Train loss on 250 batch: 0.292963
Train loss on 300 batch: 0.264657
Train loss on 350 batch: 0.272033
Train loss on 400 batch: 0.327951
Train loss on 450 batch: 0.316825
Train loss on 500 batch: 0.293797
Train loss on 550 batch: 0.318200
Train loss on 600 batch: 0.259074
Train loss on 650 batch: 0.364579
Train loss on 700 batch: 0.317758
Train loss on 750 batch: 0.333533
Train loss on 800 batch: 0.306947
Train loss on 850 batch: 0.347898
Train loss on 900 batch: 0.275131
Train loss on 950 batch: 0.282616
Train loss on 1000 batch: 0.278203
Train loss on 1050 batch: 0.370403
Train loss on 1100 batch: 0.305166
Train loss on 1150 batch: 0.304907
Train loss on 1200 batch: 0.320893
Train loss on 1250 batch: 0.254713
Train loss on 1300 batch: 0.272400
Train loss on 1350 batch: 0.241982
Train loss on 1400 batch: 0.332953
Train loss on 1450 batch: 0.244465
Train loss on 1500 batch: 0.286500
Train loss on 1550 batch: 0.319489
Train loss on 1600 batch: 0.332069
Train loss on 1650 batch: 0.289475
Train loss on 1700 batch: 0.296872
Train loss on 1750 batch: 0.333352
Train loss on 1800 batch: 0.335085
Train loss on 1850 batch: 0.289810
Train loss on 1900 batch: 0.355093
: Epoch: 20 | Training Loss: 0.303611 | Val. Loss: 0.345047 | Val. Kappa Score: 0.6825 | LR: 0.000250 | Estimated time: 516.92
Train loss on 50 batch: 0.291070
Train loss on 100 batch: 0.264764
Train loss on 150 batch: 0.332627
Train loss on 200 batch: 0.354479
Train loss on 250 batch: 0.259409
Train loss on 300 batch: 0.303646
Train loss on 350 batch: 0.294333
Train loss on 400 batch: 0.351474
Train loss on 450 batch: 0.305790
Train loss on 500 batch: 0.272175
Train loss on 550 batch: 0.307594
Train loss on 600 batch: 0.342751
Train loss on 650 batch: 0.300769
Train loss on 700 batch: 0.274141
Train loss on 750 batch: 0.281873
Train loss on 800 batch: 0.269203
Train loss on 850 batch: 0.327990
Train loss on 900 batch: 0.377841
Train loss on 950 batch: 0.291524
Train loss on 1000 batch: 0.300625
Train loss on 1050 batch: 0.273368
Train loss on 1100 batch: 0.327619
Train loss on 1150 batch: 0.257117
Train loss on 1200 batch: 0.300449
Train loss on 1250 batch: 0.303841
Train loss on 1300 batch: 0.270297
Train loss on 1350 batch: 0.329094
Train loss on 1400 batch: 0.304319
Train loss on 1450 batch: 0.320893
Train loss on 1500 batch: 0.303947
Train loss on 1550 batch: 0.293432
Train loss on 1600 batch: 0.314189
Train loss on 1650 batch: 0.274202
Train loss on 1700 batch: 0.360368
Train loss on 1750 batch: 0.359715
Train loss on 1800 batch: 0.267894
Train loss on 1850 batch: 0.302333
Train loss on 1900 batch: 0.321668
: Epoch: 21 | Training Loss: 0.306043 | Val. Loss: 0.359057 | Val. Kappa Score: 0.6841 | LR: 0.000250 | Estimated time: 515.90
Train loss on 50 batch: 0.266352
Train loss on 100 batch: 0.344264
Train loss on 150 batch: 0.350472
Train loss on 200 batch: 0.307344
Train loss on 250 batch: 0.296238
Train loss on 300 batch: 0.289697
Train loss on 350 batch: 0.271959
Train loss on 400 batch: 0.298829
Train loss on 450 batch: 0.297357
Train loss on 500 batch: 0.295041
Train loss on 550 batch: 0.278514
Train loss on 600 batch: 0.297459
Train loss on 650 batch: 0.328122
Train loss on 700 batch: 0.336762
Train loss on 750 batch: 0.319643
Train loss on 800 batch: 0.259700
Train loss on 850 batch: 0.342394
Train loss on 900 batch: 0.328332
Train loss on 950 batch: 0.236484
Train loss on 1000 batch: 0.293875
Train loss on 1050 batch: 0.297573
Train loss on 1100 batch: 0.269048
Train loss on 1150 batch: 0.338032
Train loss on 1200 batch: 0.371523
Train loss on 1250 batch: 0.251614
Train loss on 1300 batch: 0.288205
Train loss on 1350 batch: 0.300381
Train loss on 1400 batch: 0.307881
Train loss on 1450 batch: 0.304918
Train loss on 1500 batch: 0.318625
Train loss on 1550 batch: 0.292372
Train loss on 1600 batch: 0.316166
Train loss on 1650 batch: 0.275420
Train loss on 1700 batch: 0.288163
Train loss on 1750 batch: 0.251405
Train loss on 1800 batch: 0.306823
Train loss on 1850 batch: 0.315470
Train loss on 1900 batch: 0.308764
: Epoch: 22 | Training Loss: 0.301072 | Val. Loss: 0.345421 | Val. Kappa Score: 0.6868 | LR: 0.000125 | Estimated time: 511.41
Train loss on 50 batch: 0.262380
Train loss on 100 batch: 0.278573
Train loss on 150 batch: 0.272025
Train loss on 200 batch: 0.290977
Train loss on 250 batch: 0.294355
Train loss on 300 batch: 0.285739
Train loss on 350 batch: 0.292329
Train loss on 400 batch: 0.301220
Train loss on 450 batch: 0.285174
Train loss on 500 batch: 0.254486
Train loss on 550 batch: 0.287429
Train loss on 600 batch: 0.320393
Train loss on 650 batch: 0.283293
Train loss on 700 batch: 0.294704
Train loss on 750 batch: 0.263785
Train loss on 800 batch: 0.312896
Train loss on 850 batch: 0.357850
Train loss on 900 batch: 0.276760
Train loss on 950 batch: 0.276374
Train loss on 1000 batch: 0.279034
Train loss on 1050 batch: 0.315682
Train loss on 1100 batch: 0.316425
Train loss on 1150 batch: 0.358788
Train loss on 1200 batch: 0.243503
Train loss on 1250 batch: 0.338348
Train loss on 1300 batch: 0.309733
Train loss on 1350 batch: 0.306679
Train loss on 1400 batch: 0.286637
Train loss on 1450 batch: 0.263035
Train loss on 1500 batch: 0.244712
Train loss on 1550 batch: 0.313676
Train loss on 1600 batch: 0.235449
Train loss on 1650 batch: 0.280197
Train loss on 1700 batch: 0.301301
Train loss on 1750 batch: 0.284418
Train loss on 1800 batch: 0.318923
Train loss on 1850 batch: 0.258677
Train loss on 1900 batch: 0.282688
: Epoch: 23 | Training Loss: 0.290757 | Val. Loss: 0.341985 | Val. Kappa Score: 0.6890 | LR: 0.000125 | Estimated time: 518.99
Train loss on 50 batch: 0.263063
Train loss on 100 batch: 0.260919
Train loss on 150 batch: 0.256251
Train loss on 200 batch: 0.311109
Train loss on 250 batch: 0.233728
Train loss on 300 batch: 0.237831
Train loss on 350 batch: 0.312112
Train loss on 400 batch: 0.257967
Train loss on 450 batch: 0.259348
Train loss on 500 batch: 0.284956
Train loss on 550 batch: 0.270565
Train loss on 600 batch: 0.274220
Train loss on 650 batch: 0.297444
Train loss on 700 batch: 0.260769
Train loss on 750 batch: 0.257253
Train loss on 800 batch: 0.333171
Train loss on 850 batch: 0.267071
Train loss on 900 batch: 0.306371
Train loss on 950 batch: 0.272946
Train loss on 1000 batch: 0.239219
Train loss on 1050 batch: 0.286053
Train loss on 1100 batch: 0.302372
Train loss on 1150 batch: 0.308499
Train loss on 1200 batch: 0.293562
Train loss on 1250 batch: 0.300848
Train loss on 1300 batch: 0.328251
Train loss on 1350 batch: 0.284031
Train loss on 1400 batch: 0.251355
Train loss on 1450 batch: 0.305324
Train loss on 1500 batch: 0.302522
Train loss on 1550 batch: 0.311024
Train loss on 1600 batch: 0.330819
Train loss on 1650 batch: 0.273550
Train loss on 1700 batch: 0.324522
Train loss on 1750 batch: 0.261839
Train loss on 1800 batch: 0.299573
Train loss on 1850 batch: 0.268381
Train loss on 1900 batch: 0.272660
: Epoch: 24 | Training Loss: 0.283327 | Val. Loss: 0.331494 | Val. Kappa Score: 0.6913 | LR: 0.000125 | Estimated time: 522.38
Train loss on 50 batch: 0.281424
Train loss on 100 batch: 0.291767
Train loss on 150 batch: 0.292210
Train loss on 200 batch: 0.269496
Train loss on 250 batch: 0.300693
Train loss on 300 batch: 0.257687
Train loss on 350 batch: 0.273069
Train loss on 400 batch: 0.267237
Train loss on 450 batch: 0.253238
Train loss on 500 batch: 0.281901
Train loss on 550 batch: 0.277812
Train loss on 600 batch: 0.295341
Train loss on 650 batch: 0.316503
Train loss on 700 batch: 0.283530
Train loss on 750 batch: 0.249224
Train loss on 800 batch: 0.304041
Train loss on 850 batch: 0.262656
Train loss on 900 batch: 0.241472
Train loss on 950 batch: 0.283037
Train loss on 1000 batch: 0.267241
Train loss on 1050 batch: 0.325261
Train loss on 1100 batch: 0.275943
Train loss on 1150 batch: 0.271589
Train loss on 1200 batch: 0.248591
Train loss on 1250 batch: 0.296622
Train loss on 1300 batch: 0.252163
Train loss on 1350 batch: 0.310013
Train loss on 1400 batch: 0.280631
Train loss on 1450 batch: 0.303720
Train loss on 1500 batch: 0.310211
Train loss on 1550 batch: 0.276079
Train loss on 1600 batch: 0.286336
Train loss on 1650 batch: 0.290255
Train loss on 1700 batch: 0.351248
Train loss on 1750 batch: 0.253250
Train loss on 1800 batch: 0.284569
Train loss on 1850 batch: 0.279917
Train loss on 1900 batch: 0.309091
: Epoch: 25 | Training Loss: 0.282581 | Val. Loss: 0.337040 | Val. Kappa Score: 0.6935 | LR: 0.000063 | Estimated time: 517.34
Train loss on 50 batch: 0.252228
Train loss on 100 batch: 0.275127
Train loss on 150 batch: 0.257890
Train loss on 200 batch: 0.257640
Train loss on 250 batch: 0.275060
Train loss on 300 batch: 0.260164
Train loss on 350 batch: 0.266550
Train loss on 400 batch: 0.268815
Train loss on 450 batch: 0.274600
Train loss on 500 batch: 0.299643
Train loss on 550 batch: 0.257602
Train loss on 600 batch: 0.262973
Train loss on 650 batch: 0.288406
Train loss on 700 batch: 0.284691
Train loss on 750 batch: 0.269051
Train loss on 800 batch: 0.269234
Train loss on 850 batch: 0.297089
Train loss on 900 batch: 0.289753
Train loss on 950 batch: 0.286031
Train loss on 1000 batch: 0.263024
Train loss on 1050 batch: 0.274948
Train loss on 1100 batch: 0.274626
Train loss on 1150 batch: 0.288428
Train loss on 1200 batch: 0.303990
Train loss on 1250 batch: 0.240665
Train loss on 1300 batch: 0.240763
Train loss on 1350 batch: 0.274056
Train loss on 1400 batch: 0.283727
Train loss on 1450 batch: 0.272101
Train loss on 1500 batch: 0.307158
Train loss on 1550 batch: 0.262628
Train loss on 1600 batch: 0.266462
Train loss on 1650 batch: 0.315279
Train loss on 1700 batch: 0.271628
Train loss on 1750 batch: 0.307603
Train loss on 1800 batch: 0.274173
Train loss on 1850 batch: 0.251055
Train loss on 1900 batch: 0.275502
best-train-loss: 0.274182
best-valid-loss: 0.326315
best-kappa: 0.6958
: Epoch: 26 | Training Loss: 0.274182 | Val. Loss: 0.326315 | Val. Kappa Score: 0.6958 | LR: 0.000063 | Estimated time: 518.56
Train loss on 50 batch: 0.266720
Train loss on 100 batch: 0.246809
Train loss on 150 batch: 0.300894
Train loss on 200 batch: 0.271741
Train loss on 250 batch: 0.237548
Train loss on 300 batch: 0.290660
Train loss on 350 batch: 0.233541
Train loss on 400 batch: 0.269082
Train loss on 450 batch: 0.249867
Train loss on 500 batch: 0.270076
Train loss on 550 batch: 0.301084
Train loss on 600 batch: 0.269443
Train loss on 650 batch: 0.294121
Train loss on 700 batch: 0.321226
Train loss on 750 batch: 0.276762
Train loss on 800 batch: 0.300076
Train loss on 850 batch: 0.290764
Train loss on 900 batch: 0.279864
Train loss on 950 batch: 0.269949
Train loss on 1000 batch: 0.244563
Train loss on 1050 batch: 0.295281
Train loss on 1100 batch: 0.284988
Train loss on 1150 batch: 0.295915
Train loss on 1200 batch: 0.267523
Train loss on 1250 batch: 0.343694
Train loss on 1300 batch: 0.300885
Train loss on 1350 batch: 0.253367
Train loss on 1400 batch: 0.247653
Train loss on 1450 batch: 0.300802
Train loss on 1500 batch: 0.298750
Train loss on 1550 batch: 0.245086
Train loss on 1600 batch: 0.254000
Train loss on 1650 batch: 0.244591
Train loss on 1700 batch: 0.253070
Train loss on 1750 batch: 0.251543
Train loss on 1800 batch: 0.249315
Train loss on 1850 batch: 0.282957
Train loss on 1900 batch: 0.236178
: Epoch: 27 | Training Loss: 0.273399 | Val. Loss: 0.342828 | Val. Kappa Score: 0.6973 | LR: 0.000063 | Estimated time: 519.83
Train loss on 50 batch: 0.276655
Train loss on 100 batch: 0.273326
Train loss on 150 batch: 0.276544
Train loss on 200 batch: 0.218302
Train loss on 250 batch: 0.291264
Train loss on 300 batch: 0.283527
Train loss on 350 batch: 0.300395
Train loss on 400 batch: 0.257609
Train loss on 450 batch: 0.272197
Train loss on 500 batch: 0.286813
Train loss on 550 batch: 0.251837
Train loss on 600 batch: 0.311720
Train loss on 650 batch: 0.261811
Train loss on 700 batch: 0.275296
Train loss on 750 batch: 0.287464
Train loss on 800 batch: 0.274461
Train loss on 850 batch: 0.293269
Train loss on 900 batch: 0.252769
Train loss on 950 batch: 0.274642
Train loss on 1000 batch: 0.281811
Train loss on 1050 batch: 0.277740
Train loss on 1100 batch: 0.259209
Train loss on 1150 batch: 0.241996
Train loss on 1200 batch: 0.286467
Train loss on 1250 batch: 0.269548
Train loss on 1300 batch: 0.243902
Train loss on 1350 batch: 0.227957
Train loss on 1400 batch: 0.272270
Train loss on 1450 batch: 0.267667
Train loss on 1500 batch: 0.279109
Train loss on 1550 batch: 0.256139
Train loss on 1600 batch: 0.313399
Train loss on 1650 batch: 0.263361
Train loss on 1700 batch: 0.284051
Train loss on 1750 batch: 0.292290
Train loss on 1800 batch: 0.251425
Train loss on 1850 batch: 0.273989
Train loss on 1900 batch: 0.252204
best-train-loss: 0.270959
best-valid-loss: 0.325968
best-kappa: 0.6993
: Epoch: 28 | Training Loss: 0.270959 | Val. Loss: 0.325968 | Val. Kappa Score: 0.6993 | LR: 0.000063 | Estimated time: 511.54
Train loss on 50 batch: 0.268153
Train loss on 100 batch: 0.252066
Train loss on 150 batch: 0.295943
Train loss on 200 batch: 0.243081
Train loss on 250 batch: 0.260161
Train loss on 300 batch: 0.275261
Train loss on 350 batch: 0.269030
Train loss on 400 batch: 0.271160
Train loss on 450 batch: 0.315058
Train loss on 500 batch: 0.240348
Train loss on 550 batch: 0.229801
Train loss on 600 batch: 0.271161
Train loss on 650 batch: 0.251991
Train loss on 700 batch: 0.282320
Train loss on 750 batch: 0.263874
Train loss on 800 batch: 0.336497
Train loss on 850 batch: 0.282129
Train loss on 900 batch: 0.293434
Train loss on 950 batch: 0.291527
Train loss on 1000 batch: 0.261787
Train loss on 1050 batch: 0.229288
Train loss on 1100 batch: 0.279338
Train loss on 1150 batch: 0.258099
Train loss on 1200 batch: 0.334945
Train loss on 1250 batch: 0.268763
Train loss on 1300 batch: 0.273304
Train loss on 1350 batch: 0.283238
Train loss on 1400 batch: 0.279644
Train loss on 1450 batch: 0.318186
Train loss on 1500 batch: 0.255962
Train loss on 1550 batch: 0.257885
Train loss on 1600 batch: 0.280481
Train loss on 1650 batch: 0.279554
Train loss on 1700 batch: 0.246111
Train loss on 1750 batch: 0.285089
Train loss on 1800 batch: 0.248509
Train loss on 1850 batch: 0.236932
Train loss on 1900 batch: 0.254156
best-train-loss: 0.271678
best-valid-loss: 0.324565
best-kappa: 0.7013
: Epoch: 29 | Training Loss: 0.271678 | Val. Loss: 0.324565 | Val. Kappa Score: 0.7013 | LR: 0.000063 | Estimated time: 510.52
Train loss on 50 batch: 0.282490
Train loss on 100 batch: 0.242279
Train loss on 150 batch: 0.245263
Train loss on 200 batch: 0.259682
Train loss on 250 batch: 0.293216
Train loss on 300 batch: 0.286141
Train loss on 350 batch: 0.305779
Train loss on 400 batch: 0.269942
Train loss on 450 batch: 0.304915
Train loss on 500 batch: 0.267479
Train loss on 550 batch: 0.340993
Train loss on 600 batch: 0.277061
Train loss on 650 batch: 0.293052
Train loss on 700 batch: 0.277573
Train loss on 750 batch: 0.283036
Train loss on 800 batch: 0.240823
Train loss on 850 batch: 0.265103
Train loss on 900 batch: 0.259001
Train loss on 950 batch: 0.224491
Train loss on 1000 batch: 0.323499
Train loss on 1050 batch: 0.271033
Train loss on 1100 batch: 0.304412
Train loss on 1150 batch: 0.281133
Train loss on 1200 batch: 0.307941
Train loss on 1250 batch: 0.248783
Train loss on 1300 batch: 0.230516
Train loss on 1350 batch: 0.243074
Train loss on 1400 batch: 0.291328
Train loss on 1450 batch: 0.289660
Train loss on 1500 batch: 0.227799
Train loss on 1550 batch: 0.222246
Train loss on 1600 batch: 0.267976
Train loss on 1650 batch: 0.265350
Train loss on 1700 batch: 0.282864
Train loss on 1750 batch: 0.226996
Train loss on 1800 batch: 0.218582
Train loss on 1850 batch: 0.251101
Train loss on 1900 batch: 0.252654
best-train-loss: 0.268890
best-valid-loss: 0.324430
best-kappa: 0.7033
: Epoch: 30 | Training Loss: 0.268890 | Val. Loss: 0.324430 | Val. Kappa Score: 0.7033 | LR: 0.000063 | Estimated time: 525.27
Train loss on 50 batch: 0.320719
Train loss on 100 batch: 0.303842
Train loss on 150 batch: 0.280349
Train loss on 200 batch: 0.250065
Train loss on 250 batch: 0.204867
Train loss on 300 batch: 0.270475
Train loss on 350 batch: 0.280548
Train loss on 400 batch: 0.230823
Train loss on 450 batch: 0.243286
Train loss on 500 batch: 0.277056
Train loss on 550 batch: 0.254844
Train loss on 600 batch: 0.281826
Train loss on 650 batch: 0.257495
Train loss on 700 batch: 0.274903
Train loss on 750 batch: 0.262978
Train loss on 800 batch: 0.246781
Train loss on 850 batch: 0.223223
Train loss on 900 batch: 0.234819
Train loss on 950 batch: 0.236874
Train loss on 1000 batch: 0.293315
Train loss on 1050 batch: 0.262050
Train loss on 1100 batch: 0.312329
Train loss on 1150 batch: 0.224862
Train loss on 1200 batch: 0.306225
Train loss on 1250 batch: 0.220766
Train loss on 1300 batch: 0.281688
Train loss on 1350 batch: 0.260774
Train loss on 1400 batch: 0.323313
Train loss on 1450 batch: 0.249679
Train loss on 1500 batch: 0.286800
Train loss on 1550 batch: 0.301270
Train loss on 1600 batch: 0.255083
Train loss on 1650 batch: 0.262821
Train loss on 1700 batch: 0.243298
Train loss on 1750 batch: 0.266734
Train loss on 1800 batch: 0.230335
Train loss on 1850 batch: 0.254085
Train loss on 1900 batch: 0.287003
: Epoch: 31 | Training Loss: 0.265110 | Val. Loss: 0.329614 | Val. Kappa Score: 0.7046 | LR: 0.000063 | Estimated time: 520.81
Train loss on 50 batch: 0.243325
Train loss on 100 batch: 0.274028
Train loss on 150 batch: 0.283256
Train loss on 200 batch: 0.267554
Train loss on 250 batch: 0.280964
Train loss on 300 batch: 0.244972
Train loss on 350 batch: 0.255734
Train loss on 400 batch: 0.269624
Train loss on 450 batch: 0.248122
Train loss on 500 batch: 0.290339
Train loss on 550 batch: 0.262062
Train loss on 600 batch: 0.329606
Train loss on 650 batch: 0.330152
Train loss on 700 batch: 0.286645
Train loss on 750 batch: 0.248216
Train loss on 800 batch: 0.287479
Train loss on 850 batch: 0.275072
Train loss on 900 batch: 0.243420
Train loss on 950 batch: 0.285588
Train loss on 1000 batch: 0.290449
Train loss on 1050 batch: 0.306896
Train loss on 1100 batch: 0.250280
Train loss on 1150 batch: 0.241681
Train loss on 1200 batch: 0.226429
Train loss on 1250 batch: 0.273706
Train loss on 1300 batch: 0.249463
Train loss on 1350 batch: 0.290169
Train loss on 1400 batch: 0.319682
Train loss on 1450 batch: 0.257608
Train loss on 1500 batch: 0.218453
Train loss on 1550 batch: 0.277911
Train loss on 1600 batch: 0.268034
Train loss on 1650 batch: 0.266544
Train loss on 1700 batch: 0.283530
Train loss on 1750 batch: 0.227684
Train loss on 1800 batch: 0.240604
Train loss on 1850 batch: 0.232098
Train loss on 1900 batch: 0.248224
: Epoch: 32 | Training Loss: 0.266421 | Val. Loss: 0.328790 | Val. Kappa Score: 0.7058 | LR: 0.000063 | Estimated time: 520.44
Train loss on 50 batch: 0.217215
Train loss on 100 batch: 0.291720
Train loss on 150 batch: 0.252100
Train loss on 200 batch: 0.270064
Train loss on 250 batch: 0.277759
Train loss on 300 batch: 0.247217
Train loss on 350 batch: 0.280800
Train loss on 400 batch: 0.239513
Train loss on 450 batch: 0.241377
Train loss on 500 batch: 0.247699
Train loss on 550 batch: 0.251415
Train loss on 600 batch: 0.279669
Train loss on 650 batch: 0.273566
Train loss on 700 batch: 0.255718
Train loss on 750 batch: 0.242732
Train loss on 800 batch: 0.257287
Train loss on 850 batch: 0.296392
Train loss on 900 batch: 0.326492
Train loss on 950 batch: 0.248351
Train loss on 1000 batch: 0.254909
Train loss on 1050 batch: 0.249321
Train loss on 1100 batch: 0.242847
Train loss on 1150 batch: 0.269906
Train loss on 1200 batch: 0.206516
Train loss on 1250 batch: 0.254463
Train loss on 1300 batch: 0.270361
Train loss on 1350 batch: 0.236378
Train loss on 1400 batch: 0.293391
Train loss on 1450 batch: 0.327821
Train loss on 1500 batch: 0.279383
Train loss on 1550 batch: 0.296884
Train loss on 1600 batch: 0.270116
Train loss on 1650 batch: 0.290472
Train loss on 1700 batch: 0.231926
Train loss on 1750 batch: 0.284641
Train loss on 1800 batch: 0.234809
Train loss on 1850 batch: 0.254372
Train loss on 1900 batch: 0.258363
: Epoch: 33 | Training Loss: 0.262955 | Val. Loss: 0.325057 | Val. Kappa Score: 0.7071 | LR: 0.000031 | Estimated time: 519.36
Train loss on 50 batch: 0.238116
Train loss on 100 batch: 0.276826
Train loss on 150 batch: 0.273411
Train loss on 200 batch: 0.253931
Train loss on 250 batch: 0.221232
Train loss on 300 batch: 0.261675
Train loss on 350 batch: 0.218570
Train loss on 400 batch: 0.282783
Train loss on 450 batch: 0.241789
Train loss on 500 batch: 0.261077
Train loss on 550 batch: 0.251190
Train loss on 600 batch: 0.266597
Train loss on 650 batch: 0.271145
Train loss on 700 batch: 0.256174
Train loss on 750 batch: 0.255390
Train loss on 800 batch: 0.278611
Train loss on 850 batch: 0.254782
Train loss on 900 batch: 0.301333
Train loss on 950 batch: 0.284792
Train loss on 1000 batch: 0.326725
Train loss on 1050 batch: 0.253981
Train loss on 1100 batch: 0.299637
Train loss on 1150 batch: 0.268528
Train loss on 1200 batch: 0.270426
Train loss on 1250 batch: 0.289032
Train loss on 1300 batch: 0.235934
Train loss on 1350 batch: 0.242677
Train loss on 1400 batch: 0.242736
Train loss on 1450 batch: 0.267344
Train loss on 1500 batch: 0.240318
Train loss on 1550 batch: 0.288816
Train loss on 1600 batch: 0.205924
Train loss on 1650 batch: 0.229193
Train loss on 1700 batch: 0.252734
Train loss on 1750 batch: 0.234089
Train loss on 1800 batch: 0.245482
Train loss on 1850 batch: 0.199366
Train loss on 1900 batch: 0.239286
: Epoch: 34 | Training Loss: 0.257587 | Val. Loss: 0.324787 | Val. Kappa Score: 0.7085 | LR: 0.000031 | Estimated time: 512.75
Train loss on 50 batch: 0.205460
Train loss on 100 batch: 0.261366
Train loss on 150 batch: 0.223611
Train loss on 200 batch: 0.263121
Train loss on 250 batch: 0.225088
Train loss on 300 batch: 0.242825
Train loss on 350 batch: 0.251887
Train loss on 400 batch: 0.261585
Train loss on 450 batch: 0.251454
Train loss on 500 batch: 0.245826
Train loss on 550 batch: 0.227613
Train loss on 600 batch: 0.269010
Train loss on 650 batch: 0.251535
Train loss on 700 batch: 0.264734
Train loss on 750 batch: 0.282034
Train loss on 800 batch: 0.270945
Train loss on 850 batch: 0.279981
Train loss on 900 batch: 0.276314
Train loss on 950 batch: 0.292993
Train loss on 1000 batch: 0.269436
Train loss on 1050 batch: 0.259726
Train loss on 1100 batch: 0.288101
Train loss on 1150 batch: 0.226875
Train loss on 1200 batch: 0.325686
Train loss on 1250 batch: 0.267086
Train loss on 1300 batch: 0.260068
Train loss on 1350 batch: 0.276461
Train loss on 1400 batch: 0.219501
Train loss on 1450 batch: 0.253128
Train loss on 1500 batch: 0.222884
Train loss on 1550 batch: 0.253312
Train loss on 1600 batch: 0.269540
Train loss on 1650 batch: 0.258397
Train loss on 1700 batch: 0.233477
Train loss on 1750 batch: 0.319352
Train loss on 1800 batch: 0.288823
Train loss on 1850 batch: 0.240434
Train loss on 1900 batch: 0.224865
: Epoch: 35 | Training Loss: 0.257186 | Val. Loss: 0.327707 | Val. Kappa Score: 0.7098 | LR: 0.000031 | Estimated time: 513.69
Train loss on 50 batch: 0.289491
Train loss on 100 batch: 0.221982
Train loss on 150 batch: 0.305952
Train loss on 200 batch: 0.221849
Train loss on 250 batch: 0.292939
Train loss on 300 batch: 0.236760
Train loss on 350 batch: 0.266563
Train loss on 400 batch: 0.248489
Train loss on 450 batch: 0.205302
Train loss on 500 batch: 0.250905
Train loss on 550 batch: 0.266791
Train loss on 600 batch: 0.238669
Train loss on 650 batch: 0.244458
Train loss on 700 batch: 0.290918
Train loss on 750 batch: 0.239530
Train loss on 800 batch: 0.258312
Train loss on 850 batch: 0.248049
Train loss on 900 batch: 0.268976
Train loss on 950 batch: 0.226449
Train loss on 1000 batch: 0.286448
Train loss on 1050 batch: 0.249353
Train loss on 1100 batch: 0.253296
Train loss on 1150 batch: 0.247586
Train loss on 1200 batch: 0.262894
Train loss on 1250 batch: 0.256581
Train loss on 1300 batch: 0.255446
Train loss on 1350 batch: 0.212514
Train loss on 1400 batch: 0.270476
Train loss on 1450 batch: 0.254355
Train loss on 1500 batch: 0.300111
Train loss on 1550 batch: 0.254334
Train loss on 1600 batch: 0.325617
Train loss on 1650 batch: 0.247044
Train loss on 1700 batch: 0.286659
Train loss on 1750 batch: 0.249501
Train loss on 1800 batch: 0.241376
Train loss on 1850 batch: 0.258419
Train loss on 1900 batch: 0.238417
: Epoch: 36 | Training Loss: 0.258315 | Val. Loss: 0.326005 | Val. Kappa Score: 0.7108 | LR: 0.000016 | Estimated time: 515.24
Train loss on 50 batch: 0.218494
Train loss on 100 batch: 0.295118
Train loss on 150 batch: 0.265708
Train loss on 200 batch: 0.260362
Train loss on 250 batch: 0.308526
Train loss on 300 batch: 0.271636
Train loss on 350 batch: 0.285964
Train loss on 400 batch: 0.239393
Train loss on 450 batch: 0.264024
Train loss on 500 batch: 0.251411
Train loss on 550 batch: 0.241299
Train loss on 600 batch: 0.250047
Train loss on 650 batch: 0.257014
Train loss on 700 batch: 0.233026
Train loss on 750 batch: 0.258369
Train loss on 800 batch: 0.279318
Train loss on 850 batch: 0.210205
Train loss on 900 batch: 0.270536
Train loss on 950 batch: 0.253749
Train loss on 1000 batch: 0.243938
Train loss on 1050 batch: 0.233289
Train loss on 1100 batch: 0.233141
Train loss on 1150 batch: 0.241027
Train loss on 1200 batch: 0.256772
Train loss on 1250 batch: 0.302130
Train loss on 1300 batch: 0.243934
Train loss on 1350 batch: 0.237403
Train loss on 1400 batch: 0.240547
Train loss on 1450 batch: 0.300364
Train loss on 1500 batch: 0.214576
Train loss on 1550 batch: 0.236936
Train loss on 1600 batch: 0.307550
Train loss on 1650 batch: 0.291056
Train loss on 1700 batch: 0.269241
Train loss on 1750 batch: 0.280454
Train loss on 1800 batch: 0.225576
Train loss on 1850 batch: 0.276806
Train loss on 1900 batch: 0.223207
: Epoch: 37 | Training Loss: 0.256109 | Val. Loss: 0.326008 | Val. Kappa Score: 0.7119 | LR: 0.000016 | Estimated time: 513.00
Train loss on 50 batch: 0.265446
Train loss on 100 batch: 0.277793
Train loss on 150 batch: 0.204898
Train loss on 200 batch: 0.280804
Train loss on 250 batch: 0.233654
Train loss on 300 batch: 0.273698
Train loss on 350 batch: 0.245243
Train loss on 400 batch: 0.220754
Train loss on 450 batch: 0.258941
Train loss on 500 batch: 0.265887
Train loss on 550 batch: 0.287181
Train loss on 600 batch: 0.232744
Train loss on 650 batch: 0.264550
Train loss on 700 batch: 0.260267
Train loss on 750 batch: 0.249654
Train loss on 800 batch: 0.270626
Train loss on 850 batch: 0.207291
Train loss on 900 batch: 0.302611
Train loss on 950 batch: 0.268205
Train loss on 1000 batch: 0.275034
Train loss on 1050 batch: 0.244237
Train loss on 1100 batch: 0.265262
Train loss on 1150 batch: 0.225420
Train loss on 1200 batch: 0.268497
Train loss on 1250 batch: 0.213486
Train loss on 1300 batch: 0.272980
Train loss on 1350 batch: 0.264011
Train loss on 1400 batch: 0.240392
Train loss on 1450 batch: 0.227058
Train loss on 1500 batch: 0.247401
Train loss on 1550 batch: 0.283383
Train loss on 1600 batch: 0.289804
Train loss on 1650 batch: 0.281587
Train loss on 1700 batch: 0.241920
Train loss on 1750 batch: 0.254033
Train loss on 1800 batch: 0.237381
Train loss on 1850 batch: 0.247720
Train loss on 1900 batch: 0.242212
: Epoch: 38 | Training Loss: 0.254973 | Val. Loss: 0.327114 | Val. Kappa Score: 0.7127 | LR: 0.000016 | Estimated time: 510.96
time_estimated: 19559.31
n-epochs: 38
time_estimated: 19559.33
----------------------------------------

Experiment N: 70: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 02:29:18
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb982c3c50>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.891625
Train loss on 100 batch: 0.995091
Train loss on 150 batch: 0.878878
Train loss on 200 batch: 0.746050
Train loss on 250 batch: 0.831310
best-train-loss: 0.979291
best-valid-loss: 0.604610
best-kappa: 0.7763
: Epoch: 1 | Training Loss: 0.979291 | Val. Loss: 0.604610 | Val. Kappa Score: 0.7763 | LR: 0.001000 | Estimated time: 67.88
Train loss on 50 batch: 0.643075
Train loss on 100 batch: 0.681082
Train loss on 150 batch: 0.664460
Train loss on 200 batch: 0.752132
Train loss on 250 batch: 0.670417
best-train-loss: 0.670204
best-valid-loss: 0.554538
best-kappa: 0.7800
: Epoch: 2 | Training Loss: 0.670204 | Val. Loss: 0.554538 | Val. Kappa Score: 0.7800 | LR: 0.001000 | Estimated time: 67.86
Train loss on 50 batch: 0.662841
Train loss on 100 batch: 0.562415
Train loss on 150 batch: 0.632401
Train loss on 200 batch: 0.586100
Train loss on 250 batch: 0.531546
best-train-loss: 0.552332
best-valid-loss: 0.531984
best-kappa: 0.7832
: Epoch: 3 | Training Loss: 0.552332 | Val. Loss: 0.531984 | Val. Kappa Score: 0.7832 | LR: 0.001000 | Estimated time: 69.68
Train loss on 50 batch: 0.500668
Train loss on 100 batch: 0.525190
Train loss on 150 batch: 0.575038
Train loss on 200 batch: 0.577615
Train loss on 250 batch: 0.556531
: Epoch: 4 | Training Loss: 0.534944 | Val. Loss: 0.611464 | Val. Kappa Score: 0.7927 | LR: 0.001000 | Estimated time: 67.84
Train loss on 50 batch: 0.481066
Train loss on 100 batch: 0.581677
Train loss on 150 batch: 0.475004
Train loss on 200 batch: 0.586186
Train loss on 250 batch: 0.509981
best-train-loss: 0.508080
best-valid-loss: 0.504267
best-kappa: 0.7997
: Epoch: 5 | Training Loss: 0.508080 | Val. Loss: 0.504267 | Val. Kappa Score: 0.7997 | LR: 0.001000 | Estimated time: 67.84
Train loss on 50 batch: 0.462945
Train loss on 100 batch: 0.534949
Train loss on 150 batch: 0.547648
Train loss on 200 batch: 0.504041
Train loss on 250 batch: 0.497458
best-train-loss: 0.530845
best-valid-loss: 0.479769
best-kappa: 0.8051
: Epoch: 6 | Training Loss: 0.530845 | Val. Loss: 0.479769 | Val. Kappa Score: 0.8051 | LR: 0.001000 | Estimated time: 70.06
Train loss on 50 batch: 0.438476
Train loss on 100 batch: 0.459465
Train loss on 150 batch: 0.556598
Train loss on 200 batch: 0.434649
Train loss on 250 batch: 0.522402
best-train-loss: 0.464138
best-valid-loss: 0.455220
best-kappa: 0.8110
: Epoch: 7 | Training Loss: 0.464138 | Val. Loss: 0.455220 | Val. Kappa Score: 0.8110 | LR: 0.001000 | Estimated time: 71.63
Train loss on 50 batch: 0.411742
Train loss on 100 batch: 0.460404
Train loss on 150 batch: 0.493020
Train loss on 200 batch: 0.513714
Train loss on 250 batch: 0.451653
: Epoch: 8 | Training Loss: 0.473190 | Val. Loss: 0.525254 | Val. Kappa Score: 0.8136 | LR: 0.001000 | Estimated time: 74.81
Train loss on 50 batch: 0.482040
Train loss on 100 batch: 0.517748
Train loss on 150 batch: 0.524841
Train loss on 200 batch: 0.419477
Train loss on 250 batch: 0.464567
: Epoch: 9 | Training Loss: 0.439309 | Val. Loss: 0.553083 | Val. Kappa Score: 0.8152 | LR: 0.001000 | Estimated time: 75.09
Train loss on 50 batch: 0.467233
Train loss on 100 batch: 0.504575
Train loss on 150 batch: 0.455645
Train loss on 200 batch: 0.423548
Train loss on 250 batch: 0.434042
: Epoch: 10 | Training Loss: 0.448617 | Val. Loss: 0.462233 | Val. Kappa Score: 0.8194 | LR: 0.000500 | Estimated time: 72.81
Train loss on 50 batch: 0.398855
Train loss on 100 batch: 0.359508
Train loss on 150 batch: 0.323860
Train loss on 200 batch: 0.319499
Train loss on 250 batch: 0.349392
best-train-loss: 0.347354
best-valid-loss: 0.353046
best-kappa: 0.8244
: Epoch: 11 | Training Loss: 0.347354 | Val. Loss: 0.353046 | Val. Kappa Score: 0.8244 | LR: 0.000500 | Estimated time: 72.19
Train loss on 50 batch: 0.310507
Train loss on 100 batch: 0.300769
Train loss on 150 batch: 0.307606
Train loss on 200 batch: 0.312264
Train loss on 250 batch: 0.321905
best-train-loss: 0.341300
best-valid-loss: 0.350929
best-kappa: 0.8287
: Epoch: 12 | Training Loss: 0.341300 | Val. Loss: 0.350929 | Val. Kappa Score: 0.8287 | LR: 0.000500 | Estimated time: 71.48
Train loss on 50 batch: 0.304484
Train loss on 100 batch: 0.326925
Train loss on 150 batch: 0.293957
Train loss on 200 batch: 0.296686
Train loss on 250 batch: 0.312745
: Epoch: 13 | Training Loss: 0.289915 | Val. Loss: 0.363973 | Val. Kappa Score: 0.8327 | LR: 0.000500 | Estimated time: 71.41
Train loss on 50 batch: 0.289681
Train loss on 100 batch: 0.284977
Train loss on 150 batch: 0.243719
Train loss on 200 batch: 0.301081
Train loss on 250 batch: 0.320048
best-train-loss: 0.344491
best-valid-loss: 0.347493
best-kappa: 0.8359
: Epoch: 14 | Training Loss: 0.344491 | Val. Loss: 0.347493 | Val. Kappa Score: 0.8359 | LR: 0.000500 | Estimated time: 71.41
Train loss on 50 batch: 0.273570
Train loss on 100 batch: 0.273649
Train loss on 150 batch: 0.309608
Train loss on 200 batch: 0.246579
Train loss on 250 batch: 0.304625
: Epoch: 15 | Training Loss: 0.258654 | Val. Loss: 0.388586 | Val. Kappa Score: 0.8384 | LR: 0.000500 | Estimated time: 71.45
Train loss on 50 batch: 0.254057
Train loss on 100 batch: 0.242308
Train loss on 150 batch: 0.247760
Train loss on 200 batch: 0.296950
Train loss on 250 batch: 0.268237
: Epoch: 16 | Training Loss: 0.253754 | Val. Loss: 0.451034 | Val. Kappa Score: 0.8392 | LR: 0.000500 | Estimated time: 71.62
Train loss on 50 batch: 0.244123
Train loss on 100 batch: 0.300386
Train loss on 150 batch: 0.251358
Train loss on 200 batch: 0.284752
Train loss on 250 batch: 0.300067
: Epoch: 17 | Training Loss: 0.278733 | Val. Loss: 0.394453 | Val. Kappa Score: 0.8410 | LR: 0.000250 | Estimated time: 71.41
Train loss on 50 batch: 0.243368
Train loss on 100 batch: 0.206804
Train loss on 150 batch: 0.255906
Train loss on 200 batch: 0.186173
Train loss on 250 batch: 0.223156
best-train-loss: 0.203247
best-valid-loss: 0.329946
best-kappa: 0.8437
: Epoch: 18 | Training Loss: 0.203247 | Val. Loss: 0.329946 | Val. Kappa Score: 0.8437 | LR: 0.000250 | Estimated time: 71.51
Train loss on 50 batch: 0.192715
Train loss on 100 batch: 0.171650
Train loss on 150 batch: 0.199207
Train loss on 200 batch: 0.198948
Train loss on 250 batch: 0.203808
: Epoch: 19 | Training Loss: 0.193280 | Val. Loss: 0.340330 | Val. Kappa Score: 0.8459 | LR: 0.000250 | Estimated time: 71.39
Train loss on 50 batch: 0.211366
Train loss on 100 batch: 0.168854
Train loss on 150 batch: 0.168189
Train loss on 200 batch: 0.181088
Train loss on 250 batch: 0.164498
: Epoch: 20 | Training Loss: 0.194434 | Val. Loss: 0.377360 | Val. Kappa Score: 0.8472 | LR: 0.000250 | Estimated time: 71.49
Train loss on 50 batch: 0.225466
Train loss on 100 batch: 0.191941
Train loss on 150 batch: 0.154882
Train loss on 200 batch: 0.207792
Train loss on 250 batch: 0.155860
best-train-loss: 0.171644
best-valid-loss: 0.327822
best-kappa: 0.8490
: Epoch: 21 | Training Loss: 0.171644 | Val. Loss: 0.327822 | Val. Kappa Score: 0.8490 | LR: 0.000250 | Estimated time: 71.51
Train loss on 50 batch: 0.149393
Train loss on 100 batch: 0.142115
Train loss on 150 batch: 0.166778
Train loss on 200 batch: 0.155434
Train loss on 250 batch: 0.196776
: Epoch: 22 | Training Loss: 0.155140 | Val. Loss: 0.336519 | Val. Kappa Score: 0.8510 | LR: 0.000250 | Estimated time: 71.42
Train loss on 50 batch: 0.169151
Train loss on 100 batch: 0.170298
Train loss on 150 batch: 0.164060
Train loss on 200 batch: 0.141952
Train loss on 250 batch: 0.183256
: Epoch: 23 | Training Loss: 0.153130 | Val. Loss: 0.371066 | Val. Kappa Score: 0.8522 | LR: 0.000250 | Estimated time: 71.42
Train loss on 50 batch: 0.187493
Train loss on 100 batch: 0.168623
Train loss on 150 batch: 0.144415
Train loss on 200 batch: 0.138814
Train loss on 250 batch: 0.170655
: Epoch: 24 | Training Loss: 0.149758 | Val. Loss: 0.361764 | Val. Kappa Score: 0.8534 | LR: 0.000125 | Estimated time: 71.44
Train loss on 50 batch: 0.146961
Train loss on 100 batch: 0.139379
Train loss on 150 batch: 0.108819
Train loss on 200 batch: 0.160024
Train loss on 250 batch: 0.127427
: Epoch: 25 | Training Loss: 0.145565 | Val. Loss: 0.338640 | Val. Kappa Score: 0.8548 | LR: 0.000125 | Estimated time: 71.56
Train loss on 50 batch: 0.141095
Train loss on 100 batch: 0.132120
Train loss on 150 batch: 0.129681
Train loss on 200 batch: 0.096902
Train loss on 250 batch: 0.123059
best-train-loss: 0.153031
best-valid-loss: 0.318249
best-kappa: 0.8564
: Epoch: 26 | Training Loss: 0.153031 | Val. Loss: 0.318249 | Val. Kappa Score: 0.8564 | LR: 0.000125 | Estimated time: 71.46
Train loss on 50 batch: 0.098967
Train loss on 100 batch: 0.121469
Train loss on 150 batch: 0.108960
Train loss on 200 batch: 0.107676
Train loss on 250 batch: 0.115841
: Epoch: 27 | Training Loss: 0.121934 | Val. Loss: 0.323693 | Val. Kappa Score: 0.8577 | LR: 0.000125 | Estimated time: 71.44
Train loss on 50 batch: 0.114177
Train loss on 100 batch: 0.114851
Train loss on 150 batch: 0.092007
Train loss on 200 batch: 0.096930
Train loss on 250 batch: 0.104443
: Epoch: 28 | Training Loss: 0.098738 | Val. Loss: 0.349778 | Val. Kappa Score: 0.8586 | LR: 0.000125 | Estimated time: 71.56
Train loss on 50 batch: 0.106046
Train loss on 100 batch: 0.104326
Train loss on 150 batch: 0.108969
Train loss on 200 batch: 0.095435
Train loss on 250 batch: 0.124000
: Epoch: 29 | Training Loss: 0.122945 | Val. Loss: 0.318680 | Val. Kappa Score: 0.8597 | LR: 0.000063 | Estimated time: 71.54
Train loss on 50 batch: 0.110479
Train loss on 100 batch: 0.095959
Train loss on 150 batch: 0.081952
Train loss on 200 batch: 0.090525
Train loss on 250 batch: 0.086510
: Epoch: 30 | Training Loss: 0.089613 | Val. Loss: 0.327235 | Val. Kappa Score: 0.8607 | LR: 0.000063 | Estimated time: 71.50
Train loss on 50 batch: 0.077955
Train loss on 100 batch: 0.079926
Train loss on 150 batch: 0.083768
Train loss on 200 batch: 0.086695
Train loss on 250 batch: 0.102499
: Epoch: 31 | Training Loss: 0.083465 | Val. Loss: 0.331982 | Val. Kappa Score: 0.8616 | LR: 0.000063 | Estimated time: 71.66
Train loss on 50 batch: 0.081749
Train loss on 100 batch: 0.073778
Train loss on 150 batch: 0.093976
Train loss on 200 batch: 0.081286
Train loss on 250 batch: 0.086500
: Epoch: 32 | Training Loss: 0.136769 | Val. Loss: 0.331287 | Val. Kappa Score: 0.8624 | LR: 0.000031 | Estimated time: 71.50
Train loss on 50 batch: 0.071115
Train loss on 100 batch: 0.074310
Train loss on 150 batch: 0.085327
Train loss on 200 batch: 0.076348
Train loss on 250 batch: 0.093802
: Epoch: 33 | Training Loss: 0.091534 | Val. Loss: 0.323835 | Val. Kappa Score: 0.8632 | LR: 0.000031 | Estimated time: 71.50
Train loss on 50 batch: 0.086206
Train loss on 100 batch: 0.087713
Train loss on 150 batch: 0.071946
Train loss on 200 batch: 0.072087
Train loss on 250 batch: 0.075863
: Epoch: 34 | Training Loss: 0.070960 | Val. Loss: 0.327382 | Val. Kappa Score: 0.8641 | LR: 0.000031 | Estimated time: 71.55
time_estimated: 2423.57
n-epochs: 34
time_estimated: 2423.59
----------------------------------------

Experiment N: 71: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 03:09:42
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fe6e80>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 71: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 08:22:11
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f9ab00>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.368347
Train loss on 100 batch: 1.216330
Train loss on 150 batch: 1.142963
Train loss on 200 batch: 1.106994
Train loss on 250 batch: 1.233004
best-train-loss: 1.348667
best-valid-loss: 1.405278
best-kappa: 0.3893
: Epoch: 1 | Training Loss: 1.348667 | Val. Loss: 1.405278 | Val. Kappa Score: 0.3893 | LR: 0.005000 | Estimated time: 75.33
Train loss on 50 batch: 0.939453
Train loss on 100 batch: 0.989468
Train loss on 150 batch: 0.878401
Train loss on 200 batch: 0.940634
Train loss on 250 batch: 0.909685
best-train-loss: 0.992111
best-valid-loss: 0.778787
best-kappa: 0.5232
: Epoch: 2 | Training Loss: 0.992111 | Val. Loss: 0.778787 | Val. Kappa Score: 0.5232 | LR: 0.005000 | Estimated time: 75.06
Train loss on 50 batch: 0.892974
Train loss on 100 batch: 0.733999
Train loss on 150 batch: 0.944543
Train loss on 200 batch: 0.836224
Train loss on 250 batch: 0.793362
: Epoch: 3 | Training Loss: 0.832028 | Val. Loss: 1.582654 | Val. Kappa Score: 0.5208 | LR: 0.005000 | Estimated time: 74.97
Train loss on 50 batch: 0.740960
Train loss on 100 batch: 0.772585
Train loss on 150 batch: 0.837898
Train loss on 200 batch: 0.910687
Train loss on 250 batch: 0.809975
: Epoch: 4 | Training Loss: 0.826622 | Val. Loss: 1.170696 | Val. Kappa Score: 0.5261 | LR: 0.005000 | Estimated time: 74.90
Train loss on 50 batch: 0.750931
Train loss on 100 batch: 0.850656
Train loss on 150 batch: 0.640391
Train loss on 200 batch: 0.818238
Train loss on 250 batch: 0.790298
: Epoch: 5 | Training Loss: 0.783904 | Val. Loss: 1.032394 | Val. Kappa Score: 0.5626 | LR: 0.002500 | Estimated time: 74.98
Train loss on 50 batch: 0.660770
Train loss on 100 batch: 0.682398
Train loss on 150 batch: 0.663506
Train loss on 200 batch: 0.621211
Train loss on 250 batch: 0.550666
best-train-loss: 0.642677
best-valid-loss: 0.465892
best-kappa: 0.6058
: Epoch: 6 | Training Loss: 0.642677 | Val. Loss: 0.465892 | Val. Kappa Score: 0.6058 | LR: 0.002500 | Estimated time: 74.91
Train loss on 50 batch: 0.617012
Train loss on 100 batch: 0.528066
Train loss on 150 batch: 0.626388
Train loss on 200 batch: 0.554268
Train loss on 250 batch: 0.643292
: Epoch: 7 | Training Loss: 0.628771 | Val. Loss: 0.484119 | Val. Kappa Score: 0.6387 | LR: 0.002500 | Estimated time: 73.15
Train loss on 50 batch: 0.555152
Train loss on 100 batch: 0.625793
Train loss on 150 batch: 0.646810
Train loss on 200 batch: 0.693416
Train loss on 250 batch: 0.478649
: Epoch: 8 | Training Loss: 0.582497 | Val. Loss: 0.504515 | Val. Kappa Score: 0.6624 | LR: 0.002500 | Estimated time: 71.37
Train loss on 50 batch: 0.545594
Train loss on 100 batch: 0.608266
Train loss on 150 batch: 0.655374
Train loss on 200 batch: 0.535910
Train loss on 250 batch: 0.533435
: Epoch: 9 | Training Loss: 0.536064 | Val. Loss: 0.603502 | Val. Kappa Score: 0.6767 | LR: 0.001250 | Estimated time: 71.41
Train loss on 50 batch: 0.480024
Train loss on 100 batch: 0.570698
Train loss on 150 batch: 0.485562
Train loss on 200 batch: 0.439962
Train loss on 250 batch: 0.421451
best-train-loss: 0.483032
best-valid-loss: 0.460848
best-kappa: 0.6936
: Epoch: 10 | Training Loss: 0.483032 | Val. Loss: 0.460848 | Val. Kappa Score: 0.6936 | LR: 0.001250 | Estimated time: 71.35
Train loss on 50 batch: 0.463683
Train loss on 100 batch: 0.484546
Train loss on 150 batch: 0.454592
Train loss on 200 batch: 0.459959
Train loss on 250 batch: 0.463467
best-train-loss: 0.461788
best-valid-loss: 0.440001
best-kappa: 0.7068
: Epoch: 11 | Training Loss: 0.461788 | Val. Loss: 0.440001 | Val. Kappa Score: 0.7068 | LR: 0.001250 | Estimated time: 71.47
Train loss on 50 batch: 0.470557
Train loss on 100 batch: 0.453049
Train loss on 150 batch: 0.443912
Train loss on 200 batch: 0.539627
Train loss on 250 batch: 0.470855
best-train-loss: 0.515918
best-valid-loss: 0.436281
best-kappa: 0.7188
: Epoch: 12 | Training Loss: 0.515918 | Val. Loss: 0.436281 | Val. Kappa Score: 0.7188 | LR: 0.001250 | Estimated time: 71.42
Train loss on 50 batch: 0.455929
Train loss on 100 batch: 0.484548
Train loss on 150 batch: 0.416254
Train loss on 200 batch: 0.446115
Train loss on 250 batch: 0.459163
: Epoch: 13 | Training Loss: 0.420206 | Val. Loss: 0.481268 | Val. Kappa Score: 0.7285 | LR: 0.001250 | Estimated time: 71.34
Train loss on 50 batch: 0.416180
Train loss on 100 batch: 0.424075
Train loss on 150 batch: 0.391327
Train loss on 200 batch: 0.482367
Train loss on 250 batch: 0.484031
: Epoch: 14 | Training Loss: 0.494678 | Val. Loss: 0.569416 | Val. Kappa Score: 0.7363 | LR: 0.001250 | Estimated time: 71.45
Train loss on 50 batch: 0.401487
Train loss on 100 batch: 0.478123
Train loss on 150 batch: 0.499954
Train loss on 200 batch: 0.398840
Train loss on 250 batch: 0.493365
best-train-loss: 0.431008
best-valid-loss: 0.431903
best-kappa: 0.7439
: Epoch: 15 | Training Loss: 0.431008 | Val. Loss: 0.431903 | Val. Kappa Score: 0.7439 | LR: 0.001250 | Estimated time: 71.42
Train loss on 50 batch: 0.442935
Train loss on 100 batch: 0.405408
Train loss on 150 batch: 0.390643
Train loss on 200 batch: 0.469294
Train loss on 250 batch: 0.409083
: Epoch: 16 | Training Loss: 0.411761 | Val. Loss: 0.452920 | Val. Kappa Score: 0.7497 | LR: 0.001250 | Estimated time: 71.37
Train loss on 50 batch: 0.408550
Train loss on 100 batch: 0.447098
Train loss on 150 batch: 0.406604
Train loss on 200 batch: 0.435402
Train loss on 250 batch: 0.477468
: Epoch: 17 | Training Loss: 0.447104 | Val. Loss: 0.592802 | Val. Kappa Score: 0.7542 | LR: 0.001250 | Estimated time: 71.40
Train loss on 50 batch: 0.464755
Train loss on 100 batch: 0.416877
Train loss on 150 batch: 0.446540
Train loss on 200 batch: 0.403709
Train loss on 250 batch: 0.427201
: Epoch: 18 | Training Loss: 0.400284 | Val. Loss: 0.490764 | Val. Kappa Score: 0.7589 | LR: 0.000625 | Estimated time: 71.44
Train loss on 50 batch: 0.377196
Train loss on 100 batch: 0.373187
Train loss on 150 batch: 0.375523
Train loss on 200 batch: 0.394283
Train loss on 250 batch: 0.403823
best-train-loss: 0.357887
best-valid-loss: 0.411150
best-kappa: 0.7644
: Epoch: 19 | Training Loss: 0.357887 | Val. Loss: 0.411150 | Val. Kappa Score: 0.7644 | LR: 0.000625 | Estimated time: 71.42
Train loss on 50 batch: 0.395501
Train loss on 100 batch: 0.338011
Train loss on 150 batch: 0.354455
Train loss on 200 batch: 0.341822
Train loss on 250 batch: 0.335836
best-train-loss: 0.339432
best-valid-loss: 0.385829
best-kappa: 0.7693
: Epoch: 20 | Training Loss: 0.339432 | Val. Loss: 0.385829 | Val. Kappa Score: 0.7693 | LR: 0.000625 | Estimated time: 72.47
Train loss on 50 batch: 0.374501
Train loss on 100 batch: 0.387737
Train loss on 150 batch: 0.328235
Train loss on 200 batch: 0.362880
Train loss on 250 batch: 0.320836
: Epoch: 21 | Training Loss: 0.323194 | Val. Loss: 0.430186 | Val. Kappa Score: 0.7736 | LR: 0.000625 | Estimated time: 70.73
Train loss on 50 batch: 0.339559
Train loss on 100 batch: 0.320058
Train loss on 150 batch: 0.350210
Train loss on 200 batch: 0.332427
Train loss on 250 batch: 0.365248
: Epoch: 22 | Training Loss: 0.312540 | Val. Loss: 0.397592 | Val. Kappa Score: 0.7777 | LR: 0.000625 | Estimated time: 70.69
Train loss on 50 batch: 0.376527
Train loss on 100 batch: 0.357535
Train loss on 150 batch: 0.339766
Train loss on 200 batch: 0.305354
Train loss on 250 batch: 0.358700
: Epoch: 23 | Training Loss: 0.341057 | Val. Loss: 0.388268 | Val. Kappa Score: 0.7814 | LR: 0.000313 | Estimated time: 68.51
Train loss on 50 batch: 0.328558
Train loss on 100 batch: 0.316413
Train loss on 150 batch: 0.294725
Train loss on 200 batch: 0.321058
Train loss on 250 batch: 0.333647
best-train-loss: 0.291784
best-valid-loss: 0.367151
best-kappa: 0.7853
: Epoch: 24 | Training Loss: 0.291784 | Val. Loss: 0.367151 | Val. Kappa Score: 0.7853 | LR: 0.000313 | Estimated time: 68.07
Train loss on 50 batch: 0.306387
Train loss on 100 batch: 0.318995
Train loss on 150 batch: 0.254051
Train loss on 200 batch: 0.331590
Train loss on 250 batch: 0.256584
: Epoch: 25 | Training Loss: 0.303708 | Val. Loss: 0.390177 | Val. Kappa Score: 0.7890 | LR: 0.000313 | Estimated time: 67.80
Train loss on 50 batch: 0.250244
Train loss on 100 batch: 0.326627
Train loss on 150 batch: 0.270105
Train loss on 200 batch: 0.271788
Train loss on 250 batch: 0.282346
: Epoch: 26 | Training Loss: 0.295021 | Val. Loss: 0.383558 | Val. Kappa Score: 0.7922 | LR: 0.000313 | Estimated time: 67.23
Train loss on 50 batch: 0.286564
Train loss on 100 batch: 0.287961
Train loss on 150 batch: 0.317552
Train loss on 200 batch: 0.246783
Train loss on 250 batch: 0.313325
best-train-loss: 0.308341
best-valid-loss: 0.366864
best-kappa: 0.7952
: Epoch: 27 | Training Loss: 0.308341 | Val. Loss: 0.366864 | Val. Kappa Score: 0.7952 | LR: 0.000313 | Estimated time: 67.31
Train loss on 50 batch: 0.276226
Train loss on 100 batch: 0.305334
Train loss on 150 batch: 0.275831
Train loss on 200 batch: 0.259727
Train loss on 250 batch: 0.294164
best-train-loss: 0.264053
best-valid-loss: 0.352941
best-kappa: 0.7980
: Epoch: 28 | Training Loss: 0.264053 | Val. Loss: 0.352941 | Val. Kappa Score: 0.7980 | LR: 0.000313 | Estimated time: 67.24
Train loss on 50 batch: 0.244971
Train loss on 100 batch: 0.282147
Train loss on 150 batch: 0.291679
Train loss on 200 batch: 0.265846
Train loss on 250 batch: 0.292869
: Epoch: 29 | Training Loss: 0.277186 | Val. Loss: 0.360359 | Val. Kappa Score: 0.8006 | LR: 0.000313 | Estimated time: 67.25
Train loss on 50 batch: 0.271631
Train loss on 100 batch: 0.254586
Train loss on 150 batch: 0.286442
Train loss on 200 batch: 0.267023
Train loss on 250 batch: 0.246143
: Epoch: 30 | Training Loss: 0.255453 | Val. Loss: 0.402580 | Val. Kappa Score: 0.8031 | LR: 0.000313 | Estimated time: 67.31
Train loss on 50 batch: 0.219670
Train loss on 100 batch: 0.247205
Train loss on 150 batch: 0.261404
Train loss on 200 batch: 0.298029
Train loss on 250 batch: 0.289220
: Epoch: 31 | Training Loss: 0.263581 | Val. Loss: 0.431704 | Val. Kappa Score: 0.8050 | LR: 0.000156 | Estimated time: 67.42
Train loss on 50 batch: 0.262477
Train loss on 100 batch: 0.215117
Train loss on 150 batch: 0.287312
Train loss on 200 batch: 0.262254
Train loss on 250 batch: 0.243766
: Epoch: 32 | Training Loss: 0.337038 | Val. Loss: 0.365565 | Val. Kappa Score: 0.8072 | LR: 0.000156 | Estimated time: 67.28
Train loss on 50 batch: 0.265873
Train loss on 100 batch: 0.240586
Train loss on 150 batch: 0.227708
Train loss on 200 batch: 0.227463
Train loss on 250 batch: 0.249607
: Epoch: 33 | Training Loss: 0.262544 | Val. Loss: 0.368684 | Val. Kappa Score: 0.8091 | LR: 0.000156 | Estimated time: 67.29
Train loss on 50 batch: 0.203475
Train loss on 100 batch: 0.249694
Train loss on 150 batch: 0.265779
Train loss on 200 batch: 0.218929
Train loss on 250 batch: 0.232015
: Epoch: 34 | Training Loss: 0.217548 | Val. Loss: 0.381971 | Val. Kappa Score: 0.8111 | LR: 0.000078 | Estimated time: 67.35
Train loss on 50 batch: 0.230462
Train loss on 100 batch: 0.251451
Train loss on 150 batch: 0.246118
Train loss on 200 batch: 0.196103
Train loss on 250 batch: 0.206430
: Epoch: 35 | Training Loss: 0.207322 | Val. Loss: 0.379156 | Val. Kappa Score: 0.8128 | LR: 0.000078 | Estimated time: 67.37
Train loss on 50 batch: 0.223603
Train loss on 100 batch: 0.226721
Train loss on 150 batch: 0.242606
Train loss on 200 batch: 0.202181
Train loss on 250 batch: 0.230470
: Epoch: 36 | Training Loss: 0.219255 | Val. Loss: 0.379517 | Val. Kappa Score: 0.8146 | LR: 0.000078 | Estimated time: 67.43
time_estimated: 2540.54
n-epochs: 36
time_estimated: 2540.56
----------------------------------------

Experiment N: 72: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 09:04:32
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e92eb8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 3.378379
Train loss on 100 batch: 1.894096
Train loss on 150 batch: 1.760618
Train loss on 200 batch: 1.600127
Train loss on 250 batch: 1.475969
best-train-loss: 1.902853
best-valid-loss: 90.885605
best-kappa: -0.0067
: Epoch: 1 | Training Loss: 1.902853 | Val. Loss: 90.885605 | Val. Kappa Score: -0.0067 | LR: 0.010000 | Estimated time: 67.36
----------------------------------------

Experiment N: 73: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 14:01:40
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9604b320>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.965351
Train loss on 100 batch: 1.035661
Train loss on 150 batch: 0.950154
Train loss on 200 batch: 0.830009
Train loss on 250 batch: 0.928299
best-train-loss: 1.074788
best-valid-loss: 3.513261
best-kappa: 0.5072
: Epoch: 1 | Training Loss: 1.074788 | Val. Loss: 3.513261 | Val. Kappa Score: 0.5072 | LR: 0.001000 | Estimated time: 22.53
Train loss on 50 batch: 0.655713
Train loss on 100 batch: 0.743036
Train loss on 150 batch: 0.703828
Train loss on 200 batch: 0.757318
Train loss on 250 batch: 0.713891
best-train-loss: 0.692834
best-valid-loss: 0.627320
best-kappa: 0.6590
: Epoch: 2 | Training Loss: 0.692834 | Val. Loss: 0.627320 | Val. Kappa Score: 0.6590 | LR: 0.001000 | Estimated time: 21.78
Train loss on 50 batch: 0.656841
Train loss on 100 batch: 0.552409
Train loss on 150 batch: 0.648803
Train loss on 200 batch: 0.612014
Train loss on 250 batch: 0.586110
best-train-loss: 0.580530
best-valid-loss: 0.626831
best-kappa: 0.7066
: Epoch: 3 | Training Loss: 0.580530 | Val. Loss: 0.626831 | Val. Kappa Score: 0.7066 | LR: 0.001000 | Estimated time: 22.34
Train loss on 50 batch: 0.551273
Train loss on 100 batch: 0.583469
Train loss on 150 batch: 0.584206
Train loss on 200 batch: 0.645384
Train loss on 250 batch: 0.577939
: Epoch: 4 | Training Loss: 0.578393 | Val. Loss: 0.798605 | Val. Kappa Score: 0.7176 | LR: 0.001000 | Estimated time: 22.09
Train loss on 50 batch: 0.511511
Train loss on 100 batch: 0.610176
Train loss on 150 batch: 0.503097
Train loss on 200 batch: 0.577082
Train loss on 250 batch: 0.568511
best-train-loss: 0.540337
best-valid-loss: 0.529264
best-kappa: 0.7416
: Epoch: 5 | Training Loss: 0.540337 | Val. Loss: 0.529264 | Val. Kappa Score: 0.7416 | LR: 0.001000 | Estimated time: 22.17
Train loss on 50 batch: 0.475528
Train loss on 100 batch: 0.531208
Train loss on 150 batch: 0.511574
Train loss on 200 batch: 0.511528
Train loss on 250 batch: 0.485944
: Epoch: 6 | Training Loss: 0.529145 | Val. Loss: 0.534143 | Val. Kappa Score: 0.7573 | LR: 0.001000 | Estimated time: 22.42
Train loss on 50 batch: 0.527348
Train loss on 100 batch: 0.430116
Train loss on 150 batch: 0.518754
Train loss on 200 batch: 0.464820
Train loss on 250 batch: 0.513776
best-train-loss: 0.464929
best-valid-loss: 0.518195
best-kappa: 0.7680
: Epoch: 7 | Training Loss: 0.464929 | Val. Loss: 0.518195 | Val. Kappa Score: 0.7680 | LR: 0.001000 | Estimated time: 22.07
Train loss on 50 batch: 0.443259
Train loss on 100 batch: 0.450683
Train loss on 150 batch: 0.457667
Train loss on 200 batch: 0.523962
Train loss on 250 batch: 0.398810
best-train-loss: 0.449781
best-valid-loss: 0.491244
best-kappa: 0.7774
: Epoch: 8 | Training Loss: 0.449781 | Val. Loss: 0.491244 | Val. Kappa Score: 0.7774 | LR: 0.001000 | Estimated time: 22.68
Train loss on 50 batch: 0.423121
Train loss on 100 batch: 0.487351
Train loss on 150 batch: 0.543754
Train loss on 200 batch: 0.409371
Train loss on 250 batch: 0.444778
best-train-loss: 0.407964
best-valid-loss: 0.477518
best-kappa: 0.7851
: Epoch: 9 | Training Loss: 0.407964 | Val. Loss: 0.477518 | Val. Kappa Score: 0.7851 | LR: 0.001000 | Estimated time: 22.12
Train loss on 50 batch: 0.435152
Train loss on 100 batch: 0.491925
Train loss on 150 batch: 0.457073
Train loss on 200 batch: 0.417529
Train loss on 250 batch: 0.416344
: Epoch: 10 | Training Loss: 0.433323 | Val. Loss: 0.511908 | Val. Kappa Score: 0.7901 | LR: 0.001000 | Estimated time: 22.55
Train loss on 50 batch: 0.386705
Train loss on 100 batch: 0.426734
Train loss on 150 batch: 0.401659
Train loss on 200 batch: 0.444950
Train loss on 250 batch: 0.481432
best-train-loss: 0.438198
best-valid-loss: 0.429832
best-kappa: 0.7954
: Epoch: 11 | Training Loss: 0.438198 | Val. Loss: 0.429832 | Val. Kappa Score: 0.7954 | LR: 0.001000 | Estimated time: 22.02
Train loss on 50 batch: 0.391099
Train loss on 100 batch: 0.391488
Train loss on 150 batch: 0.401901
Train loss on 200 batch: 0.505819
Train loss on 250 batch: 0.434346
: Epoch: 12 | Training Loss: 0.494070 | Val. Loss: 0.496756 | Val. Kappa Score: 0.7999 | LR: 0.001000 | Estimated time: 21.95
Train loss on 50 batch: 0.370226
Train loss on 100 batch: 0.428979
Train loss on 150 batch: 0.369811
Train loss on 200 batch: 0.372850
Train loss on 250 batch: 0.392113
best-train-loss: 0.364939
best-valid-loss: 0.425507
best-kappa: 0.8048
: Epoch: 13 | Training Loss: 0.364939 | Val. Loss: 0.425507 | Val. Kappa Score: 0.8048 | LR: 0.001000 | Estimated time: 22.31
Train loss on 50 batch: 0.355286
Train loss on 100 batch: 0.335206
Train loss on 150 batch: 0.348359
Train loss on 200 batch: 0.441643
Train loss on 250 batch: 0.414727
: Epoch: 14 | Training Loss: 0.456132 | Val. Loss: 0.652172 | Val. Kappa Score: 0.8055 | LR: 0.001000 | Estimated time: 21.98
Train loss on 50 batch: 0.384012
Train loss on 100 batch: 0.431867
Train loss on 150 batch: 0.488711
Train loss on 200 batch: 0.361146
Train loss on 250 batch: 0.402826
: Epoch: 15 | Training Loss: 0.382214 | Val. Loss: 0.555993 | Val. Kappa Score: 0.8060 | LR: 0.001000 | Estimated time: 22.01
Train loss on 50 batch: 0.400099
Train loss on 100 batch: 0.363751
Train loss on 150 batch: 0.339869
Train loss on 200 batch: 0.383738
Train loss on 250 batch: 0.386795
: Epoch: 16 | Training Loss: 0.363710 | Val. Loss: 0.472253 | Val. Kappa Score: 0.8080 | LR: 0.000500 | Estimated time: 21.89
Train loss on 50 batch: 0.335152
Train loss on 100 batch: 0.294974
Train loss on 150 batch: 0.291905
Train loss on 200 batch: 0.320113
Train loss on 250 batch: 0.334516
best-train-loss: 0.331887
best-valid-loss: 0.414092
best-kappa: 0.8117
: Epoch: 17 | Training Loss: 0.331887 | Val. Loss: 0.414092 | Val. Kappa Score: 0.8117 | LR: 0.000500 | Estimated time: 21.39
Train loss on 50 batch: 0.255982
Train loss on 100 batch: 0.263749
Train loss on 150 batch: 0.307850
Train loss on 200 batch: 0.239369
Train loss on 250 batch: 0.281142
best-train-loss: 0.261196
best-valid-loss: 0.382994
best-kappa: 0.8147
: Epoch: 18 | Training Loss: 0.261196 | Val. Loss: 0.382994 | Val. Kappa Score: 0.8147 | LR: 0.000500 | Estimated time: 21.41
Train loss on 50 batch: 0.237825
Train loss on 100 batch: 0.257228
Train loss on 150 batch: 0.253644
Train loss on 200 batch: 0.287301
Train loss on 250 batch: 0.261212
: Epoch: 19 | Training Loss: 0.264300 | Val. Loss: 0.403998 | Val. Kappa Score: 0.8181 | LR: 0.000500 | Estimated time: 21.62
Train loss on 50 batch: 0.301858
Train loss on 100 batch: 0.253079
Train loss on 150 batch: 0.249152
Train loss on 200 batch: 0.232316
Train loss on 250 batch: 0.235272
: Epoch: 20 | Training Loss: 0.258129 | Val. Loss: 0.437641 | Val. Kappa Score: 0.8193 | LR: 0.000500 | Estimated time: 21.37
Train loss on 50 batch: 0.265863
Train loss on 100 batch: 0.292115
Train loss on 150 batch: 0.219458
Train loss on 200 batch: 0.266131
Train loss on 250 batch: 0.237623
: Epoch: 21 | Training Loss: 0.235891 | Val. Loss: 0.403768 | Val. Kappa Score: 0.8217 | LR: 0.000250 | Estimated time: 21.38
Train loss on 50 batch: 0.208865
Train loss on 100 batch: 0.198524
Train loss on 150 batch: 0.212158
Train loss on 200 batch: 0.182518
Train loss on 250 batch: 0.215746
: Epoch: 22 | Training Loss: 0.213150 | Val. Loss: 0.390695 | Val. Kappa Score: 0.8240 | LR: 0.000250 | Estimated time: 21.40
Train loss on 50 batch: 0.215401
Train loss on 100 batch: 0.217030
Train loss on 150 batch: 0.191507
Train loss on 200 batch: 0.173320
Train loss on 250 batch: 0.177612
: Epoch: 23 | Training Loss: 0.202758 | Val. Loss: 0.384386 | Val. Kappa Score: 0.8260 | LR: 0.000250 | Estimated time: 21.41
Train loss on 50 batch: 0.201656
Train loss on 100 batch: 0.173797
Train loss on 150 batch: 0.176695
Train loss on 200 batch: 0.189481
Train loss on 250 batch: 0.205476
best-train-loss: 0.177518
best-valid-loss: 0.379637
best-kappa: 0.8279
: Epoch: 24 | Training Loss: 0.177518 | Val. Loss: 0.379637 | Val. Kappa Score: 0.8279 | LR: 0.000250 | Estimated time: 21.54
Train loss on 50 batch: 0.161380
Train loss on 100 batch: 0.188900
Train loss on 150 batch: 0.157169
Train loss on 200 batch: 0.187065
Train loss on 250 batch: 0.162770
: Epoch: 25 | Training Loss: 0.180348 | Val. Loss: 0.419635 | Val. Kappa Score: 0.8293 | LR: 0.000250 | Estimated time: 21.64
Train loss on 50 batch: 0.154210
Train loss on 100 batch: 0.166329
Train loss on 150 batch: 0.171134
Train loss on 200 batch: 0.135115
Train loss on 250 batch: 0.180134
: Epoch: 26 | Training Loss: 0.180724 | Val. Loss: 0.403017 | Val. Kappa Score: 0.8309 | LR: 0.000250 | Estimated time: 21.52
Train loss on 50 batch: 0.154839
Train loss on 100 batch: 0.140670
Train loss on 150 batch: 0.169071
Train loss on 200 batch: 0.162838
Train loss on 250 batch: 0.161811
: Epoch: 27 | Training Loss: 0.169106 | Val. Loss: 0.381784 | Val. Kappa Score: 0.8322 | LR: 0.000125 | Estimated time: 21.25
Train loss on 50 batch: 0.129755
Train loss on 100 batch: 0.139422
Train loss on 150 batch: 0.140920
Train loss on 200 batch: 0.141831
Train loss on 250 batch: 0.132224
: Epoch: 28 | Training Loss: 0.142520 | Val. Loss: 0.395030 | Val. Kappa Score: 0.8333 | LR: 0.000125 | Estimated time: 21.23
Train loss on 50 batch: 0.101007
Train loss on 100 batch: 0.134883
Train loss on 150 batch: 0.125779
Train loss on 200 batch: 0.119281
Train loss on 250 batch: 0.143858
: Epoch: 29 | Training Loss: 0.137043 | Val. Loss: 0.388022 | Val. Kappa Score: 0.8345 | LR: 0.000125 | Estimated time: 21.42
Train loss on 50 batch: 0.134854
Train loss on 100 batch: 0.121507
Train loss on 150 batch: 0.122980
Train loss on 200 batch: 0.128516
Train loss on 250 batch: 0.124335
: Epoch: 30 | Training Loss: 0.116864 | Val. Loss: 0.407940 | Val. Kappa Score: 0.8358 | LR: 0.000063 | Estimated time: 21.69
Train loss on 50 batch: 0.101301
Train loss on 100 batch: 0.128108
Train loss on 150 batch: 0.114253
Train loss on 200 batch: 0.116410
Train loss on 250 batch: 0.118891
: Epoch: 31 | Training Loss: 0.127399 | Val. Loss: 0.403705 | Val. Kappa Score: 0.8370 | LR: 0.000063 | Estimated time: 21.34
Train loss on 50 batch: 0.113079
Train loss on 100 batch: 0.091840
Train loss on 150 batch: 0.115672
Train loss on 200 batch: 0.112977
Train loss on 250 batch: 0.115360
: Epoch: 32 | Training Loss: 0.167750 | Val. Loss: 0.395931 | Val. Kappa Score: 0.8381 | LR: 0.000063 | Estimated time: 21.47
time_estimated: 698.78
n-epochs: 32
time_estimated: 698.79
----------------------------------------

Experiment N: 74: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 14:13:19
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c0d5358>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.874495
Train loss on 100 batch: 1.033905
Train loss on 150 batch: 0.927923
Train loss on 200 batch: 0.784604
Train loss on 250 batch: 0.892223
best-train-loss: 1.011953
best-valid-loss: 0.749992
best-kappa: 0.7558
: Epoch: 1 | Training Loss: 1.011953 | Val. Loss: 0.749992 | Val. Kappa Score: 0.7558 | LR: 0.001000 | Estimated time: 67.18
Train loss on 50 batch: 0.675523
Train loss on 100 batch: 0.732868
Train loss on 150 batch: 0.644189
Train loss on 200 batch: 0.806863
Train loss on 250 batch: 0.762138
: Epoch: 2 | Training Loss: 0.719955 | Val. Loss: 0.881717 | Val. Kappa Score: 0.7659 | LR: 0.001000 | Estimated time: 67.20
Train loss on 50 batch: 0.701836
Train loss on 100 batch: 0.550840
Train loss on 150 batch: 0.677674
Train loss on 200 batch: 0.630031
Train loss on 250 batch: 0.568917
best-train-loss: 0.571131
best-valid-loss: 0.601192
best-kappa: 0.7612
: Epoch: 3 | Training Loss: 0.571131 | Val. Loss: 0.601192 | Val. Kappa Score: 0.7612 | LR: 0.001000 | Estimated time: 67.18
Train loss on 50 batch: 0.537175
Train loss on 100 batch: 0.576249
Train loss on 150 batch: 0.607356
Train loss on 200 batch: 0.594147
Train loss on 250 batch: 0.559028
best-train-loss: 0.561123
best-valid-loss: 0.586131
best-kappa: 0.7692
: Epoch: 4 | Training Loss: 0.561123 | Val. Loss: 0.586131 | Val. Kappa Score: 0.7692 | LR: 0.001000 | Estimated time: 67.17
Train loss on 50 batch: 0.486835
Train loss on 100 batch: 0.633628
Train loss on 150 batch: 0.526336
Train loss on 200 batch: 0.612783
Train loss on 250 batch: 0.518928
best-train-loss: 0.544114
best-valid-loss: 0.456818
best-kappa: 0.7852
: Epoch: 5 | Training Loss: 0.544114 | Val. Loss: 0.456818 | Val. Kappa Score: 0.7852 | LR: 0.001000 | Estimated time: 67.18
Train loss on 50 batch: 0.513794
Train loss on 100 batch: 0.585486
Train loss on 150 batch: 0.555888
Train loss on 200 batch: 0.529798
Train loss on 250 batch: 0.502056
best-train-loss: 0.542786
best-valid-loss: 0.427140
best-kappa: 0.7953
: Epoch: 6 | Training Loss: 0.542786 | Val. Loss: 0.427140 | Val. Kappa Score: 0.7953 | LR: 0.001000 | Estimated time: 67.12
Train loss on 50 batch: 0.500728
Train loss on 100 batch: 0.432086
Train loss on 150 batch: 0.562438
Train loss on 200 batch: 0.439729
Train loss on 250 batch: 0.542404
: Epoch: 7 | Training Loss: 0.487144 | Val. Loss: 0.460699 | Val. Kappa Score: 0.8029 | LR: 0.001000 | Estimated time: 67.12
Train loss on 50 batch: 0.443819
Train loss on 100 batch: 0.479671
Train loss on 150 batch: 0.510969
Train loss on 200 batch: 0.570238
Train loss on 250 batch: 0.416503
: Epoch: 8 | Training Loss: 0.484251 | Val. Loss: 0.456053 | Val. Kappa Score: 0.8088 | LR: 0.001000 | Estimated time: 67.14
Train loss on 50 batch: 0.432875
Train loss on 100 batch: 0.477288
Train loss on 150 batch: 0.534423
Train loss on 200 batch: 0.459748
Train loss on 250 batch: 0.442181
: Epoch: 9 | Training Loss: 0.417447 | Val. Loss: 0.512735 | Val. Kappa Score: 0.8112 | LR: 0.000500 | Estimated time: 67.22
Train loss on 50 batch: 0.445864
Train loss on 100 batch: 0.415945
Train loss on 150 batch: 0.375621
Train loss on 200 batch: 0.365993
Train loss on 250 batch: 0.376804
best-train-loss: 0.405296
best-valid-loss: 0.399517
best-kappa: 0.8162
: Epoch: 10 | Training Loss: 0.405296 | Val. Loss: 0.399517 | Val. Kappa Score: 0.8162 | LR: 0.000500 | Estimated time: 67.28
Train loss on 50 batch: 0.344537
Train loss on 100 batch: 0.356408
Train loss on 150 batch: 0.346660
Train loss on 200 batch: 0.338856
Train loss on 250 batch: 0.337385
: Epoch: 11 | Training Loss: 0.356493 | Val. Loss: 0.409784 | Val. Kappa Score: 0.8201 | LR: 0.000500 | Estimated time: 67.26
Train loss on 50 batch: 0.312330
Train loss on 100 batch: 0.321353
Train loss on 150 batch: 0.330079
Train loss on 200 batch: 0.310201
Train loss on 250 batch: 0.312703
best-train-loss: 0.384181
best-valid-loss: 0.392291
best-kappa: 0.8244
: Epoch: 12 | Training Loss: 0.384181 | Val. Loss: 0.392291 | Val. Kappa Score: 0.8244 | LR: 0.000500 | Estimated time: 67.36
Train loss on 50 batch: 0.294594
Train loss on 100 batch: 0.308350
Train loss on 150 batch: 0.310652
Train loss on 200 batch: 0.327941
Train loss on 250 batch: 0.314234
best-train-loss: 0.290802
best-valid-loss: 0.380642
best-kappa: 0.8284
: Epoch: 13 | Training Loss: 0.290802 | Val. Loss: 0.380642 | Val. Kappa Score: 0.8284 | LR: 0.000500 | Estimated time: 67.26
Train loss on 50 batch: 0.296701
Train loss on 100 batch: 0.292820
Train loss on 150 batch: 0.252462
Train loss on 200 batch: 0.327321
Train loss on 250 batch: 0.326005
: Epoch: 14 | Training Loss: 0.355100 | Val. Loss: 0.389071 | Val. Kappa Score: 0.8319 | LR: 0.000500 | Estimated time: 67.16
Train loss on 50 batch: 0.312713
Train loss on 100 batch: 0.308933
Train loss on 150 batch: 0.316746
Train loss on 200 batch: 0.277530
Train loss on 250 batch: 0.318028
: Epoch: 15 | Training Loss: 0.287808 | Val. Loss: 0.381819 | Val. Kappa Score: 0.8342 | LR: 0.000500 | Estimated time: 67.20
Train loss on 50 batch: 0.241768
Train loss on 100 batch: 0.279822
Train loss on 150 batch: 0.260733
Train loss on 200 batch: 0.353772
Train loss on 250 batch: 0.307605
: Epoch: 16 | Training Loss: 0.279373 | Val. Loss: 0.397084 | Val. Kappa Score: 0.8366 | LR: 0.000250 | Estimated time: 67.19
Train loss on 50 batch: 0.225711
Train loss on 100 batch: 0.218870
Train loss on 150 batch: 0.217175
Train loss on 200 batch: 0.264634
Train loss on 250 batch: 0.246697
best-train-loss: 0.236348
best-valid-loss: 0.360640
best-kappa: 0.8391
: Epoch: 17 | Training Loss: 0.236348 | Val. Loss: 0.360640 | Val. Kappa Score: 0.8391 | LR: 0.000250 | Estimated time: 67.29
Train loss on 50 batch: 0.197527
Train loss on 100 batch: 0.207718
Train loss on 150 batch: 0.242396
Train loss on 200 batch: 0.201276
Train loss on 250 batch: 0.209110
best-train-loss: 0.197040
best-valid-loss: 0.348670
best-kappa: 0.8413
: Epoch: 18 | Training Loss: 0.197040 | Val. Loss: 0.348670 | Val. Kappa Score: 0.8413 | LR: 0.000250 | Estimated time: 67.12
Train loss on 50 batch: 0.193023
Train loss on 100 batch: 0.188027
Train loss on 150 batch: 0.208450
Train loss on 200 batch: 0.206894
Train loss on 250 batch: 0.216834
: Epoch: 19 | Training Loss: 0.199851 | Val. Loss: 0.371722 | Val. Kappa Score: 0.8428 | LR: 0.000250 | Estimated time: 67.18
Train loss on 50 batch: 0.206589
Train loss on 100 batch: 0.181666
Train loss on 150 batch: 0.195042
Train loss on 200 batch: 0.173163
Train loss on 250 batch: 0.186048
: Epoch: 20 | Training Loss: 0.201508 | Val. Loss: 0.374253 | Val. Kappa Score: 0.8440 | LR: 0.000250 | Estimated time: 67.24
Train loss on 50 batch: 0.218313
Train loss on 100 batch: 0.194382
Train loss on 150 batch: 0.160690
Train loss on 200 batch: 0.197236
Train loss on 250 batch: 0.180692
: Epoch: 21 | Training Loss: 0.178953 | Val. Loss: 0.378084 | Val. Kappa Score: 0.8453 | LR: 0.000125 | Estimated time: 67.15
Train loss on 50 batch: 0.164698
Train loss on 100 batch: 0.167299
Train loss on 150 batch: 0.161514
Train loss on 200 batch: 0.160962
Train loss on 250 batch: 0.179495
: Epoch: 22 | Training Loss: 0.161975 | Val. Loss: 0.350489 | Val. Kappa Score: 0.8468 | LR: 0.000125 | Estimated time: 67.19
Train loss on 50 batch: 0.138777
Train loss on 100 batch: 0.173141
Train loss on 150 batch: 0.155077
Train loss on 200 batch: 0.126316
Train loss on 250 batch: 0.134051
: Epoch: 23 | Training Loss: 0.142053 | Val. Loss: 0.352988 | Val. Kappa Score: 0.8480 | LR: 0.000125 | Estimated time: 67.17
Train loss on 50 batch: 0.164605
Train loss on 100 batch: 0.132366
Train loss on 150 batch: 0.145686
Train loss on 200 batch: 0.122109
Train loss on 250 batch: 0.149696
: Epoch: 24 | Training Loss: 0.129533 | Val. Loss: 0.349792 | Val. Kappa Score: 0.8496 | LR: 0.000063 | Estimated time: 67.19
Train loss on 50 batch: 0.150603
Train loss on 100 batch: 0.137979
Train loss on 150 batch: 0.115170
Train loss on 200 batch: 0.128539
Train loss on 250 batch: 0.096113
: Epoch: 25 | Training Loss: 0.123311 | Val. Loss: 0.366373 | Val. Kappa Score: 0.8508 | LR: 0.000063 | Estimated time: 67.25
Train loss on 50 batch: 0.131167
Train loss on 100 batch: 0.133127
Train loss on 150 batch: 0.121924
Train loss on 200 batch: 0.093683
Train loss on 250 batch: 0.121606
best-train-loss: 0.123402
best-valid-loss: 0.346132
best-kappa: 0.8520
: Epoch: 26 | Training Loss: 0.123402 | Val. Loss: 0.346132 | Val. Kappa Score: 0.8520 | LR: 0.000063 | Estimated time: 67.23
Train loss on 50 batch: 0.107410
Train loss on 100 batch: 0.115503
Train loss on 150 batch: 0.108987
Train loss on 200 batch: 0.107330
Train loss on 250 batch: 0.107937
: Epoch: 27 | Training Loss: 0.124470 | Val. Loss: 0.351874 | Val. Kappa Score: 0.8532 | LR: 0.000063 | Estimated time: 67.23
Train loss on 50 batch: 0.118418
Train loss on 100 batch: 0.105342
Train loss on 150 batch: 0.109635
Train loss on 200 batch: 0.114561
Train loss on 250 batch: 0.126663
: Epoch: 28 | Training Loss: 0.112528 | Val. Loss: 0.349736 | Val. Kappa Score: 0.8541 | LR: 0.000063 | Estimated time: 67.23
Train loss on 50 batch: 0.093574
Train loss on 100 batch: 0.119439
Train loss on 150 batch: 0.105164
Train loss on 200 batch: 0.097148
Train loss on 250 batch: 0.124094
best-train-loss: 0.121379
best-valid-loss: 0.342671
best-kappa: 0.8552
: Epoch: 29 | Training Loss: 0.121379 | Val. Loss: 0.342671 | Val. Kappa Score: 0.8552 | LR: 0.000063 | Estimated time: 67.15
Train loss on 50 batch: 0.118785
Train loss on 100 batch: 0.107122
Train loss on 150 batch: 0.109753
Train loss on 200 batch: 0.102719
Train loss on 250 batch: 0.101569
: Epoch: 30 | Training Loss: 0.104862 | Val. Loss: 0.348481 | Val. Kappa Score: 0.8562 | LR: 0.000063 | Estimated time: 67.27
Train loss on 50 batch: 0.086569
Train loss on 100 batch: 0.110882
Train loss on 150 batch: 0.093706
Train loss on 200 batch: 0.102056
Train loss on 250 batch: 0.108560
: Epoch: 31 | Training Loss: 0.116988 | Val. Loss: 0.352583 | Val. Kappa Score: 0.8571 | LR: 0.000063 | Estimated time: 67.24
Train loss on 50 batch: 0.094321
Train loss on 100 batch: 0.085913
Train loss on 150 batch: 0.108812
Train loss on 200 batch: 0.091468
Train loss on 250 batch: 0.092148
best-train-loss: 0.137881
best-valid-loss: 0.340661
best-kappa: 0.8581
: Epoch: 32 | Training Loss: 0.137881 | Val. Loss: 0.340661 | Val. Kappa Score: 0.8581 | LR: 0.000063 | Estimated time: 67.26
Train loss on 50 batch: 0.084877
Train loss on 100 batch: 0.107789
Train loss on 150 batch: 0.099287
Train loss on 200 batch: 0.091331
Train loss on 250 batch: 0.112408
: Epoch: 33 | Training Loss: 0.093040 | Val. Loss: 0.342276 | Val. Kappa Score: 0.8591 | LR: 0.000063 | Estimated time: 67.29
Train loss on 50 batch: 0.087577
Train loss on 100 batch: 0.093289
Train loss on 150 batch: 0.093384
Train loss on 200 batch: 0.086281
Train loss on 250 batch: 0.103293
: Epoch: 34 | Training Loss: 0.083803 | Val. Loss: 0.347338 | Val. Kappa Score: 0.8599 | LR: 0.000063 | Estimated time: 67.21
Train loss on 50 batch: 0.096729
Train loss on 100 batch: 0.092037
Train loss on 150 batch: 0.114741
Train loss on 200 batch: 0.080277
Train loss on 250 batch: 0.079005
: Epoch: 35 | Training Loss: 0.082225 | Val. Loss: 0.345678 | Val. Kappa Score: 0.8605 | LR: 0.000031 | Estimated time: 67.21
Train loss on 50 batch: 0.091391
Train loss on 100 batch: 0.082903
Train loss on 150 batch: 0.076248
Train loss on 200 batch: 0.065649
Train loss on 250 batch: 0.094605
: Epoch: 36 | Training Loss: 0.081924 | Val. Loss: 0.359227 | Val. Kappa Score: 0.8612 | LR: 0.000031 | Estimated time: 67.21
Train loss on 50 batch: 0.082264
Train loss on 100 batch: 0.078182
Train loss on 150 batch: 0.094911
Train loss on 200 batch: 0.078772
Train loss on 250 batch: 0.095452
: Epoch: 37 | Training Loss: 0.084168 | Val. Loss: 0.360793 | Val. Kappa Score: 0.8619 | LR: 0.000031 | Estimated time: 67.24
Train loss on 50 batch: 0.077082
Train loss on 100 batch: 0.091476
Train loss on 150 batch: 0.071465
Train loss on 200 batch: 0.088088
Train loss on 250 batch: 0.094009
: Epoch: 38 | Training Loss: 0.095779 | Val. Loss: 0.350656 | Val. Kappa Score: 0.8627 | LR: 0.000016 | Estimated time: 67.28
Train loss on 50 batch: 0.076735
Train loss on 100 batch: 0.068334
Train loss on 150 batch: 0.081918
Train loss on 200 batch: 0.074519
Train loss on 250 batch: 0.086137
: Epoch: 39 | Training Loss: 0.078447 | Val. Loss: 0.352801 | Val. Kappa Score: 0.8634 | LR: 0.000016 | Estimated time: 67.18
Train loss on 50 batch: 0.082791
Train loss on 100 batch: 0.069706
Train loss on 150 batch: 0.090750
Train loss on 200 batch: 0.093103
Train loss on 250 batch: 0.059590
: Epoch: 40 | Training Loss: 0.080886 | Val. Loss: 0.349436 | Val. Kappa Score: 0.8640 | LR: 0.000016 | Estimated time: 67.23
time_estimated: 2690.29
n-epochs: 40
time_estimated: 2690.31
----------------------------------------

Experiment N: 75: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 14:58:09
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb7cca54a8>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.315644
Train loss on 100 batch: 1.283345
Train loss on 150 batch: 1.193174
Train loss on 200 batch: 1.004423
Train loss on 250 batch: 1.077873
best-train-loss: 1.280120
best-valid-loss: 2.486578
best-kappa: 0.1779
: Epoch: 1 | Training Loss: 1.280120 | Val. Loss: 2.486578 | Val. Kappa Score: 0.1779 | LR: 0.005000 | Estimated time: 21.57
Train loss on 50 batch: 0.802157
Train loss on 100 batch: 0.942588
Train loss on 150 batch: 0.912735
Train loss on 200 batch: 0.983763
Train loss on 250 batch: 0.860922
best-train-loss: 0.864502
best-valid-loss: 0.909777
best-kappa: 0.4726
: Epoch: 2 | Training Loss: 0.864502 | Val. Loss: 0.909777 | Val. Kappa Score: 0.4726 | LR: 0.005000 | Estimated time: 21.43
Train loss on 50 batch: 0.920295
Train loss on 100 batch: 0.708446
Train loss on 150 batch: 0.927185
Train loss on 200 batch: 0.759581
Train loss on 250 batch: 0.693261
: Epoch: 3 | Training Loss: 0.755742 | Val. Loss: 1.003184 | Val. Kappa Score: 0.5417 | LR: 0.005000 | Estimated time: 21.36
Train loss on 50 batch: 0.767433
Train loss on 100 batch: 0.745043
Train loss on 150 batch: 0.783916
Train loss on 200 batch: 0.800546
Train loss on 250 batch: 0.862680
: Epoch: 4 | Training Loss: 0.822446 | Val. Loss: 0.973571 | Val. Kappa Score: 0.5679 | LR: 0.005000 | Estimated time: 21.47
Train loss on 50 batch: 0.726607
Train loss on 100 batch: 0.848568
Train loss on 150 batch: 0.649209
Train loss on 200 batch: 0.775894
Train loss on 250 batch: 0.853100
best-train-loss: 0.740770
best-valid-loss: 0.868642
best-kappa: 0.6009
: Epoch: 5 | Training Loss: 0.740770 | Val. Loss: 0.868642 | Val. Kappa Score: 0.6009 | LR: 0.005000 | Estimated time: 21.50
Train loss on 50 batch: 0.643575
Train loss on 100 batch: 0.766870
Train loss on 150 batch: 0.748908
Train loss on 200 batch: 0.669008
Train loss on 250 batch: 0.631586
: Epoch: 6 | Training Loss: 0.710893 | Val. Loss: 1.144244 | Val. Kappa Score: 0.6074 | LR: 0.005000 | Estimated time: 21.66
Train loss on 50 batch: 0.687507
Train loss on 100 batch: 0.618512
Train loss on 150 batch: 0.703805
Train loss on 200 batch: 0.644674
Train loss on 250 batch: 0.660568
best-train-loss: 0.664181
best-valid-loss: 0.643538
best-kappa: 0.6316
: Epoch: 7 | Training Loss: 0.664181 | Val. Loss: 0.643538 | Val. Kappa Score: 0.6316 | LR: 0.005000 | Estimated time: 21.44
Train loss on 50 batch: 0.672621
Train loss on 100 batch: 0.725771
Train loss on 150 batch: 0.671739
Train loss on 200 batch: 0.787397
Train loss on 250 batch: 0.597665
: Epoch: 8 | Training Loss: 0.675710 | Val. Loss: 0.709604 | Val. Kappa Score: 0.6520 | LR: 0.005000 | Estimated time: 22.04
Train loss on 50 batch: 0.632825
Train loss on 100 batch: 0.727806
Train loss on 150 batch: 0.802014
Train loss on 200 batch: 0.653366
Train loss on 250 batch: 0.600697
: Epoch: 9 | Training Loss: 0.613406 | Val. Loss: 1.092461 | Val. Kappa Score: 0.6478 | LR: 0.005000 | Estimated time: 21.22
Train loss on 50 batch: 0.668105
Train loss on 100 batch: 0.767891
Train loss on 150 batch: 0.714898
Train loss on 200 batch: 0.598236
Train loss on 250 batch: 0.606106
best-train-loss: 0.638700
best-valid-loss: 0.497677
best-kappa: 0.6655
: Epoch: 10 | Training Loss: 0.638700 | Val. Loss: 0.497677 | Val. Kappa Score: 0.6655 | LR: 0.005000 | Estimated time: 21.32
Train loss on 50 batch: 0.632776
Train loss on 100 batch: 0.618318
Train loss on 150 batch: 0.595005
Train loss on 200 batch: 0.645940
Train loss on 250 batch: 0.701680
: Epoch: 11 | Training Loss: 0.666241 | Val. Loss: 0.751104 | Val. Kappa Score: 0.6738 | LR: 0.005000 | Estimated time: 21.29
Train loss on 50 batch: 0.656484
Train loss on 100 batch: 0.681132
Train loss on 150 batch: 0.616058
Train loss on 200 batch: 0.730346
Train loss on 250 batch: 0.698719
: Epoch: 12 | Training Loss: 0.775250 | Val. Loss: 1.890845 | Val. Kappa Score: 0.6583 | LR: 0.005000 | Estimated time: 21.43
Train loss on 50 batch: 0.670470
Train loss on 100 batch: 0.665482
Train loss on 150 batch: 0.586150
Train loss on 200 batch: 0.581749
Train loss on 250 batch: 0.653806
: Epoch: 13 | Training Loss: 0.592658 | Val. Loss: 0.621721 | Val. Kappa Score: 0.6689 | LR: 0.002500 | Estimated time: 21.43
Train loss on 50 batch: 0.597294
Train loss on 100 batch: 0.543730
Train loss on 150 batch: 0.509157
Train loss on 200 batch: 0.597609
Train loss on 250 batch: 0.556380
: Epoch: 14 | Training Loss: 0.585686 | Val. Loss: 0.521047 | Val. Kappa Score: 0.6795 | LR: 0.002500 | Estimated time: 21.54
Train loss on 50 batch: 0.504196
Train loss on 100 batch: 0.550150
Train loss on 150 batch: 0.575374
Train loss on 200 batch: 0.478746
Train loss on 250 batch: 0.559401
: Epoch: 15 | Training Loss: 0.518853 | Val. Loss: 0.529662 | Val. Kappa Score: 0.6886 | LR: 0.002500 | Estimated time: 21.40
Train loss on 50 batch: 0.546420
Train loss on 100 batch: 0.460233
Train loss on 150 batch: 0.538170
Train loss on 200 batch: 0.496156
Train loss on 250 batch: 0.473873
: Epoch: 16 | Training Loss: 0.482617 | Val. Loss: 0.772679 | Val. Kappa Score: 0.6923 | LR: 0.001250 | Estimated time: 21.31
Train loss on 50 batch: 0.479003
Train loss on 100 batch: 0.457031
Train loss on 150 batch: 0.477345
Train loss on 200 batch: 0.471342
Train loss on 250 batch: 0.508896
best-train-loss: 0.496359
best-valid-loss: 0.481341
best-kappa: 0.7003
: Epoch: 17 | Training Loss: 0.496359 | Val. Loss: 0.481341 | Val. Kappa Score: 0.7003 | LR: 0.001250 | Estimated time: 21.55
Train loss on 50 batch: 0.490176
Train loss on 100 batch: 0.502653
Train loss on 150 batch: 0.462354
Train loss on 200 batch: 0.453238
Train loss on 250 batch: 0.479539
best-train-loss: 0.436244
best-valid-loss: 0.428602
best-kappa: 0.7073
: Epoch: 18 | Training Loss: 0.436244 | Val. Loss: 0.428602 | Val. Kappa Score: 0.7073 | LR: 0.001250 | Estimated time: 21.75
Train loss on 50 batch: 0.427729
Train loss on 100 batch: 0.456081
Train loss on 150 batch: 0.451860
Train loss on 200 batch: 0.476896
Train loss on 250 batch: 0.507874
best-train-loss: 0.445022
best-valid-loss: 0.407077
best-kappa: 0.7152
: Epoch: 19 | Training Loss: 0.445022 | Val. Loss: 0.407077 | Val. Kappa Score: 0.7152 | LR: 0.001250 | Estimated time: 21.57
Train loss on 50 batch: 0.477344
Train loss on 100 batch: 0.432301
Train loss on 150 batch: 0.465051
Train loss on 200 batch: 0.437134
Train loss on 250 batch: 0.421570
: Epoch: 20 | Training Loss: 0.443190 | Val. Loss: 0.591214 | Val. Kappa Score: 0.7194 | LR: 0.001250 | Estimated time: 21.55
Train loss on 50 batch: 0.502384
Train loss on 100 batch: 0.543384
Train loss on 150 batch: 0.412204
Train loss on 200 batch: 0.430506
Train loss on 250 batch: 0.402247
: Epoch: 21 | Training Loss: 0.431888 | Val. Loss: 0.486781 | Val. Kappa Score: 0.7245 | LR: 0.001250 | Estimated time: 21.46
Train loss on 50 batch: 0.448226
Train loss on 100 batch: 0.436908
Train loss on 150 batch: 0.471911
Train loss on 200 batch: 0.422665
Train loss on 250 batch: 0.506014
: Epoch: 22 | Training Loss: 0.424200 | Val. Loss: 0.470562 | Val. Kappa Score: 0.7294 | LR: 0.000625 | Estimated time: 21.31
Train loss on 50 batch: 0.470310
Train loss on 100 batch: 0.447630
Train loss on 150 batch: 0.424351
Train loss on 200 batch: 0.357274
Train loss on 250 batch: 0.407572
best-train-loss: 0.419326
best-valid-loss: 0.402252
best-kappa: 0.7349
: Epoch: 23 | Training Loss: 0.419326 | Val. Loss: 0.402252 | Val. Kappa Score: 0.7349 | LR: 0.000625 | Estimated time: 21.23
Train loss on 50 batch: 0.412560
Train loss on 100 batch: 0.456495
Train loss on 150 batch: 0.402805
Train loss on 200 batch: 0.377552
Train loss on 250 batch: 0.436155
: Epoch: 24 | Training Loss: 0.385643 | Val. Loss: 0.424546 | Val. Kappa Score: 0.7395 | LR: 0.000625 | Estimated time: 21.34
Train loss on 50 batch: 0.411844
Train loss on 100 batch: 0.409194
Train loss on 150 batch: 0.343265
Train loss on 200 batch: 0.447099
Train loss on 250 batch: 0.369661
best-train-loss: 0.428906
best-valid-loss: 0.391976
best-kappa: 0.7445
: Epoch: 25 | Training Loss: 0.428906 | Val. Loss: 0.391976 | Val. Kappa Score: 0.7445 | LR: 0.000625 | Estimated time: 21.43
Train loss on 50 batch: 0.353293
Train loss on 100 batch: 0.442144
Train loss on 150 batch: 0.374212
Train loss on 200 batch: 0.360270
Train loss on 250 batch: 0.399780
: Epoch: 26 | Training Loss: 0.401547 | Val. Loss: 0.423190 | Val. Kappa Score: 0.7491 | LR: 0.000625 | Estimated time: 21.32
Train loss on 50 batch: 0.360775
Train loss on 100 batch: 0.374739
Train loss on 150 batch: 0.417646
Train loss on 200 batch: 0.343219
Train loss on 250 batch: 0.377512
best-train-loss: 0.402054
best-valid-loss: 0.389894
best-kappa: 0.7533
: Epoch: 27 | Training Loss: 0.402054 | Val. Loss: 0.389894 | Val. Kappa Score: 0.7533 | LR: 0.000625 | Estimated time: 21.47
Train loss on 50 batch: 0.339301
Train loss on 100 batch: 0.418315
Train loss on 150 batch: 0.384430
Train loss on 200 batch: 0.388284
Train loss on 250 batch: 0.372629
: Epoch: 28 | Training Loss: 0.370862 | Val. Loss: 0.427709 | Val. Kappa Score: 0.7568 | LR: 0.000625 | Estimated time: 21.53
Train loss on 50 batch: 0.345202
Train loss on 100 batch: 0.351038
Train loss on 150 batch: 0.378172
Train loss on 200 batch: 0.379329
Train loss on 250 batch: 0.367536
: Epoch: 29 | Training Loss: 0.368372 | Val. Loss: 0.409420 | Val. Kappa Score: 0.7607 | LR: 0.000625 | Estimated time: 21.50
Train loss on 50 batch: 0.369707
Train loss on 100 batch: 0.334474
Train loss on 150 batch: 0.385465
Train loss on 200 batch: 0.383615
Train loss on 250 batch: 0.344548
: Epoch: 30 | Training Loss: 0.350664 | Val. Loss: 0.392758 | Val. Kappa Score: 0.7642 | LR: 0.000313 | Estimated time: 21.44
Train loss on 50 batch: 0.348678
Train loss on 100 batch: 0.335719
Train loss on 150 batch: 0.334026
Train loss on 200 batch: 0.348925
Train loss on 250 batch: 0.364287
best-train-loss: 0.330361
best-valid-loss: 0.387728
best-kappa: 0.7675
: Epoch: 31 | Training Loss: 0.330361 | Val. Loss: 0.387728 | Val. Kappa Score: 0.7675 | LR: 0.000313 | Estimated time: 21.43
Train loss on 50 batch: 0.373989
Train loss on 100 batch: 0.311000
Train loss on 150 batch: 0.370543
Train loss on 200 batch: 0.362251
Train loss on 250 batch: 0.339919
: Epoch: 32 | Training Loss: 0.440113 | Val. Loss: 0.393218 | Val. Kappa Score: 0.7706 | LR: 0.000313 | Estimated time: 21.50
Train loss on 50 batch: 0.323363
Train loss on 100 batch: 0.348190
Train loss on 150 batch: 0.323575
Train loss on 200 batch: 0.345931
Train loss on 250 batch: 0.350897
best-train-loss: 0.365040
best-valid-loss: 0.383182
best-kappa: 0.7734
: Epoch: 33 | Training Loss: 0.365040 | Val. Loss: 0.383182 | Val. Kappa Score: 0.7734 | LR: 0.000313 | Estimated time: 21.26
Train loss on 50 batch: 0.298559
Train loss on 100 batch: 0.351028
Train loss on 150 batch: 0.337719
Train loss on 200 batch: 0.312990
Train loss on 250 batch: 0.327045
: Epoch: 34 | Training Loss: 0.313637 | Val. Loss: 0.395646 | Val. Kappa Score: 0.7763 | LR: 0.000313 | Estimated time: 21.55
Train loss on 50 batch: 0.330038
Train loss on 100 batch: 0.340837
Train loss on 150 batch: 0.368336
Train loss on 200 batch: 0.288696
Train loss on 250 batch: 0.355419
: Epoch: 35 | Training Loss: 0.319511 | Val. Loss: 0.386383 | Val. Kappa Score: 0.7789 | LR: 0.000313 | Estimated time: 21.62
Train loss on 50 batch: 0.328329
Train loss on 100 batch: 0.341302
Train loss on 150 batch: 0.345757
Train loss on 200 batch: 0.305941
Train loss on 250 batch: 0.346863
best-train-loss: 0.322314
best-valid-loss: 0.372886
best-kappa: 0.7815
: Epoch: 36 | Training Loss: 0.322314 | Val. Loss: 0.372886 | Val. Kappa Score: 0.7815 | LR: 0.000313 | Estimated time: 21.36
Train loss on 50 batch: 0.318193
Train loss on 100 batch: 0.298277
Train loss on 150 batch: 0.376702
Train loss on 200 batch: 0.330938
Train loss on 250 batch: 0.338414
best-train-loss: 0.304595
best-valid-loss: 0.370517
best-kappa: 0.7839
: Epoch: 37 | Training Loss: 0.304595 | Val. Loss: 0.370517 | Val. Kappa Score: 0.7839 | LR: 0.000313 | Estimated time: 22.03
Train loss on 50 batch: 0.306706
Train loss on 100 batch: 0.344557
Train loss on 150 batch: 0.295233
Train loss on 200 batch: 0.344891
Train loss on 250 batch: 0.325916
best-train-loss: 0.318455
best-valid-loss: 0.367155
best-kappa: 0.7864
: Epoch: 38 | Training Loss: 0.318455 | Val. Loss: 0.367155 | Val. Kappa Score: 0.7864 | LR: 0.000313 | Estimated time: 21.61
Train loss on 50 batch: 0.286626
Train loss on 100 batch: 0.300558
Train loss on 150 batch: 0.343620
Train loss on 200 batch: 0.319284
Train loss on 250 batch: 0.338185
: Epoch: 39 | Training Loss: 0.348689 | Val. Loss: 0.368059 | Val. Kappa Score: 0.7886 | LR: 0.000313 | Estimated time: 21.28
Train loss on 50 batch: 0.348073
Train loss on 100 batch: 0.292237
Train loss on 150 batch: 0.316268
Train loss on 200 batch: 0.285971
Train loss on 250 batch: 0.299054
: Epoch: 40 | Training Loss: 0.314656 | Val. Loss: 0.410447 | Val. Kappa Score: 0.7906 | LR: 0.000313 | Estimated time: 21.21
Train loss on 50 batch: 0.350843
Train loss on 100 batch: 0.344821
Train loss on 150 batch: 0.299757
Train loss on 200 batch: 0.313430
Train loss on 250 batch: 0.277012
: Epoch: 41 | Training Loss: 0.331993 | Val. Loss: 0.413384 | Val. Kappa Score: 0.7923 | LR: 0.000156 | Estimated time: 21.38
Train loss on 50 batch: 0.336859
Train loss on 100 batch: 0.305485
Train loss on 150 batch: 0.297416
Train loss on 200 batch: 0.278832
Train loss on 250 batch: 0.334315
best-train-loss: 0.308010
best-valid-loss: 0.362663
best-kappa: 0.7942
: Epoch: 42 | Training Loss: 0.308010 | Val. Loss: 0.362663 | Val. Kappa Score: 0.7942 | LR: 0.000156 | Estimated time: 21.44
Train loss on 50 batch: 0.280423
Train loss on 100 batch: 0.278206
Train loss on 150 batch: 0.276099
Train loss on 200 batch: 0.341465
Train loss on 250 batch: 0.308876
: Epoch: 43 | Training Loss: 0.306571 | Val. Loss: 0.372898 | Val. Kappa Score: 0.7961 | LR: 0.000156 | Estimated time: 21.47
Train loss on 50 batch: 0.257403
Train loss on 100 batch: 0.298937
Train loss on 150 batch: 0.311309
Train loss on 200 batch: 0.309560
Train loss on 250 batch: 0.292394
: Epoch: 44 | Training Loss: 0.288352 | Val. Loss: 0.383469 | Val. Kappa Score: 0.7978 | LR: 0.000156 | Estimated time: 21.28
Train loss on 50 batch: 0.359541
Train loss on 100 batch: 0.238136
Train loss on 150 batch: 0.233121
Train loss on 200 batch: 0.312653
Train loss on 250 batch: 0.330784
: Epoch: 45 | Training Loss: 0.295891 | Val. Loss: 0.376610 | Val. Kappa Score: 0.7995 | LR: 0.000078 | Estimated time: 21.36
Train loss on 50 batch: 0.311227
Train loss on 100 batch: 0.262171
Train loss on 150 batch: 0.306117
Train loss on 200 batch: 0.293070
Train loss on 250 batch: 0.312627
: Epoch: 46 | Training Loss: 0.294218 | Val. Loss: 0.369658 | Val. Kappa Score: 0.8010 | LR: 0.000078 | Estimated time: 21.70
Train loss on 50 batch: 0.292571
Train loss on 100 batch: 0.286317
Train loss on 150 batch: 0.280926
Train loss on 200 batch: 0.293033
Train loss on 250 batch: 0.267918
: Epoch: 47 | Training Loss: 0.250115 | Val. Loss: 0.375060 | Val. Kappa Score: 0.8025 | LR: 0.000078 | Estimated time: 21.41
Train loss on 50 batch: 0.291673
Train loss on 100 batch: 0.280176
Train loss on 150 batch: 0.326915
Train loss on 200 batch: 0.285718
Train loss on 250 batch: 0.265299
: Epoch: 48 | Training Loss: 0.320528 | Val. Loss: 0.375063 | Val. Kappa Score: 0.8041 | LR: 0.000039 | Estimated time: 21.32
Train loss on 50 batch: 0.310077
Train loss on 100 batch: 0.269866
Train loss on 150 batch: 0.311100
Train loss on 200 batch: 0.263761
Train loss on 250 batch: 0.285427
: Epoch: 49 | Training Loss: 0.275101 | Val. Loss: 0.365936 | Val. Kappa Score: 0.8056 | LR: 0.000039 | Estimated time: 21.50
Train loss on 50 batch: 0.234742
Train loss on 100 batch: 0.324698
Train loss on 150 batch: 0.300263
Train loss on 200 batch: 0.297181
Train loss on 250 batch: 0.275447
: Epoch: 50 | Training Loss: 0.282507 | Val. Loss: 0.367612 | Val. Kappa Score: 0.8069 | LR: 0.000039 | Estimated time: 21.37
time_estimated: 1074.17
n-epochs: 50
time_estimated: 1074.19
----------------------------------------

Experiment N: 76: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 15:16:04
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c083048>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.361984
Train loss on 100 batch: 1.480965
Train loss on 150 batch: 1.257994
Train loss on 200 batch: 1.359498
Train loss on 250 batch: 1.464166
best-train-loss: 1.521361
best-valid-loss: 16.306614
best-kappa: -0.2522
: Epoch: 1 | Training Loss: 1.521361 | Val. Loss: 16.306614 | Val. Kappa Score: -0.2522 | LR: 0.005000 | Estimated time: 67.23
Train loss on 50 batch: 1.002542
Train loss on 100 batch: 1.120139
Train loss on 150 batch: 0.993734
Train loss on 200 batch: 1.063638
Train loss on 250 batch: 0.959161
best-train-loss: 1.016673
best-valid-loss: 1.641441
best-kappa: 0.1703
: Epoch: 2 | Training Loss: 1.016673 | Val. Loss: 1.641441 | Val. Kappa Score: 0.1703 | LR: 0.005000 | Estimated time: 67.23
Train loss on 50 batch: 0.988259
Train loss on 100 batch: 0.791311
Train loss on 150 batch: 0.957317
Train loss on 200 batch: 0.882864
Train loss on 250 batch: 0.834295
: Epoch: 3 | Training Loss: 0.853342 | Val. Loss: 2.909501 | Val. Kappa Score: 0.2681 | LR: 0.005000 | Estimated time: 67.21
Train loss on 50 batch: 0.820524
Train loss on 100 batch: 0.869789
Train loss on 150 batch: 0.891191
Train loss on 200 batch: 0.909936
Train loss on 250 batch: 0.928115
: Epoch: 4 | Training Loss: 0.913213 | Val. Loss: 1.819752 | Val. Kappa Score: 0.3294 | LR: 0.005000 | Estimated time: 67.30
Train loss on 50 batch: 0.791553
Train loss on 100 batch: 0.898323
Train loss on 150 batch: 0.694822
Train loss on 200 batch: 0.885965
Train loss on 250 batch: 0.835973
best-train-loss: 0.847370
best-valid-loss: 0.787187
best-kappa: 0.4117
: Epoch: 5 | Training Loss: 0.847370 | Val. Loss: 0.787187 | Val. Kappa Score: 0.4117 | LR: 0.005000 | Estimated time: 67.20
Train loss on 50 batch: 0.746585
Train loss on 100 batch: 0.828036
Train loss on 150 batch: 0.779479
Train loss on 200 batch: 0.753657
Train loss on 250 batch: 0.732241
: Epoch: 6 | Training Loss: 0.790375 | Val. Loss: 0.810371 | Val. Kappa Score: 0.4711 | LR: 0.005000 | Estimated time: 67.22
Train loss on 50 batch: 0.807722
Train loss on 100 batch: 0.712821
Train loss on 150 batch: 0.774762
Train loss on 200 batch: 0.743165
Train loss on 250 batch: 0.734249
best-train-loss: 0.740301
best-valid-loss: 0.661037
best-kappa: 0.5160
: Epoch: 7 | Training Loss: 0.740301 | Val. Loss: 0.661037 | Val. Kappa Score: 0.5160 | LR: 0.005000 | Estimated time: 67.26
Train loss on 50 batch: 0.674391
Train loss on 100 batch: 0.726140
Train loss on 150 batch: 0.802142
Train loss on 200 batch: 0.842826
Train loss on 250 batch: 0.663465
: Epoch: 8 | Training Loss: 0.750413 | Val. Loss: 0.702677 | Val. Kappa Score: 0.5519 | LR: 0.005000 | Estimated time: 67.13
Train loss on 50 batch: 0.767368
Train loss on 100 batch: 0.747725
Train loss on 150 batch: 0.874569
Train loss on 200 batch: 0.760699
Train loss on 250 batch: 0.778049
: Epoch: 9 | Training Loss: 0.773711 | Val. Loss: 1.174113 | Val. Kappa Score: 0.5452 | LR: 0.005000 | Estimated time: 67.33
Train loss on 50 batch: 0.791968
Train loss on 100 batch: 0.780821
Train loss on 150 batch: 0.790100
Train loss on 200 batch: 0.648615
Train loss on 250 batch: 0.647262
best-train-loss: 0.703063
best-valid-loss: 0.603612
best-kappa: 0.5656
: Epoch: 10 | Training Loss: 0.703063 | Val. Loss: 0.603612 | Val. Kappa Score: 0.5656 | LR: 0.005000 | Estimated time: 67.20
Train loss on 50 batch: 0.751620
Train loss on 100 batch: 0.745466
Train loss on 150 batch: 0.723341
Train loss on 200 batch: 0.682127
Train loss on 250 batch: 0.769323
: Epoch: 11 | Training Loss: 0.779816 | Val. Loss: 0.690570 | Val. Kappa Score: 0.5861 | LR: 0.005000 | Estimated time: 67.21
Train loss on 50 batch: 0.656559
Train loss on 100 batch: 0.742110
Train loss on 150 batch: 0.671387
Train loss on 200 batch: 0.768388
Train loss on 250 batch: 0.760154
: Epoch: 12 | Training Loss: 0.824250 | Val. Loss: 0.861761 | Val. Kappa Score: 0.6024 | LR: 0.005000 | Estimated time: 67.17
Train loss on 50 batch: 0.726212
Train loss on 100 batch: 0.725665
Train loss on 150 batch: 0.704993
Train loss on 200 batch: 0.678413
Train loss on 250 batch: 0.724952
: Epoch: 13 | Training Loss: 0.661782 | Val. Loss: 0.925752 | Val. Kappa Score: 0.6112 | LR: 0.002500 | Estimated time: 67.34
Train loss on 50 batch: 0.662194
Train loss on 100 batch: 0.599687
Train loss on 150 batch: 0.624823
Train loss on 200 batch: 0.649325
Train loss on 250 batch: 0.647211
best-train-loss: 0.701860
best-valid-loss: 0.498034
best-kappa: 0.6259
: Epoch: 14 | Training Loss: 0.701860 | Val. Loss: 0.498034 | Val. Kappa Score: 0.6259 | LR: 0.002500 | Estimated time: 67.23
Train loss on 50 batch: 0.576720
Train loss on 100 batch: 0.617997
Train loss on 150 batch: 0.690979
Train loss on 200 batch: 0.547927
Train loss on 250 batch: 0.613426
: Epoch: 15 | Training Loss: 0.582107 | Val. Loss: 0.794198 | Val. Kappa Score: 0.6340 | LR: 0.002500 | Estimated time: 67.15
Train loss on 50 batch: 0.566613
Train loss on 100 batch: 0.526995
Train loss on 150 batch: 0.529897
Train loss on 200 batch: 0.539581
Train loss on 250 batch: 0.470016
: Epoch: 16 | Training Loss: 0.533081 | Val. Loss: 0.803865 | Val. Kappa Score: 0.6408 | LR: 0.002500 | Estimated time: 67.35
Train loss on 50 batch: 0.504347
Train loss on 100 batch: 0.517688
Train loss on 150 batch: 0.546184
Train loss on 200 batch: 0.571857
Train loss on 250 batch: 0.552084
: Epoch: 17 | Training Loss: 0.582271 | Val. Loss: 0.523212 | Val. Kappa Score: 0.6499 | LR: 0.001250 | Estimated time: 67.24
Train loss on 50 batch: 0.533453
Train loss on 100 batch: 0.519271
Train loss on 150 batch: 0.510576
Train loss on 200 batch: 0.456481
Train loss on 250 batch: 0.500937
best-train-loss: 0.460178
best-valid-loss: 0.491587
best-kappa: 0.6589
: Epoch: 18 | Training Loss: 0.460178 | Val. Loss: 0.491587 | Val. Kappa Score: 0.6589 | LR: 0.001250 | Estimated time: 67.16
Train loss on 50 batch: 0.438736
Train loss on 100 batch: 0.465644
Train loss on 150 batch: 0.459612
Train loss on 200 batch: 0.475606
Train loss on 250 batch: 0.480247
best-train-loss: 0.468367
best-valid-loss: 0.442355
best-kappa: 0.6691
: Epoch: 19 | Training Loss: 0.468367 | Val. Loss: 0.442355 | Val. Kappa Score: 0.6691 | LR: 0.001250 | Estimated time: 67.18
Train loss on 50 batch: 0.498683
Train loss on 100 batch: 0.478475
Train loss on 150 batch: 0.441514
Train loss on 200 batch: 0.466183
Train loss on 250 batch: 0.429677
best-train-loss: 0.451209
best-valid-loss: 0.441570
best-kappa: 0.6775
: Epoch: 20 | Training Loss: 0.451209 | Val. Loss: 0.441570 | Val. Kappa Score: 0.6775 | LR: 0.001250 | Estimated time: 67.18
Train loss on 50 batch: 0.452113
Train loss on 100 batch: 0.497308
Train loss on 150 batch: 0.408160
Train loss on 200 batch: 0.454984
Train loss on 250 batch: 0.437509
: Epoch: 21 | Training Loss: 0.429324 | Val. Loss: 0.488321 | Val. Kappa Score: 0.6841 | LR: 0.001250 | Estimated time: 67.24
Train loss on 50 batch: 0.458297
Train loss on 100 batch: 0.419882
Train loss on 150 batch: 0.483298
Train loss on 200 batch: 0.434476
Train loss on 250 batch: 0.493995
: Epoch: 22 | Training Loss: 0.449782 | Val. Loss: 0.492793 | Val. Kappa Score: 0.6907 | LR: 0.001250 | Estimated time: 67.13
Train loss on 50 batch: 0.441805
Train loss on 100 batch: 0.446782
Train loss on 150 batch: 0.422058
Train loss on 200 batch: 0.383131
Train loss on 250 batch: 0.491905
best-train-loss: 0.433976
best-valid-loss: 0.434248
best-kappa: 0.6969
: Epoch: 23 | Training Loss: 0.433976 | Val. Loss: 0.434248 | Val. Kappa Score: 0.6969 | LR: 0.001250 | Estimated time: 67.26
Train loss on 50 batch: 0.491900
Train loss on 100 batch: 0.461737
Train loss on 150 batch: 0.451274
Train loss on 200 batch: 0.432867
Train loss on 250 batch: 0.467869
: Epoch: 24 | Training Loss: 0.414930 | Val. Loss: 0.449912 | Val. Kappa Score: 0.7028 | LR: 0.001250 | Estimated time: 67.20
Train loss on 50 batch: 0.448122
Train loss on 100 batch: 0.432695
Train loss on 150 batch: 0.375555
Train loss on 200 batch: 0.464995
Train loss on 250 batch: 0.371884
: Epoch: 25 | Training Loss: 0.413497 | Val. Loss: 0.574220 | Val. Kappa Score: 0.7074 | LR: 0.001250 | Estimated time: 67.16
Train loss on 50 batch: 0.405020
Train loss on 100 batch: 0.436050
Train loss on 150 batch: 0.425167
Train loss on 200 batch: 0.407467
Train loss on 250 batch: 0.439535
: Epoch: 26 | Training Loss: 0.463407 | Val. Loss: 0.498112 | Val. Kappa Score: 0.7121 | LR: 0.000625 | Estimated time: 67.21
Train loss on 50 batch: 0.373858
Train loss on 100 batch: 0.384481
Train loss on 150 batch: 0.409650
Train loss on 200 batch: 0.343478
Train loss on 250 batch: 0.391223
best-train-loss: 0.397357
best-valid-loss: 0.399733
best-kappa: 0.7175
: Epoch: 27 | Training Loss: 0.397357 | Val. Loss: 0.399733 | Val. Kappa Score: 0.7175 | LR: 0.000625 | Estimated time: 67.29
Train loss on 50 batch: 0.326285
Train loss on 100 batch: 0.396428
Train loss on 150 batch: 0.381259
Train loss on 200 batch: 0.363013
Train loss on 250 batch: 0.368769
: Epoch: 28 | Training Loss: 0.356210 | Val. Loss: 0.403509 | Val. Kappa Score: 0.7223 | LR: 0.000625 | Estimated time: 67.16
Train loss on 50 batch: 0.334989
Train loss on 100 batch: 0.373908
Train loss on 150 batch: 0.372565
Train loss on 200 batch: 0.345009
Train loss on 250 batch: 0.371290
: Epoch: 29 | Training Loss: 0.349819 | Val. Loss: 0.402820 | Val. Kappa Score: 0.7271 | LR: 0.000625 | Estimated time: 67.30
Train loss on 50 batch: 0.379767
Train loss on 100 batch: 0.344274
Train loss on 150 batch: 0.361725
Train loss on 200 batch: 0.358043
Train loss on 250 batch: 0.359209
: Epoch: 30 | Training Loss: 0.362043 | Val. Loss: 0.414394 | Val. Kappa Score: 0.7314 | LR: 0.000313 | Estimated time: 67.28
Train loss on 50 batch: 0.318614
Train loss on 100 batch: 0.298950
Train loss on 150 batch: 0.333121
Train loss on 200 batch: 0.354366
Train loss on 250 batch: 0.365983
: Epoch: 31 | Training Loss: 0.322912 | Val. Loss: 0.402062 | Val. Kappa Score: 0.7356 | LR: 0.000313 | Estimated time: 67.17
Train loss on 50 batch: 0.368063
Train loss on 100 batch: 0.287943
Train loss on 150 batch: 0.324297
Train loss on 200 batch: 0.351951
Train loss on 250 batch: 0.349090
: Epoch: 32 | Training Loss: 0.387876 | Val. Loss: 0.457650 | Val. Kappa Score: 0.7390 | LR: 0.000313 | Estimated time: 67.21
Train loss on 50 batch: 0.331646
Train loss on 100 batch: 0.332913
Train loss on 150 batch: 0.308463
Train loss on 200 batch: 0.306628
Train loss on 250 batch: 0.322773
: Epoch: 33 | Training Loss: 0.348940 | Val. Loss: 0.416492 | Val. Kappa Score: 0.7424 | LR: 0.000156 | Estimated time: 67.29
Train loss on 50 batch: 0.309244
Train loss on 100 batch: 0.331265
Train loss on 150 batch: 0.344131
Train loss on 200 batch: 0.306333
Train loss on 250 batch: 0.320870
best-train-loss: 0.309420
best-valid-loss: 0.388674
best-kappa: 0.7461
: Epoch: 34 | Training Loss: 0.309420 | Val. Loss: 0.388674 | Val. Kappa Score: 0.7461 | LR: 0.000156 | Estimated time: 67.18
Train loss on 50 batch: 0.305839
Train loss on 100 batch: 0.338890
Train loss on 150 batch: 0.320876
Train loss on 200 batch: 0.265966
Train loss on 250 batch: 0.308502
best-train-loss: 0.282410
best-valid-loss: 0.387603
best-kappa: 0.7496
: Epoch: 35 | Training Loss: 0.282410 | Val. Loss: 0.387603 | Val. Kappa Score: 0.7496 | LR: 0.000156 | Estimated time: 67.33
Train loss on 50 batch: 0.319689
Train loss on 100 batch: 0.309180
Train loss on 150 batch: 0.325672
Train loss on 200 batch: 0.293271
Train loss on 250 batch: 0.323478
best-train-loss: 0.335780
best-valid-loss: 0.380675
best-kappa: 0.7530
: Epoch: 36 | Training Loss: 0.335780 | Val. Loss: 0.380675 | Val. Kappa Score: 0.7530 | LR: 0.000156 | Estimated time: 67.20
Train loss on 50 batch: 0.275338
Train loss on 100 batch: 0.280576
Train loss on 150 batch: 0.372841
Train loss on 200 batch: 0.297898
Train loss on 250 batch: 0.323019
: Epoch: 37 | Training Loss: 0.298849 | Val. Loss: 0.396597 | Val. Kappa Score: 0.7562 | LR: 0.000156 | Estimated time: 67.35
Train loss on 50 batch: 0.302837
Train loss on 100 batch: 0.351048
Train loss on 150 batch: 0.296749
Train loss on 200 batch: 0.331610
Train loss on 250 batch: 0.303971
: Epoch: 38 | Training Loss: 0.339061 | Val. Loss: 0.382094 | Val. Kappa Score: 0.7593 | LR: 0.000156 | Estimated time: 67.29
Train loss on 50 batch: 0.261871
Train loss on 100 batch: 0.307133
Train loss on 150 batch: 0.301218
Train loss on 200 batch: 0.295396
Train loss on 250 batch: 0.334373
: Epoch: 39 | Training Loss: 0.329742 | Val. Loss: 0.383554 | Val. Kappa Score: 0.7622 | LR: 0.000078 | Estimated time: 67.30
Train loss on 50 batch: 0.299743
Train loss on 100 batch: 0.286151
Train loss on 150 batch: 0.312027
Train loss on 200 batch: 0.282266
Train loss on 250 batch: 0.276575
: Epoch: 40 | Training Loss: 0.300083 | Val. Loss: 0.382536 | Val. Kappa Score: 0.7648 | LR: 0.000078 | Estimated time: 67.31
Train loss on 50 batch: 0.306735
Train loss on 100 batch: 0.316330
Train loss on 150 batch: 0.266237
Train loss on 200 batch: 0.306729
Train loss on 250 batch: 0.284506
: Epoch: 41 | Training Loss: 0.314891 | Val. Loss: 0.386840 | Val. Kappa Score: 0.7675 | LR: 0.000078 | Estimated time: 67.31
Train loss on 50 batch: 0.309228
Train loss on 100 batch: 0.312191
Train loss on 150 batch: 0.274717
Train loss on 200 batch: 0.260050
Train loss on 250 batch: 0.306679
best-train-loss: 0.289386
best-valid-loss: 0.375109
best-kappa: 0.7698
: Epoch: 42 | Training Loss: 0.289386 | Val. Loss: 0.375109 | Val. Kappa Score: 0.7698 | LR: 0.000078 | Estimated time: 67.27
Train loss on 50 batch: 0.278333
Train loss on 100 batch: 0.295286
Train loss on 150 batch: 0.261859
Train loss on 200 batch: 0.350484
Train loss on 250 batch: 0.295428
: Epoch: 43 | Training Loss: 0.304695 | Val. Loss: 0.384274 | Val. Kappa Score: 0.7723 | LR: 0.000078 | Estimated time: 67.25
Train loss on 50 batch: 0.298843
Train loss on 100 batch: 0.314203
Train loss on 150 batch: 0.301796
Train loss on 200 batch: 0.328317
Train loss on 250 batch: 0.283297
best-train-loss: 0.295960
best-valid-loss: 0.374919
best-kappa: 0.7746
: Epoch: 44 | Training Loss: 0.295960 | Val. Loss: 0.374919 | Val. Kappa Score: 0.7746 | LR: 0.000078 | Estimated time: 67.33
Train loss on 50 batch: 0.359402
Train loss on 100 batch: 0.261495
Train loss on 150 batch: 0.259683
Train loss on 200 batch: 0.293920
Train loss on 250 batch: 0.297948
best-train-loss: 0.305842
best-valid-loss: 0.373030
best-kappa: 0.7767
: Epoch: 45 | Training Loss: 0.305842 | Val. Loss: 0.373030 | Val. Kappa Score: 0.7767 | LR: 0.000078 | Estimated time: 67.23
Train loss on 50 batch: 0.291758
Train loss on 100 batch: 0.284416
Train loss on 150 batch: 0.246774
Train loss on 200 batch: 0.301106
Train loss on 250 batch: 0.312499
: Epoch: 46 | Training Loss: 0.268538 | Val. Loss: 0.376629 | Val. Kappa Score: 0.7787 | LR: 0.000078 | Estimated time: 67.43
Train loss on 50 batch: 0.288286
Train loss on 100 batch: 0.279721
Train loss on 150 batch: 0.269496
Train loss on 200 batch: 0.316797
Train loss on 250 batch: 0.265797
: Epoch: 47 | Training Loss: 0.253732 | Val. Loss: 0.375522 | Val. Kappa Score: 0.7808 | LR: 0.000078 | Estimated time: 67.40
Train loss on 50 batch: 0.293620
Train loss on 100 batch: 0.267145
Train loss on 150 batch: 0.314958
Train loss on 200 batch: 0.263203
Train loss on 250 batch: 0.269890
: Epoch: 48 | Training Loss: 0.332388 | Val. Loss: 0.382066 | Val. Kappa Score: 0.7829 | LR: 0.000039 | Estimated time: 67.26
Train loss on 50 batch: 0.302392
Train loss on 100 batch: 0.259126
Train loss on 150 batch: 0.316576
Train loss on 200 batch: 0.280611
Train loss on 250 batch: 0.274061
best-train-loss: 0.267763
best-valid-loss: 0.372154
best-kappa: 0.7847
: Epoch: 49 | Training Loss: 0.267763 | Val. Loss: 0.372154 | Val. Kappa Score: 0.7847 | LR: 0.000039 | Estimated time: 67.37
Train loss on 50 batch: 0.247820
Train loss on 100 batch: 0.311129
Train loss on 150 batch: 0.295507
Train loss on 200 batch: 0.302810
Train loss on 250 batch: 0.257886
: Epoch: 50 | Training Loss: 0.264649 | Val. Loss: 0.375379 | Val. Kappa Score: 0.7864 | LR: 0.000039 | Estimated time: 67.31
Train loss on 50 batch: 0.313181
Train loss on 100 batch: 0.282657
Train loss on 150 batch: 0.287601
Train loss on 200 batch: 0.280270
Train loss on 250 batch: 0.268772
: Epoch: 51 | Training Loss: 0.275743 | Val. Loss: 0.373143 | Val. Kappa Score: 0.7881 | LR: 0.000039 | Estimated time: 67.24
Train loss on 50 batch: 0.270270
Train loss on 100 batch: 0.304943
Train loss on 150 batch: 0.302824
Train loss on 200 batch: 0.296704
Train loss on 250 batch: 0.258734
: Epoch: 52 | Training Loss: 0.306406 | Val. Loss: 0.375703 | Val. Kappa Score: 0.7897 | LR: 0.000020 | Estimated time: 67.29
Train loss on 50 batch: 0.257360
Train loss on 100 batch: 0.294802
Train loss on 150 batch: 0.270002
Train loss on 200 batch: 0.313126
Train loss on 250 batch: 0.253115
: Epoch: 53 | Training Loss: 0.253338 | Val. Loss: 0.373870 | Val. Kappa Score: 0.7913 | LR: 0.000020 | Estimated time: 67.31
Train loss on 50 batch: 0.276691
Train loss on 100 batch: 0.297164
Train loss on 150 batch: 0.312278
Train loss on 200 batch: 0.265226
Train loss on 250 batch: 0.288374
: Epoch: 54 | Training Loss: 0.269489 | Val. Loss: 0.373580 | Val. Kappa Score: 0.7928 | LR: 0.000020 | Estimated time: 67.34
Train loss on 50 batch: 0.276707
Train loss on 100 batch: 0.249427
Train loss on 150 batch: 0.273225
Train loss on 200 batch: 0.290948
Train loss on 250 batch: 0.282940
: Epoch: 55 | Training Loss: 0.250863 | Val. Loss: 0.372874 | Val. Kappa Score: 0.7942 | LR: 0.000010 | Estimated time: 67.21
Train loss on 50 batch: 0.268519
Train loss on 100 batch: 0.288141
Train loss on 150 batch: 0.304977
Train loss on 200 batch: 0.266669
Train loss on 250 batch: 0.299197
: Epoch: 56 | Training Loss: 0.262098 | Val. Loss: 0.372637 | Val. Kappa Score: 0.7957 | LR: 0.000010 | Estimated time: 67.20
Train loss on 50 batch: 0.270093
Train loss on 100 batch: 0.245681
Train loss on 150 batch: 0.245984
Train loss on 200 batch: 0.326391
Train loss on 250 batch: 0.263924
: Epoch: 57 | Training Loss: 0.259317 | Val. Loss: 0.373560 | Val. Kappa Score: 0.7970 | LR: 0.000010 | Estimated time: 67.27
time_estimated: 3835.95
n-epochs: 57
time_estimated: 3835.97
----------------------------------------

Experiment N: 77: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 16:20:00
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9606db00>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.815934
Train loss on 100 batch: 1.756700
Train loss on 150 batch: 1.584908
Train loss on 200 batch: 1.598067
Train loss on 250 batch: 1.549136
best-train-loss: 1.759658
best-valid-loss: 4.919354
best-kappa: -0.1455
: Epoch: 1 | Training Loss: 1.759658 | Val. Loss: 4.919354 | Val. Kappa Score: -0.1455 | LR: 0.010000 | Estimated time: 21.57
Train loss on 50 batch: 1.267295
Train loss on 100 batch: 1.243684
Train loss on 150 batch: 1.120781
Train loss on 200 batch: 1.253134
Train loss on 250 batch: 1.072261
best-train-loss: 1.278156
best-valid-loss: 1.202219
best-kappa: 0.2678
: Epoch: 2 | Training Loss: 1.278156 | Val. Loss: 1.202219 | Val. Kappa Score: 0.2678 | LR: 0.010000 | Estimated time: 21.39
Train loss on 50 batch: 1.260597
Train loss on 100 batch: 1.064720
Train loss on 150 batch: 1.182877
Train loss on 200 batch: 1.054923
Train loss on 250 batch: 0.965034
: Epoch: 3 | Training Loss: 1.112822 | Val. Loss: 1.678720 | Val. Kappa Score: 0.3743 | LR: 0.010000 | Estimated time: 21.77
Train loss on 50 batch: 1.053147
Train loss on 100 batch: 0.961202
Train loss on 150 batch: 1.027352
Train loss on 200 batch: 1.014484
Train loss on 250 batch: 1.227521
: Epoch: 4 | Training Loss: 1.102936 | Val. Loss: 3.376219 | Val. Kappa Score: 0.2990 | LR: 0.010000 | Estimated time: 21.44
Train loss on 50 batch: 0.917629
Train loss on 100 batch: 1.017476
Train loss on 150 batch: 0.839206
Train loss on 200 batch: 1.030127
Train loss on 250 batch: 0.984328
: Epoch: 5 | Training Loss: 0.913440 | Val. Loss: 1.999757 | Val. Kappa Score: 0.3368 | LR: 0.005000 | Estimated time: 21.64
Train loss on 50 batch: 0.818225
Train loss on 100 batch: 0.846317
Train loss on 150 batch: 0.820861
Train loss on 200 batch: 0.803521
Train loss on 250 batch: 0.730090
best-train-loss: 0.795132
best-valid-loss: 0.653889
best-kappa: 0.4021
: Epoch: 6 | Training Loss: 0.795132 | Val. Loss: 0.653889 | Val. Kappa Score: 0.4021 | LR: 0.005000 | Estimated time: 21.33
Train loss on 50 batch: 0.751959
Train loss on 100 batch: 0.727972
Train loss on 150 batch: 0.772734
Train loss on 200 batch: 0.806226
Train loss on 250 batch: 0.789478
: Epoch: 7 | Training Loss: 0.758463 | Val. Loss: 1.657281 | Val. Kappa Score: 0.4219 | LR: 0.005000 | Estimated time: 21.33
Train loss on 50 batch: 0.711446
Train loss on 100 batch: 0.835847
Train loss on 150 batch: 0.800751
Train loss on 200 batch: 0.918642
Train loss on 250 batch: 0.652987
: Epoch: 8 | Training Loss: 0.727311 | Val. Loss: 1.520185 | Val. Kappa Score: 0.4342 | LR: 0.005000 | Estimated time: 21.30
Train loss on 50 batch: 0.753273
Train loss on 100 batch: 0.757771
Train loss on 150 batch: 0.848348
Train loss on 200 batch: 0.761850
Train loss on 250 batch: 0.746321
: Epoch: 9 | Training Loss: 0.776918 | Val. Loss: 1.097304 | Val. Kappa Score: 0.4583 | LR: 0.002500 | Estimated time: 21.51
Train loss on 50 batch: 0.686872
Train loss on 100 batch: 0.782798
Train loss on 150 batch: 0.728291
Train loss on 200 batch: 0.626154
Train loss on 250 batch: 0.644209
best-train-loss: 0.667109
best-valid-loss: 0.526426
best-kappa: 0.4945
: Epoch: 10 | Training Loss: 0.667109 | Val. Loss: 0.526426 | Val. Kappa Score: 0.4945 | LR: 0.002500 | Estimated time: 21.44
Train loss on 50 batch: 0.656774
Train loss on 100 batch: 0.662662
Train loss on 150 batch: 0.670537
Train loss on 200 batch: 0.663424
Train loss on 250 batch: 0.698991
: Epoch: 11 | Training Loss: 0.689229 | Val. Loss: 0.534803 | Val. Kappa Score: 0.5237 | LR: 0.002500 | Estimated time: 21.60
Train loss on 50 batch: 0.593419
Train loss on 100 batch: 0.655724
Train loss on 150 batch: 0.636676
Train loss on 200 batch: 0.709249
Train loss on 250 batch: 0.700840
: Epoch: 12 | Training Loss: 0.721291 | Val. Loss: 0.559162 | Val. Kappa Score: 0.5461 | LR: 0.002500 | Estimated time: 21.89
Train loss on 50 batch: 0.691337
Train loss on 100 batch: 0.667393
Train loss on 150 batch: 0.573444
Train loss on 200 batch: 0.581488
Train loss on 250 batch: 0.681631
: Epoch: 13 | Training Loss: 0.611751 | Val. Loss: 0.538647 | Val. Kappa Score: 0.5656 | LR: 0.001250 | Estimated time: 21.91
Train loss on 50 batch: 0.595714
Train loss on 100 batch: 0.573850
Train loss on 150 batch: 0.564583
Train loss on 200 batch: 0.646330
Train loss on 250 batch: 0.603537
: Epoch: 14 | Training Loss: 0.648305 | Val. Loss: 0.789981 | Val. Kappa Score: 0.5808 | LR: 0.001250 | Estimated time: 23.28
Train loss on 50 batch: 0.542602
Train loss on 100 batch: 0.583221
Train loss on 150 batch: 0.628213
Train loss on 200 batch: 0.519731
Train loss on 250 batch: 0.601763
: Epoch: 15 | Training Loss: 0.575867 | Val. Loss: 0.562316 | Val. Kappa Score: 0.5957 | LR: 0.001250 | Estimated time: 21.90
Train loss on 50 batch: 0.589055
Train loss on 100 batch: 0.516778
Train loss on 150 batch: 0.563385
Train loss on 200 batch: 0.527243
Train loss on 250 batch: 0.493570
: Epoch: 16 | Training Loss: 0.538906 | Val. Loss: 0.532809 | Val. Kappa Score: 0.6093 | LR: 0.000625 | Estimated time: 21.51
Train loss on 50 batch: 0.516096
Train loss on 100 batch: 0.521519
Train loss on 150 batch: 0.494396
Train loss on 200 batch: 0.545026
Train loss on 250 batch: 0.570278
best-train-loss: 0.519383
best-valid-loss: 0.485802
best-kappa: 0.6222
: Epoch: 17 | Training Loss: 0.519383 | Val. Loss: 0.485802 | Val. Kappa Score: 0.6222 | LR: 0.000625 | Estimated time: 22.08
Train loss on 50 batch: 0.528540
Train loss on 100 batch: 0.500401
Train loss on 150 batch: 0.542407
Train loss on 200 batch: 0.512588
Train loss on 250 batch: 0.507079
: Epoch: 18 | Training Loss: 0.485687 | Val. Loss: 0.521568 | Val. Kappa Score: 0.6322 | LR: 0.000625 | Estimated time: 23.06
Train loss on 50 batch: 0.484220
Train loss on 100 batch: 0.519703
Train loss on 150 batch: 0.504558
Train loss on 200 batch: 0.522159
Train loss on 250 batch: 0.525879
best-train-loss: 0.531704
best-valid-loss: 0.438034
best-kappa: 0.6440
: Epoch: 19 | Training Loss: 0.531704 | Val. Loss: 0.438034 | Val. Kappa Score: 0.6440 | LR: 0.000625 | Estimated time: 21.72
Train loss on 50 batch: 0.514406
Train loss on 100 batch: 0.491553
Train loss on 150 batch: 0.498369
Train loss on 200 batch: 0.480178
Train loss on 250 batch: 0.501838
best-train-loss: 0.515058
best-valid-loss: 0.434531
best-kappa: 0.6536
: Epoch: 20 | Training Loss: 0.515058 | Val. Loss: 0.434531 | Val. Kappa Score: 0.6536 | LR: 0.000625 | Estimated time: 23.27
Train loss on 50 batch: 0.528908
Train loss on 100 batch: 0.523799
Train loss on 150 batch: 0.498121
Train loss on 200 batch: 0.484874
Train loss on 250 batch: 0.472679
: Epoch: 21 | Training Loss: 0.472184 | Val. Loss: 0.603647 | Val. Kappa Score: 0.6607 | LR: 0.000625 | Estimated time: 22.41
Train loss on 50 batch: 0.500277
Train loss on 100 batch: 0.462802
Train loss on 150 batch: 0.531755
Train loss on 200 batch: 0.487065
Train loss on 250 batch: 0.525965
: Epoch: 22 | Training Loss: 0.479574 | Val. Loss: 0.462432 | Val. Kappa Score: 0.6683 | LR: 0.000625 | Estimated time: 21.41
Train loss on 50 batch: 0.507065
Train loss on 100 batch: 0.480474
Train loss on 150 batch: 0.484085
Train loss on 200 batch: 0.444484
Train loss on 250 batch: 0.525737
: Epoch: 23 | Training Loss: 0.466845 | Val. Loss: 0.465916 | Val. Kappa Score: 0.6761 | LR: 0.000313 | Estimated time: 21.95
Train loss on 50 batch: 0.535372
Train loss on 100 batch: 0.487510
Train loss on 150 batch: 0.429058
Train loss on 200 batch: 0.459581
Train loss on 250 batch: 0.495103
best-train-loss: 0.442975
best-valid-loss: 0.431868
best-kappa: 0.6834
: Epoch: 24 | Training Loss: 0.442975 | Val. Loss: 0.431868 | Val. Kappa Score: 0.6834 | LR: 0.000313 | Estimated time: 21.82
Train loss on 50 batch: 0.453797
Train loss on 100 batch: 0.466660
Train loss on 150 batch: 0.388488
Train loss on 200 batch: 0.503019
Train loss on 250 batch: 0.429747
: Epoch: 25 | Training Loss: 0.450666 | Val. Loss: 0.441452 | Val. Kappa Score: 0.6900 | LR: 0.000313 | Estimated time: 22.13
Train loss on 50 batch: 0.442339
Train loss on 100 batch: 0.527509
Train loss on 150 batch: 0.457147
Train loss on 200 batch: 0.412014
Train loss on 250 batch: 0.425446
: Epoch: 26 | Training Loss: 0.452106 | Val. Loss: 0.461291 | Val. Kappa Score: 0.6953 | LR: 0.000313 | Estimated time: 21.63
Train loss on 50 batch: 0.443994
Train loss on 100 batch: 0.393598
Train loss on 150 batch: 0.492270
Train loss on 200 batch: 0.413073
Train loss on 250 batch: 0.455397
best-train-loss: 0.476138
best-valid-loss: 0.415254
best-kappa: 0.7010
: Epoch: 27 | Training Loss: 0.476138 | Val. Loss: 0.415254 | Val. Kappa Score: 0.7010 | LR: 0.000313 | Estimated time: 21.55
Train loss on 50 batch: 0.380784
Train loss on 100 batch: 0.485034
Train loss on 150 batch: 0.462217
Train loss on 200 batch: 0.435798
Train loss on 250 batch: 0.422226
: Epoch: 28 | Training Loss: 0.435187 | Val. Loss: 0.425050 | Val. Kappa Score: 0.7066 | LR: 0.000313 | Estimated time: 21.92
Train loss on 50 batch: 0.383766
Train loss on 100 batch: 0.416073
Train loss on 150 batch: 0.424869
Train loss on 200 batch: 0.438255
Train loss on 250 batch: 0.464116
: Epoch: 29 | Training Loss: 0.436733 | Val. Loss: 0.489396 | Val. Kappa Score: 0.7106 | LR: 0.000313 | Estimated time: 22.33
Train loss on 50 batch: 0.445889
Train loss on 100 batch: 0.410615
Train loss on 150 batch: 0.428611
Train loss on 200 batch: 0.434405
Train loss on 250 batch: 0.394879
: Epoch: 30 | Training Loss: 0.442610 | Val. Loss: 0.446778 | Val. Kappa Score: 0.7147 | LR: 0.000156 | Estimated time: 22.78
Train loss on 50 batch: 0.384960
Train loss on 100 batch: 0.383807
Train loss on 150 batch: 0.405842
Train loss on 200 batch: 0.438926
Train loss on 250 batch: 0.430633
: Epoch: 31 | Training Loss: 0.415797 | Val. Loss: 0.419092 | Val. Kappa Score: 0.7191 | LR: 0.000156 | Estimated time: 22.22
Train loss on 50 batch: 0.433262
Train loss on 100 batch: 0.362396
Train loss on 150 batch: 0.416443
Train loss on 200 batch: 0.440697
Train loss on 250 batch: 0.410725
: Epoch: 32 | Training Loss: 0.469175 | Val. Loss: 0.428591 | Val. Kappa Score: 0.7234 | LR: 0.000156 | Estimated time: 22.40
Train loss on 50 batch: 0.388879
Train loss on 100 batch: 0.406676
Train loss on 150 batch: 0.381819
Train loss on 200 batch: 0.420331
Train loss on 250 batch: 0.446567
best-train-loss: 0.439958
best-valid-loss: 0.405531
best-kappa: 0.7272
: Epoch: 33 | Training Loss: 0.439958 | Val. Loss: 0.405531 | Val. Kappa Score: 0.7272 | LR: 0.000156 | Estimated time: 22.29
Train loss on 50 batch: 0.358870
Train loss on 100 batch: 0.404912
Train loss on 150 batch: 0.436800
Train loss on 200 batch: 0.411033
Train loss on 250 batch: 0.425133
: Epoch: 34 | Training Loss: 0.397979 | Val. Loss: 0.439098 | Val. Kappa Score: 0.7307 | LR: 0.000156 | Estimated time: 24.25
Train loss on 50 batch: 0.404300
Train loss on 100 batch: 0.425960
Train loss on 150 batch: 0.426641
Train loss on 200 batch: 0.388857
Train loss on 250 batch: 0.379853
best-train-loss: 0.364859
best-valid-loss: 0.402763
best-kappa: 0.7343
: Epoch: 35 | Training Loss: 0.364859 | Val. Loss: 0.402763 | Val. Kappa Score: 0.7343 | LR: 0.000156 | Estimated time: 22.14
Train loss on 50 batch: 0.410533
Train loss on 100 batch: 0.387496
Train loss on 150 batch: 0.434879
Train loss on 200 batch: 0.400675
Train loss on 250 batch: 0.428214
: Epoch: 36 | Training Loss: 0.459430 | Val. Loss: 0.428170 | Val. Kappa Score: 0.7377 | LR: 0.000156 | Estimated time: 22.06
Train loss on 50 batch: 0.389113
Train loss on 100 batch: 0.390784
Train loss on 150 batch: 0.464487
Train loss on 200 batch: 0.385699
Train loss on 250 batch: 0.395907
best-train-loss: 0.397825
best-valid-loss: 0.396329
best-kappa: 0.7410
: Epoch: 37 | Training Loss: 0.397825 | Val. Loss: 0.396329 | Val. Kappa Score: 0.7410 | LR: 0.000156 | Estimated time: 23.41
Train loss on 50 batch: 0.399962
Train loss on 100 batch: 0.420929
Train loss on 150 batch: 0.348365
Train loss on 200 batch: 0.419300
Train loss on 250 batch: 0.402033
: Epoch: 38 | Training Loss: 0.401078 | Val. Loss: 0.410063 | Val. Kappa Score: 0.7440 | LR: 0.000156 | Estimated time: 23.33
Train loss on 50 batch: 0.357947
Train loss on 100 batch: 0.392097
Train loss on 150 batch: 0.426422
Train loss on 200 batch: 0.394099
Train loss on 250 batch: 0.425392
: Epoch: 39 | Training Loss: 0.418520 | Val. Loss: 0.409917 | Val. Kappa Score: 0.7467 | LR: 0.000156 | Estimated time: 22.05
Train loss on 50 batch: 0.393365
Train loss on 100 batch: 0.365821
Train loss on 150 batch: 0.363893
Train loss on 200 batch: 0.364223
Train loss on 250 batch: 0.389433
: Epoch: 40 | Training Loss: 0.395344 | Val. Loss: 0.412674 | Val. Kappa Score: 0.7494 | LR: 0.000078 | Estimated time: 22.65
Train loss on 50 batch: 0.438457
Train loss on 100 batch: 0.414178
Train loss on 150 batch: 0.388095
Train loss on 200 batch: 0.371132
Train loss on 250 batch: 0.377704
: Epoch: 41 | Training Loss: 0.387130 | Val. Loss: 0.404225 | Val. Kappa Score: 0.7521 | LR: 0.000078 | Estimated time: 22.92
Train loss on 50 batch: 0.411894
Train loss on 100 batch: 0.402790
Train loss on 150 batch: 0.351932
Train loss on 200 batch: 0.362130
Train loss on 250 batch: 0.403249
: Epoch: 42 | Training Loss: 0.372054 | Val. Loss: 0.402354 | Val. Kappa Score: 0.7545 | LR: 0.000078 | Estimated time: 22.94
Train loss on 50 batch: 0.350025
Train loss on 100 batch: 0.390915
Train loss on 150 batch: 0.348167
Train loss on 200 batch: 0.413100
Train loss on 250 batch: 0.386983
: Epoch: 43 | Training Loss: 0.384656 | Val. Loss: 0.413983 | Val. Kappa Score: 0.7569 | LR: 0.000039 | Estimated time: 23.10
Train loss on 50 batch: 0.360688
Train loss on 100 batch: 0.372849
Train loss on 150 batch: 0.387229
Train loss on 200 batch: 0.380868
Train loss on 250 batch: 0.408203
: Epoch: 44 | Training Loss: 0.374662 | Val. Loss: 0.402629 | Val. Kappa Score: 0.7593 | LR: 0.000039 | Estimated time: 23.36
Train loss on 50 batch: 0.452261
Train loss on 100 batch: 0.351429
Train loss on 150 batch: 0.337460
Train loss on 200 batch: 0.393351
Train loss on 250 batch: 0.466885
: Epoch: 45 | Training Loss: 0.395520 | Val. Loss: 0.404759 | Val. Kappa Score: 0.7615 | LR: 0.000039 | Estimated time: 23.28
time_estimated: 1000.38
n-epochs: 45
time_estimated: 1000.40
----------------------------------------

Experiment N: 78: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 16:36:41
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb982c3278>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 78: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 16:41:37
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9604c320>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.965351
Train loss on 100 batch: 1.035661
Train loss on 150 batch: 0.950154
Train loss on 200 batch: 0.830009
Train loss on 250 batch: 0.928299
best-train-loss: 1.074788
best-valid-loss: 3.513261
best-kappa: 0.5072
: Epoch: 1 | Training Loss: 1.074788 | Val. Loss: 3.513261 | Val. Kappa Score: 0.5072 | LR: 0.001000 | Estimated time: 22.41
Train loss on 50 batch: 0.655713
Train loss on 100 batch: 0.743036
Train loss on 150 batch: 0.703828
Train loss on 200 batch: 0.757318
Train loss on 250 batch: 0.713891
best-train-loss: 0.692834
best-valid-loss: 0.627320
best-kappa: 0.6590
: Epoch: 2 | Training Loss: 0.692834 | Val. Loss: 0.627320 | Val. Kappa Score: 0.6590 | LR: 0.001000 | Estimated time: 22.31
Train loss on 50 batch: 0.656841
Train loss on 100 batch: 0.552409
Train loss on 150 batch: 0.648803
Train loss on 200 batch: 0.612014
Train loss on 250 batch: 0.586110
best-train-loss: 0.580530
best-valid-loss: 0.626831
best-kappa: 0.7066
: Epoch: 3 | Training Loss: 0.580530 | Val. Loss: 0.626831 | Val. Kappa Score: 0.7066 | LR: 0.001000 | Estimated time: 21.56
Train loss on 50 batch: 0.551273
Train loss on 100 batch: 0.583469
Train loss on 150 batch: 0.584206
Train loss on 200 batch: 0.645384
Train loss on 250 batch: 0.577939
: Epoch: 4 | Training Loss: 0.578393 | Val. Loss: 0.798605 | Val. Kappa Score: 0.7176 | LR: 0.001000 | Estimated time: 21.30
Train loss on 50 batch: 0.511511
Train loss on 100 batch: 0.610176
Train loss on 150 batch: 0.503097
Train loss on 200 batch: 0.577082
Train loss on 250 batch: 0.568511
best-train-loss: 0.540337
best-valid-loss: 0.529264
best-kappa: 0.7416
: Epoch: 5 | Training Loss: 0.540337 | Val. Loss: 0.529264 | Val. Kappa Score: 0.7416 | LR: 0.001000 | Estimated time: 21.39
Train loss on 50 batch: 0.475528
Train loss on 100 batch: 0.531208
Train loss on 150 batch: 0.511574
Train loss on 200 batch: 0.511528
Train loss on 250 batch: 0.485944
: Epoch: 6 | Training Loss: 0.529145 | Val. Loss: 0.534143 | Val. Kappa Score: 0.7573 | LR: 0.001000 | Estimated time: 21.40
Train loss on 50 batch: 0.527348
Train loss on 100 batch: 0.430116
Train loss on 150 batch: 0.518754
Train loss on 200 batch: 0.464820
Train loss on 250 batch: 0.513776
best-train-loss: 0.464929
best-valid-loss: 0.518195
best-kappa: 0.7680
: Epoch: 7 | Training Loss: 0.464929 | Val. Loss: 0.518195 | Val. Kappa Score: 0.7680 | LR: 0.001000 | Estimated time: 21.38
Train loss on 50 batch: 0.443259
Train loss on 100 batch: 0.450683
Train loss on 150 batch: 0.457667
Train loss on 200 batch: 0.523962
Train loss on 250 batch: 0.398810
best-train-loss: 0.449781
best-valid-loss: 0.491244
best-kappa: 0.7774
: Epoch: 8 | Training Loss: 0.449781 | Val. Loss: 0.491244 | Val. Kappa Score: 0.7774 | LR: 0.001000 | Estimated time: 21.48
Train loss on 50 batch: 0.423121
Train loss on 100 batch: 0.487351
Train loss on 150 batch: 0.543754
Train loss on 200 batch: 0.409371
Train loss on 250 batch: 0.444778
best-train-loss: 0.407964
best-valid-loss: 0.477518
best-kappa: 0.7851
: Epoch: 9 | Training Loss: 0.407964 | Val. Loss: 0.477518 | Val. Kappa Score: 0.7851 | LR: 0.001000 | Estimated time: 21.17
Train loss on 50 batch: 0.435152
Train loss on 100 batch: 0.491925
Train loss on 150 batch: 0.457073
Train loss on 200 batch: 0.417529
Train loss on 250 batch: 0.416344
: Epoch: 10 | Training Loss: 0.433323 | Val. Loss: 0.511908 | Val. Kappa Score: 0.7901 | LR: 0.001000 | Estimated time: 21.45
Train loss on 50 batch: 0.386705
Train loss on 100 batch: 0.426734
Train loss on 150 batch: 0.401659
Train loss on 200 batch: 0.444950
Train loss on 250 batch: 0.481432
best-train-loss: 0.438198
best-valid-loss: 0.429832
best-kappa: 0.7954
: Epoch: 11 | Training Loss: 0.438198 | Val. Loss: 0.429832 | Val. Kappa Score: 0.7954 | LR: 0.001000 | Estimated time: 21.40
Train loss on 50 batch: 0.391099
Train loss on 100 batch: 0.391488
Train loss on 150 batch: 0.401901
Train loss on 200 batch: 0.505819
Train loss on 250 batch: 0.434346
: Epoch: 12 | Training Loss: 0.494070 | Val. Loss: 0.496756 | Val. Kappa Score: 0.7999 | LR: 0.001000 | Estimated time: 21.14
Train loss on 50 batch: 0.370226
Train loss on 100 batch: 0.428979
Train loss on 150 batch: 0.369811
Train loss on 200 batch: 0.372850
Train loss on 250 batch: 0.392113
best-train-loss: 0.364939
best-valid-loss: 0.425507
best-kappa: 0.8048
: Epoch: 13 | Training Loss: 0.364939 | Val. Loss: 0.425507 | Val. Kappa Score: 0.8048 | LR: 0.001000 | Estimated time: 21.14
Train loss on 50 batch: 0.355286
Train loss on 100 batch: 0.335206
Train loss on 150 batch: 0.348359
Train loss on 200 batch: 0.441643
Train loss on 250 batch: 0.414727
: Epoch: 14 | Training Loss: 0.456132 | Val. Loss: 0.652172 | Val. Kappa Score: 0.8055 | LR: 0.001000 | Estimated time: 21.44
Train loss on 50 batch: 0.384012
Train loss on 100 batch: 0.431867
Train loss on 150 batch: 0.488711
Train loss on 200 batch: 0.361146
Train loss on 250 batch: 0.402826
: Epoch: 15 | Training Loss: 0.382214 | Val. Loss: 0.555993 | Val. Kappa Score: 0.8060 | LR: 0.001000 | Estimated time: 21.44
Train loss on 50 batch: 0.400099
Train loss on 100 batch: 0.363751
Train loss on 150 batch: 0.339869
Train loss on 200 batch: 0.383738
Train loss on 250 batch: 0.386795
: Epoch: 16 | Training Loss: 0.363710 | Val. Loss: 0.472253 | Val. Kappa Score: 0.8080 | LR: 0.000500 | Estimated time: 21.31
Train loss on 50 batch: 0.335152
Train loss on 100 batch: 0.294974
Train loss on 150 batch: 0.291905
Train loss on 200 batch: 0.320113
Train loss on 250 batch: 0.334516
best-train-loss: 0.331887
best-valid-loss: 0.414092
best-kappa: 0.8117
: Epoch: 17 | Training Loss: 0.331887 | Val. Loss: 0.414092 | Val. Kappa Score: 0.8117 | LR: 0.000500 | Estimated time: 21.65
Train loss on 50 batch: 0.255982
Train loss on 100 batch: 0.263749
Train loss on 150 batch: 0.307850
Train loss on 200 batch: 0.239369
Train loss on 250 batch: 0.281142
best-train-loss: 0.261196
best-valid-loss: 0.382994
best-kappa: 0.8147
: Epoch: 18 | Training Loss: 0.261196 | Val. Loss: 0.382994 | Val. Kappa Score: 0.8147 | LR: 0.000500 | Estimated time: 21.52
Train loss on 50 batch: 0.237825
Train loss on 100 batch: 0.257228
Train loss on 150 batch: 0.253644
Train loss on 200 batch: 0.287301
Train loss on 250 batch: 0.261212
: Epoch: 19 | Training Loss: 0.264300 | Val. Loss: 0.403998 | Val. Kappa Score: 0.8181 | LR: 0.000500 | Estimated time: 21.64
Train loss on 50 batch: 0.301858
Train loss on 100 batch: 0.253079
Train loss on 150 batch: 0.249152
Train loss on 200 batch: 0.232316
Train loss on 250 batch: 0.235272
: Epoch: 20 | Training Loss: 0.258129 | Val. Loss: 0.437641 | Val. Kappa Score: 0.8193 | LR: 0.000500 | Estimated time: 21.38
Train loss on 50 batch: 0.265863
Train loss on 100 batch: 0.292115
Train loss on 150 batch: 0.219458
Train loss on 200 batch: 0.266131
Train loss on 250 batch: 0.237623
: Epoch: 21 | Training Loss: 0.235891 | Val. Loss: 0.403768 | Val. Kappa Score: 0.8217 | LR: 0.000250 | Estimated time: 21.54
Train loss on 50 batch: 0.208865
Train loss on 100 batch: 0.198524
Train loss on 150 batch: 0.212158
Train loss on 200 batch: 0.182518
Train loss on 250 batch: 0.215746
: Epoch: 22 | Training Loss: 0.213150 | Val. Loss: 0.390695 | Val. Kappa Score: 0.8240 | LR: 0.000250 | Estimated time: 21.37
Train loss on 50 batch: 0.215401
Train loss on 100 batch: 0.217030
Train loss on 150 batch: 0.191507
Train loss on 200 batch: 0.173320
Train loss on 250 batch: 0.177612
: Epoch: 23 | Training Loss: 0.202758 | Val. Loss: 0.384386 | Val. Kappa Score: 0.8260 | LR: 0.000250 | Estimated time: 21.37
Train loss on 50 batch: 0.201656
Train loss on 100 batch: 0.173797
Train loss on 150 batch: 0.176695
Train loss on 200 batch: 0.189481
Train loss on 250 batch: 0.205476
best-train-loss: 0.177518
best-valid-loss: 0.379637
best-kappa: 0.8279
: Epoch: 24 | Training Loss: 0.177518 | Val. Loss: 0.379637 | Val. Kappa Score: 0.8279 | LR: 0.000250 | Estimated time: 21.02
Train loss on 50 batch: 0.161380
Train loss on 100 batch: 0.188900
Train loss on 150 batch: 0.157169
Train loss on 200 batch: 0.187065
Train loss on 250 batch: 0.162770
: Epoch: 25 | Training Loss: 0.180348 | Val. Loss: 0.419635 | Val. Kappa Score: 0.8293 | LR: 0.000250 | Estimated time: 21.52
Train loss on 50 batch: 0.154210
Train loss on 100 batch: 0.166329
Train loss on 150 batch: 0.171134
Train loss on 200 batch: 0.135115
Train loss on 250 batch: 0.180134
: Epoch: 26 | Training Loss: 0.180724 | Val. Loss: 0.403017 | Val. Kappa Score: 0.8309 | LR: 0.000250 | Estimated time: 21.61
Train loss on 50 batch: 0.154839
Train loss on 100 batch: 0.140670
Train loss on 150 batch: 0.169071
Train loss on 200 batch: 0.162838
Train loss on 250 batch: 0.161811
: Epoch: 27 | Training Loss: 0.169106 | Val. Loss: 0.381784 | Val. Kappa Score: 0.8322 | LR: 0.000125 | Estimated time: 21.77
Train loss on 50 batch: 0.129755
Train loss on 100 batch: 0.139422
Train loss on 150 batch: 0.140920
Train loss on 200 batch: 0.141831
Train loss on 250 batch: 0.132224
: Epoch: 28 | Training Loss: 0.142520 | Val. Loss: 0.395030 | Val. Kappa Score: 0.8333 | LR: 0.000125 | Estimated time: 21.34
Train loss on 50 batch: 0.101007
Train loss on 100 batch: 0.134883
Train loss on 150 batch: 0.125779
Train loss on 200 batch: 0.119281
Train loss on 250 batch: 0.143858
: Epoch: 29 | Training Loss: 0.137043 | Val. Loss: 0.388022 | Val. Kappa Score: 0.8345 | LR: 0.000125 | Estimated time: 21.16
Train loss on 50 batch: 0.134854
Train loss on 100 batch: 0.121507
Train loss on 150 batch: 0.122980
Train loss on 200 batch: 0.128516
Train loss on 250 batch: 0.124335
: Epoch: 30 | Training Loss: 0.116864 | Val. Loss: 0.407940 | Val. Kappa Score: 0.8358 | LR: 0.000063 | Estimated time: 21.58
Train loss on 50 batch: 0.101301
Train loss on 100 batch: 0.128108
Train loss on 150 batch: 0.114253
Train loss on 200 batch: 0.116410
Train loss on 250 batch: 0.118891
: Epoch: 31 | Training Loss: 0.127399 | Val. Loss: 0.403705 | Val. Kappa Score: 0.8370 | LR: 0.000063 | Estimated time: 21.35
Train loss on 50 batch: 0.113079
Train loss on 100 batch: 0.091840
Train loss on 150 batch: 0.115672
Train loss on 200 batch: 0.112977
Train loss on 250 batch: 0.115360
: Epoch: 32 | Training Loss: 0.167750 | Val. Loss: 0.395931 | Val. Kappa Score: 0.8381 | LR: 0.000063 | Estimated time: 21.51
time_estimated: 687.85
n-epochs: 32
time_estimated: 687.86
----------------------------------------

Experiment N: 79: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 16:53:05
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fedb70>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.874495
Train loss on 100 batch: 1.033905
Train loss on 150 batch: 0.927923
Train loss on 200 batch: 0.784604
Train loss on 250 batch: 0.892223
best-train-loss: 1.011953
best-valid-loss: 0.749992
best-kappa: 0.7558
: Epoch: 1 | Training Loss: 1.011953 | Val. Loss: 0.749992 | Val. Kappa Score: 0.7558 | LR: 0.001000 | Estimated time: 67.43
Train loss on 50 batch: 0.675523
Train loss on 100 batch: 0.732868
Train loss on 150 batch: 0.644189
Train loss on 200 batch: 0.806863
Train loss on 250 batch: 0.762138
: Epoch: 2 | Training Loss: 0.719955 | Val. Loss: 0.881717 | Val. Kappa Score: 0.7659 | LR: 0.001000 | Estimated time: 67.41
Train loss on 50 batch: 0.701836
Train loss on 100 batch: 0.550840
Train loss on 150 batch: 0.677674
Train loss on 200 batch: 0.630031
Train loss on 250 batch: 0.568917
best-train-loss: 0.571131
best-valid-loss: 0.601192
best-kappa: 0.7612
: Epoch: 3 | Training Loss: 0.571131 | Val. Loss: 0.601192 | Val. Kappa Score: 0.7612 | LR: 0.001000 | Estimated time: 67.44
Train loss on 50 batch: 0.537175
Train loss on 100 batch: 0.576249
Train loss on 150 batch: 0.607356
Train loss on 200 batch: 0.594147
Train loss on 250 batch: 0.559028
best-train-loss: 0.561123
best-valid-loss: 0.586131
best-kappa: 0.7692
: Epoch: 4 | Training Loss: 0.561123 | Val. Loss: 0.586131 | Val. Kappa Score: 0.7692 | LR: 0.001000 | Estimated time: 67.50
Train loss on 50 batch: 0.486835
Train loss on 100 batch: 0.633628
Train loss on 150 batch: 0.526336
Train loss on 200 batch: 0.612783
Train loss on 250 batch: 0.518928
best-train-loss: 0.544114
best-valid-loss: 0.456818
best-kappa: 0.7852
: Epoch: 5 | Training Loss: 0.544114 | Val. Loss: 0.456818 | Val. Kappa Score: 0.7852 | LR: 0.001000 | Estimated time: 67.45
Train loss on 50 batch: 0.513794
Train loss on 100 batch: 0.585486
Train loss on 150 batch: 0.555888
Train loss on 200 batch: 0.529798
Train loss on 250 batch: 0.502056
best-train-loss: 0.542786
best-valid-loss: 0.427140
best-kappa: 0.7953
: Epoch: 6 | Training Loss: 0.542786 | Val. Loss: 0.427140 | Val. Kappa Score: 0.7953 | LR: 0.001000 | Estimated time: 67.39
Train loss on 50 batch: 0.500728
Train loss on 100 batch: 0.432086
Train loss on 150 batch: 0.562438
Train loss on 200 batch: 0.439729
Train loss on 250 batch: 0.542404
: Epoch: 7 | Training Loss: 0.487144 | Val. Loss: 0.460699 | Val. Kappa Score: 0.8029 | LR: 0.001000 | Estimated time: 67.41
Train loss on 50 batch: 0.443819
Train loss on 100 batch: 0.479671
Train loss on 150 batch: 0.510969
Train loss on 200 batch: 0.570238
Train loss on 250 batch: 0.416503
: Epoch: 8 | Training Loss: 0.484251 | Val. Loss: 0.456053 | Val. Kappa Score: 0.8088 | LR: 0.001000 | Estimated time: 67.45
Train loss on 50 batch: 0.432875
Train loss on 100 batch: 0.477288
Train loss on 150 batch: 0.534423
Train loss on 200 batch: 0.459748
Train loss on 250 batch: 0.442181
: Epoch: 9 | Training Loss: 0.417447 | Val. Loss: 0.512735 | Val. Kappa Score: 0.8112 | LR: 0.000500 | Estimated time: 67.39
Train loss on 50 batch: 0.445864
Train loss on 100 batch: 0.415945
Train loss on 150 batch: 0.375621
Train loss on 200 batch: 0.365993
Train loss on 250 batch: 0.376804
best-train-loss: 0.405296
best-valid-loss: 0.399517
best-kappa: 0.8162
: Epoch: 10 | Training Loss: 0.405296 | Val. Loss: 0.399517 | Val. Kappa Score: 0.8162 | LR: 0.000500 | Estimated time: 67.43
Train loss on 50 batch: 0.344537
Train loss on 100 batch: 0.356408
Train loss on 150 batch: 0.346660
Train loss on 200 batch: 0.338856
Train loss on 250 batch: 0.337385
: Epoch: 11 | Training Loss: 0.356493 | Val. Loss: 0.409784 | Val. Kappa Score: 0.8201 | LR: 0.000500 | Estimated time: 67.49
Train loss on 50 batch: 0.312330
Train loss on 100 batch: 0.321353
Train loss on 150 batch: 0.330079
Train loss on 200 batch: 0.310201
Train loss on 250 batch: 0.312703
best-train-loss: 0.384181
best-valid-loss: 0.392291
best-kappa: 0.8244
: Epoch: 12 | Training Loss: 0.384181 | Val. Loss: 0.392291 | Val. Kappa Score: 0.8244 | LR: 0.000500 | Estimated time: 67.59
Train loss on 50 batch: 0.294594
Train loss on 100 batch: 0.308350
Train loss on 150 batch: 0.310652
Train loss on 200 batch: 0.327941
Train loss on 250 batch: 0.314234
best-train-loss: 0.290802
best-valid-loss: 0.380642
best-kappa: 0.8284
: Epoch: 13 | Training Loss: 0.290802 | Val. Loss: 0.380642 | Val. Kappa Score: 0.8284 | LR: 0.000500 | Estimated time: 67.38
Train loss on 50 batch: 0.296701
Train loss on 100 batch: 0.292820
Train loss on 150 batch: 0.252462
Train loss on 200 batch: 0.327321
Train loss on 250 batch: 0.326005
: Epoch: 14 | Training Loss: 0.355100 | Val. Loss: 0.389071 | Val. Kappa Score: 0.8319 | LR: 0.000500 | Estimated time: 67.40
Train loss on 50 batch: 0.312713
Train loss on 100 batch: 0.308933
Train loss on 150 batch: 0.316746
Train loss on 200 batch: 0.277530
Train loss on 250 batch: 0.318028
: Epoch: 15 | Training Loss: 0.287808 | Val. Loss: 0.381819 | Val. Kappa Score: 0.8342 | LR: 0.000500 | Estimated time: 67.37
Train loss on 50 batch: 0.241768
Train loss on 100 batch: 0.279822
Train loss on 150 batch: 0.260733
Train loss on 200 batch: 0.353772
Train loss on 250 batch: 0.307605
: Epoch: 16 | Training Loss: 0.279373 | Val. Loss: 0.397084 | Val. Kappa Score: 0.8366 | LR: 0.000250 | Estimated time: 67.46
Train loss on 50 batch: 0.225711
Train loss on 100 batch: 0.218870
Train loss on 150 batch: 0.217175
Train loss on 200 batch: 0.264634
Train loss on 250 batch: 0.246697
best-train-loss: 0.236348
best-valid-loss: 0.360640
best-kappa: 0.8391
: Epoch: 17 | Training Loss: 0.236348 | Val. Loss: 0.360640 | Val. Kappa Score: 0.8391 | LR: 0.000250 | Estimated time: 67.40
Train loss on 50 batch: 0.197527
Train loss on 100 batch: 0.207718
Train loss on 150 batch: 0.242396
Train loss on 200 batch: 0.201276
Train loss on 250 batch: 0.209110
best-train-loss: 0.197040
best-valid-loss: 0.348670
best-kappa: 0.8413
: Epoch: 18 | Training Loss: 0.197040 | Val. Loss: 0.348670 | Val. Kappa Score: 0.8413 | LR: 0.000250 | Estimated time: 67.50
Train loss on 50 batch: 0.193023
Train loss on 100 batch: 0.188027
Train loss on 150 batch: 0.208450
Train loss on 200 batch: 0.206894
Train loss on 250 batch: 0.216834
: Epoch: 19 | Training Loss: 0.199851 | Val. Loss: 0.371722 | Val. Kappa Score: 0.8428 | LR: 0.000250 | Estimated time: 67.42
Train loss on 50 batch: 0.206589
Train loss on 100 batch: 0.181666
Train loss on 150 batch: 0.195042
Train loss on 200 batch: 0.173163
Train loss on 250 batch: 0.186048
: Epoch: 20 | Training Loss: 0.201508 | Val. Loss: 0.374253 | Val. Kappa Score: 0.8440 | LR: 0.000250 | Estimated time: 67.48
Train loss on 50 batch: 0.218313
Train loss on 100 batch: 0.194382
Train loss on 150 batch: 0.160690
Train loss on 200 batch: 0.197236
Train loss on 250 batch: 0.180692
: Epoch: 21 | Training Loss: 0.178953 | Val. Loss: 0.378084 | Val. Kappa Score: 0.8453 | LR: 0.000125 | Estimated time: 67.48
Train loss on 50 batch: 0.164698
Train loss on 100 batch: 0.167299
Train loss on 150 batch: 0.161514
Train loss on 200 batch: 0.160962
Train loss on 250 batch: 0.179495
: Epoch: 22 | Training Loss: 0.161975 | Val. Loss: 0.350489 | Val. Kappa Score: 0.8468 | LR: 0.000125 | Estimated time: 67.45
Train loss on 50 batch: 0.138777
Train loss on 100 batch: 0.173141
Train loss on 150 batch: 0.155077
Train loss on 200 batch: 0.126316
Train loss on 250 batch: 0.134051
: Epoch: 23 | Training Loss: 0.142053 | Val. Loss: 0.352988 | Val. Kappa Score: 0.8480 | LR: 0.000125 | Estimated time: 67.45
Train loss on 50 batch: 0.164605
Train loss on 100 batch: 0.132366
Train loss on 150 batch: 0.145686
Train loss on 200 batch: 0.122109
Train loss on 250 batch: 0.149696
: Epoch: 24 | Training Loss: 0.129533 | Val. Loss: 0.349792 | Val. Kappa Score: 0.8496 | LR: 0.000063 | Estimated time: 67.52
Train loss on 50 batch: 0.150603
Train loss on 100 batch: 0.137979
Train loss on 150 batch: 0.115170
Train loss on 200 batch: 0.128539
Train loss on 250 batch: 0.096113
: Epoch: 25 | Training Loss: 0.123311 | Val. Loss: 0.366373 | Val. Kappa Score: 0.8508 | LR: 0.000063 | Estimated time: 67.48
Train loss on 50 batch: 0.131167
Train loss on 100 batch: 0.133127
Train loss on 150 batch: 0.121924
Train loss on 200 batch: 0.093683
Train loss on 250 batch: 0.121606
best-train-loss: 0.123402
best-valid-loss: 0.346132
best-kappa: 0.8520
: Epoch: 26 | Training Loss: 0.123402 | Val. Loss: 0.346132 | Val. Kappa Score: 0.8520 | LR: 0.000063 | Estimated time: 67.44
Train loss on 50 batch: 0.107410
Train loss on 100 batch: 0.115503
Train loss on 150 batch: 0.108987
Train loss on 200 batch: 0.107330
Train loss on 250 batch: 0.107937
: Epoch: 27 | Training Loss: 0.124470 | Val. Loss: 0.351874 | Val. Kappa Score: 0.8532 | LR: 0.000063 | Estimated time: 67.52
Train loss on 50 batch: 0.118418
Train loss on 100 batch: 0.105342
Train loss on 150 batch: 0.109635
Train loss on 200 batch: 0.114561
Train loss on 250 batch: 0.126663
: Epoch: 28 | Training Loss: 0.112528 | Val. Loss: 0.349736 | Val. Kappa Score: 0.8541 | LR: 0.000063 | Estimated time: 67.57
Train loss on 50 batch: 0.093574
Train loss on 100 batch: 0.119439
Train loss on 150 batch: 0.105164
Train loss on 200 batch: 0.097148
Train loss on 250 batch: 0.124094
best-train-loss: 0.121379
best-valid-loss: 0.342671
best-kappa: 0.8552
: Epoch: 29 | Training Loss: 0.121379 | Val. Loss: 0.342671 | Val. Kappa Score: 0.8552 | LR: 0.000063 | Estimated time: 67.43
Train loss on 50 batch: 0.118785
Train loss on 100 batch: 0.107122
Train loss on 150 batch: 0.109753
Train loss on 200 batch: 0.102719
Train loss on 250 batch: 0.101569
: Epoch: 30 | Training Loss: 0.104862 | Val. Loss: 0.348481 | Val. Kappa Score: 0.8562 | LR: 0.000063 | Estimated time: 67.46
Train loss on 50 batch: 0.086569
Train loss on 100 batch: 0.110882
Train loss on 150 batch: 0.093706
Train loss on 200 batch: 0.102056
Train loss on 250 batch: 0.108560
: Epoch: 31 | Training Loss: 0.116988 | Val. Loss: 0.352583 | Val. Kappa Score: 0.8571 | LR: 0.000063 | Estimated time: 67.52
Train loss on 50 batch: 0.094321
Train loss on 100 batch: 0.085913
Train loss on 150 batch: 0.108812
Train loss on 200 batch: 0.091468
Train loss on 250 batch: 0.092148
best-train-loss: 0.137881
best-valid-loss: 0.340661
best-kappa: 0.8581
: Epoch: 32 | Training Loss: 0.137881 | Val. Loss: 0.340661 | Val. Kappa Score: 0.8581 | LR: 0.000063 | Estimated time: 67.41
Train loss on 50 batch: 0.084877
Train loss on 100 batch: 0.107789
Train loss on 150 batch: 0.099287
Train loss on 200 batch: 0.091331
Train loss on 250 batch: 0.112408
: Epoch: 33 | Training Loss: 0.093040 | Val. Loss: 0.342276 | Val. Kappa Score: 0.8591 | LR: 0.000063 | Estimated time: 67.43
Train loss on 50 batch: 0.087577
Train loss on 100 batch: 0.093289
Train loss on 150 batch: 0.093384
Train loss on 200 batch: 0.086281
Train loss on 250 batch: 0.103293
: Epoch: 34 | Training Loss: 0.083803 | Val. Loss: 0.347338 | Val. Kappa Score: 0.8599 | LR: 0.000063 | Estimated time: 67.52
Train loss on 50 batch: 0.096729
Train loss on 100 batch: 0.092037
Train loss on 150 batch: 0.114741
Train loss on 200 batch: 0.080277
Train loss on 250 batch: 0.079005
: Epoch: 35 | Training Loss: 0.082225 | Val. Loss: 0.345678 | Val. Kappa Score: 0.8605 | LR: 0.000031 | Estimated time: 67.44
Train loss on 50 batch: 0.091391
Train loss on 100 batch: 0.082903
Train loss on 150 batch: 0.076248
Train loss on 200 batch: 0.065649
Train loss on 250 batch: 0.094605
: Epoch: 36 | Training Loss: 0.081924 | Val. Loss: 0.359227 | Val. Kappa Score: 0.8612 | LR: 0.000031 | Estimated time: 67.52
Train loss on 50 batch: 0.082264
Train loss on 100 batch: 0.078182
Train loss on 150 batch: 0.094911
Train loss on 200 batch: 0.078772
Train loss on 250 batch: 0.095452
: Epoch: 37 | Training Loss: 0.084168 | Val. Loss: 0.360793 | Val. Kappa Score: 0.8619 | LR: 0.000031 | Estimated time: 67.58
Train loss on 50 batch: 0.077082
Train loss on 100 batch: 0.091476
Train loss on 150 batch: 0.071465
Train loss on 200 batch: 0.088088
Train loss on 250 batch: 0.094009
: Epoch: 38 | Training Loss: 0.095779 | Val. Loss: 0.350656 | Val. Kappa Score: 0.8627 | LR: 0.000016 | Estimated time: 67.44
Train loss on 50 batch: 0.076735
Train loss on 100 batch: 0.068334
Train loss on 150 batch: 0.081918
Train loss on 200 batch: 0.074519
Train loss on 250 batch: 0.086137
: Epoch: 39 | Training Loss: 0.078447 | Val. Loss: 0.352801 | Val. Kappa Score: 0.8634 | LR: 0.000016 | Estimated time: 67.50
Train loss on 50 batch: 0.082791
Train loss on 100 batch: 0.069706
Train loss on 150 batch: 0.090750
Train loss on 200 batch: 0.093103
Train loss on 250 batch: 0.059590
: Epoch: 40 | Training Loss: 0.080886 | Val. Loss: 0.349436 | Val. Kappa Score: 0.8640 | LR: 0.000016 | Estimated time: 67.41
time_estimated: 2700.27
n-epochs: 40
time_estimated: 2700.29
----------------------------------------

Experiment N: 80: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 17:38:05
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fedef0>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.315644
Train loss on 100 batch: 1.283345
Train loss on 150 batch: 1.193174
Train loss on 200 batch: 1.004423
Train loss on 250 batch: 1.077873
best-train-loss: 1.280120
best-valid-loss: 2.486578
best-kappa: 0.1779
: Epoch: 1 | Training Loss: 1.280120 | Val. Loss: 2.486578 | Val. Kappa Score: 0.1779 | LR: 0.005000 | Estimated time: 21.55
Train loss on 50 batch: 0.802157
Train loss on 100 batch: 0.942588
Train loss on 150 batch: 0.912735
Train loss on 200 batch: 0.983763
Train loss on 250 batch: 0.860922
best-train-loss: 0.864502
best-valid-loss: 0.909777
best-kappa: 0.4726
: Epoch: 2 | Training Loss: 0.864502 | Val. Loss: 0.909777 | Val. Kappa Score: 0.4726 | LR: 0.005000 | Estimated time: 21.43
Train loss on 50 batch: 0.920295
Train loss on 100 batch: 0.708446
Train loss on 150 batch: 0.927185
Train loss on 200 batch: 0.759581
Train loss on 250 batch: 0.693261
: Epoch: 3 | Training Loss: 0.755742 | Val. Loss: 1.003184 | Val. Kappa Score: 0.5417 | LR: 0.005000 | Estimated time: 21.45
Train loss on 50 batch: 0.767433
Train loss on 100 batch: 0.745043
Train loss on 150 batch: 0.783916
Train loss on 200 batch: 0.800546
Train loss on 250 batch: 0.862680
: Epoch: 4 | Training Loss: 0.822446 | Val. Loss: 0.973571 | Val. Kappa Score: 0.5679 | LR: 0.005000 | Estimated time: 21.99
Train loss on 50 batch: 0.726607
Train loss on 100 batch: 0.848568
Train loss on 150 batch: 0.649209
Train loss on 200 batch: 0.775894
Train loss on 250 batch: 0.853100
best-train-loss: 0.740770
best-valid-loss: 0.868642
best-kappa: 0.6009
: Epoch: 5 | Training Loss: 0.740770 | Val. Loss: 0.868642 | Val. Kappa Score: 0.6009 | LR: 0.005000 | Estimated time: 21.41
Train loss on 50 batch: 0.643575
Train loss on 100 batch: 0.766870
Train loss on 150 batch: 0.748908
Train loss on 200 batch: 0.669008
Train loss on 250 batch: 0.631586
: Epoch: 6 | Training Loss: 0.710893 | Val. Loss: 1.144244 | Val. Kappa Score: 0.6074 | LR: 0.005000 | Estimated time: 21.74
Train loss on 50 batch: 0.687507
Train loss on 100 batch: 0.618512
Train loss on 150 batch: 0.703805
Train loss on 200 batch: 0.644674
Train loss on 250 batch: 0.660568
best-train-loss: 0.664181
best-valid-loss: 0.643538
best-kappa: 0.6316
: Epoch: 7 | Training Loss: 0.664181 | Val. Loss: 0.643538 | Val. Kappa Score: 0.6316 | LR: 0.005000 | Estimated time: 21.42
Train loss on 50 batch: 0.672621
Train loss on 100 batch: 0.725771
Train loss on 150 batch: 0.671739
Train loss on 200 batch: 0.787397
Train loss on 250 batch: 0.597665
: Epoch: 8 | Training Loss: 0.675710 | Val. Loss: 0.709604 | Val. Kappa Score: 0.6520 | LR: 0.005000 | Estimated time: 21.52
Train loss on 50 batch: 0.632825
Train loss on 100 batch: 0.727806
Train loss on 150 batch: 0.802014
Train loss on 200 batch: 0.653366
Train loss on 250 batch: 0.600697
: Epoch: 9 | Training Loss: 0.613406 | Val. Loss: 1.092461 | Val. Kappa Score: 0.6478 | LR: 0.005000 | Estimated time: 21.79
Train loss on 50 batch: 0.668105
Train loss on 100 batch: 0.767891
Train loss on 150 batch: 0.714898
Train loss on 200 batch: 0.598236
Train loss on 250 batch: 0.606106
best-train-loss: 0.638700
best-valid-loss: 0.497677
best-kappa: 0.6655
: Epoch: 10 | Training Loss: 0.638700 | Val. Loss: 0.497677 | Val. Kappa Score: 0.6655 | LR: 0.005000 | Estimated time: 21.88
Train loss on 50 batch: 0.632776
Train loss on 100 batch: 0.618318
Train loss on 150 batch: 0.595005
Train loss on 200 batch: 0.645940
Train loss on 250 batch: 0.701680
: Epoch: 11 | Training Loss: 0.666241 | Val. Loss: 0.751104 | Val. Kappa Score: 0.6738 | LR: 0.005000 | Estimated time: 21.75
Train loss on 50 batch: 0.656484
Train loss on 100 batch: 0.681132
Train loss on 150 batch: 0.616058
Train loss on 200 batch: 0.730346
Train loss on 250 batch: 0.698719
: Epoch: 12 | Training Loss: 0.775250 | Val. Loss: 1.890845 | Val. Kappa Score: 0.6583 | LR: 0.005000 | Estimated time: 21.41
Train loss on 50 batch: 0.670470
Train loss on 100 batch: 0.665482
Train loss on 150 batch: 0.586150
Train loss on 200 batch: 0.581749
Train loss on 250 batch: 0.653806
: Epoch: 13 | Training Loss: 0.592658 | Val. Loss: 0.621721 | Val. Kappa Score: 0.6689 | LR: 0.002500 | Estimated time: 21.50
Train loss on 50 batch: 0.597294
Train loss on 100 batch: 0.543730
Train loss on 150 batch: 0.509157
Train loss on 200 batch: 0.597609
Train loss on 250 batch: 0.556380
: Epoch: 14 | Training Loss: 0.585686 | Val. Loss: 0.521047 | Val. Kappa Score: 0.6795 | LR: 0.002500 | Estimated time: 21.29
Train loss on 50 batch: 0.504196
Train loss on 100 batch: 0.550150
Train loss on 150 batch: 0.575374
Train loss on 200 batch: 0.478746
Train loss on 250 batch: 0.559401
: Epoch: 15 | Training Loss: 0.518853 | Val. Loss: 0.529662 | Val. Kappa Score: 0.6886 | LR: 0.002500 | Estimated time: 21.32
Train loss on 50 batch: 0.546420
Train loss on 100 batch: 0.460233
Train loss on 150 batch: 0.538170
Train loss on 200 batch: 0.496156
Train loss on 250 batch: 0.473873
: Epoch: 16 | Training Loss: 0.482617 | Val. Loss: 0.772679 | Val. Kappa Score: 0.6923 | LR: 0.001250 | Estimated time: 21.45
Train loss on 50 batch: 0.479003
Train loss on 100 batch: 0.457031
Train loss on 150 batch: 0.477345
Train loss on 200 batch: 0.471342
Train loss on 250 batch: 0.508896
best-train-loss: 0.496359
best-valid-loss: 0.481341
best-kappa: 0.7003
: Epoch: 17 | Training Loss: 0.496359 | Val. Loss: 0.481341 | Val. Kappa Score: 0.7003 | LR: 0.001250 | Estimated time: 21.76
Train loss on 50 batch: 0.490176
Train loss on 100 batch: 0.502653
Train loss on 150 batch: 0.462354
Train loss on 200 batch: 0.453238
Train loss on 250 batch: 0.479539
best-train-loss: 0.436244
best-valid-loss: 0.428602
best-kappa: 0.7073
: Epoch: 18 | Training Loss: 0.436244 | Val. Loss: 0.428602 | Val. Kappa Score: 0.7073 | LR: 0.001250 | Estimated time: 21.48
Train loss on 50 batch: 0.427729
Train loss on 100 batch: 0.456081
Train loss on 150 batch: 0.451860
Train loss on 200 batch: 0.476896
Train loss on 250 batch: 0.507874
best-train-loss: 0.445022
best-valid-loss: 0.407077
best-kappa: 0.7152
: Epoch: 19 | Training Loss: 0.445022 | Val. Loss: 0.407077 | Val. Kappa Score: 0.7152 | LR: 0.001250 | Estimated time: 21.48
Train loss on 50 batch: 0.477344
Train loss on 100 batch: 0.432301
Train loss on 150 batch: 0.465051
Train loss on 200 batch: 0.437134
Train loss on 250 batch: 0.421570
: Epoch: 20 | Training Loss: 0.443190 | Val. Loss: 0.591214 | Val. Kappa Score: 0.7194 | LR: 0.001250 | Estimated time: 21.47
Train loss on 50 batch: 0.502384
Train loss on 100 batch: 0.543384
Train loss on 150 batch: 0.412204
Train loss on 200 batch: 0.430506
Train loss on 250 batch: 0.402247
: Epoch: 21 | Training Loss: 0.431888 | Val. Loss: 0.486781 | Val. Kappa Score: 0.7245 | LR: 0.001250 | Estimated time: 21.50
Train loss on 50 batch: 0.448226
Train loss on 100 batch: 0.436908
Train loss on 150 batch: 0.471911
Train loss on 200 batch: 0.422665
Train loss on 250 batch: 0.506014
: Epoch: 22 | Training Loss: 0.424200 | Val. Loss: 0.470562 | Val. Kappa Score: 0.7294 | LR: 0.000625 | Estimated time: 21.31
Train loss on 50 batch: 0.470310
Train loss on 100 batch: 0.447630
Train loss on 150 batch: 0.424351
Train loss on 200 batch: 0.357274
Train loss on 250 batch: 0.407572
best-train-loss: 0.419326
best-valid-loss: 0.402252
best-kappa: 0.7349
: Epoch: 23 | Training Loss: 0.419326 | Val. Loss: 0.402252 | Val. Kappa Score: 0.7349 | LR: 0.000625 | Estimated time: 21.31
Train loss on 50 batch: 0.412560
Train loss on 100 batch: 0.456495
Train loss on 150 batch: 0.402805
Train loss on 200 batch: 0.377552
Train loss on 250 batch: 0.436155
: Epoch: 24 | Training Loss: 0.385643 | Val. Loss: 0.424546 | Val. Kappa Score: 0.7395 | LR: 0.000625 | Estimated time: 21.60
Train loss on 50 batch: 0.411844
Train loss on 100 batch: 0.409194
Train loss on 150 batch: 0.343265
Train loss on 200 batch: 0.447099
Train loss on 250 batch: 0.369661
best-train-loss: 0.428906
best-valid-loss: 0.391976
best-kappa: 0.7445
: Epoch: 25 | Training Loss: 0.428906 | Val. Loss: 0.391976 | Val. Kappa Score: 0.7445 | LR: 0.000625 | Estimated time: 21.59
Train loss on 50 batch: 0.353293
Train loss on 100 batch: 0.442144
Train loss on 150 batch: 0.374212
Train loss on 200 batch: 0.360270
Train loss on 250 batch: 0.399780
: Epoch: 26 | Training Loss: 0.401547 | Val. Loss: 0.423190 | Val. Kappa Score: 0.7491 | LR: 0.000625 | Estimated time: 21.49
Train loss on 50 batch: 0.360775
Train loss on 100 batch: 0.374739
Train loss on 150 batch: 0.417646
Train loss on 200 batch: 0.343219
Train loss on 250 batch: 0.377512
best-train-loss: 0.402054
best-valid-loss: 0.389894
best-kappa: 0.7533
: Epoch: 27 | Training Loss: 0.402054 | Val. Loss: 0.389894 | Val. Kappa Score: 0.7533 | LR: 0.000625 | Estimated time: 21.75
Train loss on 50 batch: 0.339301
Train loss on 100 batch: 0.418315
Train loss on 150 batch: 0.384430
Train loss on 200 batch: 0.388284
Train loss on 250 batch: 0.372629
: Epoch: 28 | Training Loss: 0.370862 | Val. Loss: 0.427709 | Val. Kappa Score: 0.7568 | LR: 0.000625 | Estimated time: 21.51
Train loss on 50 batch: 0.345202
Train loss on 100 batch: 0.351038
Train loss on 150 batch: 0.378172
Train loss on 200 batch: 0.379329
Train loss on 250 batch: 0.367536
: Epoch: 29 | Training Loss: 0.368372 | Val. Loss: 0.409420 | Val. Kappa Score: 0.7607 | LR: 0.000625 | Estimated time: 21.93
Train loss on 50 batch: 0.369707
Train loss on 100 batch: 0.334474
Train loss on 150 batch: 0.385465
Train loss on 200 batch: 0.383615
Train loss on 250 batch: 0.344548
: Epoch: 30 | Training Loss: 0.350664 | Val. Loss: 0.392758 | Val. Kappa Score: 0.7642 | LR: 0.000313 | Estimated time: 21.63
Train loss on 50 batch: 0.348678
Train loss on 100 batch: 0.335719
Train loss on 150 batch: 0.334026
Train loss on 200 batch: 0.348925
Train loss on 250 batch: 0.364287
best-train-loss: 0.330361
best-valid-loss: 0.387728
best-kappa: 0.7675
: Epoch: 31 | Training Loss: 0.330361 | Val. Loss: 0.387728 | Val. Kappa Score: 0.7675 | LR: 0.000313 | Estimated time: 21.58
Train loss on 50 batch: 0.373989
Train loss on 100 batch: 0.311000
Train loss on 150 batch: 0.370543
Train loss on 200 batch: 0.362251
Train loss on 250 batch: 0.339919
: Epoch: 32 | Training Loss: 0.440113 | Val. Loss: 0.393218 | Val. Kappa Score: 0.7706 | LR: 0.000313 | Estimated time: 21.53
Train loss on 50 batch: 0.323363
Train loss on 100 batch: 0.348190
Train loss on 150 batch: 0.323575
Train loss on 200 batch: 0.345931
Train loss on 250 batch: 0.350897
best-train-loss: 0.365040
best-valid-loss: 0.383182
best-kappa: 0.7734
: Epoch: 33 | Training Loss: 0.365040 | Val. Loss: 0.383182 | Val. Kappa Score: 0.7734 | LR: 0.000313 | Estimated time: 21.55
Train loss on 50 batch: 0.298559
Train loss on 100 batch: 0.351028
Train loss on 150 batch: 0.337719
Train loss on 200 batch: 0.312990
Train loss on 250 batch: 0.327045
: Epoch: 34 | Training Loss: 0.313637 | Val. Loss: 0.395646 | Val. Kappa Score: 0.7763 | LR: 0.000313 | Estimated time: 21.43
Train loss on 50 batch: 0.330038
Train loss on 100 batch: 0.340837
Train loss on 150 batch: 0.368336
Train loss on 200 batch: 0.288696
Train loss on 250 batch: 0.355419
: Epoch: 35 | Training Loss: 0.319511 | Val. Loss: 0.386383 | Val. Kappa Score: 0.7789 | LR: 0.000313 | Estimated time: 21.64
Train loss on 50 batch: 0.328329
Train loss on 100 batch: 0.341302
Train loss on 150 batch: 0.345757
Train loss on 200 batch: 0.305941
Train loss on 250 batch: 0.346863
best-train-loss: 0.322314
best-valid-loss: 0.372886
best-kappa: 0.7815
: Epoch: 36 | Training Loss: 0.322314 | Val. Loss: 0.372886 | Val. Kappa Score: 0.7815 | LR: 0.000313 | Estimated time: 21.32
Train loss on 50 batch: 0.318193
Train loss on 100 batch: 0.298277
Train loss on 150 batch: 0.376702
Train loss on 200 batch: 0.330938
Train loss on 250 batch: 0.338414
best-train-loss: 0.304595
best-valid-loss: 0.370517
best-kappa: 0.7839
: Epoch: 37 | Training Loss: 0.304595 | Val. Loss: 0.370517 | Val. Kappa Score: 0.7839 | LR: 0.000313 | Estimated time: 21.85
Train loss on 50 batch: 0.306706
Train loss on 100 batch: 0.344557
Train loss on 150 batch: 0.295233
Train loss on 200 batch: 0.344891
Train loss on 250 batch: 0.325916
best-train-loss: 0.318455
best-valid-loss: 0.367155
best-kappa: 0.7864
: Epoch: 38 | Training Loss: 0.318455 | Val. Loss: 0.367155 | Val. Kappa Score: 0.7864 | LR: 0.000313 | Estimated time: 21.56
Train loss on 50 batch: 0.286626
Train loss on 100 batch: 0.300558
Train loss on 150 batch: 0.343620
Train loss on 200 batch: 0.319284
Train loss on 250 batch: 0.338185
: Epoch: 39 | Training Loss: 0.348689 | Val. Loss: 0.368059 | Val. Kappa Score: 0.7886 | LR: 0.000313 | Estimated time: 21.59
Train loss on 50 batch: 0.348073
Train loss on 100 batch: 0.292237
Train loss on 150 batch: 0.316268
Train loss on 200 batch: 0.285971
Train loss on 250 batch: 0.299054
: Epoch: 40 | Training Loss: 0.314656 | Val. Loss: 0.410447 | Val. Kappa Score: 0.7906 | LR: 0.000313 | Estimated time: 21.63
Train loss on 50 batch: 0.350843
Train loss on 100 batch: 0.344821
Train loss on 150 batch: 0.299757
Train loss on 200 batch: 0.313430
Train loss on 250 batch: 0.277012
: Epoch: 41 | Training Loss: 0.331993 | Val. Loss: 0.413384 | Val. Kappa Score: 0.7923 | LR: 0.000156 | Estimated time: 21.64
Train loss on 50 batch: 0.336859
Train loss on 100 batch: 0.305485
Train loss on 150 batch: 0.297416
Train loss on 200 batch: 0.278832
Train loss on 250 batch: 0.334315
best-train-loss: 0.308010
best-valid-loss: 0.362663
best-kappa: 0.7942
: Epoch: 42 | Training Loss: 0.308010 | Val. Loss: 0.362663 | Val. Kappa Score: 0.7942 | LR: 0.000156 | Estimated time: 21.60
Train loss on 50 batch: 0.280423
Train loss on 100 batch: 0.278206
Train loss on 150 batch: 0.276099
Train loss on 200 batch: 0.341465
Train loss on 250 batch: 0.308876
: Epoch: 43 | Training Loss: 0.306571 | Val. Loss: 0.372898 | Val. Kappa Score: 0.7961 | LR: 0.000156 | Estimated time: 21.50
Train loss on 50 batch: 0.257403
Train loss on 100 batch: 0.298937
Train loss on 150 batch: 0.311309
Train loss on 200 batch: 0.309560
Train loss on 250 batch: 0.292394
: Epoch: 44 | Training Loss: 0.288352 | Val. Loss: 0.383469 | Val. Kappa Score: 0.7978 | LR: 0.000156 | Estimated time: 21.55
Train loss on 50 batch: 0.359541
Train loss on 100 batch: 0.238136
Train loss on 150 batch: 0.233121
Train loss on 200 batch: 0.312653
Train loss on 250 batch: 0.330784
: Epoch: 45 | Training Loss: 0.295891 | Val. Loss: 0.376610 | Val. Kappa Score: 0.7995 | LR: 0.000078 | Estimated time: 21.70
Train loss on 50 batch: 0.311227
Train loss on 100 batch: 0.262171
Train loss on 150 batch: 0.306117
Train loss on 200 batch: 0.293070
Train loss on 250 batch: 0.312627
: Epoch: 46 | Training Loss: 0.294218 | Val. Loss: 0.369658 | Val. Kappa Score: 0.8010 | LR: 0.000078 | Estimated time: 21.63
Train loss on 50 batch: 0.292571
Train loss on 100 batch: 0.286317
Train loss on 150 batch: 0.280926
Train loss on 200 batch: 0.293033
Train loss on 250 batch: 0.267918
: Epoch: 47 | Training Loss: 0.250115 | Val. Loss: 0.375060 | Val. Kappa Score: 0.8025 | LR: 0.000078 | Estimated time: 21.56
Train loss on 50 batch: 0.291673
Train loss on 100 batch: 0.280176
Train loss on 150 batch: 0.326915
Train loss on 200 batch: 0.285718
Train loss on 250 batch: 0.265299
: Epoch: 48 | Training Loss: 0.320528 | Val. Loss: 0.375063 | Val. Kappa Score: 0.8041 | LR: 0.000039 | Estimated time: 21.68
Train loss on 50 batch: 0.310077
Train loss on 100 batch: 0.269866
Train loss on 150 batch: 0.311100
Train loss on 200 batch: 0.263761
Train loss on 250 batch: 0.285427
: Epoch: 49 | Training Loss: 0.275101 | Val. Loss: 0.365936 | Val. Kappa Score: 0.8056 | LR: 0.000039 | Estimated time: 21.85
Train loss on 50 batch: 0.234742
Train loss on 100 batch: 0.324698
Train loss on 150 batch: 0.300263
Train loss on 200 batch: 0.297181
Train loss on 250 batch: 0.275447
: Epoch: 50 | Training Loss: 0.282507 | Val. Loss: 0.367612 | Val. Kappa Score: 0.8069 | LR: 0.000039 | Estimated time: 21.51
time_estimated: 1079.91
n-epochs: 50
time_estimated: 1079.93
----------------------------------------

Experiment N: 81: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 17:56:06
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c04db00>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.361984
Train loss on 100 batch: 1.480965
Train loss on 150 batch: 1.257994
Train loss on 200 batch: 1.359498
Train loss on 250 batch: 1.464166
best-train-loss: 1.521361
best-valid-loss: 16.306614
best-kappa: -0.2522
: Epoch: 1 | Training Loss: 1.521361 | Val. Loss: 16.306614 | Val. Kappa Score: -0.2522 | LR: 0.005000 | Estimated time: 67.56
Train loss on 50 batch: 1.002542
Train loss on 100 batch: 1.120139
Train loss on 150 batch: 0.993734
Train loss on 200 batch: 1.063638
Train loss on 250 batch: 0.959161
best-train-loss: 1.016673
best-valid-loss: 1.641441
best-kappa: 0.1703
: Epoch: 2 | Training Loss: 1.016673 | Val. Loss: 1.641441 | Val. Kappa Score: 0.1703 | LR: 0.005000 | Estimated time: 67.45
Train loss on 50 batch: 0.988259
Train loss on 100 batch: 0.791311
Train loss on 150 batch: 0.957317
Train loss on 200 batch: 0.882864
Train loss on 250 batch: 0.834295
: Epoch: 3 | Training Loss: 0.853342 | Val. Loss: 2.909501 | Val. Kappa Score: 0.2681 | LR: 0.005000 | Estimated time: 67.39
Train loss on 50 batch: 0.820524
Train loss on 100 batch: 0.869789
Train loss on 150 batch: 0.891191
Train loss on 200 batch: 0.909936
Train loss on 250 batch: 0.928115
: Epoch: 4 | Training Loss: 0.913213 | Val. Loss: 1.819752 | Val. Kappa Score: 0.3294 | LR: 0.005000 | Estimated time: 67.45
Train loss on 50 batch: 0.791553
Train loss on 100 batch: 0.898323
Train loss on 150 batch: 0.694822
Train loss on 200 batch: 0.885965
Train loss on 250 batch: 0.835973
best-train-loss: 0.847370
best-valid-loss: 0.787187
best-kappa: 0.4117
: Epoch: 5 | Training Loss: 0.847370 | Val. Loss: 0.787187 | Val. Kappa Score: 0.4117 | LR: 0.005000 | Estimated time: 67.51
Train loss on 50 batch: 0.746585
Train loss on 100 batch: 0.828036
Train loss on 150 batch: 0.779479
Train loss on 200 batch: 0.753657
Train loss on 250 batch: 0.732241
: Epoch: 6 | Training Loss: 0.790375 | Val. Loss: 0.810371 | Val. Kappa Score: 0.4711 | LR: 0.005000 | Estimated time: 67.34
Train loss on 50 batch: 0.807722
Train loss on 100 batch: 0.712821
Train loss on 150 batch: 0.774762
Train loss on 200 batch: 0.743165
Train loss on 250 batch: 0.734249
best-train-loss: 0.740301
best-valid-loss: 0.661037
best-kappa: 0.5160
: Epoch: 7 | Training Loss: 0.740301 | Val. Loss: 0.661037 | Val. Kappa Score: 0.5160 | LR: 0.005000 | Estimated time: 67.51
Train loss on 50 batch: 0.674391
Train loss on 100 batch: 0.726140
Train loss on 150 batch: 0.802142
Train loss on 200 batch: 0.842826
Train loss on 250 batch: 0.663465
: Epoch: 8 | Training Loss: 0.750413 | Val. Loss: 0.702677 | Val. Kappa Score: 0.5519 | LR: 0.005000 | Estimated time: 67.39
Train loss on 50 batch: 0.767368
Train loss on 100 batch: 0.747725
Train loss on 150 batch: 0.874569
Train loss on 200 batch: 0.760699
Train loss on 250 batch: 0.778049
: Epoch: 9 | Training Loss: 0.773711 | Val. Loss: 1.174113 | Val. Kappa Score: 0.5452 | LR: 0.005000 | Estimated time: 67.44
Train loss on 50 batch: 0.791968
Train loss on 100 batch: 0.780821
Train loss on 150 batch: 0.790100
Train loss on 200 batch: 0.648615
Train loss on 250 batch: 0.647262
best-train-loss: 0.703063
best-valid-loss: 0.603612
best-kappa: 0.5656
: Epoch: 10 | Training Loss: 0.703063 | Val. Loss: 0.603612 | Val. Kappa Score: 0.5656 | LR: 0.005000 | Estimated time: 67.45
Train loss on 50 batch: 0.751620
Train loss on 100 batch: 0.745466
Train loss on 150 batch: 0.723341
Train loss on 200 batch: 0.682127
Train loss on 250 batch: 0.769323
: Epoch: 11 | Training Loss: 0.779816 | Val. Loss: 0.690570 | Val. Kappa Score: 0.5861 | LR: 0.005000 | Estimated time: 67.51
Train loss on 50 batch: 0.656559
Train loss on 100 batch: 0.742110
Train loss on 150 batch: 0.671387
Train loss on 200 batch: 0.768388
Train loss on 250 batch: 0.760154
: Epoch: 12 | Training Loss: 0.824250 | Val. Loss: 0.861761 | Val. Kappa Score: 0.6024 | LR: 0.005000 | Estimated time: 67.46
Train loss on 50 batch: 0.726212
Train loss on 100 batch: 0.725665
Train loss on 150 batch: 0.704993
Train loss on 200 batch: 0.678413
Train loss on 250 batch: 0.724952
: Epoch: 13 | Training Loss: 0.661782 | Val. Loss: 0.925752 | Val. Kappa Score: 0.6112 | LR: 0.002500 | Estimated time: 67.36
Train loss on 50 batch: 0.662194
Train loss on 100 batch: 0.599687
Train loss on 150 batch: 0.624823
Train loss on 200 batch: 0.649325
Train loss on 250 batch: 0.647211
best-train-loss: 0.701860
best-valid-loss: 0.498034
best-kappa: 0.6259
: Epoch: 14 | Training Loss: 0.701860 | Val. Loss: 0.498034 | Val. Kappa Score: 0.6259 | LR: 0.002500 | Estimated time: 67.44
Train loss on 50 batch: 0.576720
Train loss on 100 batch: 0.617997
Train loss on 150 batch: 0.690979
Train loss on 200 batch: 0.547927
Train loss on 250 batch: 0.613426
: Epoch: 15 | Training Loss: 0.582107 | Val. Loss: 0.794198 | Val. Kappa Score: 0.6340 | LR: 0.002500 | Estimated time: 67.48
Train loss on 50 batch: 0.566613
Train loss on 100 batch: 0.526995
Train loss on 150 batch: 0.529897
Train loss on 200 batch: 0.539581
Train loss on 250 batch: 0.470016
: Epoch: 16 | Training Loss: 0.533081 | Val. Loss: 0.803865 | Val. Kappa Score: 0.6408 | LR: 0.002500 | Estimated time: 67.39
Train loss on 50 batch: 0.504347
Train loss on 100 batch: 0.517688
Train loss on 150 batch: 0.546184
Train loss on 200 batch: 0.571857
Train loss on 250 batch: 0.552084
: Epoch: 17 | Training Loss: 0.582271 | Val. Loss: 0.523212 | Val. Kappa Score: 0.6499 | LR: 0.001250 | Estimated time: 67.46
Train loss on 50 batch: 0.533453
Train loss on 100 batch: 0.519271
Train loss on 150 batch: 0.510576
Train loss on 200 batch: 0.456481
Train loss on 250 batch: 0.500937
best-train-loss: 0.460178
best-valid-loss: 0.491587
best-kappa: 0.6589
: Epoch: 18 | Training Loss: 0.460178 | Val. Loss: 0.491587 | Val. Kappa Score: 0.6589 | LR: 0.001250 | Estimated time: 67.43
Train loss on 50 batch: 0.438736
Train loss on 100 batch: 0.465644
Train loss on 150 batch: 0.459612
Train loss on 200 batch: 0.475606
Train loss on 250 batch: 0.480247
best-train-loss: 0.468367
best-valid-loss: 0.442355
best-kappa: 0.6691
: Epoch: 19 | Training Loss: 0.468367 | Val. Loss: 0.442355 | Val. Kappa Score: 0.6691 | LR: 0.001250 | Estimated time: 67.55
Train loss on 50 batch: 0.498683
Train loss on 100 batch: 0.478475
Train loss on 150 batch: 0.441514
Train loss on 200 batch: 0.466183
Train loss on 250 batch: 0.429677
best-train-loss: 0.451209
best-valid-loss: 0.441570
best-kappa: 0.6775
: Epoch: 20 | Training Loss: 0.451209 | Val. Loss: 0.441570 | Val. Kappa Score: 0.6775 | LR: 0.001250 | Estimated time: 67.47
Train loss on 50 batch: 0.452113
Train loss on 100 batch: 0.497308
Train loss on 150 batch: 0.408160
Train loss on 200 batch: 0.454984
Train loss on 250 batch: 0.437509
: Epoch: 21 | Training Loss: 0.429324 | Val. Loss: 0.488321 | Val. Kappa Score: 0.6841 | LR: 0.001250 | Estimated time: 67.45
Train loss on 50 batch: 0.458297
Train loss on 100 batch: 0.419882
Train loss on 150 batch: 0.483298
Train loss on 200 batch: 0.434476
Train loss on 250 batch: 0.493995
: Epoch: 22 | Training Loss: 0.449782 | Val. Loss: 0.492793 | Val. Kappa Score: 0.6907 | LR: 0.001250 | Estimated time: 67.46
Train loss on 50 batch: 0.441805
Train loss on 100 batch: 0.446782
Train loss on 150 batch: 0.422058
Train loss on 200 batch: 0.383131
Train loss on 250 batch: 0.491905
best-train-loss: 0.433976
best-valid-loss: 0.434248
best-kappa: 0.6969
: Epoch: 23 | Training Loss: 0.433976 | Val. Loss: 0.434248 | Val. Kappa Score: 0.6969 | LR: 0.001250 | Estimated time: 67.38
Train loss on 50 batch: 0.491900
Train loss on 100 batch: 0.461737
Train loss on 150 batch: 0.451274
Train loss on 200 batch: 0.432867
Train loss on 250 batch: 0.467869
: Epoch: 24 | Training Loss: 0.414930 | Val. Loss: 0.449912 | Val. Kappa Score: 0.7028 | LR: 0.001250 | Estimated time: 67.64
Train loss on 50 batch: 0.448122
Train loss on 100 batch: 0.432695
Train loss on 150 batch: 0.375555
Train loss on 200 batch: 0.464995
Train loss on 250 batch: 0.371884
: Epoch: 25 | Training Loss: 0.413497 | Val. Loss: 0.574220 | Val. Kappa Score: 0.7074 | LR: 0.001250 | Estimated time: 68.12
Train loss on 50 batch: 0.405020
Train loss on 100 batch: 0.436050
Train loss on 150 batch: 0.425167
Train loss on 200 batch: 0.407467
Train loss on 250 batch: 0.439535
: Epoch: 26 | Training Loss: 0.463407 | Val. Loss: 0.498112 | Val. Kappa Score: 0.7121 | LR: 0.000625 | Estimated time: 69.61
Train loss on 50 batch: 0.373858
Train loss on 100 batch: 0.384481
Train loss on 150 batch: 0.409650
Train loss on 200 batch: 0.343478
Train loss on 250 batch: 0.391223
best-train-loss: 0.397357
best-valid-loss: 0.399733
best-kappa: 0.7175
: Epoch: 27 | Training Loss: 0.397357 | Val. Loss: 0.399733 | Val. Kappa Score: 0.7175 | LR: 0.000625 | Estimated time: 69.26
Train loss on 50 batch: 0.326285
Train loss on 100 batch: 0.396428
Train loss on 150 batch: 0.381259
Train loss on 200 batch: 0.363013
Train loss on 250 batch: 0.368769
: Epoch: 28 | Training Loss: 0.356210 | Val. Loss: 0.403509 | Val. Kappa Score: 0.7223 | LR: 0.000625 | Estimated time: 68.65
Train loss on 50 batch: 0.334989
Train loss on 100 batch: 0.373908
Train loss on 150 batch: 0.372565
Train loss on 200 batch: 0.345009
Train loss on 250 batch: 0.371290
: Epoch: 29 | Training Loss: 0.349819 | Val. Loss: 0.402820 | Val. Kappa Score: 0.7271 | LR: 0.000625 | Estimated time: 68.74
Train loss on 50 batch: 0.379767
Train loss on 100 batch: 0.344274
Train loss on 150 batch: 0.361725
Train loss on 200 batch: 0.358043
Train loss on 250 batch: 0.359209
: Epoch: 30 | Training Loss: 0.362043 | Val. Loss: 0.414394 | Val. Kappa Score: 0.7314 | LR: 0.000313 | Estimated time: 69.45
Train loss on 50 batch: 0.318614
Train loss on 100 batch: 0.298950
Train loss on 150 batch: 0.333121
Train loss on 200 batch: 0.354366
Train loss on 250 batch: 0.365983
: Epoch: 31 | Training Loss: 0.322912 | Val. Loss: 0.402062 | Val. Kappa Score: 0.7356 | LR: 0.000313 | Estimated time: 68.67
Train loss on 50 batch: 0.368063
Train loss on 100 batch: 0.287943
Train loss on 150 batch: 0.324297
Train loss on 200 batch: 0.351951
Train loss on 250 batch: 0.349090
: Epoch: 32 | Training Loss: 0.387876 | Val. Loss: 0.457650 | Val. Kappa Score: 0.7390 | LR: 0.000313 | Estimated time: 68.05
Train loss on 50 batch: 0.331646
Train loss on 100 batch: 0.332913
Train loss on 150 batch: 0.308463
Train loss on 200 batch: 0.306628
Train loss on 250 batch: 0.322773
: Epoch: 33 | Training Loss: 0.348940 | Val. Loss: 0.416492 | Val. Kappa Score: 0.7424 | LR: 0.000156 | Estimated time: 67.94
Train loss on 50 batch: 0.309244
Train loss on 100 batch: 0.331265
Train loss on 150 batch: 0.344131
Train loss on 200 batch: 0.306333
Train loss on 250 batch: 0.320870
best-train-loss: 0.309420
best-valid-loss: 0.388674
best-kappa: 0.7461
: Epoch: 34 | Training Loss: 0.309420 | Val. Loss: 0.388674 | Val. Kappa Score: 0.7461 | LR: 0.000156 | Estimated time: 67.89
Train loss on 50 batch: 0.305839
Train loss on 100 batch: 0.338890
Train loss on 150 batch: 0.320876
Train loss on 200 batch: 0.265966
Train loss on 250 batch: 0.308502
best-train-loss: 0.282410
best-valid-loss: 0.387603
best-kappa: 0.7496
: Epoch: 35 | Training Loss: 0.282410 | Val. Loss: 0.387603 | Val. Kappa Score: 0.7496 | LR: 0.000156 | Estimated time: 67.66
Train loss on 50 batch: 0.319689
Train loss on 100 batch: 0.309180
Train loss on 150 batch: 0.325672
Train loss on 200 batch: 0.293271
Train loss on 250 batch: 0.323478
best-train-loss: 0.335780
best-valid-loss: 0.380675
best-kappa: 0.7530
: Epoch: 36 | Training Loss: 0.335780 | Val. Loss: 0.380675 | Val. Kappa Score: 0.7530 | LR: 0.000156 | Estimated time: 68.37
Train loss on 50 batch: 0.275338
Train loss on 100 batch: 0.280576
Train loss on 150 batch: 0.372841
Train loss on 200 batch: 0.297898
Train loss on 250 batch: 0.323019
: Epoch: 37 | Training Loss: 0.298849 | Val. Loss: 0.396597 | Val. Kappa Score: 0.7562 | LR: 0.000156 | Estimated time: 68.40
Train loss on 50 batch: 0.302837
Train loss on 100 batch: 0.351048
Train loss on 150 batch: 0.296749
Train loss on 200 batch: 0.331610
Train loss on 250 batch: 0.303971
: Epoch: 38 | Training Loss: 0.339061 | Val. Loss: 0.382094 | Val. Kappa Score: 0.7593 | LR: 0.000156 | Estimated time: 68.13
Train loss on 50 batch: 0.261871
Train loss on 100 batch: 0.307133
Train loss on 150 batch: 0.301218
Train loss on 200 batch: 0.295396
Train loss on 250 batch: 0.334373
: Epoch: 39 | Training Loss: 0.329742 | Val. Loss: 0.383554 | Val. Kappa Score: 0.7622 | LR: 0.000078 | Estimated time: 68.04
Train loss on 50 batch: 0.299743
Train loss on 100 batch: 0.286151
Train loss on 150 batch: 0.312027
Train loss on 200 batch: 0.282266
Train loss on 250 batch: 0.276575
: Epoch: 40 | Training Loss: 0.300083 | Val. Loss: 0.382536 | Val. Kappa Score: 0.7648 | LR: 0.000078 | Estimated time: 68.52
Train loss on 50 batch: 0.306735
Train loss on 100 batch: 0.316330
Train loss on 150 batch: 0.266237
Train loss on 200 batch: 0.306729
Train loss on 250 batch: 0.284506
: Epoch: 41 | Training Loss: 0.314891 | Val. Loss: 0.386840 | Val. Kappa Score: 0.7675 | LR: 0.000078 | Estimated time: 68.34
Train loss on 50 batch: 0.309228
Train loss on 100 batch: 0.312191
Train loss on 150 batch: 0.274717
Train loss on 200 batch: 0.260050
Train loss on 250 batch: 0.306679
best-train-loss: 0.289386
best-valid-loss: 0.375109
best-kappa: 0.7698
: Epoch: 42 | Training Loss: 0.289386 | Val. Loss: 0.375109 | Val. Kappa Score: 0.7698 | LR: 0.000078 | Estimated time: 68.78
Train loss on 50 batch: 0.278333
Train loss on 100 batch: 0.295286
Train loss on 150 batch: 0.261859
Train loss on 200 batch: 0.350484
Train loss on 250 batch: 0.295428
: Epoch: 43 | Training Loss: 0.304695 | Val. Loss: 0.384274 | Val. Kappa Score: 0.7723 | LR: 0.000078 | Estimated time: 68.32
Train loss on 50 batch: 0.298843
Train loss on 100 batch: 0.314203
Train loss on 150 batch: 0.301796
Train loss on 200 batch: 0.328317
Train loss on 250 batch: 0.283297
best-train-loss: 0.295960
best-valid-loss: 0.374919
best-kappa: 0.7746
: Epoch: 44 | Training Loss: 0.295960 | Val. Loss: 0.374919 | Val. Kappa Score: 0.7746 | LR: 0.000078 | Estimated time: 69.33
Train loss on 50 batch: 0.359402
Train loss on 100 batch: 0.261495
Train loss on 150 batch: 0.259683
Train loss on 200 batch: 0.293920
Train loss on 250 batch: 0.297948
best-train-loss: 0.305842
best-valid-loss: 0.373030
best-kappa: 0.7767
: Epoch: 45 | Training Loss: 0.305842 | Val. Loss: 0.373030 | Val. Kappa Score: 0.7767 | LR: 0.000078 | Estimated time: 69.57
Train loss on 50 batch: 0.291758
Train loss on 100 batch: 0.284416
Train loss on 150 batch: 0.246774
Train loss on 200 batch: 0.301106
Train loss on 250 batch: 0.312499
: Epoch: 46 | Training Loss: 0.268538 | Val. Loss: 0.376629 | Val. Kappa Score: 0.7787 | LR: 0.000078 | Estimated time: 68.37
Train loss on 50 batch: 0.288286
Train loss on 100 batch: 0.279721
Train loss on 150 batch: 0.269496
Train loss on 200 batch: 0.316797
Train loss on 250 batch: 0.265797
: Epoch: 47 | Training Loss: 0.253732 | Val. Loss: 0.375522 | Val. Kappa Score: 0.7808 | LR: 0.000078 | Estimated time: 68.29
Train loss on 50 batch: 0.293620
Train loss on 100 batch: 0.267145
Train loss on 150 batch: 0.314958
Train loss on 200 batch: 0.263203
Train loss on 250 batch: 0.269890
: Epoch: 48 | Training Loss: 0.332388 | Val. Loss: 0.382066 | Val. Kappa Score: 0.7829 | LR: 0.000039 | Estimated time: 67.87
Train loss on 50 batch: 0.302392
Train loss on 100 batch: 0.259126
Train loss on 150 batch: 0.316576
Train loss on 200 batch: 0.280611
Train loss on 250 batch: 0.274061
best-train-loss: 0.267763
best-valid-loss: 0.372154
best-kappa: 0.7847
: Epoch: 49 | Training Loss: 0.267763 | Val. Loss: 0.372154 | Val. Kappa Score: 0.7847 | LR: 0.000039 | Estimated time: 67.64
Train loss on 50 batch: 0.247820
Train loss on 100 batch: 0.311129
Train loss on 150 batch: 0.295507
Train loss on 200 batch: 0.302810
Train loss on 250 batch: 0.257886
: Epoch: 50 | Training Loss: 0.264649 | Val. Loss: 0.375379 | Val. Kappa Score: 0.7864 | LR: 0.000039 | Estimated time: 67.63
Train loss on 50 batch: 0.313181
Train loss on 100 batch: 0.282657
Train loss on 150 batch: 0.287601
Train loss on 200 batch: 0.280270
Train loss on 250 batch: 0.268772
: Epoch: 51 | Training Loss: 0.275743 | Val. Loss: 0.373143 | Val. Kappa Score: 0.7881 | LR: 0.000039 | Estimated time: 67.67
Train loss on 50 batch: 0.270270
Train loss on 100 batch: 0.304943
Train loss on 150 batch: 0.302824
Train loss on 200 batch: 0.296704
Train loss on 250 batch: 0.258734
: Epoch: 52 | Training Loss: 0.306406 | Val. Loss: 0.375703 | Val. Kappa Score: 0.7897 | LR: 0.000020 | Estimated time: 67.57
Train loss on 50 batch: 0.257360
Train loss on 100 batch: 0.294802
Train loss on 150 batch: 0.270002
Train loss on 200 batch: 0.313126
Train loss on 250 batch: 0.253115
: Epoch: 53 | Training Loss: 0.253338 | Val. Loss: 0.373870 | Val. Kappa Score: 0.7913 | LR: 0.000020 | Estimated time: 67.79
Train loss on 50 batch: 0.276691
Train loss on 100 batch: 0.297164
Train loss on 150 batch: 0.312278
Train loss on 200 batch: 0.265226
Train loss on 250 batch: 0.288374
: Epoch: 54 | Training Loss: 0.269489 | Val. Loss: 0.373580 | Val. Kappa Score: 0.7928 | LR: 0.000020 | Estimated time: 67.52
Train loss on 50 batch: 0.276707
Train loss on 100 batch: 0.249427
Train loss on 150 batch: 0.273225
Train loss on 200 batch: 0.290948
Train loss on 250 batch: 0.282940
: Epoch: 55 | Training Loss: 0.250863 | Val. Loss: 0.372874 | Val. Kappa Score: 0.7942 | LR: 0.000010 | Estimated time: 67.55
Train loss on 50 batch: 0.268519
Train loss on 100 batch: 0.288141
Train loss on 150 batch: 0.304977
Train loss on 200 batch: 0.266669
Train loss on 250 batch: 0.299197
: Epoch: 56 | Training Loss: 0.262098 | Val. Loss: 0.372637 | Val. Kappa Score: 0.7957 | LR: 0.000010 | Estimated time: 67.67
Train loss on 50 batch: 0.270093
Train loss on 100 batch: 0.245681
Train loss on 150 batch: 0.245984
Train loss on 200 batch: 0.326391
Train loss on 250 batch: 0.263924
: Epoch: 57 | Training Loss: 0.259317 | Val. Loss: 0.373560 | Val. Kappa Score: 0.7970 | LR: 0.000010 | Estimated time: 67.46
time_estimated: 3874.64
n-epochs: 57
time_estimated: 3874.66
----------------------------------------

Experiment N: 82: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.14 19:00:41
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95ffcdd8>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.815934
Train loss on 100 batch: 1.756700
Train loss on 150 batch: 1.584908
Train loss on 200 batch: 1.598067
Train loss on 250 batch: 1.549136
best-train-loss: 1.759658
best-valid-loss: 4.919354
best-kappa: -0.1455
: Epoch: 1 | Training Loss: 1.759658 | Val. Loss: 4.919354 | Val. Kappa Score: -0.1455 | LR: 0.010000 | Estimated time: 21.89
Train loss on 50 batch: 1.267295
Train loss on 100 batch: 1.243684
Train loss on 150 batch: 1.120781
Train loss on 200 batch: 1.253134
Train loss on 250 batch: 1.072261
best-train-loss: 1.278156
best-valid-loss: 1.202219
best-kappa: 0.2678
: Epoch: 2 | Training Loss: 1.278156 | Val. Loss: 1.202219 | Val. Kappa Score: 0.2678 | LR: 0.010000 | Estimated time: 21.70
Train loss on 50 batch: 1.260597
Train loss on 100 batch: 1.064720
Train loss on 150 batch: 1.182877
Train loss on 200 batch: 1.054923
Train loss on 250 batch: 0.965034
: Epoch: 3 | Training Loss: 1.112822 | Val. Loss: 1.678720 | Val. Kappa Score: 0.3743 | LR: 0.010000 | Estimated time: 21.73
Train loss on 50 batch: 1.053147
Train loss on 100 batch: 0.961202
Train loss on 150 batch: 1.027352
Train loss on 200 batch: 1.014484
Train loss on 250 batch: 1.227521
: Epoch: 4 | Training Loss: 1.102936 | Val. Loss: 3.376219 | Val. Kappa Score: 0.2990 | LR: 0.010000 | Estimated time: 21.64
Train loss on 50 batch: 0.917629
Train loss on 100 batch: 1.017476
Train loss on 150 batch: 0.839206
Train loss on 200 batch: 1.030127
Train loss on 250 batch: 0.984328
: Epoch: 5 | Training Loss: 0.913440 | Val. Loss: 1.999757 | Val. Kappa Score: 0.3368 | LR: 0.005000 | Estimated time: 21.59
Train loss on 50 batch: 0.818225
Train loss on 100 batch: 0.846317
Train loss on 150 batch: 0.820861
Train loss on 200 batch: 0.803521
Train loss on 250 batch: 0.730090
best-train-loss: 0.795132
best-valid-loss: 0.653889
best-kappa: 0.4021
: Epoch: 6 | Training Loss: 0.795132 | Val. Loss: 0.653889 | Val. Kappa Score: 0.4021 | LR: 0.005000 | Estimated time: 21.73
Train loss on 50 batch: 0.751959
Train loss on 100 batch: 0.727972
Train loss on 150 batch: 0.772734
Train loss on 200 batch: 0.806226
Train loss on 250 batch: 0.789478
: Epoch: 7 | Training Loss: 0.758463 | Val. Loss: 1.657281 | Val. Kappa Score: 0.4219 | LR: 0.005000 | Estimated time: 21.65
Train loss on 50 batch: 0.711446
Train loss on 100 batch: 0.835847
Train loss on 150 batch: 0.800751
Train loss on 200 batch: 0.918642
Train loss on 250 batch: 0.652987
: Epoch: 8 | Training Loss: 0.727311 | Val. Loss: 1.520185 | Val. Kappa Score: 0.4342 | LR: 0.005000 | Estimated time: 21.63
Train loss on 50 batch: 0.753273
Train loss on 100 batch: 0.757771
Train loss on 150 batch: 0.848348
Train loss on 200 batch: 0.761850
Train loss on 250 batch: 0.746321
: Epoch: 9 | Training Loss: 0.776918 | Val. Loss: 1.097304 | Val. Kappa Score: 0.4583 | LR: 0.002500 | Estimated time: 21.80
Train loss on 50 batch: 0.686872
Train loss on 100 batch: 0.782798
Train loss on 150 batch: 0.728291
Train loss on 200 batch: 0.626154
Train loss on 250 batch: 0.644209
best-train-loss: 0.667109
best-valid-loss: 0.526426
best-kappa: 0.4945
: Epoch: 10 | Training Loss: 0.667109 | Val. Loss: 0.526426 | Val. Kappa Score: 0.4945 | LR: 0.002500 | Estimated time: 21.54
Train loss on 50 batch: 0.656774
Train loss on 100 batch: 0.662662
Train loss on 150 batch: 0.670537
Train loss on 200 batch: 0.663424
Train loss on 250 batch: 0.698991
: Epoch: 11 | Training Loss: 0.689229 | Val. Loss: 0.534803 | Val. Kappa Score: 0.5237 | LR: 0.002500 | Estimated time: 21.62
Train loss on 50 batch: 0.593419
Train loss on 100 batch: 0.655724
Train loss on 150 batch: 0.636676
Train loss on 200 batch: 0.709249
Train loss on 250 batch: 0.700840
: Epoch: 12 | Training Loss: 0.721291 | Val. Loss: 0.559162 | Val. Kappa Score: 0.5461 | LR: 0.002500 | Estimated time: 21.44
Train loss on 50 batch: 0.691337
Train loss on 100 batch: 0.667393
Train loss on 150 batch: 0.573444
Train loss on 200 batch: 0.581488
Train loss on 250 batch: 0.681631
: Epoch: 13 | Training Loss: 0.611751 | Val. Loss: 0.538647 | Val. Kappa Score: 0.5656 | LR: 0.001250 | Estimated time: 21.78
Train loss on 50 batch: 0.595714
Train loss on 100 batch: 0.573850
Train loss on 150 batch: 0.564583
Train loss on 200 batch: 0.646330
Train loss on 250 batch: 0.603537
: Epoch: 14 | Training Loss: 0.648305 | Val. Loss: 0.789981 | Val. Kappa Score: 0.5808 | LR: 0.001250 | Estimated time: 21.81
Train loss on 50 batch: 0.542602
Train loss on 100 batch: 0.583221
Train loss on 150 batch: 0.628213
Train loss on 200 batch: 0.519731
Train loss on 250 batch: 0.601763
: Epoch: 15 | Training Loss: 0.575867 | Val. Loss: 0.562316 | Val. Kappa Score: 0.5957 | LR: 0.001250 | Estimated time: 21.72
Train loss on 50 batch: 0.589055
Train loss on 100 batch: 0.516778
Train loss on 150 batch: 0.563385
Train loss on 200 batch: 0.527243
Train loss on 250 batch: 0.493570
: Epoch: 16 | Training Loss: 0.538906 | Val. Loss: 0.532809 | Val. Kappa Score: 0.6093 | LR: 0.000625 | Estimated time: 21.69
Train loss on 50 batch: 0.516096
Train loss on 100 batch: 0.521519
Train loss on 150 batch: 0.494396
Train loss on 200 batch: 0.545026
Train loss on 250 batch: 0.570278
best-train-loss: 0.519383
best-valid-loss: 0.485802
best-kappa: 0.6222
: Epoch: 17 | Training Loss: 0.519383 | Val. Loss: 0.485802 | Val. Kappa Score: 0.6222 | LR: 0.000625 | Estimated time: 21.89
Train loss on 50 batch: 0.528540
Train loss on 100 batch: 0.500401
Train loss on 150 batch: 0.542407
Train loss on 200 batch: 0.512588
Train loss on 250 batch: 0.507079
: Epoch: 18 | Training Loss: 0.485687 | Val. Loss: 0.521568 | Val. Kappa Score: 0.6322 | LR: 0.000625 | Estimated time: 21.43
Train loss on 50 batch: 0.484220
Train loss on 100 batch: 0.519703
Train loss on 150 batch: 0.504558
Train loss on 200 batch: 0.522159
Train loss on 250 batch: 0.525879
best-train-loss: 0.531704
best-valid-loss: 0.438034
best-kappa: 0.6440
: Epoch: 19 | Training Loss: 0.531704 | Val. Loss: 0.438034 | Val. Kappa Score: 0.6440 | LR: 0.000625 | Estimated time: 21.97
Train loss on 50 batch: 0.514406
Train loss on 100 batch: 0.491553
Train loss on 150 batch: 0.498369
Train loss on 200 batch: 0.480178
Train loss on 250 batch: 0.501838
best-train-loss: 0.515058
best-valid-loss: 0.434531
best-kappa: 0.6536
: Epoch: 20 | Training Loss: 0.515058 | Val. Loss: 0.434531 | Val. Kappa Score: 0.6536 | LR: 0.000625 | Estimated time: 21.80
Train loss on 50 batch: 0.528908
Train loss on 100 batch: 0.523799
Train loss on 150 batch: 0.498121
Train loss on 200 batch: 0.484874
Train loss on 250 batch: 0.472679
: Epoch: 21 | Training Loss: 0.472184 | Val. Loss: 0.603647 | Val. Kappa Score: 0.6607 | LR: 0.000625 | Estimated time: 21.96
Train loss on 50 batch: 0.500277
Train loss on 100 batch: 0.462802
Train loss on 150 batch: 0.531755
Train loss on 200 batch: 0.487065
Train loss on 250 batch: 0.525965
: Epoch: 22 | Training Loss: 0.479574 | Val. Loss: 0.462432 | Val. Kappa Score: 0.6683 | LR: 0.000625 | Estimated time: 21.70
Train loss on 50 batch: 0.507065
Train loss on 100 batch: 0.480474
Train loss on 150 batch: 0.484085
Train loss on 200 batch: 0.444484
Train loss on 250 batch: 0.525737
: Epoch: 23 | Training Loss: 0.466845 | Val. Loss: 0.465916 | Val. Kappa Score: 0.6761 | LR: 0.000313 | Estimated time: 21.76
Train loss on 50 batch: 0.535372
Train loss on 100 batch: 0.487510
Train loss on 150 batch: 0.429058
Train loss on 200 batch: 0.459581
Train loss on 250 batch: 0.495103
best-train-loss: 0.442975
best-valid-loss: 0.431868
best-kappa: 0.6834
: Epoch: 24 | Training Loss: 0.442975 | Val. Loss: 0.431868 | Val. Kappa Score: 0.6834 | LR: 0.000313 | Estimated time: 21.84
Train loss on 50 batch: 0.453797
Train loss on 100 batch: 0.466660
Train loss on 150 batch: 0.388488
Train loss on 200 batch: 0.503019
Train loss on 250 batch: 0.429747
: Epoch: 25 | Training Loss: 0.450666 | Val. Loss: 0.441452 | Val. Kappa Score: 0.6900 | LR: 0.000313 | Estimated time: 21.71
Train loss on 50 batch: 0.442339
Train loss on 100 batch: 0.527509
Train loss on 150 batch: 0.457147
Train loss on 200 batch: 0.412014
Train loss on 250 batch: 0.425446
: Epoch: 26 | Training Loss: 0.452106 | Val. Loss: 0.461291 | Val. Kappa Score: 0.6953 | LR: 0.000313 | Estimated time: 21.66
Train loss on 50 batch: 0.443994
Train loss on 100 batch: 0.393598
Train loss on 150 batch: 0.492270
Train loss on 200 batch: 0.413073
Train loss on 250 batch: 0.455397
best-train-loss: 0.476138
best-valid-loss: 0.415254
best-kappa: 0.7010
: Epoch: 27 | Training Loss: 0.476138 | Val. Loss: 0.415254 | Val. Kappa Score: 0.7010 | LR: 0.000313 | Estimated time: 21.35
Train loss on 50 batch: 0.380784
Train loss on 100 batch: 0.485034
Train loss on 150 batch: 0.462217
Train loss on 200 batch: 0.435798
Train loss on 250 batch: 0.422226
: Epoch: 28 | Training Loss: 0.435187 | Val. Loss: 0.425050 | Val. Kappa Score: 0.7066 | LR: 0.000313 | Estimated time: 21.58
Train loss on 50 batch: 0.383766
Train loss on 100 batch: 0.416073
Train loss on 150 batch: 0.424869
Train loss on 200 batch: 0.438255
Train loss on 250 batch: 0.464116
: Epoch: 29 | Training Loss: 0.436733 | Val. Loss: 0.489396 | Val. Kappa Score: 0.7106 | LR: 0.000313 | Estimated time: 21.77
Train loss on 50 batch: 0.445889
Train loss on 100 batch: 0.410615
Train loss on 150 batch: 0.428611
Train loss on 200 batch: 0.434405
Train loss on 250 batch: 0.394879
: Epoch: 30 | Training Loss: 0.442610 | Val. Loss: 0.446778 | Val. Kappa Score: 0.7147 | LR: 0.000156 | Estimated time: 21.72
Train loss on 50 batch: 0.384960
Train loss on 100 batch: 0.383807
Train loss on 150 batch: 0.405842
Train loss on 200 batch: 0.438926
Train loss on 250 batch: 0.430633
: Epoch: 31 | Training Loss: 0.415797 | Val. Loss: 0.419092 | Val. Kappa Score: 0.7191 | LR: 0.000156 | Estimated time: 21.30
Train loss on 50 batch: 0.433262
Train loss on 100 batch: 0.362396
Train loss on 150 batch: 0.416443
Train loss on 200 batch: 0.440697
Train loss on 250 batch: 0.410725
: Epoch: 32 | Training Loss: 0.469175 | Val. Loss: 0.428591 | Val. Kappa Score: 0.7234 | LR: 0.000156 | Estimated time: 21.42
Train loss on 50 batch: 0.388879
Train loss on 100 batch: 0.406676
Train loss on 150 batch: 0.381819
Train loss on 200 batch: 0.420331
Train loss on 250 batch: 0.446567
best-train-loss: 0.439958
best-valid-loss: 0.405531
best-kappa: 0.7272
: Epoch: 33 | Training Loss: 0.439958 | Val. Loss: 0.405531 | Val. Kappa Score: 0.7272 | LR: 0.000156 | Estimated time: 22.23
Train loss on 50 batch: 0.358870
Train loss on 100 batch: 0.404912
Train loss on 150 batch: 0.436800
Train loss on 200 batch: 0.411033
Train loss on 250 batch: 0.425133
: Epoch: 34 | Training Loss: 0.397979 | Val. Loss: 0.439098 | Val. Kappa Score: 0.7307 | LR: 0.000156 | Estimated time: 21.77
Train loss on 50 batch: 0.404300
Train loss on 100 batch: 0.425960
Train loss on 150 batch: 0.426641
Train loss on 200 batch: 0.388857
Train loss on 250 batch: 0.379853
best-train-loss: 0.364859
best-valid-loss: 0.402763
best-kappa: 0.7343
: Epoch: 35 | Training Loss: 0.364859 | Val. Loss: 0.402763 | Val. Kappa Score: 0.7343 | LR: 0.000156 | Estimated time: 21.56
Train loss on 50 batch: 0.410533
Train loss on 100 batch: 0.387496
Train loss on 150 batch: 0.434879
Train loss on 200 batch: 0.400675
Train loss on 250 batch: 0.428214
: Epoch: 36 | Training Loss: 0.459430 | Val. Loss: 0.428170 | Val. Kappa Score: 0.7377 | LR: 0.000156 | Estimated time: 21.60
Train loss on 50 batch: 0.389113
Train loss on 100 batch: 0.390784
Train loss on 150 batch: 0.464487
Train loss on 200 batch: 0.385699
Train loss on 250 batch: 0.395907
best-train-loss: 0.397825
best-valid-loss: 0.396329
best-kappa: 0.7410
: Epoch: 37 | Training Loss: 0.397825 | Val. Loss: 0.396329 | Val. Kappa Score: 0.7410 | LR: 0.000156 | Estimated time: 21.45
Train loss on 50 batch: 0.399962
Train loss on 100 batch: 0.420929
Train loss on 150 batch: 0.348365
Train loss on 200 batch: 0.419300
Train loss on 250 batch: 0.402033
: Epoch: 38 | Training Loss: 0.401078 | Val. Loss: 0.410063 | Val. Kappa Score: 0.7440 | LR: 0.000156 | Estimated time: 21.34
Train loss on 50 batch: 0.357947
Train loss on 100 batch: 0.392097
Train loss on 150 batch: 0.426422
Train loss on 200 batch: 0.394099
Train loss on 250 batch: 0.425392
: Epoch: 39 | Training Loss: 0.418520 | Val. Loss: 0.409917 | Val. Kappa Score: 0.7467 | LR: 0.000156 | Estimated time: 21.52
Train loss on 50 batch: 0.393365
Train loss on 100 batch: 0.365821
Train loss on 150 batch: 0.363893
Train loss on 200 batch: 0.364223
Train loss on 250 batch: 0.389433
: Epoch: 40 | Training Loss: 0.395344 | Val. Loss: 0.412674 | Val. Kappa Score: 0.7494 | LR: 0.000078 | Estimated time: 21.58
Train loss on 50 batch: 0.438457
Train loss on 100 batch: 0.414178
Train loss on 150 batch: 0.388095
Train loss on 200 batch: 0.371132
Train loss on 250 batch: 0.377704
: Epoch: 41 | Training Loss: 0.387130 | Val. Loss: 0.404225 | Val. Kappa Score: 0.7521 | LR: 0.000078 | Estimated time: 21.40
Train loss on 50 batch: 0.411894
Train loss on 100 batch: 0.402790
Train loss on 150 batch: 0.351932
Train loss on 200 batch: 0.362130
Train loss on 250 batch: 0.403249
: Epoch: 42 | Training Loss: 0.372054 | Val. Loss: 0.402354 | Val. Kappa Score: 0.7545 | LR: 0.000078 | Estimated time: 21.51
Train loss on 50 batch: 0.350025
Train loss on 100 batch: 0.390915
Train loss on 150 batch: 0.348167
Train loss on 200 batch: 0.413100
Train loss on 250 batch: 0.386983
: Epoch: 43 | Training Loss: 0.384656 | Val. Loss: 0.413983 | Val. Kappa Score: 0.7569 | LR: 0.000039 | Estimated time: 21.83
Train loss on 50 batch: 0.360688
Train loss on 100 batch: 0.372849
Train loss on 150 batch: 0.387229
Train loss on 200 batch: 0.380868
Train loss on 250 batch: 0.408203
: Epoch: 44 | Training Loss: 0.374662 | Val. Loss: 0.402629 | Val. Kappa Score: 0.7593 | LR: 0.000039 | Estimated time: 22.03
Train loss on 50 batch: 0.452261
Train loss on 100 batch: 0.351429
Train loss on 150 batch: 0.337460
Train loss on 200 batch: 0.393351
Train loss on 250 batch: 0.466885
: Epoch: 45 | Training Loss: 0.395520 | Val. Loss: 0.404759 | Val. Kappa Score: 0.7615 | LR: 0.000039 | Estimated time: 21.65
time_estimated: 976.39
n-epochs: 45
time_estimated: 976.41
----------------------------------------

Experiment N: 83: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.14 19:16:57
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9601de10>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 83: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.15 00:23:35
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9604e278>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.981823
----------------------------------------

Experiment N: 83: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 00:25:30
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102780>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 83: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.15 00:31:08
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9604d278>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.981823
Train loss on 100 batch: 0.669776
Train loss on 150 batch: 0.613940
best-train-loss: 0.683333
best-valid-loss: 0.716074
best-kappa: 0.7875
: Epoch: 1 | Training Loss: 0.683333 | Val. Loss: 0.716074 | Val. Kappa Score: 0.7875 | LR: 0.001000 | Estimated time: 154.97
Train loss on 50 batch: 0.427164
Train loss on 100 batch: 0.454459
Train loss on 150 batch: 0.383618
best-train-loss: 0.438852
best-valid-loss: 0.441229
best-kappa: 0.8213
: Epoch: 2 | Training Loss: 0.438852 | Val. Loss: 0.441229 | Val. Kappa Score: 0.8213 | LR: 0.001000 | Estimated time: 154.54
Train loss on 50 batch: 0.401674
Train loss on 100 batch: 0.449202
Train loss on 150 batch: 0.380305
: Epoch: 3 | Training Loss: 0.405510 | Val. Loss: 0.957470 | Val. Kappa Score: 0.8255 | LR: 0.001000 | Estimated time: 153.70
Train loss on 50 batch: 0.359768
Train loss on 100 batch: 0.379535
Train loss on 150 batch: 0.361387
: Epoch: 4 | Training Loss: 0.421557 | Val. Loss: 0.657196 | Val. Kappa Score: 0.8235 | LR: 0.001000 | Estimated time: 154.40
Train loss on 50 batch: 0.448181
Train loss on 100 batch: 0.396013
Train loss on 150 batch: 0.329959
best-train-loss: 0.380970
best-valid-loss: 0.432392
best-kappa: 0.8280
: Epoch: 5 | Training Loss: 0.380970 | Val. Loss: 0.432392 | Val. Kappa Score: 0.8280 | LR: 0.001000 | Estimated time: 155.50
Train loss on 50 batch: 0.396149
Train loss on 100 batch: 0.339828
Train loss on 150 batch: 0.347343
best-train-loss: 0.342994
best-valid-loss: 0.406417
best-kappa: 0.8304
: Epoch: 6 | Training Loss: 0.342994 | Val. Loss: 0.406417 | Val. Kappa Score: 0.8304 | LR: 0.001000 | Estimated time: 155.07
Train loss on 50 batch: 0.348199
Train loss on 100 batch: 0.291965
Train loss on 150 batch: 0.279643
best-train-loss: 0.304958
best-valid-loss: 0.340848
best-kappa: 0.8354
: Epoch: 7 | Training Loss: 0.304958 | Val. Loss: 0.340848 | Val. Kappa Score: 0.8354 | LR: 0.001000 | Estimated time: 154.12
Train loss on 50 batch: 0.228123
Train loss on 100 batch: 0.284858
Train loss on 150 batch: 0.247023
best-train-loss: 0.263819
best-valid-loss: 0.328742
best-kappa: 0.8396
: Epoch: 8 | Training Loss: 0.263819 | Val. Loss: 0.328742 | Val. Kappa Score: 0.8396 | LR: 0.001000 | Estimated time: 155.20
Train loss on 50 batch: 0.283501
Train loss on 100 batch: 0.288573
Train loss on 150 batch: 0.292507
: Epoch: 9 | Training Loss: 0.284651 | Val. Loss: 0.360694 | Val. Kappa Score: 0.8438 | LR: 0.001000 | Estimated time: 154.99
Train loss on 50 batch: 0.234118
Train loss on 100 batch: 0.302832
Train loss on 150 batch: 0.290957
: Epoch: 10 | Training Loss: 0.328992 | Val. Loss: 0.332382 | Val. Kappa Score: 0.8464 | LR: 0.001000 | Estimated time: 154.64
Train loss on 50 batch: 0.327409
Train loss on 100 batch: 0.301816
Train loss on 150 batch: 0.264058
: Epoch: 11 | Training Loss: 0.306056 | Val. Loss: 0.427505 | Val. Kappa Score: 0.8478 | LR: 0.000500 | Estimated time: 154.53
Train loss on 50 batch: 0.232246
Train loss on 100 batch: 0.210501
Train loss on 150 batch: 0.234660
: Epoch: 12 | Training Loss: 0.222730 | Val. Loss: 0.368740 | Val. Kappa Score: 0.8488 | LR: 0.000500 | Estimated time: 154.22
Train loss on 50 batch: 0.180829
Train loss on 100 batch: 0.220139
Train loss on 150 batch: 0.198898
best-train-loss: 0.203036
best-valid-loss: 0.291778
best-kappa: 0.8519
: Epoch: 13 | Training Loss: 0.203036 | Val. Loss: 0.291778 | Val. Kappa Score: 0.8519 | LR: 0.000500 | Estimated time: 155.19
Train loss on 50 batch: 0.186883
Train loss on 100 batch: 0.180749
Train loss on 150 batch: 0.214384
best-train-loss: 0.198245
best-valid-loss: 0.287013
best-kappa: 0.8538
: Epoch: 14 | Training Loss: 0.198245 | Val. Loss: 0.287013 | Val. Kappa Score: 0.8538 | LR: 0.000500 | Estimated time: 154.40
Train loss on 50 batch: 0.220825
Train loss on 100 batch: 0.166366
Train loss on 150 batch: 0.193404
: Epoch: 15 | Training Loss: 0.195645 | Val. Loss: 0.319824 | Val. Kappa Score: 0.8542 | LR: 0.000500 | Estimated time: 155.21
Train loss on 50 batch: 0.172820
Train loss on 100 batch: 0.173541
Train loss on 150 batch: 0.193761
: Epoch: 16 | Training Loss: 0.194186 | Val. Loss: 0.311938 | Val. Kappa Score: 0.8555 | LR: 0.000500 | Estimated time: 154.37
Train loss on 50 batch: 0.185993
Train loss on 100 batch: 0.186063
Train loss on 150 batch: 0.144813
: Epoch: 17 | Training Loss: 0.172565 | Val. Loss: 0.340383 | Val. Kappa Score: 0.8558 | LR: 0.000250 | Estimated time: 155.31
Train loss on 50 batch: 0.151276
Train loss on 100 batch: 0.115570
Train loss on 150 batch: 0.143325
: Epoch: 18 | Training Loss: 0.141197 | Val. Loss: 0.342480 | Val. Kappa Score: 0.8570 | LR: 0.000250 | Estimated time: 154.38
Train loss on 50 batch: 0.112763
Train loss on 100 batch: 0.146293
Train loss on 150 batch: 0.131216
: Epoch: 19 | Training Loss: 0.134820 | Val. Loss: 0.324738 | Val. Kappa Score: 0.8579 | LR: 0.000250 | Estimated time: 154.76
Train loss on 50 batch: 0.118527
Train loss on 100 batch: 0.140027
Train loss on 150 batch: 0.121593
: Epoch: 20 | Training Loss: 0.122611 | Val. Loss: 0.300642 | Val. Kappa Score: 0.8593 | LR: 0.000125 | Estimated time: 154.86
Train loss on 50 batch: 0.124510
Train loss on 100 batch: 0.101047
Train loss on 150 batch: 0.137102
: Epoch: 21 | Training Loss: 0.131383 | Val. Loss: 0.325438 | Val. Kappa Score: 0.8605 | LR: 0.000125 | Estimated time: 155.74
Train loss on 50 batch: 0.108130
Train loss on 100 batch: 0.121446
Train loss on 150 batch: 0.105801
: Epoch: 22 | Training Loss: 0.110127 | Val. Loss: 0.344169 | Val. Kappa Score: 0.8615 | LR: 0.000125 | Estimated time: 155.12
time_estimated: 3405.83
n-epochs: 22
time_estimated: 3405.85
----------------------------------------

Experiment N: 84: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 01:27:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c06b6a0>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.072829
Train loss on 100 batch: 0.654243
Train loss on 150 batch: 0.624449
----------------------------------------

Experiment N: 84: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b0


: 
date: 2019.08.15 01:31:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96049400>
early-stopping-patience: 8
parameters-amount: 4008829
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 84: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 01:32:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d107780>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 84: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 01:33:30
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d106748>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 84: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 01:33:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1037b8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
Train loss on 150 batch: 0.580317
best-train-loss: 0.665603
best-valid-loss: 1.313840
best-kappa: 0.7634
: Epoch: 1 | Training Loss: 0.665603 | Val. Loss: 1.313840 | Val. Kappa Score: 0.7634 | LR: 0.001000 | Estimated time: 54.04
Train loss on 50 batch: 0.449402
Train loss on 100 batch: 0.436332
Train loss on 150 batch: 0.361186
best-train-loss: 0.433382
best-valid-loss: 0.589005
best-kappa: 0.7821
: Epoch: 2 | Training Loss: 0.433382 | Val. Loss: 0.589005 | Val. Kappa Score: 0.7821 | LR: 0.001000 | Estimated time: 53.48
Train loss on 50 batch: 0.428939
Train loss on 100 batch: 0.404851
Train loss on 150 batch: 0.359333
best-train-loss: 0.381546
best-valid-loss: 0.409963
best-kappa: 0.8099
: Epoch: 3 | Training Loss: 0.381546 | Val. Loss: 0.409963 | Val. Kappa Score: 0.8099 | LR: 0.001000 | Estimated time: 53.61
Train loss on 50 batch: 0.348709
Train loss on 100 batch: 0.432814
Train loss on 150 batch: 0.373456
: Epoch: 4 | Training Loss: 0.444343 | Val. Loss: 0.477215 | Val. Kappa Score: 0.8197 | LR: 0.001000 | Estimated time: 54.85
Train loss on 50 batch: 0.466406
Train loss on 100 batch: 0.387579
Train loss on 150 batch: 0.332170
: Epoch: 5 | Training Loss: 0.383666 | Val. Loss: 0.438406 | Val. Kappa Score: 0.8231 | LR: 0.001000 | Estimated time: 56.00
Train loss on 50 batch: 0.363705
Train loss on 100 batch: 0.325094
Train loss on 150 batch: 0.330419
best-train-loss: 0.335334
best-valid-loss: 0.319121
best-kappa: 0.8325
: Epoch: 6 | Training Loss: 0.335334 | Val. Loss: 0.319121 | Val. Kappa Score: 0.8325 | LR: 0.001000 | Estimated time: 55.56
Train loss on 50 batch: 0.321575
Train loss on 100 batch: 0.317086
Train loss on 150 batch: 0.304792
best-train-loss: 0.311302
best-valid-loss: 0.304397
best-kappa: 0.8406
: Epoch: 7 | Training Loss: 0.311302 | Val. Loss: 0.304397 | Val. Kappa Score: 0.8406 | LR: 0.001000 | Estimated time: 55.44
Train loss on 50 batch: 0.243176
Train loss on 100 batch: 0.323752
Train loss on 150 batch: 0.263664
: Epoch: 8 | Training Loss: 0.298023 | Val. Loss: 0.308798 | Val. Kappa Score: 0.8472 | LR: 0.001000 | Estimated time: 56.62
Train loss on 50 batch: 0.322637
Train loss on 100 batch: 0.305392
Train loss on 150 batch: 0.331666
: Epoch: 9 | Training Loss: 0.306835 | Val. Loss: 0.310118 | Val. Kappa Score: 0.8518 | LR: 0.001000 | Estimated time: 56.58
Train loss on 50 batch: 0.272988
Train loss on 100 batch: 0.317419
Train loss on 150 batch: 0.270124
: Epoch: 10 | Training Loss: 0.358562 | Val. Loss: 0.427910 | Val. Kappa Score: 0.8476 | LR: 0.000500 | Estimated time: 56.63
Train loss on 50 batch: 0.239867
Train loss on 100 batch: 0.239563
Train loss on 150 batch: 0.229944
best-train-loss: 0.248121
best-valid-loss: 0.282691
best-kappa: 0.8509
: Epoch: 11 | Training Loss: 0.248121 | Val. Loss: 0.282691 | Val. Kappa Score: 0.8509 | LR: 0.000500 | Estimated time: 56.66
Train loss on 50 batch: 0.183481
Train loss on 100 batch: 0.203020
Train loss on 150 batch: 0.203880
: Epoch: 12 | Training Loss: 0.200980 | Val. Loss: 0.294231 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 56.58
Train loss on 50 batch: 0.169855
Train loss on 100 batch: 0.228281
Train loss on 150 batch: 0.199570
: Epoch: 13 | Training Loss: 0.205337 | Val. Loss: 0.340016 | Val. Kappa Score: 0.8552 | LR: 0.000500 | Estimated time: 56.57
Train loss on 50 batch: 0.186955
Train loss on 100 batch: 0.192416
Train loss on 150 batch: 0.208173
best-train-loss: 0.205660
best-valid-loss: 0.257970
best-kappa: 0.8582
: Epoch: 14 | Training Loss: 0.205660 | Val. Loss: 0.257970 | Val. Kappa Score: 0.8582 | LR: 0.000500 | Estimated time: 56.63
Train loss on 50 batch: 0.221033
Train loss on 100 batch: 0.191676
Train loss on 150 batch: 0.207478
: Epoch: 15 | Training Loss: 0.206612 | Val. Loss: 0.268114 | Val. Kappa Score: 0.8606 | LR: 0.000500 | Estimated time: 56.60
Train loss on 50 batch: 0.187782
Train loss on 100 batch: 0.170692
Train loss on 150 batch: 0.153422
: Epoch: 16 | Training Loss: 0.178677 | Val. Loss: 0.269115 | Val. Kappa Score: 0.8623 | LR: 0.000500 | Estimated time: 56.49
Train loss on 50 batch: 0.193814
Train loss on 100 batch: 0.184197
Train loss on 150 batch: 0.167149
: Epoch: 17 | Training Loss: 0.182851 | Val. Loss: 0.285018 | Val. Kappa Score: 0.8641 | LR: 0.000250 | Estimated time: 56.25
Train loss on 50 batch: 0.157030
Train loss on 100 batch: 0.117172
Train loss on 150 batch: 0.166063
: Epoch: 18 | Training Loss: 0.149435 | Val. Loss: 0.282949 | Val. Kappa Score: 0.8656 | LR: 0.000250 | Estimated time: 56.24
Train loss on 50 batch: 0.114739
Train loss on 100 batch: 0.145791
Train loss on 150 batch: 0.134199
: Epoch: 19 | Training Loss: 0.134297 | Val. Loss: 0.316790 | Val. Kappa Score: 0.8669 | LR: 0.000250 | Estimated time: 56.22
Train loss on 50 batch: 0.110565
Train loss on 100 batch: 0.143119
Train loss on 150 batch: 0.134156
: Epoch: 20 | Training Loss: 0.124275 | Val. Loss: 0.295902 | Val. Kappa Score: 0.8680 | LR: 0.000125 | Estimated time: 56.54
Train loss on 50 batch: 0.119500
Train loss on 100 batch: 0.099390
Train loss on 150 batch: 0.127907
: Epoch: 21 | Training Loss: 0.136079 | Val. Loss: 0.277667 | Val. Kappa Score: 0.8695 | LR: 0.000125 | Estimated time: 56.63
Train loss on 50 batch: 0.102117
Train loss on 100 batch: 0.120021
Train loss on 150 batch: 0.106643
: Epoch: 22 | Training Loss: 0.108784 | Val. Loss: 0.287053 | Val. Kappa Score: 0.8711 | LR: 0.000125 | Estimated time: 56.59
time_estimated: 1231.84
n-epochs: 22
time_estimated: 1231.86
----------------------------------------

Experiment N: 85: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.08.15 01:56:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9da39390>
early-stopping-patience: 8
parameters-amount: 42502209
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.422254
Train loss on 100 batch: 0.706316
Train loss on 150 batch: 0.691215
best-train-loss: 0.856859
best-valid-loss: 0.518759
best-kappa: 0.8008
: Epoch: 1 | Training Loss: 0.856859 | Val. Loss: 0.518759 | Val. Kappa Score: 0.8008 | LR: 0.001000 | Estimated time: 36.17
Train loss on 50 batch: 0.560659
Train loss on 100 batch: 0.565867
Train loss on 150 batch: 0.475405
: Epoch: 2 | Training Loss: 0.562192 | Val. Loss: 1.159566 | Val. Kappa Score: 0.7032 | LR: 0.001000 | Estimated time: 34.65
Train loss on 50 batch: 0.575964
Train loss on 100 batch: 0.583053
Train loss on 150 batch: 0.517074
: Epoch: 3 | Training Loss: 0.557607 | Val. Loss: 38.437426 | Val. Kappa Score: 0.5101 | LR: 0.001000 | Estimated time: 35.41
Train loss on 50 batch: 0.659998
Train loss on 100 batch: 0.541508
Train loss on 150 batch: 0.554708
best-train-loss: 0.604664
best-valid-loss: 0.479992
best-kappa: 0.5858
: Epoch: 4 | Training Loss: 0.604664 | Val. Loss: 0.479992 | Val. Kappa Score: 0.5858 | LR: 0.001000 | Estimated time: 34.57
Train loss on 50 batch: 0.558441
Train loss on 100 batch: 0.565825
Train loss on 150 batch: 0.456660
: Epoch: 5 | Training Loss: 0.520800 | Val. Loss: 1.174141 | Val. Kappa Score: 0.6084 | LR: 0.001000 | Estimated time: 34.22
Train loss on 50 batch: 0.548016
Train loss on 100 batch: 0.515160
Train loss on 150 batch: 0.466185
: Epoch: 6 | Training Loss: 0.499519 | Val. Loss: 0.588584 | Val. Kappa Score: 0.6388 | LR: 0.001000 | Estimated time: 34.16
Train loss on 50 batch: 0.544405
Train loss on 100 batch: 0.463825
Train loss on 150 batch: 0.423828
best-train-loss: 0.494055
best-valid-loss: 0.449300
best-kappa: 0.6681
: Epoch: 7 | Training Loss: 0.494055 | Val. Loss: 0.449300 | Val. Kappa Score: 0.6681 | LR: 0.001000 | Estimated time: 34.18
Train loss on 50 batch: 0.399135
Train loss on 100 batch: 0.469115
Train loss on 150 batch: 0.402206
best-train-loss: 0.424070
best-valid-loss: 0.414133
best-kappa: 0.6904
: Epoch: 8 | Training Loss: 0.424070 | Val. Loss: 0.414133 | Val. Kappa Score: 0.6904 | LR: 0.001000 | Estimated time: 34.19
Train loss on 50 batch: 0.425073
Train loss on 100 batch: 0.487196
Train loss on 150 batch: 0.424777
: Epoch: 9 | Training Loss: 0.433189 | Val. Loss: 0.485912 | Val. Kappa Score: 0.7083 | LR: 0.001000 | Estimated time: 34.45
Train loss on 50 batch: 0.335826
Train loss on 100 batch: 0.424620
Train loss on 150 batch: 0.380700
: Epoch: 10 | Training Loss: 0.420762 | Val. Loss: 1.814570 | Val. Kappa Score: 0.6785 | LR: 0.001000 | Estimated time: 33.98
Train loss on 50 batch: 0.420723
Train loss on 100 batch: 0.400607
Train loss on 150 batch: 0.419464
best-train-loss: 0.430889
best-valid-loss: 0.386046
best-kappa: 0.6944
: Epoch: 11 | Training Loss: 0.430889 | Val. Loss: 0.386046 | Val. Kappa Score: 0.6944 | LR: 0.001000 | Estimated time: 34.03
Train loss on 50 batch: 0.483639
Train loss on 100 batch: 0.390633
Train loss on 150 batch: 0.439419
best-train-loss: 0.438436
best-valid-loss: 0.364396
best-kappa: 0.7077
: Epoch: 12 | Training Loss: 0.438436 | Val. Loss: 0.364396 | Val. Kappa Score: 0.7077 | LR: 0.001000 | Estimated time: 34.09
Train loss on 50 batch: 0.372802
Train loss on 100 batch: 0.427756
Train loss on 150 batch: 0.422591
: Epoch: 13 | Training Loss: 0.386192 | Val. Loss: 0.396512 | Val. Kappa Score: 0.7199 | LR: 0.001000 | Estimated time: 34.23
Train loss on 50 batch: 0.340035
Train loss on 100 batch: 0.353105
Train loss on 150 batch: 0.430080
: Epoch: 14 | Training Loss: 0.404714 | Val. Loss: 0.633706 | Val. Kappa Score: 0.7226 | LR: 0.001000 | Estimated time: 34.90
Train loss on 50 batch: 0.541557
Train loss on 100 batch: 0.411823
Train loss on 150 batch: 0.388420
: Epoch: 15 | Training Loss: 0.430894 | Val. Loss: 0.436713 | Val. Kappa Score: 0.7302 | LR: 0.000500 | Estimated time: 35.61
Train loss on 50 batch: 0.379829
Train loss on 100 batch: 0.317212
Train loss on 150 batch: 0.326443
best-train-loss: 0.345122
best-valid-loss: 0.349025
best-kappa: 0.7379
: Epoch: 16 | Training Loss: 0.345122 | Val. Loss: 0.349025 | Val. Kappa Score: 0.7379 | LR: 0.000500 | Estimated time: 35.67
Train loss on 50 batch: 0.374634
Train loss on 100 batch: 0.319450
Train loss on 150 batch: 0.298949
: Epoch: 17 | Training Loss: 0.333128 | Val. Loss: 0.367434 | Val. Kappa Score: 0.7451 | LR: 0.000500 | Estimated time: 35.58
Train loss on 50 batch: 0.387365
Train loss on 100 batch: 0.323130
Train loss on 150 batch: 0.309788
: Epoch: 18 | Training Loss: 0.340465 | Val. Loss: 0.372690 | Val. Kappa Score: 0.7523 | LR: 0.000500 | Estimated time: 35.74
Train loss on 50 batch: 0.278588
Train loss on 100 batch: 0.356494
Train loss on 150 batch: 0.362379
: Epoch: 19 | Training Loss: 0.349254 | Val. Loss: 0.354645 | Val. Kappa Score: 0.7586 | LR: 0.000250 | Estimated time: 35.54
Train loss on 50 batch: 0.314410
Train loss on 100 batch: 0.320051
Train loss on 150 batch: 0.298602
best-train-loss: 0.320689
best-valid-loss: 0.326142
best-kappa: 0.7648
: Epoch: 20 | Training Loss: 0.320689 | Val. Loss: 0.326142 | Val. Kappa Score: 0.7648 | LR: 0.000250 | Estimated time: 35.61
Train loss on 50 batch: 0.302062
Train loss on 100 batch: 0.285935
Train loss on 150 batch: 0.328736
: Epoch: 21 | Training Loss: 0.314221 | Val. Loss: 0.345182 | Val. Kappa Score: 0.7701 | LR: 0.000250 | Estimated time: 35.47
Train loss on 50 batch: 0.280207
Train loss on 100 batch: 0.286697
Train loss on 150 batch: 0.322035
: Epoch: 22 | Training Loss: 0.309148 | Val. Loss: 0.332714 | Val. Kappa Score: 0.7749 | LR: 0.000250 | Estimated time: 36.11
Train loss on 50 batch: 0.331902
Train loss on 100 batch: 0.284030
Train loss on 150 batch: 0.302813
: Epoch: 23 | Training Loss: 0.299730 | Val. Loss: 0.349256 | Val. Kappa Score: 0.7789 | LR: 0.000125 | Estimated time: 35.64
Train loss on 50 batch: 0.280578
Train loss on 100 batch: 0.277505
Train loss on 150 batch: 0.284914
best-train-loss: 0.309493
best-valid-loss: 0.313793
best-kappa: 0.7832
: Epoch: 24 | Training Loss: 0.309493 | Val. Loss: 0.313793 | Val. Kappa Score: 0.7832 | LR: 0.000125 | Estimated time: 35.69
Train loss on 50 batch: 0.271095
Train loss on 100 batch: 0.260510
Train loss on 150 batch: 0.299041
: Epoch: 25 | Training Loss: 0.296254 | Val. Loss: 0.321584 | Val. Kappa Score: 0.7873 | LR: 0.000125 | Estimated time: 35.65
Train loss on 50 batch: 0.282861
Train loss on 100 batch: 0.235858
Train loss on 150 batch: 0.297015
: Epoch: 26 | Training Loss: 0.284931 | Val. Loss: 0.314453 | Val. Kappa Score: 0.7911 | LR: 0.000125 | Estimated time: 35.55
Train loss on 50 batch: 0.276965
Train loss on 100 batch: 0.289717
Train loss on 150 batch: 0.253058
: Epoch: 27 | Training Loss: 0.263635 | Val. Loss: 0.322445 | Val. Kappa Score: 0.7946 | LR: 0.000063 | Estimated time: 35.70
Train loss on 50 batch: 0.287523
Train loss on 100 batch: 0.254061
Train loss on 150 batch: 0.237804
best-train-loss: 0.258472
best-valid-loss: 0.306009
best-kappa: 0.7978
: Epoch: 28 | Training Loss: 0.258472 | Val. Loss: 0.306009 | Val. Kappa Score: 0.7978 | LR: 0.000063 | Estimated time: 35.52
Train loss on 50 batch: 0.236793
Train loss on 100 batch: 0.278727
Train loss on 150 batch: 0.268810
: Epoch: 29 | Training Loss: 0.259626 | Val. Loss: 0.310600 | Val. Kappa Score: 0.8008 | LR: 0.000063 | Estimated time: 35.81
Train loss on 50 batch: 0.236670
Train loss on 100 batch: 0.252246
Train loss on 150 batch: 0.253873
: Epoch: 30 | Training Loss: 0.249572 | Val. Loss: 0.306857 | Val. Kappa Score: 0.8032 | LR: 0.000063 | Estimated time: 35.11
Train loss on 50 batch: 0.217709
Train loss on 100 batch: 0.280212
Train loss on 150 batch: 0.236271
best-train-loss: 0.266292
best-valid-loss: 0.302251
best-kappa: 0.8058
: Epoch: 31 | Training Loss: 0.266292 | Val. Loss: 0.302251 | Val. Kappa Score: 0.8058 | LR: 0.000063 | Estimated time: 33.87
Train loss on 50 batch: 0.236379
Train loss on 100 batch: 0.291025
Train loss on 150 batch: 0.218921
best-train-loss: 0.242666
best-valid-loss: 0.300465
best-kappa: 0.8081
: Epoch: 32 | Training Loss: 0.242666 | Val. Loss: 0.300465 | Val. Kappa Score: 0.8081 | LR: 0.000063 | Estimated time: 35.32
Train loss on 50 batch: 0.250763
Train loss on 100 batch: 0.254365
Train loss on 150 batch: 0.255548
best-train-loss: 0.257993
best-valid-loss: 0.296700
best-kappa: 0.8104
: Epoch: 33 | Training Loss: 0.257993 | Val. Loss: 0.296700 | Val. Kappa Score: 0.8104 | LR: 0.000063 | Estimated time: 35.71
Train loss on 50 batch: 0.238079
Train loss on 100 batch: 0.265888
Train loss on 150 batch: 0.269960
: Epoch: 34 | Training Loss: 0.271950 | Val. Loss: 0.310239 | Val. Kappa Score: 0.8126 | LR: 0.000063 | Estimated time: 34.93
Train loss on 50 batch: 0.237007
Train loss on 100 batch: 0.239171
Train loss on 150 batch: 0.265128
: Epoch: 35 | Training Loss: 0.254854 | Val. Loss: 0.305581 | Val. Kappa Score: 0.8141 | LR: 0.000063 | Estimated time: 33.93
Train loss on 50 batch: 0.212595
Train loss on 100 batch: 0.274326
Train loss on 150 batch: 0.206758
: Epoch: 36 | Training Loss: 0.248387 | Val. Loss: 0.305110 | Val. Kappa Score: 0.8159 | LR: 0.000031 | Estimated time: 34.79
Train loss on 50 batch: 0.236901
Train loss on 100 batch: 0.245586
Train loss on 150 batch: 0.231592
: Epoch: 37 | Training Loss: 0.242973 | Val. Loss: 0.301394 | Val. Kappa Score: 0.8174 | LR: 0.000031 | Estimated time: 34.22
Train loss on 50 batch: 0.233286
Train loss on 100 batch: 0.215511
Train loss on 150 batch: 0.253903
: Epoch: 38 | Training Loss: 0.275917 | Val. Loss: 0.302473 | Val. Kappa Score: 0.8191 | LR: 0.000031 | Estimated time: 34.29
Train loss on 50 batch: 0.256314
Train loss on 100 batch: 0.253333
Train loss on 150 batch: 0.249688
best-train-loss: 0.252737
best-valid-loss: 0.291888
best-kappa: 0.8207
: Epoch: 39 | Training Loss: 0.252737 | Val. Loss: 0.291888 | Val. Kappa Score: 0.8207 | LR: 0.000031 | Estimated time: 34.60
Train loss on 50 batch: 0.227563
Train loss on 100 batch: 0.211869
Train loss on 150 batch: 0.251915
: Epoch: 40 | Training Loss: 0.231072 | Val. Loss: 0.307159 | Val. Kappa Score: 0.8222 | LR: 0.000031 | Estimated time: 34.33
Train loss on 50 batch: 0.211151
Train loss on 100 batch: 0.240176
Train loss on 150 batch: 0.231658
: Epoch: 41 | Training Loss: 0.240716 | Val. Loss: 0.295229 | Val. Kappa Score: 0.8238 | LR: 0.000031 | Estimated time: 34.21
Train loss on 50 batch: 0.229590
Train loss on 100 batch: 0.201097
Train loss on 150 batch: 0.231520
: Epoch: 42 | Training Loss: 0.248785 | Val. Loss: 0.301678 | Val. Kappa Score: 0.8252 | LR: 0.000016 | Estimated time: 34.34
Train loss on 50 batch: 0.235818
Train loss on 100 batch: 0.246720
Train loss on 150 batch: 0.215294
: Epoch: 43 | Training Loss: 0.252530 | Val. Loss: 0.293616 | Val. Kappa Score: 0.8267 | LR: 0.000016 | Estimated time: 34.53
Train loss on 50 batch: 0.223614
Train loss on 100 batch: 0.261135
Train loss on 150 batch: 0.219247
: Epoch: 44 | Training Loss: 0.228728 | Val. Loss: 0.304172 | Val. Kappa Score: 0.8279 | LR: 0.000016 | Estimated time: 35.44
Train loss on 50 batch: 0.230581
Train loss on 100 batch: 0.196579
Train loss on 150 batch: 0.280597
: Epoch: 45 | Training Loss: 0.244900 | Val. Loss: 0.294430 | Val. Kappa Score: 0.8293 | LR: 0.000008 | Estimated time: 35.51
Train loss on 50 batch: 0.243373
Train loss on 100 batch: 0.223733
Train loss on 150 batch: 0.224854
: Epoch: 46 | Training Loss: 0.233709 | Val. Loss: 0.299211 | Val. Kappa Score: 0.8306 | LR: 0.000008 | Estimated time: 35.22
Train loss on 50 batch: 0.224108
Train loss on 100 batch: 0.209231
Train loss on 150 batch: 0.219580
: Epoch: 47 | Training Loss: 0.230386 | Val. Loss: 0.296718 | Val. Kappa Score: 0.8317 | LR: 0.000008 | Estimated time: 35.67
time_estimated: 1646.61
n-epochs: 47
time_estimated: 1646.63
----------------------------------------

Experiment N: 86: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.08.15 02:25:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102898>
early-stopping-patience: 8
parameters-amount: 42502209
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.480073
Train loss on 100 batch: 0.750193
Train loss on 150 batch: 0.661642
best-train-loss: 0.869120
best-valid-loss: 0.758267
best-kappa: 0.6933
: Epoch: 1 | Training Loss: 0.869120 | Val. Loss: 0.758267 | Val. Kappa Score: 0.6933 | LR: 0.001000 | Estimated time: 36.01
Train loss on 50 batch: 0.529446
Train loss on 100 batch: 0.577962
Train loss on 150 batch: 0.483242
: Epoch: 2 | Training Loss: 0.566006 | Val. Loss: 4.426953 | Val. Kappa Score: 0.6430 | LR: 0.001000 | Estimated time: 35.59
Train loss on 50 batch: 0.530561
Train loss on 100 batch: 0.609029
Train loss on 150 batch: 0.519780
best-train-loss: 0.556622
best-valid-loss: 0.528653
best-kappa: 0.7052
: Epoch: 3 | Training Loss: 0.556622 | Val. Loss: 0.528653 | Val. Kappa Score: 0.7052 | LR: 0.001000 | Estimated time: 35.09
Train loss on 50 batch: 0.552046
Train loss on 100 batch: 0.484402
Train loss on 150 batch: 0.506887
best-train-loss: 0.559331
best-valid-loss: 0.413512
best-kappa: 0.7401
: Epoch: 4 | Training Loss: 0.559331 | Val. Loss: 0.413512 | Val. Kappa Score: 0.7401 | LR: 0.001000 | Estimated time: 34.64
Train loss on 50 batch: 0.525260
Train loss on 100 batch: 0.542727
Train loss on 150 batch: 0.464748
: Epoch: 5 | Training Loss: 0.500430 | Val. Loss: 0.431464 | Val. Kappa Score: 0.7633 | LR: 0.001000 | Estimated time: 34.30
Train loss on 50 batch: 0.531476
Train loss on 100 batch: 0.495081
Train loss on 150 batch: 0.455725
: Epoch: 6 | Training Loss: 0.479571 | Val. Loss: 0.545413 | Val. Kappa Score: 0.7722 | LR: 0.001000 | Estimated time: 34.02
Train loss on 50 batch: 0.537288
Train loss on 100 batch: 0.437734
Train loss on 150 batch: 0.423667
: Epoch: 7 | Training Loss: 0.476400 | Val. Loss: 0.438478 | Val. Kappa Score: 0.7808 | LR: 0.000500 | Estimated time: 33.97
Train loss on 50 batch: 0.392231
Train loss on 100 batch: 0.421002
Train loss on 150 batch: 0.345345
best-train-loss: 0.377416
best-valid-loss: 0.375936
best-kappa: 0.7891
: Epoch: 8 | Training Loss: 0.377416 | Val. Loss: 0.375936 | Val. Kappa Score: 0.7891 | LR: 0.000500 | Estimated time: 34.07
Train loss on 50 batch: 0.367517
Train loss on 100 batch: 0.418582
Train loss on 150 batch: 0.381737
: Epoch: 9 | Training Loss: 0.377711 | Val. Loss: 0.521987 | Val. Kappa Score: 0.7957 | LR: 0.000500 | Estimated time: 34.21
Train loss on 50 batch: 0.301089
Train loss on 100 batch: 0.365785
Train loss on 150 batch: 0.335982
: Epoch: 10 | Training Loss: 0.373899 | Val. Loss: 0.496097 | Val. Kappa Score: 0.7918 | LR: 0.000500 | Estimated time: 34.02
Train loss on 50 batch: 0.332335
Train loss on 100 batch: 0.363241
Train loss on 150 batch: 0.362035
: Epoch: 11 | Training Loss: 0.374255 | Val. Loss: 0.427147 | Val. Kappa Score: 0.7956 | LR: 0.000250 | Estimated time: 34.09
Train loss on 50 batch: 0.319111
Train loss on 100 batch: 0.308815
Train loss on 150 batch: 0.340966
: Epoch: 12 | Training Loss: 0.327097 | Val. Loss: 0.393592 | Val. Kappa Score: 0.8007 | LR: 0.000250 | Estimated time: 34.44
Train loss on 50 batch: 0.281701
Train loss on 100 batch: 0.346016
Train loss on 150 batch: 0.318277
best-train-loss: 0.301261
best-valid-loss: 0.343193
best-kappa: 0.8066
: Epoch: 13 | Training Loss: 0.301261 | Val. Loss: 0.343193 | Val. Kappa Score: 0.8066 | LR: 0.000250 | Estimated time: 34.11
Train loss on 50 batch: 0.272641
Train loss on 100 batch: 0.275187
Train loss on 150 batch: 0.342795
best-train-loss: 0.312482
best-valid-loss: 0.321965
best-kappa: 0.8120
: Epoch: 14 | Training Loss: 0.312482 | Val. Loss: 0.321965 | Val. Kappa Score: 0.8120 | LR: 0.000250 | Estimated time: 34.15
Train loss on 50 batch: 0.381079
Train loss on 100 batch: 0.291948
Train loss on 150 batch: 0.279064
: Epoch: 15 | Training Loss: 0.304427 | Val. Loss: 0.347719 | Val. Kappa Score: 0.8162 | LR: 0.000250 | Estimated time: 33.63
Train loss on 50 batch: 0.304840
Train loss on 100 batch: 0.273067
Train loss on 150 batch: 0.296088
: Epoch: 16 | Training Loss: 0.292762 | Val. Loss: 0.348095 | Val. Kappa Score: 0.8189 | LR: 0.000250 | Estimated time: 34.07
Train loss on 50 batch: 0.320649
Train loss on 100 batch: 0.281103
Train loss on 150 batch: 0.251515
: Epoch: 17 | Training Loss: 0.295082 | Val. Loss: 0.334149 | Val. Kappa Score: 0.8218 | LR: 0.000125 | Estimated time: 34.39
Train loss on 50 batch: 0.300396
Train loss on 100 batch: 0.239619
Train loss on 150 batch: 0.245437
best-train-loss: 0.263100
best-valid-loss: 0.305974
best-kappa: 0.8253
: Epoch: 18 | Training Loss: 0.263100 | Val. Loss: 0.305974 | Val. Kappa Score: 0.8253 | LR: 0.000125 | Estimated time: 34.16
Train loss on 50 batch: 0.213486
Train loss on 100 batch: 0.272363
Train loss on 150 batch: 0.285333
best-train-loss: 0.282881
best-valid-loss: 0.299846
best-kappa: 0.8282
: Epoch: 19 | Training Loss: 0.282881 | Val. Loss: 0.299846 | Val. Kappa Score: 0.8282 | LR: 0.000125 | Estimated time: 33.98
Train loss on 50 batch: 0.249572
Train loss on 100 batch: 0.279401
Train loss on 150 batch: 0.244540
: Epoch: 20 | Training Loss: 0.265750 | Val. Loss: 0.301943 | Val. Kappa Score: 0.8310 | LR: 0.000125 | Estimated time: 33.98
Train loss on 50 batch: 0.266126
Train loss on 100 batch: 0.252877
Train loss on 150 batch: 0.277970
: Epoch: 21 | Training Loss: 0.270574 | Val. Loss: 0.325423 | Val. Kappa Score: 0.8331 | LR: 0.000125 | Estimated time: 34.15
Train loss on 50 batch: 0.252758
Train loss on 100 batch: 0.234681
Train loss on 150 batch: 0.274683
: Epoch: 22 | Training Loss: 0.264013 | Val. Loss: 0.302162 | Val. Kappa Score: 0.8355 | LR: 0.000063 | Estimated time: 33.91
Train loss on 50 batch: 0.233022
Train loss on 100 batch: 0.232309
Train loss on 150 batch: 0.234893
: Epoch: 23 | Training Loss: 0.229502 | Val. Loss: 0.322675 | Val. Kappa Score: 0.8374 | LR: 0.000063 | Estimated time: 34.00
Train loss on 50 batch: 0.237681
Train loss on 100 batch: 0.238693
Train loss on 150 batch: 0.245475
: Epoch: 24 | Training Loss: 0.271325 | Val. Loss: 0.301444 | Val. Kappa Score: 0.8392 | LR: 0.000063 | Estimated time: 35.06
Train loss on 50 batch: 0.233792
Train loss on 100 batch: 0.220151
Train loss on 150 batch: 0.232138
best-train-loss: 0.239812
best-valid-loss: 0.295761
best-kappa: 0.8410
: Epoch: 25 | Training Loss: 0.239812 | Val. Loss: 0.295761 | Val. Kappa Score: 0.8410 | LR: 0.000063 | Estimated time: 34.30
Train loss on 50 batch: 0.246802
Train loss on 100 batch: 0.194346
Train loss on 150 batch: 0.262391
: Epoch: 26 | Training Loss: 0.241481 | Val. Loss: 0.297269 | Val. Kappa Score: 0.8427 | LR: 0.000063 | Estimated time: 34.57
Train loss on 50 batch: 0.235951
Train loss on 100 batch: 0.252459
Train loss on 150 batch: 0.227628
: Epoch: 27 | Training Loss: 0.229898 | Val. Loss: 0.301707 | Val. Kappa Score: 0.8441 | LR: 0.000063 | Estimated time: 34.79
Train loss on 50 batch: 0.248122
Train loss on 100 batch: 0.231377
Train loss on 150 batch: 0.216295
: Epoch: 28 | Training Loss: 0.230660 | Val. Loss: 0.301620 | Val. Kappa Score: 0.8456 | LR: 0.000031 | Estimated time: 34.84
Train loss on 50 batch: 0.185936
Train loss on 100 batch: 0.235951
Train loss on 150 batch: 0.218411
best-train-loss: 0.214694
best-valid-loss: 0.294647
best-kappa: 0.8470
: Epoch: 29 | Training Loss: 0.214694 | Val. Loss: 0.294647 | Val. Kappa Score: 0.8470 | LR: 0.000031 | Estimated time: 34.53
Train loss on 50 batch: 0.207105
Train loss on 100 batch: 0.214205
Train loss on 150 batch: 0.221934
: Epoch: 30 | Training Loss: 0.216535 | Val. Loss: 0.296161 | Val. Kappa Score: 0.8484 | LR: 0.000031 | Estimated time: 34.44
Train loss on 50 batch: 0.199996
Train loss on 100 batch: 0.246340
Train loss on 150 batch: 0.207985
best-train-loss: 0.238352
best-valid-loss: 0.293585
best-kappa: 0.8498
: Epoch: 31 | Training Loss: 0.238352 | Val. Loss: 0.293585 | Val. Kappa Score: 0.8498 | LR: 0.000031 | Estimated time: 35.14
Train loss on 50 batch: 0.185280
Train loss on 100 batch: 0.251352
Train loss on 150 batch: 0.200063
best-train-loss: 0.208937
best-valid-loss: 0.287173
best-kappa: 0.8508
: Epoch: 32 | Training Loss: 0.208937 | Val. Loss: 0.287173 | Val. Kappa Score: 0.8508 | LR: 0.000031 | Estimated time: 35.64
Train loss on 50 batch: 0.195016
Train loss on 100 batch: 0.205502
Train loss on 150 batch: 0.212456
: Epoch: 33 | Training Loss: 0.210948 | Val. Loss: 0.289389 | Val. Kappa Score: 0.8519 | LR: 0.000031 | Estimated time: 35.33
Train loss on 50 batch: 0.202504
Train loss on 100 batch: 0.226051
Train loss on 150 batch: 0.237766
: Epoch: 34 | Training Loss: 0.223605 | Val. Loss: 0.297281 | Val. Kappa Score: 0.8528 | LR: 0.000031 | Estimated time: 35.02
Train loss on 50 batch: 0.204503
Train loss on 100 batch: 0.209399
Train loss on 150 batch: 0.223967
: Epoch: 35 | Training Loss: 0.219027 | Val. Loss: 0.291777 | Val. Kappa Score: 0.8537 | LR: 0.000016 | Estimated time: 34.40
Train loss on 50 batch: 0.180622
Train loss on 100 batch: 0.230639
Train loss on 150 batch: 0.173444
: Epoch: 36 | Training Loss: 0.211750 | Val. Loss: 0.305625 | Val. Kappa Score: 0.8543 | LR: 0.000016 | Estimated time: 34.20
Train loss on 50 batch: 0.202360
Train loss on 100 batch: 0.211786
Train loss on 150 batch: 0.210066
: Epoch: 37 | Training Loss: 0.206906 | Val. Loss: 0.289073 | Val. Kappa Score: 0.8551 | LR: 0.000016 | Estimated time: 34.17
Train loss on 50 batch: 0.201744
Train loss on 100 batch: 0.185305
Train loss on 150 batch: 0.214803
best-train-loss: 0.236734
best-valid-loss: 0.286930
best-kappa: 0.8559
: Epoch: 38 | Training Loss: 0.236734 | Val. Loss: 0.286930 | Val. Kappa Score: 0.8559 | LR: 0.000016 | Estimated time: 34.52
Train loss on 50 batch: 0.215690
Train loss on 100 batch: 0.198108
Train loss on 150 batch: 0.206492
best-train-loss: 0.209980
best-valid-loss: 0.283555
best-kappa: 0.8565
: Epoch: 39 | Training Loss: 0.209980 | Val. Loss: 0.283555 | Val. Kappa Score: 0.8565 | LR: 0.000016 | Estimated time: 33.96
Train loss on 50 batch: 0.191991
Train loss on 100 batch: 0.179043
Train loss on 150 batch: 0.208905
: Epoch: 40 | Training Loss: 0.191566 | Val. Loss: 0.291962 | Val. Kappa Score: 0.8573 | LR: 0.000016 | Estimated time: 34.37
Train loss on 50 batch: 0.187769
Train loss on 100 batch: 0.187986
Train loss on 150 batch: 0.195956
: Epoch: 41 | Training Loss: 0.197961 | Val. Loss: 0.291678 | Val. Kappa Score: 0.8579 | LR: 0.000016 | Estimated time: 34.37
Train loss on 50 batch: 0.201127
Train loss on 100 batch: 0.179125
Train loss on 150 batch: 0.199656
: Epoch: 42 | Training Loss: 0.215492 | Val. Loss: 0.288680 | Val. Kappa Score: 0.8585 | LR: 0.000008 | Estimated time: 34.18
Train loss on 50 batch: 0.207592
Train loss on 100 batch: 0.206151
Train loss on 150 batch: 0.183677
: Epoch: 43 | Training Loss: 0.217409 | Val. Loss: 0.286802 | Val. Kappa Score: 0.8593 | LR: 0.000008 | Estimated time: 34.64
Train loss on 50 batch: 0.186577
Train loss on 100 batch: 0.241162
Train loss on 150 batch: 0.195176
: Epoch: 44 | Training Loss: 0.199782 | Val. Loss: 0.299512 | Val. Kappa Score: 0.8599 | LR: 0.000008 | Estimated time: 34.73
Train loss on 50 batch: 0.208596
Train loss on 100 batch: 0.162714
Train loss on 150 batch: 0.216962
: Epoch: 45 | Training Loss: 0.197283 | Val. Loss: 0.293444 | Val. Kappa Score: 0.8606 | LR: 0.000004 | Estimated time: 35.93
Train loss on 50 batch: 0.205305
Train loss on 100 batch: 0.198290
Train loss on 150 batch: 0.188651
: Epoch: 46 | Training Loss: 0.199411 | Val. Loss: 0.292388 | Val. Kappa Score: 0.8612 | LR: 0.000004 | Estimated time: 35.64
Train loss on 50 batch: 0.196677
Train loss on 100 batch: 0.176176
Train loss on 150 batch: 0.174436
: Epoch: 47 | Training Loss: 0.203273 | Val. Loss: 0.293356 | Val. Kappa Score: 0.8618 | LR: 0.000004 | Estimated time: 34.97
time_estimated: 1625.18
n-epochs: 47
time_estimated: 1625.21
----------------------------------------

Experiment N: 87: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 03:01:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fde3c8>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.447120
Train loss on 100 batch: 0.775461
Train loss on 150 batch: 0.687144
best-train-loss: 0.871042
best-valid-loss: 0.614134
best-kappa: 0.7787
: Epoch: 1 | Training Loss: 0.871042 | Val. Loss: 0.614134 | Val. Kappa Score: 0.7787 | LR: 0.001000 | Estimated time: 49.84
Train loss on 50 batch: 0.538267
Train loss on 100 batch: 0.531633
Train loss on 150 batch: 0.420861
: Epoch: 2 | Training Loss: 0.521682 | Val. Loss: 0.746556 | Val. Kappa Score: 0.7609 | LR: 0.001000 | Estimated time: 49.30
Train loss on 50 batch: 0.466248
Train loss on 100 batch: 0.567590
Train loss on 150 batch: 0.463056
best-train-loss: 0.497068
best-valid-loss: 0.544828
best-kappa: 0.7736
: Epoch: 3 | Training Loss: 0.497068 | Val. Loss: 0.544828 | Val. Kappa Score: 0.7736 | LR: 0.001000 | Estimated time: 49.56
Train loss on 50 batch: 0.541421
Train loss on 100 batch: 0.477868
Train loss on 150 batch: 0.494228
: Epoch: 4 | Training Loss: 0.522899 | Val. Loss: 0.715752 | Val. Kappa Score: 0.7553 | LR: 0.001000 | Estimated time: 49.83
Train loss on 50 batch: 0.617478
Train loss on 100 batch: 0.543856
Train loss on 150 batch: 0.477556
: Epoch: 5 | Training Loss: 0.532126 | Val. Loss: 0.654486 | Val. Kappa Score: 0.7678 | LR: 0.001000 | Estimated time: 49.73
Train loss on 50 batch: 0.534346
Train loss on 100 batch: 0.482894
Train loss on 150 batch: 0.439431
: Epoch: 6 | Training Loss: 0.468459 | Val. Loss: 0.711306 | Val. Kappa Score: 0.7622 | LR: 0.000500 | Estimated time: 49.93
Train loss on 50 batch: 0.462069
Train loss on 100 batch: 0.376497
Train loss on 150 batch: 0.368776
best-train-loss: 0.405638
best-valid-loss: 0.352392
best-kappa: 0.7766
: Epoch: 7 | Training Loss: 0.405638 | Val. Loss: 0.352392 | Val. Kappa Score: 0.7766 | LR: 0.000500 | Estimated time: 49.48
Train loss on 50 batch: 0.345156
Train loss on 100 batch: 0.397602
Train loss on 150 batch: 0.336066
: Epoch: 8 | Training Loss: 0.367005 | Val. Loss: 0.557342 | Val. Kappa Score: 0.7781 | LR: 0.000500 | Estimated time: 48.50
Train loss on 50 batch: 0.445211
Train loss on 100 batch: 0.492098
Train loss on 150 batch: 0.418786
: Epoch: 9 | Training Loss: 0.433001 | Val. Loss: 0.367731 | Val. Kappa Score: 0.7874 | LR: 0.000500 | Estimated time: 48.33
Train loss on 50 batch: 0.308473
Train loss on 100 batch: 0.377237
Train loss on 150 batch: 0.355314
: Epoch: 10 | Training Loss: 0.408294 | Val. Loss: 0.481427 | Val. Kappa Score: 0.7907 | LR: 0.000250 | Estimated time: 48.15
Train loss on 50 batch: 0.350557
Train loss on 100 batch: 0.342410
Train loss on 150 batch: 0.325262
: Epoch: 11 | Training Loss: 0.345104 | Val. Loss: 0.361002 | Val. Kappa Score: 0.7976 | LR: 0.000250 | Estimated time: 48.29
Train loss on 50 batch: 0.294549
Train loss on 100 batch: 0.315681
Train loss on 150 batch: 0.325762
: Epoch: 12 | Training Loss: 0.318529 | Val. Loss: 0.452248 | Val. Kappa Score: 0.8006 | LR: 0.000250 | Estimated time: 48.16
Train loss on 50 batch: 0.284010
Train loss on 100 batch: 0.350465
Train loss on 150 batch: 0.331870
best-train-loss: 0.310370
best-valid-loss: 0.339646
best-kappa: 0.8062
: Epoch: 13 | Training Loss: 0.310370 | Val. Loss: 0.339646 | Val. Kappa Score: 0.8062 | LR: 0.000250 | Estimated time: 48.33
Train loss on 50 batch: 0.288273
Train loss on 100 batch: 0.292103
Train loss on 150 batch: 0.351833
: Epoch: 14 | Training Loss: 0.317545 | Val. Loss: 0.355279 | Val. Kappa Score: 0.8101 | LR: 0.000250 | Estimated time: 48.10
Train loss on 50 batch: 0.363800
Train loss on 100 batch: 0.303420
Train loss on 150 batch: 0.280528
best-train-loss: 0.311440
best-valid-loss: 0.338555
best-kappa: 0.8139
: Epoch: 15 | Training Loss: 0.311440 | Val. Loss: 0.338555 | Val. Kappa Score: 0.8139 | LR: 0.000250 | Estimated time: 48.58
Train loss on 50 batch: 0.317775
Train loss on 100 batch: 0.293927
Train loss on 150 batch: 0.295704
: Epoch: 16 | Training Loss: 0.308014 | Val. Loss: 0.353933 | Val. Kappa Score: 0.8163 | LR: 0.000250 | Estimated time: 48.47
Train loss on 50 batch: 0.356781
Train loss on 100 batch: 0.290977
Train loss on 150 batch: 0.266122
best-train-loss: 0.299332
best-valid-loss: 0.318494
best-kappa: 0.8195
: Epoch: 17 | Training Loss: 0.299332 | Val. Loss: 0.318494 | Val. Kappa Score: 0.8195 | LR: 0.000250 | Estimated time: 48.51
Train loss on 50 batch: 0.310118
Train loss on 100 batch: 0.260227
Train loss on 150 batch: 0.280707
: Epoch: 18 | Training Loss: 0.287298 | Val. Loss: 0.336340 | Val. Kappa Score: 0.8222 | LR: 0.000250 | Estimated time: 48.63
Train loss on 50 batch: 0.260802
Train loss on 100 batch: 0.310857
Train loss on 150 batch: 0.320382
: Epoch: 19 | Training Loss: 0.317298 | Val. Loss: 0.330415 | Val. Kappa Score: 0.8247 | LR: 0.000250 | Estimated time: 48.61
Train loss on 50 batch: 0.310164
Train loss on 100 batch: 0.303480
Train loss on 150 batch: 0.275939
best-train-loss: 0.287004
best-valid-loss: 0.317411
best-kappa: 0.8275
: Epoch: 20 | Training Loss: 0.287004 | Val. Loss: 0.317411 | Val. Kappa Score: 0.8275 | LR: 0.000250 | Estimated time: 48.64
Train loss on 50 batch: 0.286888
Train loss on 100 batch: 0.271277
Train loss on 150 batch: 0.305270
: Epoch: 21 | Training Loss: 0.307369 | Val. Loss: 0.347159 | Val. Kappa Score: 0.8296 | LR: 0.000250 | Estimated time: 48.48
Train loss on 50 batch: 0.285936
Train loss on 100 batch: 0.277883
Train loss on 150 batch: 0.312411
: Epoch: 22 | Training Loss: 0.283045 | Val. Loss: 0.346987 | Val. Kappa Score: 0.8314 | LR: 0.000250 | Estimated time: 48.25
Train loss on 50 batch: 0.294966
Train loss on 100 batch: 0.272603
Train loss on 150 batch: 0.290901
: Epoch: 23 | Training Loss: 0.283813 | Val. Loss: 0.374558 | Val. Kappa Score: 0.8323 | LR: 0.000125 | Estimated time: 48.21
Train loss on 50 batch: 0.280937
Train loss on 100 batch: 0.255808
Train loss on 150 batch: 0.259438
best-train-loss: 0.317041
best-valid-loss: 0.302256
best-kappa: 0.8342
: Epoch: 24 | Training Loss: 0.317041 | Val. Loss: 0.302256 | Val. Kappa Score: 0.8342 | LR: 0.000125 | Estimated time: 48.25
Train loss on 50 batch: 0.305177
Train loss on 100 batch: 0.247262
Train loss on 150 batch: 0.296037
: Epoch: 25 | Training Loss: 0.284163 | Val. Loss: 0.306743 | Val. Kappa Score: 0.8361 | LR: 0.000125 | Estimated time: 48.54
Train loss on 50 batch: 0.243904
Train loss on 100 batch: 0.231651
Train loss on 150 batch: 0.302731
: Epoch: 26 | Training Loss: 0.284275 | Val. Loss: 0.315255 | Val. Kappa Score: 0.8379 | LR: 0.000125 | Estimated time: 46.06
Train loss on 50 batch: 0.277662
Train loss on 100 batch: 0.275890
Train loss on 150 batch: 0.249639
: Epoch: 27 | Training Loss: 0.258442 | Val. Loss: 0.308825 | Val. Kappa Score: 0.8395 | LR: 0.000063 | Estimated time: 44.30
Train loss on 50 batch: 0.274099
Train loss on 100 batch: 0.246401
Train loss on 150 batch: 0.238633
: Epoch: 28 | Training Loss: 0.248859 | Val. Loss: 0.302613 | Val. Kappa Score: 0.8409 | LR: 0.000063 | Estimated time: 44.40
Train loss on 50 batch: 0.213054
Train loss on 100 batch: 0.253585
Train loss on 150 batch: 0.231260
: Epoch: 29 | Training Loss: 0.233331 | Val. Loss: 0.310174 | Val. Kappa Score: 0.8425 | LR: 0.000063 | Estimated time: 45.59
Train loss on 50 batch: 0.215248
Train loss on 100 batch: 0.231353
Train loss on 150 batch: 0.238134
best-train-loss: 0.228779
best-valid-loss: 0.290901
best-kappa: 0.8437
: Epoch: 30 | Training Loss: 0.228779 | Val. Loss: 0.290901 | Val. Kappa Score: 0.8437 | LR: 0.000063 | Estimated time: 44.67
Train loss on 50 batch: 0.201231
Train loss on 100 batch: 0.254631
Train loss on 150 batch: 0.215268
: Epoch: 31 | Training Loss: 0.248254 | Val. Loss: 0.296827 | Val. Kappa Score: 0.8451 | LR: 0.000063 | Estimated time: 44.11
Train loss on 50 batch: 0.213725
Train loss on 100 batch: 0.263373
Train loss on 150 batch: 0.212013
: Epoch: 32 | Training Loss: 0.228756 | Val. Loss: 0.291942 | Val. Kappa Score: 0.8461 | LR: 0.000063 | Estimated time: 44.28
Train loss on 50 batch: 0.220715
Train loss on 100 batch: 0.214403
Train loss on 150 batch: 0.221737
: Epoch: 33 | Training Loss: 0.226557 | Val. Loss: 0.299936 | Val. Kappa Score: 0.8474 | LR: 0.000031 | Estimated time: 44.22
Train loss on 50 batch: 0.217153
Train loss on 100 batch: 0.230582
Train loss on 150 batch: 0.256179
best-train-loss: 0.229474
best-valid-loss: 0.290888
best-kappa: 0.8485
: Epoch: 34 | Training Loss: 0.229474 | Val. Loss: 0.290888 | Val. Kappa Score: 0.8485 | LR: 0.000031 | Estimated time: 44.18
Train loss on 50 batch: 0.216593
Train loss on 100 batch: 0.215617
Train loss on 150 batch: 0.221380
: Epoch: 35 | Training Loss: 0.228330 | Val. Loss: 0.299571 | Val. Kappa Score: 0.8495 | LR: 0.000031 | Estimated time: 44.09
Train loss on 50 batch: 0.196527
Train loss on 100 batch: 0.254298
Train loss on 150 batch: 0.199098
: Epoch: 36 | Training Loss: 0.227751 | Val. Loss: 0.303432 | Val. Kappa Score: 0.8503 | LR: 0.000016 | Estimated time: 44.19
Train loss on 50 batch: 0.211766
Train loss on 100 batch: 0.223327
Train loss on 150 batch: 0.204283
best-train-loss: 0.215594
best-valid-loss: 0.290792
best-kappa: 0.8512
: Epoch: 37 | Training Loss: 0.215594 | Val. Loss: 0.290792 | Val. Kappa Score: 0.8512 | LR: 0.000016 | Estimated time: 45.53
Train loss on 50 batch: 0.202407
Train loss on 100 batch: 0.205477
Train loss on 150 batch: 0.216387
: Epoch: 38 | Training Loss: 0.255621 | Val. Loss: 0.302463 | Val. Kappa Score: 0.8520 | LR: 0.000016 | Estimated time: 46.89
Train loss on 50 batch: 0.233473
Train loss on 100 batch: 0.213529
Train loss on 150 batch: 0.217314
best-train-loss: 0.226359
best-valid-loss: 0.285409
best-kappa: 0.8527
: Epoch: 39 | Training Loss: 0.226359 | Val. Loss: 0.285409 | Val. Kappa Score: 0.8527 | LR: 0.000016 | Estimated time: 46.65
Train loss on 50 batch: 0.214291
Train loss on 100 batch: 0.192849
Train loss on 150 batch: 0.242996
: Epoch: 40 | Training Loss: 0.212038 | Val. Loss: 0.295718 | Val. Kappa Score: 0.8536 | LR: 0.000016 | Estimated time: 47.61
Train loss on 50 batch: 0.192138
Train loss on 100 batch: 0.204097
Train loss on 150 batch: 0.206819
: Epoch: 41 | Training Loss: 0.213333 | Val. Loss: 0.293898 | Val. Kappa Score: 0.8544 | LR: 0.000016 | Estimated time: 44.39
Train loss on 50 batch: 0.209618
Train loss on 100 batch: 0.193420
Train loss on 150 batch: 0.210298
: Epoch: 42 | Training Loss: 0.225599 | Val. Loss: 0.292861 | Val. Kappa Score: 0.8553 | LR: 0.000008 | Estimated time: 44.22
Train loss on 50 batch: 0.206687
Train loss on 100 batch: 0.217602
Train loss on 150 batch: 0.192441
: Epoch: 43 | Training Loss: 0.219619 | Val. Loss: 0.291968 | Val. Kappa Score: 0.8560 | LR: 0.000008 | Estimated time: 44.27
Train loss on 50 batch: 0.202768
Train loss on 100 batch: 0.233714
Train loss on 150 batch: 0.210325
: Epoch: 44 | Training Loss: 0.206559 | Val. Loss: 0.295342 | Val. Kappa Score: 0.8567 | LR: 0.000008 | Estimated time: 44.22
Train loss on 50 batch: 0.211000
Train loss on 100 batch: 0.168263
Train loss on 150 batch: 0.248241
: Epoch: 45 | Training Loss: 0.220334 | Val. Loss: 0.297265 | Val. Kappa Score: 0.8574 | LR: 0.000004 | Estimated time: 44.25
Train loss on 50 batch: 0.201809
Train loss on 100 batch: 0.201707
Train loss on 150 batch: 0.203127
: Epoch: 46 | Training Loss: 0.207278 | Val. Loss: 0.291809 | Val. Kappa Score: 0.8581 | LR: 0.000004 | Estimated time: 44.21
Train loss on 50 batch: 0.216209
Train loss on 100 batch: 0.189511
Train loss on 150 batch: 0.183547
: Epoch: 47 | Training Loss: 0.222512 | Val. Loss: 0.292002 | Val. Kappa Score: 0.8589 | LR: 0.000004 | Estimated time: 44.23
time_estimated: 2208.11
n-epochs: 47
time_estimated: 2208.14
----------------------------------------

Experiment N: 88: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 03:38:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f800b8>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.151824
Train loss on 100 batch: 1.480276
Train loss on 150 batch: 1.131368
best-train-loss: 1.461326
best-valid-loss: 0.934934
best-kappa: 0.6414
: Epoch: 1 | Training Loss: 1.461326 | Val. Loss: 0.934934 | Val. Kappa Score: 0.6414 | LR: 0.005000 | Estimated time: 44.40
Train loss on 50 batch: 1.061548
Train loss on 100 batch: 1.031173
Train loss on 150 batch: 0.931499
: Epoch: 2 | Training Loss: 1.050638 | Val. Loss: 1.516922 | Val. Kappa Score: 0.4924 | LR: 0.005000 | Estimated time: 44.35
Train loss on 50 batch: 0.982892
Train loss on 100 batch: 1.074715
Train loss on 150 batch: 1.006846
: Epoch: 3 | Training Loss: 1.006709 | Val. Loss: 1.435430 | Val. Kappa Score: 0.4544 | LR: 0.005000 | Estimated time: 44.21
Train loss on 50 batch: 1.154000
Train loss on 100 batch: 0.916481
Train loss on 150 batch: 0.983703
: Epoch: 4 | Training Loss: 1.053510 | Val. Loss: 2.379581 | Val. Kappa Score: 0.4500 | LR: 0.002500 | Estimated time: 44.19
Train loss on 50 batch: 1.066770
Train loss on 100 batch: 1.040118
Train loss on 150 batch: 0.873331
best-train-loss: 0.964321
best-valid-loss: 0.894518
best-kappa: 0.4839
: Epoch: 5 | Training Loss: 0.964321 | Val. Loss: 0.894518 | Val. Kappa Score: 0.4839 | LR: 0.002500 | Estimated time: 44.26
Train loss on 50 batch: 0.891165
Train loss on 100 batch: 0.897556
Train loss on 150 batch: 0.815286
best-train-loss: 0.863075
best-valid-loss: 0.797419
best-kappa: 0.5204
: Epoch: 6 | Training Loss: 0.863075 | Val. Loss: 0.797419 | Val. Kappa Score: 0.5204 | LR: 0.002500 | Estimated time: 44.43
Train loss on 50 batch: 0.852560
Train loss on 100 batch: 0.763919
Train loss on 150 batch: 0.843387
: Epoch: 7 | Training Loss: 0.840524 | Val. Loss: 0.838097 | Val. Kappa Score: 0.5418 | LR: 0.002500 | Estimated time: 44.22
Train loss on 50 batch: 0.874742
Train loss on 100 batch: 0.850026
Train loss on 150 batch: 0.686479
: Epoch: 8 | Training Loss: 0.783350 | Val. Loss: 0.864482 | Val. Kappa Score: 0.5594 | LR: 0.002500 | Estimated time: 44.18
Train loss on 50 batch: 0.782865
Train loss on 100 batch: 0.788032
Train loss on 150 batch: 0.776572
: Epoch: 9 | Training Loss: 0.764290 | Val. Loss: 1.030628 | Val. Kappa Score: 0.5645 | LR: 0.001250 | Estimated time: 44.27
Train loss on 50 batch: 0.689176
Train loss on 100 batch: 0.737876
Train loss on 150 batch: 0.615085
: Epoch: 10 | Training Loss: 0.749213 | Val. Loss: 0.875680 | Val. Kappa Score: 0.5675 | LR: 0.001250 | Estimated time: 44.23
Train loss on 50 batch: 0.717430
Train loss on 100 batch: 0.654659
Train loss on 150 batch: 0.692986
: Epoch: 11 | Training Loss: 0.679402 | Val. Loss: 0.839275 | Val. Kappa Score: 0.5790 | LR: 0.001250 | Estimated time: 44.23
Train loss on 50 batch: 0.677187
Train loss on 100 batch: 0.625761
Train loss on 150 batch: 0.607765
best-train-loss: 0.634501
best-valid-loss: 0.696246
best-kappa: 0.5926
: Epoch: 12 | Training Loss: 0.634501 | Val. Loss: 0.696246 | Val. Kappa Score: 0.5926 | LR: 0.001250 | Estimated time: 44.39
Train loss on 50 batch: 0.529831
Train loss on 100 batch: 0.581797
Train loss on 150 batch: 0.571052
best-train-loss: 0.548678
best-valid-loss: 0.545709
best-kappa: 0.6095
: Epoch: 13 | Training Loss: 0.548678 | Val. Loss: 0.545709 | Val. Kappa Score: 0.6095 | LR: 0.001250 | Estimated time: 44.39
Train loss on 50 batch: 0.482336
Train loss on 100 batch: 0.508062
Train loss on 150 batch: 0.588525
: Epoch: 14 | Training Loss: 0.544079 | Val. Loss: 0.559328 | Val. Kappa Score: 0.6222 | LR: 0.001250 | Estimated time: 44.34
Train loss on 50 batch: 0.588511
Train loss on 100 batch: 0.514326
Train loss on 150 batch: 0.464408
: Epoch: 15 | Training Loss: 0.520592 | Val. Loss: 0.582111 | Val. Kappa Score: 0.6333 | LR: 0.001250 | Estimated time: 44.28
Train loss on 50 batch: 0.517144
Train loss on 100 batch: 0.481456
Train loss on 150 batch: 0.458791
: Epoch: 16 | Training Loss: 0.500827 | Val. Loss: 0.729614 | Val. Kappa Score: 0.6398 | LR: 0.000625 | Estimated time: 44.45
Train loss on 50 batch: 0.553621
Train loss on 100 batch: 0.457298
Train loss on 150 batch: 0.422602
: Epoch: 17 | Training Loss: 0.472274 | Val. Loss: 0.621118 | Val. Kappa Score: 0.6485 | LR: 0.000625 | Estimated time: 44.33
Train loss on 50 batch: 0.486075
Train loss on 100 batch: 0.397870
Train loss on 150 batch: 0.439445
best-train-loss: 0.443689
best-valid-loss: 0.439115
best-kappa: 0.6590
: Epoch: 18 | Training Loss: 0.443689 | Val. Loss: 0.439115 | Val. Kappa Score: 0.6590 | LR: 0.000625 | Estimated time: 44.29
Train loss on 50 batch: 0.395913
Train loss on 100 batch: 0.486415
Train loss on 150 batch: 0.479958
best-train-loss: 0.459247
best-valid-loss: 0.423973
best-kappa: 0.6681
: Epoch: 19 | Training Loss: 0.459247 | Val. Loss: 0.423973 | Val. Kappa Score: 0.6681 | LR: 0.000625 | Estimated time: 44.38
Train loss on 50 batch: 0.411502
Train loss on 100 batch: 0.457396
Train loss on 150 batch: 0.408347
best-train-loss: 0.416326
best-valid-loss: 0.418882
best-kappa: 0.6765
: Epoch: 20 | Training Loss: 0.416326 | Val. Loss: 0.418882 | Val. Kappa Score: 0.6765 | LR: 0.000625 | Estimated time: 44.39
Train loss on 50 batch: 0.436375
Train loss on 100 batch: 0.400704
Train loss on 150 batch: 0.471783
best-train-loss: 0.459422
best-valid-loss: 0.401787
best-kappa: 0.6840
: Epoch: 21 | Training Loss: 0.459422 | Val. Loss: 0.401787 | Val. Kappa Score: 0.6840 | LR: 0.000625 | Estimated time: 44.33
Train loss on 50 batch: 0.427298
Train loss on 100 batch: 0.434436
Train loss on 150 batch: 0.481508
: Epoch: 22 | Training Loss: 0.427699 | Val. Loss: 0.417996 | Val. Kappa Score: 0.6909 | LR: 0.000625 | Estimated time: 44.32
Train loss on 50 batch: 0.391753
Train loss on 100 batch: 0.390957
Train loss on 150 batch: 0.413069
: Epoch: 23 | Training Loss: 0.409625 | Val. Loss: 0.473344 | Val. Kappa Score: 0.6959 | LR: 0.000625 | Estimated time: 44.30
Train loss on 50 batch: 0.422001
Train loss on 100 batch: 0.405956
Train loss on 150 batch: 0.414554
: Epoch: 24 | Training Loss: 0.477493 | Val. Loss: 0.421893 | Val. Kappa Score: 0.7011 | LR: 0.000313 | Estimated time: 44.38
Train loss on 50 batch: 0.389037
Train loss on 100 batch: 0.349600
Train loss on 150 batch: 0.451285
best-train-loss: 0.385191
best-valid-loss: 0.394586
best-kappa: 0.7076
: Epoch: 25 | Training Loss: 0.385191 | Val. Loss: 0.394586 | Val. Kappa Score: 0.7076 | LR: 0.000313 | Estimated time: 44.33
Train loss on 50 batch: 0.401796
Train loss on 100 batch: 0.333761
Train loss on 150 batch: 0.416823
best-train-loss: 0.413017
best-valid-loss: 0.383479
best-kappa: 0.7133
: Epoch: 26 | Training Loss: 0.413017 | Val. Loss: 0.383479 | Val. Kappa Score: 0.7133 | LR: 0.000313 | Estimated time: 44.31
Train loss on 50 batch: 0.433550
Train loss on 100 batch: 0.441294
Train loss on 150 batch: 0.369101
best-train-loss: 0.415832
best-valid-loss: 0.371907
best-kappa: 0.7192
: Epoch: 27 | Training Loss: 0.415832 | Val. Loss: 0.371907 | Val. Kappa Score: 0.7192 | LR: 0.000313 | Estimated time: 44.43
Train loss on 50 batch: 0.426724
Train loss on 100 batch: 0.411052
Train loss on 150 batch: 0.364429
: Epoch: 28 | Training Loss: 0.393079 | Val. Loss: 0.398280 | Val. Kappa Score: 0.7240 | LR: 0.000313 | Estimated time: 44.15
Train loss on 50 batch: 0.314049
Train loss on 100 batch: 0.399321
Train loss on 150 batch: 0.383289
: Epoch: 29 | Training Loss: 0.364259 | Val. Loss: 0.388899 | Val. Kappa Score: 0.7289 | LR: 0.000313 | Estimated time: 44.41
Train loss on 50 batch: 0.355616
Train loss on 100 batch: 0.362913
Train loss on 150 batch: 0.379746
: Epoch: 30 | Training Loss: 0.373285 | Val. Loss: 0.390198 | Val. Kappa Score: 0.7331 | LR: 0.000156 | Estimated time: 44.32
Train loss on 50 batch: 0.308120
Train loss on 100 batch: 0.364907
Train loss on 150 batch: 0.341630
best-train-loss: 0.349503
best-valid-loss: 0.335087
best-kappa: 0.7376
: Epoch: 31 | Training Loss: 0.349503 | Val. Loss: 0.335087 | Val. Kappa Score: 0.7376 | LR: 0.000156 | Estimated time: 44.48
Train loss on 50 batch: 0.320455
Train loss on 100 batch: 0.399469
Train loss on 150 batch: 0.301281
: Epoch: 32 | Training Loss: 0.335750 | Val. Loss: 0.341401 | Val. Kappa Score: 0.7420 | LR: 0.000156 | Estimated time: 44.29
Train loss on 50 batch: 0.334491
Train loss on 100 batch: 0.355061
Train loss on 150 batch: 0.319877
best-train-loss: 0.340299
best-valid-loss: 0.328485
best-kappa: 0.7462
: Epoch: 33 | Training Loss: 0.340299 | Val. Loss: 0.328485 | Val. Kappa Score: 0.7462 | LR: 0.000156 | Estimated time: 44.28
Train loss on 50 batch: 0.283104
Train loss on 100 batch: 0.383181
Train loss on 150 batch: 0.340125
: Epoch: 34 | Training Loss: 0.328722 | Val. Loss: 0.400825 | Val. Kappa Score: 0.7495 | LR: 0.000156 | Estimated time: 44.23
Train loss on 50 batch: 0.311038
Train loss on 100 batch: 0.329705
Train loss on 150 batch: 0.343067
: Epoch: 35 | Training Loss: 0.338802 | Val. Loss: 0.339784 | Val. Kappa Score: 0.7533 | LR: 0.000156 | Estimated time: 44.27
Train loss on 50 batch: 0.290517
Train loss on 100 batch: 0.338628
Train loss on 150 batch: 0.311310
: Epoch: 36 | Training Loss: 0.342579 | Val. Loss: 0.365303 | Val. Kappa Score: 0.7561 | LR: 0.000078 | Estimated time: 44.43
Train loss on 50 batch: 0.307111
Train loss on 100 batch: 0.315764
Train loss on 150 batch: 0.303031
best-train-loss: 0.322153
best-valid-loss: 0.321942
best-kappa: 0.7592
: Epoch: 37 | Training Loss: 0.322153 | Val. Loss: 0.321942 | Val. Kappa Score: 0.7592 | LR: 0.000078 | Estimated time: 44.33
Train loss on 50 batch: 0.285454
Train loss on 100 batch: 0.285998
Train loss on 150 batch: 0.301731
: Epoch: 38 | Training Loss: 0.376523 | Val. Loss: 0.321947 | Val. Kappa Score: 0.7625 | LR: 0.000078 | Estimated time: 44.28
Train loss on 50 batch: 0.382585
Train loss on 100 batch: 0.306575
Train loss on 150 batch: 0.299277
best-train-loss: 0.336615
best-valid-loss: 0.321860
best-kappa: 0.7651
: Epoch: 39 | Training Loss: 0.336615 | Val. Loss: 0.321860 | Val. Kappa Score: 0.7651 | LR: 0.000078 | Estimated time: 44.30
Train loss on 50 batch: 0.289098
Train loss on 100 batch: 0.284613
Train loss on 150 batch: 0.316174
: Epoch: 40 | Training Loss: 0.299411 | Val. Loss: 0.322444 | Val. Kappa Score: 0.7680 | LR: 0.000078 | Estimated time: 44.27
Train loss on 50 batch: 0.274275
Train loss on 100 batch: 0.331422
Train loss on 150 batch: 0.297883
: Epoch: 41 | Training Loss: 0.300974 | Val. Loss: 0.321903 | Val. Kappa Score: 0.7710 | LR: 0.000078 | Estimated time: 44.28
Train loss on 50 batch: 0.321576
Train loss on 100 batch: 0.236821
Train loss on 150 batch: 0.294838
: Epoch: 42 | Training Loss: 0.293403 | Val. Loss: 0.337016 | Val. Kappa Score: 0.7735 | LR: 0.000039 | Estimated time: 44.19
Train loss on 50 batch: 0.300814
Train loss on 100 batch: 0.310821
Train loss on 150 batch: 0.271401
: Epoch: 43 | Training Loss: 0.302932 | Val. Loss: 0.328724 | Val. Kappa Score: 0.7761 | LR: 0.000039 | Estimated time: 44.34
Train loss on 50 batch: 0.282722
Train loss on 100 batch: 0.281602
Train loss on 150 batch: 0.299735
best-train-loss: 0.274145
best-valid-loss: 0.316816
best-kappa: 0.7785
: Epoch: 44 | Training Loss: 0.274145 | Val. Loss: 0.316816 | Val. Kappa Score: 0.7785 | LR: 0.000039 | Estimated time: 44.22
Train loss on 50 batch: 0.283730
Train loss on 100 batch: 0.251766
Train loss on 150 batch: 0.335694
: Epoch: 45 | Training Loss: 0.289951 | Val. Loss: 0.319944 | Val. Kappa Score: 0.7811 | LR: 0.000039 | Estimated time: 44.31
Train loss on 50 batch: 0.296441
Train loss on 100 batch: 0.270599
Train loss on 150 batch: 0.286813
best-train-loss: 0.286068
best-valid-loss: 0.311177
best-kappa: 0.7833
: Epoch: 46 | Training Loss: 0.286068 | Val. Loss: 0.311177 | Val. Kappa Score: 0.7833 | LR: 0.000039 | Estimated time: 44.30
Train loss on 50 batch: 0.282866
Train loss on 100 batch: 0.239624
Train loss on 150 batch: 0.288919
: Epoch: 47 | Training Loss: 0.282947 | Val. Loss: 0.315355 | Val. Kappa Score: 0.7855 | LR: 0.000039 | Estimated time: 44.34
Train loss on 50 batch: 0.254177
Train loss on 100 batch: 0.295698
Train loss on 150 batch: 0.287394
: Epoch: 48 | Training Loss: 0.277736 | Val. Loss: 0.319771 | Val. Kappa Score: 0.7874 | LR: 0.000039 | Estimated time: 44.48
Train loss on 50 batch: 0.257255
Train loss on 100 batch: 0.297714
Train loss on 150 batch: 0.256748
: Epoch: 49 | Training Loss: 0.276974 | Val. Loss: 0.333543 | Val. Kappa Score: 0.7892 | LR: 0.000020 | Estimated time: 44.33
Train loss on 50 batch: 0.248279
Train loss on 100 batch: 0.256686
Train loss on 150 batch: 0.295528
: Epoch: 50 | Training Loss: 0.272084 | Val. Loss: 0.317533 | Val. Kappa Score: 0.7911 | LR: 0.000020 | Estimated time: 44.33
Train loss on 50 batch: 0.283432
Train loss on 100 batch: 0.307259
Train loss on 150 batch: 0.254388
: Epoch: 51 | Training Loss: 0.278012 | Val. Loss: 0.315779 | Val. Kappa Score: 0.7930 | LR: 0.000020 | Estimated time: 44.28
Train loss on 50 batch: 0.265450
Train loss on 100 batch: 0.263590
Train loss on 150 batch: 0.282995
best-train-loss: 0.274874
best-valid-loss: 0.309236
best-kappa: 0.7947
: Epoch: 52 | Training Loss: 0.274874 | Val. Loss: 0.309236 | Val. Kappa Score: 0.7947 | LR: 0.000020 | Estimated time: 44.42
Train loss on 50 batch: 0.307242
Train loss on 100 batch: 0.244255
Train loss on 150 batch: 0.254356
: Epoch: 53 | Training Loss: 0.266483 | Val. Loss: 0.323034 | Val. Kappa Score: 0.7962 | LR: 0.000020 | Estimated time: 44.30
Train loss on 50 batch: 0.275977
Train loss on 100 batch: 0.259510
Train loss on 150 batch: 0.246799
: Epoch: 54 | Training Loss: 0.297295 | Val. Loss: 0.349427 | Val. Kappa Score: 0.7977 | LR: 0.000020 | Estimated time: 44.43
Train loss on 50 batch: 0.288490
Train loss on 100 batch: 0.272798
Train loss on 150 batch: 0.298204
: Epoch: 55 | Training Loss: 0.269310 | Val. Loss: 0.319406 | Val. Kappa Score: 0.7991 | LR: 0.000010 | Estimated time: 44.32
Train loss on 50 batch: 0.237189
Train loss on 100 batch: 0.243331
Train loss on 150 batch: 0.293941
: Epoch: 56 | Training Loss: 0.269316 | Val. Loss: 0.325902 | Val. Kappa Score: 0.8003 | LR: 0.000010 | Estimated time: 44.30
Train loss on 50 batch: 0.252898
Train loss on 100 batch: 0.276934
Train loss on 150 batch: 0.242455
: Epoch: 57 | Training Loss: 0.261647 | Val. Loss: 0.330071 | Val. Kappa Score: 0.8018 | LR: 0.000010 | Estimated time: 44.32
Train loss on 50 batch: 0.295836
Train loss on 100 batch: 0.247573
Train loss on 150 batch: 0.226125
: Epoch: 58 | Training Loss: 0.260048 | Val. Loss: 0.312544 | Val. Kappa Score: 0.8031 | LR: 0.000005 | Estimated time: 44.32
Train loss on 50 batch: 0.283952
Train loss on 100 batch: 0.250313
Train loss on 150 batch: 0.243706
: Epoch: 59 | Training Loss: 0.261240 | Val. Loss: 0.338707 | Val. Kappa Score: 0.8044 | LR: 0.000005 | Estimated time: 44.34
Train loss on 50 batch: 0.243329
Train loss on 100 batch: 0.261743
Train loss on 150 batch: 0.250635
: Epoch: 60 | Training Loss: 0.283300 | Val. Loss: 0.338407 | Val. Kappa Score: 0.8056 | LR: 0.000005 | Estimated time: 44.27
time_estimated: 2663.21
n-epochs: 60
time_estimated: 2663.23
----------------------------------------

Experiment N: 89: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.01, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 04:22:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c140710>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 3.309099
Train loss on 100 batch: 1.284390
Train loss on 150 batch: 1.136817
best-train-loss: 1.703925
best-valid-loss: 2.777681
best-kappa: 0.4357
: Epoch: 1 | Training Loss: 1.703925 | Val. Loss: 2.777681 | Val. Kappa Score: 0.4357 | LR: 0.010000 | Estimated time: 44.26
Train loss on 50 batch: 1.205139
Train loss on 100 batch: 1.134967
Train loss on 150 batch: 0.977803
best-train-loss: 1.147428
best-valid-loss: 1.158446
best-kappa: 0.4263
: Epoch: 2 | Training Loss: 1.147428 | Val. Loss: 1.158446 | Val. Kappa Score: 0.4263 | LR: 0.010000 | Estimated time: 44.20
Train loss on 50 batch: 1.066396
Train loss on 100 batch: 1.199701
Train loss on 150 batch: 1.093251
: Epoch: 3 | Training Loss: 1.073934 | Val. Loss: 1.842718 | Val. Kappa Score: 0.4787 | LR: 0.010000 | Estimated time: 44.25
Train loss on 50 batch: 1.054939
Train loss on 100 batch: 0.986454
Train loss on 150 batch: 1.022673
: Epoch: 4 | Training Loss: 1.084920 | Val. Loss: 3.378696 | Val. Kappa Score: 0.4145 | LR: 0.010000 | Estimated time: 44.19
Train loss on 50 batch: 1.480504
Train loss on 100 batch: 1.294581
Train loss on 150 batch: 1.082951
: Epoch: 5 | Training Loss: 1.226495 | Val. Loss: 1.954780 | Val. Kappa Score: 0.4493 | LR: 0.005000 | Estimated time: 44.21
Train loss on 50 batch: 1.020309
Train loss on 100 batch: 1.019989
Train loss on 150 batch: 0.898028
best-train-loss: 0.956698
best-valid-loss: 0.927845
best-kappa: 0.4823
: Epoch: 6 | Training Loss: 0.956698 | Val. Loss: 0.927845 | Val. Kappa Score: 0.4823 | LR: 0.005000 | Estimated time: 44.39
Train loss on 50 batch: 0.985487
Train loss on 100 batch: 0.879325
Train loss on 150 batch: 0.999234
: Epoch: 7 | Training Loss: 0.948825 | Val. Loss: 1.139126 | Val. Kappa Score: 0.4780 | LR: 0.005000 | Estimated time: 44.18
Train loss on 50 batch: 0.964753
Train loss on 100 batch: 0.957652
Train loss on 150 batch: 0.809058
: Epoch: 8 | Training Loss: 0.883119 | Val. Loss: 1.423718 | Val. Kappa Score: 0.4859 | LR: 0.005000 | Estimated time: 44.21
Train loss on 50 batch: 0.838087
Train loss on 100 batch: 0.853121
Train loss on 150 batch: 0.838151
: Epoch: 9 | Training Loss: 0.838744 | Val. Loss: 1.135622 | Val. Kappa Score: 0.4920 | LR: 0.002500 | Estimated time: 44.11
Train loss on 50 batch: 0.734750
Train loss on 100 batch: 0.777124
Train loss on 150 batch: 0.722211
best-train-loss: 0.799909
best-valid-loss: 0.828356
best-kappa: 0.5102
: Epoch: 10 | Training Loss: 0.799909 | Val. Loss: 0.828356 | Val. Kappa Score: 0.5102 | LR: 0.002500 | Estimated time: 44.29
Train loss on 50 batch: 0.770640
Train loss on 100 batch: 0.715094
Train loss on 150 batch: 0.703663
best-train-loss: 0.711291
best-valid-loss: 0.680541
best-kappa: 0.5319
: Epoch: 11 | Training Loss: 0.711291 | Val. Loss: 0.680541 | Val. Kappa Score: 0.5319 | LR: 0.002500 | Estimated time: 44.31
Train loss on 50 batch: 0.676303
Train loss on 100 batch: 0.633617
Train loss on 150 batch: 0.675331
: Epoch: 12 | Training Loss: 0.663651 | Val. Loss: 0.724304 | Val. Kappa Score: 0.5499 | LR: 0.002500 | Estimated time: 44.31
Train loss on 50 batch: 0.586903
Train loss on 100 batch: 0.603986
Train loss on 150 batch: 0.659513
best-train-loss: 0.608959
best-valid-loss: 0.666698
best-kappa: 0.5652
: Epoch: 13 | Training Loss: 0.608959 | Val. Loss: 0.666698 | Val. Kappa Score: 0.5652 | LR: 0.002500 | Estimated time: 44.34
Train loss on 50 batch: 0.564990
Train loss on 100 batch: 0.541027
Train loss on 150 batch: 0.664252
: Epoch: 14 | Training Loss: 0.591636 | Val. Loss: 0.730690 | Val. Kappa Score: 0.5784 | LR: 0.002500 | Estimated time: 44.28
Train loss on 50 batch: 0.609527
Train loss on 100 batch: 0.544941
Train loss on 150 batch: 0.536689
best-train-loss: 0.567372
best-valid-loss: 0.527843
best-kappa: 0.5928
: Epoch: 15 | Training Loss: 0.567372 | Val. Loss: 0.527843 | Val. Kappa Score: 0.5928 | LR: 0.002500 | Estimated time: 44.24
Train loss on 50 batch: 0.556347
Train loss on 100 batch: 0.530215
Train loss on 150 batch: 0.510662
: Epoch: 16 | Training Loss: 0.537764 | Val. Loss: 0.545364 | Val. Kappa Score: 0.6062 | LR: 0.002500 | Estimated time: 44.16
Train loss on 50 batch: 0.652926
Train loss on 100 batch: 0.553853
Train loss on 150 batch: 0.498452
: Epoch: 17 | Training Loss: 0.569066 | Val. Loss: 0.800885 | Val. Kappa Score: 0.6134 | LR: 0.002500 | Estimated time: 44.34
Train loss on 50 batch: 0.541688
Train loss on 100 batch: 0.486315
Train loss on 150 batch: 0.534164
: Epoch: 18 | Training Loss: 0.524737 | Val. Loss: 0.571792 | Val. Kappa Score: 0.6231 | LR: 0.001250 | Estimated time: 44.23
Train loss on 50 batch: 0.441086
Train loss on 100 batch: 0.549553
Train loss on 150 batch: 0.535320
: Epoch: 19 | Training Loss: 0.515994 | Val. Loss: 0.543616 | Val. Kappa Score: 0.6328 | LR: 0.001250 | Estimated time: 44.29
Train loss on 50 batch: 0.494835
Train loss on 100 batch: 0.514619
Train loss on 150 batch: 0.464600
best-train-loss: 0.484051
best-valid-loss: 0.494435
best-kappa: 0.6421
: Epoch: 20 | Training Loss: 0.484051 | Val. Loss: 0.494435 | Val. Kappa Score: 0.6421 | LR: 0.001250 | Estimated time: 44.18
Train loss on 50 batch: 0.459036
Train loss on 100 batch: 0.482872
Train loss on 150 batch: 0.532895
: Epoch: 21 | Training Loss: 0.505516 | Val. Loss: 0.501393 | Val. Kappa Score: 0.6503 | LR: 0.001250 | Estimated time: 44.36
Train loss on 50 batch: 0.472609
Train loss on 100 batch: 0.499064
Train loss on 150 batch: 0.516343
: Epoch: 22 | Training Loss: 0.470379 | Val. Loss: 0.542858 | Val. Kappa Score: 0.6570 | LR: 0.001250 | Estimated time: 44.17
Train loss on 50 batch: 0.440767
Train loss on 100 batch: 0.440398
Train loss on 150 batch: 0.485877
: Epoch: 23 | Training Loss: 0.467847 | Val. Loss: 0.500951 | Val. Kappa Score: 0.6646 | LR: 0.000625 | Estimated time: 44.22
Train loss on 50 batch: 0.480939
Train loss on 100 batch: 0.464532
Train loss on 150 batch: 0.465449
best-train-loss: 0.512669
best-valid-loss: 0.461483
best-kappa: 0.6711
: Epoch: 24 | Training Loss: 0.512669 | Val. Loss: 0.461483 | Val. Kappa Score: 0.6711 | LR: 0.000625 | Estimated time: 44.29
Train loss on 50 batch: 0.435071
Train loss on 100 batch: 0.410723
Train loss on 150 batch: 0.512893
best-train-loss: 0.436375
best-valid-loss: 0.432133
best-kappa: 0.6780
: Epoch: 25 | Training Loss: 0.436375 | Val. Loss: 0.432133 | Val. Kappa Score: 0.6780 | LR: 0.000625 | Estimated time: 44.18
Train loss on 50 batch: 0.452394
Train loss on 100 batch: 0.389966
Train loss on 150 batch: 0.499549
: Epoch: 26 | Training Loss: 0.457362 | Val. Loss: 0.444354 | Val. Kappa Score: 0.6845 | LR: 0.000625 | Estimated time: 44.12
Train loss on 50 batch: 0.490556
Train loss on 100 batch: 0.503602
Train loss on 150 batch: 0.429896
: Epoch: 27 | Training Loss: 0.457980 | Val. Loss: 0.481916 | Val. Kappa Score: 0.6893 | LR: 0.000625 | Estimated time: 44.37
Train loss on 50 batch: 0.482753
Train loss on 100 batch: 0.495375
Train loss on 150 batch: 0.418561
best-train-loss: 0.452315
best-valid-loss: 0.410432
best-kappa: 0.6943
: Epoch: 28 | Training Loss: 0.452315 | Val. Loss: 0.410432 | Val. Kappa Score: 0.6943 | LR: 0.000625 | Estimated time: 44.36
Train loss on 50 batch: 0.387966
Train loss on 100 batch: 0.462862
Train loss on 150 batch: 0.442626
: Epoch: 29 | Training Loss: 0.422152 | Val. Loss: 0.478643 | Val. Kappa Score: 0.6990 | LR: 0.000625 | Estimated time: 44.26
Train loss on 50 batch: 0.402132
Train loss on 100 batch: 0.412079
Train loss on 150 batch: 0.446082
: Epoch: 30 | Training Loss: 0.411361 | Val. Loss: 0.517552 | Val. Kappa Score: 0.7022 | LR: 0.000625 | Estimated time: 44.43
Train loss on 50 batch: 0.365362
Train loss on 100 batch: 0.418633
Train loss on 150 batch: 0.417900
: Epoch: 31 | Training Loss: 0.447482 | Val. Loss: 0.427237 | Val. Kappa Score: 0.7065 | LR: 0.000313 | Estimated time: 44.27
Train loss on 50 batch: 0.394976
Train loss on 100 batch: 0.448540
Train loss on 150 batch: 0.366145
best-train-loss: 0.400901
best-valid-loss: 0.401060
best-kappa: 0.7110
: Epoch: 32 | Training Loss: 0.400901 | Val. Loss: 0.401060 | Val. Kappa Score: 0.7110 | LR: 0.000313 | Estimated time: 44.38
Train loss on 50 batch: 0.402968
Train loss on 100 batch: 0.426344
Train loss on 150 batch: 0.369066
: Epoch: 33 | Training Loss: 0.398293 | Val. Loss: 0.444975 | Val. Kappa Score: 0.7151 | LR: 0.000313 | Estimated time: 44.25
Train loss on 50 batch: 0.334500
Train loss on 100 batch: 0.435068
Train loss on 150 batch: 0.396923
: Epoch: 34 | Training Loss: 0.377625 | Val. Loss: 0.448584 | Val. Kappa Score: 0.7190 | LR: 0.000313 | Estimated time: 44.18
Train loss on 50 batch: 0.359928
Train loss on 100 batch: 0.385699
Train loss on 150 batch: 0.393880
: Epoch: 35 | Training Loss: 0.389295 | Val. Loss: 0.425548 | Val. Kappa Score: 0.7227 | LR: 0.000156 | Estimated time: 44.20
Train loss on 50 batch: 0.336244
Train loss on 100 batch: 0.406150
Train loss on 150 batch: 0.346033
best-train-loss: 0.390191
best-valid-loss: 0.396906
best-kappa: 0.7263
: Epoch: 36 | Training Loss: 0.390191 | Val. Loss: 0.396906 | Val. Kappa Score: 0.7263 | LR: 0.000156 | Estimated time: 44.18
Train loss on 50 batch: 0.368249
Train loss on 100 batch: 0.381684
Train loss on 150 batch: 0.363922
best-train-loss: 0.380356
best-valid-loss: 0.373357
best-kappa: 0.7296
: Epoch: 37 | Training Loss: 0.380356 | Val. Loss: 0.373357 | Val. Kappa Score: 0.7296 | LR: 0.000156 | Estimated time: 44.20
Train loss on 50 batch: 0.354085
Train loss on 100 batch: 0.340506
Train loss on 150 batch: 0.361751
: Epoch: 38 | Training Loss: 0.464197 | Val. Loss: 0.385935 | Val. Kappa Score: 0.7327 | LR: 0.000156 | Estimated time: 44.18
Train loss on 50 batch: 0.437883
Train loss on 100 batch: 0.358591
Train loss on 150 batch: 0.354340
: Epoch: 39 | Training Loss: 0.389387 | Val. Loss: 0.382729 | Val. Kappa Score: 0.7358 | LR: 0.000156 | Estimated time: 44.34
Train loss on 50 batch: 0.359385
Train loss on 100 batch: 0.346453
Train loss on 150 batch: 0.371074
best-train-loss: 0.350261
best-valid-loss: 0.372012
best-kappa: 0.7387
: Epoch: 40 | Training Loss: 0.350261 | Val. Loss: 0.372012 | Val. Kappa Score: 0.7387 | LR: 0.000156 | Estimated time: 44.31
Train loss on 50 batch: 0.354828
Train loss on 100 batch: 0.370977
Train loss on 150 batch: 0.369424
best-train-loss: 0.361416
best-valid-loss: 0.364195
best-kappa: 0.7420
: Epoch: 41 | Training Loss: 0.361416 | Val. Loss: 0.364195 | Val. Kappa Score: 0.7420 | LR: 0.000156 | Estimated time: 44.26
Train loss on 50 batch: 0.374483
Train loss on 100 batch: 0.309736
Train loss on 150 batch: 0.357523
: Epoch: 42 | Training Loss: 0.362927 | Val. Loss: 0.394330 | Val. Kappa Score: 0.7447 | LR: 0.000156 | Estimated time: 44.23
Train loss on 50 batch: 0.319013
Train loss on 100 batch: 0.377898
Train loss on 150 batch: 0.339151
best-train-loss: 0.369093
best-valid-loss: 0.357842
best-kappa: 0.7473
: Epoch: 43 | Training Loss: 0.369093 | Val. Loss: 0.357842 | Val. Kappa Score: 0.7473 | LR: 0.000156 | Estimated time: 44.19
Train loss on 50 batch: 0.379822
Train loss on 100 batch: 0.331825
Train loss on 150 batch: 0.364522
: Epoch: 44 | Training Loss: 0.344303 | Val. Loss: 0.377396 | Val. Kappa Score: 0.7497 | LR: 0.000156 | Estimated time: 44.19
Train loss on 50 batch: 0.333063
Train loss on 100 batch: 0.337030
Train loss on 150 batch: 0.408407
: Epoch: 45 | Training Loss: 0.367540 | Val. Loss: 0.367822 | Val. Kappa Score: 0.7521 | LR: 0.000156 | Estimated time: 44.31
Train loss on 50 batch: 0.369774
Train loss on 100 batch: 0.338479
Train loss on 150 batch: 0.345772
: Epoch: 46 | Training Loss: 0.354806 | Val. Loss: 0.359756 | Val. Kappa Score: 0.7546 | LR: 0.000078 | Estimated time: 44.35
Train loss on 50 batch: 0.325721
Train loss on 100 batch: 0.280020
Train loss on 150 batch: 0.358197
: Epoch: 47 | Training Loss: 0.340637 | Val. Loss: 0.368853 | Val. Kappa Score: 0.7568 | LR: 0.000078 | Estimated time: 44.20
Train loss on 50 batch: 0.311999
Train loss on 100 batch: 0.339310
Train loss on 150 batch: 0.363908
: Epoch: 48 | Training Loss: 0.334722 | Val. Loss: 0.361870 | Val. Kappa Score: 0.7588 | LR: 0.000078 | Estimated time: 44.27
Train loss on 50 batch: 0.300577
Train loss on 100 batch: 0.385181
Train loss on 150 batch: 0.307304
best-train-loss: 0.328332
best-valid-loss: 0.350247
best-kappa: 0.7611
: Epoch: 49 | Training Loss: 0.328332 | Val. Loss: 0.350247 | Val. Kappa Score: 0.7611 | LR: 0.000078 | Estimated time: 44.15
Train loss on 50 batch: 0.285418
Train loss on 100 batch: 0.344842
Train loss on 150 batch: 0.344848
best-train-loss: 0.329185
best-valid-loss: 0.344171
best-kappa: 0.7632
: Epoch: 50 | Training Loss: 0.329185 | Val. Loss: 0.344171 | Val. Kappa Score: 0.7632 | LR: 0.000078 | Estimated time: 44.29
Train loss on 50 batch: 0.356031
Train loss on 100 batch: 0.363059
Train loss on 150 batch: 0.324808
: Epoch: 51 | Training Loss: 0.334004 | Val. Loss: 0.356562 | Val. Kappa Score: 0.7652 | LR: 0.000078 | Estimated time: 44.35
Train loss on 50 batch: 0.347905
Train loss on 100 batch: 0.326321
Train loss on 150 batch: 0.304356
: Epoch: 52 | Training Loss: 0.326213 | Val. Loss: 0.359914 | Val. Kappa Score: 0.7670 | LR: 0.000078 | Estimated time: 44.14
Train loss on 50 batch: 0.385572
Train loss on 100 batch: 0.278490
Train loss on 150 batch: 0.300675
: Epoch: 53 | Training Loss: 0.330838 | Val. Loss: 0.354264 | Val. Kappa Score: 0.7688 | LR: 0.000039 | Estimated time: 44.27
Train loss on 50 batch: 0.336974
Train loss on 100 batch: 0.344175
Train loss on 150 batch: 0.308785
: Epoch: 54 | Training Loss: 0.350900 | Val. Loss: 0.345678 | Val. Kappa Score: 0.7705 | LR: 0.000039 | Estimated time: 44.23
Train loss on 50 batch: 0.338276
Train loss on 100 batch: 0.316785
Train loss on 150 batch: 0.357220
: Epoch: 55 | Training Loss: 0.321406 | Val. Loss: 0.350604 | Val. Kappa Score: 0.7723 | LR: 0.000039 | Estimated time: 44.34
Train loss on 50 batch: 0.273564
Train loss on 100 batch: 0.291949
Train loss on 150 batch: 0.391370
best-train-loss: 0.322622
best-valid-loss: 0.343972
best-kappa: 0.7740
: Epoch: 56 | Training Loss: 0.322622 | Val. Loss: 0.343972 | Val. Kappa Score: 0.7740 | LR: 0.000039 | Estimated time: 44.23
Train loss on 50 batch: 0.295114
Train loss on 100 batch: 0.329943
Train loss on 150 batch: 0.284516
: Epoch: 57 | Training Loss: 0.307120 | Val. Loss: 0.362877 | Val. Kappa Score: 0.7757 | LR: 0.000039 | Estimated time: 44.37
Train loss on 50 batch: 0.345396
Train loss on 100 batch: 0.293051
Train loss on 150 batch: 0.297853
best-train-loss: 0.310318
best-valid-loss: 0.343432
best-kappa: 0.7773
: Epoch: 58 | Training Loss: 0.310318 | Val. Loss: 0.343432 | Val. Kappa Score: 0.7773 | LR: 0.000039 | Estimated time: 44.43
Train loss on 50 batch: 0.335804
Train loss on 100 batch: 0.337255
Train loss on 150 batch: 0.288417
: Epoch: 59 | Training Loss: 0.331170 | Val. Loss: 0.348269 | Val. Kappa Score: 0.7785 | LR: 0.000039 | Estimated time: 44.26
Train loss on 50 batch: 0.348802
Train loss on 100 batch: 0.315458
Train loss on 150 batch: 0.303083
: Epoch: 60 | Training Loss: 0.368541 | Val. Loss: 0.363195 | Val. Kappa Score: 0.7798 | LR: 0.000039 | Estimated time: 44.29
Train loss on 50 batch: 0.346749
Train loss on 100 batch: 0.324972
Train loss on 150 batch: 0.289184
: Epoch: 61 | Training Loss: 0.314548 | Val. Loss: 0.348130 | Val. Kappa Score: 0.7814 | LR: 0.000020 | Estimated time: 44.33
Train loss on 50 batch: 0.283489
Train loss on 100 batch: 0.277180
Train loss on 150 batch: 0.382108
: Epoch: 62 | Training Loss: 0.355035 | Val. Loss: 0.381073 | Val. Kappa Score: 0.7827 | LR: 0.000020 | Estimated time: 44.34
Train loss on 50 batch: 0.264396
Train loss on 100 batch: 0.293634
Train loss on 150 batch: 0.314440
: Epoch: 63 | Training Loss: 0.309278 | Val. Loss: 0.354185 | Val. Kappa Score: 0.7839 | LR: 0.000020 | Estimated time: 44.23
Train loss on 50 batch: 0.326133
Train loss on 100 batch: 0.311903
Train loss on 150 batch: 0.274305
: Epoch: 64 | Training Loss: 0.304286 | Val. Loss: 0.344941 | Val. Kappa Score: 0.7852 | LR: 0.000010 | Estimated time: 44.39
Train loss on 50 batch: 0.305830
Train loss on 100 batch: 0.310777
Train loss on 150 batch: 0.302359
best-train-loss: 0.297988
best-valid-loss: 0.342962
best-kappa: 0.7865
: Epoch: 65 | Training Loss: 0.297988 | Val. Loss: 0.342962 | Val. Kappa Score: 0.7865 | LR: 0.000010 | Estimated time: 44.36
Train loss on 50 batch: 0.308091
Train loss on 100 batch: 0.299740
Train loss on 150 batch: 0.315939
: Epoch: 66 | Training Loss: 0.337689 | Val. Loss: 0.398984 | Val. Kappa Score: 0.7874 | LR: 0.000010 | Estimated time: 44.27
Train loss on 50 batch: 0.260547
Train loss on 100 batch: 0.290655
Train loss on 150 batch: 0.338103
: Epoch: 67 | Training Loss: 0.297810 | Val. Loss: 0.343070 | Val. Kappa Score: 0.7886 | LR: 0.000010 | Estimated time: 44.23
Train loss on 50 batch: 0.309972
Train loss on 100 batch: 0.275939
Train loss on 150 batch: 0.292451
best-train-loss: 0.304485
best-valid-loss: 0.339430
best-kappa: 0.7897
: Epoch: 68 | Training Loss: 0.304485 | Val. Loss: 0.339430 | Val. Kappa Score: 0.7897 | LR: 0.000010 | Estimated time: 44.35
Train loss on 50 batch: 0.304713
Train loss on 100 batch: 0.294916
Train loss on 150 batch: 0.299367
best-train-loss: 0.302414
best-valid-loss: 0.338290
best-kappa: 0.7908
: Epoch: 69 | Training Loss: 0.302414 | Val. Loss: 0.338290 | Val. Kappa Score: 0.7908 | LR: 0.000010 | Estimated time: 44.21
Train loss on 50 batch: 0.282510
Train loss on 100 batch: 0.328124
Train loss on 150 batch: 0.298140
: Epoch: 70 | Training Loss: 0.294797 | Val. Loss: 0.342791 | Val. Kappa Score: 0.7919 | LR: 0.000010 | Estimated time: 44.40
Train loss on 50 batch: 0.325303
Train loss on 100 batch: 0.251953
Train loss on 150 batch: 0.352602
: Epoch: 71 | Training Loss: 0.292699 | Val. Loss: 0.345907 | Val. Kappa Score: 0.7930 | LR: 0.000010 | Estimated time: 44.33
Train loss on 50 batch: 0.261090
Train loss on 100 batch: 0.308349
Train loss on 150 batch: 0.315858
: Epoch: 72 | Training Loss: 0.302889 | Val. Loss: 0.346416 | Val. Kappa Score: 0.7941 | LR: 0.000005 | Estimated time: 44.25
Train loss on 50 batch: 0.284726
Train loss on 100 batch: 0.321680
Train loss on 150 batch: 0.303379
: Epoch: 73 | Training Loss: 0.332700 | Val. Loss: 0.352311 | Val. Kappa Score: 0.7949 | LR: 0.000005 | Estimated time: 44.39
Train loss on 50 batch: 0.327485
Train loss on 100 batch: 0.289481
Train loss on 150 batch: 0.276407
: Epoch: 74 | Training Loss: 0.303332 | Val. Loss: 0.341484 | Val. Kappa Score: 0.7958 | LR: 0.000005 | Estimated time: 44.40
Train loss on 50 batch: 0.326986
Train loss on 100 batch: 0.276684
Train loss on 150 batch: 0.271970
: Epoch: 75 | Training Loss: 0.300211 | Val. Loss: 0.341523 | Val. Kappa Score: 0.7967 | LR: 0.000002 | Estimated time: 44.16
Train loss on 50 batch: 0.263129
Train loss on 100 batch: 0.311982
Train loss on 150 batch: 0.304593
: Epoch: 76 | Training Loss: 0.293465 | Val. Loss: 0.344229 | Val. Kappa Score: 0.7976 | LR: 0.000002 | Estimated time: 44.39
Train loss on 50 batch: 0.318839
Train loss on 100 batch: 0.310318
Train loss on 150 batch: 0.325136
: Epoch: 77 | Training Loss: 0.326655 | Val. Loss: 0.348391 | Val. Kappa Score: 0.7985 | LR: 0.000002 | Estimated time: 44.42
time_estimated: 3414.35
n-epochs: 77
time_estimated: 3414.37
----------------------------------------

Experiment N: 90: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.05, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 05:19:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.05
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c150438>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 16.967710
Train loss on 100 batch: 1.631803
Train loss on 150 batch: 1.279820
best-train-loss: 5.332432
best-valid-loss: 22.119751
best-kappa: -0.2110
: Epoch: 1 | Training Loss: 5.332432 | Val. Loss: 22.119751 | Val. Kappa Score: -0.2110 | LR: 0.050000 | Estimated time: 44.29
Train loss on 50 batch: 1.284806
Train loss on 100 batch: 1.134023
Train loss on 150 batch: 0.954909
best-train-loss: 1.132609
best-valid-loss: 1.943504
best-kappa: 0.1286
: Epoch: 2 | Training Loss: 1.132609 | Val. Loss: 1.943504 | Val. Kappa Score: 0.1286 | LR: 0.050000 | Estimated time: 44.32
Train loss on 50 batch: 1.087833
Train loss on 100 batch: 1.108924
Train loss on 150 batch: 1.048595
: Epoch: 3 | Training Loss: 1.056727 | Val. Loss: 16.836162 | Val. Kappa Score: 0.2408 | LR: 0.050000 | Estimated time: 44.32
Train loss on 50 batch: 1.127538
Train loss on 100 batch: 0.920910
Train loss on 150 batch: 0.997880
: Epoch: 4 | Training Loss: 1.086429 | Val. Loss: 2.768309 | Val. Kappa Score: 0.3283 | LR: 0.050000 | Estimated time: 44.34
Train loss on 50 batch: 1.100423
Train loss on 100 batch: 1.106624
Train loss on 150 batch: 0.970507
: Epoch: 5 | Training Loss: 1.097470 | Val. Loss: 717085.109035 | Val. Kappa Score: 0.2701 | LR: 0.025000 | Estimated time: 44.29
Train loss on 50 batch: 1.427758
Train loss on 100 batch: 1.247220
Train loss on 150 batch: 1.089772
: Epoch: 6 | Training Loss: 1.206648 | Val. Loss: 2.190180 | Val. Kappa Score: 0.2953 | LR: 0.025000 | Estimated time: 44.29
Train loss on 50 batch: 1.041684
Train loss on 100 batch: 1.023447
Train loss on 150 batch: 1.001508
best-train-loss: 1.010975
best-valid-loss: 1.827728
best-kappa: 0.3091
: Epoch: 7 | Training Loss: 1.010975 | Val. Loss: 1.827728 | Val. Kappa Score: 0.3091 | LR: 0.025000 | Estimated time: 44.25
Train loss on 50 batch: 1.010659
Train loss on 100 batch: 1.015084
Train loss on 150 batch: 0.906111
best-train-loss: 0.952754
best-valid-loss: 1.026969
best-kappa: 0.3465
: Epoch: 8 | Training Loss: 0.952754 | Val. Loss: 1.026969 | Val. Kappa Score: 0.3465 | LR: 0.025000 | Estimated time: 44.29
Train loss on 50 batch: 0.913887
Train loss on 100 batch: 0.953408
Train loss on 150 batch: 0.939531
: Epoch: 9 | Training Loss: 0.931835 | Val. Loss: 2.313945 | Val. Kappa Score: 0.3441 | LR: 0.025000 | Estimated time: 44.32
Train loss on 50 batch: 0.873114
Train loss on 100 batch: 0.951336
Train loss on 150 batch: 0.890625
: Epoch: 10 | Training Loss: 0.963023 | Val. Loss: 1.038182 | Val. Kappa Score: 0.3562 | LR: 0.025000 | Estimated time: 44.27
Train loss on 50 batch: 0.969894
Train loss on 100 batch: 0.917608
Train loss on 150 batch: 0.908590
: Epoch: 11 | Training Loss: 0.906612 | Val. Loss: 1.133717 | Val. Kappa Score: 0.3827 | LR: 0.012500 | Estimated time: 44.24
Train loss on 50 batch: 0.930539
Train loss on 100 batch: 0.808521
Train loss on 150 batch: 0.837677
best-train-loss: 0.848986
best-valid-loss: 0.873876
best-kappa: 0.4062
: Epoch: 12 | Training Loss: 0.848986 | Val. Loss: 0.873876 | Val. Kappa Score: 0.4062 | LR: 0.012500 | Estimated time: 44.29
Train loss on 50 batch: 0.807543
Train loss on 100 batch: 0.825613
Train loss on 150 batch: 0.831218
: Epoch: 13 | Training Loss: 0.813362 | Val. Loss: 0.947977 | Val. Kappa Score: 0.4258 | LR: 0.012500 | Estimated time: 44.25
Train loss on 50 batch: 0.757592
Train loss on 100 batch: 0.747762
Train loss on 150 batch: 0.853039
: Epoch: 14 | Training Loss: 0.793113 | Val. Loss: 1.126410 | Val. Kappa Score: 0.4415 | LR: 0.012500 | Estimated time: 44.46
Train loss on 50 batch: 0.815393
Train loss on 100 batch: 0.725115
Train loss on 150 batch: 0.732078
best-train-loss: 0.776308
best-valid-loss: 0.783589
best-kappa: 0.4567
: Epoch: 15 | Training Loss: 0.776308 | Val. Loss: 0.783589 | Val. Kappa Score: 0.4567 | LR: 0.012500 | Estimated time: 44.26
Train loss on 50 batch: 0.734829
Train loss on 100 batch: 0.790261
Train loss on 150 batch: 0.714308
: Epoch: 16 | Training Loss: 0.757810 | Val. Loss: 1.554844 | Val. Kappa Score: 0.4637 | LR: 0.012500 | Estimated time: 44.25
Train loss on 50 batch: 0.885684
Train loss on 100 batch: 0.760475
Train loss on 150 batch: 0.693926
: Epoch: 17 | Training Loss: 0.779884 | Val. Loss: 3.393140 | Val. Kappa Score: 0.4588 | LR: 0.012500 | Estimated time: 44.24
Train loss on 50 batch: 0.799889
Train loss on 100 batch: 0.673950
Train loss on 150 batch: 0.758002
: Epoch: 18 | Training Loss: 0.738766 | Val. Loss: 1.360004 | Val. Kappa Score: 0.4661 | LR: 0.006250 | Estimated time: 44.37
Train loss on 50 batch: 0.641091
Train loss on 100 batch: 0.706061
Train loss on 150 batch: 0.702861
: Epoch: 19 | Training Loss: 0.697304 | Val. Loss: 0.874837 | Val. Kappa Score: 0.4783 | LR: 0.006250 | Estimated time: 44.30
Train loss on 50 batch: 0.703726
Train loss on 100 batch: 0.676515
Train loss on 150 batch: 0.570537
best-train-loss: 0.656465
best-valid-loss: 0.613070
best-kappa: 0.4932
: Epoch: 20 | Training Loss: 0.656465 | Val. Loss: 0.613070 | Val. Kappa Score: 0.4932 | LR: 0.006250 | Estimated time: 44.39
Train loss on 50 batch: 0.626902
Train loss on 100 batch: 0.630294
Train loss on 150 batch: 0.745145
: Epoch: 21 | Training Loss: 0.675560 | Val. Loss: 1.166362 | Val. Kappa Score: 0.4956 | LR: 0.006250 | Estimated time: 44.23
Train loss on 50 batch: 0.669962
Train loss on 100 batch: 0.626129
Train loss on 150 batch: 0.702114
: Epoch: 22 | Training Loss: 0.643056 | Val. Loss: 1.477741 | Val. Kappa Score: 0.5006 | LR: 0.006250 | Estimated time: 44.38
Train loss on 50 batch: 0.643080
Train loss on 100 batch: 0.670957
Train loss on 150 batch: 0.600186
: Epoch: 23 | Training Loss: 0.627960 | Val. Loss: 0.670783 | Val. Kappa Score: 0.5111 | LR: 0.003125 | Estimated time: 44.36
Train loss on 50 batch: 0.649108
Train loss on 100 batch: 0.568791
Train loss on 150 batch: 0.569774
: Epoch: 24 | Training Loss: 0.665685 | Val. Loss: 1.144314 | Val. Kappa Score: 0.5156 | LR: 0.003125 | Estimated time: 44.23
Train loss on 50 batch: 0.605456
Train loss on 100 batch: 0.530540
Train loss on 150 batch: 0.666730
: Epoch: 25 | Training Loss: 0.587906 | Val. Loss: 0.624186 | Val. Kappa Score: 0.5265 | LR: 0.003125 | Estimated time: 44.18
Train loss on 50 batch: 0.619065
Train loss on 100 batch: 0.521189
Train loss on 150 batch: 0.625655
best-train-loss: 0.609701
best-valid-loss: 0.564536
best-kappa: 0.5358
: Epoch: 26 | Training Loss: 0.609701 | Val. Loss: 0.564536 | Val. Kappa Score: 0.5358 | LR: 0.003125 | Estimated time: 44.25
Train loss on 50 batch: 0.628145
Train loss on 100 batch: 0.628300
Train loss on 150 batch: 0.564023
: Epoch: 27 | Training Loss: 0.592412 | Val. Loss: 0.614258 | Val. Kappa Score: 0.5446 | LR: 0.003125 | Estimated time: 44.32
Train loss on 50 batch: 0.613261
Train loss on 100 batch: 0.618203
Train loss on 150 batch: 0.558466
best-train-loss: 0.573496
best-valid-loss: 0.528111
best-kappa: 0.5541
: Epoch: 28 | Training Loss: 0.573496 | Val. Loss: 0.528111 | Val. Kappa Score: 0.5541 | LR: 0.003125 | Estimated time: 44.27
Train loss on 50 batch: 0.538167
Train loss on 100 batch: 0.547266
Train loss on 150 batch: 0.564620
best-train-loss: 0.540611
best-valid-loss: 0.527321
best-kappa: 0.5628
: Epoch: 29 | Training Loss: 0.540611 | Val. Loss: 0.527321 | Val. Kappa Score: 0.5628 | LR: 0.003125 | Estimated time: 44.27
Train loss on 50 batch: 0.521451
Train loss on 100 batch: 0.557362
Train loss on 150 batch: 0.593691
: Epoch: 30 | Training Loss: 0.547939 | Val. Loss: 0.545333 | Val. Kappa Score: 0.5702 | LR: 0.003125 | Estimated time: 44.27
Train loss on 50 batch: 0.482920
Train loss on 100 batch: 0.519699
Train loss on 150 batch: 0.553745
: Epoch: 31 | Training Loss: 0.537559 | Val. Loss: 0.625217 | Val. Kappa Score: 0.5763 | LR: 0.003125 | Estimated time: 44.33
Train loss on 50 batch: 0.489913
Train loss on 100 batch: 0.589145
Train loss on 150 batch: 0.524191
best-train-loss: 0.532536
best-valid-loss: 0.505990
best-kappa: 0.5839
: Epoch: 32 | Training Loss: 0.532536 | Val. Loss: 0.505990 | Val. Kappa Score: 0.5839 | LR: 0.003125 | Estimated time: 44.28
Train loss on 50 batch: 0.547846
Train loss on 100 batch: 0.579679
Train loss on 150 batch: 0.501022
: Epoch: 33 | Training Loss: 0.534011 | Val. Loss: 0.521690 | Val. Kappa Score: 0.5909 | LR: 0.003125 | Estimated time: 44.21
Train loss on 50 batch: 0.443444
Train loss on 100 batch: 0.571526
Train loss on 150 batch: 0.503135
: Epoch: 34 | Training Loss: 0.503176 | Val. Loss: 0.804933 | Val. Kappa Score: 0.5958 | LR: 0.003125 | Estimated time: 44.33
Train loss on 50 batch: 0.477912
Train loss on 100 batch: 0.493222
Train loss on 150 batch: 0.542465
best-train-loss: 0.522221
best-valid-loss: 0.499710
best-kappa: 0.6018
: Epoch: 35 | Training Loss: 0.522221 | Val. Loss: 0.499710 | Val. Kappa Score: 0.6018 | LR: 0.003125 | Estimated time: 44.34
Train loss on 50 batch: 0.481004
Train loss on 100 batch: 0.549382
Train loss on 150 batch: 0.496281
: Epoch: 36 | Training Loss: 0.537867 | Val. Loss: 0.541869 | Val. Kappa Score: 0.6072 | LR: 0.003125 | Estimated time: 44.39
Train loss on 50 batch: 0.508939
Train loss on 100 batch: 0.484970
Train loss on 150 batch: 0.499837
: Epoch: 37 | Training Loss: 0.507356 | Val. Loss: 0.509973 | Val. Kappa Score: 0.6124 | LR: 0.003125 | Estimated time: 44.36
Train loss on 50 batch: 0.433520
Train loss on 100 batch: 0.475298
Train loss on 150 batch: 0.477273
: Epoch: 38 | Training Loss: 0.551231 | Val. Loss: 0.653660 | Val. Kappa Score: 0.6160 | LR: 0.001563 | Estimated time: 44.45
Train loss on 50 batch: 0.552062
Train loss on 100 batch: 0.468137
Train loss on 150 batch: 0.466095
best-train-loss: 0.494136
best-valid-loss: 0.440321
best-kappa: 0.6216
: Epoch: 39 | Training Loss: 0.494136 | Val. Loss: 0.440321 | Val. Kappa Score: 0.6216 | LR: 0.001563 | Estimated time: 44.35
Train loss on 50 batch: 0.442312
Train loss on 100 batch: 0.449110
Train loss on 150 batch: 0.466145
: Epoch: 40 | Training Loss: 0.462199 | Val. Loss: 0.454709 | Val. Kappa Score: 0.6263 | LR: 0.001563 | Estimated time: 44.21
Train loss on 50 batch: 0.421693
Train loss on 100 batch: 0.486473
Train loss on 150 batch: 0.441289
: Epoch: 41 | Training Loss: 0.450429 | Val. Loss: 0.494009 | Val. Kappa Score: 0.6313 | LR: 0.001563 | Estimated time: 44.26
Train loss on 50 batch: 0.489763
Train loss on 100 batch: 0.408123
Train loss on 150 batch: 0.448227
: Epoch: 42 | Training Loss: 0.450455 | Val. Loss: 0.652677 | Val. Kappa Score: 0.6338 | LR: 0.000781 | Estimated time: 44.34
Train loss on 50 batch: 0.410678
Train loss on 100 batch: 0.474978
Train loss on 150 batch: 0.410351
best-train-loss: 0.436664
best-valid-loss: 0.413208
best-kappa: 0.6388
: Epoch: 43 | Training Loss: 0.436664 | Val. Loss: 0.413208 | Val. Kappa Score: 0.6388 | LR: 0.000781 | Estimated time: 44.41
Train loss on 50 batch: 0.418067
Train loss on 100 batch: 0.427668
Train loss on 150 batch: 0.423223
: Epoch: 44 | Training Loss: 0.413151 | Val. Loss: 0.422687 | Val. Kappa Score: 0.6435 | LR: 0.000781 | Estimated time: 44.27
Train loss on 50 batch: 0.380855
Train loss on 100 batch: 0.412017
Train loss on 150 batch: 0.483542
best-train-loss: 0.422982
best-valid-loss: 0.398073
best-kappa: 0.6481
: Epoch: 45 | Training Loss: 0.422982 | Val. Loss: 0.398073 | Val. Kappa Score: 0.6481 | LR: 0.000781 | Estimated time: 44.25
Train loss on 50 batch: 0.444978
Train loss on 100 batch: 0.420997
Train loss on 150 batch: 0.421702
: Epoch: 46 | Training Loss: 0.431919 | Val. Loss: 0.406811 | Val. Kappa Score: 0.6524 | LR: 0.000781 | Estimated time: 44.37
Train loss on 50 batch: 0.415210
Train loss on 100 batch: 0.369098
Train loss on 150 batch: 0.453503
: Epoch: 47 | Training Loss: 0.424164 | Val. Loss: 0.421873 | Val. Kappa Score: 0.6564 | LR: 0.000781 | Estimated time: 44.30
Train loss on 50 batch: 0.410360
Train loss on 100 batch: 0.432161
Train loss on 150 batch: 0.405469
best-train-loss: 0.413085
best-valid-loss: 0.382443
best-kappa: 0.6602
: Epoch: 48 | Training Loss: 0.413085 | Val. Loss: 0.382443 | Val. Kappa Score: 0.6602 | LR: 0.000781 | Estimated time: 44.32
Train loss on 50 batch: 0.360145
Train loss on 100 batch: 0.466500
Train loss on 150 batch: 0.411494
: Epoch: 49 | Training Loss: 0.435985 | Val. Loss: 0.401955 | Val. Kappa Score: 0.6641 | LR: 0.000781 | Estimated time: 44.31
Train loss on 50 batch: 0.386340
Train loss on 100 batch: 0.435139
Train loss on 150 batch: 0.447737
: Epoch: 50 | Training Loss: 0.409875 | Val. Loss: 0.402230 | Val. Kappa Score: 0.6679 | LR: 0.000781 | Estimated time: 44.31
Train loss on 50 batch: 0.422682
Train loss on 100 batch: 0.444957
Train loss on 150 batch: 0.453415
: Epoch: 51 | Training Loss: 0.431167 | Val. Loss: 0.533102 | Val. Kappa Score: 0.6705 | LR: 0.000391 | Estimated time: 44.39
Train loss on 50 batch: 0.414407
Train loss on 100 batch: 0.401150
Train loss on 150 batch: 0.364060
: Epoch: 52 | Training Loss: 0.394997 | Val. Loss: 0.390242 | Val. Kappa Score: 0.6741 | LR: 0.000391 | Estimated time: 44.32
Train loss on 50 batch: 0.459362
Train loss on 100 batch: 0.342982
Train loss on 150 batch: 0.360272
: Epoch: 53 | Training Loss: 0.395354 | Val. Loss: 0.384838 | Val. Kappa Score: 0.6776 | LR: 0.000391 | Estimated time: 44.35
Train loss on 50 batch: 0.362229
Train loss on 100 batch: 0.413612
Train loss on 150 batch: 0.363371
: Epoch: 54 | Training Loss: 0.417530 | Val. Loss: 0.401099 | Val. Kappa Score: 0.6808 | LR: 0.000195 | Estimated time: 44.26
Train loss on 50 batch: 0.397863
Train loss on 100 batch: 0.367601
Train loss on 150 batch: 0.385531
best-train-loss: 0.373029
best-valid-loss: 0.373743
best-kappa: 0.6841
: Epoch: 55 | Training Loss: 0.373029 | Val. Loss: 0.373743 | Val. Kappa Score: 0.6841 | LR: 0.000195 | Estimated time: 44.21
Train loss on 50 batch: 0.331397
Train loss on 100 batch: 0.366979
Train loss on 150 batch: 0.414287
best-train-loss: 0.389760
best-valid-loss: 0.365915
best-kappa: 0.6870
: Epoch: 56 | Training Loss: 0.389760 | Val. Loss: 0.365915 | Val. Kappa Score: 0.6870 | LR: 0.000195 | Estimated time: 44.15
Train loss on 50 batch: 0.369181
Train loss on 100 batch: 0.422784
Train loss on 150 batch: 0.334057
best-train-loss: 0.371316
best-valid-loss: 0.364007
best-kappa: 0.6900
: Epoch: 57 | Training Loss: 0.371316 | Val. Loss: 0.364007 | Val. Kappa Score: 0.6900 | LR: 0.000195 | Estimated time: 44.29
Train loss on 50 batch: 0.394481
Train loss on 100 batch: 0.328460
Train loss on 150 batch: 0.347032
: Epoch: 58 | Training Loss: 0.363727 | Val. Loss: 0.372947 | Val. Kappa Score: 0.6927 | LR: 0.000195 | Estimated time: 44.37
Train loss on 50 batch: 0.355698
Train loss on 100 batch: 0.366760
Train loss on 150 batch: 0.336734
: Epoch: 59 | Training Loss: 0.357066 | Val. Loss: 0.410908 | Val. Kappa Score: 0.6953 | LR: 0.000195 | Estimated time: 44.21
Train loss on 50 batch: 0.381842
Train loss on 100 batch: 0.359517
Train loss on 150 batch: 0.360366
: Epoch: 60 | Training Loss: 0.423791 | Val. Loss: 0.376092 | Val. Kappa Score: 0.6980 | LR: 0.000098 | Estimated time: 44.38
Train loss on 50 batch: 0.395693
Train loss on 100 batch: 0.372110
Train loss on 150 batch: 0.346620
best-train-loss: 0.367618
best-valid-loss: 0.363164
best-kappa: 0.7007
: Epoch: 61 | Training Loss: 0.367618 | Val. Loss: 0.363164 | Val. Kappa Score: 0.7007 | LR: 0.000098 | Estimated time: 44.28
Train loss on 50 batch: 0.316912
Train loss on 100 batch: 0.329042
Train loss on 150 batch: 0.429656
: Epoch: 62 | Training Loss: 0.414514 | Val. Loss: 0.443525 | Val. Kappa Score: 0.7027 | LR: 0.000098 | Estimated time: 44.31
Train loss on 50 batch: 0.297959
Train loss on 100 batch: 0.346833
Train loss on 150 batch: 0.351949
: Epoch: 63 | Training Loss: 0.360156 | Val. Loss: 0.374733 | Val. Kappa Score: 0.7052 | LR: 0.000098 | Estimated time: 44.22
Train loss on 50 batch: 0.368523
Train loss on 100 batch: 0.338322
Train loss on 150 batch: 0.307190
best-train-loss: 0.336874
best-valid-loss: 0.358403
best-kappa: 0.7076
: Epoch: 64 | Training Loss: 0.336874 | Val. Loss: 0.358403 | Val. Kappa Score: 0.7076 | LR: 0.000098 | Estimated time: 44.24
Train loss on 50 batch: 0.308884
Train loss on 100 batch: 0.376271
Train loss on 150 batch: 0.349741
: Epoch: 65 | Training Loss: 0.344985 | Val. Loss: 0.397650 | Val. Kappa Score: 0.7097 | LR: 0.000098 | Estimated time: 44.25
Train loss on 50 batch: 0.317909
Train loss on 100 batch: 0.350654
Train loss on 150 batch: 0.388548
: Epoch: 66 | Training Loss: 0.407700 | Val. Loss: 0.428737 | Val. Kappa Score: 0.7116 | LR: 0.000098 | Estimated time: 44.35
Train loss on 50 batch: 0.324412
Train loss on 100 batch: 0.322201
Train loss on 150 batch: 0.352213
: Epoch: 67 | Training Loss: 0.340573 | Val. Loss: 0.387134 | Val. Kappa Score: 0.7137 | LR: 0.000049 | Estimated time: 44.37
Train loss on 50 batch: 0.348933
Train loss on 100 batch: 0.300005
Train loss on 150 batch: 0.345476
: Epoch: 68 | Training Loss: 0.343078 | Val. Loss: 0.360517 | Val. Kappa Score: 0.7158 | LR: 0.000049 | Estimated time: 44.36
Train loss on 50 batch: 0.340246
Train loss on 100 batch: 0.349252
Train loss on 150 batch: 0.314285
best-train-loss: 0.343774
best-valid-loss: 0.352164
best-kappa: 0.7179
: Epoch: 69 | Training Loss: 0.343774 | Val. Loss: 0.352164 | Val. Kappa Score: 0.7179 | LR: 0.000049 | Estimated time: 44.34
Train loss on 50 batch: 0.304367
Train loss on 100 batch: 0.369230
Train loss on 150 batch: 0.307959
: Epoch: 70 | Training Loss: 0.321401 | Val. Loss: 0.355232 | Val. Kappa Score: 0.7199 | LR: 0.000049 | Estimated time: 44.28
Train loss on 50 batch: 0.319948
Train loss on 100 batch: 0.345907
Train loss on 150 batch: 0.382774
: Epoch: 71 | Training Loss: 0.332781 | Val. Loss: 0.359912 | Val. Kappa Score: 0.7220 | LR: 0.000049 | Estimated time: 44.30
Train loss on 50 batch: 0.320612
Train loss on 100 batch: 0.345699
Train loss on 150 batch: 0.365534
: Epoch: 72 | Training Loss: 0.352212 | Val. Loss: 0.358884 | Val. Kappa Score: 0.7239 | LR: 0.000024 | Estimated time: 44.31
Train loss on 50 batch: 0.302572
Train loss on 100 batch: 0.356641
Train loss on 150 batch: 0.342013
: Epoch: 73 | Training Loss: 0.377924 | Val. Loss: 0.362774 | Val. Kappa Score: 0.7258 | LR: 0.000024 | Estimated time: 44.46
Train loss on 50 batch: 0.323691
Train loss on 100 batch: 0.327773
Train loss on 150 batch: 0.305108
best-train-loss: 0.325242
best-valid-loss: 0.349566
best-kappa: 0.7275
: Epoch: 74 | Training Loss: 0.325242 | Val. Loss: 0.349566 | Val. Kappa Score: 0.7275 | LR: 0.000024 | Estimated time: 44.23
Train loss on 50 batch: 0.333636
Train loss on 100 batch: 0.307783
Train loss on 150 batch: 0.313605
: Epoch: 75 | Training Loss: 0.328796 | Val. Loss: 0.355148 | Val. Kappa Score: 0.7293 | LR: 0.000024 | Estimated time: 44.29
Train loss on 50 batch: 0.304198
Train loss on 100 batch: 0.329335
Train loss on 150 batch: 0.326342
: Epoch: 76 | Training Loss: 0.321121 | Val. Loss: 0.357560 | Val. Kappa Score: 0.7309 | LR: 0.000024 | Estimated time: 44.41
Train loss on 50 batch: 0.333556
Train loss on 100 batch: 0.324867
Train loss on 150 batch: 0.352324
: Epoch: 77 | Training Loss: 0.326402 | Val. Loss: 0.365209 | Val. Kappa Score: 0.7326 | LR: 0.000012 | Estimated time: 44.35
Train loss on 50 batch: 0.323789
Train loss on 100 batch: 0.293797
Train loss on 150 batch: 0.305796
: Epoch: 78 | Training Loss: 0.319112 | Val. Loss: 0.351871 | Val. Kappa Score: 0.7343 | LR: 0.000012 | Estimated time: 44.50
Train loss on 50 batch: 0.323228
Train loss on 100 batch: 0.324578
Train loss on 150 batch: 0.336071
: Epoch: 79 | Training Loss: 0.326278 | Val. Loss: 0.366876 | Val. Kappa Score: 0.7359 | LR: 0.000012 | Estimated time: 44.24
Train loss on 50 batch: 0.343321
Train loss on 100 batch: 0.285008
Train loss on 150 batch: 0.330951
: Epoch: 80 | Training Loss: 0.333884 | Val. Loss: 0.358824 | Val. Kappa Score: 0.7374 | LR: 0.000006 | Estimated time: 44.41
Train loss on 50 batch: 0.280209
Train loss on 100 batch: 0.325235
Train loss on 150 batch: 0.358011
: Epoch: 81 | Training Loss: 0.320724 | Val. Loss: 0.362512 | Val. Kappa Score: 0.7389 | LR: 0.000006 | Estimated time: 44.24
Train loss on 50 batch: 0.324180
Train loss on 100 batch: 0.338416
Train loss on 150 batch: 0.279541
: Epoch: 82 | Training Loss: 0.323375 | Val. Loss: 0.357404 | Val. Kappa Score: 0.7405 | LR: 0.000006 | Estimated time: 44.34
time_estimated: 3638.42
n-epochs: 82
time_estimated: 3638.44
----------------------------------------

Experiment N: 91: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.08.15 08:32:51
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102518>
early-stopping-patience: 8
parameters-amount: 42502209
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.480073
Train loss on 100 batch: 0.750193
Train loss on 150 batch: 0.661642
best-train-loss: 0.869120
best-valid-loss: 0.758267
best-kappa: 0.6933
: Epoch: 1 | Training Loss: 0.869120 | Val. Loss: 0.758267 | Val. Kappa Score: 0.6933 | LR: 0.001000 | Estimated time: 31.13
Train loss on 50 batch: 0.529446
Train loss on 100 batch: 0.577962
Train loss on 150 batch: 0.483242
: Epoch: 2 | Training Loss: 0.566006 | Val. Loss: 4.426953 | Val. Kappa Score: 0.6430 | LR: 0.001000 | Estimated time: 30.68
Train loss on 50 batch: 0.530561
Train loss on 100 batch: 0.609029
Train loss on 150 batch: 0.519780
best-train-loss: 0.556622
best-valid-loss: 0.528653
best-kappa: 0.7052
: Epoch: 3 | Training Loss: 0.556622 | Val. Loss: 0.528653 | Val. Kappa Score: 0.7052 | LR: 0.001000 | Estimated time: 30.64
Train loss on 50 batch: 0.552046
Train loss on 100 batch: 0.484402
Train loss on 150 batch: 0.506887
best-train-loss: 0.559331
best-valid-loss: 0.413512
best-kappa: 0.7401
: Epoch: 4 | Training Loss: 0.559331 | Val. Loss: 0.413512 | Val. Kappa Score: 0.7401 | LR: 0.001000 | Estimated time: 30.70
Train loss on 50 batch: 0.525260
Train loss on 100 batch: 0.542727
Train loss on 150 batch: 0.464748
: Epoch: 5 | Training Loss: 0.500430 | Val. Loss: 0.431464 | Val. Kappa Score: 0.7633 | LR: 0.001000 | Estimated time: 30.71
Train loss on 50 batch: 0.531476
Train loss on 100 batch: 0.495081
Train loss on 150 batch: 0.455725
: Epoch: 6 | Training Loss: 0.479571 | Val. Loss: 0.545413 | Val. Kappa Score: 0.7722 | LR: 0.001000 | Estimated time: 30.86
Train loss on 50 batch: 0.537288
Train loss on 100 batch: 0.437734
Train loss on 150 batch: 0.423667
: Epoch: 7 | Training Loss: 0.476400 | Val. Loss: 0.438478 | Val. Kappa Score: 0.7808 | LR: 0.000500 | Estimated time: 30.67
Train loss on 50 batch: 0.392231
Train loss on 100 batch: 0.421002
Train loss on 150 batch: 0.345345
best-train-loss: 0.377416
best-valid-loss: 0.375936
best-kappa: 0.7891
: Epoch: 8 | Training Loss: 0.377416 | Val. Loss: 0.375936 | Val. Kappa Score: 0.7891 | LR: 0.000500 | Estimated time: 30.61
Train loss on 50 batch: 0.367517
Train loss on 100 batch: 0.418582
Train loss on 150 batch: 0.381737
: Epoch: 9 | Training Loss: 0.377711 | Val. Loss: 0.521987 | Val. Kappa Score: 0.7957 | LR: 0.000500 | Estimated time: 30.67
Train loss on 50 batch: 0.301089
Train loss on 100 batch: 0.365785
Train loss on 150 batch: 0.335982
: Epoch: 10 | Training Loss: 0.373899 | Val. Loss: 0.496097 | Val. Kappa Score: 0.7918 | LR: 0.000500 | Estimated time: 30.85
Train loss on 50 batch: 0.332335
Train loss on 100 batch: 0.363241
Train loss on 150 batch: 0.362035
: Epoch: 11 | Training Loss: 0.374255 | Val. Loss: 0.427147 | Val. Kappa Score: 0.7956 | LR: 0.000250 | Estimated time: 30.75
Train loss on 50 batch: 0.319111
Train loss on 100 batch: 0.308815
Train loss on 150 batch: 0.340966
: Epoch: 12 | Training Loss: 0.327097 | Val. Loss: 0.393592 | Val. Kappa Score: 0.8007 | LR: 0.000250 | Estimated time: 30.78
Train loss on 50 batch: 0.281701
Train loss on 100 batch: 0.346016
Train loss on 150 batch: 0.318277
best-train-loss: 0.301261
best-valid-loss: 0.343193
best-kappa: 0.8066
: Epoch: 13 | Training Loss: 0.301261 | Val. Loss: 0.343193 | Val. Kappa Score: 0.8066 | LR: 0.000250 | Estimated time: 30.77
Train loss on 50 batch: 0.272641
Train loss on 100 batch: 0.275187
Train loss on 150 batch: 0.342795
best-train-loss: 0.312482
best-valid-loss: 0.321965
best-kappa: 0.8120
: Epoch: 14 | Training Loss: 0.312482 | Val. Loss: 0.321965 | Val. Kappa Score: 0.8120 | LR: 0.000250 | Estimated time: 31.20
Train loss on 50 batch: 0.381079
Train loss on 100 batch: 0.291948
Train loss on 150 batch: 0.279064
: Epoch: 15 | Training Loss: 0.304427 | Val. Loss: 0.347719 | Val. Kappa Score: 0.8162 | LR: 0.000250 | Estimated time: 30.90
Train loss on 50 batch: 0.304840
Train loss on 100 batch: 0.273067
Train loss on 150 batch: 0.296088
: Epoch: 16 | Training Loss: 0.292762 | Val. Loss: 0.348095 | Val. Kappa Score: 0.8189 | LR: 0.000250 | Estimated time: 30.77
Train loss on 50 batch: 0.320649
Train loss on 100 batch: 0.281103
Train loss on 150 batch: 0.251515
: Epoch: 17 | Training Loss: 0.295082 | Val. Loss: 0.334149 | Val. Kappa Score: 0.8218 | LR: 0.000125 | Estimated time: 30.67
Train loss on 50 batch: 0.300396
Train loss on 100 batch: 0.239619
Train loss on 150 batch: 0.245437
best-train-loss: 0.263100
best-valid-loss: 0.305974
best-kappa: 0.8253
: Epoch: 18 | Training Loss: 0.263100 | Val. Loss: 0.305974 | Val. Kappa Score: 0.8253 | LR: 0.000125 | Estimated time: 30.91
Train loss on 50 batch: 0.213486
Train loss on 100 batch: 0.272363
Train loss on 150 batch: 0.285333
best-train-loss: 0.282881
best-valid-loss: 0.299846
best-kappa: 0.8282
: Epoch: 19 | Training Loss: 0.282881 | Val. Loss: 0.299846 | Val. Kappa Score: 0.8282 | LR: 0.000125 | Estimated time: 30.77
Train loss on 50 batch: 0.249572
Train loss on 100 batch: 0.279401
Train loss on 150 batch: 0.244540
: Epoch: 20 | Training Loss: 0.265750 | Val. Loss: 0.301943 | Val. Kappa Score: 0.8310 | LR: 0.000125 | Estimated time: 30.70
Train loss on 50 batch: 0.266126
Train loss on 100 batch: 0.252877
Train loss on 150 batch: 0.277970
: Epoch: 21 | Training Loss: 0.270574 | Val. Loss: 0.325423 | Val. Kappa Score: 0.8331 | LR: 0.000125 | Estimated time: 30.75
Train loss on 50 batch: 0.252758
Train loss on 100 batch: 0.234681
Train loss on 150 batch: 0.274683
: Epoch: 22 | Training Loss: 0.264013 | Val. Loss: 0.302162 | Val. Kappa Score: 0.8355 | LR: 0.000063 | Estimated time: 30.63
Train loss on 50 batch: 0.233022
Train loss on 100 batch: 0.232309
Train loss on 150 batch: 0.234893
: Epoch: 23 | Training Loss: 0.229502 | Val. Loss: 0.322675 | Val. Kappa Score: 0.8374 | LR: 0.000063 | Estimated time: 30.86
Train loss on 50 batch: 0.237681
Train loss on 100 batch: 0.238693
Train loss on 150 batch: 0.245475
: Epoch: 24 | Training Loss: 0.271325 | Val. Loss: 0.301444 | Val. Kappa Score: 0.8392 | LR: 0.000063 | Estimated time: 31.01
Train loss on 50 batch: 0.233792
Train loss on 100 batch: 0.220151
Train loss on 150 batch: 0.232138
best-train-loss: 0.239812
best-valid-loss: 0.295761
best-kappa: 0.8410
: Epoch: 25 | Training Loss: 0.239812 | Val. Loss: 0.295761 | Val. Kappa Score: 0.8410 | LR: 0.000063 | Estimated time: 30.69
Train loss on 50 batch: 0.246802
Train loss on 100 batch: 0.194346
Train loss on 150 batch: 0.262391
: Epoch: 26 | Training Loss: 0.241481 | Val. Loss: 0.297269 | Val. Kappa Score: 0.8427 | LR: 0.000063 | Estimated time: 30.73
Train loss on 50 batch: 0.235951
Train loss on 100 batch: 0.252459
Train loss on 150 batch: 0.227628
: Epoch: 27 | Training Loss: 0.229898 | Val. Loss: 0.301707 | Val. Kappa Score: 0.8441 | LR: 0.000063 | Estimated time: 30.85
Train loss on 50 batch: 0.248122
Train loss on 100 batch: 0.231377
Train loss on 150 batch: 0.216295
: Epoch: 28 | Training Loss: 0.230660 | Val. Loss: 0.301620 | Val. Kappa Score: 0.8456 | LR: 0.000031 | Estimated time: 30.69
Train loss on 50 batch: 0.185936
Train loss on 100 batch: 0.235951
Train loss on 150 batch: 0.218411
best-train-loss: 0.214694
best-valid-loss: 0.294647
best-kappa: 0.8470
: Epoch: 29 | Training Loss: 0.214694 | Val. Loss: 0.294647 | Val. Kappa Score: 0.8470 | LR: 0.000031 | Estimated time: 30.84
Train loss on 50 batch: 0.207105
Train loss on 100 batch: 0.214205
Train loss on 150 batch: 0.221934
: Epoch: 30 | Training Loss: 0.216535 | Val. Loss: 0.296161 | Val. Kappa Score: 0.8484 | LR: 0.000031 | Estimated time: 30.76
Train loss on 50 batch: 0.199996
Train loss on 100 batch: 0.246340
Train loss on 150 batch: 0.207985
best-train-loss: 0.238352
best-valid-loss: 0.293585
best-kappa: 0.8498
: Epoch: 31 | Training Loss: 0.238352 | Val. Loss: 0.293585 | Val. Kappa Score: 0.8498 | LR: 0.000031 | Estimated time: 30.70
Train loss on 50 batch: 0.185280
Train loss on 100 batch: 0.251352
Train loss on 150 batch: 0.200063
best-train-loss: 0.208937
best-valid-loss: 0.287173
best-kappa: 0.8508
: Epoch: 32 | Training Loss: 0.208937 | Val. Loss: 0.287173 | Val. Kappa Score: 0.8508 | LR: 0.000031 | Estimated time: 30.74
Train loss on 50 batch: 0.195016
Train loss on 100 batch: 0.205502
Train loss on 150 batch: 0.212456
: Epoch: 33 | Training Loss: 0.210948 | Val. Loss: 0.289389 | Val. Kappa Score: 0.8519 | LR: 0.000031 | Estimated time: 30.70
Train loss on 50 batch: 0.202504
Train loss on 100 batch: 0.226051
Train loss on 150 batch: 0.237766
: Epoch: 34 | Training Loss: 0.223605 | Val. Loss: 0.297281 | Val. Kappa Score: 0.8528 | LR: 0.000031 | Estimated time: 30.67
Train loss on 50 batch: 0.204503
Train loss on 100 batch: 0.209399
Train loss on 150 batch: 0.223967
: Epoch: 35 | Training Loss: 0.219027 | Val. Loss: 0.291777 | Val. Kappa Score: 0.8537 | LR: 0.000016 | Estimated time: 30.60
Train loss on 50 batch: 0.180622
Train loss on 100 batch: 0.230639
Train loss on 150 batch: 0.173444
: Epoch: 36 | Training Loss: 0.211750 | Val. Loss: 0.305625 | Val. Kappa Score: 0.8543 | LR: 0.000016 | Estimated time: 30.77
Train loss on 50 batch: 0.202360
Train loss on 100 batch: 0.211786
Train loss on 150 batch: 0.210066
: Epoch: 37 | Training Loss: 0.206906 | Val. Loss: 0.289073 | Val. Kappa Score: 0.8551 | LR: 0.000016 | Estimated time: 30.64
Train loss on 50 batch: 0.201744
Train loss on 100 batch: 0.185305
Train loss on 150 batch: 0.214803
best-train-loss: 0.236734
best-valid-loss: 0.286930
best-kappa: 0.8559
: Epoch: 38 | Training Loss: 0.236734 | Val. Loss: 0.286930 | Val. Kappa Score: 0.8559 | LR: 0.000016 | Estimated time: 30.64
Train loss on 50 batch: 0.215690
Train loss on 100 batch: 0.198108
Train loss on 150 batch: 0.206492
best-train-loss: 0.209980
best-valid-loss: 0.283555
best-kappa: 0.8565
: Epoch: 39 | Training Loss: 0.209980 | Val. Loss: 0.283555 | Val. Kappa Score: 0.8565 | LR: 0.000016 | Estimated time: 30.73
Train loss on 50 batch: 0.191991
Train loss on 100 batch: 0.179043
Train loss on 150 batch: 0.208905
: Epoch: 40 | Training Loss: 0.191566 | Val. Loss: 0.291962 | Val. Kappa Score: 0.8573 | LR: 0.000016 | Estimated time: 30.74
Train loss on 50 batch: 0.187769
Train loss on 100 batch: 0.187986
Train loss on 150 batch: 0.195956
: Epoch: 41 | Training Loss: 0.197961 | Val. Loss: 0.291678 | Val. Kappa Score: 0.8579 | LR: 0.000016 | Estimated time: 30.92
Train loss on 50 batch: 0.201127
Train loss on 100 batch: 0.179125
Train loss on 150 batch: 0.199656
: Epoch: 42 | Training Loss: 0.215492 | Val. Loss: 0.288680 | Val. Kappa Score: 0.8585 | LR: 0.000008 | Estimated time: 31.02
Train loss on 50 batch: 0.207592
Train loss on 100 batch: 0.206151
Train loss on 150 batch: 0.183677
: Epoch: 43 | Training Loss: 0.217409 | Val. Loss: 0.286802 | Val. Kappa Score: 0.8593 | LR: 0.000008 | Estimated time: 31.46
Train loss on 50 batch: 0.186577
Train loss on 100 batch: 0.241162
Train loss on 150 batch: 0.195176
: Epoch: 44 | Training Loss: 0.199782 | Val. Loss: 0.299512 | Val. Kappa Score: 0.8599 | LR: 0.000008 | Estimated time: 30.79
Train loss on 50 batch: 0.208596
Train loss on 100 batch: 0.162714
Train loss on 150 batch: 0.216962
: Epoch: 45 | Training Loss: 0.197283 | Val. Loss: 0.293444 | Val. Kappa Score: 0.8606 | LR: 0.000004 | Estimated time: 30.72
Train loss on 50 batch: 0.205305
Train loss on 100 batch: 0.198290
Train loss on 150 batch: 0.188651
: Epoch: 46 | Training Loss: 0.199411 | Val. Loss: 0.292388 | Val. Kappa Score: 0.8612 | LR: 0.000004 | Estimated time: 31.06
Train loss on 50 batch: 0.196677
Train loss on 100 batch: 0.176176
Train loss on 150 batch: 0.174436
: Epoch: 47 | Training Loss: 0.203273 | Val. Loss: 0.293356 | Val. Kappa Score: 0.8618 | LR: 0.000004 | Estimated time: 30.78
time_estimated: 1449.82
n-epochs: 47
time_estimated: 1449.84
----------------------------------------

Experiment N: 92: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.08.15 08:57:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c1d40b8>
early-stopping-patience: 8
parameters-amount: 42502209
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 92: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 08:59:12
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fde390>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 92: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 09:00:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fdd390>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.028676
Train loss on 100 batch: 1.244300
Train loss on 150 batch: 0.920749
best-train-loss: 1.255737
best-valid-loss: 1.159627
best-kappa: 0.5847
: Epoch: 1 | Training Loss: 1.255737 | Val. Loss: 1.159627 | Val. Kappa Score: 0.5847 | LR: 0.002000 | Estimated time: 44.61
Train loss on 50 batch: 0.724172
Train loss on 100 batch: 0.742842
Train loss on 150 batch: 0.671328
best-train-loss: 0.709814
best-valid-loss: 1.081799
best-kappa: 0.6039
: Epoch: 2 | Training Loss: 0.709814 | Val. Loss: 1.081799 | Val. Kappa Score: 0.6039 | LR: 0.002000 | Estimated time: 44.41
Train loss on 50 batch: 0.659930
Train loss on 100 batch: 0.686040
Train loss on 150 batch: 0.634833
best-train-loss: 0.646381
best-valid-loss: 0.653368
best-kappa: 0.6573
: Epoch: 3 | Training Loss: 0.646381 | Val. Loss: 0.653368 | Val. Kappa Score: 0.6573 | LR: 0.002000 | Estimated time: 44.37
Train loss on 50 batch: 0.666935
Train loss on 100 batch: 0.558486
Train loss on 150 batch: 0.589415
best-train-loss: 0.650555
best-valid-loss: 0.561347
best-kappa: 0.6912
: Epoch: 4 | Training Loss: 0.650555 | Val. Loss: 0.561347 | Val. Kappa Score: 0.6912 | LR: 0.002000 | Estimated time: 44.26
Train loss on 50 batch: 0.658327
Train loss on 100 batch: 0.677544
Train loss on 150 batch: 0.656462
: Epoch: 5 | Training Loss: 0.665536 | Val. Loss: 8.489970 | Val. Kappa Score: 0.6628 | LR: 0.002000 | Estimated time: 44.08
Train loss on 50 batch: 0.698225
Train loss on 100 batch: 0.602632
Train loss on 150 batch: 0.536023
: Epoch: 6 | Training Loss: 0.592246 | Val. Loss: 0.631237 | Val. Kappa Score: 0.6804 | LR: 0.002000 | Estimated time: 44.34
Train loss on 50 batch: 0.591066
Train loss on 100 batch: 0.528115
Train loss on 150 batch: 0.470876
best-train-loss: 0.542032
best-valid-loss: 0.425241
best-kappa: 0.7042
: Epoch: 7 | Training Loss: 0.542032 | Val. Loss: 0.425241 | Val. Kappa Score: 0.7042 | LR: 0.002000 | Estimated time: 44.32
Train loss on 50 batch: 0.452456
Train loss on 100 batch: 0.525030
Train loss on 150 batch: 0.450259
: Epoch: 8 | Training Loss: 0.471976 | Val. Loss: 0.453574 | Val. Kappa Score: 0.7193 | LR: 0.002000 | Estimated time: 44.15
Train loss on 50 batch: 0.489163
Train loss on 100 batch: 0.538182
Train loss on 150 batch: 0.501700
: Epoch: 9 | Training Loss: 0.500016 | Val. Loss: 0.498403 | Val. Kappa Score: 0.7313 | LR: 0.002000 | Estimated time: 44.28
Train loss on 50 batch: 0.376922
Train loss on 100 batch: 0.519492
Train loss on 150 batch: 0.451367
: Epoch: 10 | Training Loss: 0.492775 | Val. Loss: 0.447851 | Val. Kappa Score: 0.7419 | LR: 0.001000 | Estimated time: 44.15
Train loss on 50 batch: 0.480695
Train loss on 100 batch: 0.435662
Train loss on 150 batch: 0.458933
best-train-loss: 0.468848
best-valid-loss: 0.381069
best-kappa: 0.7526
: Epoch: 11 | Training Loss: 0.468848 | Val. Loss: 0.381069 | Val. Kappa Score: 0.7526 | LR: 0.001000 | Estimated time: 44.27
Train loss on 50 batch: 0.432450
Train loss on 100 batch: 0.414386
Train loss on 150 batch: 0.483369
: Epoch: 12 | Training Loss: 0.453206 | Val. Loss: 0.630888 | Val. Kappa Score: 0.7540 | LR: 0.001000 | Estimated time: 44.17
Train loss on 50 batch: 0.428635
Train loss on 100 batch: 0.473249
Train loss on 150 batch: 0.627353
: Epoch: 13 | Training Loss: 0.503994 | Val. Loss: 0.503792 | Val. Kappa Score: 0.7584 | LR: 0.001000 | Estimated time: 44.12
Train loss on 50 batch: 0.481574
Train loss on 100 batch: 0.444996
Train loss on 150 batch: 0.553717
: Epoch: 14 | Training Loss: 0.500058 | Val. Loss: 0.476284 | Val. Kappa Score: 0.7630 | LR: 0.000500 | Estimated time: 44.17
Train loss on 50 batch: 0.483914
Train loss on 100 batch: 0.389057
Train loss on 150 batch: 0.394082
: Epoch: 15 | Training Loss: 0.415361 | Val. Loss: 0.384574 | Val. Kappa Score: 0.7684 | LR: 0.000500 | Estimated time: 44.06
Train loss on 50 batch: 0.433878
Train loss on 100 batch: 0.409730
Train loss on 150 batch: 0.371807
: Epoch: 16 | Training Loss: 0.416960 | Val. Loss: 0.439107 | Val. Kappa Score: 0.7730 | LR: 0.000500 | Estimated time: 44.05
Train loss on 50 batch: 0.492421
Train loss on 100 batch: 0.380028
Train loss on 150 batch: 0.385252
: Epoch: 17 | Training Loss: 0.409099 | Val. Loss: 0.470265 | Val. Kappa Score: 0.7748 | LR: 0.000250 | Estimated time: 44.20
Train loss on 50 batch: 0.381826
Train loss on 100 batch: 0.325178
Train loss on 150 batch: 0.371356
: Epoch: 18 | Training Loss: 0.358078 | Val. Loss: 0.385331 | Val. Kappa Score: 0.7792 | LR: 0.000250 | Estimated time: 44.07
Train loss on 50 batch: 0.304659
Train loss on 100 batch: 0.367092
Train loss on 150 batch: 0.391931
: Epoch: 19 | Training Loss: 0.381942 | Val. Loss: 0.382563 | Val. Kappa Score: 0.7837 | LR: 0.000250 | Estimated time: 44.24
time_estimated: 841.62
n-epochs: 19
time_estimated: 841.64
----------------------------------------

Experiment N: 93: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.08.15 09:14:19
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb8c18c048>
early-stopping-patience: 8
parameters-amount: 42502209
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.759944
Train loss on 100 batch: 1.341336
Train loss on 150 batch: 0.994351
best-train-loss: 1.247280
best-valid-loss: 0.845894
best-kappa: 0.5424
: Epoch: 1 | Training Loss: 1.247280 | Val. Loss: 0.845894 | Val. Kappa Score: 0.5424 | LR: 0.002000 | Estimated time: 30.92
Train loss on 50 batch: 0.789810
Train loss on 100 batch: 0.761939
Train loss on 150 batch: 0.664795
best-train-loss: 0.745544
best-valid-loss: 0.666619
best-kappa: 0.6355
: Epoch: 2 | Training Loss: 0.745544 | Val. Loss: 0.666619 | Val. Kappa Score: 0.6355 | LR: 0.002000 | Estimated time: 31.10
Train loss on 50 batch: 0.734061
Train loss on 100 batch: 0.800028
Train loss on 150 batch: 0.702876
best-train-loss: 0.722509
best-valid-loss: 0.623435
best-kappa: 0.6806
: Epoch: 3 | Training Loss: 0.722509 | Val. Loss: 0.623435 | Val. Kappa Score: 0.6806 | LR: 0.002000 | Estimated time: 31.06
Train loss on 50 batch: 0.714898
Train loss on 100 batch: 0.613695
Train loss on 150 batch: 0.617176
best-train-loss: 0.696999
best-valid-loss: 0.539899
best-kappa: 0.7103
: Epoch: 4 | Training Loss: 0.696999 | Val. Loss: 0.539899 | Val. Kappa Score: 0.7103 | LR: 0.002000 | Estimated time: 30.87
Train loss on 50 batch: 0.688162
Train loss on 100 batch: 0.691799
Train loss on 150 batch: 0.647324
: Epoch: 5 | Training Loss: 0.650513 | Val. Loss: 0.551452 | Val. Kappa Score: 0.7275 | LR: 0.002000 | Estimated time: 31.08
Train loss on 50 batch: 0.577917
Train loss on 100 batch: 0.568291
Train loss on 150 batch: 0.550807
: Epoch: 6 | Training Loss: 0.568441 | Val. Loss: 0.622574 | Val. Kappa Score: 0.7340 | LR: 0.002000 | Estimated time: 30.90
Train loss on 50 batch: 0.637544
Train loss on 100 batch: 0.534056
Train loss on 150 batch: 0.531860
best-train-loss: 0.579440
best-valid-loss: 0.495453
best-kappa: 0.7451
: Epoch: 7 | Training Loss: 0.579440 | Val. Loss: 0.495453 | Val. Kappa Score: 0.7451 | LR: 0.002000 | Estimated time: 30.82
Train loss on 50 batch: 0.504534
Train loss on 100 batch: 0.550408
Train loss on 150 batch: 0.481355
: Epoch: 8 | Training Loss: 0.501595 | Val. Loss: 0.587674 | Val. Kappa Score: 0.7521 | LR: 0.002000 | Estimated time: 30.90
Train loss on 50 batch: 0.513402
Train loss on 100 batch: 0.554005
Train loss on 150 batch: 0.544026
: Epoch: 9 | Training Loss: 0.522025 | Val. Loss: 0.576488 | Val. Kappa Score: 0.7572 | LR: 0.002000 | Estimated time: 30.86
Train loss on 50 batch: 0.422517
Train loss on 100 batch: 0.552244
Train loss on 150 batch: 0.458655
: Epoch: 10 | Training Loss: 0.528770 | Val. Loss: 0.695113 | Val. Kappa Score: 0.7578 | LR: 0.001000 | Estimated time: 30.74
Train loss on 50 batch: 0.532452
Train loss on 100 batch: 0.511588
Train loss on 150 batch: 0.494293
best-train-loss: 0.505518
best-valid-loss: 0.427528
best-kappa: 0.7659
: Epoch: 11 | Training Loss: 0.505518 | Val. Loss: 0.427528 | Val. Kappa Score: 0.7659 | LR: 0.001000 | Estimated time: 30.99
Train loss on 50 batch: 0.505714
Train loss on 100 batch: 0.450426
Train loss on 150 batch: 0.542374
: Epoch: 12 | Training Loss: 0.500204 | Val. Loss: 2.267062 | Val. Kappa Score: 0.7140 | LR: 0.001000 | Estimated time: 30.99
Train loss on 50 batch: 0.687428
Train loss on 100 batch: 0.574960
Train loss on 150 batch: 0.582536
: Epoch: 13 | Training Loss: 0.571799 | Val. Loss: 0.475264 | Val. Kappa Score: 0.7240 | LR: 0.001000 | Estimated time: 31.05
Train loss on 50 batch: 0.481397
Train loss on 100 batch: 0.448401
Train loss on 150 batch: 0.555125
: Epoch: 14 | Training Loss: 0.498525 | Val. Loss: 0.446613 | Val. Kappa Score: 0.7316 | LR: 0.000500 | Estimated time: 30.94
Train loss on 50 batch: 0.458962
Train loss on 100 batch: 0.405962
Train loss on 150 batch: 0.385644
: Epoch: 15 | Training Loss: 0.413728 | Val. Loss: 0.431280 | Val. Kappa Score: 0.7380 | LR: 0.000500 | Estimated time: 30.98
Train loss on 50 batch: 0.436836
Train loss on 100 batch: 0.403543
Train loss on 150 batch: 0.368712
best-train-loss: 0.416023
best-valid-loss: 0.387336
best-kappa: 0.7450
: Epoch: 16 | Training Loss: 0.416023 | Val. Loss: 0.387336 | Val. Kappa Score: 0.7450 | LR: 0.000500 | Estimated time: 31.22
Train loss on 50 batch: 0.489076
Train loss on 100 batch: 0.372774
Train loss on 150 batch: 0.392892
best-train-loss: 0.414992
best-valid-loss: 0.386055
best-kappa: 0.7517
: Epoch: 17 | Training Loss: 0.414992 | Val. Loss: 0.386055 | Val. Kappa Score: 0.7517 | LR: 0.000500 | Estimated time: 30.95
Train loss on 50 batch: 0.438177
Train loss on 100 batch: 0.364408
Train loss on 150 batch: 0.379245
best-train-loss: 0.395569
best-valid-loss: 0.376482
best-kappa: 0.7578
: Epoch: 18 | Training Loss: 0.395569 | Val. Loss: 0.376482 | Val. Kappa Score: 0.7578 | LR: 0.000500 | Estimated time: 30.96
Train loss on 50 batch: 0.341693
Train loss on 100 batch: 0.399954
Train loss on 150 batch: 0.424496
: Epoch: 19 | Training Loss: 0.425089 | Val. Loss: 0.437646 | Val. Kappa Score: 0.7627 | LR: 0.000500 | Estimated time: 31.54
Train loss on 50 batch: 0.434663
Train loss on 100 batch: 0.384994
Train loss on 150 batch: 0.378146
: Epoch: 20 | Training Loss: 0.386120 | Val. Loss: 0.379542 | Val. Kappa Score: 0.7679 | LR: 0.000500 | Estimated time: 30.97
Train loss on 50 batch: 0.409327
Train loss on 100 batch: 0.412906
Train loss on 150 batch: 0.446796
: Epoch: 21 | Training Loss: 0.429257 | Val. Loss: 0.429175 | Val. Kappa Score: 0.7711 | LR: 0.000250 | Estimated time: 31.17
Train loss on 50 batch: 0.374160
Train loss on 100 batch: 0.375650
Train loss on 150 batch: 0.417564
best-train-loss: 0.384762
best-valid-loss: 0.372400
best-kappa: 0.7750
: Epoch: 22 | Training Loss: 0.384762 | Val. Loss: 0.372400 | Val. Kappa Score: 0.7750 | LR: 0.000250 | Estimated time: 30.94
Train loss on 50 batch: 0.423778
Train loss on 100 batch: 0.372557
Train loss on 150 batch: 0.376787
: Epoch: 23 | Training Loss: 0.385504 | Val. Loss: 0.376531 | Val. Kappa Score: 0.7787 | LR: 0.000250 | Estimated time: 30.77
Train loss on 50 batch: 0.335783
Train loss on 100 batch: 0.356586
Train loss on 150 batch: 0.355594
best-train-loss: 0.389467
best-valid-loss: 0.361033
best-kappa: 0.7821
: Epoch: 24 | Training Loss: 0.389467 | Val. Loss: 0.361033 | Val. Kappa Score: 0.7821 | LR: 0.000250 | Estimated time: 30.94
Train loss on 50 batch: 0.367137
Train loss on 100 batch: 0.315602
Train loss on 150 batch: 0.410081
: Epoch: 25 | Training Loss: 0.372874 | Val. Loss: 0.378876 | Val. Kappa Score: 0.7849 | LR: 0.000250 | Estimated time: 30.92
Train loss on 50 batch: 0.361433
Train loss on 100 batch: 0.300346
Train loss on 150 batch: 0.403249
: Epoch: 26 | Training Loss: 0.362116 | Val. Loss: 0.363159 | Val. Kappa Score: 0.7880 | LR: 0.000250 | Estimated time: 30.84
Train loss on 50 batch: 0.392278
Train loss on 100 batch: 0.390905
Train loss on 150 batch: 0.331916
: Epoch: 27 | Training Loss: 0.353459 | Val. Loss: 0.369640 | Val. Kappa Score: 0.7908 | LR: 0.000125 | Estimated time: 30.98
Train loss on 50 batch: 0.365824
Train loss on 100 batch: 0.335841
Train loss on 150 batch: 0.322108
: Epoch: 28 | Training Loss: 0.334906 | Val. Loss: 0.364664 | Val. Kappa Score: 0.7930 | LR: 0.000125 | Estimated time: 30.85
Train loss on 50 batch: 0.288843
Train loss on 100 batch: 0.358150
Train loss on 150 batch: 0.371281
: Epoch: 29 | Training Loss: 0.330934 | Val. Loss: 0.372446 | Val. Kappa Score: 0.7955 | LR: 0.000125 | Estimated time: 30.88
Train loss on 50 batch: 0.335589
Train loss on 100 batch: 0.334742
Train loss on 150 batch: 0.313070
: Epoch: 30 | Training Loss: 0.320648 | Val. Loss: 0.384624 | Val. Kappa Score: 0.7970 | LR: 0.000063 | Estimated time: 30.95
Train loss on 50 batch: 0.275343
Train loss on 100 batch: 0.350230
Train loss on 150 batch: 0.305064
best-train-loss: 0.334028
best-valid-loss: 0.353849
best-kappa: 0.7995
: Epoch: 31 | Training Loss: 0.334028 | Val. Loss: 0.353849 | Val. Kappa Score: 0.7995 | LR: 0.000063 | Estimated time: 30.88
Train loss on 50 batch: 0.292101
Train loss on 100 batch: 0.363859
Train loss on 150 batch: 0.268852
: Epoch: 32 | Training Loss: 0.307141 | Val. Loss: 0.359590 | Val. Kappa Score: 0.8014 | LR: 0.000063 | Estimated time: 30.97
Train loss on 50 batch: 0.310590
Train loss on 100 batch: 0.315757
Train loss on 150 batch: 0.291135
best-train-loss: 0.313474
best-valid-loss: 0.353315
best-kappa: 0.8032
: Epoch: 33 | Training Loss: 0.313474 | Val. Loss: 0.353315 | Val. Kappa Score: 0.8032 | LR: 0.000063 | Estimated time: 30.72
Train loss on 50 batch: 0.311551
Train loss on 100 batch: 0.336968
Train loss on 150 batch: 0.333728
: Epoch: 34 | Training Loss: 0.320042 | Val. Loss: 0.405826 | Val. Kappa Score: 0.8051 | LR: 0.000063 | Estimated time: 31.05
Train loss on 50 batch: 0.310450
Train loss on 100 batch: 0.310506
Train loss on 150 batch: 0.333630
best-train-loss: 0.326913
best-valid-loss: 0.350530
best-kappa: 0.8068
: Epoch: 35 | Training Loss: 0.326913 | Val. Loss: 0.350530 | Val. Kappa Score: 0.8068 | LR: 0.000063 | Estimated time: 30.88
Train loss on 50 batch: 0.287504
Train loss on 100 batch: 0.340507
Train loss on 150 batch: 0.300473
: Epoch: 36 | Training Loss: 0.325550 | Val. Loss: 0.352875 | Val. Kappa Score: 0.8084 | LR: 0.000063 | Estimated time: 30.98
Train loss on 50 batch: 0.318222
Train loss on 100 batch: 0.315595
Train loss on 150 batch: 0.297378
: Epoch: 37 | Training Loss: 0.311722 | Val. Loss: 0.354432 | Val. Kappa Score: 0.8096 | LR: 0.000063 | Estimated time: 30.92
Train loss on 50 batch: 0.306142
Train loss on 100 batch: 0.288350
Train loss on 150 batch: 0.317168
: Epoch: 38 | Training Loss: 0.341855 | Val. Loss: 0.354765 | Val. Kappa Score: 0.8112 | LR: 0.000031 | Estimated time: 30.98
Train loss on 50 batch: 0.343581
Train loss on 100 batch: 0.285147
Train loss on 150 batch: 0.303143
: Epoch: 39 | Training Loss: 0.310082 | Val. Loss: 0.356323 | Val. Kappa Score: 0.8124 | LR: 0.000031 | Estimated time: 30.84
Train loss on 50 batch: 0.295744
Train loss on 100 batch: 0.301290
Train loss on 150 batch: 0.329450
: Epoch: 40 | Training Loss: 0.304836 | Val. Loss: 0.353130 | Val. Kappa Score: 0.8136 | LR: 0.000031 | Estimated time: 30.87
Train loss on 50 batch: 0.277572
Train loss on 100 batch: 0.316407
Train loss on 150 batch: 0.312513
: Epoch: 41 | Training Loss: 0.314129 | Val. Loss: 0.358671 | Val. Kappa Score: 0.8150 | LR: 0.000016 | Estimated time: 30.91
Train loss on 50 batch: 0.324150
Train loss on 100 batch: 0.265152
Train loss on 150 batch: 0.291710
best-train-loss: 0.316945
best-valid-loss: 0.349423
best-kappa: 0.8161
: Epoch: 42 | Training Loss: 0.316945 | Val. Loss: 0.349423 | Val. Kappa Score: 0.8161 | LR: 0.000016 | Estimated time: 31.09
Train loss on 50 batch: 0.302263
Train loss on 100 batch: 0.310863
Train loss on 150 batch: 0.276905
best-train-loss: 0.317918
best-valid-loss: 0.348607
best-kappa: 0.8174
: Epoch: 43 | Training Loss: 0.317918 | Val. Loss: 0.348607 | Val. Kappa Score: 0.8174 | LR: 0.000016 | Estimated time: 31.01
Train loss on 50 batch: 0.303034
Train loss on 100 batch: 0.324914
Train loss on 150 batch: 0.318398
: Epoch: 44 | Training Loss: 0.308534 | Val. Loss: 0.351909 | Val. Kappa Score: 0.8182 | LR: 0.000016 | Estimated time: 30.84
Train loss on 50 batch: 0.303294
Train loss on 100 batch: 0.285530
Train loss on 150 batch: 0.359628
: Epoch: 45 | Training Loss: 0.326778 | Val. Loss: 0.349306 | Val. Kappa Score: 0.8194 | LR: 0.000016 | Estimated time: 30.99
Train loss on 50 batch: 0.303044
Train loss on 100 batch: 0.289992
Train loss on 150 batch: 0.291172
: Epoch: 46 | Training Loss: 0.300639 | Val. Loss: 0.349341 | Val. Kappa Score: 0.8204 | LR: 0.000008 | Estimated time: 30.94
Train loss on 50 batch: 0.288976
Train loss on 100 batch: 0.267147
Train loss on 150 batch: 0.301411
: Epoch: 47 | Training Loss: 0.305191 | Val. Loss: 0.349213 | Val. Kappa Score: 0.8214 | LR: 0.000008 | Estimated time: 30.99
Train loss on 50 batch: 0.260777
Train loss on 100 batch: 0.323537
Train loss on 150 batch: 0.280413
: Epoch: 48 | Training Loss: 0.292175 | Val. Loss: 0.352832 | Val. Kappa Score: 0.8220 | LR: 0.000008 | Estimated time: 31.00
Train loss on 50 batch: 0.292947
Train loss on 100 batch: 0.315726
Train loss on 150 batch: 0.306055
: Epoch: 49 | Training Loss: 0.309606 | Val. Loss: 0.351938 | Val. Kappa Score: 0.8228 | LR: 0.000004 | Estimated time: 30.97
Train loss on 50 batch: 0.269696
Train loss on 100 batch: 0.288495
Train loss on 150 batch: 0.339260
: Epoch: 50 | Training Loss: 0.308998 | Val. Loss: 0.352797 | Val. Kappa Score: 0.8236 | LR: 0.000004 | Estimated time: 30.95
Train loss on 50 batch: 0.315878
Train loss on 100 batch: 0.317506
Train loss on 150 batch: 0.283901
: Epoch: 51 | Training Loss: 0.291515 | Val. Loss: 0.359997 | Val. Kappa Score: 0.8243 | LR: 0.000004 | Estimated time: 30.83
time_estimated: 1581.63
n-epochs: 51
time_estimated: 1581.65
----------------------------------------

Experiment N: 94: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.002, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 12:53:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fde860>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.919318
Train loss on 100 batch: 1.434948
Train loss on 150 batch: 1.250331
best-train-loss: 1.433643
best-valid-loss: 1.482466
best-kappa: 0.3627
: Epoch: 1 | Training Loss: 1.433643 | Val. Loss: 1.482466 | Val. Kappa Score: 0.3627 | LR: 0.002000 | Estimated time: 45.59
Train loss on 50 batch: 1.270028
Train loss on 100 batch: 1.264722
Train loss on 150 batch: 1.072761
: Epoch: 2 | Training Loss: 1.191258 | Val. Loss: 1.514321 | Val. Kappa Score: 0.3075 | LR: 0.002000 | Estimated time: 45.48
Train loss on 50 batch: 1.077514
Train loss on 100 batch: 1.096098
Train loss on 150 batch: 1.069408
: Epoch: 3 | Training Loss: 1.032064 | Val. Loss: 1.586072 | Val. Kappa Score: 0.3613 | LR: 0.002000 | Estimated time: 44.56
Train loss on 50 batch: 0.987549
Train loss on 100 batch: 0.938487
Train loss on 150 batch: 0.925001
: Epoch: 4 | Training Loss: 0.988985 | Val. Loss: 13.491963 | Val. Kappa Score: 0.2837 | LR: 0.001000 | Estimated time: 45.35
Train loss on 50 batch: 0.793947
Train loss on 100 batch: 0.820273
Train loss on 150 batch: 0.717269
: Epoch: 5 | Training Loss: 0.757302 | Val. Loss: 1.579917 | Val. Kappa Score: 0.3505 | LR: 0.001000 | Estimated time: 45.31
Train loss on 50 batch: 0.683882
Train loss on 100 batch: 0.654053
Train loss on 150 batch: 0.583756
best-train-loss: 0.638864
best-valid-loss: 0.611332
best-kappa: 0.4203
: Epoch: 6 | Training Loss: 0.638864 | Val. Loss: 0.611332 | Val. Kappa Score: 0.4203 | LR: 0.001000 | Estimated time: 45.62
Train loss on 50 batch: 0.653050
Train loss on 100 batch: 0.578019
Train loss on 150 batch: 0.569041
best-train-loss: 0.623282
best-valid-loss: 0.503089
best-kappa: 0.4752
: Epoch: 7 | Training Loss: 0.623282 | Val. Loss: 0.503089 | Val. Kappa Score: 0.4752 | LR: 0.001000 | Estimated time: 46.18
Train loss on 50 batch: 0.565879
Train loss on 100 batch: 0.618480
Train loss on 150 batch: 0.510453
: Epoch: 8 | Training Loss: 0.550690 | Val. Loss: 0.574312 | Val. Kappa Score: 0.5129 | LR: 0.001000 | Estimated time: 44.99
Train loss on 50 batch: 0.531450
Train loss on 100 batch: 0.578660
Train loss on 150 batch: 0.547124
: Epoch: 9 | Training Loss: 0.545465 | Val. Loss: 0.684164 | Val. Kappa Score: 0.5456 | LR: 0.001000 | Estimated time: 45.14
Train loss on 50 batch: 0.464322
Train loss on 100 batch: 0.583655
Train loss on 150 batch: 0.463776
: Epoch: 10 | Training Loss: 0.544190 | Val. Loss: 0.547809 | Val. Kappa Score: 0.5710 | LR: 0.000500 | Estimated time: 46.17
Train loss on 50 batch: 0.525480
Train loss on 100 batch: 0.492601
Train loss on 150 batch: 0.516265
best-train-loss: 0.505187
best-valid-loss: 0.403676
best-kappa: 0.5974
: Epoch: 11 | Training Loss: 0.505187 | Val. Loss: 0.403676 | Val. Kappa Score: 0.5974 | LR: 0.000500 | Estimated time: 48.86
Train loss on 50 batch: 0.431324
Train loss on 100 batch: 0.406764
Train loss on 150 batch: 0.499611
: Epoch: 12 | Training Loss: 0.458246 | Val. Loss: 0.475091 | Val. Kappa Score: 0.6158 | LR: 0.000500 | Estimated time: 48.78
Train loss on 50 batch: 0.426121
Train loss on 100 batch: 0.451848
Train loss on 150 batch: 0.479605
: Epoch: 13 | Training Loss: 0.432965 | Val. Loss: 0.431445 | Val. Kappa Score: 0.6337 | LR: 0.000500 | Estimated time: 48.82
Train loss on 50 batch: 0.406273
Train loss on 100 batch: 0.421560
Train loss on 150 batch: 0.593627
: Epoch: 14 | Training Loss: 0.495707 | Val. Loss: 0.547585 | Val. Kappa Score: 0.6451 | LR: 0.000250 | Estimated time: 48.82
Train loss on 50 batch: 0.486885
Train loss on 100 batch: 0.415006
Train loss on 150 batch: 0.404837
: Epoch: 15 | Training Loss: 0.426458 | Val. Loss: 0.407363 | Val. Kappa Score: 0.6593 | LR: 0.000250 | Estimated time: 48.98
Train loss on 50 batch: 0.442509
Train loss on 100 batch: 0.418165
Train loss on 150 batch: 0.386939
: Epoch: 16 | Training Loss: 0.426274 | Val. Loss: 0.490754 | Val. Kappa Score: 0.6682 | LR: 0.000250 | Estimated time: 48.98
Train loss on 50 batch: 0.538820
Train loss on 100 batch: 0.402757
Train loss on 150 batch: 0.385357
: Epoch: 17 | Training Loss: 0.442505 | Val. Loss: 0.437259 | Val. Kappa Score: 0.6779 | LR: 0.000125 | Estimated time: 47.71
Train loss on 50 batch: 0.423764
Train loss on 100 batch: 0.346238
Train loss on 150 batch: 0.389981
best-train-loss: 0.382724
best-valid-loss: 0.360332
best-kappa: 0.6887
: Epoch: 18 | Training Loss: 0.382724 | Val. Loss: 0.360332 | Val. Kappa Score: 0.6887 | LR: 0.000125 | Estimated time: 47.16
Train loss on 50 batch: 0.355439
Train loss on 100 batch: 0.424800
Train loss on 150 batch: 0.443328
: Epoch: 19 | Training Loss: 0.419348 | Val. Loss: 0.362920 | Val. Kappa Score: 0.6979 | LR: 0.000125 | Estimated time: 47.13
Train loss on 50 batch: 0.364195
Train loss on 100 batch: 0.396935
Train loss on 150 batch: 0.358424
best-train-loss: 0.364502
best-valid-loss: 0.338971
best-kappa: 0.7070
: Epoch: 20 | Training Loss: 0.364502 | Val. Loss: 0.338971 | Val. Kappa Score: 0.7070 | LR: 0.000125 | Estimated time: 47.15
Train loss on 50 batch: 0.374307
Train loss on 100 batch: 0.366200
Train loss on 150 batch: 0.427484
: Epoch: 21 | Training Loss: 0.402074 | Val. Loss: 0.385462 | Val. Kappa Score: 0.7147 | LR: 0.000125 | Estimated time: 47.09
Train loss on 50 batch: 0.343236
Train loss on 100 batch: 0.371086
Train loss on 150 batch: 0.398980
: Epoch: 22 | Training Loss: 0.370178 | Val. Loss: 0.353555 | Val. Kappa Score: 0.7222 | LR: 0.000125 | Estimated time: 47.15
Train loss on 50 batch: 0.345939
Train loss on 100 batch: 0.345332
Train loss on 150 batch: 0.365444
: Epoch: 23 | Training Loss: 0.346974 | Val. Loss: 0.388289 | Val. Kappa Score: 0.7281 | LR: 0.000063 | Estimated time: 47.15
Train loss on 50 batch: 0.343611
Train loss on 100 batch: 0.340990
Train loss on 150 batch: 0.353751
: Epoch: 24 | Training Loss: 0.368385 | Val. Loss: 0.360710 | Val. Kappa Score: 0.7338 | LR: 0.000063 | Estimated time: 47.15
Train loss on 50 batch: 0.353661
Train loss on 100 batch: 0.311873
Train loss on 150 batch: 0.385191
: Epoch: 25 | Training Loss: 0.350106 | Val. Loss: 0.348949 | Val. Kappa Score: 0.7398 | LR: 0.000063 | Estimated time: 47.24
Train loss on 50 batch: 0.353145
Train loss on 100 batch: 0.288515
Train loss on 150 batch: 0.364938
: Epoch: 26 | Training Loss: 0.337521 | Val. Loss: 0.347963 | Val. Kappa Score: 0.7451 | LR: 0.000031 | Estimated time: 47.15
Train loss on 50 batch: 0.344105
Train loss on 100 batch: 0.341336
Train loss on 150 batch: 0.311053
: Epoch: 27 | Training Loss: 0.324818 | Val. Loss: 0.345249 | Val. Kappa Score: 0.7499 | LR: 0.000031 | Estimated time: 47.14
Train loss on 50 batch: 0.360413
Train loss on 100 batch: 0.342733
Train loss on 150 batch: 0.315961
: Epoch: 28 | Training Loss: 0.330367 | Val. Loss: 0.339767 | Val. Kappa Score: 0.7542 | LR: 0.000031 | Estimated time: 47.06
time_estimated: 1315.48
n-epochs: 28
time_estimated: 1315.51
----------------------------------------

Experiment N: 95: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 13:15:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fc5f98>
early-stopping-patience: 8
parameters-amount: 58145857
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.422272
Train loss on 100 batch: 0.770825
Train loss on 150 batch: 0.667273
best-train-loss: 0.850414
best-valid-loss: 0.695406
best-kappa: 0.7365
: Epoch: 1 | Training Loss: 0.850414 | Val. Loss: 0.695406 | Val. Kappa Score: 0.7365 | LR: 0.001000 | Estimated time: 47.38
Train loss on 50 batch: 0.612276
Train loss on 100 batch: 0.581708
Train loss on 150 batch: 0.491210
best-train-loss: 0.575285
best-valid-loss: 0.581570
best-kappa: 0.7630
: Epoch: 2 | Training Loss: 0.575285 | Val. Loss: 0.581570 | Val. Kappa Score: 0.7630 | LR: 0.001000 | Estimated time: 47.26
Train loss on 50 batch: 0.526288
Train loss on 100 batch: 0.567630
Train loss on 150 batch: 0.513780
best-train-loss: 0.532831
best-valid-loss: 0.449419
best-kappa: 0.7912
: Epoch: 3 | Training Loss: 0.532831 | Val. Loss: 0.449419 | Val. Kappa Score: 0.7912 | LR: 0.001000 | Estimated time: 47.26
Train loss on 50 batch: 0.524341
Train loss on 100 batch: 0.509601
Train loss on 150 batch: 0.509642
best-train-loss: 0.549054
best-valid-loss: 0.440351
best-kappa: 0.8020
: Epoch: 4 | Training Loss: 0.549054 | Val. Loss: 0.440351 | Val. Kappa Score: 0.8020 | LR: 0.001000 | Estimated time: 47.25
Train loss on 50 batch: 0.589511
Train loss on 100 batch: 0.568466
Train loss on 150 batch: 0.496977
: Epoch: 5 | Training Loss: 0.549424 | Val. Loss: 2.361604 | Val. Kappa Score: 0.7702 | LR: 0.001000 | Estimated time: 47.29
Train loss on 50 batch: 0.547151
Train loss on 100 batch: 0.492047
Train loss on 150 batch: 0.462344
: Epoch: 6 | Training Loss: 0.491864 | Val. Loss: 1.030265 | Val. Kappa Score: 0.7620 | LR: 0.001000 | Estimated time: 47.24
Train loss on 50 batch: 0.558220
Train loss on 100 batch: 0.457416
Train loss on 150 batch: 0.434545
: Epoch: 7 | Training Loss: 0.501426 | Val. Loss: 0.575933 | Val. Kappa Score: 0.7641 | LR: 0.000500 | Estimated time: 47.16
Train loss on 50 batch: 0.446743
Train loss on 100 batch: 0.464767
Train loss on 150 batch: 0.385469
best-train-loss: 0.415807
best-valid-loss: 0.377048
best-kappa: 0.7759
: Epoch: 8 | Training Loss: 0.415807 | Val. Loss: 0.377048 | Val. Kappa Score: 0.7759 | LR: 0.000500 | Estimated time: 47.22
Train loss on 50 batch: 0.377690
Train loss on 100 batch: 0.451493
Train loss on 150 batch: 0.404419
: Epoch: 9 | Training Loss: 0.403135 | Val. Loss: 0.585419 | Val. Kappa Score: 0.7821 | LR: 0.000500 | Estimated time: 47.22
Train loss on 50 batch: 0.323931
Train loss on 100 batch: 0.404450
Train loss on 150 batch: 0.360828
: Epoch: 10 | Training Loss: 0.384702 | Val. Loss: 0.409529 | Val. Kappa Score: 0.7861 | LR: 0.000500 | Estimated time: 47.18
Train loss on 50 batch: 0.359044
Train loss on 100 batch: 0.360946
Train loss on 150 batch: 0.401061
: Epoch: 11 | Training Loss: 0.396227 | Val. Loss: 0.421761 | Val. Kappa Score: 0.7914 | LR: 0.000250 | Estimated time: 46.31
Train loss on 50 batch: 0.357056
Train loss on 100 batch: 0.332261
Train loss on 150 batch: 0.380631
: Epoch: 12 | Training Loss: 0.364253 | Val. Loss: 0.426236 | Val. Kappa Score: 0.7956 | LR: 0.000250 | Estimated time: 44.30
Train loss on 50 batch: 0.327591
Train loss on 100 batch: 0.369542
Train loss on 150 batch: 0.365731
best-train-loss: 0.335520
best-valid-loss: 0.362188
best-kappa: 0.8009
: Epoch: 13 | Training Loss: 0.335520 | Val. Loss: 0.362188 | Val. Kappa Score: 0.8009 | LR: 0.000250 | Estimated time: 44.31
Train loss on 50 batch: 0.298670
Train loss on 100 batch: 0.278861
Train loss on 150 batch: 0.356030
: Epoch: 14 | Training Loss: 0.329106 | Val. Loss: 0.371243 | Val. Kappa Score: 0.8047 | LR: 0.000250 | Estimated time: 44.35
Train loss on 50 batch: 0.386064
Train loss on 100 batch: 0.299256
Train loss on 150 batch: 0.308184
best-train-loss: 0.319990
best-valid-loss: 0.354204
best-kappa: 0.8086
: Epoch: 15 | Training Loss: 0.319990 | Val. Loss: 0.354204 | Val. Kappa Score: 0.8086 | LR: 0.000250 | Estimated time: 44.43
Train loss on 50 batch: 0.309794
Train loss on 100 batch: 0.288398
Train loss on 150 batch: 0.312579
: Epoch: 16 | Training Loss: 0.316963 | Val. Loss: 0.381171 | Val. Kappa Score: 0.8111 | LR: 0.000250 | Estimated time: 44.36
Train loss on 50 batch: 0.356972
Train loss on 100 batch: 0.302245
Train loss on 150 batch: 0.279873
: Epoch: 17 | Training Loss: 0.315893 | Val. Loss: 0.376799 | Val. Kappa Score: 0.8136 | LR: 0.000250 | Estimated time: 44.55
Train loss on 50 batch: 0.360471
Train loss on 100 batch: 0.277356
Train loss on 150 batch: 0.292473
: Epoch: 18 | Training Loss: 0.309216 | Val. Loss: 0.365676 | Val. Kappa Score: 0.8166 | LR: 0.000125 | Estimated time: 44.45
Train loss on 50 batch: 0.250671
Train loss on 100 batch: 0.310915
Train loss on 150 batch: 0.321753
best-train-loss: 0.312038
best-valid-loss: 0.335615
best-kappa: 0.8197
: Epoch: 19 | Training Loss: 0.312038 | Val. Loss: 0.335615 | Val. Kappa Score: 0.8197 | LR: 0.000125 | Estimated time: 44.31
Train loss on 50 batch: 0.263767
Train loss on 100 batch: 0.305708
Train loss on 150 batch: 0.288136
best-train-loss: 0.292928
best-valid-loss: 0.316634
best-kappa: 0.8222
: Epoch: 20 | Training Loss: 0.292928 | Val. Loss: 0.316634 | Val. Kappa Score: 0.8222 | LR: 0.000125 | Estimated time: 44.32
Train loss on 50 batch: 0.274422
Train loss on 100 batch: 0.273383
Train loss on 150 batch: 0.317374
: Epoch: 21 | Training Loss: 0.296705 | Val. Loss: 0.367298 | Val. Kappa Score: 0.8244 | LR: 0.000125 | Estimated time: 44.30
Train loss on 50 batch: 0.273975
Train loss on 100 batch: 0.273322
Train loss on 150 batch: 0.297126
: Epoch: 22 | Training Loss: 0.286140 | Val. Loss: 0.332608 | Val. Kappa Score: 0.8270 | LR: 0.000125 | Estimated time: 44.43
Train loss on 50 batch: 0.282963
Train loss on 100 batch: 0.254219
Train loss on 150 batch: 0.273029
: Epoch: 23 | Training Loss: 0.266183 | Val. Loss: 0.344976 | Val. Kappa Score: 0.8288 | LR: 0.000063 | Estimated time: 44.49
Train loss on 50 batch: 0.255309
Train loss on 100 batch: 0.255336
Train loss on 150 batch: 0.267396
: Epoch: 24 | Training Loss: 0.296173 | Val. Loss: 0.319977 | Val. Kappa Score: 0.8307 | LR: 0.000063 | Estimated time: 44.32
Train loss on 50 batch: 0.254925
Train loss on 100 batch: 0.255850
Train loss on 150 batch: 0.269702
: Epoch: 25 | Training Loss: 0.260163 | Val. Loss: 0.322761 | Val. Kappa Score: 0.8326 | LR: 0.000063 | Estimated time: 44.49
Train loss on 50 batch: 0.248904
Train loss on 100 batch: 0.213999
Train loss on 150 batch: 0.293869
: Epoch: 26 | Training Loss: 0.265587 | Val. Loss: 0.322169 | Val. Kappa Score: 0.8343 | LR: 0.000031 | Estimated time: 44.32
Train loss on 50 batch: 0.259273
Train loss on 100 batch: 0.268064
Train loss on 150 batch: 0.234832
: Epoch: 27 | Training Loss: 0.248606 | Val. Loss: 0.329197 | Val. Kappa Score: 0.8357 | LR: 0.000031 | Estimated time: 44.32
Train loss on 50 batch: 0.280987
Train loss on 100 batch: 0.238151
Train loss on 150 batch: 0.235483
: Epoch: 28 | Training Loss: 0.245270 | Val. Loss: 0.321881 | Val. Kappa Score: 0.8372 | LR: 0.000031 | Estimated time: 44.40
time_estimated: 1275.21
n-epochs: 28
time_estimated: 1275.24
----------------------------------------

Experiment N: 96: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 19:52:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1076d8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 96: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 19:54:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1086d8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.026977
Train loss on 100 batch: 0.571088
Train loss on 150 batch: 0.633203
best-train-loss: 0.685062
best-valid-loss: 0.355695
best-kappa: 0.8529
: Epoch: 1 | Training Loss: 0.685062 | Val. Loss: 0.355695 | Val. Kappa Score: 0.8529 | LR: 0.001000 | Estimated time: 68.10
Train loss on 50 batch: 0.465176
Train loss on 100 batch: 0.449342
Train loss on 150 batch: 0.351430
: Epoch: 2 | Training Loss: 0.444835 | Val. Loss: 0.543162 | Val. Kappa Score: 0.8342 | LR: 0.001000 | Estimated time: 67.19
Train loss on 50 batch: 0.374874
Train loss on 100 batch: 0.394033
Train loss on 150 batch: 0.418940
best-train-loss: 0.380802
best-valid-loss: 0.344864
best-kappa: 0.8515
: Epoch: 3 | Training Loss: 0.380802 | Val. Loss: 0.344864 | Val. Kappa Score: 0.8515 | LR: 0.001000 | Estimated time: 68.02
Train loss on 50 batch: 0.360610
Train loss on 100 batch: 0.392474
Train loss on 150 batch: 0.400262
----------------------------------------

Experiment N: 97: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 20:00:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d106668>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.026977
Train loss on 100 batch: 0.571088
Train loss on 150 batch: 0.633203
best-train-loss: 0.685062
best-valid-loss: 0.355695
best-kappa: 0.8529
: Epoch: 1 | Training Loss: 0.685062 | Val. Loss: 0.355695 | Val. Kappa Score: 0.8529 | LR: 0.001000 | Estimated time: 68.32
Train loss on 50 batch: 0.465176
Train loss on 100 batch: 0.449342
Train loss on 150 batch: 0.351430
: Epoch: 2 | Training Loss: 0.444835 | Val. Loss: 0.543162 | Val. Kappa Score: 0.8342 | LR: 0.001000 | Estimated time: 65.90
Train loss on 50 batch: 0.374874
Train loss on 100 batch: 0.394033
Train loss on 150 batch: 0.418940
best-train-loss: 0.380802
best-valid-loss: 0.344864
best-kappa: 0.8515
: Epoch: 3 | Training Loss: 0.380802 | Val. Loss: 0.344864 | Val. Kappa Score: 0.8515 | LR: 0.001000 | Estimated time: 66.25
Train loss on 50 batch: 0.360610
Train loss on 100 batch: 0.392474
Train loss on 150 batch: 0.400262
: Epoch: 4 | Training Loss: 0.453662 | Val. Loss: 0.445616 | Val. Kappa Score: 0.8471 | LR: 0.001000 | Estimated time: 67.16
Train loss on 50 batch: 0.476650
Train loss on 100 batch: 0.441622
Train loss on 150 batch: 0.348696
: Epoch: 5 | Training Loss: 0.419326 | Val. Loss: 0.612884 | Val. Kappa Score: 0.8320 | LR: 0.001000 | Estimated time: 66.82
Train loss on 50 batch: 0.353744
Train loss on 100 batch: 0.323417
Train loss on 150 batch: 0.327459
: Epoch: 6 | Training Loss: 0.323739 | Val. Loss: 0.380586 | Val. Kappa Score: 0.8349 | LR: 0.000500 | Estimated time: 66.52
Train loss on 50 batch: 0.326382
Train loss on 100 batch: 0.253852
Train loss on 150 batch: 0.252823
best-train-loss: 0.270017
best-valid-loss: 0.290801
best-kappa: 0.8433
: Epoch: 7 | Training Loss: 0.270017 | Val. Loss: 0.290801 | Val. Kappa Score: 0.8433 | LR: 0.000500 | Estimated time: 67.38
Train loss on 50 batch: 0.203204
Train loss on 100 batch: 0.262544
Train loss on 150 batch: 0.202374
best-train-loss: 0.242823
best-valid-loss: 0.290420
best-kappa: 0.8490
: Epoch: 8 | Training Loss: 0.242823 | Val. Loss: 0.290420 | Val. Kappa Score: 0.8490 | LR: 0.000500 | Estimated time: 67.62
Train loss on 50 batch: 0.232986
Train loss on 100 batch: 0.274977
Train loss on 150 batch: 0.249889
best-train-loss: 0.243047
best-valid-loss: 0.268509
best-kappa: 0.8548
: Epoch: 9 | Training Loss: 0.243047 | Val. Loss: 0.268509 | Val. Kappa Score: 0.8548 | LR: 0.000500 | Estimated time: 67.31
Train loss on 50 batch: 0.207185
Train loss on 100 batch: 0.223130
Train loss on 150 batch: 0.234011
: Epoch: 10 | Training Loss: 0.287737 | Val. Loss: 0.281315 | Val. Kappa Score: 0.8584 | LR: 0.000500 | Estimated time: 68.15
Train loss on 50 batch: 0.224313
Train loss on 100 batch: 0.232228
Train loss on 150 batch: 0.214605
: Epoch: 11 | Training Loss: 0.235833 | Val. Loss: 0.320474 | Val. Kappa Score: 0.8601 | LR: 0.000500 | Estimated time: 67.45
Train loss on 50 batch: 0.219773
Train loss on 100 batch: 0.212566
Train loss on 150 batch: 0.214211
: Epoch: 12 | Training Loss: 0.223834 | Val. Loss: 0.295584 | Val. Kappa Score: 0.8620 | LR: 0.000250 | Estimated time: 67.72
Train loss on 50 batch: 0.173594
Train loss on 100 batch: 0.206781
Train loss on 150 batch: 0.146182
: Epoch: 13 | Training Loss: 0.187409 | Val. Loss: 0.282104 | Val. Kappa Score: 0.8643 | LR: 0.000250 | Estimated time: 67.79
Train loss on 50 batch: 0.161585
Train loss on 100 batch: 0.168679
Train loss on 150 batch: 0.184858
: Epoch: 14 | Training Loss: 0.172213 | Val. Loss: 0.285363 | Val. Kappa Score: 0.8660 | LR: 0.000250 | Estimated time: 67.70
Train loss on 50 batch: 0.169852
Train loss on 100 batch: 0.158311
Train loss on 150 batch: 0.180968
: Epoch: 15 | Training Loss: 0.169266 | Val. Loss: 0.289024 | Val. Kappa Score: 0.8670 | LR: 0.000125 | Estimated time: 66.41
Train loss on 50 batch: 0.147407
Train loss on 100 batch: 0.126234
Train loss on 150 batch: 0.136917
: Epoch: 16 | Training Loss: 0.137402 | Val. Loss: 0.290018 | Val. Kappa Score: 0.8686 | LR: 0.000125 | Estimated time: 66.54
Train loss on 50 batch: 0.143012
Train loss on 100 batch: 0.159271
Train loss on 150 batch: 0.132306
: Epoch: 17 | Training Loss: 0.136805 | Val. Loss: 0.287401 | Val. Kappa Score: 0.8702 | LR: 0.000125 | Estimated time: 67.29
time_estimated: 1143.16
n-epochs: 17
time_estimated: 1143.19
----------------------------------------

Experiment N: 98: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 20:20:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109668>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.061979
Train loss on 100 batch: 0.588251
Train loss on 150 batch: 0.577330
best-train-loss: 0.677405
best-valid-loss: 0.456687
best-kappa: 0.8364
: Epoch: 1 | Training Loss: 0.677405 | Val. Loss: 0.456687 | Val. Kappa Score: 0.8364 | LR: 0.001000 | Estimated time: 78.23
Train loss on 50 batch: 0.458162
Train loss on 100 batch: 0.457932
Train loss on 150 batch: 0.410564
: Epoch: 2 | Training Loss: 0.467543 | Val. Loss: 0.615891 | Val. Kappa Score: 0.8072 | LR: 0.001000 | Estimated time: 77.57
Train loss on 50 batch: 0.382797
Train loss on 100 batch: 0.405810
Train loss on 150 batch: 0.384375
: Epoch: 3 | Training Loss: 0.382859 | Val. Loss: 0.499261 | Val. Kappa Score: 0.8204 | LR: 0.001000 | Estimated time: 77.68
Train loss on 50 batch: 0.356543
Train loss on 100 batch: 0.362068
Train loss on 150 batch: 0.340515
: Epoch: 4 | Training Loss: 0.413074 | Val. Loss: 0.499508 | Val. Kappa Score: 0.8270 | LR: 0.000500 | Estimated time: 76.87
Train loss on 50 batch: 0.408313
Train loss on 100 batch: 0.346873
Train loss on 150 batch: 0.227769
best-train-loss: 0.331227
best-valid-loss: 0.298143
best-kappa: 0.8367
: Epoch: 5 | Training Loss: 0.331227 | Val. Loss: 0.298143 | Val. Kappa Score: 0.8367 | LR: 0.000500 | Estimated time: 78.04
Train loss on 50 batch: 0.282495
Train loss on 100 batch: 0.263217
Train loss on 150 batch: 0.248132
best-train-loss: 0.256880
best-valid-loss: 0.297747
best-kappa: 0.8442
: Epoch: 6 | Training Loss: 0.256880 | Val. Loss: 0.297747 | Val. Kappa Score: 0.8442 | LR: 0.000500 | Estimated time: 78.22
Train loss on 50 batch: 0.251640
Train loss on 100 batch: 0.251366
Train loss on 150 batch: 0.242637
: Epoch: 7 | Training Loss: 0.244064 | Val. Loss: 0.327326 | Val. Kappa Score: 0.8486 | LR: 0.000500 | Estimated time: 78.03
Train loss on 50 batch: 0.200327
Train loss on 100 batch: 0.252461
Train loss on 150 batch: 0.199011
best-train-loss: 0.235359
best-valid-loss: 0.289165
best-kappa: 0.8545
: Epoch: 8 | Training Loss: 0.235359 | Val. Loss: 0.289165 | Val. Kappa Score: 0.8545 | LR: 0.000500 | Estimated time: 76.84
Train loss on 50 batch: 0.239308
Train loss on 100 batch: 0.252175
Train loss on 150 batch: 0.265373
best-train-loss: 0.234992
best-valid-loss: 0.272334
best-kappa: 0.8589
: Epoch: 9 | Training Loss: 0.234992 | Val. Loss: 0.272334 | Val. Kappa Score: 0.8589 | LR: 0.000500 | Estimated time: 78.47
Train loss on 50 batch: 0.215786
Train loss on 100 batch: 0.220490
Train loss on 150 batch: 0.277459
: Epoch: 10 | Training Loss: 0.298008 | Val. Loss: 0.337987 | Val. Kappa Score: 0.8613 | LR: 0.000500 | Estimated time: 77.03
Train loss on 50 batch: 0.225376
Train loss on 100 batch: 0.226434
Train loss on 150 batch: 0.214312
: Epoch: 11 | Training Loss: 0.235917 | Val. Loss: 0.292614 | Val. Kappa Score: 0.8633 | LR: 0.000500 | Estimated time: 75.20
Train loss on 50 batch: 0.202654
Train loss on 100 batch: 0.200020
Train loss on 150 batch: 0.204350
: Epoch: 12 | Training Loss: 0.206509 | Val. Loss: 0.286011 | Val. Kappa Score: 0.8654 | LR: 0.000250 | Estimated time: 74.16
Train loss on 50 batch: 0.164756
Train loss on 100 batch: 0.196797
Train loss on 150 batch: 0.148035
: Epoch: 13 | Training Loss: 0.174661 | Val. Loss: 0.284463 | Val. Kappa Score: 0.8671 | LR: 0.000250 | Estimated time: 74.47
Train loss on 50 batch: 0.139190
Train loss on 100 batch: 0.147405
Train loss on 150 batch: 0.156149
: Epoch: 14 | Training Loss: 0.155916 | Val. Loss: 0.279948 | Val. Kappa Score: 0.8692 | LR: 0.000250 | Estimated time: 77.08
Train loss on 50 batch: 0.170794
Train loss on 100 batch: 0.145103
Train loss on 150 batch: 0.162411
: Epoch: 15 | Training Loss: 0.157241 | Val. Loss: 0.281160 | Val. Kappa Score: 0.8705 | LR: 0.000125 | Estimated time: 77.25
Train loss on 50 batch: 0.132486
Train loss on 100 batch: 0.127531
Train loss on 150 batch: 0.105395
: Epoch: 16 | Training Loss: 0.117827 | Val. Loss: 0.295488 | Val. Kappa Score: 0.8709 | LR: 0.000125 | Estimated time: 76.50
Train loss on 50 batch: 0.125295
Train loss on 100 batch: 0.118816
Train loss on 150 batch: 0.110814
: Epoch: 17 | Training Loss: 0.116003 | Val. Loss: 0.281381 | Val. Kappa Score: 0.8722 | LR: 0.000125 | Estimated time: 74.32
time_estimated: 1306.81
n-epochs: 17
time_estimated: 1306.84
----------------------------------------

Experiment N: 99: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 20:42:46
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1085c0>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
Train loss on 150 batch: 0.580317
best-train-loss: 0.665603
best-valid-loss: 1.313840
best-kappa: 0.7634
: Epoch: 1 | Training Loss: 0.665603 | Val. Loss: 1.313840 | Val. Kappa Score: 0.7634 | LR: 0.001000 | Estimated time: 165.21
Train loss on 50 batch: 0.449402
Train loss on 100 batch: 0.436332
Train loss on 150 batch: 0.361186
best-train-loss: 0.433382
best-valid-loss: 0.589005
best-kappa: 0.7821
: Epoch: 2 | Training Loss: 0.433382 | Val. Loss: 0.589005 | Val. Kappa Score: 0.7821 | LR: 0.001000 | Estimated time: 162.11
----------------------------------------

Experiment N: 100: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.15 20:49:15
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1076d8>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.018803
Train loss on 100 batch: 0.585430
Train loss on 150 batch: 0.624020
best-train-loss: 0.688772
best-valid-loss: 0.426828
best-kappa: 0.8523
: Epoch: 1 | Training Loss: 0.688772 | Val. Loss: 0.426828 | Val. Kappa Score: 0.8523 | LR: 0.001000 | Estimated time: 91.80
Train loss on 50 batch: 0.439584
Train loss on 100 batch: 0.456304
Train loss on 150 batch: 0.366349
: Epoch: 2 | Training Loss: 0.444126 | Val. Loss: 0.801825 | Val. Kappa Score: 0.7888 | LR: 0.001000 | Estimated time: 93.54
Train loss on 50 batch: 0.379725
Train loss on 100 batch: 0.380243
Train loss on 150 batch: 0.381126
best-train-loss: 0.372625
best-valid-loss: 0.362502
best-kappa: 0.8157
: Epoch: 3 | Training Loss: 0.372625 | Val. Loss: 0.362502 | Val. Kappa Score: 0.8157 | LR: 0.001000 | Estimated time: 91.78
Train loss on 50 batch: 0.401884
Train loss on 100 batch: 0.408789
Train loss on 150 batch: 0.383374
: Epoch: 4 | Training Loss: 0.455026 | Val. Loss: 0.571792 | Val. Kappa Score: 0.8219 | LR: 0.001000 | Estimated time: 92.27
Train loss on 50 batch: 0.538711
Train loss on 100 batch: 0.494382
Train loss on 150 batch: 0.386033
: Epoch: 5 | Training Loss: 0.457055 | Val. Loss: 0.465951 | Val. Kappa Score: 0.8236 | LR: 0.001000 | Estimated time: 92.85
Train loss on 50 batch: 0.369675
Train loss on 100 batch: 0.334205
Train loss on 150 batch: 0.322174
best-train-loss: 0.321894
best-valid-loss: 0.353014
best-kappa: 0.8291
: Epoch: 6 | Training Loss: 0.321894 | Val. Loss: 0.353014 | Val. Kappa Score: 0.8291 | LR: 0.001000 | Estimated time: 92.09
Train loss on 50 batch: 0.329434
Train loss on 100 batch: 0.325206
Train loss on 150 batch: 0.282161
best-train-loss: 0.311838
best-valid-loss: 0.312884
best-kappa: 0.8359
: Epoch: 7 | Training Loss: 0.311838 | Val. Loss: 0.312884 | Val. Kappa Score: 0.8359 | LR: 0.001000 | Estimated time: 93.74
Train loss on 50 batch: 0.239907
Train loss on 100 batch: 0.324289
Train loss on 150 batch: 0.260939
best-train-loss: 0.291283
best-valid-loss: 0.296604
best-kappa: 0.8435
: Epoch: 8 | Training Loss: 0.291283 | Val. Loss: 0.296604 | Val. Kappa Score: 0.8435 | LR: 0.001000 | Estimated time: 94.18
Train loss on 50 batch: 0.309472
Train loss on 100 batch: 0.315576
Train loss on 150 batch: 0.306177
best-train-loss: 0.303873
best-valid-loss: 0.275080
best-kappa: 0.8498
: Epoch: 9 | Training Loss: 0.303873 | Val. Loss: 0.275080 | Val. Kappa Score: 0.8498 | LR: 0.001000 | Estimated time: 94.44
Train loss on 50 batch: 0.287796
Train loss on 100 batch: 0.296579
Train loss on 150 batch: 0.289893
: Epoch: 10 | Training Loss: 0.356483 | Val. Loss: 0.325985 | Val. Kappa Score: 0.8522 | LR: 0.001000 | Estimated time: 94.47
Train loss on 50 batch: 0.286041
Train loss on 100 batch: 0.333155
Train loss on 150 batch: 0.293703
: Epoch: 11 | Training Loss: 0.314761 | Val. Loss: 0.316597 | Val. Kappa Score: 0.8541 | LR: 0.001000 | Estimated time: 93.92
Train loss on 50 batch: 0.272716
Train loss on 100 batch: 0.251999
Train loss on 150 batch: 0.255282
: Epoch: 12 | Training Loss: 0.264821 | Val. Loss: 0.367365 | Val. Kappa Score: 0.8547 | LR: 0.000500 | Estimated time: 93.72
Train loss on 50 batch: 0.211693
Train loss on 100 batch: 0.250742
Train loss on 150 batch: 0.202614
: Epoch: 13 | Training Loss: 0.232464 | Val. Loss: 0.292085 | Val. Kappa Score: 0.8576 | LR: 0.000500 | Estimated time: 93.61
Train loss on 50 batch: 0.200524
Train loss on 100 batch: 0.197941
Train loss on 150 batch: 0.220756
best-train-loss: 0.202341
best-valid-loss: 0.256055
best-kappa: 0.8605
: Epoch: 14 | Training Loss: 0.202341 | Val. Loss: 0.256055 | Val. Kappa Score: 0.8605 | LR: 0.000500 | Estimated time: 94.82
Train loss on 50 batch: 0.210680
Train loss on 100 batch: 0.184495
Train loss on 150 batch: 0.206739
: Epoch: 15 | Training Loss: 0.196100 | Val. Loss: 0.293564 | Val. Kappa Score: 0.8620 | LR: 0.000500 | Estimated time: 95.08
Train loss on 50 batch: 0.189247
Train loss on 100 batch: 0.175118
Train loss on 150 batch: 0.193639
: Epoch: 16 | Training Loss: 0.188150 | Val. Loss: 0.265583 | Val. Kappa Score: 0.8645 | LR: 0.000500 | Estimated time: 93.67
Train loss on 50 batch: 0.176833
Train loss on 100 batch: 0.185236
Train loss on 150 batch: 0.173722
: Epoch: 17 | Training Loss: 0.176291 | Val. Loss: 0.297364 | Val. Kappa Score: 0.8662 | LR: 0.000250 | Estimated time: 92.75
Train loss on 50 batch: 0.159895
Train loss on 100 batch: 0.131170
Train loss on 150 batch: 0.150252
: Epoch: 18 | Training Loss: 0.152035 | Val. Loss: 0.279428 | Val. Kappa Score: 0.8676 | LR: 0.000250 | Estimated time: 92.07
Train loss on 50 batch: 0.119978
Train loss on 100 batch: 0.144469
Train loss on 150 batch: 0.154951
: Epoch: 19 | Training Loss: 0.147081 | Val. Loss: 0.271447 | Val. Kappa Score: 0.8688 | LR: 0.000250 | Estimated time: 92.76
Train loss on 50 batch: 0.117754
Train loss on 100 batch: 0.146027
Train loss on 150 batch: 0.124269
: Epoch: 20 | Training Loss: 0.132828 | Val. Loss: 0.292338 | Val. Kappa Score: 0.8698 | LR: 0.000125 | Estimated time: 91.21
Train loss on 50 batch: 0.126047
Train loss on 100 batch: 0.105487
Train loss on 150 batch: 0.125952
: Epoch: 21 | Training Loss: 0.147410 | Val. Loss: 0.277082 | Val. Kappa Score: 0.8715 | LR: 0.000125 | Estimated time: 90.93
Train loss on 50 batch: 0.100106
Train loss on 100 batch: 0.125897
Train loss on 150 batch: 0.124478
: Epoch: 22 | Training Loss: 0.116439 | Val. Loss: 0.266587 | Val. Kappa Score: 0.8734 | LR: 0.000125 | Estimated time: 91.49
time_estimated: 2048.35
n-epochs: 22
time_estimated: 2048.37
----------------------------------------

Experiment N: 101: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet152


: 
date: 2019.08.15 21:23:53
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95fde828>
early-stopping-patience: 250
parameters-amount: 58145857
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.251224
Train loss on 100 batch: 1.588281
Train loss on 150 batch: 1.290839
Train loss on 200 batch: 1.191820
Train loss on 250 batch: 1.119314
best-train-loss: 1.418540
best-valid-loss: 1.087037
best-kappa: 0.5719
: Epoch: 1 | Training Loss: 1.418540 | Val. Loss: 1.087037 | Val. Kappa Score: 0.5719 | LR: 0.000998 | Estimated time: 66.58
Train loss on 50 batch: 1.043977
Train loss on 100 batch: 0.982369
Train loss on 150 batch: 1.197564
Train loss on 200 batch: 1.035989
Train loss on 250 batch: 1.020728
best-train-loss: 1.053131
best-valid-loss: 0.873475
best-kappa: 0.6241
: Epoch: 2 | Training Loss: 1.053131 | Val. Loss: 0.873475 | Val. Kappa Score: 0.6241 | LR: 0.000992 | Estimated time: 65.88
Train loss on 50 batch: 1.019246
Train loss on 100 batch: 0.887910
Train loss on 150 batch: 0.916684
Train loss on 200 batch: 0.950321
Train loss on 250 batch: 1.039573
: Epoch: 3 | Training Loss: 0.968824 | Val. Loss: 0.925944 | Val. Kappa Score: 0.6313 | LR: 0.000982 | Estimated time: 65.66
Train loss on 50 batch: 1.086833
Train loss on 100 batch: 0.987403
Train loss on 150 batch: 1.031873
Train loss on 200 batch: 0.857015
Train loss on 250 batch: 0.877609
best-train-loss: 0.974958
best-valid-loss: 0.870878
best-kappa: 0.6490
: Epoch: 4 | Training Loss: 0.974958 | Val. Loss: 0.870878 | Val. Kappa Score: 0.6490 | LR: 0.000968 | Estimated time: 65.74
Train loss on 50 batch: 0.906952
Train loss on 100 batch: 0.861467
Train loss on 150 batch: 0.989778
Train loss on 200 batch: 0.796056
Train loss on 250 batch: 0.810223
: Epoch: 5 | Training Loss: 0.893489 | Val. Loss: 0.874483 | Val. Kappa Score: 0.6598 | LR: 0.000950 | Estimated time: 65.69
Train loss on 50 batch: 0.926108
Train loss on 100 batch: 0.955183
Train loss on 150 batch: 0.936452
Train loss on 200 batch: 0.887137
Train loss on 250 batch: 0.813068
: Epoch: 6 | Training Loss: 0.899034 | Val. Loss: 0.977096 | Val. Kappa Score: 0.6660 | LR: 0.000929 | Estimated time: 65.64
Train loss on 50 batch: 0.803572
Train loss on 100 batch: 0.919191
Train loss on 150 batch: 0.785544
Train loss on 200 batch: 0.820395
Train loss on 250 batch: 0.859502
: Epoch: 7 | Training Loss: 0.845025 | Val. Loss: 1.130321 | Val. Kappa Score: 0.6547 | LR: 0.000905 | Estimated time: 65.78
Train loss on 50 batch: 0.876948
Train loss on 100 batch: 0.787482
Train loss on 150 batch: 0.809618
Train loss on 200 batch: 0.711678
Train loss on 250 batch: 0.797309
best-train-loss: 0.807497
best-valid-loss: 0.826925
best-kappa: 0.6634
: Epoch: 8 | Training Loss: 0.807497 | Val. Loss: 0.826925 | Val. Kappa Score: 0.6634 | LR: 0.000877 | Estimated time: 65.53
Train loss on 50 batch: 0.857095
Train loss on 100 batch: 0.882776
Train loss on 150 batch: 0.784651
Train loss on 200 batch: 0.766215
Train loss on 250 batch: 0.816616
: Epoch: 9 | Training Loss: 0.824064 | Val. Loss: 0.860419 | Val. Kappa Score: 0.6708 | LR: 0.000846 | Estimated time: 65.66
Train loss on 50 batch: 0.768567
Train loss on 100 batch: 0.755194
Train loss on 150 batch: 0.818969
Train loss on 200 batch: 0.665347
Train loss on 250 batch: 0.818681
: Epoch: 10 | Training Loss: 0.795956 | Val. Loss: 1.340988 | Val. Kappa Score: 0.6647 | LR: 0.000812 | Estimated time: 65.86
Train loss on 50 batch: 1.008828
Train loss on 100 batch: 0.904507
Train loss on 150 batch: 0.878792
Train loss on 200 batch: 0.869646
Train loss on 250 batch: 0.814035
: Epoch: 11 | Training Loss: 0.876527 | Val. Loss: 15.959039 | Val. Kappa Score: 0.6461 | LR: 0.000775 | Estimated time: 65.58
Train loss on 50 batch: 0.861619
Train loss on 100 batch: 0.746138
Train loss on 150 batch: 0.838953
Train loss on 200 batch: 0.701806
Train loss on 250 batch: 0.717975
best-train-loss: 0.761641
best-valid-loss: 0.616284
best-kappa: 0.6574
: Epoch: 12 | Training Loss: 0.761641 | Val. Loss: 0.616284 | Val. Kappa Score: 0.6574 | LR: 0.000737 | Estimated time: 65.64
Train loss on 50 batch: 0.749527
Train loss on 100 batch: 0.728844
Train loss on 150 batch: 0.806882
Train loss on 200 batch: 0.819586
Train loss on 250 batch: 0.902460
: Epoch: 13 | Training Loss: 0.796998 | Val. Loss: 0.695988 | Val. Kappa Score: 0.6659 | LR: 0.000697 | Estimated time: 65.69
Train loss on 50 batch: 0.790947
Train loss on 100 batch: 0.857165
Train loss on 150 batch: 0.821659
Train loss on 200 batch: 0.903456
Train loss on 250 batch: 0.698625
: Epoch: 14 | Training Loss: 0.783678 | Val. Loss: 0.651201 | Val. Kappa Score: 0.6736 | LR: 0.000655 | Estimated time: 65.84
Train loss on 50 batch: 0.667652
Train loss on 100 batch: 0.704769
Train loss on 150 batch: 0.724189
Train loss on 200 batch: 0.812236
Train loss on 250 batch: 0.731252
: Epoch: 15 | Training Loss: 0.751663 | Val. Loss: 0.665284 | Val. Kappa Score: 0.6808 | LR: 0.000611 | Estimated time: 65.83
Train loss on 50 batch: 0.682267
Train loss on 100 batch: 0.728837
Train loss on 150 batch: 0.733887
Train loss on 200 batch: 0.696461
Train loss on 250 batch: 0.732727
best-train-loss: 0.694513
best-valid-loss: 0.579967
best-kappa: 0.6879
: Epoch: 16 | Training Loss: 0.694513 | Val. Loss: 0.579967 | Val. Kappa Score: 0.6879 | LR: 0.000567 | Estimated time: 65.55
Train loss on 50 batch: 0.703899
Train loss on 100 batch: 0.652892
Train loss on 150 batch: 0.688407
Train loss on 200 batch: 0.691926
Train loss on 250 batch: 0.681688
: Epoch: 17 | Training Loss: 0.691798 | Val. Loss: 0.601152 | Val. Kappa Score: 0.6933 | LR: 0.000522 | Estimated time: 65.81
Train loss on 50 batch: 0.644705
Train loss on 100 batch: 0.739303
Train loss on 150 batch: 0.708896
Train loss on 200 batch: 0.731252
Train loss on 250 batch: 0.647926
: Epoch: 18 | Training Loss: 0.686439 | Val. Loss: 0.602517 | Val. Kappa Score: 0.6991 | LR: 0.000478 | Estimated time: 65.70
Train loss on 50 batch: 0.698375
Train loss on 100 batch: 0.622545
Train loss on 150 batch: 0.684723
Train loss on 200 batch: 0.566628
Train loss on 250 batch: 0.693059
best-train-loss: 0.667258
best-valid-loss: 0.568535
best-kappa: 0.7040
: Epoch: 19 | Training Loss: 0.667258 | Val. Loss: 0.568535 | Val. Kappa Score: 0.7040 | LR: 0.000433 | Estimated time: 65.74
Train loss on 50 batch: 0.657708
Train loss on 100 batch: 0.661489
Train loss on 150 batch: 0.651533
Train loss on 200 batch: 0.648029
Train loss on 250 batch: 0.625804
: Epoch: 20 | Training Loss: 0.647419 | Val. Loss: 0.608684 | Val. Kappa Score: 0.7081 | LR: 0.000389 | Estimated time: 65.67
Train loss on 50 batch: 0.631704
Train loss on 100 batch: 0.734212
Train loss on 150 batch: 0.570593
Train loss on 200 batch: 0.654913
Train loss on 250 batch: 0.624955
: Epoch: 21 | Training Loss: 0.657041 | Val. Loss: 0.571912 | Val. Kappa Score: 0.7131 | LR: 0.000345 | Estimated time: 65.65
Train loss on 50 batch: 0.712611
Train loss on 100 batch: 0.627714
Train loss on 150 batch: 0.601183
Train loss on 200 batch: 0.660768
Train loss on 250 batch: 0.713124
best-train-loss: 0.662739
best-valid-loss: 0.545697
best-kappa: 0.7166
: Epoch: 22 | Training Loss: 0.662739 | Val. Loss: 0.545697 | Val. Kappa Score: 0.7166 | LR: 0.000303 | Estimated time: 65.70
Train loss on 50 batch: 0.574091
Train loss on 100 batch: 0.554076
Train loss on 150 batch: 0.564305
Train loss on 200 batch: 0.557639
Train loss on 250 batch: 0.635681
: Epoch: 23 | Training Loss: 0.588225 | Val. Loss: 0.555639 | Val. Kappa Score: 0.7201 | LR: 0.000263 | Estimated time: 65.58
Train loss on 50 batch: 0.633106
Train loss on 100 batch: 0.488255
Train loss on 150 batch: 0.573348
Train loss on 200 batch: 0.606294
Train loss on 250 batch: 0.538857
: Epoch: 24 | Training Loss: 0.583619 | Val. Loss: 0.622949 | Val. Kappa Score: 0.7224 | LR: 0.000225 | Estimated time: 65.71
Train loss on 50 batch: 0.592289
Train loss on 100 batch: 0.662955
Train loss on 150 batch: 0.554033
Train loss on 200 batch: 0.597411
Train loss on 250 batch: 0.594512
best-train-loss: 0.612152
best-valid-loss: 0.544709
best-kappa: 0.7259
: Epoch: 25 | Training Loss: 0.612152 | Val. Loss: 0.544709 | Val. Kappa Score: 0.7259 | LR: 0.000188 | Estimated time: 65.77
Train loss on 50 batch: 0.540794
Train loss on 100 batch: 0.622424
Train loss on 150 batch: 0.549424
Train loss on 200 batch: 0.557166
Train loss on 250 batch: 0.535588
best-train-loss: 0.566375
best-valid-loss: 0.511130
best-kappa: 0.7298
: Epoch: 26 | Training Loss: 0.566375 | Val. Loss: 0.511130 | Val. Kappa Score: 0.7298 | LR: 0.000154 | Estimated time: 65.72
Train loss on 50 batch: 0.585035
Train loss on 100 batch: 0.564226
Train loss on 150 batch: 0.565702
Train loss on 200 batch: 0.560172
Train loss on 250 batch: 0.568254
best-train-loss: 0.558219
best-valid-loss: 0.501521
best-kappa: 0.7333
: Epoch: 27 | Training Loss: 0.558219 | Val. Loss: 0.501521 | Val. Kappa Score: 0.7333 | LR: 0.000123 | Estimated time: 65.72
Train loss on 50 batch: 0.566241
Train loss on 100 batch: 0.565967
Train loss on 150 batch: 0.592263
Train loss on 200 batch: 0.540814
Train loss on 250 batch: 0.518132
best-train-loss: 0.554839
best-valid-loss: 0.499020
best-kappa: 0.7364
: Epoch: 28 | Training Loss: 0.554839 | Val. Loss: 0.499020 | Val. Kappa Score: 0.7364 | LR: 0.000095 | Estimated time: 65.64
Train loss on 50 batch: 0.502270
Train loss on 100 batch: 0.556574
Train loss on 150 batch: 0.556425
Train loss on 200 batch: 0.537711
Train loss on 250 batch: 0.444232
: Epoch: 29 | Training Loss: 0.529585 | Val. Loss: 0.506098 | Val. Kappa Score: 0.7396 | LR: 0.000071 | Estimated time: 65.65
Train loss on 50 batch: 0.510344
Train loss on 100 batch: 0.532946
Train loss on 150 batch: 0.470843
Train loss on 200 batch: 0.582626
Train loss on 250 batch: 0.452475
: Epoch: 30 | Training Loss: 0.521967 | Val. Loss: 0.518414 | Val. Kappa Score: 0.7420 | LR: 0.000050 | Estimated time: 65.74
Train loss on 50 batch: 0.524430
Train loss on 100 batch: 0.473122
Train loss on 150 batch: 0.465027
Train loss on 200 batch: 0.484893
Train loss on 250 batch: 0.461668
best-train-loss: 0.506569
best-valid-loss: 0.494432
best-kappa: 0.7448
: Epoch: 31 | Training Loss: 0.506569 | Val. Loss: 0.494432 | Val. Kappa Score: 0.7448 | LR: 0.000032 | Estimated time: 65.79
Train loss on 50 batch: 0.486200
Train loss on 100 batch: 0.504101
Train loss on 150 batch: 0.435976
Train loss on 200 batch: 0.497259
Train loss on 250 batch: 0.477248
best-train-loss: 0.492721
best-valid-loss: 0.479682
best-kappa: 0.7473
: Epoch: 32 | Training Loss: 0.492721 | Val. Loss: 0.479682 | Val. Kappa Score: 0.7473 | LR: 0.000018 | Estimated time: 65.77
Train loss on 50 batch: 0.453245
Train loss on 100 batch: 0.494744
Train loss on 150 batch: 0.430757
Train loss on 200 batch: 0.479443
Train loss on 250 batch: 0.519431
: Epoch: 33 | Training Loss: 0.473667 | Val. Loss: 0.493453 | Val. Kappa Score: 0.7500 | LR: 0.000008 | Estimated time: 65.70
Train loss on 50 batch: 0.463155
Train loss on 100 batch: 0.459546
Train loss on 150 batch: 0.487657
Train loss on 200 batch: 0.465088
Train loss on 250 batch: 0.452296
: Epoch: 34 | Training Loss: 0.483269 | Val. Loss: 0.480440 | Val. Kappa Score: 0.7526 | LR: 0.000002 | Estimated time: 65.64
Train loss on 50 batch: 0.431944
Train loss on 100 batch: 0.426932
Train loss on 150 batch: 0.495813
Train loss on 200 batch: 0.509211
Train loss on 250 batch: 0.441909
: Epoch: 35 | Training Loss: 0.455022 | Val. Loss: 0.481638 | Val. Kappa Score: 0.7550 | LR: 0.000000 | Estimated time: 65.64
Train loss on 50 batch: 0.496948
Train loss on 100 batch: 0.474192
Train loss on 150 batch: 0.450865
Train loss on 200 batch: 0.485443
Train loss on 250 batch: 0.466133
: Epoch: 36 | Training Loss: 0.489088 | Val. Loss: 0.488441 | Val. Kappa Score: 0.7571 | LR: 0.000002 | Estimated time: 65.71
Train loss on 50 batch: 0.469745
Train loss on 100 batch: 0.496236
Train loss on 150 batch: 0.462162
Train loss on 200 batch: 0.444568
Train loss on 250 batch: 0.428207
best-train-loss: 0.457238
best-valid-loss: 0.475143
best-kappa: 0.7592
: Epoch: 37 | Training Loss: 0.457238 | Val. Loss: 0.475143 | Val. Kappa Score: 0.7592 | LR: 0.000008 | Estimated time: 65.70
Train loss on 50 batch: 0.465057
Train loss on 100 batch: 0.444220
Train loss on 150 batch: 0.459158
Train loss on 200 batch: 0.461815
Train loss on 250 batch: 0.475994
: Epoch: 38 | Training Loss: 0.459409 | Val. Loss: 0.498306 | Val. Kappa Score: 0.7607 | LR: 0.000018 | Estimated time: 65.64
Train loss on 50 batch: 0.425473
Train loss on 100 batch: 0.434777
Train loss on 150 batch: 0.442159
Train loss on 200 batch: 0.486538
Train loss on 250 batch: 0.508648
: Epoch: 39 | Training Loss: 0.466305 | Val. Loss: 0.494646 | Val. Kappa Score: 0.7626 | LR: 0.000032 | Estimated time: 65.64
Train loss on 50 batch: 0.527291
Train loss on 100 batch: 0.439558
Train loss on 150 batch: 0.465464
Train loss on 200 batch: 0.436401
Train loss on 250 batch: 0.502384
: Epoch: 40 | Training Loss: 0.479440 | Val. Loss: 0.485863 | Val. Kappa Score: 0.7643 | LR: 0.000050 | Estimated time: 65.84
Train loss on 50 batch: 0.495871
Train loss on 100 batch: 0.468620
Train loss on 150 batch: 0.498836
Train loss on 200 batch: 0.416197
Train loss on 250 batch: 0.443630
: Epoch: 41 | Training Loss: 0.480363 | Val. Loss: 0.477924 | Val. Kappa Score: 0.7659 | LR: 0.000071 | Estimated time: 65.62
Train loss on 50 batch: 0.471057
Train loss on 100 batch: 0.393827
Train loss on 150 batch: 0.525811
Train loss on 200 batch: 0.476705
Train loss on 250 batch: 0.463631
: Epoch: 42 | Training Loss: 0.468691 | Val. Loss: 0.503048 | Val. Kappa Score: 0.7672 | LR: 0.000095 | Estimated time: 65.70
Train loss on 50 batch: 0.506557
Train loss on 100 batch: 0.449932
Train loss on 150 batch: 0.460257
Train loss on 200 batch: 0.454600
Train loss on 250 batch: 0.500289
: Epoch: 43 | Training Loss: 0.460739 | Val. Loss: 0.502115 | Val. Kappa Score: 0.7683 | LR: 0.000123 | Estimated time: 65.59
Train loss on 50 batch: 0.445077
Train loss on 100 batch: 0.513821
Train loss on 150 batch: 0.450607
Train loss on 200 batch: 0.486749
Train loss on 250 batch: 0.473356
: Epoch: 44 | Training Loss: 0.477354 | Val. Loss: 0.481837 | Val. Kappa Score: 0.7700 | LR: 0.000154 | Estimated time: 65.65
Train loss on 50 batch: 0.458381
Train loss on 100 batch: 0.483829
Train loss on 150 batch: 0.565941
Train loss on 200 batch: 0.475682
Train loss on 250 batch: 0.514917
: Epoch: 45 | Training Loss: 0.507066 | Val. Loss: 0.576286 | Val. Kappa Score: 0.7707 | LR: 0.000188 | Estimated time: 65.70
Train loss on 50 batch: 0.466997
Train loss on 100 batch: 0.495913
Train loss on 150 batch: 0.461278
Train loss on 200 batch: 0.537396
Train loss on 250 batch: 0.448582
: Epoch: 46 | Training Loss: 0.486392 | Val. Loss: 0.574847 | Val. Kappa Score: 0.7712 | LR: 0.000225 | Estimated time: 65.62
Train loss on 50 batch: 0.551595
Train loss on 100 batch: 0.461083
Train loss on 150 batch: 0.472258
Train loss on 200 batch: 0.445509
Train loss on 250 batch: 0.518143
: Epoch: 47 | Training Loss: 0.495613 | Val. Loss: 0.486761 | Val. Kappa Score: 0.7723 | LR: 0.000263 | Estimated time: 65.75
Train loss on 50 batch: 0.492644
Train loss on 100 batch: 0.542926
Train loss on 150 batch: 0.518001
Train loss on 200 batch: 0.470685
Train loss on 250 batch: 0.516030
: Epoch: 48 | Training Loss: 0.554787 | Val. Loss: 0.504805 | Val. Kappa Score: 0.7734 | LR: 0.000303 | Estimated time: 65.52
Train loss on 50 batch: 0.590738
Train loss on 100 batch: 0.502966
Train loss on 150 batch: 0.527180
Train loss on 200 batch: 0.510059
Train loss on 250 batch: 0.529088
: Epoch: 49 | Training Loss: 0.536887 | Val. Loss: 0.573448 | Val. Kappa Score: 0.7741 | LR: 0.000345 | Estimated time: 65.68
Train loss on 50 batch: 0.463538
Train loss on 100 batch: 0.566268
Train loss on 150 batch: 0.494701
Train loss on 200 batch: 0.528349
Train loss on 250 batch: 0.547521
: Epoch: 50 | Training Loss: 0.521698 | Val. Loss: 0.544233 | Val. Kappa Score: 0.7750 | LR: 0.000389 | Estimated time: 65.72
Train loss on 50 batch: 0.550417
Train loss on 100 batch: 0.518596
Train loss on 150 batch: 0.542420
Train loss on 200 batch: 0.560260
Train loss on 250 batch: 0.481113
: Epoch: 51 | Training Loss: 0.523725 | Val. Loss: 0.596455 | Val. Kappa Score: 0.7757 | LR: 0.000433 | Estimated time: 65.63
Train loss on 50 batch: 0.587213
Train loss on 100 batch: 0.605553
Train loss on 150 batch: 0.495045
Train loss on 200 batch: 0.543880
Train loss on 250 batch: 0.472393
: Epoch: 52 | Training Loss: 0.565509 | Val. Loss: 0.519816 | Val. Kappa Score: 0.7765 | LR: 0.000478 | Estimated time: 65.62
Train loss on 50 batch: 0.735715
Train loss on 100 batch: 0.660705
Train loss on 150 batch: 0.579115
Train loss on 200 batch: 0.642993
Train loss on 250 batch: 0.634377
: Epoch: 53 | Training Loss: 0.644808 | Val. Loss: 0.639806 | Val. Kappa Score: 0.7766 | LR: 0.000522 | Estimated time: 65.54
Train loss on 50 batch: 0.586252
Train loss on 100 batch: 0.558029
Train loss on 150 batch: 0.506039
Train loss on 200 batch: 0.549468
Train loss on 250 batch: 0.582664
: Epoch: 54 | Training Loss: 0.572703 | Val. Loss: 0.563491 | Val. Kappa Score: 0.7770 | LR: 0.000567 | Estimated time: 65.74
Train loss on 50 batch: 0.529224
Train loss on 100 batch: 0.663265
Train loss on 150 batch: 0.601016
Train loss on 200 batch: 0.634255
Train loss on 250 batch: 0.592806
: Epoch: 55 | Training Loss: 0.607082 | Val. Loss: 0.878442 | Val. Kappa Score: 0.7759 | LR: 0.000611 | Estimated time: 65.63
Train loss on 50 batch: 0.610793
Train loss on 100 batch: 0.571881
Train loss on 150 batch: 0.499536
Train loss on 200 batch: 0.609684
Train loss on 250 batch: 0.553270
: Epoch: 56 | Training Loss: 0.566265 | Val. Loss: 0.659797 | Val. Kappa Score: 0.7756 | LR: 0.000655 | Estimated time: 65.55
Train loss on 50 batch: 0.553209
Train loss on 100 batch: 0.636493
Train loss on 150 batch: 0.543222
Train loss on 200 batch: 0.538428
Train loss on 250 batch: 0.627478
: Epoch: 57 | Training Loss: 0.598371 | Val. Loss: 0.569629 | Val. Kappa Score: 0.7761 | LR: 0.000697 | Estimated time: 65.35
Train loss on 50 batch: 0.726291
Train loss on 100 batch: 0.636533
Train loss on 150 batch: 0.693215
Train loss on 200 batch: 0.543751
Train loss on 250 batch: 0.557871
: Epoch: 58 | Training Loss: 0.633700 | Val. Loss: 0.626073 | Val. Kappa Score: 0.7764 | LR: 0.000737 | Estimated time: 65.50
Train loss on 50 batch: 0.627951
Train loss on 100 batch: 0.652353
Train loss on 150 batch: 0.552156
Train loss on 200 batch: 0.524048
Train loss on 250 batch: 0.652135
: Epoch: 59 | Training Loss: 0.607180 | Val. Loss: 0.655539 | Val. Kappa Score: 0.7765 | LR: 0.000775 | Estimated time: 65.35
Train loss on 50 batch: 0.710064
Train loss on 100 batch: 0.552458
Train loss on 150 batch: 0.523190
Train loss on 200 batch: 0.565976
Train loss on 250 batch: 0.579738
: Epoch: 60 | Training Loss: 0.590336 | Val. Loss: 0.630179 | Val. Kappa Score: 0.7765 | LR: 0.000812 | Estimated time: 65.52
Train loss on 50 batch: 0.667123
Train loss on 100 batch: 0.648405
Train loss on 150 batch: 0.653703
Train loss on 200 batch: 0.619154
Train loss on 250 batch: 0.533873
: Epoch: 61 | Training Loss: 0.612394 | Val. Loss: 0.519760 | Val. Kappa Score: 0.7771 | LR: 0.000846 | Estimated time: 65.50
Train loss on 50 batch: 0.594866
Train loss on 100 batch: 0.629232
Train loss on 150 batch: 0.533573
Train loss on 200 batch: 0.559481
Train loss on 250 batch: 0.644484
: Epoch: 62 | Training Loss: 0.605427 | Val. Loss: 0.579205 | Val. Kappa Score: 0.7774 | LR: 0.000877 | Estimated time: 65.24
Train loss on 50 batch: 0.608563
Train loss on 100 batch: 0.647395
Train loss on 150 batch: 0.589579
Train loss on 200 batch: 0.599534
Train loss on 250 batch: 0.636755
: Epoch: 63 | Training Loss: 0.598470 | Val. Loss: 0.518088 | Val. Kappa Score: 0.7781 | LR: 0.000905 | Estimated time: 65.25
Train loss on 50 batch: 0.561347
Train loss on 100 batch: 0.544265
Train loss on 150 batch: 0.587175
Train loss on 200 batch: 0.655944
Train loss on 250 batch: 0.577229
: Epoch: 64 | Training Loss: 0.583457 | Val. Loss: 0.689379 | Val. Kappa Score: 0.7786 | LR: 0.000929 | Estimated time: 65.44
Train loss on 50 batch: 0.737458
Train loss on 100 batch: 0.657540
Train loss on 150 batch: 0.555147
Train loss on 200 batch: 0.675204
Train loss on 250 batch: 0.640855
: Epoch: 65 | Training Loss: 0.675926 | Val. Loss: 0.694675 | Val. Kappa Score: 0.7779 | LR: 0.000950 | Estimated time: 65.35
Train loss on 50 batch: 0.726093
Train loss on 100 batch: 0.673703
Train loss on 150 batch: 0.635775
Train loss on 200 batch: 0.623772
Train loss on 250 batch: 0.548551
: Epoch: 66 | Training Loss: 0.647632 | Val. Loss: 0.810667 | Val. Kappa Score: 0.7777 | LR: 0.000968 | Estimated time: 65.31
Train loss on 50 batch: 0.798158
Train loss on 100 batch: 0.667405
Train loss on 150 batch: 0.613032
Train loss on 200 batch: 0.590275
Train loss on 250 batch: 0.622184
: Epoch: 67 | Training Loss: 0.680766 | Val. Loss: 0.539014 | Val. Kappa Score: 0.7780 | LR: 0.000982 | Estimated time: 65.22
Train loss on 50 batch: 0.726691
Train loss on 100 batch: 0.604117
Train loss on 150 batch: 0.604640
Train loss on 200 batch: 0.602958
Train loss on 250 batch: 0.622823
: Epoch: 68 | Training Loss: 0.620670 | Val. Loss: 0.715616 | Val. Kappa Score: 0.7779 | LR: 0.000992 | Estimated time: 65.23
Train loss on 50 batch: 0.569523
Train loss on 100 batch: 0.572639
Train loss on 150 batch: 0.536266
Train loss on 200 batch: 0.597983
Train loss on 250 batch: 0.625974
: Epoch: 69 | Training Loss: 0.582571 | Val. Loss: 0.585337 | Val. Kappa Score: 0.7780 | LR: 0.000998 | Estimated time: 65.31
Train loss on 50 batch: 0.601668
Train loss on 100 batch: 0.564068
Train loss on 150 batch: 0.643375
Train loss on 200 batch: 0.613774
Train loss on 250 batch: 0.542525
: Epoch: 70 | Training Loss: 0.589248 | Val. Loss: 0.609109 | Val. Kappa Score: 0.7779 | LR: 0.001000 | Estimated time: 65.25
Train loss on 50 batch: 0.630378
Train loss on 100 batch: 0.501699
Train loss on 150 batch: 0.574089
Train loss on 200 batch: 0.521514
Train loss on 250 batch: 0.609795
: Epoch: 71 | Training Loss: 0.573628 | Val. Loss: 0.695235 | Val. Kappa Score: 0.7779 | LR: 0.000998 | Estimated time: 65.33
Train loss on 50 batch: 0.545302
Train loss on 100 batch: 0.624665
Train loss on 150 batch: 0.586198
Train loss on 200 batch: 0.603829
Train loss on 250 batch: 0.532998
: Epoch: 72 | Training Loss: 0.567469 | Val. Loss: 0.803540 | Val. Kappa Score: 0.7772 | LR: 0.000992 | Estimated time: 65.28
Train loss on 50 batch: 0.541226
Train loss on 100 batch: 0.534878
Train loss on 150 batch: 0.593678
Train loss on 200 batch: 0.661610
Train loss on 250 batch: 0.701066
: Epoch: 73 | Training Loss: 0.628663 | Val. Loss: 0.825354 | Val. Kappa Score: 0.7764 | LR: 0.000982 | Estimated time: 65.11
Train loss on 50 batch: 0.702567
Train loss on 100 batch: 0.694017
Train loss on 150 batch: 0.570052
Train loss on 200 batch: 0.586629
Train loss on 250 batch: 0.538829
: Epoch: 74 | Training Loss: 0.637417 | Val. Loss: 0.644199 | Val. Kappa Score: 0.7762 | LR: 0.000968 | Estimated time: 65.13
Train loss on 50 batch: 0.671227
Train loss on 100 batch: 0.521887
Train loss on 150 batch: 0.612816
Train loss on 200 batch: 0.543550
Train loss on 250 batch: 0.533777
: Epoch: 75 | Training Loss: 0.576852 | Val. Loss: 0.534432 | Val. Kappa Score: 0.7768 | LR: 0.000950 | Estimated time: 65.22
Train loss on 50 batch: 0.552152
Train loss on 100 batch: 0.509947
Train loss on 150 batch: 0.589761
Train loss on 200 batch: 0.541120
Train loss on 250 batch: 0.511417
: Epoch: 76 | Training Loss: 0.535240 | Val. Loss: 0.840347 | Val. Kappa Score: 0.7763 | LR: 0.000929 | Estimated time: 65.20
Train loss on 50 batch: 0.502038
Train loss on 100 batch: 0.547961
Train loss on 150 batch: 0.578206
Train loss on 200 batch: 0.480187
Train loss on 250 batch: 0.570195
: Epoch: 77 | Training Loss: 0.540260 | Val. Loss: 0.727577 | Val. Kappa Score: 0.7764 | LR: 0.000905 | Estimated time: 65.15
Train loss on 50 batch: 0.496090
Train loss on 100 batch: 0.474614
Train loss on 150 batch: 0.520375
Train loss on 200 batch: 0.538000
Train loss on 250 batch: 0.562526
: Epoch: 78 | Training Loss: 0.509486 | Val. Loss: 0.608592 | Val. Kappa Score: 0.7761 | LR: 0.000877 | Estimated time: 65.10
Train loss on 50 batch: 0.538632
Train loss on 100 batch: 0.523230
Train loss on 150 batch: 0.556134
Train loss on 200 batch: 0.500521
Train loss on 250 batch: 0.518272
: Epoch: 79 | Training Loss: 0.526046 | Val. Loss: 0.727758 | Val. Kappa Score: 0.7761 | LR: 0.000846 | Estimated time: 64.96
Train loss on 50 batch: 0.532542
Train loss on 100 batch: 0.496084
Train loss on 150 batch: 0.596594
Train loss on 200 batch: 0.531394
Train loss on 250 batch: 0.464017
: Epoch: 80 | Training Loss: 0.533162 | Val. Loss: 0.683972 | Val. Kappa Score: 0.7762 | LR: 0.000812 | Estimated time: 65.09
Train loss on 50 batch: 0.618415
Train loss on 100 batch: 0.613252
Train loss on 150 batch: 0.551523
Train loss on 200 batch: 0.633199
Train loss on 250 batch: 0.540212
: Epoch: 81 | Training Loss: 0.574403 | Val. Loss: 0.546686 | Val. Kappa Score: 0.7768 | LR: 0.000775 | Estimated time: 65.11
Train loss on 50 batch: 0.556332
Train loss on 100 batch: 0.463998
Train loss on 150 batch: 0.513789
Train loss on 200 batch: 0.549081
Train loss on 250 batch: 0.446477
: Epoch: 82 | Training Loss: 0.521638 | Val. Loss: 0.662476 | Val. Kappa Score: 0.7771 | LR: 0.000737 | Estimated time: 65.09
Train loss on 50 batch: 0.521588
Train loss on 100 batch: 0.461060
Train loss on 150 batch: 0.540123
Train loss on 200 batch: 0.484394
Train loss on 250 batch: 0.525287
: Epoch: 83 | Training Loss: 0.500442 | Val. Loss: 0.536629 | Val. Kappa Score: 0.7775 | LR: 0.000697 | Estimated time: 65.03
Train loss on 50 batch: 0.509294
Train loss on 100 batch: 0.441943
Train loss on 150 batch: 0.435009
Train loss on 200 batch: 0.472993
Train loss on 250 batch: 0.430772
: Epoch: 84 | Training Loss: 0.512612 | Val. Loss: 0.638797 | Val. Kappa Score: 0.7775 | LR: 0.000655 | Estimated time: 65.12
Train loss on 50 batch: 0.585280
Train loss on 100 batch: 0.559014
Train loss on 150 batch: 0.452240
Train loss on 200 batch: 0.445769
Train loss on 250 batch: 0.542842
: Epoch: 85 | Training Loss: 0.517221 | Val. Loss: 0.523909 | Val. Kappa Score: 0.7779 | LR: 0.000611 | Estimated time: 64.96
Train loss on 50 batch: 0.492082
Train loss on 100 batch: 0.500139
Train loss on 150 batch: 0.528719
Train loss on 200 batch: 0.465111
Train loss on 250 batch: 0.474221
: Epoch: 86 | Training Loss: 0.509222 | Val. Loss: 0.541644 | Val. Kappa Score: 0.7780 | LR: 0.000567 | Estimated time: 64.89
Train loss on 50 batch: 0.491300
Train loss on 100 batch: 0.487972
Train loss on 150 batch: 0.462208
Train loss on 200 batch: 0.468322
Train loss on 250 batch: 0.475256
: Epoch: 87 | Training Loss: 0.464196 | Val. Loss: 0.522034 | Val. Kappa Score: 0.7785 | LR: 0.000522 | Estimated time: 65.11
Train loss on 50 batch: 0.450867
Train loss on 100 batch: 0.455872
Train loss on 150 batch: 0.470442
Train loss on 200 batch: 0.442328
Train loss on 250 batch: 0.437554
: Epoch: 88 | Training Loss: 0.462417 | Val. Loss: 0.499726 | Val. Kappa Score: 0.7791 | LR: 0.000478 | Estimated time: 65.10
Train loss on 50 batch: 0.530920
Train loss on 100 batch: 0.423025
Train loss on 150 batch: 0.387634
Train loss on 200 batch: 0.438281
Train loss on 250 batch: 0.408554
: Epoch: 89 | Training Loss: 0.439279 | Val. Loss: 0.638747 | Val. Kappa Score: 0.7794 | LR: 0.000433 | Estimated time: 65.00
Train loss on 50 batch: 0.443341
Train loss on 100 batch: 0.414898
Train loss on 150 batch: 0.486248
Train loss on 200 batch: 0.399677
Train loss on 250 batch: 0.391071
: Epoch: 90 | Training Loss: 0.427204 | Val. Loss: 0.520247 | Val. Kappa Score: 0.7799 | LR: 0.000389 | Estimated time: 65.12
Train loss on 50 batch: 0.470295
Train loss on 100 batch: 0.364864
Train loss on 150 batch: 0.385670
Train loss on 200 batch: 0.428260
Train loss on 250 batch: 0.437664
: Epoch: 91 | Training Loss: 0.448869 | Val. Loss: 0.489777 | Val. Kappa Score: 0.7804 | LR: 0.000345 | Estimated time: 65.07
Train loss on 50 batch: 0.442167
Train loss on 100 batch: 0.469999
Train loss on 150 batch: 0.407341
Train loss on 200 batch: 0.385846
Train loss on 250 batch: 0.376181
: Epoch: 92 | Training Loss: 0.416757 | Val. Loss: 0.500388 | Val. Kappa Score: 0.7809 | LR: 0.000303 | Estimated time: 65.24
Train loss on 50 batch: 0.398420
Train loss on 100 batch: 0.407614
Train loss on 150 batch: 0.412090
Train loss on 200 batch: 0.428357
Train loss on 250 batch: 0.410023
: Epoch: 93 | Training Loss: 0.407175 | Val. Loss: 0.506209 | Val. Kappa Score: 0.7813 | LR: 0.000263 | Estimated time: 65.07
Train loss on 50 batch: 0.377086
Train loss on 100 batch: 0.438731
Train loss on 150 batch: 0.387746
Train loss on 200 batch: 0.409401
Train loss on 250 batch: 0.377652
: Epoch: 94 | Training Loss: 0.415756 | Val. Loss: 0.560062 | Val. Kappa Score: 0.7817 | LR: 0.000225 | Estimated time: 65.04
Train loss on 50 batch: 0.414689
Train loss on 100 batch: 0.380389
Train loss on 150 batch: 0.375459
Train loss on 200 batch: 0.358449
Train loss on 250 batch: 0.399020
: Epoch: 95 | Training Loss: 0.409923 | Val. Loss: 0.485849 | Val. Kappa Score: 0.7823 | LR: 0.000188 | Estimated time: 65.30
Train loss on 50 batch: 0.378112
Train loss on 100 batch: 0.376834
Train loss on 150 batch: 0.375261
Train loss on 200 batch: 0.379451
Train loss on 250 batch: 0.366257
: Epoch: 96 | Training Loss: 0.390424 | Val. Loss: 0.532411 | Val. Kappa Score: 0.7828 | LR: 0.000154 | Estimated time: 64.98
Train loss on 50 batch: 0.373991
Train loss on 100 batch: 0.381096
Train loss on 150 batch: 0.349461
Train loss on 200 batch: 0.385187
Train loss on 250 batch: 0.406332
: Epoch: 97 | Training Loss: 0.373378 | Val. Loss: 0.488118 | Val. Kappa Score: 0.7833 | LR: 0.000123 | Estimated time: 65.00
Train loss on 50 batch: 0.332906
Train loss on 100 batch: 0.411559
Train loss on 150 batch: 0.367496
Train loss on 200 batch: 0.332271
Train loss on 250 batch: 0.381752
: Epoch: 98 | Training Loss: 0.356507 | Val. Loss: 0.499033 | Val. Kappa Score: 0.7837 | LR: 0.000095 | Estimated time: 65.00
Train loss on 50 batch: 0.337858
Train loss on 100 batch: 0.390290
Train loss on 150 batch: 0.344816
Train loss on 200 batch: 0.355414
Train loss on 250 batch: 0.382368
: Epoch: 99 | Training Loss: 0.368089 | Val. Loss: 0.541219 | Val. Kappa Score: 0.7841 | LR: 0.000071 | Estimated time: 64.96
Train loss on 50 batch: 0.357318
Train loss on 100 batch: 0.385694
Train loss on 150 batch: 0.317592
Train loss on 200 batch: 0.355410
Train loss on 250 batch: 0.331308
: Epoch: 100 | Training Loss: 0.345898 | Val. Loss: 0.497470 | Val. Kappa Score: 0.7846 | LR: 0.000050 | Estimated time: 64.98
Train loss on 50 batch: 0.410617
Train loss on 100 batch: 0.342400
Train loss on 150 batch: 0.308119
Train loss on 200 batch: 0.335687
Train loss on 250 batch: 0.409472
best-train-loss: 0.362466
best-valid-loss: 0.468385
best-kappa: 0.7851
: Epoch: 101 | Training Loss: 0.362466 | Val. Loss: 0.468385 | Val. Kappa Score: 0.7851 | LR: 0.000032 | Estimated time: 64.99
Train loss on 50 batch: 0.302817
Train loss on 100 batch: 0.387400
Train loss on 150 batch: 0.320776
Train loss on 200 batch: 0.376705
Train loss on 250 batch: 0.333191
: Epoch: 102 | Training Loss: 0.344110 | Val. Loss: 0.475995 | Val. Kappa Score: 0.7857 | LR: 0.000018 | Estimated time: 64.99
Train loss on 50 batch: 0.330874
Train loss on 100 batch: 0.330164
Train loss on 150 batch: 0.318968
Train loss on 200 batch: 0.379014
Train loss on 250 batch: 0.356692
: Epoch: 103 | Training Loss: 0.349572 | Val. Loss: 0.485195 | Val. Kappa Score: 0.7862 | LR: 0.000008 | Estimated time: 64.92
Train loss on 50 batch: 0.322808
Train loss on 100 batch: 0.330036
Train loss on 150 batch: 0.329677
Train loss on 200 batch: 0.294286
Train loss on 250 batch: 0.330896
: Epoch: 104 | Training Loss: 0.331744 | Val. Loss: 0.475036 | Val. Kappa Score: 0.7867 | LR: 0.000002 | Estimated time: 65.03
Train loss on 50 batch: 0.322959
Train loss on 100 batch: 0.349635
Train loss on 150 batch: 0.383736
Train loss on 200 batch: 0.338717
Train loss on 250 batch: 0.320476
: Epoch: 105 | Training Loss: 0.336643 | Val. Loss: 0.486294 | Val. Kappa Score: 0.7873 | LR: 0.000000 | Estimated time: 64.94
Train loss on 50 batch: 0.308389
Train loss on 100 batch: 0.318659
Train loss on 150 batch: 0.339332
Train loss on 200 batch: 0.338699
Train loss on 250 batch: 0.372339
best-train-loss: 0.341528
best-valid-loss: 0.462659
best-kappa: 0.7877
: Epoch: 106 | Training Loss: 0.341528 | Val. Loss: 0.462659 | Val. Kappa Score: 0.7877 | LR: 0.000002 | Estimated time: 64.92
Train loss on 50 batch: 0.330905
Train loss on 100 batch: 0.295173
Train loss on 150 batch: 0.370390
Train loss on 200 batch: 0.338720
Train loss on 250 batch: 0.371865
: Epoch: 107 | Training Loss: 0.337984 | Val. Loss: 0.470043 | Val. Kappa Score: 0.7881 | LR: 0.000008 | Estimated time: 65.16
Train loss on 50 batch: 0.363109
Train loss on 100 batch: 0.377429
Train loss on 150 batch: 0.326664
Train loss on 200 batch: 0.309647
Train loss on 250 batch: 0.324696
: Epoch: 108 | Training Loss: 0.341597 | Val. Loss: 0.495529 | Val. Kappa Score: 0.7886 | LR: 0.000018 | Estimated time: 65.06
Train loss on 50 batch: 0.316272
Train loss on 100 batch: 0.365300
Train loss on 150 batch: 0.328086
Train loss on 200 batch: 0.348794
Train loss on 250 batch: 0.310165
: Epoch: 109 | Training Loss: 0.329338 | Val. Loss: 0.480675 | Val. Kappa Score: 0.7890 | LR: 0.000032 | Estimated time: 64.97
Train loss on 50 batch: 0.342631
Train loss on 100 batch: 0.325526
Train loss on 150 batch: 0.330042
Train loss on 200 batch: 0.337555
Train loss on 250 batch: 0.329204
: Epoch: 110 | Training Loss: 0.341140 | Val. Loss: 0.476412 | Val. Kappa Score: 0.7896 | LR: 0.000050 | Estimated time: 65.08
Train loss on 50 batch: 0.296183
Train loss on 100 batch: 0.327969
Train loss on 150 batch: 0.351884
Train loss on 200 batch: 0.360037
Train loss on 250 batch: 0.350580
: Epoch: 111 | Training Loss: 0.342725 | Val. Loss: 0.489599 | Val. Kappa Score: 0.7899 | LR: 0.000071 | Estimated time: 64.96
Train loss on 50 batch: 0.319406
Train loss on 100 batch: 0.347006
Train loss on 150 batch: 0.385615
Train loss on 200 batch: 0.358777
Train loss on 250 batch: 0.340014
: Epoch: 112 | Training Loss: 0.358527 | Val. Loss: 0.463497 | Val. Kappa Score: 0.7904 | LR: 0.000095 | Estimated time: 64.97
Train loss on 50 batch: 0.356070
Train loss on 100 batch: 0.341736
Train loss on 150 batch: 0.365993
Train loss on 200 batch: 0.371035
Train loss on 250 batch: 0.336318
: Epoch: 113 | Training Loss: 0.364395 | Val. Loss: 0.472522 | Val. Kappa Score: 0.7908 | LR: 0.000123 | Estimated time: 65.02
Train loss on 50 batch: 0.332499
Train loss on 100 batch: 0.364758
Train loss on 150 batch: 0.321272
Train loss on 200 batch: 0.353602
Train loss on 250 batch: 0.367795
: Epoch: 114 | Training Loss: 0.343959 | Val. Loss: 0.483670 | Val. Kappa Score: 0.7912 | LR: 0.000154 | Estimated time: 65.11
Train loss on 50 batch: 0.325370
Train loss on 100 batch: 0.349508
Train loss on 150 batch: 0.367710
Train loss on 200 batch: 0.318785
Train loss on 250 batch: 0.358174
: Epoch: 115 | Training Loss: 0.346085 | Val. Loss: 0.468003 | Val. Kappa Score: 0.7917 | LR: 0.000188 | Estimated time: 65.25
Train loss on 50 batch: 0.339732
Train loss on 100 batch: 0.330592
Train loss on 150 batch: 0.371212
Train loss on 200 batch: 0.373327
Train loss on 250 batch: 0.359771
: Epoch: 116 | Training Loss: 0.349251 | Val. Loss: 0.464004 | Val. Kappa Score: 0.7921 | LR: 0.000225 | Estimated time: 65.04
Train loss on 50 batch: 0.325482
Train loss on 100 batch: 0.337007
Train loss on 150 batch: 0.346695
Train loss on 200 batch: 0.348845
Train loss on 250 batch: 0.363568
: Epoch: 117 | Training Loss: 0.373634 | Val. Loss: 0.492261 | Val. Kappa Score: 0.7925 | LR: 0.000263 | Estimated time: 65.31
Train loss on 50 batch: 0.301277
Train loss on 100 batch: 0.343956
Train loss on 150 batch: 0.321865
Train loss on 200 batch: 0.386158
Train loss on 250 batch: 0.385764
: Epoch: 118 | Training Loss: 0.344376 | Val. Loss: 0.481622 | Val. Kappa Score: 0.7929 | LR: 0.000303 | Estimated time: 65.16
Train loss on 50 batch: 0.337550
Train loss on 100 batch: 0.325814
Train loss on 150 batch: 0.365527
Train loss on 200 batch: 0.393424
Train loss on 250 batch: 0.368691
: Epoch: 119 | Training Loss: 0.371312 | Val. Loss: 0.519204 | Val. Kappa Score: 0.7931 | LR: 0.000345 | Estimated time: 65.14
Train loss on 50 batch: 0.542400
Train loss on 100 batch: 0.460484
Train loss on 150 batch: 0.396416
Train loss on 200 batch: 0.400659
Train loss on 250 batch: 0.445799
: Epoch: 120 | Training Loss: 0.457377 | Val. Loss: 0.529479 | Val. Kappa Score: 0.7935 | LR: 0.000389 | Estimated time: 65.02
Train loss on 50 batch: 0.374096
Train loss on 100 batch: 0.367072
Train loss on 150 batch: 0.425010
Train loss on 200 batch: 0.416144
Train loss on 250 batch: 0.394681
: Epoch: 121 | Training Loss: 0.433891 | Val. Loss: 0.490108 | Val. Kappa Score: 0.7937 | LR: 0.000433 | Estimated time: 65.13
Train loss on 50 batch: 0.377547
Train loss on 100 batch: 0.352937
Train loss on 150 batch: 0.391263
Train loss on 200 batch: 0.401523
Train loss on 250 batch: 0.401426
: Epoch: 122 | Training Loss: 0.377257 | Val. Loss: 0.558748 | Val. Kappa Score: 0.7938 | LR: 0.000478 | Estimated time: 65.30
Train loss on 50 batch: 0.360731
Train loss on 100 batch: 0.426930
Train loss on 150 batch: 0.360442
Train loss on 200 batch: 0.396875
Train loss on 250 batch: 0.400047
: Epoch: 123 | Training Loss: 0.387743 | Val. Loss: 0.495923 | Val. Kappa Score: 0.7941 | LR: 0.000522 | Estimated time: 65.11
Train loss on 50 batch: 0.388324
Train loss on 100 batch: 0.371633
Train loss on 150 batch: 0.390513
Train loss on 200 batch: 0.351860
Train loss on 250 batch: 0.372286
: Epoch: 124 | Training Loss: 0.382491 | Val. Loss: 0.506946 | Val. Kappa Score: 0.7945 | LR: 0.000567 | Estimated time: 64.98
Train loss on 50 batch: 0.419544
Train loss on 100 batch: 0.414106
Train loss on 150 batch: 0.378041
Train loss on 200 batch: 0.388993
Train loss on 250 batch: 0.356407
: Epoch: 125 | Training Loss: 0.416407 | Val. Loss: 0.521081 | Val. Kappa Score: 0.7948 | LR: 0.000611 | Estimated time: 65.10
Train loss on 50 batch: 0.450652
Train loss on 100 batch: 0.413265
Train loss on 150 batch: 0.436884
Train loss on 200 batch: 0.374353
Train loss on 250 batch: 0.422742
: Epoch: 126 | Training Loss: 0.416887 | Val. Loss: 0.467512 | Val. Kappa Score: 0.7952 | LR: 0.000655 | Estimated time: 65.09
Train loss on 50 batch: 0.432914
Train loss on 100 batch: 0.414500
Train loss on 150 batch: 0.408932
Train loss on 200 batch: 0.406987
Train loss on 250 batch: 0.400362
: Epoch: 127 | Training Loss: 0.408081 | Val. Loss: 0.510422 | Val. Kappa Score: 0.7954 | LR: 0.000697 | Estimated time: 65.15
Train loss on 50 batch: 0.362007
Train loss on 100 batch: 0.430470
Train loss on 150 batch: 0.399794
Train loss on 200 batch: 0.364203
Train loss on 250 batch: 0.438193
: Epoch: 128 | Training Loss: 0.403636 | Val. Loss: 0.513736 | Val. Kappa Score: 0.7956 | LR: 0.000737 | Estimated time: 65.13
Train loss on 50 batch: 0.413615
Train loss on 100 batch: 0.375830
Train loss on 150 batch: 0.424941
Train loss on 200 batch: 0.387872
Train loss on 250 batch: 0.389151
: Epoch: 129 | Training Loss: 0.408916 | Val. Loss: 0.491485 | Val. Kappa Score: 0.7959 | LR: 0.000775 | Estimated time: 65.02
Train loss on 50 batch: 0.453833
Train loss on 100 batch: 0.438830
Train loss on 150 batch: 0.423827
Train loss on 200 batch: 0.450611
Train loss on 250 batch: 0.384415
: Epoch: 130 | Training Loss: 0.419294 | Val. Loss: 0.495001 | Val. Kappa Score: 0.7961 | LR: 0.000812 | Estimated time: 65.07
Train loss on 50 batch: 0.436986
Train loss on 100 batch: 0.411003
Train loss on 150 batch: 0.415357
Train loss on 200 batch: 0.404517
Train loss on 250 batch: 0.445920
: Epoch: 131 | Training Loss: 0.419058 | Val. Loss: 0.566453 | Val. Kappa Score: 0.7961 | LR: 0.000846 | Estimated time: 64.79
Train loss on 50 batch: 0.348174
Train loss on 100 batch: 0.417887
Train loss on 150 batch: 0.465051
Train loss on 200 batch: 0.417178
Train loss on 250 batch: 0.469657
: Epoch: 132 | Training Loss: 0.428690 | Val. Loss: 0.616576 | Val. Kappa Score: 0.7962 | LR: 0.000877 | Estimated time: 65.16
Train loss on 50 batch: 0.469655
Train loss on 100 batch: 0.435996
Train loss on 150 batch: 0.417762
Train loss on 200 batch: 0.397474
Train loss on 250 batch: 0.454641
: Epoch: 133 | Training Loss: 0.458066 | Val. Loss: 0.542395 | Val. Kappa Score: 0.7964 | LR: 0.000905 | Estimated time: 65.09
Train loss on 50 batch: 0.685905
Train loss on 100 batch: 0.583098
Train loss on 150 batch: 0.494970
Train loss on 200 batch: 0.443180
Train loss on 250 batch: 0.456104
: Epoch: 134 | Training Loss: 0.532332 | Val. Loss: 0.549028 | Val. Kappa Score: 0.7967 | LR: 0.000929 | Estimated time: 65.13
Train loss on 50 batch: 0.434993
Train loss on 100 batch: 0.459810
Train loss on 150 batch: 0.468814
Train loss on 200 batch: 0.435014
Train loss on 250 batch: 0.428852
: Epoch: 135 | Training Loss: 0.459415 | Val. Loss: 0.748800 | Val. Kappa Score: 0.7963 | LR: 0.000950 | Estimated time: 65.00
Train loss on 50 batch: 0.465933
Train loss on 100 batch: 0.459151
Train loss on 150 batch: 0.467610
Train loss on 200 batch: 0.418326
Train loss on 250 batch: 0.399431
: Epoch: 136 | Training Loss: 0.442118 | Val. Loss: 0.587388 | Val. Kappa Score: 0.7964 | LR: 0.000968 | Estimated time: 65.00
Train loss on 50 batch: 0.434070
Train loss on 100 batch: 0.444563
Train loss on 150 batch: 0.435954
Train loss on 200 batch: 0.412754
Train loss on 250 batch: 0.455526
: Epoch: 137 | Training Loss: 0.444757 | Val. Loss: 0.556192 | Val. Kappa Score: 0.7965 | LR: 0.000982 | Estimated time: 65.03
Train loss on 50 batch: 0.548641
Train loss on 100 batch: 0.505406
Train loss on 150 batch: 0.495879
Train loss on 200 batch: 0.431068
Train loss on 250 batch: 0.478686
: Epoch: 138 | Training Loss: 0.512155 | Val. Loss: 0.705339 | Val. Kappa Score: 0.7961 | LR: 0.000992 | Estimated time: 65.05
Train loss on 50 batch: 0.596035
Train loss on 100 batch: 0.511702
Train loss on 150 batch: 0.458436
Train loss on 200 batch: 0.454851
Train loss on 250 batch: 0.434439
: Epoch: 139 | Training Loss: 0.491857 | Val. Loss: 0.533803 | Val. Kappa Score: 0.7963 | LR: 0.000998 | Estimated time: 65.05
Train loss on 50 batch: 0.496286
Train loss on 100 batch: 0.461999
Train loss on 150 batch: 0.431630
Train loss on 200 batch: 0.431465
Train loss on 250 batch: 0.431561
: Epoch: 140 | Training Loss: 0.456640 | Val. Loss: 0.468460 | Val. Kappa Score: 0.7966 | LR: 0.001000 | Estimated time: 64.83
Train loss on 50 batch: 0.454241
Train loss on 100 batch: 0.413682
Train loss on 150 batch: 0.474874
Train loss on 200 batch: 0.441175
Train loss on 250 batch: 0.423828
: Epoch: 141 | Training Loss: 0.432248 | Val. Loss: 0.569357 | Val. Kappa Score: 0.7967 | LR: 0.000998 | Estimated time: 64.96
Train loss on 50 batch: 0.403197
Train loss on 100 batch: 0.391646
Train loss on 150 batch: 0.473532
Train loss on 200 batch: 0.446592
Train loss on 250 batch: 0.403362
: Epoch: 142 | Training Loss: 0.444016 | Val. Loss: 0.549244 | Val. Kappa Score: 0.7967 | LR: 0.000992 | Estimated time: 65.01
Train loss on 50 batch: 0.485753
Train loss on 100 batch: 0.412360
Train loss on 150 batch: 0.418454
Train loss on 200 batch: 0.426513
Train loss on 250 batch: 0.464429
: Epoch: 143 | Training Loss: 0.444228 | Val. Loss: 0.568044 | Val. Kappa Score: 0.7968 | LR: 0.000982 | Estimated time: 64.94
Train loss on 50 batch: 0.489879
Train loss on 100 batch: 0.456891
Train loss on 150 batch: 0.460240
Train loss on 200 batch: 0.464495
Train loss on 250 batch: 0.453991
: Epoch: 144 | Training Loss: 0.471131 | Val. Loss: 0.607213 | Val. Kappa Score: 0.7968 | LR: 0.000968 | Estimated time: 64.93
Train loss on 50 batch: 0.426999
Train loss on 100 batch: 0.551938
Train loss on 150 batch: 0.405018
Train loss on 200 batch: 0.481868
Train loss on 250 batch: 0.432727
: Epoch: 145 | Training Loss: 0.465357 | Val. Loss: 0.528262 | Val. Kappa Score: 0.7970 | LR: 0.000950 | Estimated time: 64.80
Train loss on 50 batch: 0.434187
Train loss on 100 batch: 0.473522
Train loss on 150 batch: 0.490685
Train loss on 200 batch: 0.487184
Train loss on 250 batch: 0.456937
: Epoch: 146 | Training Loss: 0.468648 | Val. Loss: 0.539569 | Val. Kappa Score: 0.7972 | LR: 0.000929 | Estimated time: 64.79
Train loss on 50 batch: 0.578581
Train loss on 100 batch: 0.447022
Train loss on 150 batch: 0.489404
Train loss on 200 batch: 0.470229
Train loss on 250 batch: 0.400797
: Epoch: 147 | Training Loss: 0.482154 | Val. Loss: 0.533687 | Val. Kappa Score: 0.7973 | LR: 0.000905 | Estimated time: 64.80
Train loss on 50 batch: 0.487215
Train loss on 100 batch: 0.528634
Train loss on 150 batch: 0.437728
Train loss on 200 batch: 0.353246
Train loss on 250 batch: 0.425396
: Epoch: 148 | Training Loss: 0.449226 | Val. Loss: 0.559832 | Val. Kappa Score: 0.7972 | LR: 0.000877 | Estimated time: 64.90
Train loss on 50 batch: 0.422994
Train loss on 100 batch: 0.416165
Train loss on 150 batch: 0.374053
Train loss on 200 batch: 0.400780
Train loss on 250 batch: 0.447461
: Epoch: 149 | Training Loss: 0.409164 | Val. Loss: 0.469174 | Val. Kappa Score: 0.7975 | LR: 0.000846 | Estimated time: 64.71
Train loss on 50 batch: 0.400507
Train loss on 100 batch: 0.427463
Train loss on 150 batch: 0.413054
Train loss on 200 batch: 0.406479
Train loss on 250 batch: 0.393467
: Epoch: 150 | Training Loss: 0.400000 | Val. Loss: 0.488930 | Val. Kappa Score: 0.7978 | LR: 0.000812 | Estimated time: 64.76
Train loss on 50 batch: 0.420056
Train loss on 100 batch: 0.403626
Train loss on 150 batch: 0.388413
Train loss on 200 batch: 0.389081
Train loss on 250 batch: 0.397031
: Epoch: 151 | Training Loss: 0.395819 | Val. Loss: 0.555519 | Val. Kappa Score: 0.7979 | LR: 0.000775 | Estimated time: 65.00
Train loss on 50 batch: 0.394978
Train loss on 100 batch: 0.386237
Train loss on 150 batch: 0.401952
Train loss on 200 batch: 0.432950
Train loss on 250 batch: 0.392299
: Epoch: 152 | Training Loss: 0.404403 | Val. Loss: 0.569840 | Val. Kappa Score: 0.7978 | LR: 0.000737 | Estimated time: 64.94
Train loss on 50 batch: 0.378688
Train loss on 100 batch: 0.406516
Train loss on 150 batch: 0.371403
Train loss on 200 batch: 0.333086
Train loss on 250 batch: 0.447512
: Epoch: 153 | Training Loss: 0.385629 | Val. Loss: 0.489821 | Val. Kappa Score: 0.7981 | LR: 0.000697 | Estimated time: 64.84
Train loss on 50 batch: 0.412234
Train loss on 100 batch: 0.369094
Train loss on 150 batch: 0.441412
Train loss on 200 batch: 0.375677
Train loss on 250 batch: 0.368731
: Epoch: 154 | Training Loss: 0.388551 | Val. Loss: 0.497677 | Val. Kappa Score: 0.7984 | LR: 0.000655 | Estimated time: 64.99
Train loss on 50 batch: 0.371815
Train loss on 100 batch: 0.388421
Train loss on 150 batch: 0.368724
Train loss on 200 batch: 0.393228
Train loss on 250 batch: 0.380139
: Epoch: 155 | Training Loss: 0.375688 | Val. Loss: 0.498592 | Val. Kappa Score: 0.7986 | LR: 0.000611 | Estimated time: 64.98
Train loss on 50 batch: 0.345768
Train loss on 100 batch: 0.381549
Train loss on 150 batch: 0.342213
Train loss on 200 batch: 0.426055
Train loss on 250 batch: 0.406434
: Epoch: 156 | Training Loss: 0.389387 | Val. Loss: 0.540553 | Val. Kappa Score: 0.7987 | LR: 0.000567 | Estimated time: 64.91
Train loss on 50 batch: 0.377289
Train loss on 100 batch: 0.390809
Train loss on 150 batch: 0.359434
Train loss on 200 batch: 0.392830
Train loss on 250 batch: 0.348173
: Epoch: 157 | Training Loss: 0.369367 | Val. Loss: 0.478195 | Val. Kappa Score: 0.7990 | LR: 0.000522 | Estimated time: 64.89
Train loss on 50 batch: 0.377160
Train loss on 100 batch: 0.344584
Train loss on 150 batch: 0.337357
Train loss on 200 batch: 0.338345
Train loss on 250 batch: 0.358164
: Epoch: 158 | Training Loss: 0.344026 | Val. Loss: 0.504803 | Val. Kappa Score: 0.7991 | LR: 0.000478 | Estimated time: 64.84
Train loss on 50 batch: 0.306241
Train loss on 100 batch: 0.382660
Train loss on 150 batch: 0.323450
Train loss on 200 batch: 0.318604
Train loss on 250 batch: 0.356396
: Epoch: 159 | Training Loss: 0.333648 | Val. Loss: 0.505291 | Val. Kappa Score: 0.7993 | LR: 0.000433 | Estimated time: 64.72
Train loss on 50 batch: 0.345283
Train loss on 100 batch: 0.334682
Train loss on 150 batch: 0.339484
Train loss on 200 batch: 0.369850
Train loss on 250 batch: 0.327840
: Epoch: 160 | Training Loss: 0.344038 | Val. Loss: 0.479943 | Val. Kappa Score: 0.7996 | LR: 0.000389 | Estimated time: 64.96
Train loss on 50 batch: 0.337400
Train loss on 100 batch: 0.371935
Train loss on 150 batch: 0.333497
Train loss on 200 batch: 0.287387
Train loss on 250 batch: 0.334143
: Epoch: 161 | Training Loss: 0.333738 | Val. Loss: 0.483943 | Val. Kappa Score: 0.7999 | LR: 0.000345 | Estimated time: 64.95
Train loss on 50 batch: 0.323896
Train loss on 100 batch: 0.305306
Train loss on 150 batch: 0.318718
Train loss on 200 batch: 0.346902
Train loss on 250 batch: 0.326082
: Epoch: 162 | Training Loss: 0.319514 | Val. Loss: 0.514150 | Val. Kappa Score: 0.8002 | LR: 0.000303 | Estimated time: 64.76
Train loss on 50 batch: 0.325802
Train loss on 100 batch: 0.332089
Train loss on 150 batch: 0.293499
Train loss on 200 batch: 0.352963
Train loss on 250 batch: 0.309869
: Epoch: 163 | Training Loss: 0.336192 | Val. Loss: 0.512914 | Val. Kappa Score: 0.8004 | LR: 0.000263 | Estimated time: 64.64
Train loss on 50 batch: 0.350653
Train loss on 100 batch: 0.299187
Train loss on 150 batch: 0.265769
Train loss on 200 batch: 0.280129
Train loss on 250 batch: 0.295325
: Epoch: 164 | Training Loss: 0.312648 | Val. Loss: 0.495835 | Val. Kappa Score: 0.8006 | LR: 0.000225 | Estimated time: 64.78
Train loss on 50 batch: 0.267873
Train loss on 100 batch: 0.269101
Train loss on 150 batch: 0.291842
Train loss on 200 batch: 0.339163
Train loss on 250 batch: 0.323916
: Epoch: 165 | Training Loss: 0.307979 | Val. Loss: 0.480716 | Val. Kappa Score: 0.8009 | LR: 0.000188 | Estimated time: 64.79
Train loss on 50 batch: 0.300250
Train loss on 100 batch: 0.320128
Train loss on 150 batch: 0.302245
Train loss on 200 batch: 0.295074
Train loss on 250 batch: 0.304137
: Epoch: 166 | Training Loss: 0.297482 | Val. Loss: 0.476876 | Val. Kappa Score: 0.8011 | LR: 0.000154 | Estimated time: 64.75
Train loss on 50 batch: 0.283746
Train loss on 100 batch: 0.262168
Train loss on 150 batch: 0.302692
Train loss on 200 batch: 0.301908
Train loss on 250 batch: 0.260468
: Epoch: 167 | Training Loss: 0.303023 | Val. Loss: 0.477248 | Val. Kappa Score: 0.8015 | LR: 0.000123 | Estimated time: 64.85
Train loss on 50 batch: 0.271909
Train loss on 100 batch: 0.271096
Train loss on 150 batch: 0.284563
Train loss on 200 batch: 0.291619
Train loss on 250 batch: 0.274374
: Epoch: 168 | Training Loss: 0.285617 | Val. Loss: 0.504674 | Val. Kappa Score: 0.8017 | LR: 0.000095 | Estimated time: 64.73
Train loss on 50 batch: 0.306080
Train loss on 100 batch: 0.272996
Train loss on 150 batch: 0.272099
Train loss on 200 batch: 0.257012
Train loss on 250 batch: 0.285319
: Epoch: 169 | Training Loss: 0.281663 | Val. Loss: 0.466642 | Val. Kappa Score: 0.8020 | LR: 0.000071 | Estimated time: 64.74
Train loss on 50 batch: 0.268091
Train loss on 100 batch: 0.254156
Train loss on 150 batch: 0.288684
Train loss on 200 batch: 0.264599
Train loss on 250 batch: 0.265355
: Epoch: 170 | Training Loss: 0.268811 | Val. Loss: 0.475975 | Val. Kappa Score: 0.8022 | LR: 0.000050 | Estimated time: 64.60
Train loss on 50 batch: 0.265359
Train loss on 100 batch: 0.251708
Train loss on 150 batch: 0.265099
Train loss on 200 batch: 0.282658
Train loss on 250 batch: 0.269890
: Epoch: 171 | Training Loss: 0.266246 | Val. Loss: 0.478966 | Val. Kappa Score: 0.8025 | LR: 0.000032 | Estimated time: 64.77
Train loss on 50 batch: 0.291701
Train loss on 100 batch: 0.248420
Train loss on 150 batch: 0.271364
Train loss on 200 batch: 0.256512
Train loss on 250 batch: 0.226852
: Epoch: 172 | Training Loss: 0.261283 | Val. Loss: 0.477672 | Val. Kappa Score: 0.8028 | LR: 0.000018 | Estimated time: 64.87
Train loss on 50 batch: 0.289693
Train loss on 100 batch: 0.233948
Train loss on 150 batch: 0.249606
Train loss on 200 batch: 0.267439
Train loss on 250 batch: 0.244394
: Epoch: 173 | Training Loss: 0.258575 | Val. Loss: 0.470824 | Val. Kappa Score: 0.8031 | LR: 0.000008 | Estimated time: 64.70
Train loss on 50 batch: 0.251874
Train loss on 100 batch: 0.247204
Train loss on 150 batch: 0.263571
Train loss on 200 batch: 0.232194
Train loss on 250 batch: 0.254806
best-train-loss: 0.250842
best-valid-loss: 0.460341
best-kappa: 0.8034
: Epoch: 174 | Training Loss: 0.250842 | Val. Loss: 0.460341 | Val. Kappa Score: 0.8034 | LR: 0.000002 | Estimated time: 64.63
Train loss on 50 batch: 0.268651
Train loss on 100 batch: 0.243217
Train loss on 150 batch: 0.254038
Train loss on 200 batch: 0.253006
Train loss on 250 batch: 0.270642
: Epoch: 175 | Training Loss: 0.294849 | Val. Loss: 0.487305 | Val. Kappa Score: 0.8036 | LR: 0.000000 | Estimated time: 64.71
Train loss on 50 batch: 0.258466
Train loss on 100 batch: 0.274135
Train loss on 150 batch: 0.251229
Train loss on 200 batch: 0.290563
Train loss on 250 batch: 0.239359
: Epoch: 176 | Training Loss: 0.260292 | Val. Loss: 0.461324 | Val. Kappa Score: 0.8038 | LR: 0.000002 | Estimated time: 64.80
Train loss on 50 batch: 0.255722
Train loss on 100 batch: 0.271868
Train loss on 150 batch: 0.264335
Train loss on 200 batch: 0.237620
Train loss on 250 batch: 0.288554
: Epoch: 177 | Training Loss: 0.280213 | Val. Loss: 0.490205 | Val. Kappa Score: 0.8040 | LR: 0.000008 | Estimated time: 64.64
Train loss on 50 batch: 0.235553
Train loss on 100 batch: 0.251354
Train loss on 150 batch: 0.213026
Train loss on 200 batch: 0.294816
Train loss on 250 batch: 0.279275
: Epoch: 178 | Training Loss: 0.255877 | Val. Loss: 0.505852 | Val. Kappa Score: 0.8041 | LR: 0.000018 | Estimated time: 64.83
Train loss on 50 batch: 0.274701
Train loss on 100 batch: 0.241511
Train loss on 150 batch: 0.227082
Train loss on 200 batch: 0.239063
Train loss on 250 batch: 0.234631
: Epoch: 179 | Training Loss: 0.267685 | Val. Loss: 0.479815 | Val. Kappa Score: 0.8044 | LR: 0.000032 | Estimated time: 64.78
Train loss on 50 batch: 0.254522
Train loss on 100 batch: 0.255568
Train loss on 150 batch: 0.280681
Train loss on 200 batch: 0.272581
Train loss on 250 batch: 0.244545
: Epoch: 180 | Training Loss: 0.261216 | Val. Loss: 0.476640 | Val. Kappa Score: 0.8046 | LR: 0.000050 | Estimated time: 64.83
Train loss on 50 batch: 0.269913
Train loss on 100 batch: 0.295699
Train loss on 150 batch: 0.268100
Train loss on 200 batch: 0.237032
Train loss on 250 batch: 0.240291
: Epoch: 181 | Training Loss: 0.262099 | Val. Loss: 0.468990 | Val. Kappa Score: 0.8049 | LR: 0.000071 | Estimated time: 64.91
Train loss on 50 batch: 0.276429
Train loss on 100 batch: 0.243082
Train loss on 150 batch: 0.264026
Train loss on 200 batch: 0.247469
Train loss on 250 batch: 0.297826
: Epoch: 182 | Training Loss: 0.258565 | Val. Loss: 0.488826 | Val. Kappa Score: 0.8051 | LR: 0.000095 | Estimated time: 64.72
Train loss on 50 batch: 0.281360
Train loss on 100 batch: 0.266634
Train loss on 150 batch: 0.223186
Train loss on 200 batch: 0.285013
Train loss on 250 batch: 0.257504
: Epoch: 183 | Training Loss: 0.262088 | Val. Loss: 0.471373 | Val. Kappa Score: 0.8053 | LR: 0.000123 | Estimated time: 64.76
Train loss on 50 batch: 0.286763
Train loss on 100 batch: 0.243010
Train loss on 150 batch: 0.264597
Train loss on 200 batch: 0.301593
Train loss on 250 batch: 0.284378
: Epoch: 184 | Training Loss: 0.270737 | Val. Loss: 0.467557 | Val. Kappa Score: 0.8055 | LR: 0.000154 | Estimated time: 64.83
Train loss on 50 batch: 0.252572
Train loss on 100 batch: 0.216280
Train loss on 150 batch: 0.246034
Train loss on 200 batch: 0.295394
Train loss on 250 batch: 0.275388
: Epoch: 185 | Training Loss: 0.256522 | Val. Loss: 0.478325 | Val. Kappa Score: 0.8057 | LR: 0.000188 | Estimated time: 64.79
Train loss on 50 batch: 0.287374
Train loss on 100 batch: 0.252782
Train loss on 150 batch: 0.271652
Train loss on 200 batch: 0.265349
Train loss on 250 batch: 0.279308
: Epoch: 186 | Training Loss: 0.272510 | Val. Loss: 0.513304 | Val. Kappa Score: 0.8059 | LR: 0.000225 | Estimated time: 64.88
Train loss on 50 batch: 0.281907
Train loss on 100 batch: 0.316799
Train loss on 150 batch: 0.262551
Train loss on 200 batch: 0.267165
Train loss on 250 batch: 0.308692
: Epoch: 187 | Training Loss: 0.288345 | Val. Loss: 0.474967 | Val. Kappa Score: 0.8061 | LR: 0.000263 | Estimated time: 64.92
Train loss on 50 batch: 0.255166
Train loss on 100 batch: 0.299942
Train loss on 150 batch: 0.289443
Train loss on 200 batch: 0.275607
Train loss on 250 batch: 0.313156
: Epoch: 188 | Training Loss: 0.294904 | Val. Loss: 0.466727 | Val. Kappa Score: 0.8063 | LR: 0.000303 | Estimated time: 64.95
Train loss on 50 batch: 0.334326
Train loss on 100 batch: 0.316664
Train loss on 150 batch: 0.327324
Train loss on 200 batch: 0.302918
Train loss on 250 batch: 0.321871
: Epoch: 189 | Training Loss: 0.341325 | Val. Loss: 0.497843 | Val. Kappa Score: 0.8065 | LR: 0.000345 | Estimated time: 65.05
Train loss on 50 batch: 0.328642
Train loss on 100 batch: 0.280657
Train loss on 150 batch: 0.282961
Train loss on 200 batch: 0.315476
Train loss on 250 batch: 0.311022
: Epoch: 190 | Training Loss: 0.304305 | Val. Loss: 0.480297 | Val. Kappa Score: 0.8067 | LR: 0.000389 | Estimated time: 65.00
Train loss on 50 batch: 0.271003
Train loss on 100 batch: 0.313899
Train loss on 150 batch: 0.261969
Train loss on 200 batch: 0.252420
Train loss on 250 batch: 0.335750
: Epoch: 191 | Training Loss: 0.296318 | Val. Loss: 0.525751 | Val. Kappa Score: 0.8069 | LR: 0.000433 | Estimated time: 65.04
Train loss on 50 batch: 0.297636
Train loss on 100 batch: 0.262701
Train loss on 150 batch: 0.285707
Train loss on 200 batch: 0.292007
Train loss on 250 batch: 0.279651
: Epoch: 192 | Training Loss: 0.301553 | Val. Loss: 0.496718 | Val. Kappa Score: 0.8071 | LR: 0.000478 | Estimated time: 64.96
Train loss on 50 batch: 0.330342
Train loss on 100 batch: 0.297457
Train loss on 150 batch: 0.305884
Train loss on 200 batch: 0.305262
Train loss on 250 batch: 0.319713
: Epoch: 193 | Training Loss: 0.310231 | Val. Loss: 0.514591 | Val. Kappa Score: 0.8072 | LR: 0.000522 | Estimated time: 65.04
Train loss on 50 batch: 0.285799
Train loss on 100 batch: 0.349329
Train loss on 150 batch: 0.271727
Train loss on 200 batch: 0.301307
Train loss on 250 batch: 0.348973
: Epoch: 194 | Training Loss: 0.328127 | Val. Loss: 0.554205 | Val. Kappa Score: 0.8072 | LR: 0.000567 | Estimated time: 64.90
Train loss on 50 batch: 0.409399
Train loss on 100 batch: 0.342745
Train loss on 150 batch: 0.384800
Train loss on 200 batch: 0.333271
Train loss on 250 batch: 0.369937
best-train-loss: 0.372721
best-valid-loss: 0.456040
best-kappa: 0.8074
: Epoch: 195 | Training Loss: 0.372721 | Val. Loss: 0.456040 | Val. Kappa Score: 0.8074 | LR: 0.000611 | Estimated time: 64.98
Train loss on 50 batch: 0.357956
Train loss on 100 batch: 0.362933
Train loss on 150 batch: 0.366869
Train loss on 200 batch: 0.382405
Train loss on 250 batch: 0.331508
: Epoch: 196 | Training Loss: 0.355676 | Val. Loss: 0.480591 | Val. Kappa Score: 0.8075 | LR: 0.000655 | Estimated time: 65.17
Train loss on 50 batch: 0.327664
Train loss on 100 batch: 0.305539
Train loss on 150 batch: 0.326382
Train loss on 200 batch: 0.338539
Train loss on 250 batch: 0.313500
: Epoch: 197 | Training Loss: 0.319719 | Val. Loss: 0.558247 | Val. Kappa Score: 0.8076 | LR: 0.000697 | Estimated time: 64.93
Train loss on 50 batch: 0.313464
Train loss on 100 batch: 0.325431
Train loss on 150 batch: 0.290319
Train loss on 200 batch: 0.337895
Train loss on 250 batch: 0.343988
: Epoch: 198 | Training Loss: 0.333560 | Val. Loss: 0.500381 | Val. Kappa Score: 0.8077 | LR: 0.000737 | Estimated time: 64.93
Train loss on 50 batch: 0.322507
Train loss on 100 batch: 0.321745
Train loss on 150 batch: 0.368377
Train loss on 200 batch: 0.350991
Train loss on 250 batch: 0.361886
: Epoch: 199 | Training Loss: 0.357219 | Val. Loss: 0.567329 | Val. Kappa Score: 0.8076 | LR: 0.000775 | Estimated time: 64.74
Train loss on 50 batch: 0.378968
Train loss on 100 batch: 0.333361
Train loss on 150 batch: 0.312667
Train loss on 200 batch: 0.355352
Train loss on 250 batch: 0.373897
: Epoch: 200 | Training Loss: 0.341209 | Val. Loss: 0.516963 | Val. Kappa Score: 0.8077 | LR: 0.000812 | Estimated time: 64.78
Train loss on 50 batch: 0.391212
Train loss on 100 batch: 0.331302
Train loss on 150 batch: 0.331366
Train loss on 200 batch: 0.388676
Train loss on 250 batch: 0.396398
: Epoch: 201 | Training Loss: 0.365393 | Val. Loss: 0.725381 | Val. Kappa Score: 0.8074 | LR: 0.000846 | Estimated time: 64.97
Train loss on 50 batch: 0.312152
Train loss on 100 batch: 0.430613
Train loss on 150 batch: 0.489848
Train loss on 200 batch: 0.380661
Train loss on 250 batch: 0.354782
: Epoch: 202 | Training Loss: 0.397590 | Val. Loss: 0.560596 | Val. Kappa Score: 0.8074 | LR: 0.000877 | Estimated time: 64.89
Train loss on 50 batch: 0.408162
Train loss on 100 batch: 0.348696
Train loss on 150 batch: 0.343551
Train loss on 200 batch: 0.402439
Train loss on 250 batch: 0.365772
: Epoch: 203 | Training Loss: 0.366596 | Val. Loss: 0.579981 | Val. Kappa Score: 0.8074 | LR: 0.000905 | Estimated time: 64.83
Train loss on 50 batch: 0.318203
Train loss on 100 batch: 0.347526
Train loss on 150 batch: 0.364717
Train loss on 200 batch: 0.395260
Train loss on 250 batch: 0.305410
: Epoch: 204 | Training Loss: 0.347286 | Val. Loss: 0.482415 | Val. Kappa Score: 0.8076 | LR: 0.000929 | Estimated time: 64.88
Train loss on 50 batch: 0.370080
Train loss on 100 batch: 0.392582
Train loss on 150 batch: 0.339362
Train loss on 200 batch: 0.355558
Train loss on 250 batch: 0.344253
: Epoch: 205 | Training Loss: 0.360475 | Val. Loss: 0.486428 | Val. Kappa Score: 0.8077 | LR: 0.000950 | Estimated time: 64.83
Train loss on 50 batch: 0.365247
Train loss on 100 batch: 0.322927
Train loss on 150 batch: 0.351450
Train loss on 200 batch: 0.418395
Train loss on 250 batch: 0.396346
: Epoch: 206 | Training Loss: 0.372728 | Val. Loss: 0.587157 | Val. Kappa Score: 0.8077 | LR: 0.000968 | Estimated time: 64.75
Train loss on 50 batch: 0.378248
Train loss on 100 batch: 0.333746
Train loss on 150 batch: 0.429828
Train loss on 200 batch: 0.377450
Train loss on 250 batch: 0.385763
: Epoch: 207 | Training Loss: 0.380767 | Val. Loss: 0.536864 | Val. Kappa Score: 0.8078 | LR: 0.000982 | Estimated time: 64.86
Train loss on 50 batch: 0.389450
Train loss on 100 batch: 0.380005
Train loss on 150 batch: 0.366884
Train loss on 200 batch: 0.398483
Train loss on 250 batch: 0.397696
: Epoch: 208 | Training Loss: 0.407328 | Val. Loss: 0.672893 | Val. Kappa Score: 0.8075 | LR: 0.000992 | Estimated time: 65.07
Train loss on 50 batch: 0.713826
Train loss on 100 batch: 0.570325
Train loss on 150 batch: 0.497489
Train loss on 200 batch: 0.427440
Train loss on 250 batch: 0.469069
: Epoch: 209 | Training Loss: 0.530015 | Val. Loss: 0.546078 | Val. Kappa Score: 0.8076 | LR: 0.000998 | Estimated time: 64.70
Train loss on 50 batch: 0.399296
Train loss on 100 batch: 0.426953
Train loss on 150 batch: 0.419197
Train loss on 200 batch: 0.403544
Train loss on 250 batch: 0.469586
: Epoch: 210 | Training Loss: 0.426937 | Val. Loss: 0.473098 | Val. Kappa Score: 0.8077 | LR: 0.001000 | Estimated time: 64.81
Train loss on 50 batch: 0.430030
Train loss on 100 batch: 0.424162
Train loss on 150 batch: 0.394047
Train loss on 200 batch: 0.374769
Train loss on 250 batch: 0.427530
: Epoch: 211 | Training Loss: 0.426109 | Val. Loss: 0.534727 | Val. Kappa Score: 0.8077 | LR: 0.000998 | Estimated time: 64.72
Train loss on 50 batch: 0.464942
Train loss on 100 batch: 0.406344
Train loss on 150 batch: 0.406262
Train loss on 200 batch: 0.474537
Train loss on 250 batch: 0.392761
: Epoch: 212 | Training Loss: 0.416115 | Val. Loss: 0.492634 | Val. Kappa Score: 0.8078 | LR: 0.000992 | Estimated time: 64.89
Train loss on 50 batch: 0.394778
Train loss on 100 batch: 0.373235
Train loss on 150 batch: 0.390257
Train loss on 200 batch: 0.433727
Train loss on 250 batch: 0.376011
: Epoch: 213 | Training Loss: 0.390218 | Val. Loss: 0.485214 | Val. Kappa Score: 0.8079 | LR: 0.000982 | Estimated time: 64.85
Train loss on 50 batch: 0.371162
Train loss on 100 batch: 0.379408
Train loss on 150 batch: 0.368351
Train loss on 200 batch: 0.349477
Train loss on 250 batch: 0.427661
: Epoch: 214 | Training Loss: 0.377929 | Val. Loss: 0.528486 | Val. Kappa Score: 0.8080 | LR: 0.000968 | Estimated time: 64.74
Train loss on 50 batch: 0.364234
Train loss on 100 batch: 0.379315
Train loss on 150 batch: 0.381235
Train loss on 200 batch: 0.351750
Train loss on 250 batch: 0.341722
: Epoch: 215 | Training Loss: 0.369417 | Val. Loss: 0.571777 | Val. Kappa Score: 0.8080 | LR: 0.000950 | Estimated time: 65.01
Train loss on 50 batch: 0.369970
Train loss on 100 batch: 0.382276
Train loss on 150 batch: 0.349121
Train loss on 200 batch: 0.387869
Train loss on 250 batch: 0.379454
: Epoch: 216 | Training Loss: 0.365591 | Val. Loss: 0.512986 | Val. Kappa Score: 0.8080 | LR: 0.000929 | Estimated time: 64.84
Train loss on 50 batch: 0.371481
Train loss on 100 batch: 0.372220
Train loss on 150 batch: 0.356755
Train loss on 200 batch: 0.382183
Train loss on 250 batch: 0.338108
: Epoch: 217 | Training Loss: 0.367613 | Val. Loss: 0.553311 | Val. Kappa Score: 0.8081 | LR: 0.000905 | Estimated time: 64.78
Train loss on 50 batch: 0.394401
Train loss on 100 batch: 0.326110
Train loss on 150 batch: 0.357493
Train loss on 200 batch: 0.352315
Train loss on 250 batch: 0.384009
: Epoch: 218 | Training Loss: 0.376832 | Val. Loss: 0.533674 | Val. Kappa Score: 0.8081 | LR: 0.000877 | Estimated time: 64.95
Train loss on 50 batch: 0.319254
Train loss on 100 batch: 0.331333
Train loss on 150 batch: 0.314204
Train loss on 200 batch: 0.366819
Train loss on 250 batch: 0.387124
: Epoch: 219 | Training Loss: 0.359131 | Val. Loss: 0.684914 | Val. Kappa Score: 0.8080 | LR: 0.000846 | Estimated time: 64.77
Train loss on 50 batch: 0.349072
Train loss on 100 batch: 0.344124
Train loss on 150 batch: 0.341349
Train loss on 200 batch: 0.350027
Train loss on 250 batch: 0.370812
: Epoch: 220 | Training Loss: 0.360907 | Val. Loss: 0.577879 | Val. Kappa Score: 0.8080 | LR: 0.000812 | Estimated time: 64.71
Train loss on 50 batch: 0.500146
Train loss on 100 batch: 0.429912
Train loss on 150 batch: 0.400519
Train loss on 200 batch: 0.359465
Train loss on 250 batch: 0.382052
: Epoch: 221 | Training Loss: 0.407887 | Val. Loss: 0.512671 | Val. Kappa Score: 0.8081 | LR: 0.000775 | Estimated time: 64.64
Train loss on 50 batch: 0.383493
Train loss on 100 batch: 0.355955
Train loss on 150 batch: 0.359463
Train loss on 200 batch: 0.319489
Train loss on 250 batch: 0.303604
: Epoch: 222 | Training Loss: 0.343123 | Val. Loss: 0.469225 | Val. Kappa Score: 0.8083 | LR: 0.000737 | Estimated time: 64.80
Train loss on 50 batch: 0.316532
Train loss on 100 batch: 0.362743
Train loss on 150 batch: 0.289207
Train loss on 200 batch: 0.355928
Train loss on 250 batch: 0.312195
: Epoch: 223 | Training Loss: 0.323106 | Val. Loss: 0.588561 | Val. Kappa Score: 0.8082 | LR: 0.000697 | Estimated time: 64.66
Train loss on 50 batch: 0.359136
Train loss on 100 batch: 0.330324
Train loss on 150 batch: 0.316322
Train loss on 200 batch: 0.348579
Train loss on 250 batch: 0.378388
: Epoch: 224 | Training Loss: 0.351012 | Val. Loss: 0.499186 | Val. Kappa Score: 0.8083 | LR: 0.000655 | Estimated time: 64.65
Train loss on 50 batch: 0.366197
Train loss on 100 batch: 0.260540
Train loss on 150 batch: 0.348000
Train loss on 200 batch: 0.366813
Train loss on 250 batch: 0.366848
: Epoch: 225 | Training Loss: 0.355016 | Val. Loss: 0.541147 | Val. Kappa Score: 0.8084 | LR: 0.000611 | Estimated time: 64.66
Train loss on 50 batch: 0.314350
Train loss on 100 batch: 0.349968
Train loss on 150 batch: 0.344010
Train loss on 200 batch: 0.346352
Train loss on 250 batch: 0.339459
: Epoch: 226 | Training Loss: 0.330503 | Val. Loss: 0.484100 | Val. Kappa Score: 0.8086 | LR: 0.000567 | Estimated time: 64.79
Train loss on 50 batch: 0.372163
Train loss on 100 batch: 0.261424
Train loss on 150 batch: 0.312426
Train loss on 200 batch: 0.309771
Train loss on 250 batch: 0.313849
: Epoch: 227 | Training Loss: 0.328889 | Val. Loss: 0.543691 | Val. Kappa Score: 0.8087 | LR: 0.000522 | Estimated time: 64.74
Train loss on 50 batch: 0.346955
Train loss on 100 batch: 0.324179
Train loss on 150 batch: 0.317105
Train loss on 200 batch: 0.267583
Train loss on 250 batch: 0.330767
: Epoch: 228 | Training Loss: 0.314272 | Val. Loss: 0.500962 | Val. Kappa Score: 0.8089 | LR: 0.000478 | Estimated time: 64.83
Train loss on 50 batch: 0.304692
Train loss on 100 batch: 0.289468
Train loss on 150 batch: 0.297427
Train loss on 200 batch: 0.341911
Train loss on 250 batch: 0.281790
: Epoch: 229 | Training Loss: 0.300084 | Val. Loss: 0.521823 | Val. Kappa Score: 0.8090 | LR: 0.000433 | Estimated time: 64.78
Train loss on 50 batch: 0.293207
Train loss on 100 batch: 0.282010
Train loss on 150 batch: 0.252296
Train loss on 200 batch: 0.289014
Train loss on 250 batch: 0.291907
: Epoch: 230 | Training Loss: 0.285814 | Val. Loss: 0.482153 | Val. Kappa Score: 0.8090 | LR: 0.000389 | Estimated time: 64.79
Train loss on 50 batch: 0.278536
Train loss on 100 batch: 0.277778
Train loss on 150 batch: 0.287346
Train loss on 200 batch: 0.287286
Train loss on 250 batch: 0.273196
: Epoch: 231 | Training Loss: 0.286410 | Val. Loss: 0.522143 | Val. Kappa Score: 0.8091 | LR: 0.000345 | Estimated time: 64.85
Train loss on 50 batch: 0.221659
Train loss on 100 batch: 0.304069
Train loss on 150 batch: 0.269198
Train loss on 200 batch: 0.268804
Train loss on 250 batch: 0.282250
: Epoch: 232 | Training Loss: 0.269099 | Val. Loss: 0.478825 | Val. Kappa Score: 0.8092 | LR: 0.000303 | Estimated time: 64.88
Train loss on 50 batch: 0.254071
Train loss on 100 batch: 0.238487
Train loss on 150 batch: 0.258224
Train loss on 200 batch: 0.264223
Train loss on 250 batch: 0.283999
: Epoch: 233 | Training Loss: 0.257137 | Val. Loss: 0.479313 | Val. Kappa Score: 0.8093 | LR: 0.000263 | Estimated time: 64.70
Train loss on 50 batch: 0.251214
Train loss on 100 batch: 0.249747
Train loss on 150 batch: 0.249996
Train loss on 200 batch: 0.231219
Train loss on 250 batch: 0.269737
: Epoch: 234 | Training Loss: 0.270391 | Val. Loss: 0.501419 | Val. Kappa Score: 0.8094 | LR: 0.000225 | Estimated time: 64.80
Train loss on 50 batch: 0.240518
Train loss on 100 batch: 0.275751
Train loss on 150 batch: 0.193573
Train loss on 200 batch: 0.260768
Train loss on 250 batch: 0.253678
: Epoch: 235 | Training Loss: 0.268387 | Val. Loss: 0.467615 | Val. Kappa Score: 0.8095 | LR: 0.000188 | Estimated time: 64.75
Train loss on 50 batch: 0.259480
Train loss on 100 batch: 0.256530
Train loss on 150 batch: 0.223295
Train loss on 200 batch: 0.238660
Train loss on 250 batch: 0.233214
: Epoch: 236 | Training Loss: 0.257544 | Val. Loss: 0.487978 | Val. Kappa Score: 0.8096 | LR: 0.000154 | Estimated time: 64.68
Train loss on 50 batch: 0.248412
Train loss on 100 batch: 0.245462
Train loss on 150 batch: 0.232515
Train loss on 200 batch: 0.232280
Train loss on 250 batch: 0.255603
: Epoch: 237 | Training Loss: 0.243466 | Val. Loss: 0.492357 | Val. Kappa Score: 0.8097 | LR: 0.000123 | Estimated time: 64.92
Train loss on 50 batch: 0.264547
Train loss on 100 batch: 0.228771
Train loss on 150 batch: 0.229857
Train loss on 200 batch: 0.233352
Train loss on 250 batch: 0.226079
: Epoch: 238 | Training Loss: 0.236841 | Val. Loss: 0.535547 | Val. Kappa Score: 0.8097 | LR: 0.000095 | Estimated time: 64.75
Train loss on 50 batch: 0.232883
Train loss on 100 batch: 0.211333
Train loss on 150 batch: 0.225708
Train loss on 200 batch: 0.228975
Train loss on 250 batch: 0.231810
: Epoch: 239 | Training Loss: 0.237984 | Val. Loss: 0.465700 | Val. Kappa Score: 0.8099 | LR: 0.000071 | Estimated time: 64.77
Train loss on 50 batch: 0.230486
Train loss on 100 batch: 0.223543
Train loss on 150 batch: 0.228123
Train loss on 200 batch: 0.217853
Train loss on 250 batch: 0.231382
: Epoch: 240 | Training Loss: 0.223978 | Val. Loss: 0.461217 | Val. Kappa Score: 0.8100 | LR: 0.000050 | Estimated time: 64.63
Train loss on 50 batch: 0.243000
Train loss on 100 batch: 0.246975
Train loss on 150 batch: 0.198051
Train loss on 200 batch: 0.225714
Train loss on 250 batch: 0.211118
: Epoch: 241 | Training Loss: 0.229020 | Val. Loss: 0.507169 | Val. Kappa Score: 0.8101 | LR: 0.000032 | Estimated time: 64.70
Train loss on 50 batch: 0.209003
Train loss on 100 batch: 0.229346
Train loss on 150 batch: 0.242772
Train loss on 200 batch: 0.204112
Train loss on 250 batch: 0.198894
: Epoch: 242 | Training Loss: 0.239480 | Val. Loss: 0.462508 | Val. Kappa Score: 0.8103 | LR: 0.000018 | Estimated time: 64.73
Train loss on 50 batch: 0.220323
Train loss on 100 batch: 0.205154
Train loss on 150 batch: 0.209070
Train loss on 200 batch: 0.200553
Train loss on 250 batch: 0.213386
: Epoch: 243 | Training Loss: 0.211883 | Val. Loss: 0.469423 | Val. Kappa Score: 0.8104 | LR: 0.000008 | Estimated time: 64.82
Train loss on 50 batch: 0.242621
Train loss on 100 batch: 0.194958
Train loss on 150 batch: 0.207145
Train loss on 200 batch: 0.200858
Train loss on 250 batch: 0.233231
: Epoch: 244 | Training Loss: 0.226653 | Val. Loss: 0.483384 | Val. Kappa Score: 0.8106 | LR: 0.000002 | Estimated time: 64.75
Train loss on 50 batch: 0.221185
Train loss on 100 batch: 0.202690
Train loss on 150 batch: 0.217958
Train loss on 200 batch: 0.218909
Train loss on 250 batch: 0.197926
: Epoch: 245 | Training Loss: 0.217293 | Val. Loss: 0.485424 | Val. Kappa Score: 0.8107 | LR: 0.000000 | Estimated time: 64.57
Train loss on 50 batch: 0.206195
Train loss on 100 batch: 0.225004
Train loss on 150 batch: 0.229426
Train loss on 200 batch: 0.220561
Train loss on 250 batch: 0.193790
: Epoch: 246 | Training Loss: 0.215651 | Val. Loss: 0.478076 | Val. Kappa Score: 0.8109 | LR: 0.000002 | Estimated time: 64.55
Train loss on 50 batch: 0.196338
Train loss on 100 batch: 0.193027
Train loss on 150 batch: 0.213524
Train loss on 200 batch: 0.199871
Train loss on 250 batch: 0.226831
: Epoch: 247 | Training Loss: 0.210205 | Val. Loss: 0.470444 | Val. Kappa Score: 0.8109 | LR: 0.000008 | Estimated time: 64.50
Train loss on 50 batch: 0.224246
Train loss on 100 batch: 0.203904
Train loss on 150 batch: 0.217491
Train loss on 200 batch: 0.209922
Train loss on 250 batch: 0.231608
: Epoch: 248 | Training Loss: 0.227862 | Val. Loss: 0.465868 | Val. Kappa Score: 0.8111 | LR: 0.000018 | Estimated time: 64.66
Train loss on 50 batch: 0.246433
Train loss on 100 batch: 0.188998
Train loss on 150 batch: 0.209079
Train loss on 200 batch: 0.231377
Train loss on 250 batch: 0.216130
: Epoch: 249 | Training Loss: 0.213427 | Val. Loss: 0.456919 | Val. Kappa Score: 0.8113 | LR: 0.000032 | Estimated time: 64.65
Train loss on 50 batch: 0.199998
Train loss on 100 batch: 0.200925
Train loss on 150 batch: 0.245679
Train loss on 200 batch: 0.213510
Train loss on 250 batch: 0.183803
best-train-loss: 0.220211
best-valid-loss: 0.455476
best-kappa: 0.8115
: Epoch: 250 | Training Loss: 0.220211 | Val. Loss: 0.455476 | Val. Kappa Score: 0.8115 | LR: 0.000050 | Estimated time: 64.72
Train loss on 50 batch: 0.214330
Train loss on 100 batch: 0.216211
Train loss on 150 batch: 0.178341
Train loss on 200 batch: 0.216444
Train loss on 250 batch: 0.241123
: Epoch: 251 | Training Loss: 0.208781 | Val. Loss: 0.473182 | Val. Kappa Score: 0.8116 | LR: 0.000071 | Estimated time: 64.59
Train loss on 50 batch: 0.210266
Train loss on 100 batch: 0.213645
Train loss on 150 batch: 0.201505
Train loss on 200 batch: 0.205591
Train loss on 250 batch: 0.218191
: Epoch: 252 | Training Loss: 0.218018 | Val. Loss: 0.488123 | Val. Kappa Score: 0.8117 | LR: 0.000095 | Estimated time: 64.68
Train loss on 50 batch: 0.227633
Train loss on 100 batch: 0.204690
Train loss on 150 batch: 0.232559
Train loss on 200 batch: 0.188607
Train loss on 250 batch: 0.241116
best-train-loss: 0.234978
best-valid-loss: 0.440008
best-kappa: 0.8118
: Epoch: 253 | Training Loss: 0.234978 | Val. Loss: 0.440008 | Val. Kappa Score: 0.8118 | LR: 0.000123 | Estimated time: 64.84
Train loss on 50 batch: 0.210855
Train loss on 100 batch: 0.235679
Train loss on 150 batch: 0.214049
Train loss on 200 batch: 0.234250
Train loss on 250 batch: 0.218383
: Epoch: 254 | Training Loss: 0.223956 | Val. Loss: 0.471572 | Val. Kappa Score: 0.8120 | LR: 0.000154 | Estimated time: 64.81
Train loss on 50 batch: 0.215662
Train loss on 100 batch: 0.205893
Train loss on 150 batch: 0.211442
Train loss on 200 batch: 0.258790
Train loss on 250 batch: 0.243973
: Epoch: 255 | Training Loss: 0.238035 | Val. Loss: 0.490499 | Val. Kappa Score: 0.8121 | LR: 0.000188 | Estimated time: 64.75
Train loss on 50 batch: 0.196633
Train loss on 100 batch: 0.219495
Train loss on 150 batch: 0.246656
Train loss on 200 batch: 0.248224
Train loss on 250 batch: 0.213042
: Epoch: 256 | Training Loss: 0.225165 | Val. Loss: 0.454328 | Val. Kappa Score: 0.8122 | LR: 0.000225 | Estimated time: 64.84
Train loss on 50 batch: 0.249889
Train loss on 100 batch: 0.204791
Train loss on 150 batch: 0.206300
Train loss on 200 batch: 0.230070
Train loss on 250 batch: 0.229411
: Epoch: 257 | Training Loss: 0.239918 | Val. Loss: 0.511711 | Val. Kappa Score: 0.8123 | LR: 0.000263 | Estimated time: 64.73
Train loss on 50 batch: 0.235676
Train loss on 100 batch: 0.226043
Train loss on 150 batch: 0.232031
Train loss on 200 batch: 0.235565
Train loss on 250 batch: 0.228453
: Epoch: 258 | Training Loss: 0.234765 | Val. Loss: 0.502696 | Val. Kappa Score: 0.8124 | LR: 0.000303 | Estimated time: 64.86
Train loss on 50 batch: 0.241894
Train loss on 100 batch: 0.218606
Train loss on 150 batch: 0.225033
Train loss on 200 batch: 0.252093
Train loss on 250 batch: 0.223742
: Epoch: 259 | Training Loss: 0.237322 | Val. Loss: 0.496085 | Val. Kappa Score: 0.8125 | LR: 0.000345 | Estimated time: 64.70
Train loss on 50 batch: 0.271944
Train loss on 100 batch: 0.261574
Train loss on 150 batch: 0.243083
Train loss on 200 batch: 0.217662
Train loss on 250 batch: 0.233222
best-train-loss: 0.250550
best-valid-loss: 0.439410
best-kappa: 0.8126
: Epoch: 260 | Training Loss: 0.250550 | Val. Loss: 0.439410 | Val. Kappa Score: 0.8126 | LR: 0.000389 | Estimated time: 64.81
Train loss on 50 batch: 0.216021
Train loss on 100 batch: 0.247969
Train loss on 150 batch: 0.192270
Train loss on 200 batch: 0.256885
Train loss on 250 batch: 0.256887
: Epoch: 261 | Training Loss: 0.242656 | Val. Loss: 0.458195 | Val. Kappa Score: 0.8128 | LR: 0.000433 | Estimated time: 65.03
Train loss on 50 batch: 0.252416
Train loss on 100 batch: 0.259933
Train loss on 150 batch: 0.290242
Train loss on 200 batch: 0.311856
Train loss on 250 batch: 0.237670
: Epoch: 262 | Training Loss: 0.259522 | Val. Loss: 0.481989 | Val. Kappa Score: 0.8129 | LR: 0.000478 | Estimated time: 64.86
Train loss on 50 batch: 0.250447
Train loss on 100 batch: 0.223482
Train loss on 150 batch: 0.229388
Train loss on 200 batch: 0.282304
Train loss on 250 batch: 0.254896
: Epoch: 263 | Training Loss: 0.260391 | Val. Loss: 0.468629 | Val. Kappa Score: 0.8130 | LR: 0.000522 | Estimated time: 64.86
Train loss on 50 batch: 0.294896
Train loss on 100 batch: 0.270265
Train loss on 150 batch: 0.306327
Train loss on 200 batch: 0.297507
Train loss on 250 batch: 0.292624
: Epoch: 264 | Training Loss: 0.286677 | Val. Loss: 0.525268 | Val. Kappa Score: 0.8131 | LR: 0.000567 | Estimated time: 64.92
Train loss on 50 batch: 0.262814
Train loss on 100 batch: 0.258869
Train loss on 150 batch: 0.254740
Train loss on 200 batch: 0.267117
Train loss on 250 batch: 0.298199
: Epoch: 265 | Training Loss: 0.265753 | Val. Loss: 0.557669 | Val. Kappa Score: 0.8131 | LR: 0.000611 | Estimated time: 64.76
Train loss on 50 batch: 0.261794
Train loss on 100 batch: 0.309554
Train loss on 150 batch: 0.300460
Train loss on 200 batch: 0.307718
Train loss on 250 batch: 0.282506
: Epoch: 266 | Training Loss: 0.298223 | Val. Loss: 0.641691 | Val. Kappa Score: 0.8130 | LR: 0.000655 | Estimated time: 64.74
Train loss on 50 batch: 0.300153
Train loss on 100 batch: 0.340850
Train loss on 150 batch: 0.308974
Train loss on 200 batch: 0.310963
Train loss on 250 batch: 0.318074
: Epoch: 267 | Training Loss: 0.339184 | Val. Loss: 0.450334 | Val. Kappa Score: 0.8131 | LR: 0.000697 | Estimated time: 64.78
Train loss on 50 batch: 0.312820
Train loss on 100 batch: 0.326308
Train loss on 150 batch: 0.261834
Train loss on 200 batch: 0.299176
Train loss on 250 batch: 0.278990
: Epoch: 268 | Training Loss: 0.309916 | Val. Loss: 0.520181 | Val. Kappa Score: 0.8131 | LR: 0.000737 | Estimated time: 64.79
Train loss on 50 batch: 0.394205
Train loss on 100 batch: 0.300581
Train loss on 150 batch: 0.357782
Train loss on 200 batch: 0.288422
Train loss on 250 batch: 0.294955
: Epoch: 269 | Training Loss: 0.333144 | Val. Loss: 0.564532 | Val. Kappa Score: 0.8131 | LR: 0.000775 | Estimated time: 64.80
Train loss on 50 batch: 0.635471
Train loss on 100 batch: 0.451797
Train loss on 150 batch: 0.396431
Train loss on 200 batch: 0.445713
Train loss on 250 batch: 0.364012
: Epoch: 270 | Training Loss: 0.455640 | Val. Loss: 0.534185 | Val. Kappa Score: 0.8131 | LR: 0.000812 | Estimated time: 64.94
Train loss on 50 batch: 0.398713
Train loss on 100 batch: 0.346510
Train loss on 150 batch: 0.309926
Train loss on 200 batch: 0.341501
Train loss on 250 batch: 0.323582
: Epoch: 271 | Training Loss: 0.356283 | Val. Loss: 0.534615 | Val. Kappa Score: 0.8131 | LR: 0.000846 | Estimated time: 64.95
Train loss on 50 batch: 0.362159
Train loss on 100 batch: 0.314799
Train loss on 150 batch: 0.434557
Train loss on 200 batch: 0.324847
Train loss on 250 batch: 0.297946
: Epoch: 272 | Training Loss: 0.340451 | Val. Loss: 0.533555 | Val. Kappa Score: 0.8132 | LR: 0.000877 | Estimated time: 64.86
Train loss on 50 batch: 0.317699
Train loss on 100 batch: 0.339768
Train loss on 150 batch: 0.323868
Train loss on 200 batch: 0.334810
Train loss on 250 batch: 0.368442
: Epoch: 273 | Training Loss: 0.326792 | Val. Loss: 0.485522 | Val. Kappa Score: 0.8133 | LR: 0.000905 | Estimated time: 64.82
Train loss on 50 batch: 0.310357
Train loss on 100 batch: 0.294160
Train loss on 150 batch: 0.292601
Train loss on 200 batch: 0.280665
Train loss on 250 batch: 0.320318
: Epoch: 274 | Training Loss: 0.321052 | Val. Loss: 0.512987 | Val. Kappa Score: 0.8134 | LR: 0.000929 | Estimated time: 64.77
Train loss on 50 batch: 0.308383
Train loss on 100 batch: 0.314351
Train loss on 150 batch: 0.291174
Train loss on 200 batch: 0.317313
Train loss on 250 batch: 0.323467
: Epoch: 275 | Training Loss: 0.304900 | Val. Loss: 0.523024 | Val. Kappa Score: 0.8134 | LR: 0.000950 | Estimated time: 64.83
Train loss on 50 batch: 0.250577
Train loss on 100 batch: 0.310754
Train loss on 150 batch: 0.317611
Train loss on 200 batch: 0.361677
Train loss on 250 batch: 0.284632
: Epoch: 276 | Training Loss: 0.317631 | Val. Loss: 0.480111 | Val. Kappa Score: 0.8135 | LR: 0.000968 | Estimated time: 64.81
Train loss on 50 batch: 0.319914
Train loss on 100 batch: 0.278626
Train loss on 150 batch: 0.359004
Train loss on 200 batch: 0.297467
Train loss on 250 batch: 0.312651
: Epoch: 277 | Training Loss: 0.315876 | Val. Loss: 0.620205 | Val. Kappa Score: 0.8135 | LR: 0.000982 | Estimated time: 64.49
Train loss on 50 batch: 0.352041
Train loss on 100 batch: 0.314578
Train loss on 150 batch: 0.335744
Train loss on 200 batch: 0.284726
Train loss on 250 batch: 0.290195
: Epoch: 278 | Training Loss: 0.312117 | Val. Loss: 0.500183 | Val. Kappa Score: 0.8136 | LR: 0.000992 | Estimated time: 64.89
Train loss on 50 batch: 0.330878
Train loss on 100 batch: 0.307772
Train loss on 150 batch: 0.322730
Train loss on 200 batch: 0.297848
Train loss on 250 batch: 0.283012
: Epoch: 279 | Training Loss: 0.328155 | Val. Loss: 0.587516 | Val. Kappa Score: 0.8136 | LR: 0.000998 | Estimated time: 64.97
Train loss on 50 batch: 0.322581
Train loss on 100 batch: 0.294654
Train loss on 150 batch: 0.331004
Train loss on 200 batch: 0.341962
Train loss on 250 batch: 0.319528
: Epoch: 280 | Training Loss: 0.337504 | Val. Loss: 0.496619 | Val. Kappa Score: 0.8136 | LR: 0.001000 | Estimated time: 64.99
Train loss on 50 batch: 0.289353
Train loss on 100 batch: 0.308087
Train loss on 150 batch: 0.302624
Train loss on 200 batch: 0.316591
Train loss on 250 batch: 0.319930
: Epoch: 281 | Training Loss: 0.345511 | Val. Loss: 0.632082 | Val. Kappa Score: 0.8135 | LR: 0.000998 | Estimated time: 64.61
Train loss on 50 batch: 0.448963
Train loss on 100 batch: 0.387540
Train loss on 150 batch: 0.298317
Train loss on 200 batch: 0.250900
Train loss on 250 batch: 0.344441
: Epoch: 282 | Training Loss: 0.360885 | Val. Loss: 0.455095 | Val. Kappa Score: 0.8136 | LR: 0.000992 | Estimated time: 64.75
Train loss on 50 batch: 0.314627
Train loss on 100 batch: 0.354660
Train loss on 150 batch: 0.300061
Train loss on 200 batch: 0.400532
Train loss on 250 batch: 0.337153
: Epoch: 283 | Training Loss: 0.378786 | Val. Loss: 0.691729 | Val. Kappa Score: 0.8135 | LR: 0.000982 | Estimated time: 64.88
Train loss on 50 batch: 0.471685
Train loss on 100 batch: 0.310655
Train loss on 150 batch: 0.345559
Train loss on 200 batch: 0.308829
Train loss on 250 batch: 0.404775
: Epoch: 284 | Training Loss: 0.375050 | Val. Loss: 0.604514 | Val. Kappa Score: 0.8135 | LR: 0.000968 | Estimated time: 64.68
Train loss on 50 batch: 0.420256
Train loss on 100 batch: 0.417747
Train loss on 150 batch: 0.291620
Train loss on 200 batch: 0.357111
Train loss on 250 batch: 0.322586
: Epoch: 285 | Training Loss: 0.368423 | Val. Loss: 0.543430 | Val. Kappa Score: 0.8135 | LR: 0.000950 | Estimated time: 64.78
Train loss on 50 batch: 0.305929
Train loss on 100 batch: 0.343418
Train loss on 150 batch: 0.355487
Train loss on 200 batch: 0.332262
Train loss on 250 batch: 0.333220
best-train-loss: 0.341773
best-valid-loss: 0.431253
best-kappa: 0.8137
: Epoch: 286 | Training Loss: 0.341773 | Val. Loss: 0.431253 | Val. Kappa Score: 0.8137 | LR: 0.000929 | Estimated time: 64.75
Train loss on 50 batch: 0.377406
Train loss on 100 batch: 0.291213
Train loss on 150 batch: 0.366410
Train loss on 200 batch: 0.312278
Train loss on 250 batch: 0.322823
: Epoch: 287 | Training Loss: 0.329676 | Val. Loss: 0.546261 | Val. Kappa Score: 0.8137 | LR: 0.000905 | Estimated time: 64.80
Train loss on 50 batch: 0.282778
Train loss on 100 batch: 0.374858
Train loss on 150 batch: 0.340461
Train loss on 200 batch: 0.382617
Train loss on 250 batch: 0.310092
: Epoch: 288 | Training Loss: 0.329868 | Val. Loss: 0.503842 | Val. Kappa Score: 0.8137 | LR: 0.000877 | Estimated time: 64.69
Train loss on 50 batch: 0.285011
Train loss on 100 batch: 0.337558
Train loss on 150 batch: 0.331058
Train loss on 200 batch: 0.269138
Train loss on 250 batch: 0.305520
: Epoch: 289 | Training Loss: 0.318695 | Val. Loss: 0.503131 | Val. Kappa Score: 0.8137 | LR: 0.000846 | Estimated time: 64.79
Train loss on 50 batch: 0.296458
Train loss on 100 batch: 0.302783
Train loss on 150 batch: 0.325327
Train loss on 200 batch: 0.271317
Train loss on 250 batch: 0.277596
: Epoch: 290 | Training Loss: 0.318955 | Val. Loss: 0.468907 | Val. Kappa Score: 0.8139 | LR: 0.000812 | Estimated time: 64.78
Train loss on 50 batch: 0.370412
Train loss on 100 batch: 0.305057
Train loss on 150 batch: 0.289591
Train loss on 200 batch: 0.288449
Train loss on 250 batch: 0.257071
: Epoch: 291 | Training Loss: 0.314132 | Val. Loss: 0.512824 | Val. Kappa Score: 0.8140 | LR: 0.000775 | Estimated time: 64.62
Train loss on 50 batch: 0.266596
Train loss on 100 batch: 0.285071
Train loss on 150 batch: 0.359109
Train loss on 200 batch: 0.371265
Train loss on 250 batch: 0.323077
: Epoch: 292 | Training Loss: 0.313249 | Val. Loss: 0.501759 | Val. Kappa Score: 0.8141 | LR: 0.000737 | Estimated time: 64.66
Train loss on 50 batch: 0.263747
Train loss on 100 batch: 0.309616
Train loss on 150 batch: 0.342667
Train loss on 200 batch: 0.277423
Train loss on 250 batch: 0.267218
: Epoch: 293 | Training Loss: 0.294679 | Val. Loss: 0.597725 | Val. Kappa Score: 0.8141 | LR: 0.000697 | Estimated time: 64.74
Train loss on 50 batch: 0.285612
Train loss on 100 batch: 0.259299
Train loss on 150 batch: 0.255054
Train loss on 200 batch: 0.291187
Train loss on 250 batch: 0.245673
: Epoch: 294 | Training Loss: 0.274679 | Val. Loss: 0.526084 | Val. Kappa Score: 0.8142 | LR: 0.000655 | Estimated time: 64.81
Train loss on 50 batch: 0.326631
Train loss on 100 batch: 0.283269
Train loss on 150 batch: 0.256075
Train loss on 200 batch: 0.239980
Train loss on 250 batch: 0.255028
: Epoch: 295 | Training Loss: 0.272245 | Val. Loss: 0.482666 | Val. Kappa Score: 0.8143 | LR: 0.000611 | Estimated time: 64.83
Train loss on 50 batch: 0.278952
Train loss on 100 batch: 0.303775
Train loss on 150 batch: 0.273356
Train loss on 200 batch: 0.235807
Train loss on 250 batch: 0.213289
: Epoch: 296 | Training Loss: 0.262600 | Val. Loss: 0.637559 | Val. Kappa Score: 0.8143 | LR: 0.000567 | Estimated time: 64.83
Train loss on 50 batch: 0.299169
Train loss on 100 batch: 0.244653
Train loss on 150 batch: 0.250980
Train loss on 200 batch: 0.254922
Train loss on 250 batch: 0.279852
: Epoch: 297 | Training Loss: 0.260816 | Val. Loss: 0.463778 | Val. Kappa Score: 0.8144 | LR: 0.000522 | Estimated time: 64.78
Train loss on 50 batch: 0.260027
Train loss on 100 batch: 0.247882
Train loss on 150 batch: 0.237440
Train loss on 200 batch: 0.233565
Train loss on 250 batch: 0.256437
: Epoch: 298 | Training Loss: 0.259350 | Val. Loss: 0.632175 | Val. Kappa Score: 0.8144 | LR: 0.000478 | Estimated time: 64.79
Train loss on 50 batch: 0.280902
Train loss on 100 batch: 0.225133
Train loss on 150 batch: 0.232990
Train loss on 200 batch: 0.251883
Train loss on 250 batch: 0.197996
: Epoch: 299 | Training Loss: 0.239013 | Val. Loss: 0.494666 | Val. Kappa Score: 0.8144 | LR: 0.000433 | Estimated time: 64.73
Train loss on 50 batch: 0.222774
Train loss on 100 batch: 0.218162
Train loss on 150 batch: 0.243922
Train loss on 200 batch: 0.250423
Train loss on 250 batch: 0.237642
: Epoch: 300 | Training Loss: 0.235298 | Val. Loss: 0.522128 | Val. Kappa Score: 0.8144 | LR: 0.000389 | Estimated time: 64.68
Train loss on 50 batch: 0.225491
Train loss on 100 batch: 0.207312
Train loss on 150 batch: 0.204242
Train loss on 200 batch: 0.229646
Train loss on 250 batch: 0.228196
: Epoch: 301 | Training Loss: 0.235153 | Val. Loss: 0.515074 | Val. Kappa Score: 0.8145 | LR: 0.000345 | Estimated time: 64.98
Train loss on 50 batch: 0.238990
Train loss on 100 batch: 0.203819
Train loss on 150 batch: 0.220729
Train loss on 200 batch: 0.219680
Train loss on 250 batch: 0.211420
: Epoch: 302 | Training Loss: 0.220143 | Val. Loss: 0.502092 | Val. Kappa Score: 0.8146 | LR: 0.000303 | Estimated time: 64.65
Train loss on 50 batch: 0.209373
Train loss on 100 batch: 0.204882
Train loss on 150 batch: 0.201017
Train loss on 200 batch: 0.197831
Train loss on 250 batch: 0.218290
: Epoch: 303 | Training Loss: 0.210691 | Val. Loss: 0.480244 | Val. Kappa Score: 0.8146 | LR: 0.000263 | Estimated time: 64.60
Train loss on 50 batch: 0.216428
Train loss on 100 batch: 0.191903
Train loss on 150 batch: 0.214742
Train loss on 200 batch: 0.183690
Train loss on 250 batch: 0.203985
: Epoch: 304 | Training Loss: 0.213148 | Val. Loss: 0.445248 | Val. Kappa Score: 0.8148 | LR: 0.000225 | Estimated time: 64.86
Train loss on 50 batch: 0.211677
Train loss on 100 batch: 0.193105
Train loss on 150 batch: 0.195403
Train loss on 200 batch: 0.205421
Train loss on 250 batch: 0.200085
: Epoch: 305 | Training Loss: 0.203245 | Val. Loss: 0.455103 | Val. Kappa Score: 0.8149 | LR: 0.000188 | Estimated time: 64.68
Train loss on 50 batch: 0.191155
Train loss on 100 batch: 0.219431
Train loss on 150 batch: 0.190560
Train loss on 200 batch: 0.193230
Train loss on 250 batch: 0.191113
: Epoch: 306 | Training Loss: 0.223570 | Val. Loss: 0.551892 | Val. Kappa Score: 0.8149 | LR: 0.000154 | Estimated time: 64.81
Train loss on 50 batch: 0.203762
Train loss on 100 batch: 0.174255
Train loss on 150 batch: 0.166392
Train loss on 200 batch: 0.201674
Train loss on 250 batch: 0.192971
: Epoch: 307 | Training Loss: 0.205079 | Val. Loss: 0.474107 | Val. Kappa Score: 0.8149 | LR: 0.000123 | Estimated time: 64.73
Train loss on 50 batch: 0.195870
Train loss on 100 batch: 0.212147
Train loss on 150 batch: 0.202809
Train loss on 200 batch: 0.191399
Train loss on 250 batch: 0.174400
: Epoch: 308 | Training Loss: 0.203274 | Val. Loss: 0.467430 | Val. Kappa Score: 0.8150 | LR: 0.000095 | Estimated time: 64.90
Train loss on 50 batch: 0.185140
Train loss on 100 batch: 0.174501
Train loss on 150 batch: 0.159201
Train loss on 200 batch: 0.199977
Train loss on 250 batch: 0.182430
: Epoch: 309 | Training Loss: 0.183228 | Val. Loss: 0.465430 | Val. Kappa Score: 0.8151 | LR: 0.000071 | Estimated time: 64.74
Train loss on 50 batch: 0.170013
Train loss on 100 batch: 0.172309
Train loss on 150 batch: 0.186100
Train loss on 200 batch: 0.196195
Train loss on 250 batch: 0.196081
: Epoch: 310 | Training Loss: 0.188055 | Val. Loss: 0.472353 | Val. Kappa Score: 0.8151 | LR: 0.000050 | Estimated time: 64.50
Train loss on 50 batch: 0.192428
Train loss on 100 batch: 0.177368
Train loss on 150 batch: 0.170769
Train loss on 200 batch: 0.177868
Train loss on 250 batch: 0.186484
: Epoch: 311 | Training Loss: 0.178784 | Val. Loss: 0.470719 | Val. Kappa Score: 0.8153 | LR: 0.000032 | Estimated time: 64.76
Train loss on 50 batch: 0.207530
Train loss on 100 batch: 0.183499
Train loss on 150 batch: 0.173366
Train loss on 200 batch: 0.162847
Train loss on 250 batch: 0.161653
: Epoch: 312 | Training Loss: 0.176668 | Val. Loss: 0.482840 | Val. Kappa Score: 0.8154 | LR: 0.000018 | Estimated time: 64.51
Train loss on 50 batch: 0.174358
Train loss on 100 batch: 0.162003
Train loss on 150 batch: 0.171553
Train loss on 200 batch: 0.144533
Train loss on 250 batch: 0.177302
: Epoch: 313 | Training Loss: 0.165042 | Val. Loss: 0.471141 | Val. Kappa Score: 0.8155 | LR: 0.000008 | Estimated time: 64.64
Train loss on 50 batch: 0.152246
Train loss on 100 batch: 0.193398
Train loss on 150 batch: 0.179674
Train loss on 200 batch: 0.166675
Train loss on 250 batch: 0.157819
: Epoch: 314 | Training Loss: 0.170920 | Val. Loss: 0.481541 | Val. Kappa Score: 0.8155 | LR: 0.000002 | Estimated time: 64.52
Train loss on 50 batch: 0.177696
Train loss on 100 batch: 0.152847
Train loss on 150 batch: 0.167665
Train loss on 200 batch: 0.169254
Train loss on 250 batch: 0.174750
: Epoch: 315 | Training Loss: 0.170245 | Val. Loss: 0.454707 | Val. Kappa Score: 0.8156 | LR: 0.000000 | Estimated time: 64.53
Train loss on 50 batch: 0.178018
Train loss on 100 batch: 0.156735
Train loss on 150 batch: 0.160666
Train loss on 200 batch: 0.177082
Train loss on 250 batch: 0.151062
: Epoch: 316 | Training Loss: 0.171119 | Val. Loss: 0.451538 | Val. Kappa Score: 0.8157 | LR: 0.000002 | Estimated time: 64.42
Train loss on 50 batch: 0.199372
Train loss on 100 batch: 0.165298
Train loss on 150 batch: 0.161486
Train loss on 200 batch: 0.183700
Train loss on 250 batch: 0.173156
: Epoch: 317 | Training Loss: 0.177596 | Val. Loss: 0.472325 | Val. Kappa Score: 0.8158 | LR: 0.000008 | Estimated time: 64.60
Train loss on 50 batch: 0.161277
Train loss on 100 batch: 0.148839
Train loss on 150 batch: 0.159050
Train loss on 200 batch: 0.188601
Train loss on 250 batch: 0.159592
: Epoch: 318 | Training Loss: 0.169178 | Val. Loss: 0.457330 | Val. Kappa Score: 0.8159 | LR: 0.000018 | Estimated time: 64.67
Train loss on 50 batch: 0.162688
Train loss on 100 batch: 0.184399
Train loss on 150 batch: 0.161275
Train loss on 200 batch: 0.190013
Train loss on 250 batch: 0.164942
: Epoch: 319 | Training Loss: 0.169941 | Val. Loss: 0.469516 | Val. Kappa Score: 0.8160 | LR: 0.000032 | Estimated time: 64.62
Train loss on 50 batch: 0.154491
Train loss on 100 batch: 0.162748
Train loss on 150 batch: 0.186430
Train loss on 200 batch: 0.179251
Train loss on 250 batch: 0.167385
: Epoch: 320 | Training Loss: 0.170200 | Val. Loss: 0.470210 | Val. Kappa Score: 0.8161 | LR: 0.000050 | Estimated time: 64.68
Train loss on 50 batch: 0.166590
Train loss on 100 batch: 0.179406
Train loss on 150 batch: 0.160834
Train loss on 200 batch: 0.162723
Train loss on 250 batch: 0.173148
: Epoch: 321 | Training Loss: 0.176903 | Val. Loss: 0.470721 | Val. Kappa Score: 0.8162 | LR: 0.000071 | Estimated time: 64.67
Train loss on 50 batch: 0.175031
Train loss on 100 batch: 0.166026
Train loss on 150 batch: 0.148823
Train loss on 200 batch: 0.186721
Train loss on 250 batch: 0.176187
: Epoch: 322 | Training Loss: 0.177032 | Val. Loss: 0.480743 | Val. Kappa Score: 0.8163 | LR: 0.000095 | Estimated time: 64.78
Train loss on 50 batch: 0.154759
Train loss on 100 batch: 0.169621
Train loss on 150 batch: 0.195771
Train loss on 200 batch: 0.162024
Train loss on 250 batch: 0.164764
: Epoch: 323 | Training Loss: 0.182660 | Val. Loss: 0.486036 | Val. Kappa Score: 0.8163 | LR: 0.000123 | Estimated time: 64.69
Train loss on 50 batch: 0.168067
Train loss on 100 batch: 0.172394
Train loss on 150 batch: 0.176267
Train loss on 200 batch: 0.202076
Train loss on 250 batch: 0.193645
: Epoch: 324 | Training Loss: 0.185374 | Val. Loss: 0.483152 | Val. Kappa Score: 0.8164 | LR: 0.000154 | Estimated time: 64.76
Train loss on 50 batch: 0.182578
Train loss on 100 batch: 0.195034
Train loss on 150 batch: 0.177971
Train loss on 200 batch: 0.193112
Train loss on 250 batch: 0.158108
: Epoch: 325 | Training Loss: 0.199954 | Val. Loss: 0.477653 | Val. Kappa Score: 0.8165 | LR: 0.000188 | Estimated time: 64.79
Train loss on 50 batch: 0.195484
Train loss on 100 batch: 0.179015
Train loss on 150 batch: 0.188692
Train loss on 200 batch: 0.167632
Train loss on 250 batch: 0.160544
: Epoch: 326 | Training Loss: 0.181732 | Val. Loss: 0.476547 | Val. Kappa Score: 0.8166 | LR: 0.000225 | Estimated time: 64.64
Train loss on 50 batch: 0.189210
Train loss on 100 batch: 0.173492
Train loss on 150 batch: 0.208955
Train loss on 200 batch: 0.186699
Train loss on 250 batch: 0.192393
: Epoch: 327 | Training Loss: 0.195969 | Val. Loss: 0.486933 | Val. Kappa Score: 0.8166 | LR: 0.000263 | Estimated time: 64.76
Train loss on 50 batch: 0.166740
Train loss on 100 batch: 0.169724
Train loss on 150 batch: 0.191666
Train loss on 200 batch: 0.168871
Train loss on 250 batch: 0.212563
: Epoch: 328 | Training Loss: 0.190970 | Val. Loss: 0.513223 | Val. Kappa Score: 0.8167 | LR: 0.000303 | Estimated time: 64.69
Train loss on 50 batch: 0.173352
Train loss on 100 batch: 0.185403
Train loss on 150 batch: 0.171123
Train loss on 200 batch: 0.199202
Train loss on 250 batch: 0.215226
: Epoch: 329 | Training Loss: 0.195094 | Val. Loss: 0.633535 | Val. Kappa Score: 0.8167 | LR: 0.000345 | Estimated time: 64.68
Train loss on 50 batch: 0.199893
Train loss on 100 batch: 0.195062
Train loss on 150 batch: 0.203072
Train loss on 200 batch: 0.179632
Train loss on 250 batch: 0.195363
: Epoch: 330 | Training Loss: 0.202640 | Val. Loss: 0.523793 | Val. Kappa Score: 0.8167 | LR: 0.000389 | Estimated time: 64.76
Train loss on 50 batch: 0.192191
Train loss on 100 batch: 0.210383
Train loss on 150 batch: 0.206328
Train loss on 200 batch: 0.211900
Train loss on 250 batch: 0.203336
: Epoch: 331 | Training Loss: 0.201540 | Val. Loss: 0.507771 | Val. Kappa Score: 0.8168 | LR: 0.000433 | Estimated time: 64.76
Train loss on 50 batch: 0.220362
Train loss on 100 batch: 0.249115
Train loss on 150 batch: 0.189223
Train loss on 200 batch: 0.183713
Train loss on 250 batch: 0.210297
: Epoch: 332 | Training Loss: 0.214851 | Val. Loss: 0.523152 | Val. Kappa Score: 0.8169 | LR: 0.000478 | Estimated time: 64.77
Train loss on 50 batch: 0.240032
Train loss on 100 batch: 0.217217
Train loss on 150 batch: 0.182785
Train loss on 200 batch: 0.226820
Train loss on 250 batch: 0.195048
: Epoch: 333 | Training Loss: 0.229702 | Val. Loss: 0.561530 | Val. Kappa Score: 0.8169 | LR: 0.000522 | Estimated time: 64.88
Train loss on 50 batch: 0.258431
Train loss on 100 batch: 0.199983
Train loss on 150 batch: 0.295617
Train loss on 200 batch: 0.232255
Train loss on 250 batch: 0.224316
: Epoch: 334 | Training Loss: 0.237179 | Val. Loss: 0.634802 | Val. Kappa Score: 0.8168 | LR: 0.000567 | Estimated time: 64.87
Train loss on 50 batch: 0.214444
Train loss on 100 batch: 0.196523
Train loss on 150 batch: 0.217870
Train loss on 200 batch: 0.246480
Train loss on 250 batch: 0.257442
: Epoch: 335 | Training Loss: 0.227848 | Val. Loss: 0.483764 | Val. Kappa Score: 0.8169 | LR: 0.000611 | Estimated time: 64.97
Train loss on 50 batch: 0.215024
Train loss on 100 batch: 0.252485
Train loss on 150 batch: 0.232601
Train loss on 200 batch: 0.252647
Train loss on 250 batch: 0.210141
: Epoch: 336 | Training Loss: 0.261124 | Val. Loss: 0.483435 | Val. Kappa Score: 0.8170 | LR: 0.000655 | Estimated time: 64.67
Train loss on 50 batch: 0.349328
Train loss on 100 batch: 0.279277
Train loss on 150 batch: 0.224528
Train loss on 200 batch: 0.238820
Train loss on 250 batch: 0.243360
: Epoch: 337 | Training Loss: 0.263307 | Val. Loss: 0.534103 | Val. Kappa Score: 0.8170 | LR: 0.000697 | Estimated time: 64.78
Train loss on 50 batch: 0.235790
Train loss on 100 batch: 0.262438
Train loss on 150 batch: 0.254712
Train loss on 200 batch: 0.228164
Train loss on 250 batch: 0.266723
: Epoch: 338 | Training Loss: 0.254412 | Val. Loss: 0.483042 | Val. Kappa Score: 0.8170 | LR: 0.000737 | Estimated time: 64.70
Train loss on 50 batch: 0.255316
Train loss on 100 batch: 0.199564
Train loss on 150 batch: 0.240070
Train loss on 200 batch: 0.264315
Train loss on 250 batch: 0.280311
: Epoch: 339 | Training Loss: 0.252561 | Val. Loss: 0.542765 | Val. Kappa Score: 0.8170 | LR: 0.000775 | Estimated time: 64.75
Train loss on 50 batch: 0.288346
Train loss on 100 batch: 0.267563
Train loss on 150 batch: 0.262472
Train loss on 200 batch: 0.253474
Train loss on 250 batch: 0.227629
: Epoch: 340 | Training Loss: 0.255152 | Val. Loss: 0.592214 | Val. Kappa Score: 0.8169 | LR: 0.000812 | Estimated time: 64.74
Train loss on 50 batch: 0.404220
Train loss on 100 batch: 0.328529
Train loss on 150 batch: 0.336296
Train loss on 200 batch: 0.329442
Train loss on 250 batch: 0.272415
: Epoch: 341 | Training Loss: 0.326445 | Val. Loss: 0.552319 | Val. Kappa Score: 0.8169 | LR: 0.000846 | Estimated time: 64.77
Train loss on 50 batch: 0.270344
Train loss on 100 batch: 0.277079
Train loss on 150 batch: 0.240822
Train loss on 200 batch: 0.263621
Train loss on 250 batch: 0.245633
: Epoch: 342 | Training Loss: 0.260216 | Val. Loss: 0.504880 | Val. Kappa Score: 0.8170 | LR: 0.000877 | Estimated time: 64.82
Train loss on 50 batch: 0.301111
Train loss on 100 batch: 0.260534
Train loss on 150 batch: 0.318168
Train loss on 200 batch: 0.289175
Train loss on 250 batch: 0.248845
: Epoch: 343 | Training Loss: 0.283959 | Val. Loss: 0.490787 | Val. Kappa Score: 0.8170 | LR: 0.000905 | Estimated time: 64.79
Train loss on 50 batch: 0.372630
Train loss on 100 batch: 0.298371
Train loss on 150 batch: 0.252115
Train loss on 200 batch: 0.296978
Train loss on 250 batch: 0.288357
: Epoch: 344 | Training Loss: 0.290519 | Val. Loss: 0.549214 | Val. Kappa Score: 0.8170 | LR: 0.000929 | Estimated time: 64.83
Train loss on 50 batch: 0.267966
Train loss on 100 batch: 0.265885
Train loss on 150 batch: 0.310090
Train loss on 200 batch: 0.273004
Train loss on 250 batch: 0.254425
: Epoch: 345 | Training Loss: 0.273819 | Val. Loss: 0.480495 | Val. Kappa Score: 0.8170 | LR: 0.000950 | Estimated time: 64.62
Train loss on 50 batch: 0.247061
Train loss on 100 batch: 0.261474
Train loss on 150 batch: 0.253171
Train loss on 200 batch: 0.270432
Train loss on 250 batch: 0.306772
: Epoch: 346 | Training Loss: 0.272379 | Val. Loss: 0.498878 | Val. Kappa Score: 0.8171 | LR: 0.000968 | Estimated time: 64.82
Train loss on 50 batch: 0.265689
Train loss on 100 batch: 0.278456
Train loss on 150 batch: 0.244834
Train loss on 200 batch: 0.294619
Train loss on 250 batch: 0.252535
: Epoch: 347 | Training Loss: 0.272238 | Val. Loss: 0.545552 | Val. Kappa Score: 0.8171 | LR: 0.000982 | Estimated time: 64.87
Train loss on 50 batch: 0.246905
Train loss on 100 batch: 0.269984
Train loss on 150 batch: 0.302594
Train loss on 200 batch: 0.303927
Train loss on 250 batch: 0.288621
: Epoch: 348 | Training Loss: 0.285942 | Val. Loss: 0.584114 | Val. Kappa Score: 0.8170 | LR: 0.000992 | Estimated time: 64.78
Train loss on 50 batch: 0.304183
Train loss on 100 batch: 0.254321
Train loss on 150 batch: 0.222810
Train loss on 200 batch: 0.339088
Train loss on 250 batch: 0.306349
: Epoch: 349 | Training Loss: 0.289134 | Val. Loss: 0.625127 | Val. Kappa Score: 0.8171 | LR: 0.000998 | Estimated time: 64.62
Train loss on 50 batch: 0.315661
Train loss on 100 batch: 0.276480
Train loss on 150 batch: 0.263947
Train loss on 200 batch: 0.314780
Train loss on 250 batch: 0.282797
: Epoch: 350 | Training Loss: 0.311496 | Val. Loss: 0.505130 | Val. Kappa Score: 0.8171 | LR: 0.001000 | Estimated time: 64.83
Train loss on 50 batch: 0.408946
Train loss on 100 batch: 0.341175
Train loss on 150 batch: 0.281127
Train loss on 200 batch: 0.277783
Train loss on 250 batch: 0.266672
: Epoch: 351 | Training Loss: 0.318719 | Val. Loss: 0.515113 | Val. Kappa Score: 0.8171 | LR: 0.000998 | Estimated time: 64.60
Train loss on 50 batch: 0.733845
Train loss on 100 batch: 0.421649
Train loss on 150 batch: 0.394569
Train loss on 200 batch: 0.374095
Train loss on 250 batch: 0.330002
: Epoch: 352 | Training Loss: 0.450280 | Val. Loss: 0.586428 | Val. Kappa Score: 0.8171 | LR: 0.000992 | Estimated time: 64.72
Train loss on 50 batch: 0.430366
Train loss on 100 batch: 0.306960
Train loss on 150 batch: 0.349191
Train loss on 200 batch: 0.365659
Train loss on 250 batch: 0.326330
: Epoch: 353 | Training Loss: 0.346884 | Val. Loss: 0.526178 | Val. Kappa Score: 0.8171 | LR: 0.000982 | Estimated time: 64.80
Train loss on 50 batch: 0.287593
Train loss on 100 batch: 0.282467
Train loss on 150 batch: 0.286344
Train loss on 200 batch: 0.310263
Train loss on 250 batch: 0.318895
: Epoch: 354 | Training Loss: 0.299516 | Val. Loss: 0.552766 | Val. Kappa Score: 0.8171 | LR: 0.000968 | Estimated time: 64.79
Train loss on 50 batch: 0.340020
Train loss on 100 batch: 0.300768
Train loss on 150 batch: 0.275859
Train loss on 200 batch: 0.299837
Train loss on 250 batch: 0.280202
: Epoch: 355 | Training Loss: 0.297031 | Val. Loss: 0.655546 | Val. Kappa Score: 0.8170 | LR: 0.000950 | Estimated time: 64.87
Train loss on 50 batch: 0.250290
Train loss on 100 batch: 0.278393
Train loss on 150 batch: 0.252735
Train loss on 200 batch: 0.273134
Train loss on 250 batch: 0.278738
: Epoch: 356 | Training Loss: 0.280823 | Val. Loss: 0.584291 | Val. Kappa Score: 0.8170 | LR: 0.000929 | Estimated time: 64.77
Train loss on 50 batch: 0.290792
Train loss on 100 batch: 0.277335
Train loss on 150 batch: 0.281102
Train loss on 200 batch: 0.284332
Train loss on 250 batch: 0.309076
: Epoch: 357 | Training Loss: 0.282810 | Val. Loss: 0.514997 | Val. Kappa Score: 0.8170 | LR: 0.000905 | Estimated time: 64.78
Train loss on 50 batch: 0.281749
Train loss on 100 batch: 0.248589
Train loss on 150 batch: 0.285574
Train loss on 200 batch: 0.245888
Train loss on 250 batch: 0.281039
: Epoch: 358 | Training Loss: 0.272582 | Val. Loss: 0.630862 | Val. Kappa Score: 0.8170 | LR: 0.000877 | Estimated time: 64.75
Train loss on 50 batch: 0.296269
Train loss on 100 batch: 0.243743
Train loss on 150 batch: 0.222327
Train loss on 200 batch: 0.261279
Train loss on 250 batch: 0.325655
: Epoch: 359 | Training Loss: 0.280907 | Val. Loss: 0.488246 | Val. Kappa Score: 0.8171 | LR: 0.000846 | Estimated time: 64.79
Train loss on 50 batch: 0.313690
Train loss on 100 batch: 0.306454
Train loss on 150 batch: 0.252314
Train loss on 200 batch: 0.264738
Train loss on 250 batch: 0.247081
: Epoch: 360 | Training Loss: 0.280406 | Val. Loss: 0.498796 | Val. Kappa Score: 0.8171 | LR: 0.000812 | Estimated time: 64.80
Train loss on 50 batch: 0.328408
Train loss on 100 batch: 0.265593
Train loss on 150 batch: 0.253937
Train loss on 200 batch: 0.265262
Train loss on 250 batch: 0.184676
: Epoch: 361 | Training Loss: 0.280829 | Val. Loss: 0.567800 | Val. Kappa Score: 0.8171 | LR: 0.000775 | Estimated time: 64.81
Train loss on 50 batch: 0.330062
Train loss on 100 batch: 0.300030
Train loss on 150 batch: 0.259558
Train loss on 200 batch: 0.267123
Train loss on 250 batch: 0.257923
: Epoch: 362 | Training Loss: 0.291216 | Val. Loss: 0.523668 | Val. Kappa Score: 0.8172 | LR: 0.000737 | Estimated time: 64.81
Train loss on 50 batch: 0.263565
Train loss on 100 batch: 0.250693
Train loss on 150 batch: 0.221518
Train loss on 200 batch: 0.263802
Train loss on 250 batch: 0.230443
: Epoch: 363 | Training Loss: 0.250300 | Val. Loss: 0.532912 | Val. Kappa Score: 0.8172 | LR: 0.000697 | Estimated time: 64.70
Train loss on 50 batch: 0.326985
Train loss on 100 batch: 0.289902
Train loss on 150 batch: 0.236595
Train loss on 200 batch: 0.241136
Train loss on 250 batch: 0.243544
: Epoch: 364 | Training Loss: 0.266831 | Val. Loss: 0.529311 | Val. Kappa Score: 0.8172 | LR: 0.000655 | Estimated time: 64.76
Train loss on 50 batch: 0.249930
Train loss on 100 batch: 0.244110
Train loss on 150 batch: 0.208450
Train loss on 200 batch: 0.252350
Train loss on 250 batch: 0.209412
: Epoch: 365 | Training Loss: 0.243992 | Val. Loss: 0.500152 | Val. Kappa Score: 0.8173 | LR: 0.000611 | Estimated time: 64.75
Train loss on 50 batch: 0.293660
Train loss on 100 batch: 0.303998
Train loss on 150 batch: 0.236417
Train loss on 200 batch: 0.248978
Train loss on 250 batch: 0.236027
: Epoch: 366 | Training Loss: 0.259458 | Val. Loss: 0.503087 | Val. Kappa Score: 0.8174 | LR: 0.000567 | Estimated time: 64.77
Train loss on 50 batch: 0.239509
Train loss on 100 batch: 0.263244
Train loss on 150 batch: 0.198263
Train loss on 200 batch: 0.205318
Train loss on 250 batch: 0.211384
: Epoch: 367 | Training Loss: 0.226767 | Val. Loss: 0.535507 | Val. Kappa Score: 0.8174 | LR: 0.000522 | Estimated time: 64.71
Train loss on 50 batch: 0.225949
Train loss on 100 batch: 0.221941
Train loss on 150 batch: 0.233863
Train loss on 200 batch: 0.203656
Train loss on 250 batch: 0.211036
: Epoch: 368 | Training Loss: 0.223617 | Val. Loss: 0.549488 | Val. Kappa Score: 0.8174 | LR: 0.000478 | Estimated time: 64.60
Train loss on 50 batch: 0.228540
Train loss on 100 batch: 0.246260
Train loss on 150 batch: 0.219140
Train loss on 200 batch: 0.197155
Train loss on 250 batch: 0.207046
: Epoch: 369 | Training Loss: 0.215918 | Val. Loss: 0.488409 | Val. Kappa Score: 0.8175 | LR: 0.000433 | Estimated time: 64.65
Train loss on 50 batch: 0.197752
Train loss on 100 batch: 0.204711
Train loss on 150 batch: 0.225072
Train loss on 200 batch: 0.202140
Train loss on 250 batch: 0.163332
: Epoch: 370 | Training Loss: 0.192460 | Val. Loss: 0.453909 | Val. Kappa Score: 0.8176 | LR: 0.000389 | Estimated time: 64.81
Train loss on 50 batch: 0.179652
Train loss on 100 batch: 0.185177
Train loss on 150 batch: 0.201713
Train loss on 200 batch: 0.202518
Train loss on 250 batch: 0.200996
: Epoch: 371 | Training Loss: 0.199568 | Val. Loss: 0.482815 | Val. Kappa Score: 0.8177 | LR: 0.000345 | Estimated time: 64.80
Train loss on 50 batch: 0.210212
Train loss on 100 batch: 0.181338
Train loss on 150 batch: 0.181910
Train loss on 200 batch: 0.201304
Train loss on 250 batch: 0.200253
: Epoch: 372 | Training Loss: 0.194155 | Val. Loss: 0.446176 | Val. Kappa Score: 0.8177 | LR: 0.000303 | Estimated time: 64.75
Train loss on 50 batch: 0.186182
Train loss on 100 batch: 0.172609
Train loss on 150 batch: 0.193327
Train loss on 200 batch: 0.181854
Train loss on 250 batch: 0.198595
: Epoch: 373 | Training Loss: 0.182495 | Val. Loss: 0.486226 | Val. Kappa Score: 0.8178 | LR: 0.000263 | Estimated time: 64.73
Train loss on 50 batch: 0.180637
Train loss on 100 batch: 0.156596
Train loss on 150 batch: 0.169412
Train loss on 200 batch: 0.171972
Train loss on 250 batch: 0.164342
: Epoch: 374 | Training Loss: 0.180499 | Val. Loss: 0.520726 | Val. Kappa Score: 0.8179 | LR: 0.000225 | Estimated time: 64.64
Train loss on 50 batch: 0.180943
Train loss on 100 batch: 0.174628
Train loss on 150 batch: 0.161787
Train loss on 200 batch: 0.171411
Train loss on 250 batch: 0.167654
: Epoch: 375 | Training Loss: 0.170055 | Val. Loss: 0.502857 | Val. Kappa Score: 0.8180 | LR: 0.000188 | Estimated time: 64.75
Train loss on 50 batch: 0.138130
Train loss on 100 batch: 0.163095
Train loss on 150 batch: 0.181245
Train loss on 200 batch: 0.163026
Train loss on 250 batch: 0.180061
: Epoch: 376 | Training Loss: 0.172917 | Val. Loss: 0.457920 | Val. Kappa Score: 0.8180 | LR: 0.000154 | Estimated time: 64.65
Train loss on 50 batch: 0.141237
Train loss on 100 batch: 0.185252
Train loss on 150 batch: 0.153467
Train loss on 200 batch: 0.169821
Train loss on 250 batch: 0.144715
: Epoch: 377 | Training Loss: 0.178891 | Val. Loss: 0.456100 | Val. Kappa Score: 0.8182 | LR: 0.000123 | Estimated time: 64.52
Train loss on 50 batch: 0.173189
Train loss on 100 batch: 0.155599
Train loss on 150 batch: 0.157720
Train loss on 200 batch: 0.154995
Train loss on 250 batch: 0.160439
: Epoch: 378 | Training Loss: 0.157631 | Val. Loss: 0.472392 | Val. Kappa Score: 0.8182 | LR: 0.000095 | Estimated time: 64.56
Train loss on 50 batch: 0.141637
Train loss on 100 batch: 0.163172
Train loss on 150 batch: 0.152083
Train loss on 200 batch: 0.154034
Train loss on 250 batch: 0.155001
: Epoch: 379 | Training Loss: 0.154871 | Val. Loss: 0.476158 | Val. Kappa Score: 0.8183 | LR: 0.000071 | Estimated time: 64.70
Train loss on 50 batch: 0.141678
Train loss on 100 batch: 0.146883
Train loss on 150 batch: 0.162716
Train loss on 200 batch: 0.157346
Train loss on 250 batch: 0.155974
: Epoch: 380 | Training Loss: 0.164770 | Val. Loss: 0.481659 | Val. Kappa Score: 0.8184 | LR: 0.000050 | Estimated time: 64.77
Train loss on 50 batch: 0.154540
Train loss on 100 batch: 0.136498
Train loss on 150 batch: 0.139904
Train loss on 200 batch: 0.177903
Train loss on 250 batch: 0.169983
: Epoch: 381 | Training Loss: 0.154307 | Val. Loss: 0.477263 | Val. Kappa Score: 0.8185 | LR: 0.000032 | Estimated time: 64.66
Train loss on 50 batch: 0.164718
Train loss on 100 batch: 0.150302
Train loss on 150 batch: 0.148451
Train loss on 200 batch: 0.145074
Train loss on 250 batch: 0.168981
: Epoch: 382 | Training Loss: 0.156330 | Val. Loss: 0.471568 | Val. Kappa Score: 0.8185 | LR: 0.000018 | Estimated time: 64.49
Train loss on 50 batch: 0.145298
Train loss on 100 batch: 0.148498
Train loss on 150 batch: 0.157768
Train loss on 200 batch: 0.153344
Train loss on 250 batch: 0.144471
: Epoch: 383 | Training Loss: 0.147723 | Val. Loss: 0.480275 | Val. Kappa Score: 0.8186 | LR: 0.000008 | Estimated time: 64.49
Train loss on 50 batch: 0.157119
Train loss on 100 batch: 0.155822
Train loss on 150 batch: 0.137710
Train loss on 200 batch: 0.126470
Train loss on 250 batch: 0.147756
: Epoch: 384 | Training Loss: 0.155912 | Val. Loss: 0.490623 | Val. Kappa Score: 0.8187 | LR: 0.000002 | Estimated time: 64.52
Train loss on 50 batch: 0.149638
Train loss on 100 batch: 0.167007
Train loss on 150 batch: 0.132642
Train loss on 200 batch: 0.142293
Train loss on 250 batch: 0.145434
: Epoch: 385 | Training Loss: 0.155906 | Val. Loss: 0.471116 | Val. Kappa Score: 0.8187 | LR: 0.000000 | Estimated time: 64.55
Train loss on 50 batch: 0.150876
Train loss on 100 batch: 0.136605
Train loss on 150 batch: 0.146930
Train loss on 200 batch: 0.142765
Train loss on 250 batch: 0.161738
: Epoch: 386 | Training Loss: 0.149633 | Val. Loss: 0.462495 | Val. Kappa Score: 0.8188 | LR: 0.000002 | Estimated time: 64.47
Train loss on 50 batch: 0.147181
Train loss on 100 batch: 0.147939
Train loss on 150 batch: 0.136557
Train loss on 200 batch: 0.143206
Train loss on 250 batch: 0.140440
: Epoch: 387 | Training Loss: 0.146454 | Val. Loss: 0.493631 | Val. Kappa Score: 0.8187 | LR: 0.000008 | Estimated time: 64.53
Train loss on 50 batch: 0.137778
Train loss on 100 batch: 0.142426
Train loss on 150 batch: 0.178832
Train loss on 200 batch: 0.159657
Train loss on 250 batch: 0.126132
: Epoch: 388 | Training Loss: 0.149970 | Val. Loss: 0.495748 | Val. Kappa Score: 0.8188 | LR: 0.000018 | Estimated time: 64.48
Train loss on 50 batch: 0.142188
Train loss on 100 batch: 0.139966
Train loss on 150 batch: 0.151372
Train loss on 200 batch: 0.140957
Train loss on 250 batch: 0.153550
: Epoch: 389 | Training Loss: 0.149998 | Val. Loss: 0.474112 | Val. Kappa Score: 0.8188 | LR: 0.000032 | Estimated time: 64.57
Train loss on 50 batch: 0.159656
Train loss on 100 batch: 0.145224
Train loss on 150 batch: 0.152160
Train loss on 200 batch: 0.134359
Train loss on 250 batch: 0.153010
: Epoch: 390 | Training Loss: 0.145128 | Val. Loss: 0.480432 | Val. Kappa Score: 0.8189 | LR: 0.000050 | Estimated time: 64.46
Train loss on 50 batch: 0.161616
Train loss on 100 batch: 0.138719
Train loss on 150 batch: 0.160638
Train loss on 200 batch: 0.133449
Train loss on 250 batch: 0.160833
: Epoch: 391 | Training Loss: 0.148404 | Val. Loss: 0.476308 | Val. Kappa Score: 0.8190 | LR: 0.000071 | Estimated time: 64.43
Train loss on 50 batch: 0.140387
Train loss on 100 batch: 0.131337
Train loss on 150 batch: 0.149037
Train loss on 200 batch: 0.143564
Train loss on 250 batch: 0.147664
: Epoch: 392 | Training Loss: 0.157595 | Val. Loss: 0.503061 | Val. Kappa Score: 0.8191 | LR: 0.000095 | Estimated time: 64.49
Train loss on 50 batch: 0.164735
Train loss on 100 batch: 0.144873
Train loss on 150 batch: 0.137086
Train loss on 200 batch: 0.142886
Train loss on 250 batch: 0.163895
: Epoch: 393 | Training Loss: 0.151129 | Val. Loss: 0.460194 | Val. Kappa Score: 0.8191 | LR: 0.000123 | Estimated time: 64.76
Train loss on 50 batch: 0.144649
Train loss on 100 batch: 0.146184
Train loss on 150 batch: 0.140578
Train loss on 200 batch: 0.169614
Train loss on 250 batch: 0.137703
: Epoch: 394 | Training Loss: 0.149034 | Val. Loss: 0.491699 | Val. Kappa Score: 0.8192 | LR: 0.000154 | Estimated time: 64.77
Train loss on 50 batch: 0.136946
Train loss on 100 batch: 0.145011
Train loss on 150 batch: 0.139151
Train loss on 200 batch: 0.142832
Train loss on 250 batch: 0.164422
: Epoch: 395 | Training Loss: 0.157239 | Val. Loss: 0.532348 | Val. Kappa Score: 0.8192 | LR: 0.000188 | Estimated time: 64.76
Train loss on 50 batch: 0.179741
Train loss on 100 batch: 0.171502
Train loss on 150 batch: 0.147877
Train loss on 200 batch: 0.148108
Train loss on 250 batch: 0.154177
: Epoch: 396 | Training Loss: 0.157658 | Val. Loss: 0.473841 | Val. Kappa Score: 0.8193 | LR: 0.000225 | Estimated time: 64.89
Train loss on 50 batch: 0.133788
Train loss on 100 batch: 0.155338
Train loss on 150 batch: 0.181544
Train loss on 200 batch: 0.161919
Train loss on 250 batch: 0.150448
: Epoch: 397 | Training Loss: 0.161270 | Val. Loss: 0.475949 | Val. Kappa Score: 0.8194 | LR: 0.000263 | Estimated time: 64.89
Train loss on 50 batch: 0.163242
Train loss on 100 batch: 0.161988
Train loss on 150 batch: 0.164364
Train loss on 200 batch: 0.167302
Train loss on 250 batch: 0.145046
: Epoch: 398 | Training Loss: 0.171914 | Val. Loss: 0.520421 | Val. Kappa Score: 0.8194 | LR: 0.000303 | Estimated time: 64.90
Train loss on 50 batch: 0.223088
Train loss on 100 batch: 0.184394
Train loss on 150 batch: 0.177120
Train loss on 200 batch: 0.161738
Train loss on 250 batch: 0.166472
: Epoch: 399 | Training Loss: 0.196198 | Val. Loss: 0.473777 | Val. Kappa Score: 0.8195 | LR: 0.000345 | Estimated time: 64.77
Train loss on 50 batch: 0.192486
Train loss on 100 batch: 0.172755
Train loss on 150 batch: 0.178693
Train loss on 200 batch: 0.189616
Train loss on 250 batch: 0.148897
: Epoch: 400 | Training Loss: 0.178032 | Val. Loss: 0.492433 | Val. Kappa Score: 0.8195 | LR: 0.000389 | Estimated time: 64.69
Train loss on 50 batch: 0.155687
Train loss on 100 batch: 0.172386
Train loss on 150 batch: 0.181623
Train loss on 200 batch: 0.150238
Train loss on 250 batch: 0.195642
: Epoch: 401 | Training Loss: 0.179151 | Val. Loss: 0.446373 | Val. Kappa Score: 0.8196 | LR: 0.000433 | Estimated time: 64.62
Train loss on 50 batch: 0.212537
Train loss on 100 batch: 0.192778
Train loss on 150 batch: 0.168177
Train loss on 200 batch: 0.171063
Train loss on 250 batch: 0.171341
: Epoch: 402 | Training Loss: 0.183496 | Val. Loss: 0.456137 | Val. Kappa Score: 0.8197 | LR: 0.000478 | Estimated time: 64.80
Train loss on 50 batch: 0.161750
Train loss on 100 batch: 0.178551
Train loss on 150 batch: 0.170446
Train loss on 200 batch: 0.156017
Train loss on 250 batch: 0.166217
: Epoch: 403 | Training Loss: 0.174696 | Val. Loss: 0.478408 | Val. Kappa Score: 0.8197 | LR: 0.000522 | Estimated time: 64.77
Train loss on 50 batch: 0.186866
Train loss on 100 batch: 0.163630
Train loss on 150 batch: 0.170246
Train loss on 200 batch: 0.184936
Train loss on 250 batch: 0.194903
: Epoch: 404 | Training Loss: 0.190234 | Val. Loss: 0.482212 | Val. Kappa Score: 0.8198 | LR: 0.000567 | Estimated time: 64.74
Train loss on 50 batch: 0.210552
Train loss on 100 batch: 0.194797
Train loss on 150 batch: 0.194130
Train loss on 200 batch: 0.160303
Train loss on 250 batch: 0.253458
: Epoch: 405 | Training Loss: 0.213726 | Val. Loss: 0.492550 | Val. Kappa Score: 0.8198 | LR: 0.000611 | Estimated time: 64.65
Train loss on 50 batch: 0.192350
Train loss on 100 batch: 0.201142
Train loss on 150 batch: 0.188539
Train loss on 200 batch: 0.220773
Train loss on 250 batch: 0.207830
: Epoch: 406 | Training Loss: 0.208133 | Val. Loss: 0.497639 | Val. Kappa Score: 0.8199 | LR: 0.000655 | Estimated time: 64.80
Train loss on 50 batch: 0.271649
Train loss on 100 batch: 0.237102
Train loss on 150 batch: 0.191110
Train loss on 200 batch: 0.206030
Train loss on 250 batch: 0.200935
: Epoch: 407 | Training Loss: 0.216017 | Val. Loss: 0.584374 | Val. Kappa Score: 0.8199 | LR: 0.000697 | Estimated time: 64.87
Train loss on 50 batch: 0.212846
Train loss on 100 batch: 0.186631
Train loss on 150 batch: 0.183446
Train loss on 200 batch: 0.187194
Train loss on 250 batch: 0.220289
: Epoch: 408 | Training Loss: 0.200260 | Val. Loss: 0.538566 | Val. Kappa Score: 0.8199 | LR: 0.000737 | Estimated time: 64.88
Train loss on 50 batch: 0.230941
Train loss on 100 batch: 0.215939
Train loss on 150 batch: 0.243557
Train loss on 200 batch: 0.226316
Train loss on 250 batch: 0.224388
: Epoch: 409 | Training Loss: 0.239447 | Val. Loss: 0.578403 | Val. Kappa Score: 0.8199 | LR: 0.000775 | Estimated time: 64.93
Train loss on 50 batch: 0.423252
Train loss on 100 batch: 0.393740
Train loss on 150 batch: 0.333111
Train loss on 200 batch: 0.335903
Train loss on 250 batch: 0.318280
: Epoch: 410 | Training Loss: 0.361259 | Val. Loss: 0.557387 | Val. Kappa Score: 0.8199 | LR: 0.000812 | Estimated time: 64.65
Train loss on 50 batch: 0.302109
Train loss on 100 batch: 0.260111
Train loss on 150 batch: 0.262470
Train loss on 200 batch: 0.215393
Train loss on 250 batch: 0.258739
: Epoch: 411 | Training Loss: 0.273650 | Val. Loss: 0.555042 | Val. Kappa Score: 0.8199 | LR: 0.000846 | Estimated time: 64.84
Train loss on 50 batch: 0.283931
Train loss on 100 batch: 0.273562
Train loss on 150 batch: 0.261106
Train loss on 200 batch: 0.275403
Train loss on 250 batch: 0.232394
: Epoch: 412 | Training Loss: 0.255696 | Val. Loss: 0.679453 | Val. Kappa Score: 0.8198 | LR: 0.000877 | Estimated time: 64.96
Train loss on 50 batch: 0.230428
Train loss on 100 batch: 0.244993
Train loss on 150 batch: 0.230600
Train loss on 200 batch: 0.254271
Train loss on 250 batch: 0.238909
: Epoch: 413 | Training Loss: 0.236127 | Val. Loss: 0.565625 | Val. Kappa Score: 0.8198 | LR: 0.000905 | Estimated time: 64.68
Train loss on 50 batch: 0.183012
Train loss on 100 batch: 0.208589
Train loss on 150 batch: 0.228289
Train loss on 200 batch: 0.218778
Train loss on 250 batch: 0.234043
: Epoch: 414 | Training Loss: 0.226713 | Val. Loss: 0.666015 | Val. Kappa Score: 0.8198 | LR: 0.000929 | Estimated time: 64.74
Train loss on 50 batch: 0.299095
Train loss on 100 batch: 0.259640
Train loss on 150 batch: 0.219082
Train loss on 200 batch: 0.251694
Train loss on 250 batch: 0.196518
: Epoch: 415 | Training Loss: 0.243029 | Val. Loss: 0.653685 | Val. Kappa Score: 0.8198 | LR: 0.000950 | Estimated time: 64.80
Train loss on 50 batch: 0.279737
Train loss on 100 batch: 0.225397
Train loss on 150 batch: 0.236722
Train loss on 200 batch: 0.244537
Train loss on 250 batch: 0.216812
: Epoch: 416 | Training Loss: 0.235010 | Val. Loss: 0.498809 | Val. Kappa Score: 0.8198 | LR: 0.000968 | Estimated time: 64.79
Train loss on 50 batch: 0.226756
Train loss on 100 batch: 0.222188
Train loss on 150 batch: 0.226147
Train loss on 200 batch: 0.220267
Train loss on 250 batch: 0.229049
: Epoch: 417 | Training Loss: 0.222673 | Val. Loss: 0.484506 | Val. Kappa Score: 0.8198 | LR: 0.000982 | Estimated time: 64.66
Train loss on 50 batch: 0.207129
Train loss on 100 batch: 0.187596
Train loss on 150 batch: 0.258712
Train loss on 200 batch: 0.189189
Train loss on 250 batch: 0.211486
: Epoch: 418 | Training Loss: 0.213854 | Val. Loss: 0.510877 | Val. Kappa Score: 0.8199 | LR: 0.000992 | Estimated time: 64.76
Train loss on 50 batch: 0.214004
Train loss on 100 batch: 0.244223
Train loss on 150 batch: 0.224268
Train loss on 200 batch: 0.223144
Train loss on 250 batch: 0.251947
: Epoch: 419 | Training Loss: 0.242489 | Val. Loss: 0.516041 | Val. Kappa Score: 0.8199 | LR: 0.000998 | Estimated time: 64.68
Train loss on 50 batch: 0.297962
Train loss on 100 batch: 0.241955
Train loss on 150 batch: 0.219785
Train loss on 200 batch: 0.276836
Train loss on 250 batch: 0.316809
: Epoch: 420 | Training Loss: 0.291623 | Val. Loss: 0.562137 | Val. Kappa Score: 0.8199 | LR: 0.001000 | Estimated time: 64.81
Train loss on 50 batch: 0.311530
Train loss on 100 batch: 0.276875
Train loss on 150 batch: 0.250610
Train loss on 200 batch: 0.261611
Train loss on 250 batch: 0.255108
: Epoch: 421 | Training Loss: 0.272777 | Val. Loss: 0.530485 | Val. Kappa Score: 0.8199 | LR: 0.000998 | Estimated time: 64.74
Train loss on 50 batch: 0.294400
Train loss on 100 batch: 0.243337
Train loss on 150 batch: 0.232736
Train loss on 200 batch: 0.219739
Train loss on 250 batch: 0.251800
: Epoch: 422 | Training Loss: 0.265009 | Val. Loss: 0.491367 | Val. Kappa Score: 0.8199 | LR: 0.000992 | Estimated time: 64.80
Train loss on 50 batch: 0.295183
Train loss on 100 batch: 0.278885
Train loss on 150 batch: 0.260994
Train loss on 200 batch: 0.298395
Train loss on 250 batch: 0.225779
: Epoch: 423 | Training Loss: 0.273888 | Val. Loss: 0.497515 | Val. Kappa Score: 0.8199 | LR: 0.000982 | Estimated time: 64.73
Train loss on 50 batch: 0.244893
Train loss on 100 batch: 0.237194
Train loss on 150 batch: 0.212023
Train loss on 200 batch: 0.242049
Train loss on 250 batch: 0.227793
: Epoch: 424 | Training Loss: 0.241788 | Val. Loss: 0.486682 | Val. Kappa Score: 0.8200 | LR: 0.000968 | Estimated time: 64.76
Train loss on 50 batch: 0.202566
Train loss on 100 batch: 0.231879
Train loss on 150 batch: 0.212578
Train loss on 200 batch: 0.246581
Train loss on 250 batch: 0.226845
: Epoch: 425 | Training Loss: 0.233395 | Val. Loss: 0.555844 | Val. Kappa Score: 0.8200 | LR: 0.000950 | Estimated time: 64.80
Train loss on 50 batch: 0.269419
Train loss on 100 batch: 0.211921
Train loss on 150 batch: 0.256200
Train loss on 200 batch: 0.282365
Train loss on 250 batch: 0.285741
: Epoch: 426 | Training Loss: 0.265528 | Val. Loss: 0.496562 | Val. Kappa Score: 0.8200 | LR: 0.000929 | Estimated time: 64.87
Train loss on 50 batch: 0.233624
Train loss on 100 batch: 0.236654
Train loss on 150 batch: 0.225437
Train loss on 200 batch: 0.230476
Train loss on 250 batch: 0.235335
: Epoch: 427 | Training Loss: 0.245558 | Val. Loss: 0.532236 | Val. Kappa Score: 0.8200 | LR: 0.000905 | Estimated time: 64.66
Train loss on 50 batch: 0.582280
Train loss on 100 batch: 0.461607
Train loss on 150 batch: 0.340959
Train loss on 200 batch: 0.373033
Train loss on 250 batch: 0.252960
: Epoch: 428 | Training Loss: 0.371233 | Val. Loss: 0.666117 | Val. Kappa Score: 0.8199 | LR: 0.000877 | Estimated time: 64.66
Train loss on 50 batch: 0.210640
Train loss on 100 batch: 0.248511
Train loss on 150 batch: 0.274291
Train loss on 200 batch: 0.306181
Train loss on 250 batch: 0.260668
: Epoch: 429 | Training Loss: 0.266160 | Val. Loss: 0.548083 | Val. Kappa Score: 0.8200 | LR: 0.000846 | Estimated time: 64.62
Train loss on 50 batch: 0.282338
Train loss on 100 batch: 0.273567
Train loss on 150 batch: 0.228241
Train loss on 200 batch: 0.226390
Train loss on 250 batch: 0.230348
: Epoch: 430 | Training Loss: 0.264786 | Val. Loss: 0.501775 | Val. Kappa Score: 0.8200 | LR: 0.000812 | Estimated time: 64.72
Train loss on 50 batch: 0.448603
Train loss on 100 batch: 0.291087
Train loss on 150 batch: 0.269392
Train loss on 200 batch: 0.219046
Train loss on 250 batch: 0.263507
: Epoch: 431 | Training Loss: 0.286060 | Val. Loss: 0.578481 | Val. Kappa Score: 0.8200 | LR: 0.000775 | Estimated time: 64.81
Train loss on 50 batch: 0.291544
Train loss on 100 batch: 0.291122
Train loss on 150 batch: 0.237910
Train loss on 200 batch: 0.262599
Train loss on 250 batch: 0.212765
: Epoch: 432 | Training Loss: 0.255847 | Val. Loss: 0.497675 | Val. Kappa Score: 0.8200 | LR: 0.000737 | Estimated time: 64.75
Train loss on 50 batch: 0.223779
Train loss on 100 batch: 0.227517
Train loss on 150 batch: 0.231114
Train loss on 200 batch: 0.282086
Train loss on 250 batch: 0.250360
: Epoch: 433 | Training Loss: 0.251468 | Val. Loss: 0.479974 | Val. Kappa Score: 0.8201 | LR: 0.000697 | Estimated time: 64.87
Train loss on 50 batch: 0.248806
Train loss on 100 batch: 0.229692
Train loss on 150 batch: 0.197106
Train loss on 200 batch: 0.176639
Train loss on 250 batch: 0.227844
: Epoch: 434 | Training Loss: 0.230329 | Val. Loss: 0.480596 | Val. Kappa Score: 0.8201 | LR: 0.000655 | Estimated time: 64.74
Train loss on 50 batch: 0.253650
Train loss on 100 batch: 0.262181
Train loss on 150 batch: 0.237588
Train loss on 200 batch: 0.274183
Train loss on 250 batch: 0.176909
: Epoch: 435 | Training Loss: 0.231664 | Val. Loss: 0.520164 | Val. Kappa Score: 0.8201 | LR: 0.000611 | Estimated time: 64.80
Train loss on 50 batch: 0.191663
Train loss on 100 batch: 0.209491
Train loss on 150 batch: 0.212679
Train loss on 200 batch: 0.244801
Train loss on 250 batch: 0.170666
: Epoch: 436 | Training Loss: 0.202469 | Val. Loss: 0.486420 | Val. Kappa Score: 0.8201 | LR: 0.000567 | Estimated time: 64.77
Train loss on 50 batch: 0.189596
Train loss on 100 batch: 0.200448
Train loss on 150 batch: 0.175793
Train loss on 200 batch: 0.215394
Train loss on 250 batch: 0.175496
: Epoch: 437 | Training Loss: 0.194592 | Val. Loss: 0.507316 | Val. Kappa Score: 0.8201 | LR: 0.000522 | Estimated time: 64.56
Train loss on 50 batch: 0.185235
Train loss on 100 batch: 0.163184
Train loss on 150 batch: 0.174097
Train loss on 200 batch: 0.185675
Train loss on 250 batch: 0.201671
: Epoch: 438 | Training Loss: 0.190068 | Val. Loss: 0.481928 | Val. Kappa Score: 0.8202 | LR: 0.000478 | Estimated time: 64.78
Train loss on 50 batch: 0.208002
Train loss on 100 batch: 0.179212
Train loss on 150 batch: 0.180855
Train loss on 200 batch: 0.169322
Train loss on 250 batch: 0.155288
: Epoch: 439 | Training Loss: 0.182201 | Val. Loss: 0.477823 | Val. Kappa Score: 0.8202 | LR: 0.000433 | Estimated time: 64.80
Train loss on 50 batch: 0.178458
Train loss on 100 batch: 0.200995
Train loss on 150 batch: 0.157581
Train loss on 200 batch: 0.153049
Train loss on 250 batch: 0.176768
: Epoch: 440 | Training Loss: 0.175571 | Val. Loss: 0.519627 | Val. Kappa Score: 0.8202 | LR: 0.000389 | Estimated time: 64.80
Train loss on 50 batch: 0.142306
Train loss on 100 batch: 0.172293
Train loss on 150 batch: 0.172334
Train loss on 200 batch: 0.180990
Train loss on 250 batch: 0.188825
: Epoch: 441 | Training Loss: 0.173547 | Val. Loss: 0.466491 | Val. Kappa Score: 0.8203 | LR: 0.000345 | Estimated time: 64.67
Train loss on 50 batch: 0.158975
Train loss on 100 batch: 0.162395
Train loss on 150 batch: 0.160388
Train loss on 200 batch: 0.175701
Train loss on 250 batch: 0.170492
: Epoch: 442 | Training Loss: 0.169198 | Val. Loss: 0.534743 | Val. Kappa Score: 0.8203 | LR: 0.000303 | Estimated time: 64.79
Train loss on 50 batch: 0.184852
Train loss on 100 batch: 0.214262
Train loss on 150 batch: 0.181795
Train loss on 200 batch: 0.151849
Train loss on 250 batch: 0.166203
: Epoch: 443 | Training Loss: 0.176610 | Val. Loss: 0.520327 | Val. Kappa Score: 0.8204 | LR: 0.000263 | Estimated time: 64.74
Train loss on 50 batch: 0.140745
Train loss on 100 batch: 0.153240
Train loss on 150 batch: 0.166725
Train loss on 200 batch: 0.167202
Train loss on 250 batch: 0.157747
: Epoch: 444 | Training Loss: 0.155733 | Val. Loss: 0.478632 | Val. Kappa Score: 0.8204 | LR: 0.000225 | Estimated time: 64.84
Train loss on 50 batch: 0.145057
Train loss on 100 batch: 0.160175
Train loss on 150 batch: 0.146672
Train loss on 200 batch: 0.132948
Train loss on 250 batch: 0.153107
: Epoch: 445 | Training Loss: 0.158873 | Val. Loss: 0.526033 | Val. Kappa Score: 0.8205 | LR: 0.000188 | Estimated time: 64.78
Train loss on 50 batch: 0.144863
Train loss on 100 batch: 0.146596
Train loss on 150 batch: 0.143516
Train loss on 200 batch: 0.168225
Train loss on 250 batch: 0.136499
: Epoch: 446 | Training Loss: 0.147636 | Val. Loss: 0.486187 | Val. Kappa Score: 0.8205 | LR: 0.000154 | Estimated time: 64.75
Train loss on 50 batch: 0.140860
Train loss on 100 batch: 0.134781
Train loss on 150 batch: 0.150113
Train loss on 200 batch: 0.136860
Train loss on 250 batch: 0.141780
: Epoch: 447 | Training Loss: 0.143282 | Val. Loss: 0.474642 | Val. Kappa Score: 0.8205 | LR: 0.000123 | Estimated time: 64.82
Train loss on 50 batch: 0.139796
Train loss on 100 batch: 0.120878
Train loss on 150 batch: 0.146311
Train loss on 200 batch: 0.119093
Train loss on 250 batch: 0.144824
: Epoch: 448 | Training Loss: 0.139252 | Val. Loss: 0.500849 | Val. Kappa Score: 0.8206 | LR: 0.000095 | Estimated time: 64.71
Train loss on 50 batch: 0.136867
Train loss on 100 batch: 0.156361
Train loss on 150 batch: 0.138340
Train loss on 200 batch: 0.125112
Train loss on 250 batch: 0.117349
: Epoch: 449 | Training Loss: 0.153070 | Val. Loss: 0.469084 | Val. Kappa Score: 0.8206 | LR: 0.000071 | Estimated time: 64.60
Train loss on 50 batch: 0.140263
Train loss on 100 batch: 0.125297
Train loss on 150 batch: 0.131335
Train loss on 200 batch: 0.129491
Train loss on 250 batch: 0.148009
: Epoch: 450 | Training Loss: 0.140768 | Val. Loss: 0.473899 | Val. Kappa Score: 0.8207 | LR: 0.000050 | Estimated time: 64.64
Train loss on 50 batch: 0.123903
Train loss on 100 batch: 0.127090
Train loss on 150 batch: 0.128435
Train loss on 200 batch: 0.122214
Train loss on 250 batch: 0.128922
: Epoch: 451 | Training Loss: 0.128482 | Val. Loss: 0.475282 | Val. Kappa Score: 0.8207 | LR: 0.000032 | Estimated time: 64.60
Train loss on 50 batch: 0.119076
Train loss on 100 batch: 0.138818
Train loss on 150 batch: 0.139516
Train loss on 200 batch: 0.128730
Train loss on 250 batch: 0.121511
: Epoch: 452 | Training Loss: 0.127580 | Val. Loss: 0.482518 | Val. Kappa Score: 0.8207 | LR: 0.000018 | Estimated time: 64.57
Train loss on 50 batch: 0.120666
Train loss on 100 batch: 0.119169
Train loss on 150 batch: 0.131661
Train loss on 200 batch: 0.127361
Train loss on 250 batch: 0.125101
: Epoch: 453 | Training Loss: 0.126677 | Val. Loss: 0.509231 | Val. Kappa Score: 0.8208 | LR: 0.000008 | Estimated time: 64.48
Train loss on 50 batch: 0.145200
Train loss on 100 batch: 0.114246
Train loss on 150 batch: 0.126919
Train loss on 200 batch: 0.120624
Train loss on 250 batch: 0.124171
: Epoch: 454 | Training Loss: 0.127598 | Val. Loss: 0.499642 | Val. Kappa Score: 0.8208 | LR: 0.000002 | Estimated time: 64.66
Train loss on 50 batch: 0.117376
Train loss on 100 batch: 0.123232
Train loss on 150 batch: 0.107521
Train loss on 200 batch: 0.124124
Train loss on 250 batch: 0.144850
: Epoch: 455 | Training Loss: 0.126153 | Val. Loss: 0.492833 | Val. Kappa Score: 0.8208 | LR: 0.000000 | Estimated time: 64.51
Train loss on 50 batch: 0.115463
Train loss on 100 batch: 0.123541
Train loss on 150 batch: 0.134324
Train loss on 200 batch: 0.133790
Train loss on 250 batch: 0.113986
: Epoch: 456 | Training Loss: 0.128664 | Val. Loss: 0.475634 | Val. Kappa Score: 0.8209 | LR: 0.000002 | Estimated time: 64.61
Train loss on 50 batch: 0.117463
Train loss on 100 batch: 0.136468
Train loss on 150 batch: 0.120732
Train loss on 200 batch: 0.125686
Train loss on 250 batch: 0.125270
: Epoch: 457 | Training Loss: 0.125221 | Val. Loss: 0.487462 | Val. Kappa Score: 0.8209 | LR: 0.000008 | Estimated time: 64.53
Train loss on 50 batch: 0.127222
Train loss on 100 batch: 0.122493
Train loss on 150 batch: 0.121418
Train loss on 200 batch: 0.126016
Train loss on 250 batch: 0.142405
: Epoch: 458 | Training Loss: 0.129931 | Val. Loss: 0.508810 | Val. Kappa Score: 0.8210 | LR: 0.000018 | Estimated time: 64.46
Train loss on 50 batch: 0.143124
Train loss on 100 batch: 0.116328
Train loss on 150 batch: 0.121731
Train loss on 200 batch: 0.127887
Train loss on 250 batch: 0.120721
: Epoch: 459 | Training Loss: 0.125319 | Val. Loss: 0.483987 | Val. Kappa Score: 0.8210 | LR: 0.000032 | Estimated time: 64.49
Train loss on 50 batch: 0.118294
Train loss on 100 batch: 0.133854
Train loss on 150 batch: 0.110073
Train loss on 200 batch: 0.114954
Train loss on 250 batch: 0.143527
: Epoch: 460 | Training Loss: 0.127386 | Val. Loss: 0.497867 | Val. Kappa Score: 0.8210 | LR: 0.000050 | Estimated time: 64.47
Train loss on 50 batch: 0.129703
Train loss on 100 batch: 0.138415
Train loss on 150 batch: 0.137349
Train loss on 200 batch: 0.136576
Train loss on 250 batch: 0.110887
: Epoch: 461 | Training Loss: 0.135806 | Val. Loss: 0.479117 | Val. Kappa Score: 0.8210 | LR: 0.000071 | Estimated time: 64.44
Train loss on 50 batch: 0.121366
Train loss on 100 batch: 0.126280
Train loss on 150 batch: 0.127767
Train loss on 200 batch: 0.124064
Train loss on 250 batch: 0.137834
: Epoch: 462 | Training Loss: 0.124662 | Val. Loss: 0.484363 | Val. Kappa Score: 0.8211 | LR: 0.000095 | Estimated time: 64.78
Train loss on 50 batch: 0.120634
Train loss on 100 batch: 0.137744
Train loss on 150 batch: 0.133112
Train loss on 200 batch: 0.131173
Train loss on 250 batch: 0.123002
: Epoch: 463 | Training Loss: 0.138960 | Val. Loss: 0.548025 | Val. Kappa Score: 0.8211 | LR: 0.000123 | Estimated time: 64.69
Train loss on 50 batch: 0.141533
Train loss on 100 batch: 0.132413
Train loss on 150 batch: 0.132850
Train loss on 200 batch: 0.137561
Train loss on 250 batch: 0.119491
: Epoch: 464 | Training Loss: 0.130035 | Val. Loss: 0.531728 | Val. Kappa Score: 0.8211 | LR: 0.000154 | Estimated time: 64.75
Train loss on 50 batch: 0.121905
Train loss on 100 batch: 0.112089
Train loss on 150 batch: 0.144518
Train loss on 200 batch: 0.111984
Train loss on 250 batch: 0.139113
: Epoch: 465 | Training Loss: 0.128589 | Val. Loss: 0.531419 | Val. Kappa Score: 0.8211 | LR: 0.000188 | Estimated time: 64.59
Train loss on 50 batch: 0.143336
Train loss on 100 batch: 0.132544
Train loss on 150 batch: 0.129410
Train loss on 200 batch: 0.132459
Train loss on 250 batch: 0.133480
: Epoch: 466 | Training Loss: 0.135635 | Val. Loss: 0.489542 | Val. Kappa Score: 0.8212 | LR: 0.000225 | Estimated time: 64.71
Train loss on 50 batch: 0.161122
Train loss on 100 batch: 0.161253
Train loss on 150 batch: 0.121866
Train loss on 200 batch: 0.150853
Train loss on 250 batch: 0.123085
: Epoch: 467 | Training Loss: 0.180143 | Val. Loss: 0.486004 | Val. Kappa Score: 0.8212 | LR: 0.000263 | Estimated time: 64.87
Train loss on 50 batch: 0.169490
Train loss on 100 batch: 0.138089
Train loss on 150 batch: 0.159970
Train loss on 200 batch: 0.147735
Train loss on 250 batch: 0.136641
: Epoch: 468 | Training Loss: 0.148758 | Val. Loss: 0.517500 | Val. Kappa Score: 0.8212 | LR: 0.000303 | Estimated time: 64.96
Train loss on 50 batch: 0.144818
Train loss on 100 batch: 0.125539
Train loss on 150 batch: 0.127984
Train loss on 200 batch: 0.146475
Train loss on 250 batch: 0.132053
: Epoch: 469 | Training Loss: 0.142421 | Val. Loss: 0.542510 | Val. Kappa Score: 0.8212 | LR: 0.000345 | Estimated time: 64.78
Train loss on 50 batch: 0.158892
Train loss on 100 batch: 0.176104
Train loss on 150 batch: 0.143794
Train loss on 200 batch: 0.149179
Train loss on 250 batch: 0.143054
: Epoch: 470 | Training Loss: 0.154072 | Val. Loss: 0.488033 | Val. Kappa Score: 0.8213 | LR: 0.000389 | Estimated time: 64.77
Train loss on 50 batch: 0.124824
Train loss on 100 batch: 0.140684
Train loss on 150 batch: 0.135541
Train loss on 200 batch: 0.157985
Train loss on 250 batch: 0.127005
: Epoch: 471 | Training Loss: 0.147571 | Val. Loss: 0.578439 | Val. Kappa Score: 0.8213 | LR: 0.000433 | Estimated time: 64.84
Train loss on 50 batch: 0.161301
Train loss on 100 batch: 0.148495
Train loss on 150 batch: 0.147885
Train loss on 200 batch: 0.157642
Train loss on 250 batch: 0.169151
: Epoch: 472 | Training Loss: 0.158874 | Val. Loss: 0.586418 | Val. Kappa Score: 0.8213 | LR: 0.000478 | Estimated time: 64.64
Train loss on 50 batch: 0.173939
Train loss on 100 batch: 0.141921
Train loss on 150 batch: 0.161144
Train loss on 200 batch: 0.148467
Train loss on 250 batch: 0.165850
: Epoch: 473 | Training Loss: 0.165867 | Val. Loss: 0.549680 | Val. Kappa Score: 0.8212 | LR: 0.000522 | Estimated time: 64.79
Train loss on 50 batch: 0.179743
Train loss on 100 batch: 0.199642
Train loss on 150 batch: 0.166784
Train loss on 200 batch: 0.162643
Train loss on 250 batch: 0.155385
: Epoch: 474 | Training Loss: 0.177438 | Val. Loss: 0.538709 | Val. Kappa Score: 0.8213 | LR: 0.000567 | Estimated time: 64.79
Train loss on 50 batch: 0.254644
Train loss on 100 batch: 0.217515
Train loss on 150 batch: 0.228151
Train loss on 200 batch: 0.162238
Train loss on 250 batch: 0.166829
: Epoch: 475 | Training Loss: 0.221662 | Val. Loss: 0.515838 | Val. Kappa Score: 0.8213 | LR: 0.000611 | Estimated time: 64.95
Train loss on 50 batch: 0.279374
Train loss on 100 batch: 0.225579
Train loss on 150 batch: 0.185964
Train loss on 200 batch: 0.182305
Train loss on 250 batch: 0.202439
: Epoch: 476 | Training Loss: 0.216035 | Val. Loss: 0.512578 | Val. Kappa Score: 0.8213 | LR: 0.000655 | Estimated time: 64.89
Train loss on 50 batch: 0.210359
Train loss on 100 batch: 0.177248
Train loss on 150 batch: 0.174724
Train loss on 200 batch: 0.195147
Train loss on 250 batch: 0.179607
: Epoch: 477 | Training Loss: 0.198206 | Val. Loss: 0.522296 | Val. Kappa Score: 0.8213 | LR: 0.000697 | Estimated time: 64.93
Train loss on 50 batch: 0.216673
Train loss on 100 batch: 0.229015
Train loss on 150 batch: 0.186461
Train loss on 200 batch: 0.196938
Train loss on 250 batch: 0.181065
: Epoch: 478 | Training Loss: 0.205323 | Val. Loss: 0.489087 | Val. Kappa Score: 0.8214 | LR: 0.000737 | Estimated time: 64.84
Train loss on 50 batch: 0.205186
Train loss on 100 batch: 0.206080
Train loss on 150 batch: 0.262119
Train loss on 200 batch: 0.213888
Train loss on 250 batch: 0.233435
: Epoch: 479 | Training Loss: 0.220838 | Val. Loss: 0.491928 | Val. Kappa Score: 0.8214 | LR: 0.000775 | Estimated time: 64.78
Train loss on 50 batch: 0.178688
Train loss on 100 batch: 0.198959
Train loss on 150 batch: 0.196620
Train loss on 200 batch: 0.220324
Train loss on 250 batch: 0.250949
: Epoch: 480 | Training Loss: 0.216849 | Val. Loss: 0.485818 | Val. Kappa Score: 0.8214 | LR: 0.000812 | Estimated time: 64.77
Train loss on 50 batch: 0.255898
Train loss on 100 batch: 0.212162
Train loss on 150 batch: 0.221879
Train loss on 200 batch: 0.190659
Train loss on 250 batch: 0.179033
: Epoch: 481 | Training Loss: 0.213376 | Val. Loss: 0.535293 | Val. Kappa Score: 0.8214 | LR: 0.000846 | Estimated time: 64.86
Train loss on 50 batch: 0.176501
Train loss on 100 batch: 0.201534
Train loss on 150 batch: 0.215202
Train loss on 200 batch: 0.205727
Train loss on 250 batch: 0.182101
: Epoch: 482 | Training Loss: 0.201095 | Val. Loss: 0.560967 | Val. Kappa Score: 0.8214 | LR: 0.000877 | Estimated time: 64.73
Train loss on 50 batch: 0.325778
Train loss on 100 batch: 0.318264
Train loss on 150 batch: 0.253227
Train loss on 200 batch: 0.261513
Train loss on 250 batch: 0.199645
: Epoch: 483 | Training Loss: 0.270405 | Val. Loss: 0.528963 | Val. Kappa Score: 0.8215 | LR: 0.000905 | Estimated time: 64.98
Train loss on 50 batch: 0.312479
Train loss on 100 batch: 0.225493
Train loss on 150 batch: 0.224749
Train loss on 200 batch: 0.219009
Train loss on 250 batch: 0.236185
: Epoch: 484 | Training Loss: 0.244517 | Val. Loss: 0.618788 | Val. Kappa Score: 0.8214 | LR: 0.000929 | Estimated time: 64.74
Train loss on 50 batch: 0.346833
Train loss on 100 batch: 0.320542
Train loss on 150 batch: 0.281172
Train loss on 200 batch: 0.254310
Train loss on 250 batch: 0.254279
: Epoch: 485 | Training Loss: 0.292615 | Val. Loss: 0.547344 | Val. Kappa Score: 0.8214 | LR: 0.000950 | Estimated time: 64.70
Train loss on 50 batch: 0.207060
Train loss on 100 batch: 0.229094
Train loss on 150 batch: 0.234357
Train loss on 200 batch: 0.208620
Train loss on 250 batch: 0.203256
: Epoch: 486 | Training Loss: 0.223666 | Val. Loss: 0.943945 | Val. Kappa Score: 0.8213 | LR: 0.000968 | Estimated time: 64.87
Train loss on 50 batch: 0.329537
Train loss on 100 batch: 0.251975
Train loss on 150 batch: 0.228280
Train loss on 200 batch: 0.233921
Train loss on 250 batch: 0.221303
: Epoch: 487 | Training Loss: 0.256025 | Val. Loss: 0.596937 | Val. Kappa Score: 0.8213 | LR: 0.000982 | Estimated time: 64.67
Train loss on 50 batch: 0.238419
Train loss on 100 batch: 0.235470
Train loss on 150 batch: 0.226880
Train loss on 200 batch: 0.263795
Train loss on 250 batch: 0.258901
: Epoch: 488 | Training Loss: 0.248561 | Val. Loss: 0.478243 | Val. Kappa Score: 0.8213 | LR: 0.000992 | Estimated time: 64.84
Train loss on 50 batch: 0.266647
Train loss on 100 batch: 0.188697
Train loss on 150 batch: 0.244728
Train loss on 200 batch: 0.272515
Train loss on 250 batch: 0.234518
: Epoch: 489 | Training Loss: 0.250222 | Val. Loss: 0.510063 | Val. Kappa Score: 0.8213 | LR: 0.000998 | Estimated time: 64.72
Train loss on 50 batch: 0.233030
Train loss on 100 batch: 0.203347
Train loss on 150 batch: 0.192640
Train loss on 200 batch: 0.256482
Train loss on 250 batch: 0.225036
: Epoch: 490 | Training Loss: 0.212429 | Val. Loss: 0.495604 | Val. Kappa Score: 0.8214 | LR: 0.001000 | Estimated time: 64.90
Train loss on 50 batch: 0.177689
Train loss on 100 batch: 0.208181
Train loss on 150 batch: 0.217207
Train loss on 200 batch: 0.220315
Train loss on 250 batch: 0.228738
: Epoch: 491 | Training Loss: 0.216727 | Val. Loss: 0.597132 | Val. Kappa Score: 0.8213 | LR: 0.000998 | Estimated time: 64.88
Train loss on 50 batch: 0.363978
Train loss on 100 batch: 0.247606
Train loss on 150 batch: 0.207334
Train loss on 200 batch: 0.217729
Train loss on 250 batch: 0.220557
: Epoch: 492 | Training Loss: 0.243615 | Val. Loss: 0.505756 | Val. Kappa Score: 0.8214 | LR: 0.000992 | Estimated time: 64.70
Train loss on 50 batch: 0.229133
Train loss on 100 batch: 0.269237
Train loss on 150 batch: 0.233225
Train loss on 200 batch: 0.210819
Train loss on 250 batch: 0.220483
: Epoch: 493 | Training Loss: 0.241764 | Val. Loss: 0.595150 | Val. Kappa Score: 0.8213 | LR: 0.000982 | Estimated time: 64.82
Train loss on 50 batch: 0.280737
Train loss on 100 batch: 0.233646
Train loss on 150 batch: 0.213337
Train loss on 200 batch: 0.195604
Train loss on 250 batch: 0.236048
: Epoch: 494 | Training Loss: 0.233588 | Val. Loss: 0.475448 | Val. Kappa Score: 0.8213 | LR: 0.000968 | Estimated time: 64.74
Train loss on 50 batch: 0.222737
Train loss on 100 batch: 0.234924
Train loss on 150 batch: 0.258292
Train loss on 200 batch: 0.229879
Train loss on 250 batch: 0.198845
: Epoch: 495 | Training Loss: 0.240492 | Val. Loss: 0.598677 | Val. Kappa Score: 0.8213 | LR: 0.000950 | Estimated time: 64.89
Train loss on 50 batch: 0.336220
Train loss on 100 batch: 0.237534
Train loss on 150 batch: 0.224392
Train loss on 200 batch: 0.246800
Train loss on 250 batch: 0.236356
: Epoch: 496 | Training Loss: 0.261326 | Val. Loss: 0.477644 | Val. Kappa Score: 0.8213 | LR: 0.000929 | Estimated time: 64.68
Train loss on 50 batch: 0.218635
Train loss on 100 batch: 0.231894
Train loss on 150 batch: 0.237761
Train loss on 200 batch: 0.218583
Train loss on 250 batch: 0.225608
: Epoch: 497 | Training Loss: 0.225791 | Val. Loss: 0.524882 | Val. Kappa Score: 0.8213 | LR: 0.000905 | Estimated time: 64.82
Train loss on 50 batch: 0.177947
Train loss on 100 batch: 0.202101
Train loss on 150 batch: 0.222241
Train loss on 200 batch: 0.214426
Train loss on 250 batch: 0.224763
: Epoch: 498 | Training Loss: 0.217738 | Val. Loss: 0.502387 | Val. Kappa Score: 0.8213 | LR: 0.000877 | Estimated time: 64.78
Train loss on 50 batch: 0.254423
Train loss on 100 batch: 0.210839
Train loss on 150 batch: 0.212257
Train loss on 200 batch: 0.200548
Train loss on 250 batch: 0.208466
: Epoch: 499 | Training Loss: 0.221282 | Val. Loss: 0.552102 | Val. Kappa Score: 0.8213 | LR: 0.000846 | Estimated time: 64.83
Train loss on 50 batch: 0.225408
Train loss on 100 batch: 0.214215
Train loss on 150 batch: 0.217807
Train loss on 200 batch: 0.175825
Train loss on 250 batch: 0.249155
: Epoch: 500 | Training Loss: 0.215315 | Val. Loss: 0.526028 | Val. Kappa Score: 0.8213 | LR: 0.000812 | Estimated time: 64.81
Train loss on 50 batch: 0.194598
Train loss on 100 batch: 0.194300
Train loss on 150 batch: 0.231775
Train loss on 200 batch: 0.199264
Train loss on 250 batch: 0.182440
: Epoch: 501 | Training Loss: 0.200249 | Val. Loss: 0.542876 | Val. Kappa Score: 0.8213 | LR: 0.000775 | Estimated time: 64.75
Train loss on 50 batch: 0.190055
Train loss on 100 batch: 0.235274
Train loss on 150 batch: 0.198046
Train loss on 200 batch: 0.180659
Train loss on 250 batch: 0.187003
: Epoch: 502 | Training Loss: 0.197380 | Val. Loss: 0.587141 | Val. Kappa Score: 0.8213 | LR: 0.000737 | Estimated time: 64.90
Train loss on 50 batch: 0.182471
Train loss on 100 batch: 0.182902
Train loss on 150 batch: 0.200810
Train loss on 200 batch: 0.173958
Train loss on 250 batch: 0.186597
: Epoch: 503 | Training Loss: 0.184966 | Val. Loss: 0.550556 | Val. Kappa Score: 0.8213 | LR: 0.000697 | Estimated time: 64.64
Train loss on 50 batch: 0.179849
Train loss on 100 batch: 0.232270
Train loss on 150 batch: 0.167862
Train loss on 200 batch: 0.179070
Train loss on 250 batch: 0.166064
: Epoch: 504 | Training Loss: 0.201091 | Val. Loss: 0.551303 | Val. Kappa Score: 0.8213 | LR: 0.000655 | Estimated time: 64.75
Train loss on 50 batch: 0.444269
Train loss on 100 batch: 0.374733
Train loss on 150 batch: 0.302774
Train loss on 200 batch: 0.269900
Train loss on 250 batch: 0.322248
: Epoch: 505 | Training Loss: 0.337496 | Val. Loss: 0.465618 | Val. Kappa Score: 0.8213 | LR: 0.000611 | Estimated time: 64.82
Train loss on 50 batch: 0.249378
Train loss on 100 batch: 0.211303
Train loss on 150 batch: 0.206051
Train loss on 200 batch: 0.224330
Train loss on 250 batch: 0.214611
: Epoch: 506 | Training Loss: 0.213830 | Val. Loss: 0.464183 | Val. Kappa Score: 0.8214 | LR: 0.000567 | Estimated time: 64.76
Train loss on 50 batch: 0.190230
Train loss on 100 batch: 0.219954
Train loss on 150 batch: 0.198304
Train loss on 200 batch: 0.163746
Train loss on 250 batch: 0.190181
: Epoch: 507 | Training Loss: 0.196674 | Val. Loss: 0.490916 | Val. Kappa Score: 0.8214 | LR: 0.000522 | Estimated time: 64.71
Train loss on 50 batch: 0.197739
Train loss on 100 batch: 0.184597
Train loss on 150 batch: 0.168761
Train loss on 200 batch: 0.157963
Train loss on 250 batch: 0.194531
: Epoch: 508 | Training Loss: 0.173920 | Val. Loss: 0.493183 | Val. Kappa Score: 0.8215 | LR: 0.000478 | Estimated time: 64.61
Train loss on 50 batch: 0.163445
Train loss on 100 batch: 0.151080
Train loss on 150 batch: 0.163564
Train loss on 200 batch: 0.153455
Train loss on 250 batch: 0.187479
: Epoch: 509 | Training Loss: 0.167796 | Val. Loss: 0.468887 | Val. Kappa Score: 0.8215 | LR: 0.000433 | Estimated time: 64.69
Train loss on 50 batch: 0.159795
Train loss on 100 batch: 0.201257
Train loss on 150 batch: 0.145703
Train loss on 200 batch: 0.181525
Train loss on 250 batch: 0.150974
: Epoch: 510 | Training Loss: 0.167505 | Val. Loss: 0.464030 | Val. Kappa Score: 0.8215 | LR: 0.000389 | Estimated time: 64.73
Train loss on 50 batch: 0.152344
Train loss on 100 batch: 0.150447
Train loss on 150 batch: 0.156961
Train loss on 200 batch: 0.147812
Train loss on 250 batch: 0.140857
: Epoch: 511 | Training Loss: 0.157197 | Val. Loss: 0.505832 | Val. Kappa Score: 0.8216 | LR: 0.000345 | Estimated time: 64.81
Train loss on 50 batch: 0.141347
Train loss on 100 batch: 0.149868
Train loss on 150 batch: 0.156639
Train loss on 200 batch: 0.153568
Train loss on 250 batch: 0.160379
: Epoch: 512 | Training Loss: 0.153097 | Val. Loss: 0.479091 | Val. Kappa Score: 0.8216 | LR: 0.000303 | Estimated time: 64.73
Train loss on 50 batch: 0.135096
Train loss on 100 batch: 0.136102
Train loss on 150 batch: 0.162490
Train loss on 200 batch: 0.174187
Train loss on 250 batch: 0.161663
: Epoch: 513 | Training Loss: 0.150850 | Val. Loss: 0.510074 | Val. Kappa Score: 0.8217 | LR: 0.000263 | Estimated time: 64.62
Train loss on 50 batch: 0.127545
Train loss on 100 batch: 0.131824
Train loss on 150 batch: 0.145890
Train loss on 200 batch: 0.135729
Train loss on 250 batch: 0.142137
: Epoch: 514 | Training Loss: 0.159269 | Val. Loss: 0.473482 | Val. Kappa Score: 0.8217 | LR: 0.000225 | Estimated time: 64.74
Train loss on 50 batch: 0.186929
Train loss on 100 batch: 0.136226
Train loss on 150 batch: 0.146556
Train loss on 200 batch: 0.154517
Train loss on 250 batch: 0.142134
: Epoch: 515 | Training Loss: 0.151138 | Val. Loss: 0.501627 | Val. Kappa Score: 0.8218 | LR: 0.000188 | Estimated time: 64.76
Train loss on 50 batch: 0.138140
Train loss on 100 batch: 0.130341
Train loss on 150 batch: 0.146797
Train loss on 200 batch: 0.169169
Train loss on 250 batch: 0.140459
: Epoch: 516 | Training Loss: 0.142402 | Val. Loss: 0.496138 | Val. Kappa Score: 0.8218 | LR: 0.000154 | Estimated time: 64.69
Train loss on 50 batch: 0.120646
Train loss on 100 batch: 0.121956
Train loss on 150 batch: 0.123024
Train loss on 200 batch: 0.130667
Train loss on 250 batch: 0.133645
: Epoch: 517 | Training Loss: 0.123910 | Val. Loss: 0.475629 | Val. Kappa Score: 0.8219 | LR: 0.000123 | Estimated time: 65.05
Train loss on 50 batch: 0.133280
Train loss on 100 batch: 0.138679
Train loss on 150 batch: 0.126880
Train loss on 200 batch: 0.127956
Train loss on 250 batch: 0.125445
: Epoch: 518 | Training Loss: 0.129437 | Val. Loss: 0.463462 | Val. Kappa Score: 0.8219 | LR: 0.000095 | Estimated time: 65.02
Train loss on 50 batch: 0.131668
Train loss on 100 batch: 0.123340
Train loss on 150 batch: 0.117742
Train loss on 200 batch: 0.126665
Train loss on 250 batch: 0.120941
: Epoch: 519 | Training Loss: 0.123725 | Val. Loss: 0.473011 | Val. Kappa Score: 0.8219 | LR: 0.000071 | Estimated time: 64.55
Train loss on 50 batch: 0.119448
Train loss on 100 batch: 0.113031
Train loss on 150 batch: 0.128073
Train loss on 200 batch: 0.115440
Train loss on 250 batch: 0.115066
: Epoch: 520 | Training Loss: 0.121577 | Val. Loss: 0.466759 | Val. Kappa Score: 0.8220 | LR: 0.000050 | Estimated time: 64.62
Train loss on 50 batch: 0.133075
Train loss on 100 batch: 0.108809
Train loss on 150 batch: 0.111615
Train loss on 200 batch: 0.120171
Train loss on 250 batch: 0.118009
: Epoch: 521 | Training Loss: 0.116728 | Val. Loss: 0.462095 | Val. Kappa Score: 0.8221 | LR: 0.000032 | Estimated time: 64.72
Train loss on 50 batch: 0.129144
Train loss on 100 batch: 0.129837
Train loss on 150 batch: 0.121643
Train loss on 200 batch: 0.110103
Train loss on 250 batch: 0.123685
: Epoch: 522 | Training Loss: 0.126912 | Val. Loss: 0.480373 | Val. Kappa Score: 0.8221 | LR: 0.000018 | Estimated time: 64.69
Train loss on 50 batch: 0.133865
Train loss on 100 batch: 0.128839
Train loss on 150 batch: 0.117892
Train loss on 200 batch: 0.108108
Train loss on 250 batch: 0.110911
: Epoch: 523 | Training Loss: 0.132716 | Val. Loss: 0.485199 | Val. Kappa Score: 0.8221 | LR: 0.000008 | Estimated time: 64.61
Train loss on 50 batch: 0.139571
Train loss on 100 batch: 0.118172
Train loss on 150 batch: 0.116650
Train loss on 200 batch: 0.128772
Train loss on 250 batch: 0.120944
: Epoch: 524 | Training Loss: 0.141941 | Val. Loss: 0.460072 | Val. Kappa Score: 0.8222 | LR: 0.000002 | Estimated time: 64.58
Train loss on 50 batch: 0.118796
Train loss on 100 batch: 0.123401
Train loss on 150 batch: 0.107533
Train loss on 200 batch: 0.118699
Train loss on 250 batch: 0.120580
: Epoch: 525 | Training Loss: 0.142917 | Val. Loss: 0.467987 | Val. Kappa Score: 0.8222 | LR: 0.000000 | Estimated time: 64.49
Train loss on 50 batch: 0.113177
Train loss on 100 batch: 0.126839
Train loss on 150 batch: 0.123501
Train loss on 200 batch: 0.111550
Train loss on 250 batch: 0.124603
: Epoch: 526 | Training Loss: 0.120321 | Val. Loss: 0.477307 | Val. Kappa Score: 0.8223 | LR: 0.000002 | Estimated time: 64.60
Train loss on 50 batch: 0.110366
Train loss on 100 batch: 0.122787
Train loss on 150 batch: 0.115463
Train loss on 200 batch: 0.108488
Train loss on 250 batch: 0.134387
: Epoch: 527 | Training Loss: 0.129902 | Val. Loss: 0.471150 | Val. Kappa Score: 0.8223 | LR: 0.000008 | Estimated time: 64.50
Train loss on 50 batch: 0.114455
Train loss on 100 batch: 0.105667
Train loss on 150 batch: 0.110310
Train loss on 200 batch: 0.115019
Train loss on 250 batch: 0.113368
: Epoch: 528 | Training Loss: 0.128317 | Val. Loss: 0.478308 | Val. Kappa Score: 0.8223 | LR: 0.000018 | Estimated time: 64.58
Train loss on 50 batch: 0.129038
Train loss on 100 batch: 0.133145
Train loss on 150 batch: 0.117463
Train loss on 200 batch: 0.115445
Train loss on 250 batch: 0.127966
: Epoch: 529 | Training Loss: 0.130132 | Val. Loss: 0.486271 | Val. Kappa Score: 0.8223 | LR: 0.000032 | Estimated time: 64.63
Train loss on 50 batch: 0.125632
Train loss on 100 batch: 0.112362
Train loss on 150 batch: 0.115974
Train loss on 200 batch: 0.118169
Train loss on 250 batch: 0.116692
: Epoch: 530 | Training Loss: 0.128752 | Val. Loss: 0.476854 | Val. Kappa Score: 0.8224 | LR: 0.000050 | Estimated time: 64.46
Train loss on 50 batch: 0.126468
Train loss on 100 batch: 0.118380
Train loss on 150 batch: 0.118466
Train loss on 200 batch: 0.105458
Train loss on 250 batch: 0.121963
: Epoch: 531 | Training Loss: 0.119203 | Val. Loss: 0.465792 | Val. Kappa Score: 0.8224 | LR: 0.000071 | Estimated time: 64.53
Train loss on 50 batch: 0.121042
Train loss on 100 batch: 0.118668
Train loss on 150 batch: 0.128538
Train loss on 200 batch: 0.131108
Train loss on 250 batch: 0.131449
: Epoch: 532 | Training Loss: 0.125265 | Val. Loss: 0.456090 | Val. Kappa Score: 0.8224 | LR: 0.000095 | Estimated time: 64.60
Train loss on 50 batch: 0.127485
Train loss on 100 batch: 0.118876
Train loss on 150 batch: 0.125045
Train loss on 200 batch: 0.137341
Train loss on 250 batch: 0.128963
: Epoch: 533 | Training Loss: 0.127611 | Val. Loss: 0.490989 | Val. Kappa Score: 0.8225 | LR: 0.000123 | Estimated time: 64.73
Train loss on 50 batch: 0.118186
Train loss on 100 batch: 0.117088
Train loss on 150 batch: 0.109286
Train loss on 200 batch: 0.126287
Train loss on 250 batch: 0.126567
: Epoch: 534 | Training Loss: 0.119431 | Val. Loss: 0.460302 | Val. Kappa Score: 0.8225 | LR: 0.000154 | Estimated time: 64.66
Train loss on 50 batch: 0.115397
Train loss on 100 batch: 0.117324
Train loss on 150 batch: 0.117691
Train loss on 200 batch: 0.119736
Train loss on 250 batch: 0.122363
: Epoch: 535 | Training Loss: 0.125194 | Val. Loss: 0.512450 | Val. Kappa Score: 0.8225 | LR: 0.000188 | Estimated time: 64.78
Train loss on 50 batch: 0.129454
Train loss on 100 batch: 0.126589
Train loss on 150 batch: 0.128263
Train loss on 200 batch: 0.128956
Train loss on 250 batch: 0.120546
: Epoch: 536 | Training Loss: 0.126827 | Val. Loss: 0.498271 | Val. Kappa Score: 0.8226 | LR: 0.000225 | Estimated time: 64.58
time_estimated: 34809.29
n-epochs: 536
time_estimated: 34809.31
----------------------------------------

Experiment N: 102: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.16 08:20:18
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb9d102780>
early-stopping-patience: 250
parameters-amount: 28342833
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030221
Train loss on 100 batch: 0.576435
Train loss on 150 batch: 0.583337
Train loss on 200 batch: 0.462122
best-train-loss: 0.655892
best-valid-loss: 0.585073
best-kappa: 0.8289
: Epoch: 1 | Training Loss: 0.655892 | Val. Loss: 0.585073 | Val. Kappa Score: 0.8289 | LR: 0.000998 | Estimated time: 54.21
Train loss on 50 batch: 0.460425
Train loss on 100 batch: 0.415598
Train loss on 150 batch: 0.469717
Train loss on 200 batch: 0.400920
best-train-loss: 0.406758
best-valid-loss: 0.424488
best-kappa: 0.8256
: Epoch: 2 | Training Loss: 0.406758 | Val. Loss: 0.424488 | Val. Kappa Score: 0.8256 | LR: 0.000992 | Estimated time: 53.63
Train loss on 50 batch: 0.422507
Train loss on 100 batch: 0.415976
Train loss on 150 batch: 0.334755
Train loss on 200 batch: 0.417126
best-train-loss: 0.392417
best-valid-loss: 0.329129
best-kappa: 0.8421
: Epoch: 3 | Training Loss: 0.392417 | Val. Loss: 0.329129 | Val. Kappa Score: 0.8421 | LR: 0.000982 | Estimated time: 53.69
Train loss on 50 batch: 0.351767
Train loss on 100 batch: 0.465731
Train loss on 150 batch: 0.454900
Train loss on 200 batch: 0.371260
: Epoch: 4 | Training Loss: 0.421645 | Val. Loss: 0.344479 | Val. Kappa Score: 0.8474 | LR: 0.000968 | Estimated time: 53.54
Train loss on 50 batch: 0.296274
Train loss on 100 batch: 0.344960
Train loss on 150 batch: 0.374427
Train loss on 200 batch: 0.437583
best-train-loss: 0.363405
best-valid-loss: 0.286881
best-kappa: 0.8546
: Epoch: 5 | Training Loss: 0.363405 | Val. Loss: 0.286881 | Val. Kappa Score: 0.8546 | LR: 0.000950 | Estimated time: 53.64
Train loss on 50 batch: 0.323723
Train loss on 100 batch: 0.283756
Train loss on 150 batch: 0.352964
Train loss on 200 batch: 0.312239
: Epoch: 6 | Training Loss: 0.344359 | Val. Loss: 0.342521 | Val. Kappa Score: 0.8555 | LR: 0.000929 | Estimated time: 53.55
Train loss on 50 batch: 0.291516
Train loss on 100 batch: 0.308040
Train loss on 150 batch: 0.275937
Train loss on 200 batch: 0.307936
: Epoch: 7 | Training Loss: 0.294477 | Val. Loss: 0.304837 | Val. Kappa Score: 0.8608 | LR: 0.000905 | Estimated time: 53.54
Train loss on 50 batch: 0.288408
Train loss on 100 batch: 0.303750
Train loss on 150 batch: 0.298515
Train loss on 200 batch: 0.302535
best-train-loss: 0.296205
best-valid-loss: 0.274129
best-kappa: 0.8645
: Epoch: 8 | Training Loss: 0.296205 | Val. Loss: 0.274129 | Val. Kappa Score: 0.8645 | LR: 0.000877 | Estimated time: 53.74
Train loss on 50 batch: 0.257881
Train loss on 100 batch: 0.297077
Train loss on 150 batch: 0.312285
Train loss on 200 batch: 0.309963
: Epoch: 9 | Training Loss: 0.318414 | Val. Loss: 0.441960 | Val. Kappa Score: 0.8632 | LR: 0.000846 | Estimated time: 53.49
Train loss on 50 batch: 0.242211
Train loss on 100 batch: 0.290593
Train loss on 150 batch: 0.264063
Train loss on 200 batch: 0.311021
: Epoch: 10 | Training Loss: 0.270732 | Val. Loss: 0.281184 | Val. Kappa Score: 0.8645 | LR: 0.000812 | Estimated time: 53.61
Train loss on 50 batch: 0.328236
Train loss on 100 batch: 0.303606
Train loss on 150 batch: 0.221420
Train loss on 200 batch: 0.252709
: Epoch: 11 | Training Loss: 0.295364 | Val. Loss: 0.289357 | Val. Kappa Score: 0.8646 | LR: 0.000775 | Estimated time: 53.54
Train loss on 50 batch: 0.287052
Train loss on 100 batch: 0.264722
Train loss on 150 batch: 0.254805
Train loss on 200 batch: 0.228617
best-train-loss: 0.251748
best-valid-loss: 0.245011
best-kappa: 0.8677
: Epoch: 12 | Training Loss: 0.251748 | Val. Loss: 0.245011 | Val. Kappa Score: 0.8677 | LR: 0.000737 | Estimated time: 53.47
Train loss on 50 batch: 0.218768
Train loss on 100 batch: 0.232142
Train loss on 150 batch: 0.244051
Train loss on 200 batch: 0.229434
best-train-loss: 0.231232
best-valid-loss: 0.232160
best-kappa: 0.8707
: Epoch: 13 | Training Loss: 0.231232 | Val. Loss: 0.232160 | Val. Kappa Score: 0.8707 | LR: 0.000697 | Estimated time: 53.54
Train loss on 50 batch: 0.230214
Train loss on 100 batch: 0.232918
Train loss on 150 batch: 0.255151
Train loss on 200 batch: 0.272993
best-train-loss: 0.236194
best-valid-loss: 0.223214
best-kappa: 0.8737
: Epoch: 14 | Training Loss: 0.236194 | Val. Loss: 0.223214 | Val. Kappa Score: 0.8737 | LR: 0.000655 | Estimated time: 53.48
Train loss on 50 batch: 0.269330
Train loss on 100 batch: 0.225586
Train loss on 150 batch: 0.207296
Train loss on 200 batch: 0.260735
: Epoch: 15 | Training Loss: 0.243703 | Val. Loss: 0.272664 | Val. Kappa Score: 0.8761 | LR: 0.000611 | Estimated time: 53.62
Train loss on 50 batch: 0.197370
Train loss on 100 batch: 0.216570
Train loss on 150 batch: 0.212128
Train loss on 200 batch: 0.218951
: Epoch: 16 | Training Loss: 0.215155 | Val. Loss: 0.256536 | Val. Kappa Score: 0.8776 | LR: 0.000567 | Estimated time: 53.47
Train loss on 50 batch: 0.173653
Train loss on 100 batch: 0.175235
Train loss on 150 batch: 0.208282
Train loss on 200 batch: 0.232564
: Epoch: 17 | Training Loss: 0.206928 | Val. Loss: 0.263481 | Val. Kappa Score: 0.8777 | LR: 0.000522 | Estimated time: 53.53
Train loss on 50 batch: 0.172601
Train loss on 100 batch: 0.232924
Train loss on 150 batch: 0.177382
Train loss on 200 batch: 0.171256
: Epoch: 18 | Training Loss: 0.186070 | Val. Loss: 0.232755 | Val. Kappa Score: 0.8800 | LR: 0.000478 | Estimated time: 53.42
Train loss on 50 batch: 0.180023
Train loss on 100 batch: 0.144706
Train loss on 150 batch: 0.234172
Train loss on 200 batch: 0.165930
: Epoch: 19 | Training Loss: 0.168767 | Val. Loss: 0.228677 | Val. Kappa Score: 0.8816 | LR: 0.000433 | Estimated time: 53.47
Train loss on 50 batch: 0.165656
Train loss on 100 batch: 0.175767
Train loss on 150 batch: 0.149925
Train loss on 200 batch: 0.157857
: Epoch: 20 | Training Loss: 0.163835 | Val. Loss: 0.224661 | Val. Kappa Score: 0.8827 | LR: 0.000389 | Estimated time: 53.56
Train loss on 50 batch: 0.138407
Train loss on 100 batch: 0.185204
Train loss on 150 batch: 0.142747
Train loss on 200 batch: 0.154867
: Epoch: 21 | Training Loss: 0.150136 | Val. Loss: 0.235667 | Val. Kappa Score: 0.8846 | LR: 0.000345 | Estimated time: 53.60
Train loss on 50 batch: 0.152968
Train loss on 100 batch: 0.152683
Train loss on 150 batch: 0.122928
Train loss on 200 batch: 0.118017
best-train-loss: 0.147794
best-valid-loss: 0.219083
best-kappa: 0.8859
: Epoch: 22 | Training Loss: 0.147794 | Val. Loss: 0.219083 | Val. Kappa Score: 0.8859 | LR: 0.000303 | Estimated time: 53.45
Train loss on 50 batch: 0.168507
Train loss on 100 batch: 0.145086
Train loss on 150 batch: 0.102351
Train loss on 200 batch: 0.110119
: Epoch: 23 | Training Loss: 0.124043 | Val. Loss: 0.278200 | Val. Kappa Score: 0.8864 | LR: 0.000263 | Estimated time: 53.51
Train loss on 50 batch: 0.112461
Train loss on 100 batch: 0.121024
Train loss on 150 batch: 0.131612
Train loss on 200 batch: 0.125226
: Epoch: 24 | Training Loss: 0.124572 | Val. Loss: 0.232381 | Val. Kappa Score: 0.8875 | LR: 0.000225 | Estimated time: 53.52
Train loss on 50 batch: 0.103640
Train loss on 100 batch: 0.125796
Train loss on 150 batch: 0.111073
Train loss on 200 batch: 0.108050
: Epoch: 25 | Training Loss: 0.122247 | Val. Loss: 0.229393 | Val. Kappa Score: 0.8889 | LR: 0.000188 | Estimated time: 53.45
Train loss on 50 batch: 0.107444
Train loss on 100 batch: 0.083200
Train loss on 150 batch: 0.118861
Train loss on 200 batch: 0.089203
: Epoch: 26 | Training Loss: 0.101439 | Val. Loss: 0.235477 | Val. Kappa Score: 0.8896 | LR: 0.000154 | Estimated time: 53.46
Train loss on 50 batch: 0.089610
Train loss on 100 batch: 0.089246
Train loss on 150 batch: 0.109234
Train loss on 200 batch: 0.100305
: Epoch: 27 | Training Loss: 0.090959 | Val. Loss: 0.239481 | Val. Kappa Score: 0.8905 | LR: 0.000123 | Estimated time: 53.45
Train loss on 50 batch: 0.086936
Train loss on 100 batch: 0.084040
Train loss on 150 batch: 0.070171
Train loss on 200 batch: 0.091778
: Epoch: 28 | Training Loss: 0.091269 | Val. Loss: 0.233995 | Val. Kappa Score: 0.8913 | LR: 0.000095 | Estimated time: 53.47
Train loss on 50 batch: 0.082713
Train loss on 100 batch: 0.075768
Train loss on 150 batch: 0.080372
Train loss on 200 batch: 0.082042
: Epoch: 29 | Training Loss: 0.085629 | Val. Loss: 0.223122 | Val. Kappa Score: 0.8923 | LR: 0.000071 | Estimated time: 53.52
Train loss on 50 batch: 0.085954
Train loss on 100 batch: 0.082428
Train loss on 150 batch: 0.074121
Train loss on 200 batch: 0.066625
: Epoch: 30 | Training Loss: 0.075086 | Val. Loss: 0.220868 | Val. Kappa Score: 0.8930 | LR: 0.000050 | Estimated time: 53.50
Train loss on 50 batch: 0.064754
Train loss on 100 batch: 0.063754
Train loss on 150 batch: 0.073628
Train loss on 200 batch: 0.076652
: Epoch: 31 | Training Loss: 0.080159 | Val. Loss: 0.226614 | Val. Kappa Score: 0.8934 | LR: 0.000032 | Estimated time: 53.51
Train loss on 50 batch: 0.076361
Train loss on 100 batch: 0.066386
Train loss on 150 batch: 0.067138
Train loss on 200 batch: 0.061868
: Epoch: 32 | Training Loss: 0.064092 | Val. Loss: 0.225578 | Val. Kappa Score: 0.8940 | LR: 0.000018 | Estimated time: 53.48
Train loss on 50 batch: 0.065670
Train loss on 100 batch: 0.063610
Train loss on 150 batch: 0.082113
Train loss on 200 batch: 0.062561
: Epoch: 33 | Training Loss: 0.071815 | Val. Loss: 0.219498 | Val. Kappa Score: 0.8945 | LR: 0.000008 | Estimated time: 53.47
Train loss on 50 batch: 0.066604
Train loss on 100 batch: 0.056389
Train loss on 150 batch: 0.077842
Train loss on 200 batch: 0.062305
: Epoch: 34 | Training Loss: 0.065173 | Val. Loss: 0.219442 | Val. Kappa Score: 0.8951 | LR: 0.000002 | Estimated time: 53.52
Train loss on 50 batch: 0.063331
Train loss on 100 batch: 0.061690
Train loss on 150 batch: 0.053128
Train loss on 200 batch: 0.063820
: Epoch: 35 | Training Loss: 0.059305 | Val. Loss: 0.219326 | Val. Kappa Score: 0.8956 | LR: 0.000000 | Estimated time: 53.51
Train loss on 50 batch: 0.063535
Train loss on 100 batch: 0.064087
Train loss on 150 batch: 0.053440
Train loss on 200 batch: 0.072785
: Epoch: 36 | Training Loss: 0.064897 | Val. Loss: 0.219115 | Val. Kappa Score: 0.8958 | LR: 0.000002 | Estimated time: 53.43
Train loss on 50 batch: 0.059875
Train loss on 100 batch: 0.057521
Train loss on 150 batch: 0.059245
Train loss on 200 batch: 0.075250
: Epoch: 37 | Training Loss: 0.060805 | Val. Loss: 0.219352 | Val. Kappa Score: 0.8964 | LR: 0.000008 | Estimated time: 53.47
Train loss on 50 batch: 0.068297
Train loss on 100 batch: 0.064659
Train loss on 150 batch: 0.047624
Train loss on 200 batch: 0.069498
: Epoch: 38 | Training Loss: 0.058840 | Val. Loss: 0.219484 | Val. Kappa Score: 0.8972 | LR: 0.000018 | Estimated time: 53.42
Train loss on 50 batch: 0.056488
Train loss on 100 batch: 0.067424
Train loss on 150 batch: 0.056084
Train loss on 200 batch: 0.069751
: Epoch: 39 | Training Loss: 0.061066 | Val. Loss: 0.219332 | Val. Kappa Score: 0.8976 | LR: 0.000032 | Estimated time: 53.56
Train loss on 50 batch: 0.060225
Train loss on 100 batch: 0.050758
Train loss on 150 batch: 0.061708
Train loss on 200 batch: 0.070612
: Epoch: 40 | Training Loss: 0.061706 | Val. Loss: 0.219167 | Val. Kappa Score: 0.8977 | LR: 0.000050 | Estimated time: 53.56
Train loss on 50 batch: 0.056660
Train loss on 100 batch: 0.056751
Train loss on 150 batch: 0.066651
Train loss on 200 batch: 0.073227
: Epoch: 41 | Training Loss: 0.060935 | Val. Loss: 0.226208 | Val. Kappa Score: 0.8979 | LR: 0.000071 | Estimated time: 53.54
Train loss on 50 batch: 0.056321
Train loss on 100 batch: 0.055772
Train loss on 150 batch: 0.063069
Train loss on 200 batch: 0.072639
: Epoch: 42 | Training Loss: 0.059820 | Val. Loss: 0.221694 | Val. Kappa Score: 0.8981 | LR: 0.000095 | Estimated time: 53.46
Train loss on 50 batch: 0.067159
Train loss on 100 batch: 0.062247
Train loss on 150 batch: 0.075559
Train loss on 200 batch: 0.071221
: Epoch: 43 | Training Loss: 0.070802 | Val. Loss: 0.222277 | Val. Kappa Score: 0.8984 | LR: 0.000123 | Estimated time: 53.47
Train loss on 50 batch: 0.059241
Train loss on 100 batch: 0.077427
Train loss on 150 batch: 0.073164
Train loss on 200 batch: 0.069056
: Epoch: 44 | Training Loss: 0.068177 | Val. Loss: 0.225099 | Val. Kappa Score: 0.8985 | LR: 0.000154 | Estimated time: 53.50
Train loss on 50 batch: 0.055262
Train loss on 100 batch: 0.066418
Train loss on 150 batch: 0.073657
Train loss on 200 batch: 0.070174
: Epoch: 45 | Training Loss: 0.074751 | Val. Loss: 0.226085 | Val. Kappa Score: 0.8986 | LR: 0.000188 | Estimated time: 53.49
Train loss on 50 batch: 0.080000
Train loss on 100 batch: 0.064463
Train loss on 150 batch: 0.080215
Train loss on 200 batch: 0.078671
: Epoch: 46 | Training Loss: 0.069716 | Val. Loss: 0.255410 | Val. Kappa Score: 0.8986 | LR: 0.000225 | Estimated time: 53.55
Train loss on 50 batch: 0.059395
Train loss on 100 batch: 0.075510
Train loss on 150 batch: 0.091077
Train loss on 200 batch: 0.093183
: Epoch: 47 | Training Loss: 0.076620 | Val. Loss: 0.258380 | Val. Kappa Score: 0.8989 | LR: 0.000263 | Estimated time: 53.46
Train loss on 50 batch: 0.075776
Train loss on 100 batch: 0.081168
Train loss on 150 batch: 0.084170
Train loss on 200 batch: 0.112670
: Epoch: 48 | Training Loss: 0.078159 | Val. Loss: 0.262964 | Val. Kappa Score: 0.8991 | LR: 0.000303 | Estimated time: 53.62
Train loss on 50 batch: 0.127902
Train loss on 100 batch: 0.127678
Train loss on 150 batch: 0.106835
Train loss on 200 batch: 0.094567
: Epoch: 49 | Training Loss: 0.114140 | Val. Loss: 0.298563 | Val. Kappa Score: 0.8993 | LR: 0.000345 | Estimated time: 53.51
Train loss on 50 batch: 0.076204
Train loss on 100 batch: 0.104820
Train loss on 150 batch: 0.109663
Train loss on 200 batch: 0.099801
: Epoch: 50 | Training Loss: 0.101669 | Val. Loss: 0.260046 | Val. Kappa Score: 0.8996 | LR: 0.000389 | Estimated time: 53.49
Train loss on 50 batch: 0.085185
Train loss on 100 batch: 0.100063
Train loss on 150 batch: 0.110641
Train loss on 200 batch: 0.098729
: Epoch: 51 | Training Loss: 0.113119 | Val. Loss: 0.254727 | Val. Kappa Score: 0.8997 | LR: 0.000433 | Estimated time: 53.50
Train loss on 50 batch: 0.093463
Train loss on 100 batch: 0.102111
Train loss on 150 batch: 0.126488
Train loss on 200 batch: 0.104000
: Epoch: 52 | Training Loss: 0.113544 | Val. Loss: 0.228418 | Val. Kappa Score: 0.9001 | LR: 0.000478 | Estimated time: 53.55
Train loss on 50 batch: 0.073521
Train loss on 100 batch: 0.093961
Train loss on 150 batch: 0.151407
Train loss on 200 batch: 0.173746
: Epoch: 53 | Training Loss: 0.123643 | Val. Loss: 0.219372 | Val. Kappa Score: 0.9003 | LR: 0.000522 | Estimated time: 53.44
Train loss on 50 batch: 0.114995
Train loss on 100 batch: 0.120365
Train loss on 150 batch: 0.143483
Train loss on 200 batch: 0.153764
: Epoch: 54 | Training Loss: 0.150138 | Val. Loss: 0.268484 | Val. Kappa Score: 0.9004 | LR: 0.000567 | Estimated time: 53.54
Train loss on 50 batch: 0.108207
Train loss on 100 batch: 0.090617
Train loss on 150 batch: 0.139429
Train loss on 200 batch: 0.148227
: Epoch: 55 | Training Loss: 0.113344 | Val. Loss: 0.315104 | Val. Kappa Score: 0.9001 | LR: 0.000611 | Estimated time: 53.52
Train loss on 50 batch: 0.118422
Train loss on 100 batch: 0.103939
Train loss on 150 batch: 0.119121
Train loss on 200 batch: 0.166616
: Epoch: 56 | Training Loss: 0.132345 | Val. Loss: 0.341666 | Val. Kappa Score: 0.8997 | LR: 0.000655 | Estimated time: 53.50
Train loss on 50 batch: 0.152874
Train loss on 100 batch: 0.153179
Train loss on 150 batch: 0.132661
Train loss on 200 batch: 0.131169
: Epoch: 57 | Training Loss: 0.140663 | Val. Loss: 0.236991 | Val. Kappa Score: 0.9000 | LR: 0.000697 | Estimated time: 53.51
Train loss on 50 batch: 0.173938
Train loss on 100 batch: 0.191310
Train loss on 150 batch: 0.176128
Train loss on 200 batch: 0.166498
: Epoch: 58 | Training Loss: 0.170027 | Val. Loss: 0.295929 | Val. Kappa Score: 0.8999 | LR: 0.000737 | Estimated time: 53.56
Train loss on 50 batch: 0.196521
Train loss on 100 batch: 0.165836
Train loss on 150 batch: 0.165826
Train loss on 200 batch: 0.173783
: Epoch: 59 | Training Loss: 0.174607 | Val. Loss: 0.261014 | Val. Kappa Score: 0.9000 | LR: 0.000775 | Estimated time: 53.48
Train loss on 50 batch: 0.162462
Train loss on 100 batch: 0.175130
Train loss on 150 batch: 0.191147
Train loss on 200 batch: 0.172163
: Epoch: 60 | Training Loss: 0.166049 | Val. Loss: 0.305274 | Val. Kappa Score: 0.8999 | LR: 0.000812 | Estimated time: 53.54
Train loss on 50 batch: 0.161772
Train loss on 100 batch: 0.146338
Train loss on 150 batch: 0.126985
Train loss on 200 batch: 0.131173
: Epoch: 61 | Training Loss: 0.141614 | Val. Loss: 0.278903 | Val. Kappa Score: 0.8999 | LR: 0.000846 | Estimated time: 53.50
Train loss on 50 batch: 0.127744
Train loss on 100 batch: 0.131000
Train loss on 150 batch: 0.158047
Train loss on 200 batch: 0.179048
: Epoch: 62 | Training Loss: 0.177625 | Val. Loss: 0.314887 | Val. Kappa Score: 0.8998 | LR: 0.000877 | Estimated time: 53.49
Train loss on 50 batch: 0.186808
Train loss on 100 batch: 0.219527
Train loss on 150 batch: 0.237031
Train loss on 200 batch: 0.186943
: Epoch: 63 | Training Loss: 0.208753 | Val. Loss: 0.377849 | Val. Kappa Score: 0.8986 | LR: 0.000905 | Estimated time: 53.52
Train loss on 50 batch: 0.212578
Train loss on 100 batch: 0.207126
Train loss on 150 batch: 0.177315
Train loss on 200 batch: 0.155321
: Epoch: 64 | Training Loss: 0.186075 | Val. Loss: 0.327672 | Val. Kappa Score: 0.8983 | LR: 0.000929 | Estimated time: 53.48
Train loss on 50 batch: 0.177730
Train loss on 100 batch: 0.191584
Train loss on 150 batch: 0.163245
Train loss on 200 batch: 0.193424
: Epoch: 65 | Training Loss: 0.171053 | Val. Loss: 0.243999 | Val. Kappa Score: 0.8986 | LR: 0.000950 | Estimated time: 53.55
Train loss on 50 batch: 0.145598
Train loss on 100 batch: 0.148787
Train loss on 150 batch: 0.161393
Train loss on 200 batch: 0.204480
: Epoch: 66 | Training Loss: 0.169303 | Val. Loss: 0.315285 | Val. Kappa Score: 0.8984 | LR: 0.000968 | Estimated time: 53.45
Train loss on 50 batch: 0.155201
Train loss on 100 batch: 0.175721
Train loss on 150 batch: 0.182688
Train loss on 200 batch: 0.127317
: Epoch: 67 | Training Loss: 0.166572 | Val. Loss: 0.288645 | Val. Kappa Score: 0.8983 | LR: 0.000982 | Estimated time: 53.51
Train loss on 50 batch: 0.150908
Train loss on 100 batch: 0.122025
Train loss on 150 batch: 0.163613
Train loss on 200 batch: 0.183211
: Epoch: 68 | Training Loss: 0.167381 | Val. Loss: 0.279654 | Val. Kappa Score: 0.8983 | LR: 0.000992 | Estimated time: 53.51
Train loss on 50 batch: 0.256430
Train loss on 100 batch: 0.219735
Train loss on 150 batch: 0.159783
Train loss on 200 batch: 0.151733
: Epoch: 69 | Training Loss: 0.196479 | Val. Loss: 0.330003 | Val. Kappa Score: 0.8980 | LR: 0.000998 | Estimated time: 53.46
Train loss on 50 batch: 0.147960
Train loss on 100 batch: 0.150282
Train loss on 150 batch: 0.206754
Train loss on 200 batch: 0.237611
: Epoch: 70 | Training Loss: 0.223232 | Val. Loss: 0.306459 | Val. Kappa Score: 0.8978 | LR: 0.001000 | Estimated time: 53.52
Train loss on 50 batch: 0.222658
Train loss on 100 batch: 0.223467
Train loss on 150 batch: 0.176106
Train loss on 200 batch: 0.160485
: Epoch: 71 | Training Loss: 0.182745 | Val. Loss: 0.241496 | Val. Kappa Score: 0.8979 | LR: 0.000998 | Estimated time: 53.54
Train loss on 50 batch: 0.155198
Train loss on 100 batch: 0.134577
Train loss on 150 batch: 0.137510
Train loss on 200 batch: 0.136378
: Epoch: 72 | Training Loss: 0.151873 | Val. Loss: 0.247099 | Val. Kappa Score: 0.8980 | LR: 0.000992 | Estimated time: 53.55
Train loss on 50 batch: 0.139191
Train loss on 100 batch: 0.138653
Train loss on 150 batch: 0.133973
Train loss on 200 batch: 0.162773
: Epoch: 73 | Training Loss: 0.142003 | Val. Loss: 0.273543 | Val. Kappa Score: 0.8979 | LR: 0.000982 | Estimated time: 53.51
Train loss on 50 batch: 0.172876
Train loss on 100 batch: 0.144667
Train loss on 150 batch: 0.188306
Train loss on 200 batch: 0.151139
: Epoch: 74 | Training Loss: 0.161251 | Val. Loss: 0.313541 | Val. Kappa Score: 0.8976 | LR: 0.000968 | Estimated time: 53.51
Train loss on 50 batch: 0.138248
Train loss on 100 batch: 0.169395
Train loss on 150 batch: 0.149762
Train loss on 200 batch: 0.147453
: Epoch: 75 | Training Loss: 0.150885 | Val. Loss: 0.321400 | Val. Kappa Score: 0.8974 | LR: 0.000950 | Estimated time: 53.52
Train loss on 50 batch: 0.116200
Train loss on 100 batch: 0.185287
Train loss on 150 batch: 0.141466
Train loss on 200 batch: 0.146448
: Epoch: 76 | Training Loss: 0.145124 | Val. Loss: 0.320964 | Val. Kappa Score: 0.8970 | LR: 0.000929 | Estimated time: 53.43
Train loss on 50 batch: 0.120037
Train loss on 100 batch: 0.126650
Train loss on 150 batch: 0.155319
Train loss on 200 batch: 0.147560
: Epoch: 77 | Training Loss: 0.132853 | Val. Loss: 0.276216 | Val. Kappa Score: 0.8966 | LR: 0.000905 | Estimated time: 53.48
Train loss on 50 batch: 0.107882
Train loss on 100 batch: 0.130506
Train loss on 150 batch: 0.115031
Train loss on 200 batch: 0.135458
: Epoch: 78 | Training Loss: 0.113988 | Val. Loss: 0.283305 | Val. Kappa Score: 0.8967 | LR: 0.000877 | Estimated time: 53.50
Train loss on 50 batch: 0.130510
Train loss on 100 batch: 0.111134
Train loss on 150 batch: 0.134404
Train loss on 200 batch: 0.118934
: Epoch: 79 | Training Loss: 0.131937 | Val. Loss: 0.248816 | Val. Kappa Score: 0.8970 | LR: 0.000846 | Estimated time: 53.50
Train loss on 50 batch: 0.089982
Train loss on 100 batch: 0.118235
Train loss on 150 batch: 0.123036
Train loss on 200 batch: 0.155182
: Epoch: 80 | Training Loss: 0.119893 | Val. Loss: 1.538033 | Val. Kappa Score: 0.8927 | LR: 0.000812 | Estimated time: 53.49
Train loss on 50 batch: 0.122719
Train loss on 100 batch: 0.127643
Train loss on 150 batch: 0.118278
Train loss on 200 batch: 0.220015
: Epoch: 81 | Training Loss: 0.154755 | Val. Loss: 0.270474 | Val. Kappa Score: 0.8928 | LR: 0.000775 | Estimated time: 53.47
Train loss on 50 batch: 0.161213
Train loss on 100 batch: 0.126450
Train loss on 150 batch: 0.121208
Train loss on 200 batch: 0.118667
: Epoch: 82 | Training Loss: 0.126782 | Val. Loss: 0.260589 | Val. Kappa Score: 0.8931 | LR: 0.000737 | Estimated time: 53.47
Train loss on 50 batch: 0.102999
Train loss on 100 batch: 0.081020
Train loss on 150 batch: 0.092810
Train loss on 200 batch: 0.107276
: Epoch: 83 | Training Loss: 0.098408 | Val. Loss: 0.245789 | Val. Kappa Score: 0.8931 | LR: 0.000697 | Estimated time: 53.47
Train loss on 50 batch: 0.104791
Train loss on 100 batch: 0.096850
Train loss on 150 batch: 0.102631
Train loss on 200 batch: 0.091066
: Epoch: 84 | Training Loss: 0.095832 | Val. Loss: 0.244860 | Val. Kappa Score: 0.8932 | LR: 0.000655 | Estimated time: 53.57
Train loss on 50 batch: 0.103989
Train loss on 100 batch: 0.084101
Train loss on 150 batch: 0.090658
Train loss on 200 batch: 0.094537
: Epoch: 85 | Training Loss: 0.089435 | Val. Loss: 0.250081 | Val. Kappa Score: 0.8934 | LR: 0.000611 | Estimated time: 53.49
Train loss on 50 batch: 0.073475
Train loss on 100 batch: 0.064167
Train loss on 150 batch: 0.058381
Train loss on 200 batch: 0.087792
: Epoch: 86 | Training Loss: 0.073152 | Val. Loss: 0.240983 | Val. Kappa Score: 0.8935 | LR: 0.000567 | Estimated time: 53.56
Train loss on 50 batch: 0.059001
Train loss on 100 batch: 0.063578
Train loss on 150 batch: 0.069526
Train loss on 200 batch: 0.062566
: Epoch: 87 | Training Loss: 0.075974 | Val. Loss: 0.224552 | Val. Kappa Score: 0.8936 | LR: 0.000522 | Estimated time: 53.46
Train loss on 50 batch: 0.062244
Train loss on 100 batch: 0.067141
Train loss on 150 batch: 0.050104
Train loss on 200 batch: 0.101464
: Epoch: 88 | Training Loss: 0.068713 | Val. Loss: 0.272793 | Val. Kappa Score: 0.8935 | LR: 0.000478 | Estimated time: 53.51
Train loss on 50 batch: 0.059596
Train loss on 100 batch: 0.068688
Train loss on 150 batch: 0.054331
Train loss on 200 batch: 0.068879
: Epoch: 89 | Training Loss: 0.060496 | Val. Loss: 0.220937 | Val. Kappa Score: 0.8938 | LR: 0.000433 | Estimated time: 53.42
Train loss on 50 batch: 0.048068
Train loss on 100 batch: 0.068461
Train loss on 150 batch: 0.049655
Train loss on 200 batch: 0.059419
: Epoch: 90 | Training Loss: 0.058647 | Val. Loss: 0.233024 | Val. Kappa Score: 0.8939 | LR: 0.000389 | Estimated time: 53.53
Train loss on 50 batch: 0.048816
Train loss on 100 batch: 0.043082
Train loss on 150 batch: 0.058393
Train loss on 200 batch: 0.042816
: Epoch: 91 | Training Loss: 0.049344 | Val. Loss: 0.251224 | Val. Kappa Score: 0.8942 | LR: 0.000345 | Estimated time: 53.51
Train loss on 50 batch: 0.043869
Train loss on 100 batch: 0.046384
Train loss on 150 batch: 0.057027
Train loss on 200 batch: 0.048403
: Epoch: 92 | Training Loss: 0.045681 | Val. Loss: 0.234632 | Val. Kappa Score: 0.8943 | LR: 0.000303 | Estimated time: 53.46
Train loss on 50 batch: 0.050958
Train loss on 100 batch: 0.043101
Train loss on 150 batch: 0.061605
Train loss on 200 batch: 0.050620
: Epoch: 93 | Training Loss: 0.053666 | Val. Loss: 0.249202 | Val. Kappa Score: 0.8943 | LR: 0.000263 | Estimated time: 53.47
Train loss on 50 batch: 0.054937
Train loss on 100 batch: 0.039157
Train loss on 150 batch: 0.047185
Train loss on 200 batch: 0.045835
: Epoch: 94 | Training Loss: 0.051119 | Val. Loss: 0.228710 | Val. Kappa Score: 0.8946 | LR: 0.000225 | Estimated time: 53.51
Train loss on 50 batch: 0.043449
Train loss on 100 batch: 0.034363
Train loss on 150 batch: 0.038806
Train loss on 200 batch: 0.047847
: Epoch: 95 | Training Loss: 0.045857 | Val. Loss: 0.252250 | Val. Kappa Score: 0.8947 | LR: 0.000188 | Estimated time: 53.49
Train loss on 50 batch: 0.037253
Train loss on 100 batch: 0.027864
Train loss on 150 batch: 0.043535
Train loss on 200 batch: 0.037769
: Epoch: 96 | Training Loss: 0.037165 | Val. Loss: 0.260433 | Val. Kappa Score: 0.8948 | LR: 0.000154 | Estimated time: 53.49
Train loss on 50 batch: 0.034888
Train loss on 100 batch: 0.041647
Train loss on 150 batch: 0.028824
Train loss on 200 batch: 0.033166
: Epoch: 97 | Training Loss: 0.035708 | Val. Loss: 0.228656 | Val. Kappa Score: 0.8950 | LR: 0.000123 | Estimated time: 53.46
Train loss on 50 batch: 0.032655
Train loss on 100 batch: 0.041909
Train loss on 150 batch: 0.026298
Train loss on 200 batch: 0.031033
: Epoch: 98 | Training Loss: 0.031712 | Val. Loss: 0.224578 | Val. Kappa Score: 0.8951 | LR: 0.000095 | Estimated time: 53.45
Train loss on 50 batch: 0.035695
Train loss on 100 batch: 0.030127
Train loss on 150 batch: 0.029261
Train loss on 200 batch: 0.028088
: Epoch: 99 | Training Loss: 0.031059 | Val. Loss: 0.226315 | Val. Kappa Score: 0.8953 | LR: 0.000071 | Estimated time: 53.48
Train loss on 50 batch: 0.034048
Train loss on 100 batch: 0.027869
Train loss on 150 batch: 0.029477
Train loss on 200 batch: 0.029580
: Epoch: 100 | Training Loss: 0.028300 | Val. Loss: 0.223948 | Val. Kappa Score: 0.8956 | LR: 0.000050 | Estimated time: 53.60
Train loss on 50 batch: 0.027969
Train loss on 100 batch: 0.026872
Train loss on 150 batch: 0.028826
Train loss on 200 batch: 0.027588
: Epoch: 101 | Training Loss: 0.029663 | Val. Loss: 0.226466 | Val. Kappa Score: 0.8958 | LR: 0.000032 | Estimated time: 53.44
Train loss on 50 batch: 0.035960
Train loss on 100 batch: 0.020269
Train loss on 150 batch: 0.027204
Train loss on 200 batch: 0.021428
: Epoch: 102 | Training Loss: 0.029107 | Val. Loss: 0.227829 | Val. Kappa Score: 0.8961 | LR: 0.000018 | Estimated time: 53.47
Train loss on 50 batch: 0.037783
Train loss on 100 batch: 0.021969
Train loss on 150 batch: 0.026448
Train loss on 200 batch: 0.028019
: Epoch: 103 | Training Loss: 0.028028 | Val. Loss: 0.228324 | Val. Kappa Score: 0.8962 | LR: 0.000008 | Estimated time: 53.48
Train loss on 50 batch: 0.027731
Train loss on 100 batch: 0.032196
Train loss on 150 batch: 0.025069
Train loss on 200 batch: 0.027686
: Epoch: 104 | Training Loss: 0.027788 | Val. Loss: 0.228395 | Val. Kappa Score: 0.8965 | LR: 0.000002 | Estimated time: 53.46
Train loss on 50 batch: 0.027868
Train loss on 100 batch: 0.026552
Train loss on 150 batch: 0.036384
Train loss on 200 batch: 0.023101
: Epoch: 105 | Training Loss: 0.027314 | Val. Loss: 0.229290 | Val. Kappa Score: 0.8967 | LR: 0.000000 | Estimated time: 53.44
Train loss on 50 batch: 0.025684
Train loss on 100 batch: 0.030762
Train loss on 150 batch: 0.035806
Train loss on 200 batch: 0.023600
: Epoch: 106 | Training Loss: 0.028134 | Val. Loss: 0.229756 | Val. Kappa Score: 0.8968 | LR: 0.000002 | Estimated time: 53.47
Train loss on 50 batch: 0.024806
Train loss on 100 batch: 0.026551
Train loss on 150 batch: 0.028410
Train loss on 200 batch: 0.029390
: Epoch: 107 | Training Loss: 0.031598 | Val. Loss: 0.230719 | Val. Kappa Score: 0.8970 | LR: 0.000008 | Estimated time: 53.55
Train loss on 50 batch: 0.030429
Train loss on 100 batch: 0.023442
Train loss on 150 batch: 0.027362
Train loss on 200 batch: 0.029952
: Epoch: 108 | Training Loss: 0.026663 | Val. Loss: 0.228633 | Val. Kappa Score: 0.8972 | LR: 0.000018 | Estimated time: 53.51
Train loss on 50 batch: 0.022804
Train loss on 100 batch: 0.029380
Train loss on 150 batch: 0.022502
Train loss on 200 batch: 0.034542
: Epoch: 109 | Training Loss: 0.031548 | Val. Loss: 0.230183 | Val. Kappa Score: 0.8974 | LR: 0.000032 | Estimated time: 53.49
Train loss on 50 batch: 0.024938
Train loss on 100 batch: 0.020225
Train loss on 150 batch: 0.026287
Train loss on 200 batch: 0.028345
: Epoch: 110 | Training Loss: 0.026711 | Val. Loss: 0.228643 | Val. Kappa Score: 0.8975 | LR: 0.000050 | Estimated time: 53.49
Train loss on 50 batch: 0.030555
Train loss on 100 batch: 0.025476
Train loss on 150 batch: 0.037121
Train loss on 200 batch: 0.027998
: Epoch: 111 | Training Loss: 0.030777 | Val. Loss: 0.228624 | Val. Kappa Score: 0.8977 | LR: 0.000071 | Estimated time: 53.50
Train loss on 50 batch: 0.029304
Train loss on 100 batch: 0.033115
Train loss on 150 batch: 0.023773
Train loss on 200 batch: 0.025128
: Epoch: 112 | Training Loss: 0.027436 | Val. Loss: 0.226373 | Val. Kappa Score: 0.8979 | LR: 0.000095 | Estimated time: 53.47
Train loss on 50 batch: 0.029937
Train loss on 100 batch: 0.028929
Train loss on 150 batch: 0.028342
Train loss on 200 batch: 0.029025
: Epoch: 113 | Training Loss: 0.027904 | Val. Loss: 0.228756 | Val. Kappa Score: 0.8981 | LR: 0.000123 | Estimated time: 53.54
Train loss on 50 batch: 0.024424
Train loss on 100 batch: 0.023293
Train loss on 150 batch: 0.026250
Train loss on 200 batch: 0.042952
: Epoch: 114 | Training Loss: 0.027356 | Val. Loss: 0.229189 | Val. Kappa Score: 0.8982 | LR: 0.000154 | Estimated time: 53.54
Train loss on 50 batch: 0.034349
Train loss on 100 batch: 0.032281
Train loss on 150 batch: 0.027715
Train loss on 200 batch: 0.038440
: Epoch: 115 | Training Loss: 0.031525 | Val. Loss: 0.240695 | Val. Kappa Score: 0.8983 | LR: 0.000188 | Estimated time: 53.45
Train loss on 50 batch: 0.023163
Train loss on 100 batch: 0.030701
Train loss on 150 batch: 0.035458
Train loss on 200 batch: 0.043025
: Epoch: 116 | Training Loss: 0.031281 | Val. Loss: 0.254566 | Val. Kappa Score: 0.8983 | LR: 0.000225 | Estimated time: 53.41
Train loss on 50 batch: 0.027674
Train loss on 100 batch: 0.029983
Train loss on 150 batch: 0.035520
Train loss on 200 batch: 0.034113
: Epoch: 117 | Training Loss: 0.032706 | Val. Loss: 0.244791 | Val. Kappa Score: 0.8984 | LR: 0.000263 | Estimated time: 53.46
Train loss on 50 batch: 0.029886
Train loss on 100 batch: 0.040254
Train loss on 150 batch: 0.040210
Train loss on 200 batch: 0.034343
: Epoch: 118 | Training Loss: 0.033543 | Val. Loss: 0.252012 | Val. Kappa Score: 0.8984 | LR: 0.000303 | Estimated time: 53.46
Train loss on 50 batch: 0.033600
Train loss on 100 batch: 0.044766
Train loss on 150 batch: 0.109005
Train loss on 200 batch: 0.068862
: Epoch: 119 | Training Loss: 0.062507 | Val. Loss: 0.303835 | Val. Kappa Score: 0.8983 | LR: 0.000345 | Estimated time: 53.53
Train loss on 50 batch: 0.065120
Train loss on 100 batch: 0.048269
Train loss on 150 batch: 0.060696
Train loss on 200 batch: 0.067234
: Epoch: 120 | Training Loss: 0.062788 | Val. Loss: 0.271438 | Val. Kappa Score: 0.8982 | LR: 0.000389 | Estimated time: 53.52
Train loss on 50 batch: 0.054968
Train loss on 100 batch: 0.046683
Train loss on 150 batch: 0.032450
Train loss on 200 batch: 0.036694
: Epoch: 121 | Training Loss: 0.050304 | Val. Loss: 0.266123 | Val. Kappa Score: 0.8983 | LR: 0.000433 | Estimated time: 53.49
Train loss on 50 batch: 0.045049
Train loss on 100 batch: 0.035372
Train loss on 150 batch: 0.038475
Train loss on 200 batch: 0.050962
: Epoch: 122 | Training Loss: 0.043080 | Val. Loss: 0.280953 | Val. Kappa Score: 0.8983 | LR: 0.000478 | Estimated time: 53.50
Train loss on 50 batch: 0.044402
Train loss on 100 batch: 0.044662
Train loss on 150 batch: 0.042476
Train loss on 200 batch: 0.061879
: Epoch: 123 | Training Loss: 0.044700 | Val. Loss: 0.233122 | Val. Kappa Score: 0.8984 | LR: 0.000522 | Estimated time: 53.43
Train loss on 50 batch: 0.050378
Train loss on 100 batch: 0.062556
Train loss on 150 batch: 0.071842
Train loss on 200 batch: 0.049452
: Epoch: 124 | Training Loss: 0.056502 | Val. Loss: 0.271158 | Val. Kappa Score: 0.8985 | LR: 0.000567 | Estimated time: 53.58
Train loss on 50 batch: 0.038281
Train loss on 100 batch: 0.064801
Train loss on 150 batch: 0.063448
Train loss on 200 batch: 0.060639
: Epoch: 125 | Training Loss: 0.067880 | Val. Loss: 0.302788 | Val. Kappa Score: 0.8985 | LR: 0.000611 | Estimated time: 53.43
Train loss on 50 batch: 0.054849
Train loss on 100 batch: 0.053956
Train loss on 150 batch: 0.060169
Train loss on 200 batch: 0.066618
: Epoch: 126 | Training Loss: 0.065147 | Val. Loss: 0.287261 | Val. Kappa Score: 0.8984 | LR: 0.000655 | Estimated time: 53.50
Train loss on 50 batch: 0.066159
Train loss on 100 batch: 0.064661
Train loss on 150 batch: 0.070394
Train loss on 200 batch: 0.087489
: Epoch: 127 | Training Loss: 0.071048 | Val. Loss: 0.269562 | Val. Kappa Score: 0.8984 | LR: 0.000697 | Estimated time: 53.43
Train loss on 50 batch: 0.061544
Train loss on 100 batch: 0.063259
Train loss on 150 batch: 0.076716
Train loss on 200 batch: 0.090715
: Epoch: 128 | Training Loss: 0.074677 | Val. Loss: 0.304284 | Val. Kappa Score: 0.8984 | LR: 0.000737 | Estimated time: 53.47
Train loss on 50 batch: 0.072710
Train loss on 100 batch: 0.105895
Train loss on 150 batch: 0.108092
Train loss on 200 batch: 0.125147
: Epoch: 129 | Training Loss: 0.109298 | Val. Loss: 0.392933 | Val. Kappa Score: 0.8982 | LR: 0.000775 | Estimated time: 53.42
Train loss on 50 batch: 0.114062
Train loss on 100 batch: 0.086365
Train loss on 150 batch: 0.095360
Train loss on 200 batch: 0.093543
: Epoch: 130 | Training Loss: 0.093459 | Val. Loss: 0.247659 | Val. Kappa Score: 0.8984 | LR: 0.000812 | Estimated time: 53.52
Train loss on 50 batch: 0.087694
Train loss on 100 batch: 0.119427
Train loss on 150 batch: 0.111098
Train loss on 200 batch: 0.085144
: Epoch: 131 | Training Loss: 0.094916 | Val. Loss: 0.401024 | Val. Kappa Score: 0.8982 | LR: 0.000846 | Estimated time: 53.48
Train loss on 50 batch: 0.082091
Train loss on 100 batch: 0.064812
Train loss on 150 batch: 0.080756
Train loss on 200 batch: 0.102712
: Epoch: 132 | Training Loss: 0.101201 | Val. Loss: 0.264397 | Val. Kappa Score: 0.8983 | LR: 0.000877 | Estimated time: 53.44
Train loss on 50 batch: 0.112105
Train loss on 100 batch: 0.273588
Train loss on 150 batch: 0.191934
Train loss on 200 batch: 0.173357
: Epoch: 133 | Training Loss: 0.223922 | Val. Loss: 0.392073 | Val. Kappa Score: 0.8979 | LR: 0.000905 | Estimated time: 53.42
Train loss on 50 batch: 0.192279
Train loss on 100 batch: 0.139872
Train loss on 150 batch: 0.111198
Train loss on 200 batch: 0.123994
: Epoch: 134 | Training Loss: 0.126236 | Val. Loss: 0.275662 | Val. Kappa Score: 0.8979 | LR: 0.000929 | Estimated time: 53.52
Train loss on 50 batch: 0.105548
Train loss on 100 batch: 0.106579
Train loss on 150 batch: 0.093535
Train loss on 200 batch: 0.106235
best-train-loss: 0.093787
best-valid-loss: 0.204284
best-kappa: 0.8981
: Epoch: 135 | Training Loss: 0.093787 | Val. Loss: 0.204284 | Val. Kappa Score: 0.8981 | LR: 0.000950 | Estimated time: 53.50
Train loss on 50 batch: 0.072459
Train loss on 100 batch: 0.086281
Train loss on 150 batch: 0.159821
Train loss on 200 batch: 0.151397
: Epoch: 136 | Training Loss: 0.117337 | Val. Loss: 0.243190 | Val. Kappa Score: 0.8982 | LR: 0.000968 | Estimated time: 53.43
Train loss on 50 batch: 0.116179
Train loss on 100 batch: 0.080511
Train loss on 150 batch: 0.122032
Train loss on 200 batch: 0.174726
: Epoch: 137 | Training Loss: 0.121892 | Val. Loss: 0.317464 | Val. Kappa Score: 0.8981 | LR: 0.000982 | Estimated time: 53.42
Train loss on 50 batch: 0.097529
Train loss on 100 batch: 0.134291
Train loss on 150 batch: 0.100160
Train loss on 200 batch: 0.122015
: Epoch: 138 | Training Loss: 0.101680 | Val. Loss: 0.343987 | Val. Kappa Score: 0.8979 | LR: 0.000992 | Estimated time: 53.47
Train loss on 50 batch: 0.089721
Train loss on 100 batch: 0.099807
Train loss on 150 batch: 0.102761
Train loss on 200 batch: 0.080955
: Epoch: 139 | Training Loss: 0.090682 | Val. Loss: 0.304506 | Val. Kappa Score: 0.8979 | LR: 0.000998 | Estimated time: 53.50
Train loss on 50 batch: 0.074554
Train loss on 100 batch: 0.104410
Train loss on 150 batch: 0.083177
Train loss on 200 batch: 0.092677
: Epoch: 140 | Training Loss: 0.095795 | Val. Loss: 0.264452 | Val. Kappa Score: 0.8979 | LR: 0.001000 | Estimated time: 53.44
Train loss on 50 batch: 0.062729
Train loss on 100 batch: 0.066429
Train loss on 150 batch: 0.076736
Train loss on 200 batch: 0.079767
: Epoch: 141 | Training Loss: 0.072757 | Val. Loss: 0.332832 | Val. Kappa Score: 0.8979 | LR: 0.000998 | Estimated time: 53.51
Train loss on 50 batch: 0.086567
Train loss on 100 batch: 0.080900
Train loss on 150 batch: 0.085284
Train loss on 200 batch: 0.079119
: Epoch: 142 | Training Loss: 0.076133 | Val. Loss: 0.224530 | Val. Kappa Score: 0.8979 | LR: 0.000992 | Estimated time: 53.45
Train loss on 50 batch: 0.061928
Train loss on 100 batch: 0.102277
Train loss on 150 batch: 0.058901
Train loss on 200 batch: 0.097683
: Epoch: 143 | Training Loss: 0.078735 | Val. Loss: 0.322804 | Val. Kappa Score: 0.8979 | LR: 0.000982 | Estimated time: 53.46
Train loss on 50 batch: 0.100031
Train loss on 100 batch: 0.062186
Train loss on 150 batch: 0.070801
Train loss on 200 batch: 0.110662
: Epoch: 144 | Training Loss: 0.099116 | Val. Loss: 0.348032 | Val. Kappa Score: 0.8977 | LR: 0.000968 | Estimated time: 53.42
Train loss on 50 batch: 0.105872
Train loss on 100 batch: 0.100768
Train loss on 150 batch: 0.131366
Train loss on 200 batch: 0.148292
: Epoch: 145 | Training Loss: 0.124657 | Val. Loss: 0.308198 | Val. Kappa Score: 0.8977 | LR: 0.000950 | Estimated time: 53.43
Train loss on 50 batch: 0.139984
Train loss on 100 batch: 0.138707
Train loss on 150 batch: 0.113181
Train loss on 200 batch: 0.089779
: Epoch: 146 | Training Loss: 0.136999 | Val. Loss: 0.304130 | Val. Kappa Score: 0.8977 | LR: 0.000929 | Estimated time: 53.42
Train loss on 50 batch: 0.124168
Train loss on 100 batch: 0.128948
Train loss on 150 batch: 0.157756
Train loss on 200 batch: 0.130395
: Epoch: 147 | Training Loss: 0.135837 | Val. Loss: 0.384311 | Val. Kappa Score: 0.8976 | LR: 0.000905 | Estimated time: 53.42
Train loss on 50 batch: 0.091438
Train loss on 100 batch: 0.095017
Train loss on 150 batch: 0.107063
Train loss on 200 batch: 0.102564
: Epoch: 148 | Training Loss: 0.100152 | Val. Loss: 0.288810 | Val. Kappa Score: 0.8975 | LR: 0.000877 | Estimated time: 53.57
Train loss on 50 batch: 0.066790
Train loss on 100 batch: 0.073232
Train loss on 150 batch: 0.070499
Train loss on 200 batch: 0.075107
: Epoch: 149 | Training Loss: 0.067448 | Val. Loss: 0.242725 | Val. Kappa Score: 0.8976 | LR: 0.000846 | Estimated time: 53.48
Train loss on 50 batch: 0.085118
Train loss on 100 batch: 0.083300
Train loss on 150 batch: 0.065939
Train loss on 200 batch: 0.060372
: Epoch: 150 | Training Loss: 0.066146 | Val. Loss: 0.253198 | Val. Kappa Score: 0.8977 | LR: 0.000812 | Estimated time: 53.38
Train loss on 50 batch: 0.068823
Train loss on 100 batch: 0.057122
Train loss on 150 batch: 0.055724
Train loss on 200 batch: 0.075983
: Epoch: 151 | Training Loss: 0.064685 | Val. Loss: 0.255306 | Val. Kappa Score: 0.8977 | LR: 0.000775 | Estimated time: 53.43
Train loss on 50 batch: 0.054927
Train loss on 100 batch: 0.050883
Train loss on 150 batch: 0.036637
Train loss on 200 batch: 0.064781
: Epoch: 152 | Training Loss: 0.051781 | Val. Loss: 0.230193 | Val. Kappa Score: 0.8979 | LR: 0.000737 | Estimated time: 53.48
Train loss on 50 batch: 0.044944
Train loss on 100 batch: 0.048129
Train loss on 150 batch: 0.043241
Train loss on 200 batch: 0.063426
: Epoch: 153 | Training Loss: 0.057228 | Val. Loss: 0.285641 | Val. Kappa Score: 0.8979 | LR: 0.000697 | Estimated time: 53.48
Train loss on 50 batch: 0.051791
Train loss on 100 batch: 0.063703
Train loss on 150 batch: 0.051512
Train loss on 200 batch: 0.051313
: Epoch: 154 | Training Loss: 0.055680 | Val. Loss: 0.283421 | Val. Kappa Score: 0.8980 | LR: 0.000655 | Estimated time: 53.49
Train loss on 50 batch: 0.043002
Train loss on 100 batch: 0.053047
Train loss on 150 batch: 0.055517
Train loss on 200 batch: 0.049169
: Epoch: 155 | Training Loss: 0.058673 | Val. Loss: 0.257301 | Val. Kappa Score: 0.8980 | LR: 0.000611 | Estimated time: 53.41
Train loss on 50 batch: 0.037882
Train loss on 100 batch: 0.049433
Train loss on 150 batch: 0.047858
Train loss on 200 batch: 0.065103
: Epoch: 156 | Training Loss: 0.045739 | Val. Loss: 0.255800 | Val. Kappa Score: 0.8981 | LR: 0.000567 | Estimated time: 53.53
Train loss on 50 batch: 0.047746
Train loss on 100 batch: 0.041946
Train loss on 150 batch: 0.038132
Train loss on 200 batch: 0.046290
: Epoch: 157 | Training Loss: 0.046112 | Val. Loss: 0.290519 | Val. Kappa Score: 0.8980 | LR: 0.000522 | Estimated time: 53.46
Train loss on 50 batch: 0.038042
Train loss on 100 batch: 0.035340
Train loss on 150 batch: 0.042921
Train loss on 200 batch: 0.038465
: Epoch: 158 | Training Loss: 0.038300 | Val. Loss: 0.280096 | Val. Kappa Score: 0.8979 | LR: 0.000478 | Estimated time: 53.44
Train loss on 50 batch: 0.038338
Train loss on 100 batch: 0.030213
Train loss on 150 batch: 0.030341
Train loss on 200 batch: 0.042733
: Epoch: 159 | Training Loss: 0.041755 | Val. Loss: 0.282892 | Val. Kappa Score: 0.8980 | LR: 0.000433 | Estimated time: 53.48
Train loss on 50 batch: 0.032514
Train loss on 100 batch: 0.039634
Train loss on 150 batch: 0.067606
Train loss on 200 batch: 0.077425
: Epoch: 160 | Training Loss: 0.055030 | Val. Loss: 0.310954 | Val. Kappa Score: 0.8980 | LR: 0.000389 | Estimated time: 53.43
Train loss on 50 batch: 0.045754
Train loss on 100 batch: 0.049995
Train loss on 150 batch: 0.056320
Train loss on 200 batch: 0.040618
: Epoch: 161 | Training Loss: 0.051876 | Val. Loss: 0.273217 | Val. Kappa Score: 0.8980 | LR: 0.000345 | Estimated time: 53.44
Train loss on 50 batch: 0.030896
Train loss on 100 batch: 0.043568
Train loss on 150 batch: 0.044656
Train loss on 200 batch: 0.054106
: Epoch: 162 | Training Loss: 0.040833 | Val. Loss: 0.256626 | Val. Kappa Score: 0.8980 | LR: 0.000303 | Estimated time: 53.49
Train loss on 50 batch: 0.033076
Train loss on 100 batch: 0.028112
Train loss on 150 batch: 0.037117
Train loss on 200 batch: 0.035724
: Epoch: 163 | Training Loss: 0.033066 | Val. Loss: 0.247709 | Val. Kappa Score: 0.8980 | LR: 0.000263 | Estimated time: 53.44
Train loss on 50 batch: 0.036174
Train loss on 100 batch: 0.030665
Train loss on 150 batch: 0.034563
Train loss on 200 batch: 0.027714
: Epoch: 164 | Training Loss: 0.035603 | Val. Loss: 0.252081 | Val. Kappa Score: 0.8980 | LR: 0.000225 | Estimated time: 53.45
Train loss on 50 batch: 0.022861
Train loss on 100 batch: 0.029728
Train loss on 150 batch: 0.030934
Train loss on 200 batch: 0.024807
: Epoch: 165 | Training Loss: 0.028695 | Val. Loss: 0.234979 | Val. Kappa Score: 0.8981 | LR: 0.000188 | Estimated time: 53.48
Train loss on 50 batch: 0.029779
Train loss on 100 batch: 0.024486
Train loss on 150 batch: 0.023786
Train loss on 200 batch: 0.032411
: Epoch: 166 | Training Loss: 0.024436 | Val. Loss: 0.243574 | Val. Kappa Score: 0.8981 | LR: 0.000154 | Estimated time: 53.47
Train loss on 50 batch: 0.022838
Train loss on 100 batch: 0.022028
Train loss on 150 batch: 0.026223
Train loss on 200 batch: 0.024354
: Epoch: 167 | Training Loss: 0.025412 | Val. Loss: 0.242503 | Val. Kappa Score: 0.8982 | LR: 0.000123 | Estimated time: 53.49
Train loss on 50 batch: 0.023880
Train loss on 100 batch: 0.019432
Train loss on 150 batch: 0.020739
Train loss on 200 batch: 0.026309
: Epoch: 168 | Training Loss: 0.021981 | Val. Loss: 0.238706 | Val. Kappa Score: 0.8982 | LR: 0.000095 | Estimated time: 53.51
Train loss on 50 batch: 0.030101
Train loss on 100 batch: 0.022896
Train loss on 150 batch: 0.020317
Train loss on 200 batch: 0.019571
: Epoch: 169 | Training Loss: 0.021569 | Val. Loss: 0.225166 | Val. Kappa Score: 0.8983 | LR: 0.000071 | Estimated time: 53.46
Train loss on 50 batch: 0.019199
Train loss on 100 batch: 0.024180
Train loss on 150 batch: 0.030508
Train loss on 200 batch: 0.020662
: Epoch: 170 | Training Loss: 0.022203 | Val. Loss: 0.230289 | Val. Kappa Score: 0.8984 | LR: 0.000050 | Estimated time: 53.50
Train loss on 50 batch: 0.021592
Train loss on 100 batch: 0.019049
Train loss on 150 batch: 0.021364
Train loss on 200 batch: 0.022895
: Epoch: 171 | Training Loss: 0.019557 | Val. Loss: 0.227753 | Val. Kappa Score: 0.8986 | LR: 0.000032 | Estimated time: 53.55
Train loss on 50 batch: 0.023217
Train loss on 100 batch: 0.019271
Train loss on 150 batch: 0.024217
Train loss on 200 batch: 0.021661
: Epoch: 172 | Training Loss: 0.021098 | Val. Loss: 0.228272 | Val. Kappa Score: 0.8987 | LR: 0.000018 | Estimated time: 53.46
Train loss on 50 batch: 0.018867
Train loss on 100 batch: 0.017600
Train loss on 150 batch: 0.026853
Train loss on 200 batch: 0.022092
: Epoch: 173 | Training Loss: 0.022796 | Val. Loss: 0.229857 | Val. Kappa Score: 0.8987 | LR: 0.000008 | Estimated time: 53.47
Train loss on 50 batch: 0.021259
Train loss on 100 batch: 0.020378
Train loss on 150 batch: 0.015496
Train loss on 200 batch: 0.022934
: Epoch: 174 | Training Loss: 0.025159 | Val. Loss: 0.227899 | Val. Kappa Score: 0.8988 | LR: 0.000002 | Estimated time: 53.45
Train loss on 50 batch: 0.021270
Train loss on 100 batch: 0.023682
Train loss on 150 batch: 0.016851
Train loss on 200 batch: 0.013193
: Epoch: 175 | Training Loss: 0.020661 | Val. Loss: 0.228017 | Val. Kappa Score: 0.8990 | LR: 0.000000 | Estimated time: 53.46
Train loss on 50 batch: 0.018593
Train loss on 100 batch: 0.017900
Train loss on 150 batch: 0.019853
Train loss on 200 batch: 0.029243
: Epoch: 176 | Training Loss: 0.019894 | Val. Loss: 0.228094 | Val. Kappa Score: 0.8991 | LR: 0.000002 | Estimated time: 53.47
Train loss on 50 batch: 0.014717
Train loss on 100 batch: 0.017585
Train loss on 150 batch: 0.020225
Train loss on 200 batch: 0.027772
: Epoch: 177 | Training Loss: 0.018474 | Val. Loss: 0.228794 | Val. Kappa Score: 0.8991 | LR: 0.000008 | Estimated time: 53.49
Train loss on 50 batch: 0.015458
Train loss on 100 batch: 0.019206
Train loss on 150 batch: 0.022100
Train loss on 200 batch: 0.021120
: Epoch: 178 | Training Loss: 0.021346 | Val. Loss: 0.227163 | Val. Kappa Score: 0.8992 | LR: 0.000018 | Estimated time: 53.47
Train loss on 50 batch: 0.016532
Train loss on 100 batch: 0.022639
Train loss on 150 batch: 0.020430
Train loss on 200 batch: 0.022863
: Epoch: 179 | Training Loss: 0.018606 | Val. Loss: 0.224934 | Val. Kappa Score: 0.8993 | LR: 0.000032 | Estimated time: 53.46
Train loss on 50 batch: 0.016346
Train loss on 100 batch: 0.021887
Train loss on 150 batch: 0.021871
Train loss on 200 batch: 0.019951
: Epoch: 180 | Training Loss: 0.018828 | Val. Loss: 0.226423 | Val. Kappa Score: 0.8995 | LR: 0.000050 | Estimated time: 53.47
Train loss on 50 batch: 0.019599
Train loss on 100 batch: 0.020379
Train loss on 150 batch: 0.020199
Train loss on 200 batch: 0.021838
: Epoch: 181 | Training Loss: 0.018760 | Val. Loss: 0.225041 | Val. Kappa Score: 0.8995 | LR: 0.000071 | Estimated time: 53.48
Train loss on 50 batch: 0.021612
Train loss on 100 batch: 0.018936
Train loss on 150 batch: 0.022372
Train loss on 200 batch: 0.022054
: Epoch: 182 | Training Loss: 0.021678 | Val. Loss: 0.221789 | Val. Kappa Score: 0.8996 | LR: 0.000095 | Estimated time: 53.48
Train loss on 50 batch: 0.026079
Train loss on 100 batch: 0.017029
Train loss on 150 batch: 0.023607
Train loss on 200 batch: 0.017614
: Epoch: 183 | Training Loss: 0.021658 | Val. Loss: 0.225081 | Val. Kappa Score: 0.8998 | LR: 0.000123 | Estimated time: 53.47
Train loss on 50 batch: 0.021156
Train loss on 100 batch: 0.019366
Train loss on 150 batch: 0.019567
Train loss on 200 batch: 0.029496
: Epoch: 184 | Training Loss: 0.025009 | Val. Loss: 0.230303 | Val. Kappa Score: 0.8998 | LR: 0.000154 | Estimated time: 53.45
Train loss on 50 batch: 0.013787
Train loss on 100 batch: 0.022894
Train loss on 150 batch: 0.024558
Train loss on 200 batch: 0.026880
: Epoch: 185 | Training Loss: 0.026378 | Val. Loss: 0.229109 | Val. Kappa Score: 0.8999 | LR: 0.000188 | Estimated time: 53.43
Train loss on 50 batch: 0.023493
Train loss on 100 batch: 0.023046
Train loss on 150 batch: 0.018177
Train loss on 200 batch: 0.031160
: Epoch: 186 | Training Loss: 0.022144 | Val. Loss: 0.236805 | Val. Kappa Score: 0.9000 | LR: 0.000225 | Estimated time: 53.50
Train loss on 50 batch: 0.024726
Train loss on 100 batch: 0.020878
Train loss on 150 batch: 0.024372
Train loss on 200 batch: 0.019453
: Epoch: 187 | Training Loss: 0.026169 | Val. Loss: 0.249970 | Val. Kappa Score: 0.9000 | LR: 0.000263 | Estimated time: 53.45
Train loss on 50 batch: 0.023335
Train loss on 100 batch: 0.023008
Train loss on 150 batch: 0.059595
Train loss on 200 batch: 0.040736
: Epoch: 188 | Training Loss: 0.035732 | Val. Loss: 0.260221 | Val. Kappa Score: 0.9000 | LR: 0.000303 | Estimated time: 53.42
Train loss on 50 batch: 0.026891
Train loss on 100 batch: 0.032610
Train loss on 150 batch: 0.024614
Train loss on 200 batch: 0.038518
: Epoch: 189 | Training Loss: 0.027634 | Val. Loss: 0.253504 | Val. Kappa Score: 0.9001 | LR: 0.000345 | Estimated time: 53.45
Train loss on 50 batch: 0.022490
Train loss on 100 batch: 0.028749
Train loss on 150 batch: 0.033484
Train loss on 200 batch: 0.032854
: Epoch: 190 | Training Loss: 0.027306 | Val. Loss: 0.244541 | Val. Kappa Score: 0.9001 | LR: 0.000389 | Estimated time: 53.42
Train loss on 50 batch: 0.024109
Train loss on 100 batch: 0.037592
Train loss on 150 batch: 0.033389
Train loss on 200 batch: 0.027373
: Epoch: 191 | Training Loss: 0.030747 | Val. Loss: 0.275094 | Val. Kappa Score: 0.9002 | LR: 0.000433 | Estimated time: 53.47
Train loss on 50 batch: 0.035692
Train loss on 100 batch: 0.039286
Train loss on 150 batch: 0.038373
Train loss on 200 batch: 0.037329
: Epoch: 192 | Training Loss: 0.041225 | Val. Loss: 0.246898 | Val. Kappa Score: 0.9002 | LR: 0.000478 | Estimated time: 53.43
Train loss on 50 batch: 0.055712
Train loss on 100 batch: 0.037065
Train loss on 150 batch: 0.038452
Train loss on 200 batch: 0.031759
: Epoch: 193 | Training Loss: 0.038182 | Val. Loss: 0.257911 | Val. Kappa Score: 0.9002 | LR: 0.000522 | Estimated time: 53.49
Train loss on 50 batch: 0.044962
Train loss on 100 batch: 0.042768
Train loss on 150 batch: 0.040825
Train loss on 200 batch: 0.043667
: Epoch: 194 | Training Loss: 0.042472 | Val. Loss: 0.271192 | Val. Kappa Score: 0.9003 | LR: 0.000567 | Estimated time: 53.47
Train loss on 50 batch: 0.040172
Train loss on 100 batch: 0.039499
Train loss on 150 batch: 0.048557
Train loss on 200 batch: 0.053137
: Epoch: 195 | Training Loss: 0.046907 | Val. Loss: 0.343346 | Val. Kappa Score: 0.9002 | LR: 0.000611 | Estimated time: 53.49
Train loss on 50 batch: 0.049482
Train loss on 100 batch: 0.045874
Train loss on 150 batch: 0.046222
Train loss on 200 batch: 0.044003
: Epoch: 196 | Training Loss: 0.050962 | Val. Loss: 0.214452 | Val. Kappa Score: 0.9004 | LR: 0.000655 | Estimated time: 53.45
Train loss on 50 batch: 0.035647
Train loss on 100 batch: 0.046499
Train loss on 150 batch: 0.091326
Train loss on 200 batch: 0.079406
: Epoch: 197 | Training Loss: 0.066774 | Val. Loss: 0.267269 | Val. Kappa Score: 0.9003 | LR: 0.000697 | Estimated time: 53.41
Train loss on 50 batch: 0.103594
Train loss on 100 batch: 0.053606
Train loss on 150 batch: 0.100235
Train loss on 200 batch: 0.076422
: Epoch: 198 | Training Loss: 0.084399 | Val. Loss: 0.312179 | Val. Kappa Score: 0.9003 | LR: 0.000737 | Estimated time: 53.51
Train loss on 50 batch: 0.088465
Train loss on 100 batch: 0.097512
Train loss on 150 batch: 0.107994
Train loss on 200 batch: 0.061544
: Epoch: 199 | Training Loss: 0.101172 | Val. Loss: 0.281748 | Val. Kappa Score: 0.9003 | LR: 0.000775 | Estimated time: 53.43
Train loss on 50 batch: 0.059795
Train loss on 100 batch: 0.074989
Train loss on 150 batch: 0.095304
Train loss on 200 batch: 0.083916
: Epoch: 200 | Training Loss: 0.077950 | Val. Loss: 0.258343 | Val. Kappa Score: 0.9004 | LR: 0.000812 | Estimated time: 53.49
Train loss on 50 batch: 0.078741
Train loss on 100 batch: 0.085815
Train loss on 150 batch: 0.088375
Train loss on 200 batch: 0.112100
: Epoch: 201 | Training Loss: 0.100904 | Val. Loss: 0.339465 | Val. Kappa Score: 0.9004 | LR: 0.000846 | Estimated time: 53.51
Train loss on 50 batch: 0.141363
Train loss on 100 batch: 0.154432
Train loss on 150 batch: 0.218107
Train loss on 200 batch: 0.162655
: Epoch: 202 | Training Loss: 0.191901 | Val. Loss: 0.400251 | Val. Kappa Score: 0.9003 | LR: 0.000877 | Estimated time: 53.47
Train loss on 50 batch: 0.125948
Train loss on 100 batch: 0.100639
Train loss on 150 batch: 0.099219
Train loss on 200 batch: 0.070247
: Epoch: 203 | Training Loss: 0.106054 | Val. Loss: 0.244679 | Val. Kappa Score: 0.9003 | LR: 0.000905 | Estimated time: 53.45
Train loss on 50 batch: 0.072461
Train loss on 100 batch: 0.080208
Train loss on 150 batch: 0.075270
Train loss on 200 batch: 0.072012
: Epoch: 204 | Training Loss: 0.074647 | Val. Loss: 0.258021 | Val. Kappa Score: 0.9003 | LR: 0.000929 | Estimated time: 53.48
Train loss on 50 batch: 0.069844
Train loss on 100 batch: 0.079851
Train loss on 150 batch: 0.068078
Train loss on 200 batch: 0.062309
: Epoch: 205 | Training Loss: 0.066272 | Val. Loss: 0.253823 | Val. Kappa Score: 0.9004 | LR: 0.000950 | Estimated time: 53.45
Train loss on 50 batch: 0.066819
Train loss on 100 batch: 0.060498
Train loss on 150 batch: 0.052521
Train loss on 200 batch: 0.061453
: Epoch: 206 | Training Loss: 0.067274 | Val. Loss: 0.257927 | Val. Kappa Score: 0.9004 | LR: 0.000968 | Estimated time: 53.42
Train loss on 50 batch: 0.048272
Train loss on 100 batch: 0.048892
Train loss on 150 batch: 0.059894
Train loss on 200 batch: 0.061237
: Epoch: 207 | Training Loss: 0.063800 | Val. Loss: 0.260592 | Val. Kappa Score: 0.9005 | LR: 0.000982 | Estimated time: 53.43
Train loss on 50 batch: 0.074352
Train loss on 100 batch: 0.064259
Train loss on 150 batch: 0.052484
Train loss on 200 batch: 0.064721
: Epoch: 208 | Training Loss: 0.060244 | Val. Loss: 0.291796 | Val. Kappa Score: 0.9005 | LR: 0.000992 | Estimated time: 53.48
Train loss on 50 batch: 0.065257
Train loss on 100 batch: 0.191053
Train loss on 150 batch: 0.182978
Train loss on 200 batch: 0.218038
: Epoch: 209 | Training Loss: 0.167692 | Val. Loss: 0.330198 | Val. Kappa Score: 0.9004 | LR: 0.000998 | Estimated time: 53.50
Train loss on 50 batch: 0.164198
Train loss on 100 batch: 0.134350
Train loss on 150 batch: 0.117328
Train loss on 200 batch: 0.107325
: Epoch: 210 | Training Loss: 0.126038 | Val. Loss: 0.263736 | Val. Kappa Score: 0.9003 | LR: 0.001000 | Estimated time: 53.46
Train loss on 50 batch: 0.093606
Train loss on 100 batch: 0.077877
Train loss on 150 batch: 0.103333
Train loss on 200 batch: 0.090272
: Epoch: 211 | Training Loss: 0.087684 | Val. Loss: 0.297979 | Val. Kappa Score: 0.9004 | LR: 0.000998 | Estimated time: 53.47
Train loss on 50 batch: 0.064005
Train loss on 100 batch: 0.069606
Train loss on 150 batch: 0.091828
Train loss on 200 batch: 0.165612
: Epoch: 212 | Training Loss: 0.125626 | Val. Loss: 1.363931 | Val. Kappa Score: 0.8994 | LR: 0.000992 | Estimated time: 53.53
Train loss on 50 batch: 0.164442
Train loss on 100 batch: 0.107078
Train loss on 150 batch: 0.127137
Train loss on 200 batch: 0.105159
: Epoch: 213 | Training Loss: 0.125007 | Val. Loss: 0.288675 | Val. Kappa Score: 0.8993 | LR: 0.000982 | Estimated time: 53.47
Train loss on 50 batch: 0.070710
Train loss on 100 batch: 0.071044
Train loss on 150 batch: 0.081824
Train loss on 200 batch: 0.075978
: Epoch: 214 | Training Loss: 0.072403 | Val. Loss: 0.321857 | Val. Kappa Score: 0.8993 | LR: 0.000968 | Estimated time: 53.49
Train loss on 50 batch: 0.063523
Train loss on 100 batch: 0.078969
Train loss on 150 batch: 0.051441
Train loss on 200 batch: 0.058513
: Epoch: 215 | Training Loss: 0.059260 | Val. Loss: 0.255337 | Val. Kappa Score: 0.8993 | LR: 0.000950 | Estimated time: 53.40
Train loss on 50 batch: 0.059466
Train loss on 100 batch: 0.042840
Train loss on 150 batch: 0.052705
Train loss on 200 batch: 0.047185
: Epoch: 216 | Training Loss: 0.044626 | Val. Loss: 0.253960 | Val. Kappa Score: 0.8993 | LR: 0.000929 | Estimated time: 53.47
Train loss on 50 batch: 0.046065
Train loss on 100 batch: 0.059294
Train loss on 150 batch: 0.051920
Train loss on 200 batch: 0.049928
: Epoch: 217 | Training Loss: 0.068252 | Val. Loss: 0.292002 | Val. Kappa Score: 0.8994 | LR: 0.000905 | Estimated time: 53.52
Train loss on 50 batch: 0.051022
Train loss on 100 batch: 0.061568
Train loss on 150 batch: 0.047919
Train loss on 200 batch: 0.056707
: Epoch: 218 | Training Loss: 0.053868 | Val. Loss: 0.274955 | Val. Kappa Score: 0.8993 | LR: 0.000877 | Estimated time: 53.48
Train loss on 50 batch: 0.039921
Train loss on 100 batch: 0.065631
Train loss on 150 batch: 0.041831
Train loss on 200 batch: 0.045913
: Epoch: 219 | Training Loss: 0.046452 | Val. Loss: 0.253636 | Val. Kappa Score: 0.8993 | LR: 0.000846 | Estimated time: 53.61
Train loss on 50 batch: 0.046199
Train loss on 100 batch: 0.038793
Train loss on 150 batch: 0.049591
Train loss on 200 batch: 0.046918
: Epoch: 220 | Training Loss: 0.044632 | Val. Loss: 0.253083 | Val. Kappa Score: 0.8993 | LR: 0.000812 | Estimated time: 53.47
Train loss on 50 batch: 0.051540
Train loss on 100 batch: 0.035641
Train loss on 150 batch: 0.058066
Train loss on 200 batch: 0.062578
: Epoch: 221 | Training Loss: 0.054332 | Val. Loss: 0.272496 | Val. Kappa Score: 0.8993 | LR: 0.000775 | Estimated time: 53.43
Train loss on 50 batch: 0.054378
Train loss on 100 batch: 0.062594
Train loss on 150 batch: 0.045334
Train loss on 200 batch: 0.049414
: Epoch: 222 | Training Loss: 0.054273 | Val. Loss: 0.246023 | Val. Kappa Score: 0.8993 | LR: 0.000737 | Estimated time: 53.49
Train loss on 50 batch: 0.052510
Train loss on 100 batch: 0.045591
Train loss on 150 batch: 0.059757
Train loss on 200 batch: 0.071166
: Epoch: 223 | Training Loss: 0.063131 | Val. Loss: 0.280564 | Val. Kappa Score: 0.8993 | LR: 0.000697 | Estimated time: 53.51
Train loss on 50 batch: 0.056380
Train loss on 100 batch: 0.054526
Train loss on 150 batch: 0.039372
Train loss on 200 batch: 0.049307
: Epoch: 224 | Training Loss: 0.048644 | Val. Loss: 0.257442 | Val. Kappa Score: 0.8994 | LR: 0.000655 | Estimated time: 53.44
Train loss on 50 batch: 0.055476
Train loss on 100 batch: 0.057040
Train loss on 150 batch: 0.048345
Train loss on 200 batch: 0.043675
: Epoch: 225 | Training Loss: 0.048123 | Val. Loss: 0.290855 | Val. Kappa Score: 0.8994 | LR: 0.000611 | Estimated time: 53.43
Train loss on 50 batch: 0.045975
Train loss on 100 batch: 0.029494
Train loss on 150 batch: 0.039259
Train loss on 200 batch: 0.039429
: Epoch: 226 | Training Loss: 0.036358 | Val. Loss: 0.277709 | Val. Kappa Score: 0.8994 | LR: 0.000567 | Estimated time: 53.46
Train loss on 50 batch: 0.029884
Train loss on 100 batch: 0.046105
Train loss on 150 batch: 0.052607
Train loss on 200 batch: 0.047413
: Epoch: 227 | Training Loss: 0.041558 | Val. Loss: 0.291716 | Val. Kappa Score: 0.8995 | LR: 0.000522 | Estimated time: 53.51
Train loss on 50 batch: 0.026307
Train loss on 100 batch: 0.036729
Train loss on 150 batch: 0.038302
Train loss on 200 batch: 0.030891
: Epoch: 228 | Training Loss: 0.031008 | Val. Loss: 0.252784 | Val. Kappa Score: 0.8995 | LR: 0.000478 | Estimated time: 53.45
Train loss on 50 batch: 0.033607
Train loss on 100 batch: 0.037507
Train loss on 150 batch: 0.033187
Train loss on 200 batch: 0.029745
: Epoch: 229 | Training Loss: 0.031921 | Val. Loss: 0.249496 | Val. Kappa Score: 0.8996 | LR: 0.000433 | Estimated time: 53.46
Train loss on 50 batch: 0.027745
Train loss on 100 batch: 0.030188
Train loss on 150 batch: 0.020719
Train loss on 200 batch: 0.035664
: Epoch: 230 | Training Loss: 0.028749 | Val. Loss: 0.277579 | Val. Kappa Score: 0.8996 | LR: 0.000389 | Estimated time: 53.40
Train loss on 50 batch: 0.035508
Train loss on 100 batch: 0.032594
Train loss on 150 batch: 0.038184
Train loss on 200 batch: 0.029130
: Epoch: 231 | Training Loss: 0.032011 | Val. Loss: 0.277783 | Val. Kappa Score: 0.8995 | LR: 0.000345 | Estimated time: 53.53
Train loss on 50 batch: 0.030010
Train loss on 100 batch: 0.023478
Train loss on 150 batch: 0.026722
Train loss on 200 batch: 0.019779
: Epoch: 232 | Training Loss: 0.026358 | Val. Loss: 0.264067 | Val. Kappa Score: 0.8996 | LR: 0.000303 | Estimated time: 53.48
Train loss on 50 batch: 0.025179
Train loss on 100 batch: 0.017041
Train loss on 150 batch: 0.021653
Train loss on 200 batch: 0.025617
: Epoch: 233 | Training Loss: 0.025649 | Val. Loss: 0.245498 | Val. Kappa Score: 0.8996 | LR: 0.000263 | Estimated time: 53.46
Train loss on 50 batch: 0.023727
Train loss on 100 batch: 0.026067
Train loss on 150 batch: 0.021638
Train loss on 200 batch: 0.026886
: Epoch: 234 | Training Loss: 0.022059 | Val. Loss: 0.245635 | Val. Kappa Score: 0.8996 | LR: 0.000225 | Estimated time: 53.44
Train loss on 50 batch: 0.016774
Train loss on 100 batch: 0.020663
Train loss on 150 batch: 0.016751
Train loss on 200 batch: 0.027843
: Epoch: 235 | Training Loss: 0.017930 | Val. Loss: 0.244709 | Val. Kappa Score: 0.8997 | LR: 0.000188 | Estimated time: 53.47
Train loss on 50 batch: 0.023362
Train loss on 100 batch: 0.016710
Train loss on 150 batch: 0.017092
Train loss on 200 batch: 0.028064
: Epoch: 236 | Training Loss: 0.022166 | Val. Loss: 0.247443 | Val. Kappa Score: 0.8997 | LR: 0.000154 | Estimated time: 53.39
Train loss on 50 batch: 0.016340
Train loss on 100 batch: 0.019704
Train loss on 150 batch: 0.028612
Train loss on 200 batch: 0.017817
: Epoch: 237 | Training Loss: 0.018941 | Val. Loss: 0.248089 | Val. Kappa Score: 0.8998 | LR: 0.000123 | Estimated time: 53.57
Train loss on 50 batch: 0.023698
Train loss on 100 batch: 0.018955
Train loss on 150 batch: 0.018561
Train loss on 200 batch: 0.020730
: Epoch: 238 | Training Loss: 0.022864 | Val. Loss: 0.238477 | Val. Kappa Score: 0.8999 | LR: 0.000095 | Estimated time: 53.53
Train loss on 50 batch: 0.017948
Train loss on 100 batch: 0.017140
Train loss on 150 batch: 0.026343
Train loss on 200 batch: 0.015076
: Epoch: 239 | Training Loss: 0.018058 | Val. Loss: 0.237876 | Val. Kappa Score: 0.9000 | LR: 0.000071 | Estimated time: 53.50
Train loss on 50 batch: 0.023594
Train loss on 100 batch: 0.015705
Train loss on 150 batch: 0.018968
Train loss on 200 batch: 0.013921
: Epoch: 240 | Training Loss: 0.017511 | Val. Loss: 0.236290 | Val. Kappa Score: 0.9000 | LR: 0.000050 | Estimated time: 53.45
Train loss on 50 batch: 0.018281
Train loss on 100 batch: 0.018420
Train loss on 150 batch: 0.020393
Train loss on 200 batch: 0.017766
: Epoch: 241 | Training Loss: 0.020310 | Val. Loss: 0.238279 | Val. Kappa Score: 0.9001 | LR: 0.000032 | Estimated time: 53.55
Train loss on 50 batch: 0.025440
Train loss on 100 batch: 0.013900
Train loss on 150 batch: 0.019557
Train loss on 200 batch: 0.014044
: Epoch: 242 | Training Loss: 0.018621 | Val. Loss: 0.240078 | Val. Kappa Score: 0.9001 | LR: 0.000018 | Estimated time: 53.55
Train loss on 50 batch: 0.015772
Train loss on 100 batch: 0.021919
Train loss on 150 batch: 0.019308
Train loss on 200 batch: 0.014802
: Epoch: 243 | Training Loss: 0.019646 | Val. Loss: 0.235894 | Val. Kappa Score: 0.9002 | LR: 0.000008 | Estimated time: 53.52
Train loss on 50 batch: 0.023165
Train loss on 100 batch: 0.016254
Train loss on 150 batch: 0.014218
Train loss on 200 batch: 0.015176
: Epoch: 244 | Training Loss: 0.016533 | Val. Loss: 0.238156 | Val. Kappa Score: 0.9002 | LR: 0.000002 | Estimated time: 53.47
Train loss on 50 batch: 0.019732
Train loss on 100 batch: 0.017299
Train loss on 150 batch: 0.016345
Train loss on 200 batch: 0.017855
: Epoch: 245 | Training Loss: 0.017601 | Val. Loss: 0.236700 | Val. Kappa Score: 0.9003 | LR: 0.000000 | Estimated time: 53.54
Train loss on 50 batch: 0.015468
Train loss on 100 batch: 0.026323
Train loss on 150 batch: 0.014755
Train loss on 200 batch: 0.013305
: Epoch: 246 | Training Loss: 0.022101 | Val. Loss: 0.236990 | Val. Kappa Score: 0.9003 | LR: 0.000002 | Estimated time: 53.47
Train loss on 50 batch: 0.013707
Train loss on 100 batch: 0.018536
Train loss on 150 batch: 0.017412
Train loss on 200 batch: 0.018992
: Epoch: 247 | Training Loss: 0.016848 | Val. Loss: 0.237873 | Val. Kappa Score: 0.9004 | LR: 0.000008 | Estimated time: 53.48
Train loss on 50 batch: 0.012433
Train loss on 100 batch: 0.016572
Train loss on 150 batch: 0.016082
Train loss on 200 batch: 0.025987
: Epoch: 248 | Training Loss: 0.018459 | Val. Loss: 0.235731 | Val. Kappa Score: 0.9005 | LR: 0.000018 | Estimated time: 53.45
Train loss on 50 batch: 0.016162
Train loss on 100 batch: 0.016069
Train loss on 150 batch: 0.016774
Train loss on 200 batch: 0.018711
: Epoch: 249 | Training Loss: 0.023491 | Val. Loss: 0.237222 | Val. Kappa Score: 0.9005 | LR: 0.000032 | Estimated time: 53.48
Train loss on 50 batch: 0.018204
Train loss on 100 batch: 0.016538
Train loss on 150 batch: 0.017163
Train loss on 200 batch: 0.014851
: Epoch: 250 | Training Loss: 0.014598 | Val. Loss: 0.235507 | Val. Kappa Score: 0.9006 | LR: 0.000050 | Estimated time: 53.51
Train loss on 50 batch: 0.015754
Train loss on 100 batch: 0.021972
Train loss on 150 batch: 0.019200
Train loss on 200 batch: 0.011423
: Epoch: 251 | Training Loss: 0.017616 | Val. Loss: 0.241900 | Val. Kappa Score: 0.9006 | LR: 0.000071 | Estimated time: 53.49
Train loss on 50 batch: 0.018160
Train loss on 100 batch: 0.019947
Train loss on 150 batch: 0.018597
Train loss on 200 batch: 0.013598
: Epoch: 252 | Training Loss: 0.018304 | Val. Loss: 0.236208 | Val. Kappa Score: 0.9007 | LR: 0.000095 | Estimated time: 53.48
Train loss on 50 batch: 0.012547
Train loss on 100 batch: 0.021173
Train loss on 150 batch: 0.017302
Train loss on 200 batch: 0.024659
: Epoch: 253 | Training Loss: 0.018996 | Val. Loss: 0.230198 | Val. Kappa Score: 0.9008 | LR: 0.000123 | Estimated time: 53.53
Train loss on 50 batch: 0.018752
Train loss on 100 batch: 0.012898
Train loss on 150 batch: 0.020572
Train loss on 200 batch: 0.016050
: Epoch: 254 | Training Loss: 0.021261 | Val. Loss: 0.240554 | Val. Kappa Score: 0.9008 | LR: 0.000154 | Estimated time: 53.51
Train loss on 50 batch: 0.013601
Train loss on 100 batch: 0.022050
Train loss on 150 batch: 0.018984
Train loss on 200 batch: 0.020167
: Epoch: 255 | Training Loss: 0.018030 | Val. Loss: 0.235741 | Val. Kappa Score: 0.9008 | LR: 0.000188 | Estimated time: 53.58
Train loss on 50 batch: 0.011962
Train loss on 100 batch: 0.019581
Train loss on 150 batch: 0.022136
Train loss on 200 batch: 0.022154
: Epoch: 256 | Training Loss: 0.018489 | Val. Loss: 0.246353 | Val. Kappa Score: 0.9009 | LR: 0.000225 | Estimated time: 53.41
Train loss on 50 batch: 0.018396
Train loss on 100 batch: 0.015476
Train loss on 150 batch: 0.020154
Train loss on 200 batch: 0.025541
: Epoch: 257 | Training Loss: 0.019609 | Val. Loss: 0.259198 | Val. Kappa Score: 0.9010 | LR: 0.000263 | Estimated time: 53.40
Train loss on 50 batch: 0.019707
Train loss on 100 batch: 0.019853
Train loss on 150 batch: 0.027291
Train loss on 200 batch: 0.028212
: Epoch: 258 | Training Loss: 0.022067 | Val. Loss: 0.263293 | Val. Kappa Score: 0.9010 | LR: 0.000303 | Estimated time: 53.53
Train loss on 50 batch: 0.027582
Train loss on 100 batch: 0.020387
Train loss on 150 batch: 0.027957
Train loss on 200 batch: 0.020928
: Epoch: 259 | Training Loss: 0.021650 | Val. Loss: 0.242270 | Val. Kappa Score: 0.9011 | LR: 0.000345 | Estimated time: 53.47
Train loss on 50 batch: 0.025666
Train loss on 100 batch: 0.033316
Train loss on 150 batch: 0.021855
Train loss on 200 batch: 0.016634
: Epoch: 260 | Training Loss: 0.025733 | Val. Loss: 0.272240 | Val. Kappa Score: 0.9011 | LR: 0.000389 | Estimated time: 53.43
Train loss on 50 batch: 0.024235
Train loss on 100 batch: 0.022769
Train loss on 150 batch: 0.028805
Train loss on 200 batch: 0.033163
: Epoch: 261 | Training Loss: 0.031703 | Val. Loss: 0.261307 | Val. Kappa Score: 0.9011 | LR: 0.000433 | Estimated time: 53.51
Train loss on 50 batch: 0.026597
Train loss on 100 batch: 0.031706
Train loss on 150 batch: 0.027383
Train loss on 200 batch: 0.036683
: Epoch: 262 | Training Loss: 0.028141 | Val. Loss: 0.268867 | Val. Kappa Score: 0.9011 | LR: 0.000478 | Estimated time: 53.44
Train loss on 50 batch: 0.032389
Train loss on 100 batch: 0.038265
Train loss on 150 batch: 0.088240
Train loss on 200 batch: 0.057719
: Epoch: 263 | Training Loss: 0.052933 | Val. Loss: 0.228666 | Val. Kappa Score: 0.9011 | LR: 0.000522 | Estimated time: 53.44
Train loss on 50 batch: 0.071801
Train loss on 100 batch: 0.054915
Train loss on 150 batch: 0.048067
Train loss on 200 batch: 0.051479
: Epoch: 264 | Training Loss: 0.057335 | Val. Loss: 0.332255 | Val. Kappa Score: 0.9011 | LR: 0.000567 | Estimated time: 53.46
Train loss on 50 batch: 0.042864
Train loss on 100 batch: 0.047000
Train loss on 150 batch: 0.053976
Train loss on 200 batch: 0.052174
: Epoch: 265 | Training Loss: 0.048071 | Val. Loss: 0.314351 | Val. Kappa Score: 0.9010 | LR: 0.000611 | Estimated time: 53.43
Train loss on 50 batch: 0.032943
Train loss on 100 batch: 0.033601
Train loss on 150 batch: 0.048010
Train loss on 200 batch: 0.035326
: Epoch: 266 | Training Loss: 0.039429 | Val. Loss: 0.297441 | Val. Kappa Score: 0.9010 | LR: 0.000655 | Estimated time: 53.49
Train loss on 50 batch: 0.061474
Train loss on 100 batch: 0.066438
Train loss on 150 batch: 0.045398
Train loss on 200 batch: 0.053181
: Epoch: 267 | Training Loss: 0.056536 | Val. Loss: 0.292566 | Val. Kappa Score: 0.9010 | LR: 0.000697 | Estimated time: 53.45
Train loss on 50 batch: 0.044528
Train loss on 100 batch: 0.045118
Train loss on 150 batch: 0.050514
Train loss on 200 batch: 0.068784
: Epoch: 268 | Training Loss: 0.046037 | Val. Loss: 0.307973 | Val. Kappa Score: 0.9010 | LR: 0.000737 | Estimated time: 53.43
Train loss on 50 batch: 0.066216
Train loss on 100 batch: 0.048416
Train loss on 150 batch: 0.039101
Train loss on 200 batch: 0.039140
: Epoch: 269 | Training Loss: 0.050221 | Val. Loss: 0.293467 | Val. Kappa Score: 0.9010 | LR: 0.000775 | Estimated time: 53.46
Train loss on 50 batch: 0.034410
Train loss on 100 batch: 0.053558
Train loss on 150 batch: 0.055763
Train loss on 200 batch: 0.050781
: Epoch: 270 | Training Loss: 0.046620 | Val. Loss: 0.298135 | Val. Kappa Score: 0.9010 | LR: 0.000812 | Estimated time: 53.41
Train loss on 50 batch: 0.032740
Train loss on 100 batch: 0.027908
Train loss on 150 batch: 0.048967
Train loss on 200 batch: 0.044262
: Epoch: 271 | Training Loss: 0.046399 | Val. Loss: 0.288249 | Val. Kappa Score: 0.9011 | LR: 0.000846 | Estimated time: 53.45
Train loss on 50 batch: 0.044424
Train loss on 100 batch: 0.032637
Train loss on 150 batch: 0.036739
Train loss on 200 batch: 0.046028
: Epoch: 272 | Training Loss: 0.052006 | Val. Loss: 0.299337 | Val. Kappa Score: 0.9010 | LR: 0.000877 | Estimated time: 53.46
Train loss on 50 batch: 0.098650
Train loss on 100 batch: 0.150962
Train loss on 150 batch: 0.117816
Train loss on 200 batch: 0.088869
: Epoch: 273 | Training Loss: 0.102671 | Val. Loss: 0.360527 | Val. Kappa Score: 0.9009 | LR: 0.000905 | Estimated time: 53.46
Train loss on 50 batch: 0.074667
Train loss on 100 batch: 0.077622
Train loss on 150 batch: 0.073892
Train loss on 200 batch: 0.095068
: Epoch: 274 | Training Loss: 0.079177 | Val. Loss: 0.303668 | Val. Kappa Score: 0.9010 | LR: 0.000929 | Estimated time: 53.49
Train loss on 50 batch: 0.057727
Train loss on 100 batch: 0.047773
Train loss on 150 batch: 0.038308
Train loss on 200 batch: 0.053774
: Epoch: 275 | Training Loss: 0.044495 | Val. Loss: 0.277146 | Val. Kappa Score: 0.9010 | LR: 0.000950 | Estimated time: 53.43
Train loss on 50 batch: 0.037496
Train loss on 100 batch: 0.044120
Train loss on 150 batch: 0.056225
Train loss on 200 batch: 0.061917
: Epoch: 276 | Training Loss: 0.052707 | Val. Loss: 0.308583 | Val. Kappa Score: 0.9009 | LR: 0.000968 | Estimated time: 53.46
Train loss on 50 batch: 0.051668
Train loss on 100 batch: 0.062402
Train loss on 150 batch: 0.050682
Train loss on 200 batch: 0.054916
: Epoch: 277 | Training Loss: 0.049616 | Val. Loss: 0.254804 | Val. Kappa Score: 0.9009 | LR: 0.000982 | Estimated time: 53.49
Train loss on 50 batch: 0.045048
Train loss on 100 batch: 0.065291
Train loss on 150 batch: 0.067486
Train loss on 200 batch: 0.118617
: Epoch: 278 | Training Loss: 0.094995 | Val. Loss: 0.384623 | Val. Kappa Score: 0.9009 | LR: 0.000992 | Estimated time: 53.48
Train loss on 50 batch: 0.121608
Train loss on 100 batch: 0.106229
Train loss on 150 batch: 0.077192
Train loss on 200 batch: 0.084559
: Epoch: 279 | Training Loss: 0.093616 | Val. Loss: 0.367509 | Val. Kappa Score: 0.9007 | LR: 0.000998 | Estimated time: 53.40
Train loss on 50 batch: 0.075670
Train loss on 100 batch: 0.081341
Train loss on 150 batch: 0.110138
Train loss on 200 batch: 0.138018
: Epoch: 280 | Training Loss: 0.103795 | Val. Loss: 0.670448 | Val. Kappa Score: 0.9003 | LR: 0.001000 | Estimated time: 53.53
Train loss on 50 batch: 0.138808
Train loss on 100 batch: 0.088850
Train loss on 150 batch: 0.091396
Train loss on 200 batch: 0.046862
: Epoch: 281 | Training Loss: 0.085539 | Val. Loss: 0.298367 | Val. Kappa Score: 0.9003 | LR: 0.000998 | Estimated time: 53.46
Train loss on 50 batch: 0.055020
Train loss on 100 batch: 0.078036
Train loss on 150 batch: 0.057112
Train loss on 200 batch: 0.069956
: Epoch: 282 | Training Loss: 0.072056 | Val. Loss: 0.315624 | Val. Kappa Score: 0.9003 | LR: 0.000992 | Estimated time: 53.46
Train loss on 50 batch: 0.078241
Train loss on 100 batch: 0.111884
Train loss on 150 batch: 0.135043
Train loss on 200 batch: 0.153624
: Epoch: 283 | Training Loss: 0.122753 | Val. Loss: 0.368291 | Val. Kappa Score: 0.9002 | LR: 0.000982 | Estimated time: 53.42
Train loss on 50 batch: 0.084749
Train loss on 100 batch: 0.080077
Train loss on 150 batch: 0.074365
Train loss on 200 batch: 0.066481
: Epoch: 284 | Training Loss: 0.074689 | Val. Loss: 0.287191 | Val. Kappa Score: 0.9003 | LR: 0.000968 | Estimated time: 53.46
Train loss on 50 batch: 0.069014
Train loss on 100 batch: 0.066932
Train loss on 150 batch: 0.077753
Train loss on 200 batch: 0.120870
: Epoch: 285 | Training Loss: 0.098620 | Val. Loss: 4.756202 | Val. Kappa Score: 0.8974 | LR: 0.000950 | Estimated time: 53.43
Train loss on 50 batch: 0.177531
Train loss on 100 batch: 0.080947
Train loss on 150 batch: 0.104372
Train loss on 200 batch: 0.117470
: Epoch: 286 | Training Loss: 0.182687 | Val. Loss: 0.455696 | Val. Kappa Score: 0.8972 | LR: 0.000929 | Estimated time: 53.52
Train loss on 50 batch: 0.133488
Train loss on 100 batch: 0.095277
Train loss on 150 batch: 0.071304
Train loss on 200 batch: 0.079923
: Epoch: 287 | Training Loss: 0.087274 | Val. Loss: 0.284395 | Val. Kappa Score: 0.8971 | LR: 0.000905 | Estimated time: 53.48
Train loss on 50 batch: 0.052208
Train loss on 100 batch: 0.053232
Train loss on 150 batch: 0.041757
Train loss on 200 batch: 0.055535
: Epoch: 288 | Training Loss: 0.050032 | Val. Loss: 0.304789 | Val. Kappa Score: 0.8972 | LR: 0.000877 | Estimated time: 53.52
Train loss on 50 batch: 0.040417
Train loss on 100 batch: 0.052223
Train loss on 150 batch: 0.053309
Train loss on 200 batch: 0.049585
: Epoch: 289 | Training Loss: 0.058074 | Val. Loss: 0.286457 | Val. Kappa Score: 0.8972 | LR: 0.000846 | Estimated time: 53.39
Train loss on 50 batch: 0.051698
Train loss on 100 batch: 0.050075
Train loss on 150 batch: 0.057052
Train loss on 200 batch: 0.059197
: Epoch: 290 | Training Loss: 0.054206 | Val. Loss: 0.298612 | Val. Kappa Score: 0.8972 | LR: 0.000812 | Estimated time: 53.49
Train loss on 50 batch: 0.039713
Train loss on 100 batch: 0.034986
Train loss on 150 batch: 0.051007
Train loss on 200 batch: 0.034141
: Epoch: 291 | Training Loss: 0.043123 | Val. Loss: 0.261043 | Val. Kappa Score: 0.8972 | LR: 0.000775 | Estimated time: 53.50
Train loss on 50 batch: 0.035350
Train loss on 100 batch: 0.037133
Train loss on 150 batch: 0.035598
Train loss on 200 batch: 0.033891
: Epoch: 292 | Training Loss: 0.034206 | Val. Loss: 0.247429 | Val. Kappa Score: 0.8973 | LR: 0.000737 | Estimated time: 53.44
Train loss on 50 batch: 0.028536
Train loss on 100 batch: 0.031925
Train loss on 150 batch: 0.030450
Train loss on 200 batch: 0.027824
: Epoch: 293 | Training Loss: 0.032902 | Val. Loss: 0.292408 | Val. Kappa Score: 0.8973 | LR: 0.000697 | Estimated time: 53.46
Train loss on 50 batch: 0.023217
Train loss on 100 batch: 0.034312
Train loss on 150 batch: 0.031876
Train loss on 200 batch: 0.030199
: Epoch: 294 | Training Loss: 0.032965 | Val. Loss: 0.247491 | Val. Kappa Score: 0.8973 | LR: 0.000655 | Estimated time: 53.51
Train loss on 50 batch: 0.039100
Train loss on 100 batch: 0.033854
Train loss on 150 batch: 0.020848
Train loss on 200 batch: 0.028534
: Epoch: 295 | Training Loss: 0.029506 | Val. Loss: 0.239783 | Val. Kappa Score: 0.8973 | LR: 0.000611 | Estimated time: 53.51
Train loss on 50 batch: 0.036772
Train loss on 100 batch: 0.035549
Train loss on 150 batch: 0.028228
Train loss on 200 batch: 0.024956
: Epoch: 296 | Training Loss: 0.029816 | Val. Loss: 0.232759 | Val. Kappa Score: 0.8974 | LR: 0.000567 | Estimated time: 53.44
Train loss on 50 batch: 0.022752
Train loss on 100 batch: 0.028510
Train loss on 150 batch: 0.031695
Train loss on 200 batch: 0.038540
: Epoch: 297 | Training Loss: 0.033524 | Val. Loss: 0.244698 | Val. Kappa Score: 0.8975 | LR: 0.000522 | Estimated time: 53.47
Train loss on 50 batch: 0.030682
Train loss on 100 batch: 0.023962
Train loss on 150 batch: 0.025433
Train loss on 200 batch: 0.038345
: Epoch: 298 | Training Loss: 0.029264 | Val. Loss: 0.263369 | Val. Kappa Score: 0.8976 | LR: 0.000478 | Estimated time: 53.41
Train loss on 50 batch: 0.021541
Train loss on 100 batch: 0.026342
Train loss on 150 batch: 0.024333
Train loss on 200 batch: 0.025868
: Epoch: 299 | Training Loss: 0.025215 | Val. Loss: 0.259906 | Val. Kappa Score: 0.8976 | LR: 0.000433 | Estimated time: 53.43
Train loss on 50 batch: 0.026054
Train loss on 100 batch: 0.027364
Train loss on 150 batch: 0.027477
Train loss on 200 batch: 0.028505
: Epoch: 300 | Training Loss: 0.022937 | Val. Loss: 0.239841 | Val. Kappa Score: 0.8976 | LR: 0.000389 | Estimated time: 53.48
Train loss on 50 batch: 0.019459
Train loss on 100 batch: 0.020184
Train loss on 150 batch: 0.027441
Train loss on 200 batch: 0.024366
: Epoch: 301 | Training Loss: 0.025735 | Val. Loss: 0.247050 | Val. Kappa Score: 0.8976 | LR: 0.000345 | Estimated time: 53.45
Train loss on 50 batch: 0.026353
Train loss on 100 batch: 0.026939
Train loss on 150 batch: 0.027723
Train loss on 200 batch: 0.022488
: Epoch: 302 | Training Loss: 0.024112 | Val. Loss: 0.255333 | Val. Kappa Score: 0.8977 | LR: 0.000303 | Estimated time: 53.44
Train loss on 50 batch: 0.020324
Train loss on 100 batch: 0.029325
Train loss on 150 batch: 0.024303
Train loss on 200 batch: 0.024849
: Epoch: 303 | Training Loss: 0.023237 | Val. Loss: 0.245343 | Val. Kappa Score: 0.8977 | LR: 0.000263 | Estimated time: 53.47
Train loss on 50 batch: 0.014600
Train loss on 100 batch: 0.024466
Train loss on 150 batch: 0.023383
Train loss on 200 batch: 0.029586
: Epoch: 304 | Training Loss: 0.020182 | Val. Loss: 0.248131 | Val. Kappa Score: 0.8977 | LR: 0.000225 | Estimated time: 53.44
Train loss on 50 batch: 0.019196
Train loss on 100 batch: 0.019941
Train loss on 150 batch: 0.024954
Train loss on 200 batch: 0.019079
: Epoch: 305 | Training Loss: 0.018266 | Val. Loss: 0.246301 | Val. Kappa Score: 0.8977 | LR: 0.000188 | Estimated time: 53.50
Train loss on 50 batch: 0.019673
Train loss on 100 batch: 0.022444
Train loss on 150 batch: 0.018166
Train loss on 200 batch: 0.015811
: Epoch: 306 | Training Loss: 0.018144 | Val. Loss: 0.243201 | Val. Kappa Score: 0.8977 | LR: 0.000154 | Estimated time: 53.42
Train loss on 50 batch: 0.017482
Train loss on 100 batch: 0.017089
Train loss on 150 batch: 0.015989
Train loss on 200 batch: 0.021649
: Epoch: 307 | Training Loss: 0.015330 | Val. Loss: 0.241488 | Val. Kappa Score: 0.8978 | LR: 0.000123 | Estimated time: 53.47
Train loss on 50 batch: 0.016759
Train loss on 100 batch: 0.014772
Train loss on 150 batch: 0.016773
Train loss on 200 batch: 0.023266
: Epoch: 308 | Training Loss: 0.019199 | Val. Loss: 0.242000 | Val. Kappa Score: 0.8979 | LR: 0.000095 | Estimated time: 53.45
Train loss on 50 batch: 0.025894
Train loss on 100 batch: 0.014321
Train loss on 150 batch: 0.017116
Train loss on 200 batch: 0.017226
: Epoch: 309 | Training Loss: 0.016301 | Val. Loss: 0.243803 | Val. Kappa Score: 0.8979 | LR: 0.000071 | Estimated time: 53.48
Train loss on 50 batch: 0.020558
Train loss on 100 batch: 0.014113
Train loss on 150 batch: 0.015284
Train loss on 200 batch: 0.013911
: Epoch: 310 | Training Loss: 0.014068 | Val. Loss: 0.242542 | Val. Kappa Score: 0.8979 | LR: 0.000050 | Estimated time: 53.46
Train loss on 50 batch: 0.012222
Train loss on 100 batch: 0.022303
Train loss on 150 batch: 0.014823
Train loss on 200 batch: 0.015172
: Epoch: 311 | Training Loss: 0.016565 | Val. Loss: 0.243529 | Val. Kappa Score: 0.8980 | LR: 0.000032 | Estimated time: 53.40
Train loss on 50 batch: 0.017349
Train loss on 100 batch: 0.014405
Train loss on 150 batch: 0.016106
Train loss on 200 batch: 0.016282
: Epoch: 312 | Training Loss: 0.015331 | Val. Loss: 0.244236 | Val. Kappa Score: 0.8981 | LR: 0.000018 | Estimated time: 53.42
Train loss on 50 batch: 0.021292
Train loss on 100 batch: 0.014346
Train loss on 150 batch: 0.013934
Train loss on 200 batch: 0.017702
: Epoch: 313 | Training Loss: 0.017881 | Val. Loss: 0.246466 | Val. Kappa Score: 0.8981 | LR: 0.000008 | Estimated time: 53.49
Train loss on 50 batch: 0.018091
Train loss on 100 batch: 0.017619
Train loss on 150 batch: 0.013306
Train loss on 200 batch: 0.016620
: Epoch: 314 | Training Loss: 0.015934 | Val. Loss: 0.246266 | Val. Kappa Score: 0.8982 | LR: 0.000002 | Estimated time: 53.48
Train loss on 50 batch: 0.017918
Train loss on 100 batch: 0.017567
Train loss on 150 batch: 0.013980
Train loss on 200 batch: 0.013188
: Epoch: 315 | Training Loss: 0.017897 | Val. Loss: 0.245804 | Val. Kappa Score: 0.8982 | LR: 0.000000 | Estimated time: 53.48
Train loss on 50 batch: 0.018646
Train loss on 100 batch: 0.014517
Train loss on 150 batch: 0.013585
Train loss on 200 batch: 0.014363
: Epoch: 316 | Training Loss: 0.015254 | Val. Loss: 0.245834 | Val. Kappa Score: 0.8982 | LR: 0.000002 | Estimated time: 53.50
Train loss on 50 batch: 0.019155
Train loss on 100 batch: 0.011352
Train loss on 150 batch: 0.016287
Train loss on 200 batch: 0.016274
: Epoch: 317 | Training Loss: 0.017785 | Val. Loss: 0.245116 | Val. Kappa Score: 0.8983 | LR: 0.000008 | Estimated time: 53.45
Train loss on 50 batch: 0.017118
Train loss on 100 batch: 0.018174
Train loss on 150 batch: 0.014492
Train loss on 200 batch: 0.016026
: Epoch: 318 | Training Loss: 0.014351 | Val. Loss: 0.245414 | Val. Kappa Score: 0.8983 | LR: 0.000018 | Estimated time: 53.43
Train loss on 50 batch: 0.011904
Train loss on 100 batch: 0.016151
Train loss on 150 batch: 0.015149
Train loss on 200 batch: 0.021638
: Epoch: 319 | Training Loss: 0.016212 | Val. Loss: 0.245787 | Val. Kappa Score: 0.8983 | LR: 0.000032 | Estimated time: 53.49
Train loss on 50 batch: 0.017689
Train loss on 100 batch: 0.019300
Train loss on 150 batch: 0.020540
Train loss on 200 batch: 0.013132
: Epoch: 320 | Training Loss: 0.017217 | Val. Loss: 0.247605 | Val. Kappa Score: 0.8984 | LR: 0.000050 | Estimated time: 53.42
Train loss on 50 batch: 0.021675
Train loss on 100 batch: 0.012486
Train loss on 150 batch: 0.012942
Train loss on 200 batch: 0.014947
: Epoch: 321 | Training Loss: 0.017986 | Val. Loss: 0.248189 | Val. Kappa Score: 0.8984 | LR: 0.000071 | Estimated time: 53.45
Train loss on 50 batch: 0.013832
Train loss on 100 batch: 0.017032
Train loss on 150 batch: 0.018927
Train loss on 200 batch: 0.017008
: Epoch: 322 | Training Loss: 0.015875 | Val. Loss: 0.247700 | Val. Kappa Score: 0.8984 | LR: 0.000095 | Estimated time: 53.48
Train loss on 50 batch: 0.013713
Train loss on 100 batch: 0.022214
Train loss on 150 batch: 0.016362
Train loss on 200 batch: 0.012076
: Epoch: 323 | Training Loss: 0.014470 | Val. Loss: 0.244507 | Val. Kappa Score: 0.8985 | LR: 0.000123 | Estimated time: 53.43
Train loss on 50 batch: 0.020291
Train loss on 100 batch: 0.018899
Train loss on 150 batch: 0.021805
Train loss on 200 batch: 0.015332
: Epoch: 324 | Training Loss: 0.018246 | Val. Loss: 0.253599 | Val. Kappa Score: 0.8985 | LR: 0.000154 | Estimated time: 53.52
Train loss on 50 batch: 0.017229
Train loss on 100 batch: 0.011716
Train loss on 150 batch: 0.018276
Train loss on 200 batch: 0.019875
: Epoch: 325 | Training Loss: 0.015136 | Val. Loss: 0.257601 | Val. Kappa Score: 0.8985 | LR: 0.000188 | Estimated time: 53.57
Train loss on 50 batch: 0.027448
Train loss on 100 batch: 0.015121
Train loss on 150 batch: 0.015970
Train loss on 200 batch: 0.013532
: Epoch: 326 | Training Loss: 0.018105 | Val. Loss: 0.252792 | Val. Kappa Score: 0.8985 | LR: 0.000225 | Estimated time: 53.42
Train loss on 50 batch: 0.018070
Train loss on 100 batch: 0.017784
Train loss on 150 batch: 0.017458
Train loss on 200 batch: 0.020030
: Epoch: 327 | Training Loss: 0.019535 | Val. Loss: 0.238594 | Val. Kappa Score: 0.8986 | LR: 0.000263 | Estimated time: 53.44
Train loss on 50 batch: 0.017230
Train loss on 100 batch: 0.023078
Train loss on 150 batch: 0.018307
Train loss on 200 batch: 0.017080
: Epoch: 328 | Training Loss: 0.024433 | Val. Loss: 0.255865 | Val. Kappa Score: 0.8986 | LR: 0.000303 | Estimated time: 53.47
Train loss on 50 batch: 0.020886
Train loss on 100 batch: 0.022846
Train loss on 150 batch: 0.025567
Train loss on 200 batch: 0.021420
: Epoch: 329 | Training Loss: 0.024079 | Val. Loss: 0.271641 | Val. Kappa Score: 0.8985 | LR: 0.000345 | Estimated time: 53.47
Train loss on 50 batch: 0.023903
Train loss on 100 batch: 0.018071
Train loss on 150 batch: 0.029642
Train loss on 200 batch: 0.023925
: Epoch: 330 | Training Loss: 0.022226 | Val. Loss: 0.291682 | Val. Kappa Score: 0.8986 | LR: 0.000389 | Estimated time: 53.49
Train loss on 50 batch: 0.016853
Train loss on 100 batch: 0.032398
Train loss on 150 batch: 0.020133
Train loss on 200 batch: 0.026811
: Epoch: 331 | Training Loss: 0.020639 | Val. Loss: 0.274509 | Val. Kappa Score: 0.8986 | LR: 0.000433 | Estimated time: 53.54
Train loss on 50 batch: 0.024809
Train loss on 100 batch: 0.030331
Train loss on 150 batch: 0.026485
Train loss on 200 batch: 0.031343
: Epoch: 332 | Training Loss: 0.038702 | Val. Loss: 0.322934 | Val. Kappa Score: 0.8986 | LR: 0.000478 | Estimated time: 53.50
Train loss on 50 batch: 0.031618
Train loss on 100 batch: 0.046983
Train loss on 150 batch: 0.044346
Train loss on 200 batch: 0.034194
: Epoch: 333 | Training Loss: 0.038118 | Val. Loss: 0.316313 | Val. Kappa Score: 0.8986 | LR: 0.000522 | Estimated time: 53.51
Train loss on 50 batch: 0.038650
Train loss on 100 batch: 0.041885
Train loss on 150 batch: 0.045786
Train loss on 200 batch: 0.057257
: Epoch: 334 | Training Loss: 0.047388 | Val. Loss: 0.257505 | Val. Kappa Score: 0.8986 | LR: 0.000567 | Estimated time: 53.45
Train loss on 50 batch: 0.042407
Train loss on 100 batch: 0.052921
Train loss on 150 batch: 0.034913
Train loss on 200 batch: 0.039334
: Epoch: 335 | Training Loss: 0.044879 | Val. Loss: 0.284966 | Val. Kappa Score: 0.8986 | LR: 0.000611 | Estimated time: 53.42
Train loss on 50 batch: 0.031369
Train loss on 100 batch: 0.047204
Train loss on 150 batch: 0.027589
Train loss on 200 batch: 0.039914
: Epoch: 336 | Training Loss: 0.031987 | Val. Loss: 0.263165 | Val. Kappa Score: 0.8986 | LR: 0.000655 | Estimated time: 53.49
Train loss on 50 batch: 0.033288
Train loss on 100 batch: 0.038596
Train loss on 150 batch: 0.042527
Train loss on 200 batch: 0.038961
: Epoch: 337 | Training Loss: 0.037360 | Val. Loss: 0.248327 | Val. Kappa Score: 0.8987 | LR: 0.000697 | Estimated time: 53.53
Train loss on 50 batch: 0.027206
Train loss on 100 batch: 0.037494
Train loss on 150 batch: 0.037885
Train loss on 200 batch: 0.034092
: Epoch: 338 | Training Loss: 0.034966 | Val. Loss: 0.248196 | Val. Kappa Score: 0.8987 | LR: 0.000737 | Estimated time: 53.49
Train loss on 50 batch: 0.036956
Train loss on 100 batch: 0.024810
Train loss on 150 batch: 0.040501
Train loss on 200 batch: 0.051639
: Epoch: 339 | Training Loss: 0.040043 | Val. Loss: 0.324942 | Val. Kappa Score: 0.8987 | LR: 0.000775 | Estimated time: 53.44
Train loss on 50 batch: 0.058319
Train loss on 100 batch: 0.031621
Train loss on 150 batch: 0.054759
Train loss on 200 batch: 0.094885
: Epoch: 340 | Training Loss: 0.062654 | Val. Loss: 0.372749 | Val. Kappa Score: 0.8986 | LR: 0.000812 | Estimated time: 53.46
Train loss on 50 batch: 0.094921
Train loss on 100 batch: 0.110204
Train loss on 150 batch: 0.089392
Train loss on 200 batch: 0.095704
: Epoch: 341 | Training Loss: 0.090539 | Val. Loss: 0.317051 | Val. Kappa Score: 0.8986 | LR: 0.000846 | Estimated time: 53.44
Train loss on 50 batch: 0.064759
Train loss on 100 batch: 0.072232
Train loss on 150 batch: 0.060912
Train loss on 200 batch: 0.050596
: Epoch: 342 | Training Loss: 0.064893 | Val. Loss: 0.355614 | Val. Kappa Score: 0.8986 | LR: 0.000877 | Estimated time: 53.46
Train loss on 50 batch: 0.045245
Train loss on 100 batch: 0.043229
Train loss on 150 batch: 0.051249
Train loss on 200 batch: 0.059113
: Epoch: 343 | Training Loss: 0.063024 | Val. Loss: 0.332346 | Val. Kappa Score: 0.8985 | LR: 0.000905 | Estimated time: 53.45
Train loss on 50 batch: 0.102315
Train loss on 100 batch: 0.115789
Train loss on 150 batch: 0.126122
Train loss on 200 batch: 0.097751
: Epoch: 344 | Training Loss: 0.103703 | Val. Loss: 0.447907 | Val. Kappa Score: 0.8984 | LR: 0.000929 | Estimated time: 53.45
Train loss on 50 batch: 0.080505
Train loss on 100 batch: 0.071235
Train loss on 150 batch: 0.064922
Train loss on 200 batch: 0.063872
: Epoch: 345 | Training Loss: 0.071270 | Val. Loss: 0.313958 | Val. Kappa Score: 0.8984 | LR: 0.000950 | Estimated time: 53.41
Train loss on 50 batch: 0.046388
Train loss on 100 batch: 0.069882
Train loss on 150 batch: 0.055803
Train loss on 200 batch: 0.042722
: Epoch: 346 | Training Loss: 0.054519 | Val. Loss: 0.249858 | Val. Kappa Score: 0.8984 | LR: 0.000968 | Estimated time: 53.54
Train loss on 50 batch: 0.044700
Train loss on 100 batch: 0.034312
Train loss on 150 batch: 0.056642
Train loss on 200 batch: 0.068398
: Epoch: 347 | Training Loss: 0.065430 | Val. Loss: 0.442089 | Val. Kappa Score: 0.8983 | LR: 0.000982 | Estimated time: 53.46
Train loss on 50 batch: 0.116867
Train loss on 100 batch: 0.074279
Train loss on 150 batch: 0.057743
Train loss on 200 batch: 0.061234
: Epoch: 348 | Training Loss: 0.077426 | Val. Loss: 0.337943 | Val. Kappa Score: 0.8982 | LR: 0.000992 | Estimated time: 53.46
Train loss on 50 batch: 0.114308
Train loss on 100 batch: 0.130091
Train loss on 150 batch: 0.123882
Train loss on 200 batch: 0.082035
: Epoch: 349 | Training Loss: 0.103846 | Val. Loss: 0.312070 | Val. Kappa Score: 0.8982 | LR: 0.000998 | Estimated time: 53.46
Train loss on 50 batch: 0.120070
Train loss on 100 batch: 0.095794
Train loss on 150 batch: 0.071340
Train loss on 200 batch: 0.075002
: Epoch: 350 | Training Loss: 0.080002 | Val. Loss: 0.259730 | Val. Kappa Score: 0.8983 | LR: 0.001000 | Estimated time: 53.42
Train loss on 50 batch: 0.050142
Train loss on 100 batch: 0.056687
Train loss on 150 batch: 0.039003
Train loss on 200 batch: 0.073744
: Epoch: 351 | Training Loss: 0.054056 | Val. Loss: 0.286081 | Val. Kappa Score: 0.8983 | LR: 0.000998 | Estimated time: 53.52
Train loss on 50 batch: 0.056604
Train loss on 100 batch: 0.052689
Train loss on 150 batch: 0.043136
Train loss on 200 batch: 0.084520
: Epoch: 352 | Training Loss: 0.082271 | Val. Loss: 0.331719 | Val. Kappa Score: 0.8983 | LR: 0.000992 | Estimated time: 53.45
Train loss on 50 batch: 0.063662
Train loss on 100 batch: 0.082813
Train loss on 150 batch: 0.066101
Train loss on 200 batch: 0.050612
: Epoch: 353 | Training Loss: 0.082221 | Val. Loss: 0.389955 | Val. Kappa Score: 0.8982 | LR: 0.000982 | Estimated time: 53.44
Train loss on 50 batch: 0.054773
Train loss on 100 batch: 0.043541
Train loss on 150 batch: 0.049751
Train loss on 200 batch: 0.042597
: Epoch: 354 | Training Loss: 0.042411 | Val. Loss: 0.279821 | Val. Kappa Score: 0.8982 | LR: 0.000968 | Estimated time: 53.50
Train loss on 50 batch: 0.039773
Train loss on 100 batch: 0.035154
Train loss on 150 batch: 0.056661
Train loss on 200 batch: 0.080304
: Epoch: 355 | Training Loss: 0.048159 | Val. Loss: 0.276213 | Val. Kappa Score: 0.8983 | LR: 0.000950 | Estimated time: 53.42
Train loss on 50 batch: 0.046913
Train loss on 100 batch: 0.035632
Train loss on 150 batch: 0.043700
Train loss on 200 batch: 0.039926
: Epoch: 356 | Training Loss: 0.039921 | Val. Loss: 0.258491 | Val. Kappa Score: 0.8983 | LR: 0.000929 | Estimated time: 53.46
Train loss on 50 batch: 0.035565
Train loss on 100 batch: 0.035573
Train loss on 150 batch: 0.052234
Train loss on 200 batch: 0.043769
: Epoch: 357 | Training Loss: 0.039875 | Val. Loss: 0.293837 | Val. Kappa Score: 0.8983 | LR: 0.000905 | Estimated time: 53.54
Train loss on 50 batch: 0.049272
Train loss on 100 batch: 0.043841
Train loss on 150 batch: 0.043100
Train loss on 200 batch: 0.062479
: Epoch: 358 | Training Loss: 0.057974 | Val. Loss: 0.274824 | Val. Kappa Score: 0.8983 | LR: 0.000877 | Estimated time: 53.50
Train loss on 50 batch: 0.063007
Train loss on 100 batch: 0.040857
Train loss on 150 batch: 0.057643
Train loss on 200 batch: 0.060507
: Epoch: 359 | Training Loss: 0.052189 | Val. Loss: 0.263850 | Val. Kappa Score: 0.8983 | LR: 0.000846 | Estimated time: 53.55
Train loss on 50 batch: 0.051278
Train loss on 100 batch: 0.050104
Train loss on 150 batch: 0.039418
Train loss on 200 batch: 0.048816
: Epoch: 360 | Training Loss: 0.049605 | Val. Loss: 0.248595 | Val. Kappa Score: 0.8984 | LR: 0.000812 | Estimated time: 53.44
Train loss on 50 batch: 0.036034
Train loss on 100 batch: 0.043637
Train loss on 150 batch: 0.024263
Train loss on 200 batch: 0.030824
: Epoch: 361 | Training Loss: 0.032484 | Val. Loss: 0.248900 | Val. Kappa Score: 0.8984 | LR: 0.000775 | Estimated time: 53.52
Train loss on 50 batch: 0.018923
Train loss on 100 batch: 0.035713
Train loss on 150 batch: 0.034098
Train loss on 200 batch: 0.037852
: Epoch: 362 | Training Loss: 0.034444 | Val. Loss: 0.237279 | Val. Kappa Score: 0.8984 | LR: 0.000737 | Estimated time: 53.61
Train loss on 50 batch: 0.030084
Train loss on 100 batch: 0.024959
Train loss on 150 batch: 0.028620
Train loss on 200 batch: 0.039620
: Epoch: 363 | Training Loss: 0.030357 | Val. Loss: 0.281106 | Val. Kappa Score: 0.8985 | LR: 0.000697 | Estimated time: 53.55
Train loss on 50 batch: 0.024958
Train loss on 100 batch: 0.039308
Train loss on 150 batch: 0.027557
Train loss on 200 batch: 0.029060
: Epoch: 364 | Training Loss: 0.031004 | Val. Loss: 0.265600 | Val. Kappa Score: 0.8985 | LR: 0.000655 | Estimated time: 53.47
Train loss on 50 batch: 0.031195
Train loss on 100 batch: 0.031753
Train loss on 150 batch: 0.024347
Train loss on 200 batch: 0.031323
: Epoch: 365 | Training Loss: 0.027269 | Val. Loss: 0.260070 | Val. Kappa Score: 0.8985 | LR: 0.000611 | Estimated time: 53.48
Train loss on 50 batch: 0.019601
Train loss on 100 batch: 0.026329
Train loss on 150 batch: 0.027024
Train loss on 200 batch: 0.029821
: Epoch: 366 | Training Loss: 0.023511 | Val. Loss: 0.252857 | Val. Kappa Score: 0.8986 | LR: 0.000567 | Estimated time: 53.46
Train loss on 50 batch: 0.019941
Train loss on 100 batch: 0.023218
Train loss on 150 batch: 0.030382
Train loss on 200 batch: 0.037259
: Epoch: 367 | Training Loss: 0.028201 | Val. Loss: 0.253741 | Val. Kappa Score: 0.8986 | LR: 0.000522 | Estimated time: 53.49
Train loss on 50 batch: 0.023457
Train loss on 100 batch: 0.029883
Train loss on 150 batch: 0.020147
Train loss on 200 batch: 0.025368
: Epoch: 368 | Training Loss: 0.025254 | Val. Loss: 0.243864 | Val. Kappa Score: 0.8986 | LR: 0.000478 | Estimated time: 53.41
Train loss on 50 batch: 0.024162
Train loss on 100 batch: 0.025516
Train loss on 150 batch: 0.025774
Train loss on 200 batch: 0.024345
: Epoch: 369 | Training Loss: 0.026385 | Val. Loss: 0.279325 | Val. Kappa Score: 0.8986 | LR: 0.000433 | Estimated time: 53.44
Train loss on 50 batch: 0.024797
Train loss on 100 batch: 0.032261
Train loss on 150 batch: 0.025117
Train loss on 200 batch: 0.021767
: Epoch: 370 | Training Loss: 0.034463 | Val. Loss: 0.261599 | Val. Kappa Score: 0.8986 | LR: 0.000389 | Estimated time: 53.46
Train loss on 50 batch: 0.021957
Train loss on 100 batch: 0.020414
Train loss on 150 batch: 0.024672
Train loss on 200 batch: 0.028588
: Epoch: 371 | Training Loss: 0.021328 | Val. Loss: 0.247441 | Val. Kappa Score: 0.8986 | LR: 0.000345 | Estimated time: 53.45
Train loss on 50 batch: 0.021731
Train loss on 100 batch: 0.018066
Train loss on 150 batch: 0.021390
Train loss on 200 batch: 0.027086
: Epoch: 372 | Training Loss: 0.022028 | Val. Loss: 0.232093 | Val. Kappa Score: 0.8987 | LR: 0.000303 | Estimated time: 53.40
Train loss on 50 batch: 0.019895
Train loss on 100 batch: 0.024307
Train loss on 150 batch: 0.020807
Train loss on 200 batch: 0.018113
: Epoch: 373 | Training Loss: 0.022600 | Val. Loss: 0.237942 | Val. Kappa Score: 0.8987 | LR: 0.000263 | Estimated time: 53.45
Train loss on 50 batch: 0.023764
Train loss on 100 batch: 0.018744
Train loss on 150 batch: 0.019752
Train loss on 200 batch: 0.021299
: Epoch: 374 | Training Loss: 0.021951 | Val. Loss: 0.233990 | Val. Kappa Score: 0.8988 | LR: 0.000225 | Estimated time: 53.44
Train loss on 50 batch: 0.023706
Train loss on 100 batch: 0.022000
Train loss on 150 batch: 0.015293
Train loss on 200 batch: 0.018114
: Epoch: 375 | Training Loss: 0.017358 | Val. Loss: 0.247269 | Val. Kappa Score: 0.8988 | LR: 0.000188 | Estimated time: 53.43
Train loss on 50 batch: 0.016065
Train loss on 100 batch: 0.024779
Train loss on 150 batch: 0.019816
Train loss on 200 batch: 0.016609
: Epoch: 376 | Training Loss: 0.019292 | Val. Loss: 0.242530 | Val. Kappa Score: 0.8988 | LR: 0.000154 | Estimated time: 53.45
Train loss on 50 batch: 0.017723
Train loss on 100 batch: 0.014219
Train loss on 150 batch: 0.020698
Train loss on 200 batch: 0.012133
: Epoch: 377 | Training Loss: 0.016935 | Val. Loss: 0.238364 | Val. Kappa Score: 0.8989 | LR: 0.000123 | Estimated time: 53.47
Train loss on 50 batch: 0.015067
Train loss on 100 batch: 0.020011
Train loss on 150 batch: 0.012806
Train loss on 200 batch: 0.015858
: Epoch: 378 | Training Loss: 0.015590 | Val. Loss: 0.238721 | Val. Kappa Score: 0.8989 | LR: 0.000095 | Estimated time: 53.45
Train loss on 50 batch: 0.017670
Train loss on 100 batch: 0.012154
Train loss on 150 batch: 0.016343
Train loss on 200 batch: 0.013993
: Epoch: 379 | Training Loss: 0.014980 | Val. Loss: 0.234029 | Val. Kappa Score: 0.8989 | LR: 0.000071 | Estimated time: 53.53
Train loss on 50 batch: 0.014651
Train loss on 100 batch: 0.013941
Train loss on 150 batch: 0.014712
Train loss on 200 batch: 0.022982
: Epoch: 380 | Training Loss: 0.014538 | Val. Loss: 0.236286 | Val. Kappa Score: 0.8990 | LR: 0.000050 | Estimated time: 53.44
Train loss on 50 batch: 0.015494
Train loss on 100 batch: 0.012866
Train loss on 150 batch: 0.016339
Train loss on 200 batch: 0.015764
: Epoch: 381 | Training Loss: 0.013235 | Val. Loss: 0.233624 | Val. Kappa Score: 0.8990 | LR: 0.000032 | Estimated time: 53.50
Train loss on 50 batch: 0.013683
Train loss on 100 batch: 0.012879
Train loss on 150 batch: 0.021118
Train loss on 200 batch: 0.015471
: Epoch: 382 | Training Loss: 0.015967 | Val. Loss: 0.238599 | Val. Kappa Score: 0.8991 | LR: 0.000018 | Estimated time: 53.53
Train loss on 50 batch: 0.007365
Train loss on 100 batch: 0.021052
Train loss on 150 batch: 0.014703
Train loss on 200 batch: 0.022684
: Epoch: 383 | Training Loss: 0.014892 | Val. Loss: 0.234913 | Val. Kappa Score: 0.8991 | LR: 0.000008 | Estimated time: 53.46
Train loss on 50 batch: 0.015449
Train loss on 100 batch: 0.012076
Train loss on 150 batch: 0.016309
Train loss on 200 batch: 0.017390
: Epoch: 384 | Training Loss: 0.014380 | Val. Loss: 0.234314 | Val. Kappa Score: 0.8991 | LR: 0.000002 | Estimated time: 53.44
Train loss on 50 batch: 0.012969
Train loss on 100 batch: 0.023840
Train loss on 150 batch: 0.017416
Train loss on 200 batch: 0.012378
: Epoch: 385 | Training Loss: 0.013922 | Val. Loss: 0.234208 | Val. Kappa Score: 0.8992 | LR: 0.000000 | Estimated time: 53.56
time_estimated: 20601.61
n-epochs: 385
time_estimated: 20601.64
----------------------------------------

Experiment N: 103: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.17 03:32:00
data-type: new_old_mixed_ben_preprocessing
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb9d1028d0>
early-stopping-patience: 250
parameters-amount: 28342833
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.996647
Train loss on 100 batch: 0.916428
Train loss on 150 batch: 0.805565
Train loss on 200 batch: 0.782458
Train loss on 250 batch: 0.684504
Train loss on 300 batch: 0.722335
Train loss on 350 batch: 0.778996
Train loss on 400 batch: 0.647241
Train loss on 450 batch: 0.704042
Train loss on 500 batch: 0.647001
Train loss on 550 batch: 0.653344
Train loss on 600 batch: 0.682173
Train loss on 650 batch: 0.696127
Train loss on 700 batch: 0.664475
Train loss on 750 batch: 0.723638
Train loss on 800 batch: 0.687591
Train loss on 850 batch: 0.658079
Train loss on 900 batch: 0.668329
Train loss on 950 batch: 0.612165
Train loss on 1000 batch: 0.579632
Train loss on 1050 batch: 0.632603
Train loss on 1100 batch: 0.689141
Train loss on 1150 batch: 0.652538
Train loss on 1200 batch: 0.623227
Train loss on 1250 batch: 0.622985
Train loss on 1300 batch: 0.679293
Train loss on 1350 batch: 0.594888
Train loss on 1400 batch: 0.630721
Train loss on 1450 batch: 0.598614
Train loss on 1500 batch: 0.605751
Train loss on 1550 batch: 0.621399
Train loss on 1600 batch: 0.678340
Train loss on 1650 batch: 0.555518
Train loss on 1700 batch: 0.626626
Train loss on 1750 batch: 0.583294
Train loss on 1800 batch: 0.593111
Train loss on 1850 batch: 0.618544
Train loss on 1900 batch: 0.644657
Train loss on 1950 batch: 0.661803
Train loss on 2000 batch: 0.540803
Train loss on 2050 batch: 0.595370
Train loss on 2100 batch: 0.612731
Train loss on 2150 batch: 0.574566
best-train-loss: 0.663386
best-valid-loss: 0.490623
best-kappa: 0.6033
: Epoch: 1 | Training Loss: 0.663386 | Val. Loss: 0.490623 | Val. Kappa Score: 0.6033 | LR: 0.000998 | Estimated time: 572.70
Train loss on 50 batch: 0.574721
Train loss on 100 batch: 0.579074
Train loss on 150 batch: 0.596099
Train loss on 200 batch: 0.588083
Train loss on 250 batch: 0.609995
Train loss on 300 batch: 0.527099
Train loss on 350 batch: 0.579666
Train loss on 400 batch: 0.638496
Train loss on 450 batch: 0.563791
Train loss on 500 batch: 0.514783
Train loss on 550 batch: 0.518642
Train loss on 600 batch: 0.530166
Train loss on 650 batch: 0.528294
Train loss on 700 batch: 0.535375
Train loss on 750 batch: 0.534442
Train loss on 800 batch: 0.501070
Train loss on 850 batch: 0.521454
Train loss on 900 batch: 0.545360
Train loss on 950 batch: 0.583969
Train loss on 1000 batch: 0.522336
Train loss on 1050 batch: 0.609910
Train loss on 1100 batch: 0.545656
Train loss on 1150 batch: 0.510777
Train loss on 1200 batch: 0.552212
Train loss on 1250 batch: 0.566202
Train loss on 1300 batch: 0.557809
Train loss on 1350 batch: 0.502638
Train loss on 1400 batch: 0.507968
Train loss on 1450 batch: 0.582673
Train loss on 1500 batch: 0.540845
Train loss on 1550 batch: 0.534730
Train loss on 1600 batch: 0.517847
Train loss on 1650 batch: 0.590281
Train loss on 1700 batch: 0.543077
Train loss on 1750 batch: 0.551720
Train loss on 1800 batch: 0.556584
Train loss on 1850 batch: 0.596744
Train loss on 1900 batch: 0.567266
Train loss on 1950 batch: 0.563899
Train loss on 2000 batch: 0.581424
Train loss on 2050 batch: 0.565506
Train loss on 2100 batch: 0.555437
Train loss on 2150 batch: 0.617573
: Epoch: 2 | Training Loss: 0.559011 | Val. Loss: 0.531279 | Val. Kappa Score: 0.6025 | LR: 0.000992 | Estimated time: 554.72
Train loss on 50 batch: 0.623385
Train loss on 100 batch: 0.549630
Train loss on 150 batch: 0.484976
Train loss on 200 batch: 0.554180
Train loss on 250 batch: 0.569936
Train loss on 300 batch: 0.530076
Train loss on 350 batch: 0.537755
Train loss on 400 batch: 0.642968
Train loss on 450 batch: 0.545975
Train loss on 500 batch: 0.506915
Train loss on 550 batch: 0.555592
Train loss on 600 batch: 0.464367
Train loss on 650 batch: 0.495681
Train loss on 700 batch: 0.536083
Train loss on 750 batch: 0.463454
Train loss on 800 batch: 0.544402
Train loss on 850 batch: 0.625730
Train loss on 900 batch: 0.490514
Train loss on 950 batch: 0.530462
Train loss on 1000 batch: 0.551096
Train loss on 1050 batch: 0.485232
Train loss on 1100 batch: 0.555645
Train loss on 1150 batch: 0.500690
Train loss on 1200 batch: 0.490252
Train loss on 1250 batch: 0.471934
Train loss on 1300 batch: 0.487932
Train loss on 1350 batch: 0.540409
Train loss on 1400 batch: 0.518037
Train loss on 1450 batch: 0.565059
Train loss on 1500 batch: 0.454880
Train loss on 1550 batch: 0.610392
Train loss on 1600 batch: 0.528885
Train loss on 1650 batch: 0.451564
Train loss on 1700 batch: 0.542266
Train loss on 1750 batch: 0.490733
Train loss on 1800 batch: 0.484737
Train loss on 1850 batch: 0.493274
Train loss on 1900 batch: 0.447753
Train loss on 1950 batch: 0.512735
Train loss on 2000 batch: 0.486923
Train loss on 2050 batch: 0.456795
Train loss on 2100 batch: 0.414380
Train loss on 2150 batch: 0.500130
best-train-loss: 0.518337
best-valid-loss: 0.436349
best-kappa: 0.6202
: Epoch: 3 | Training Loss: 0.518337 | Val. Loss: 0.436349 | Val. Kappa Score: 0.6202 | LR: 0.000982 | Estimated time: 554.74
Train loss on 50 batch: 0.476269
Train loss on 100 batch: 0.463316
Train loss on 150 batch: 0.543899
Train loss on 200 batch: 0.499755
Train loss on 250 batch: 0.567523
Train loss on 300 batch: 0.523023
Train loss on 350 batch: 0.577645
Train loss on 400 batch: 0.542620
Train loss on 450 batch: 0.533181
Train loss on 500 batch: 0.505288
Train loss on 550 batch: 0.455095
Train loss on 600 batch: 0.433800
Train loss on 650 batch: 0.402005
Train loss on 700 batch: 0.468006
Train loss on 750 batch: 0.493743
Train loss on 800 batch: 0.482052
Train loss on 850 batch: 0.524956
Train loss on 900 batch: 0.486696
Train loss on 950 batch: 0.628585
Train loss on 1000 batch: 0.597595
Train loss on 1050 batch: 0.470449
Train loss on 1100 batch: 0.501669
Train loss on 1150 batch: 0.526257
Train loss on 1200 batch: 0.513675
Train loss on 1250 batch: 0.478463
Train loss on 1300 batch: 0.480653
Train loss on 1350 batch: 0.500586
Train loss on 1400 batch: 0.550654
Train loss on 1450 batch: 0.376214
Train loss on 1500 batch: 0.498936
Train loss on 1550 batch: 0.475837
Train loss on 1600 batch: 0.411704
Train loss on 1650 batch: 0.485738
Train loss on 1700 batch: 0.470755
Train loss on 1750 batch: 0.499696
Train loss on 1800 batch: 0.504672
Train loss on 1850 batch: 0.446475
Train loss on 1900 batch: 0.486721
Train loss on 1950 batch: 0.514412
Train loss on 2000 batch: 0.465832
Train loss on 2050 batch: 0.586409
Train loss on 2100 batch: 0.417056
Train loss on 2150 batch: 0.424720
: Epoch: 4 | Training Loss: 0.493087 | Val. Loss: 0.474002 | Val. Kappa Score: 0.6252 | LR: 0.000968 | Estimated time: 554.92
Train loss on 50 batch: 0.475658
Train loss on 100 batch: 0.451582
Train loss on 150 batch: 0.439018
Train loss on 200 batch: 0.410200
Train loss on 250 batch: 0.417615
Train loss on 300 batch: 0.485683
Train loss on 350 batch: 0.496930
Train loss on 400 batch: 0.451302
Train loss on 450 batch: 0.418214
Train loss on 500 batch: 0.567105
Train loss on 550 batch: 0.482071
Train loss on 600 batch: 0.497013
Train loss on 650 batch: 0.502981
Train loss on 700 batch: 0.458859
Train loss on 750 batch: 0.470816
Train loss on 800 batch: 0.407549
Train loss on 850 batch: 0.463389
Train loss on 900 batch: 0.476640
Train loss on 950 batch: 0.511081
Train loss on 1000 batch: 0.536446
Train loss on 1050 batch: 0.448185
Train loss on 1100 batch: 0.543352
Train loss on 1150 batch: 0.466594
Train loss on 1200 batch: 0.436511
Train loss on 1250 batch: 0.482118
Train loss on 1300 batch: 0.515533
Train loss on 1350 batch: 0.538730
Train loss on 1400 batch: 0.462195
Train loss on 1450 batch: 0.460898
Train loss on 1500 batch: 0.440269
Train loss on 1550 batch: 0.448146
Train loss on 1600 batch: 0.515120
Train loss on 1650 batch: 0.472103
Train loss on 1700 batch: 0.481088
Train loss on 1750 batch: 0.475652
Train loss on 1800 batch: 0.499875
Train loss on 1850 batch: 0.485058
Train loss on 1900 batch: 0.454854
Train loss on 1950 batch: 0.422157
Train loss on 2000 batch: 0.479301
Train loss on 2050 batch: 0.435209
Train loss on 2100 batch: 0.480456
Train loss on 2150 batch: 0.430993
: Epoch: 5 | Training Loss: 0.471343 | Val. Loss: 0.476502 | Val. Kappa Score: 0.6274 | LR: 0.000950 | Estimated time: 554.84
Train loss on 50 batch: 0.423413
Train loss on 100 batch: 0.450428
Train loss on 150 batch: 0.470533
Train loss on 200 batch: 0.438318
Train loss on 250 batch: 0.513719
Train loss on 300 batch: 0.386260
Train loss on 350 batch: 0.410421
Train loss on 400 batch: 0.488739
Train loss on 450 batch: 0.448480
Train loss on 500 batch: 0.439965
Train loss on 550 batch: 0.438125
Train loss on 600 batch: 0.476721
Train loss on 650 batch: 0.483839
Train loss on 700 batch: 0.478364
Train loss on 750 batch: 0.515868
Train loss on 800 batch: 0.510725
Train loss on 850 batch: 0.414793
Train loss on 900 batch: 0.491844
Train loss on 950 batch: 0.513647
Train loss on 1000 batch: 0.469314
Train loss on 1050 batch: 0.530565
Train loss on 1100 batch: 0.404723
Train loss on 1150 batch: 0.530550
Train loss on 1200 batch: 0.452320
Train loss on 1250 batch: 0.509278
Train loss on 1300 batch: 0.475855
Train loss on 1350 batch: 0.431257
Train loss on 1400 batch: 0.390433
Train loss on 1450 batch: 0.477642
Train loss on 1500 batch: 0.435858
Train loss on 1550 batch: 0.387037
Train loss on 1600 batch: 0.473773
Train loss on 1650 batch: 0.431002
Train loss on 1700 batch: 0.554432
Train loss on 1750 batch: 0.476560
Train loss on 1800 batch: 0.462770
Train loss on 1850 batch: 0.467491
Train loss on 1900 batch: 0.451681
Train loss on 1950 batch: 0.451314
Train loss on 2000 batch: 0.422982
Train loss on 2050 batch: 0.453592
Train loss on 2100 batch: 0.462869
Train loss on 2150 batch: 0.463159
best-train-loss: 0.462940
best-valid-loss: 0.426067
best-kappa: 0.6301
: Epoch: 6 | Training Loss: 0.462940 | Val. Loss: 0.426067 | Val. Kappa Score: 0.6301 | LR: 0.000929 | Estimated time: 554.83
Train loss on 50 batch: 0.480923
Train loss on 100 batch: 0.453239
Train loss on 150 batch: 0.484780
Train loss on 200 batch: 0.468819
Train loss on 250 batch: 0.439981
Train loss on 300 batch: 0.484804
Train loss on 350 batch: 0.433960
Train loss on 400 batch: 0.373397
Train loss on 450 batch: 0.442758
Train loss on 500 batch: 0.400258
Train loss on 550 batch: 0.481234
Train loss on 600 batch: 0.459444
Train loss on 650 batch: 0.416401
Train loss on 700 batch: 0.444849
Train loss on 750 batch: 0.444357
Train loss on 800 batch: 0.433684
Train loss on 850 batch: 0.513792
Train loss on 900 batch: 0.467728
Train loss on 950 batch: 0.473578
Train loss on 1000 batch: 0.531292
Train loss on 1050 batch: 0.451181
Train loss on 1100 batch: 0.399883
Train loss on 1150 batch: 0.393355
Train loss on 1200 batch: 0.440740
Train loss on 1250 batch: 0.451046
Train loss on 1300 batch: 0.456232
Train loss on 1350 batch: 0.465012
Train loss on 1400 batch: 0.518003
Train loss on 1450 batch: 0.454376
Train loss on 1500 batch: 0.406719
Train loss on 1550 batch: 0.380990
Train loss on 1600 batch: 0.397268
Train loss on 1650 batch: 0.411615
Train loss on 1700 batch: 0.444140
Train loss on 1750 batch: 0.437461
Train loss on 1800 batch: 0.442584
Train loss on 1850 batch: 0.453097
Train loss on 1900 batch: 0.500066
Train loss on 1950 batch: 0.432446
Train loss on 2000 batch: 0.416725
Train loss on 2050 batch: 0.476615
Train loss on 2100 batch: 0.380830
Train loss on 2150 batch: 0.451869
: Epoch: 7 | Training Loss: 0.446514 | Val. Loss: 0.452809 | Val. Kappa Score: 0.6331 | LR: 0.000905 | Estimated time: 554.29
Train loss on 50 batch: 0.424824
Train loss on 100 batch: 0.438238
Train loss on 150 batch: 0.440515
Train loss on 200 batch: 0.517184
Train loss on 250 batch: 0.460512
Train loss on 300 batch: 0.449805
Train loss on 350 batch: 0.441085
Train loss on 400 batch: 0.428446
Train loss on 450 batch: 0.388710
Train loss on 500 batch: 0.466620
Train loss on 550 batch: 0.411683
Train loss on 600 batch: 0.480998
Train loss on 650 batch: 0.376116
Train loss on 700 batch: 0.430358
Train loss on 750 batch: 0.444344
Train loss on 800 batch: 0.422024
Train loss on 850 batch: 0.398513
Train loss on 900 batch: 0.450748
Train loss on 950 batch: 0.443306
Train loss on 1000 batch: 0.441319
Train loss on 1050 batch: 0.507426
Train loss on 1100 batch: 0.391730
Train loss on 1150 batch: 0.445406
Train loss on 1200 batch: 0.410883
Train loss on 1250 batch: 0.388064
Train loss on 1300 batch: 0.443293
Train loss on 1350 batch: 0.440142
Train loss on 1400 batch: 0.368638
Train loss on 1450 batch: 0.390930
Train loss on 1500 batch: 0.434544
Train loss on 1550 batch: 0.467919
Train loss on 1600 batch: 0.512832
Train loss on 1650 batch: 0.422897
Train loss on 1700 batch: 0.442707
Train loss on 1750 batch: 0.440266
Train loss on 1800 batch: 0.413264
Train loss on 1850 batch: 0.428002
Train loss on 1900 batch: 0.382188
Train loss on 1950 batch: 0.422309
Train loss on 2000 batch: 0.416539
Train loss on 2050 batch: 0.379761
Train loss on 2100 batch: 0.471527
Train loss on 2150 batch: 0.383781
best-train-loss: 0.431029
best-valid-loss: 0.420720
best-kappa: 0.6403
: Epoch: 8 | Training Loss: 0.431029 | Val. Loss: 0.420720 | Val. Kappa Score: 0.6403 | LR: 0.000877 | Estimated time: 555.07
Train loss on 50 batch: 0.380585
Train loss on 100 batch: 0.419991
Train loss on 150 batch: 0.377794
Train loss on 200 batch: 0.423079
Train loss on 250 batch: 0.424839
Train loss on 300 batch: 0.409160
Train loss on 350 batch: 0.415147
Train loss on 400 batch: 0.435880
Train loss on 450 batch: 0.406363
Train loss on 500 batch: 0.448811
Train loss on 550 batch: 0.429879
Train loss on 600 batch: 0.473492
Train loss on 650 batch: 0.394413
Train loss on 700 batch: 0.380948
Train loss on 750 batch: 0.435924
Train loss on 800 batch: 0.372366
Train loss on 850 batch: 0.388207
Train loss on 900 batch: 0.464390
Train loss on 950 batch: 0.383305
Train loss on 1000 batch: 0.460687
Train loss on 1050 batch: 0.421246
Train loss on 1100 batch: 0.443964
Train loss on 1150 batch: 0.390231
Train loss on 1200 batch: 0.463140
Train loss on 1250 batch: 0.479064
Train loss on 1300 batch: 0.396856
Train loss on 1350 batch: 0.487025
Train loss on 1400 batch: 0.424614
Train loss on 1450 batch: 0.399224
Train loss on 1500 batch: 0.404060
Train loss on 1550 batch: 0.418079
Train loss on 1600 batch: 0.452365
Train loss on 1650 batch: 0.418342
Train loss on 1700 batch: 0.499981
Train loss on 1750 batch: 0.335978
Train loss on 1800 batch: 0.431308
Train loss on 1850 batch: 0.433128
Train loss on 1900 batch: 0.347415
Train loss on 1950 batch: 0.427181
Train loss on 2000 batch: 0.424343
Train loss on 2050 batch: 0.437609
Train loss on 2100 batch: 0.433530
Train loss on 2150 batch: 0.418475
: Epoch: 9 | Training Loss: 0.421088 | Val. Loss: 0.508496 | Val. Kappa Score: 0.6355 | LR: 0.000846 | Estimated time: 555.00
Train loss on 50 batch: 0.395598
Train loss on 100 batch: 0.420227
Train loss on 150 batch: 0.397129
Train loss on 200 batch: 0.400624
Train loss on 250 batch: 0.365727
Train loss on 300 batch: 0.459291
Train loss on 350 batch: 0.382124
Train loss on 400 batch: 0.414524
Train loss on 450 batch: 0.386775
Train loss on 500 batch: 0.415746
Train loss on 550 batch: 0.447913
Train loss on 600 batch: 0.402585
Train loss on 650 batch: 0.386504
Train loss on 700 batch: 0.392641
Train loss on 750 batch: 0.463806
Train loss on 800 batch: 0.385825
Train loss on 850 batch: 0.417435
Train loss on 900 batch: 0.450235
Train loss on 950 batch: 0.442992
Train loss on 1000 batch: 0.398591
Train loss on 1050 batch: 0.395145
Train loss on 1100 batch: 0.411602
Train loss on 1150 batch: 0.414393
Train loss on 1200 batch: 0.438083
Train loss on 1250 batch: 0.387562
Train loss on 1300 batch: 0.378519
Train loss on 1350 batch: 0.439166
Train loss on 1400 batch: 0.361984
Train loss on 1450 batch: 0.403691
Train loss on 1500 batch: 0.475467
Train loss on 1550 batch: 0.381685
Train loss on 1600 batch: 0.436427
Train loss on 1650 batch: 0.466853
Train loss on 1700 batch: 0.376904
Train loss on 1750 batch: 0.379715
Train loss on 1800 batch: 0.430642
Train loss on 1850 batch: 0.471792
Train loss on 1900 batch: 0.405477
Train loss on 1950 batch: 0.419119
Train loss on 2000 batch: 0.407595
Train loss on 2050 batch: 0.446554
Train loss on 2100 batch: 0.441882
Train loss on 2150 batch: 0.434645
: Epoch: 10 | Training Loss: 0.413354 | Val. Loss: 0.453208 | Val. Kappa Score: 0.6419 | LR: 0.000812 | Estimated time: 554.95
Train loss on 50 batch: 0.391634
Train loss on 100 batch: 0.357582
Train loss on 150 batch: 0.377848
Train loss on 200 batch: 0.424242
Train loss on 250 batch: 0.372852
Train loss on 300 batch: 0.446358
Train loss on 350 batch: 0.376756
Train loss on 400 batch: 0.406706
Train loss on 450 batch: 0.441460
Train loss on 500 batch: 0.431104
Train loss on 550 batch: 0.352821
Train loss on 600 batch: 0.335290
Train loss on 650 batch: 0.333551
Train loss on 700 batch: 0.427796
Train loss on 750 batch: 0.441883
Train loss on 800 batch: 0.403163
Train loss on 850 batch: 0.373121
Train loss on 900 batch: 0.344008
Train loss on 950 batch: 0.388783
Train loss on 1000 batch: 0.354619
Train loss on 1050 batch: 0.401544
Train loss on 1100 batch: 0.427629
Train loss on 1150 batch: 0.344174
Train loss on 1200 batch: 0.413237
Train loss on 1250 batch: 0.427956
Train loss on 1300 batch: 0.387571
Train loss on 1350 batch: 0.415210
Train loss on 1400 batch: 0.488915
Train loss on 1450 batch: 0.396375
Train loss on 1500 batch: 0.392524
Train loss on 1550 batch: 0.459996
Train loss on 1600 batch: 0.414823
Train loss on 1650 batch: 0.476914
Train loss on 1700 batch: 0.389881
Train loss on 1750 batch: 0.463166
Train loss on 1800 batch: 0.339534
Train loss on 1850 batch: 0.448164
Train loss on 1900 batch: 0.364922
Train loss on 1950 batch: 0.455783
Train loss on 2000 batch: 0.376879
Train loss on 2050 batch: 0.350676
Train loss on 2100 batch: 0.403726
Train loss on 2150 batch: 0.373835
best-train-loss: 0.400405
best-valid-loss: 0.376682
best-kappa: 0.6486
: Epoch: 11 | Training Loss: 0.400405 | Val. Loss: 0.376682 | Val. Kappa Score: 0.6486 | LR: 0.000775 | Estimated time: 554.98
Train loss on 50 batch: 0.440341
Train loss on 100 batch: 0.479346
Train loss on 150 batch: 0.391243
Train loss on 200 batch: 0.415222
Train loss on 250 batch: 0.390908
Train loss on 300 batch: 0.375988
Train loss on 350 batch: 0.433580
Train loss on 400 batch: 0.417956
Train loss on 450 batch: 0.393150
Train loss on 500 batch: 0.473339
Train loss on 550 batch: 0.435093
Train loss on 600 batch: 0.389360
Train loss on 650 batch: 0.382188
Train loss on 700 batch: 0.353283
Train loss on 750 batch: 0.366060
Train loss on 800 batch: 0.389290
Train loss on 850 batch: 0.442527
Train loss on 900 batch: 0.383555
Train loss on 950 batch: 0.392849
Train loss on 1000 batch: 0.363616
Train loss on 1050 batch: 0.374558
Train loss on 1100 batch: 0.403290
Train loss on 1150 batch: 0.388466
Train loss on 1200 batch: 0.360446
Train loss on 1250 batch: 0.398298
Train loss on 1300 batch: 0.406365
Train loss on 1350 batch: 0.415644
Train loss on 1400 batch: 0.438093
Train loss on 1450 batch: 0.365818
Train loss on 1500 batch: 0.447007
Train loss on 1550 batch: 0.401295
Train loss on 1600 batch: 0.364984
Train loss on 1650 batch: 0.371920
Train loss on 1700 batch: 0.350864
Train loss on 1750 batch: 0.394328
Train loss on 1800 batch: 0.400524
Train loss on 1850 batch: 0.365772
Train loss on 1900 batch: 0.383121
Train loss on 1950 batch: 0.370904
Train loss on 2000 batch: 0.386300
Train loss on 2050 batch: 0.426968
Train loss on 2100 batch: 0.401710
Train loss on 2150 batch: 0.446399
: Epoch: 12 | Training Loss: 0.398799 | Val. Loss: 0.509750 | Val. Kappa Score: 0.6501 | LR: 0.000737 | Estimated time: 555.15
Train loss on 50 batch: 0.388130
Train loss on 100 batch: 0.362776
Train loss on 150 batch: 0.410391
Train loss on 200 batch: 0.384097
Train loss on 250 batch: 0.321152
Train loss on 300 batch: 0.336514
Train loss on 350 batch: 0.381209
Train loss on 400 batch: 0.326726
Train loss on 450 batch: 0.423640
Train loss on 500 batch: 0.325891
Train loss on 550 batch: 0.411942
Train loss on 600 batch: 0.347513
Train loss on 650 batch: 0.411836
Train loss on 700 batch: 0.384799
Train loss on 750 batch: 0.389559
Train loss on 800 batch: 0.322989
Train loss on 850 batch: 0.384491
Train loss on 900 batch: 0.409822
Train loss on 950 batch: 0.406750
Train loss on 1000 batch: 0.438310
Train loss on 1050 batch: 0.353594
Train loss on 1100 batch: 0.405287
Train loss on 1150 batch: 0.372081
Train loss on 1200 batch: 0.320857
Train loss on 1250 batch: 0.341652
Train loss on 1300 batch: 0.335364
Train loss on 1350 batch: 0.393205
Train loss on 1400 batch: 0.438953
Train loss on 1450 batch: 0.364277
Train loss on 1500 batch: 0.405980
Train loss on 1550 batch: 0.399232
Train loss on 1600 batch: 0.411613
Train loss on 1650 batch: 0.416386
Train loss on 1700 batch: 0.429029
Train loss on 1750 batch: 0.428952
Train loss on 1800 batch: 0.393825
Train loss on 1850 batch: 0.381059
Train loss on 1900 batch: 0.424980
Train loss on 1950 batch: 0.473894
Train loss on 2000 batch: 0.368435
Train loss on 2050 batch: 0.371149
Train loss on 2100 batch: 0.369167
Train loss on 2150 batch: 0.361974
: Epoch: 13 | Training Loss: 0.383037 | Val. Loss: 0.404027 | Val. Kappa Score: 0.6522 | LR: 0.000697 | Estimated time: 554.91
Train loss on 50 batch: 0.382150
Train loss on 100 batch: 0.336468
Train loss on 150 batch: 0.367731
Train loss on 200 batch: 0.383601
Train loss on 250 batch: 0.381621
Train loss on 300 batch: 0.288220
Train loss on 350 batch: 0.351252
Train loss on 400 batch: 0.400693
Train loss on 450 batch: 0.360298
Train loss on 500 batch: 0.426165
Train loss on 550 batch: 0.320877
Train loss on 600 batch: 0.383162
Train loss on 650 batch: 0.333353
Train loss on 700 batch: 0.368424
Train loss on 750 batch: 0.433213
Train loss on 800 batch: 0.422005
Train loss on 850 batch: 0.359618
Train loss on 900 batch: 0.400026
Train loss on 950 batch: 0.392299
Train loss on 1000 batch: 0.389315
Train loss on 1050 batch: 0.356073
Train loss on 1100 batch: 0.357721
Train loss on 1150 batch: 0.395142
Train loss on 1200 batch: 0.318982
Train loss on 1250 batch: 0.339092
Train loss on 1300 batch: 0.343491
Train loss on 1350 batch: 0.368972
Train loss on 1400 batch: 0.456879
Train loss on 1450 batch: 0.347333
Train loss on 1500 batch: 0.367707
Train loss on 1550 batch: 0.342263
Train loss on 1600 batch: 0.349858
Train loss on 1650 batch: 0.329042
Train loss on 1700 batch: 0.392132
Train loss on 1750 batch: 0.370933
Train loss on 1800 batch: 0.390426
Train loss on 1850 batch: 0.353660
Train loss on 1900 batch: 0.335975
Train loss on 1950 batch: 0.452480
Train loss on 2000 batch: 0.382617
Train loss on 2050 batch: 0.393640
Train loss on 2100 batch: 0.401785
Train loss on 2150 batch: 0.400289
: Epoch: 14 | Training Loss: 0.373221 | Val. Loss: 0.385999 | Val. Kappa Score: 0.6547 | LR: 0.000655 | Estimated time: 554.95
Train loss on 50 batch: 0.335769
Train loss on 100 batch: 0.414955
Train loss on 150 batch: 0.390189
Train loss on 200 batch: 0.440669
Train loss on 250 batch: 0.318914
Train loss on 300 batch: 0.319099
Train loss on 350 batch: 0.313378
Train loss on 400 batch: 0.356690
Train loss on 450 batch: 0.412748
Train loss on 500 batch: 0.358803
Train loss on 550 batch: 0.327896
Train loss on 600 batch: 0.357106
Train loss on 650 batch: 0.333485
Train loss on 700 batch: 0.326907
Train loss on 750 batch: 0.360963
Train loss on 800 batch: 0.404275
Train loss on 850 batch: 0.322701
Train loss on 900 batch: 0.371901
Train loss on 950 batch: 0.376296
Train loss on 1000 batch: 0.364073
Train loss on 1050 batch: 0.341712
Train loss on 1100 batch: 0.379142
Train loss on 1150 batch: 0.343360
Train loss on 1200 batch: 0.452932
Train loss on 1250 batch: 0.420070
Train loss on 1300 batch: 0.359974
Train loss on 1350 batch: 0.349559
Train loss on 1400 batch: 0.390334
Train loss on 1450 batch: 0.387622
Train loss on 1500 batch: 0.367109
Train loss on 1550 batch: 0.385198
Train loss on 1600 batch: 0.412561
Train loss on 1650 batch: 0.370153
Train loss on 1700 batch: 0.344713
Train loss on 1750 batch: 0.374967
Train loss on 1800 batch: 0.388563
Train loss on 1850 batch: 0.366071
Train loss on 1900 batch: 0.371839
Train loss on 1950 batch: 0.350957
Train loss on 2000 batch: 0.324298
Train loss on 2050 batch: 0.402237
Train loss on 2100 batch: 0.369905
Train loss on 2150 batch: 0.347420
best-train-loss: 0.368650
best-valid-loss: 0.354229
best-kappa: 0.6588
: Epoch: 15 | Training Loss: 0.368650 | Val. Loss: 0.354229 | Val. Kappa Score: 0.6588 | LR: 0.000611 | Estimated time: 554.99
Train loss on 50 batch: 0.356219
Train loss on 100 batch: 0.346578
Train loss on 150 batch: 0.401853
Train loss on 200 batch: 0.342411
Train loss on 250 batch: 0.313869
Train loss on 300 batch: 0.297997
Train loss on 350 batch: 0.273615
Train loss on 400 batch: 0.327663
Train loss on 450 batch: 0.372267
Train loss on 500 batch: 0.380486
Train loss on 550 batch: 0.383400
Train loss on 600 batch: 0.341730
Train loss on 650 batch: 0.417577
Train loss on 700 batch: 0.317321
Train loss on 750 batch: 0.334545
Train loss on 800 batch: 0.393767
Train loss on 850 batch: 0.377636
Train loss on 900 batch: 0.346836
Train loss on 950 batch: 0.367723
Train loss on 1000 batch: 0.355467
Train loss on 1050 batch: 0.326114
Train loss on 1100 batch: 0.412997
Train loss on 1150 batch: 0.346997
Train loss on 1200 batch: 0.372203
Train loss on 1250 batch: 0.324752
Train loss on 1300 batch: 0.381149
Train loss on 1350 batch: 0.334492
Train loss on 1400 batch: 0.364039
Train loss on 1450 batch: 0.370286
Train loss on 1500 batch: 0.399308
Train loss on 1550 batch: 0.342949
Train loss on 1600 batch: 0.347655
Train loss on 1650 batch: 0.329091
Train loss on 1700 batch: 0.359514
Train loss on 1750 batch: 0.407188
Train loss on 1800 batch: 0.383728
Train loss on 1850 batch: 0.343961
Train loss on 1900 batch: 0.417711
Train loss on 1950 batch: 0.370246
Train loss on 2000 batch: 0.393531
Train loss on 2050 batch: 0.358615
Train loss on 2100 batch: 0.319458
Train loss on 2150 batch: 0.411038
: Epoch: 16 | Training Loss: 0.359270 | Val. Loss: 0.672988 | Val. Kappa Score: 0.6561 | LR: 0.000567 | Estimated time: 554.98
Train loss on 50 batch: 0.426995
Train loss on 100 batch: 0.348953
Train loss on 150 batch: 0.305706
Train loss on 200 batch: 0.341816
Train loss on 250 batch: 0.327877
Train loss on 300 batch: 0.336190
Train loss on 350 batch: 0.395824
Train loss on 400 batch: 0.383743
Train loss on 450 batch: 0.326973
Train loss on 500 batch: 0.343523
Train loss on 550 batch: 0.370400
Train loss on 600 batch: 0.346224
Train loss on 650 batch: 0.352587
Train loss on 700 batch: 0.349925
Train loss on 750 batch: 0.417665
Train loss on 800 batch: 0.300017
Train loss on 850 batch: 0.344806
Train loss on 900 batch: 0.361979
Train loss on 950 batch: 0.380805
Train loss on 1000 batch: 0.319772
Train loss on 1050 batch: 0.353886
Train loss on 1100 batch: 0.344024
Train loss on 1150 batch: 0.336621
Train loss on 1200 batch: 0.356776
Train loss on 1250 batch: 0.351982
Train loss on 1300 batch: 0.343530
Train loss on 1350 batch: 0.307411
Train loss on 1400 batch: 0.332633
Train loss on 1450 batch: 0.361792
Train loss on 1500 batch: 0.318771
Train loss on 1550 batch: 0.331348
Train loss on 1600 batch: 0.300596
Train loss on 1650 batch: 0.389051
Train loss on 1700 batch: 0.369675
Train loss on 1750 batch: 0.352087
Train loss on 1800 batch: 0.345548
Train loss on 1850 batch: 0.353517
Train loss on 1900 batch: 0.357796
Train loss on 1950 batch: 0.385591
Train loss on 2000 batch: 0.326088
Train loss on 2050 batch: 0.369846
Train loss on 2100 batch: 0.397820
Train loss on 2150 batch: 0.325635
: Epoch: 17 | Training Loss: 0.350789 | Val. Loss: 0.357491 | Val. Kappa Score: 0.6595 | LR: 0.000522 | Estimated time: 554.82
Train loss on 50 batch: 0.347305
Train loss on 100 batch: 0.375174
Train loss on 150 batch: 0.394871
Train loss on 200 batch: 0.356330
Train loss on 250 batch: 0.328770
Train loss on 300 batch: 0.361856
Train loss on 350 batch: 0.332918
Train loss on 400 batch: 0.336554
Train loss on 450 batch: 0.357942
Train loss on 500 batch: 0.385496
Train loss on 550 batch: 0.304743
Train loss on 600 batch: 0.343040
Train loss on 650 batch: 0.425391
Train loss on 700 batch: 0.358296
Train loss on 750 batch: 0.375405
Train loss on 800 batch: 0.303158
Train loss on 850 batch: 0.340321
Train loss on 900 batch: 0.325142
Train loss on 950 batch: 0.316986
Train loss on 1000 batch: 0.362647
Train loss on 1050 batch: 0.397205
Train loss on 1100 batch: 0.356990
Train loss on 1150 batch: 0.322827
Train loss on 1200 batch: 0.345440
Train loss on 1250 batch: 0.336948
Train loss on 1300 batch: 0.290083
Train loss on 1350 batch: 0.309253
Train loss on 1400 batch: 0.381214
Train loss on 1450 batch: 0.315533
Train loss on 1500 batch: 0.309240
Train loss on 1550 batch: 0.320224
Train loss on 1600 batch: 0.388480
Train loss on 1650 batch: 0.347229
Train loss on 1700 batch: 0.328540
Train loss on 1750 batch: 0.325466
Train loss on 1800 batch: 0.259221
Train loss on 1850 batch: 0.358276
Train loss on 1900 batch: 0.377049
Train loss on 1950 batch: 0.334288
Train loss on 2000 batch: 0.349485
Train loss on 2050 batch: 0.349905
Train loss on 2100 batch: 0.345218
Train loss on 2150 batch: 0.392286
: Epoch: 18 | Training Loss: 0.345373 | Val. Loss: 0.397962 | Val. Kappa Score: 0.6614 | LR: 0.000478 | Estimated time: 555.26
Train loss on 50 batch: 0.295837
Train loss on 100 batch: 0.383917
Train loss on 150 batch: 0.370201
Train loss on 200 batch: 0.392792
Train loss on 250 batch: 0.328580
Train loss on 300 batch: 0.337787
Train loss on 350 batch: 0.357460
Train loss on 400 batch: 0.382893
Train loss on 450 batch: 0.330565
Train loss on 500 batch: 0.350533
Train loss on 550 batch: 0.289831
Train loss on 600 batch: 0.318013
Train loss on 650 batch: 0.254419
Train loss on 700 batch: 0.334481
Train loss on 750 batch: 0.333834
Train loss on 800 batch: 0.307173
Train loss on 850 batch: 0.317012
Train loss on 900 batch: 0.288678
Train loss on 950 batch: 0.332151
Train loss on 1000 batch: 0.388866
Train loss on 1050 batch: 0.333026
Train loss on 1100 batch: 0.359707
Train loss on 1150 batch: 0.315618
Train loss on 1200 batch: 0.326288
Train loss on 1250 batch: 0.308823
Train loss on 1300 batch: 0.331324
Train loss on 1350 batch: 0.330318
Train loss on 1400 batch: 0.331886
Train loss on 1450 batch: 0.345498
Train loss on 1500 batch: 0.327814
Train loss on 1550 batch: 0.365753
Train loss on 1600 batch: 0.350608
Train loss on 1650 batch: 0.303480
Train loss on 1700 batch: 0.324107
Train loss on 1750 batch: 0.368640
Train loss on 1800 batch: 0.328501
Train loss on 1850 batch: 0.321227
Train loss on 1900 batch: 0.372492
Train loss on 1950 batch: 0.360279
Train loss on 2000 batch: 0.329763
Train loss on 2050 batch: 0.374174
Train loss on 2100 batch: 0.345683
Train loss on 2150 batch: 0.342429
: Epoch: 19 | Training Loss: 0.337417 | Val. Loss: 0.431261 | Val. Kappa Score: 0.6633 | LR: 0.000433 | Estimated time: 555.12
Train loss on 50 batch: 0.331306
Train loss on 100 batch: 0.310708
Train loss on 150 batch: 0.233909
Train loss on 200 batch: 0.349970
Train loss on 250 batch: 0.386950
Train loss on 300 batch: 0.327225
Train loss on 350 batch: 0.330757
Train loss on 400 batch: 0.332069
Train loss on 450 batch: 0.341939
Train loss on 500 batch: 0.314368
Train loss on 550 batch: 0.302052
Train loss on 600 batch: 0.319376
Train loss on 650 batch: 0.317896
Train loss on 700 batch: 0.409918
Train loss on 750 batch: 0.370708
Train loss on 800 batch: 0.284622
Train loss on 850 batch: 0.283504
Train loss on 900 batch: 0.333748
Train loss on 950 batch: 0.295694
Train loss on 1000 batch: 0.339794
Train loss on 1050 batch: 0.326972
Train loss on 1100 batch: 0.337627
Train loss on 1150 batch: 0.293441
Train loss on 1200 batch: 0.379401
Train loss on 1250 batch: 0.285846
Train loss on 1300 batch: 0.341783
Train loss on 1350 batch: 0.320899
Train loss on 1400 batch: 0.295585
Train loss on 1450 batch: 0.285242
Train loss on 1500 batch: 0.332448
Train loss on 1550 batch: 0.331345
Train loss on 1600 batch: 0.317393
Train loss on 1650 batch: 0.352609
Train loss on 1700 batch: 0.323699
Train loss on 1750 batch: 0.311980
Train loss on 1800 batch: 0.334263
Train loss on 1850 batch: 0.326880
Train loss on 1900 batch: 0.343708
Train loss on 1950 batch: 0.301225
Train loss on 2000 batch: 0.331277
Train loss on 2050 batch: 0.368590
Train loss on 2100 batch: 0.302574
Train loss on 2150 batch: 0.314344
: Epoch: 20 | Training Loss: 0.325372 | Val. Loss: 0.383100 | Val. Kappa Score: 0.6659 | LR: 0.000389 | Estimated time: 555.10
Train loss on 50 batch: 0.335954
Train loss on 100 batch: 0.319585
Train loss on 150 batch: 0.317744
Train loss on 200 batch: 0.393934
Train loss on 250 batch: 0.331396
Train loss on 300 batch: 0.265658
Train loss on 350 batch: 0.375286
Train loss on 400 batch: 0.306520
Train loss on 450 batch: 0.263379
Train loss on 500 batch: 0.299837
Train loss on 550 batch: 0.239414
Train loss on 600 batch: 0.310831
Train loss on 650 batch: 0.348046
Train loss on 700 batch: 0.308992
Train loss on 750 batch: 0.315373
Train loss on 800 batch: 0.307960
Train loss on 850 batch: 0.271710
Train loss on 900 batch: 0.340033
Train loss on 950 batch: 0.348112
Train loss on 1000 batch: 0.348896
Train loss on 1050 batch: 0.352536
Train loss on 1100 batch: 0.391824
Train loss on 1150 batch: 0.296587
Train loss on 1200 batch: 0.308161
Train loss on 1250 batch: 0.301481
Train loss on 1300 batch: 0.356247
Train loss on 1350 batch: 0.360063
Train loss on 1400 batch: 0.284180
Train loss on 1450 batch: 0.320474
Train loss on 1500 batch: 0.320908
Train loss on 1550 batch: 0.307146
Train loss on 1600 batch: 0.327253
Train loss on 1650 batch: 0.297897
Train loss on 1700 batch: 0.352353
Train loss on 1750 batch: 0.270095
Train loss on 1800 batch: 0.344232
Train loss on 1850 batch: 0.346797
Train loss on 1900 batch: 0.306975
Train loss on 1950 batch: 0.266290
Train loss on 2000 batch: 0.357805
Train loss on 2050 batch: 0.398866
Train loss on 2100 batch: 0.277956
Train loss on 2150 batch: 0.323926
: Epoch: 21 | Training Loss: 0.320433 | Val. Loss: 0.394051 | Val. Kappa Score: 0.6689 | LR: 0.000345 | Estimated time: 555.11
Train loss on 50 batch: 0.311453
Train loss on 100 batch: 0.323173
Train loss on 150 batch: 0.333595
Train loss on 200 batch: 0.307922
Train loss on 250 batch: 0.326922
Train loss on 300 batch: 0.297265
Train loss on 350 batch: 0.309606
Train loss on 400 batch: 0.301198
Train loss on 450 batch: 0.332401
Train loss on 500 batch: 0.297340
Train loss on 550 batch: 0.302117
Train loss on 600 batch: 0.367732
Train loss on 650 batch: 0.310455
Train loss on 700 batch: 0.321234
Train loss on 750 batch: 0.331078
Train loss on 800 batch: 0.373991
Train loss on 850 batch: 0.334555
Train loss on 900 batch: 0.284154
Train loss on 950 batch: 0.353282
Train loss on 1000 batch: 0.404213
Train loss on 1050 batch: 0.282264
Train loss on 1100 batch: 0.343195
Train loss on 1150 batch: 0.319179
Train loss on 1200 batch: 0.331654
Train loss on 1250 batch: 0.308683
Train loss on 1300 batch: 0.327565
Train loss on 1350 batch: 0.354561
Train loss on 1400 batch: 0.312309
Train loss on 1450 batch: 0.374977
Train loss on 1500 batch: 0.309726
Train loss on 1550 batch: 0.288382
Train loss on 1600 batch: 0.253171
Train loss on 1650 batch: 0.302086
Train loss on 1700 batch: 0.277053
Train loss on 1750 batch: 0.253959
Train loss on 1800 batch: 0.312085
Train loss on 1850 batch: 0.282496
Train loss on 1900 batch: 0.296086
Train loss on 1950 batch: 0.301271
Train loss on 2000 batch: 0.320610
Train loss on 2050 batch: 0.296711
Train loss on 2100 batch: 0.297783
Train loss on 2150 batch: 0.296429
best-train-loss: 0.315484
best-valid-loss: 0.322412
best-kappa: 0.6727
: Epoch: 22 | Training Loss: 0.315484 | Val. Loss: 0.322412 | Val. Kappa Score: 0.6727 | LR: 0.000303 | Estimated time: 555.00
Train loss on 50 batch: 0.290084
Train loss on 100 batch: 0.266305
Train loss on 150 batch: 0.283931
Train loss on 200 batch: 0.319120
Train loss on 250 batch: 0.304655
Train loss on 300 batch: 0.309488
Train loss on 350 batch: 0.291817
Train loss on 400 batch: 0.358243
Train loss on 450 batch: 0.334148
Train loss on 500 batch: 0.337939
Train loss on 550 batch: 0.356297
Train loss on 600 batch: 0.334530
Train loss on 650 batch: 0.358914
Train loss on 700 batch: 0.368222
Train loss on 750 batch: 0.287466
Train loss on 800 batch: 0.326172
Train loss on 850 batch: 0.311538
Train loss on 900 batch: 0.304160
Train loss on 950 batch: 0.372432
Train loss on 1000 batch: 0.294542
Train loss on 1050 batch: 0.260337
Train loss on 1100 batch: 0.284057
Train loss on 1150 batch: 0.352461
Train loss on 1200 batch: 0.279479
Train loss on 1250 batch: 0.274986
Train loss on 1300 batch: 0.290206
Train loss on 1350 batch: 0.281253
Train loss on 1400 batch: 0.293819
Train loss on 1450 batch: 0.312262
Train loss on 1500 batch: 0.299282
Train loss on 1550 batch: 0.255855
Train loss on 1600 batch: 0.346791
Train loss on 1650 batch: 0.256477
Train loss on 1700 batch: 0.289452
Train loss on 1750 batch: 0.290024
Train loss on 1800 batch: 0.286028
Train loss on 1850 batch: 0.310421
Train loss on 1900 batch: 0.292923
Train loss on 1950 batch: 0.302752
Train loss on 2000 batch: 0.323081
Train loss on 2050 batch: 0.320699
Train loss on 2100 batch: 0.310753
Train loss on 2150 batch: 0.260417
: Epoch: 23 | Training Loss: 0.306544 | Val. Loss: 0.369383 | Val. Kappa Score: 0.6759 | LR: 0.000263 | Estimated time: 555.13
Train loss on 50 batch: 0.335196
Train loss on 100 batch: 0.281501
Train loss on 150 batch: 0.325097
Train loss on 200 batch: 0.288658
Train loss on 250 batch: 0.293932
Train loss on 300 batch: 0.300695
Train loss on 350 batch: 0.325575
Train loss on 400 batch: 0.269940
Train loss on 450 batch: 0.281674
Train loss on 500 batch: 0.324956
Train loss on 550 batch: 0.353251
Train loss on 600 batch: 0.351084
Train loss on 650 batch: 0.335444
Train loss on 700 batch: 0.283814
Train loss on 750 batch: 0.269667
Train loss on 800 batch: 0.305095
Train loss on 850 batch: 0.310161
Train loss on 900 batch: 0.265450
Train loss on 950 batch: 0.341640
Train loss on 1000 batch: 0.278306
Train loss on 1050 batch: 0.280571
Train loss on 1100 batch: 0.301974
Train loss on 1150 batch: 0.346324
Train loss on 1200 batch: 0.319007
Train loss on 1250 batch: 0.298115
Train loss on 1300 batch: 0.337808
Train loss on 1350 batch: 0.352168
Train loss on 1400 batch: 0.320592
Train loss on 1450 batch: 0.295224
Train loss on 1500 batch: 0.264793
Train loss on 1550 batch: 0.282790
Train loss on 1600 batch: 0.307039
Train loss on 1650 batch: 0.260959
Train loss on 1700 batch: 0.295728
Train loss on 1750 batch: 0.298511
Train loss on 1800 batch: 0.344050
Train loss on 1850 batch: 0.326493
Train loss on 1900 batch: 0.291017
Train loss on 1950 batch: 0.285008
Train loss on 2000 batch: 0.300916
Train loss on 2050 batch: 0.314933
Train loss on 2100 batch: 0.268208
Train loss on 2150 batch: 0.271241
: Epoch: 24 | Training Loss: 0.303761 | Val. Loss: 0.324048 | Val. Kappa Score: 0.6785 | LR: 0.000225 | Estimated time: 554.76
Train loss on 50 batch: 0.278414
Train loss on 100 batch: 0.300307
Train loss on 150 batch: 0.282437
Train loss on 200 batch: 0.291167
Train loss on 250 batch: 0.294082
Train loss on 300 batch: 0.318012
Train loss on 350 batch: 0.267800
Train loss on 400 batch: 0.330721
Train loss on 450 batch: 0.263598
Train loss on 500 batch: 0.275622
Train loss on 550 batch: 0.307172
Train loss on 600 batch: 0.281375
Train loss on 650 batch: 0.335520
Train loss on 700 batch: 0.292900
Train loss on 750 batch: 0.297925
Train loss on 800 batch: 0.291118
Train loss on 850 batch: 0.312224
Train loss on 900 batch: 0.269472
Train loss on 950 batch: 0.324882
Train loss on 1000 batch: 0.295604
Train loss on 1050 batch: 0.263714
Train loss on 1100 batch: 0.261152
Train loss on 1150 batch: 0.284889
Train loss on 1200 batch: 0.271646
Train loss on 1250 batch: 0.281275
Train loss on 1300 batch: 0.264024
Train loss on 1350 batch: 0.230295
Train loss on 1400 batch: 0.297660
Train loss on 1450 batch: 0.327111
Train loss on 1500 batch: 0.297367
Train loss on 1550 batch: 0.311768
Train loss on 1600 batch: 0.295784
Train loss on 1650 batch: 0.310459
Train loss on 1700 batch: 0.317296
Train loss on 1750 batch: 0.259401
Train loss on 1800 batch: 0.271007
Train loss on 1850 batch: 0.286328
Train loss on 1900 batch: 0.244179
Train loss on 1950 batch: 0.317141
Train loss on 2000 batch: 0.302659
Train loss on 2050 batch: 0.340204
Train loss on 2100 batch: 0.306606
Train loss on 2150 batch: 0.305154
: Epoch: 25 | Training Loss: 0.292453 | Val. Loss: 0.339563 | Val. Kappa Score: 0.6808 | LR: 0.000188 | Estimated time: 554.68
Train loss on 50 batch: 0.274082
Train loss on 100 batch: 0.288429
Train loss on 150 batch: 0.262299
Train loss on 200 batch: 0.244522
Train loss on 250 batch: 0.320220
Train loss on 300 batch: 0.275740
Train loss on 350 batch: 0.225907
Train loss on 400 batch: 0.312944
Train loss on 450 batch: 0.252268
Train loss on 500 batch: 0.260506
Train loss on 550 batch: 0.273212
Train loss on 600 batch: 0.279584
Train loss on 650 batch: 0.285874
Train loss on 700 batch: 0.281237
Train loss on 750 batch: 0.265931
Train loss on 800 batch: 0.261684
Train loss on 850 batch: 0.262156
Train loss on 900 batch: 0.282788
Train loss on 950 batch: 0.336286
Train loss on 1000 batch: 0.243455
Train loss on 1050 batch: 0.340493
Train loss on 1100 batch: 0.326706
Train loss on 1150 batch: 0.258646
Train loss on 1200 batch: 0.289548
Train loss on 1250 batch: 0.308762
Train loss on 1300 batch: 0.344090
Train loss on 1350 batch: 0.280905
Train loss on 1400 batch: 0.297098
Train loss on 1450 batch: 0.247952
Train loss on 1500 batch: 0.266687
Train loss on 1550 batch: 0.310963
Train loss on 1600 batch: 0.314346
Train loss on 1650 batch: 0.251442
Train loss on 1700 batch: 0.296899
Train loss on 1750 batch: 0.235345
Train loss on 1800 batch: 0.286088
Train loss on 1850 batch: 0.317801
Train loss on 1900 batch: 0.276499
Train loss on 1950 batch: 0.316197
Train loss on 2000 batch: 0.272140
Train loss on 2050 batch: 0.315497
Train loss on 2100 batch: 0.300234
Train loss on 2150 batch: 0.304678
: Epoch: 26 | Training Loss: 0.285037 | Val. Loss: 0.326021 | Val. Kappa Score: 0.6835 | LR: 0.000154 | Estimated time: 555.49
Train loss on 50 batch: 0.277102
Train loss on 100 batch: 0.216036
Train loss on 150 batch: 0.276752
Train loss on 200 batch: 0.282547
Train loss on 250 batch: 0.299286
Train loss on 300 batch: 0.292905
Train loss on 350 batch: 0.330633
Train loss on 400 batch: 0.313500
Train loss on 450 batch: 0.256445
Train loss on 500 batch: 0.241851
Train loss on 550 batch: 0.264937
Train loss on 600 batch: 0.264521
Train loss on 650 batch: 0.248544
Train loss on 700 batch: 0.278571
Train loss on 750 batch: 0.313897
Train loss on 800 batch: 0.285383
Train loss on 850 batch: 0.291536
Train loss on 900 batch: 0.308825
Train loss on 950 batch: 0.278605
Train loss on 1000 batch: 0.291507
Train loss on 1050 batch: 0.252075
Train loss on 1100 batch: 0.274343
Train loss on 1150 batch: 0.255887
Train loss on 1200 batch: 0.296164
Train loss on 1250 batch: 0.217676
Train loss on 1300 batch: 0.278024
Train loss on 1350 batch: 0.315439
Train loss on 1400 batch: 0.288969
Train loss on 1450 batch: 0.273156
Train loss on 1500 batch: 0.327811
Train loss on 1550 batch: 0.304825
Train loss on 1600 batch: 0.290510
Train loss on 1650 batch: 0.254777
Train loss on 1700 batch: 0.287918
Train loss on 1750 batch: 0.302826
Train loss on 1800 batch: 0.285671
Train loss on 1850 batch: 0.272627
Train loss on 1900 batch: 0.224288
Train loss on 1950 batch: 0.338914
Train loss on 2000 batch: 0.253407
Train loss on 2050 batch: 0.244161
Train loss on 2100 batch: 0.292712
Train loss on 2150 batch: 0.279232
: Epoch: 27 | Training Loss: 0.279665 | Val. Loss: 0.345200 | Val. Kappa Score: 0.6856 | LR: 0.000123 | Estimated time: 554.84
Train loss on 50 batch: 0.312934
Train loss on 100 batch: 0.284027
Train loss on 150 batch: 0.310054
Train loss on 200 batch: 0.280902
Train loss on 250 batch: 0.267022
Train loss on 300 batch: 0.234373
Train loss on 350 batch: 0.319673
Train loss on 400 batch: 0.265135
Train loss on 450 batch: 0.297613
Train loss on 500 batch: 0.311953
Train loss on 550 batch: 0.252148
Train loss on 600 batch: 0.283671
Train loss on 650 batch: 0.250293
Train loss on 700 batch: 0.319576
Train loss on 750 batch: 0.256570
Train loss on 800 batch: 0.288444
Train loss on 850 batch: 0.291410
Train loss on 900 batch: 0.256610
Train loss on 950 batch: 0.248277
Train loss on 1000 batch: 0.275683
Train loss on 1050 batch: 0.282510
Train loss on 1100 batch: 0.242786
Train loss on 1150 batch: 0.260209
Train loss on 1200 batch: 0.287677
Train loss on 1250 batch: 0.288005
Train loss on 1300 batch: 0.290840
Train loss on 1350 batch: 0.309297
Train loss on 1400 batch: 0.293904
Train loss on 1450 batch: 0.307704
Train loss on 1500 batch: 0.282895
Train loss on 1550 batch: 0.285322
Train loss on 1600 batch: 0.270558
Train loss on 1650 batch: 0.230105
Train loss on 1700 batch: 0.269992
Train loss on 1750 batch: 0.280225
Train loss on 1800 batch: 0.277936
Train loss on 1850 batch: 0.258406
Train loss on 1900 batch: 0.255351
Train loss on 1950 batch: 0.268191
Train loss on 2000 batch: 0.247257
Train loss on 2050 batch: 0.226854
Train loss on 2100 batch: 0.223652
Train loss on 2150 batch: 0.302207
: Epoch: 28 | Training Loss: 0.275377 | Val. Loss: 0.325928 | Val. Kappa Score: 0.6879 | LR: 0.000095 | Estimated time: 554.92
Train loss on 50 batch: 0.281029
Train loss on 100 batch: 0.284251
Train loss on 150 batch: 0.269977
Train loss on 200 batch: 0.237814
Train loss on 250 batch: 0.273640
Train loss on 300 batch: 0.292768
Train loss on 350 batch: 0.247027
Train loss on 400 batch: 0.288720
Train loss on 450 batch: 0.237978
Train loss on 500 batch: 0.279786
Train loss on 550 batch: 0.250880
Train loss on 600 batch: 0.254053
Train loss on 650 batch: 0.255871
Train loss on 700 batch: 0.347290
Train loss on 750 batch: 0.271967
Train loss on 800 batch: 0.249789
Train loss on 850 batch: 0.306471
Train loss on 900 batch: 0.264880
Train loss on 950 batch: 0.226056
Train loss on 1000 batch: 0.241748
Train loss on 1050 batch: 0.238459
Train loss on 1100 batch: 0.286977
Train loss on 1150 batch: 0.266240
Train loss on 1200 batch: 0.277729
Train loss on 1250 batch: 0.256157
Train loss on 1300 batch: 0.249496
Train loss on 1350 batch: 0.307635
Train loss on 1400 batch: 0.270845
Train loss on 1450 batch: 0.226312
Train loss on 1500 batch: 0.313785
Train loss on 1550 batch: 0.283188
Train loss on 1600 batch: 0.256487
Train loss on 1650 batch: 0.265237
Train loss on 1700 batch: 0.260629
Train loss on 1750 batch: 0.250397
Train loss on 1800 batch: 0.272122
Train loss on 1850 batch: 0.326180
Train loss on 1900 batch: 0.247211
Train loss on 1950 batch: 0.202341
Train loss on 2000 batch: 0.242077
Train loss on 2050 batch: 0.258113
Train loss on 2100 batch: 0.285897
Train loss on 2150 batch: 0.276248
best-train-loss: 0.267210
best-valid-loss: 0.317842
best-kappa: 0.6903
: Epoch: 29 | Training Loss: 0.267210 | Val. Loss: 0.317842 | Val. Kappa Score: 0.6903 | LR: 0.000071 | Estimated time: 554.58
Train loss on 50 batch: 0.253791
Train loss on 100 batch: 0.232909
Train loss on 150 batch: 0.256494
Train loss on 200 batch: 0.279652
Train loss on 250 batch: 0.278729
Train loss on 300 batch: 0.299483
Train loss on 350 batch: 0.303632
Train loss on 400 batch: 0.256121
Train loss on 450 batch: 0.274013
Train loss on 500 batch: 0.282011
Train loss on 550 batch: 0.222585
Train loss on 600 batch: 0.254773
Train loss on 650 batch: 0.232229
Train loss on 700 batch: 0.267675
Train loss on 750 batch: 0.267384
Train loss on 800 batch: 0.296625
Train loss on 850 batch: 0.274072
Train loss on 900 batch: 0.223711
Train loss on 950 batch: 0.247074
Train loss on 1000 batch: 0.288422
Train loss on 1050 batch: 0.273087
Train loss on 1100 batch: 0.241707
Train loss on 1150 batch: 0.265355
Train loss on 1200 batch: 0.256289
Train loss on 1250 batch: 0.255943
Train loss on 1300 batch: 0.245402
Train loss on 1350 batch: 0.267600
Train loss on 1400 batch: 0.322889
Train loss on 1450 batch: 0.306066
Train loss on 1500 batch: 0.262414
Train loss on 1550 batch: 0.234528
Train loss on 1600 batch: 0.255261
Train loss on 1650 batch: 0.303872
Train loss on 1700 batch: 0.284545
Train loss on 1750 batch: 0.268778
Train loss on 1800 batch: 0.303766
Train loss on 1850 batch: 0.246726
Train loss on 1900 batch: 0.301361
Train loss on 1950 batch: 0.252413
Train loss on 2000 batch: 0.257101
Train loss on 2050 batch: 0.223739
Train loss on 2100 batch: 0.281713
Train loss on 2150 batch: 0.280458
: Epoch: 30 | Training Loss: 0.266879 | Val. Loss: 0.322866 | Val. Kappa Score: 0.6925 | LR: 0.000050 | Estimated time: 554.97
Train loss on 50 batch: 0.292365
Train loss on 100 batch: 0.269865
Train loss on 150 batch: 0.255718
Train loss on 200 batch: 0.271746
Train loss on 250 batch: 0.251202
Train loss on 300 batch: 0.262504
Train loss on 350 batch: 0.253501
Train loss on 400 batch: 0.257309
Train loss on 450 batch: 0.265467
Train loss on 500 batch: 0.294568
Train loss on 550 batch: 0.270793
Train loss on 600 batch: 0.248239
Train loss on 650 batch: 0.239333
Train loss on 700 batch: 0.262943
Train loss on 750 batch: 0.198884
Train loss on 800 batch: 0.234838
Train loss on 850 batch: 0.268245
Train loss on 900 batch: 0.325760
Train loss on 950 batch: 0.255633
Train loss on 1000 batch: 0.305966
Train loss on 1050 batch: 0.260274
Train loss on 1100 batch: 0.300599
Train loss on 1150 batch: 0.278930
Train loss on 1200 batch: 0.227238
Train loss on 1250 batch: 0.267802
Train loss on 1300 batch: 0.232498
Train loss on 1350 batch: 0.273208
Train loss on 1400 batch: 0.278009
Train loss on 1450 batch: 0.260573
Train loss on 1500 batch: 0.265291
Train loss on 1550 batch: 0.274982
Train loss on 1600 batch: 0.254910
Train loss on 1650 batch: 0.273366
Train loss on 1700 batch: 0.205385
Train loss on 1750 batch: 0.274688
Train loss on 1800 batch: 0.229654
Train loss on 1850 batch: 0.284721
Train loss on 1900 batch: 0.213164
Train loss on 1950 batch: 0.283627
Train loss on 2000 batch: 0.266475
Train loss on 2050 batch: 0.241863
Train loss on 2100 batch: 0.252692
Train loss on 2150 batch: 0.278428
: Epoch: 31 | Training Loss: 0.261923 | Val. Loss: 0.322672 | Val. Kappa Score: 0.6946 | LR: 0.000032 | Estimated time: 555.11
Train loss on 50 batch: 0.221370
Train loss on 100 batch: 0.256916
Train loss on 150 batch: 0.210247
Train loss on 200 batch: 0.255601
Train loss on 250 batch: 0.300241
Train loss on 300 batch: 0.256733
Train loss on 350 batch: 0.205809
Train loss on 400 batch: 0.270230
Train loss on 450 batch: 0.251844
Train loss on 500 batch: 0.251316
Train loss on 550 batch: 0.285679
Train loss on 600 batch: 0.234022
Train loss on 650 batch: 0.246722
Train loss on 700 batch: 0.243717
Train loss on 750 batch: 0.297641
Train loss on 800 batch: 0.238384
Train loss on 850 batch: 0.310138
Train loss on 900 batch: 0.260974
Train loss on 950 batch: 0.222670
Train loss on 1000 batch: 0.251576
Train loss on 1050 batch: 0.212616
Train loss on 1100 batch: 0.266511
Train loss on 1150 batch: 0.306023
Train loss on 1200 batch: 0.271231
Train loss on 1250 batch: 0.232538
Train loss on 1300 batch: 0.246884
Train loss on 1350 batch: 0.219841
Train loss on 1400 batch: 0.208398
Train loss on 1450 batch: 0.291217
Train loss on 1500 batch: 0.311709
Train loss on 1550 batch: 0.239882
Train loss on 1600 batch: 0.260805
Train loss on 1650 batch: 0.277259
Train loss on 1700 batch: 0.242444
Train loss on 1750 batch: 0.310216
Train loss on 1800 batch: 0.258442
Train loss on 1850 batch: 0.283932
Train loss on 1900 batch: 0.230467
Train loss on 1950 batch: 0.292497
Train loss on 2000 batch: 0.258102
Train loss on 2050 batch: 0.285709
Train loss on 2100 batch: 0.234795
Train loss on 2150 batch: 0.266188
best-train-loss: 0.257492
best-valid-loss: 0.317829
best-kappa: 0.6968
: Epoch: 32 | Training Loss: 0.257492 | Val. Loss: 0.317829 | Val. Kappa Score: 0.6968 | LR: 0.000018 | Estimated time: 554.84
Train loss on 50 batch: 0.260322
Train loss on 100 batch: 0.282811
Train loss on 150 batch: 0.212429
Train loss on 200 batch: 0.284317
Train loss on 250 batch: 0.274687
Train loss on 300 batch: 0.261592
Train loss on 350 batch: 0.247203
Train loss on 400 batch: 0.245924
Train loss on 450 batch: 0.252087
Train loss on 500 batch: 0.235879
Train loss on 550 batch: 0.284157
Train loss on 600 batch: 0.297937
Train loss on 650 batch: 0.248657
Train loss on 700 batch: 0.275594
Train loss on 750 batch: 0.227229
Train loss on 800 batch: 0.284453
Train loss on 850 batch: 0.262928
Train loss on 900 batch: 0.250232
Train loss on 950 batch: 0.258139
Train loss on 1000 batch: 0.245887
Train loss on 1050 batch: 0.248399
Train loss on 1100 batch: 0.246757
Train loss on 1150 batch: 0.289687
Train loss on 1200 batch: 0.275193
Train loss on 1250 batch: 0.258097
Train loss on 1300 batch: 0.258065
Train loss on 1350 batch: 0.253084
Train loss on 1400 batch: 0.231758
Train loss on 1450 batch: 0.257848
Train loss on 1500 batch: 0.286659
Train loss on 1550 batch: 0.264083
Train loss on 1600 batch: 0.262200
Train loss on 1650 batch: 0.244085
Train loss on 1700 batch: 0.283335
Train loss on 1750 batch: 0.234586
Train loss on 1800 batch: 0.216059
Train loss on 1850 batch: 0.274089
Train loss on 1900 batch: 0.292486
Train loss on 1950 batch: 0.299351
Train loss on 2000 batch: 0.239183
Train loss on 2050 batch: 0.278354
Train loss on 2100 batch: 0.269464
Train loss on 2150 batch: 0.306852
best-train-loss: 0.262402
best-valid-loss: 0.316845
best-kappa: 0.6987
: Epoch: 33 | Training Loss: 0.262402 | Val. Loss: 0.316845 | Val. Kappa Score: 0.6987 | LR: 0.000008 | Estimated time: 555.14
Train loss on 50 batch: 0.250508
Train loss on 100 batch: 0.251422
Train loss on 150 batch: 0.259608
Train loss on 200 batch: 0.231515
Train loss on 250 batch: 0.263237
Train loss on 300 batch: 0.235806
Train loss on 350 batch: 0.279631
Train loss on 400 batch: 0.271523
Train loss on 450 batch: 0.282740
Train loss on 500 batch: 0.286037
Train loss on 550 batch: 0.292033
Train loss on 600 batch: 0.281346
Train loss on 650 batch: 0.254059
Train loss on 700 batch: 0.245181
Train loss on 750 batch: 0.239251
Train loss on 800 batch: 0.238938
Train loss on 850 batch: 0.250682
Train loss on 900 batch: 0.272154
Train loss on 950 batch: 0.249846
Train loss on 1000 batch: 0.242997
Train loss on 1050 batch: 0.282134
Train loss on 1100 batch: 0.260529
Train loss on 1150 batch: 0.268718
Train loss on 1200 batch: 0.239258
Train loss on 1250 batch: 0.255258
Train loss on 1300 batch: 0.271531
Train loss on 1350 batch: 0.293941
Train loss on 1400 batch: 0.261307
Train loss on 1450 batch: 0.248981
Train loss on 1500 batch: 0.208486
Train loss on 1550 batch: 0.297257
Train loss on 1600 batch: 0.228226
Train loss on 1650 batch: 0.240825
Train loss on 1700 batch: 0.274403
Train loss on 1750 batch: 0.277493
Train loss on 1800 batch: 0.220081
Train loss on 1850 batch: 0.242056
Train loss on 1900 batch: 0.275674
Train loss on 1950 batch: 0.277689
Train loss on 2000 batch: 0.264101
Train loss on 2050 batch: 0.270800
Train loss on 2100 batch: 0.221068
Train loss on 2150 batch: 0.274683
best-train-loss: 0.260083
best-valid-loss: 0.315942
best-kappa: 0.7002
: Epoch: 34 | Training Loss: 0.260083 | Val. Loss: 0.315942 | Val. Kappa Score: 0.7002 | LR: 0.000002 | Estimated time: 554.71
Train loss on 50 batch: 0.250741
Train loss on 100 batch: 0.242298
Train loss on 150 batch: 0.287774
Train loss on 200 batch: 0.247412
Train loss on 250 batch: 0.234402
Train loss on 300 batch: 0.269555
Train loss on 350 batch: 0.225874
Train loss on 400 batch: 0.287708
Train loss on 450 batch: 0.279304
Train loss on 500 batch: 0.293010
Train loss on 550 batch: 0.272924
Train loss on 600 batch: 0.262563
Train loss on 650 batch: 0.305487
Train loss on 700 batch: 0.271648
Train loss on 750 batch: 0.215887
Train loss on 800 batch: 0.235834
Train loss on 850 batch: 0.236450
Train loss on 900 batch: 0.221638
Train loss on 950 batch: 0.274944
Train loss on 1000 batch: 0.251556
Train loss on 1050 batch: 0.220501
Train loss on 1100 batch: 0.223365
Train loss on 1150 batch: 0.240814
Train loss on 1200 batch: 0.221523
Train loss on 1250 batch: 0.258183
Train loss on 1300 batch: 0.264359
Train loss on 1350 batch: 0.273812
Train loss on 1400 batch: 0.272298
Train loss on 1450 batch: 0.217763
Train loss on 1500 batch: 0.292644
Train loss on 1550 batch: 0.274119
Train loss on 1600 batch: 0.230463
Train loss on 1650 batch: 0.275991
Train loss on 1700 batch: 0.228920
Train loss on 1750 batch: 0.235759
Train loss on 1800 batch: 0.267866
Train loss on 1850 batch: 0.280428
Train loss on 1900 batch: 0.227615
Train loss on 1950 batch: 0.252770
Train loss on 2000 batch: 0.260979
Train loss on 2050 batch: 0.245610
Train loss on 2100 batch: 0.257578
Train loss on 2150 batch: 0.277379
: Epoch: 35 | Training Loss: 0.254825 | Val. Loss: 0.316006 | Val. Kappa Score: 0.7020 | LR: 0.000000 | Estimated time: 555.16
Train loss on 50 batch: 0.223992
Train loss on 100 batch: 0.269577
Train loss on 150 batch: 0.273340
Train loss on 200 batch: 0.273256
Train loss on 250 batch: 0.264249
Train loss on 300 batch: 0.255066
Train loss on 350 batch: 0.224674
Train loss on 400 batch: 0.262952
Train loss on 450 batch: 0.218136
Train loss on 500 batch: 0.273613
Train loss on 550 batch: 0.267106
Train loss on 600 batch: 0.255885
Train loss on 650 batch: 0.230238
Train loss on 700 batch: 0.230897
Train loss on 750 batch: 0.268741
Train loss on 800 batch: 0.244089
Train loss on 850 batch: 0.259812
Train loss on 900 batch: 0.263620
Train loss on 950 batch: 0.255224
Train loss on 1000 batch: 0.209228
Train loss on 1050 batch: 0.204396
Train loss on 1100 batch: 0.291916
Train loss on 1150 batch: 0.301942
Train loss on 1200 batch: 0.292423
Train loss on 1250 batch: 0.242830
Train loss on 1300 batch: 0.242181
Train loss on 1350 batch: 0.269150
Train loss on 1400 batch: 0.278110
Train loss on 1450 batch: 0.225006
Train loss on 1500 batch: 0.263465
Train loss on 1550 batch: 0.280930
Train loss on 1600 batch: 0.327885
Train loss on 1650 batch: 0.258378
Train loss on 1700 batch: 0.261027
Train loss on 1750 batch: 0.229120
Train loss on 1800 batch: 0.273958
Train loss on 1850 batch: 0.270347
Train loss on 1900 batch: 0.250586
Train loss on 1950 batch: 0.297661
Train loss on 2000 batch: 0.276856
Train loss on 2050 batch: 0.268340
Train loss on 2100 batch: 0.258406
Train loss on 2150 batch: 0.242291
: Epoch: 36 | Training Loss: 0.258645 | Val. Loss: 0.316517 | Val. Kappa Score: 0.7032 | LR: 0.000002 | Estimated time: 554.75
Train loss on 50 batch: 0.227901
Train loss on 100 batch: 0.264006
Train loss on 150 batch: 0.267020
Train loss on 200 batch: 0.249674
Train loss on 250 batch: 0.273545
Train loss on 300 batch: 0.253011
Train loss on 350 batch: 0.265064
Train loss on 400 batch: 0.278022
Train loss on 450 batch: 0.293583
Train loss on 500 batch: 0.270677
Train loss on 550 batch: 0.212291
Train loss on 600 batch: 0.227223
Train loss on 650 batch: 0.238354
Train loss on 700 batch: 0.271710
Train loss on 750 batch: 0.274377
Train loss on 800 batch: 0.211278
Train loss on 850 batch: 0.266147
Train loss on 900 batch: 0.248115
Train loss on 950 batch: 0.233613
Train loss on 1000 batch: 0.232335
Train loss on 1050 batch: 0.271056
Train loss on 1100 batch: 0.254502
Train loss on 1150 batch: 0.274973
Train loss on 1200 batch: 0.243771
Train loss on 1250 batch: 0.261722
Train loss on 1300 batch: 0.275606
Train loss on 1350 batch: 0.289551
Train loss on 1400 batch: 0.257480
Train loss on 1450 batch: 0.267066
Train loss on 1500 batch: 0.238088
Train loss on 1550 batch: 0.230197
Train loss on 1600 batch: 0.218778
Train loss on 1650 batch: 0.248868
Train loss on 1700 batch: 0.282743
Train loss on 1750 batch: 0.280855
Train loss on 1800 batch: 0.269596
Train loss on 1850 batch: 0.214811
Train loss on 1900 batch: 0.245696
Train loss on 1950 batch: 0.270341
Train loss on 2000 batch: 0.239757
Train loss on 2050 batch: 0.294214
Train loss on 2100 batch: 0.260929
Train loss on 2150 batch: 0.292182
: Epoch: 37 | Training Loss: 0.256315 | Val. Loss: 0.317455 | Val. Kappa Score: 0.7046 | LR: 0.000008 | Estimated time: 554.90
Train loss on 50 batch: 0.234784
Train loss on 100 batch: 0.251769
Train loss on 150 batch: 0.253333
Train loss on 200 batch: 0.268695
Train loss on 250 batch: 0.248054
Train loss on 300 batch: 0.269089
Train loss on 350 batch: 0.232156
Train loss on 400 batch: 0.244320
Train loss on 450 batch: 0.246944
Train loss on 500 batch: 0.290970
Train loss on 550 batch: 0.230894
Train loss on 600 batch: 0.261153
Train loss on 650 batch: 0.236919
Train loss on 700 batch: 0.261098
Train loss on 750 batch: 0.280196
Train loss on 800 batch: 0.276572
Train loss on 850 batch: 0.273204
Train loss on 900 batch: 0.271293
Train loss on 950 batch: 0.278921
Train loss on 1000 batch: 0.226595
Train loss on 1050 batch: 0.246566
Train loss on 1100 batch: 0.293080
Train loss on 1150 batch: 0.262232
Train loss on 1200 batch: 0.268582
Train loss on 1250 batch: 0.269618
Train loss on 1300 batch: 0.246018
Train loss on 1350 batch: 0.260989
Train loss on 1400 batch: 0.284250
Train loss on 1450 batch: 0.242244
Train loss on 1500 batch: 0.255716
Train loss on 1550 batch: 0.261867
Train loss on 1600 batch: 0.238689
Train loss on 1650 batch: 0.266147
Train loss on 1700 batch: 0.273632
Train loss on 1750 batch: 0.266175
Train loss on 1800 batch: 0.314485
Train loss on 1850 batch: 0.304355
Train loss on 1900 batch: 0.238560
Train loss on 1950 batch: 0.213977
Train loss on 2000 batch: 0.251978
Train loss on 2050 batch: 0.243024
Train loss on 2100 batch: 0.226320
Train loss on 2150 batch: 0.267931
: Epoch: 38 | Training Loss: 0.258694 | Val. Loss: 0.317759 | Val. Kappa Score: 0.7059 | LR: 0.000018 | Estimated time: 555.28
Train loss on 50 batch: 0.243172
Train loss on 100 batch: 0.244503
Train loss on 150 batch: 0.305929
Train loss on 200 batch: 0.322601
Train loss on 250 batch: 0.212741
Train loss on 300 batch: 0.259037
Train loss on 350 batch: 0.275090
Train loss on 400 batch: 0.255948
Train loss on 450 batch: 0.255825
Train loss on 500 batch: 0.259503
Train loss on 550 batch: 0.243372
Train loss on 600 batch: 0.225551
Train loss on 650 batch: 0.230746
Train loss on 700 batch: 0.315532
Train loss on 750 batch: 0.232879
Train loss on 800 batch: 0.245293
Train loss on 850 batch: 0.237484
Train loss on 900 batch: 0.292277
Train loss on 950 batch: 0.251690
Train loss on 1000 batch: 0.298393
Train loss on 1050 batch: 0.253584
Train loss on 1100 batch: 0.222444
Train loss on 1150 batch: 0.249876
Train loss on 1200 batch: 0.260012
Train loss on 1250 batch: 0.272811
Train loss on 1300 batch: 0.271022
Train loss on 1350 batch: 0.247780
Train loss on 1400 batch: 0.182365
Train loss on 1450 batch: 0.324674
Train loss on 1500 batch: 0.271497
Train loss on 1550 batch: 0.282371
Train loss on 1600 batch: 0.254822
Train loss on 1650 batch: 0.245253
Train loss on 1700 batch: 0.237714
Train loss on 1750 batch: 0.267191
Train loss on 1800 batch: 0.264140
Train loss on 1850 batch: 0.242301
Train loss on 1900 batch: 0.230441
Train loss on 1950 batch: 0.272140
Train loss on 2000 batch: 0.282730
Train loss on 2050 batch: 0.272392
Train loss on 2100 batch: 0.197227
Train loss on 2150 batch: 0.251440
: Epoch: 39 | Training Loss: 0.257902 | Val. Loss: 0.318935 | Val. Kappa Score: 0.7074 | LR: 0.000032 | Estimated time: 555.03
Train loss on 50 batch: 0.243778
Train loss on 100 batch: 0.282502
Train loss on 150 batch: 0.280645
Train loss on 200 batch: 0.278954
Train loss on 250 batch: 0.273456
Train loss on 300 batch: 0.287817
Train loss on 350 batch: 0.247591
Train loss on 400 batch: 0.288935
Train loss on 450 batch: 0.210556
Train loss on 500 batch: 0.269819
Train loss on 550 batch: 0.264187
Train loss on 600 batch: 0.196280
Train loss on 650 batch: 0.182169
Train loss on 700 batch: 0.194960
Train loss on 750 batch: 0.274640
Train loss on 800 batch: 0.245582
Train loss on 850 batch: 0.278980
Train loss on 900 batch: 0.256222
Train loss on 950 batch: 0.250962
Train loss on 1000 batch: 0.324701
Train loss on 1050 batch: 0.265705
Train loss on 1100 batch: 0.214335
Train loss on 1150 batch: 0.224949
Train loss on 1200 batch: 0.242315
Train loss on 1250 batch: 0.293641
Train loss on 1300 batch: 0.254828
Train loss on 1350 batch: 0.260459
Train loss on 1400 batch: 0.255013
Train loss on 1450 batch: 0.234304
Train loss on 1500 batch: 0.326712
Train loss on 1550 batch: 0.246092
Train loss on 1600 batch: 0.242970
Train loss on 1650 batch: 0.226748
Train loss on 1700 batch: 0.265612
Train loss on 1750 batch: 0.261920
Train loss on 1800 batch: 0.274437
Train loss on 1850 batch: 0.250400
Train loss on 1900 batch: 0.319669
Train loss on 1950 batch: 0.258556
Train loss on 2000 batch: 0.261808
Train loss on 2050 batch: 0.240431
Train loss on 2100 batch: 0.253548
Train loss on 2150 batch: 0.237821
: Epoch: 40 | Training Loss: 0.256219 | Val. Loss: 0.320026 | Val. Kappa Score: 0.7088 | LR: 0.000050 | Estimated time: 555.08
Train loss on 50 batch: 0.246037
Train loss on 100 batch: 0.271795
Train loss on 150 batch: 0.244268
Train loss on 200 batch: 0.232958
Train loss on 250 batch: 0.219900
Train loss on 300 batch: 0.273068
Train loss on 350 batch: 0.290358
Train loss on 400 batch: 0.225717
Train loss on 450 batch: 0.280536
Train loss on 500 batch: 0.216376
Train loss on 550 batch: 0.260529
Train loss on 600 batch: 0.246459
Train loss on 650 batch: 0.271981
Train loss on 700 batch: 0.256046
Train loss on 750 batch: 0.271641
Train loss on 800 batch: 0.208705
Train loss on 850 batch: 0.228899
Train loss on 900 batch: 0.253290
Train loss on 950 batch: 0.247458
Train loss on 1000 batch: 0.265932
Train loss on 1050 batch: 0.226277
Train loss on 1100 batch: 0.241840
Train loss on 1150 batch: 0.281511
Train loss on 1200 batch: 0.264247
Train loss on 1250 batch: 0.218165
Train loss on 1300 batch: 0.289802
Train loss on 1350 batch: 0.244627
Train loss on 1400 batch: 0.295933
Train loss on 1450 batch: 0.236580
Train loss on 1500 batch: 0.308964
Train loss on 1550 batch: 0.294655
Train loss on 1600 batch: 0.256406
Train loss on 1650 batch: 0.269100
Train loss on 1700 batch: 0.244098
Train loss on 1750 batch: 0.270516
Train loss on 1800 batch: 0.234744
Train loss on 1850 batch: 0.229553
Train loss on 1900 batch: 0.245451
Train loss on 1950 batch: 0.282047
Train loss on 2000 batch: 0.308187
Train loss on 2050 batch: 0.263232
Train loss on 2100 batch: 0.314218
Train loss on 2150 batch: 0.266663
: Epoch: 41 | Training Loss: 0.259289 | Val. Loss: 0.324849 | Val. Kappa Score: 0.7097 | LR: 0.000071 | Estimated time: 555.09
Train loss on 50 batch: 0.253661
Train loss on 100 batch: 0.310447
Train loss on 150 batch: 0.281305
Train loss on 200 batch: 0.237085
Train loss on 250 batch: 0.318001
Train loss on 300 batch: 0.272491
Train loss on 350 batch: 0.264904
Train loss on 400 batch: 0.243343
Train loss on 450 batch: 0.218918
Train loss on 500 batch: 0.231254
Train loss on 550 batch: 0.257615
Train loss on 600 batch: 0.236090
Train loss on 650 batch: 0.262385
Train loss on 700 batch: 0.245113
Train loss on 750 batch: 0.243096
Train loss on 800 batch: 0.233438
Train loss on 850 batch: 0.268111
Train loss on 900 batch: 0.269884
Train loss on 950 batch: 0.241857
Train loss on 1000 batch: 0.292940
Train loss on 1050 batch: 0.286846
Train loss on 1100 batch: 0.261099
Train loss on 1150 batch: 0.247856
Train loss on 1200 batch: 0.275656
Train loss on 1250 batch: 0.248878
Train loss on 1300 batch: 0.232033
Train loss on 1350 batch: 0.241082
Train loss on 1400 batch: 0.312467
Train loss on 1450 batch: 0.209480
Train loss on 1500 batch: 0.261277
Train loss on 1550 batch: 0.209499
Train loss on 1600 batch: 0.264496
Train loss on 1650 batch: 0.279711
Train loss on 1700 batch: 0.241025
Train loss on 1750 batch: 0.254758
Train loss on 1800 batch: 0.267483
Train loss on 1850 batch: 0.210320
Train loss on 1900 batch: 0.293053
Train loss on 1950 batch: 0.249684
Train loss on 2000 batch: 0.265269
Train loss on 2050 batch: 0.254960
Train loss on 2100 batch: 0.261565
Train loss on 2150 batch: 0.329067
: Epoch: 42 | Training Loss: 0.259304 | Val. Loss: 0.334792 | Val. Kappa Score: 0.7105 | LR: 0.000095 | Estimated time: 554.88
Train loss on 50 batch: 0.260602
Train loss on 100 batch: 0.259258
Train loss on 150 batch: 0.250921
Train loss on 200 batch: 0.238907
Train loss on 250 batch: 0.248324
Train loss on 300 batch: 0.252554
Train loss on 350 batch: 0.265946
Train loss on 400 batch: 0.273093
Train loss on 450 batch: 0.244032
Train loss on 500 batch: 0.251791
Train loss on 550 batch: 0.242298
Train loss on 600 batch: 0.267462
Train loss on 650 batch: 0.270011
Train loss on 700 batch: 0.230257
Train loss on 750 batch: 0.274134
Train loss on 800 batch: 0.230299
Train loss on 850 batch: 0.254551
Train loss on 900 batch: 0.259985
Train loss on 950 batch: 0.290717
Train loss on 1000 batch: 0.244174
Train loss on 1050 batch: 0.327684
Train loss on 1100 batch: 0.282512
Train loss on 1150 batch: 0.251085
Train loss on 1200 batch: 0.291656
Train loss on 1250 batch: 0.236538
Train loss on 1300 batch: 0.248165
Train loss on 1350 batch: 0.230543
Train loss on 1400 batch: 0.226749
Train loss on 1450 batch: 0.304079
Train loss on 1500 batch: 0.281670
Train loss on 1550 batch: 0.268766
Train loss on 1600 batch: 0.264313
Train loss on 1650 batch: 0.272709
Train loss on 1700 batch: 0.283792
Train loss on 1750 batch: 0.290126
Train loss on 1800 batch: 0.294523
Train loss on 1850 batch: 0.257754
Train loss on 1900 batch: 0.234130
Train loss on 1950 batch: 0.239756
Train loss on 2000 batch: 0.237628
Train loss on 2050 batch: 0.248862
Train loss on 2100 batch: 0.271255
Train loss on 2150 batch: 0.277564
: Epoch: 43 | Training Loss: 0.261478 | Val. Loss: 0.319435 | Val. Kappa Score: 0.7118 | LR: 0.000123 | Estimated time: 554.79
Train loss on 50 batch: 0.259093
Train loss on 100 batch: 0.277671
Train loss on 150 batch: 0.262035
Train loss on 200 batch: 0.266435
Train loss on 250 batch: 0.341558
Train loss on 300 batch: 0.216542
Train loss on 350 batch: 0.270800
Train loss on 400 batch: 0.246278
Train loss on 450 batch: 0.249629
Train loss on 500 batch: 0.256581
Train loss on 550 batch: 0.221292
Train loss on 600 batch: 0.259371
Train loss on 650 batch: 0.317236
Train loss on 700 batch: 0.223289
Train loss on 750 batch: 0.238012
Train loss on 800 batch: 0.299691
Train loss on 850 batch: 0.250841
Train loss on 900 batch: 0.276083
Train loss on 950 batch: 0.252550
Train loss on 1000 batch: 0.264787
Train loss on 1050 batch: 0.260232
Train loss on 1100 batch: 0.253927
Train loss on 1150 batch: 0.271795
Train loss on 1200 batch: 0.253258
Train loss on 1250 batch: 0.257745
Train loss on 1300 batch: 0.225084
Train loss on 1350 batch: 0.271918
Train loss on 1400 batch: 0.227460
Train loss on 1450 batch: 0.253404
Train loss on 1500 batch: 0.250837
Train loss on 1550 batch: 0.249293
Train loss on 1600 batch: 0.286868
Train loss on 1650 batch: 0.285219
Train loss on 1700 batch: 0.227356
Train loss on 1750 batch: 0.279491
Train loss on 1800 batch: 0.231972
Train loss on 1850 batch: 0.282649
Train loss on 1900 batch: 0.235344
Train loss on 1950 batch: 0.275794
Train loss on 2000 batch: 0.318065
Train loss on 2050 batch: 0.262631
Train loss on 2100 batch: 0.260930
Train loss on 2150 batch: 0.247023
: Epoch: 44 | Training Loss: 0.261409 | Val. Loss: 0.322824 | Val. Kappa Score: 0.7127 | LR: 0.000154 | Estimated time: 554.81
Train loss on 50 batch: 0.281762
Train loss on 100 batch: 0.226730
Train loss on 150 batch: 0.276103
Train loss on 200 batch: 0.261419
Train loss on 250 batch: 0.244117
Train loss on 300 batch: 0.327595
Train loss on 350 batch: 0.216332
Train loss on 400 batch: 0.312406
Train loss on 450 batch: 0.252177
Train loss on 500 batch: 0.240658
Train loss on 550 batch: 0.265520
Train loss on 600 batch: 0.275629
Train loss on 650 batch: 0.271196
Train loss on 700 batch: 0.236815
Train loss on 750 batch: 0.227171
Train loss on 800 batch: 0.294367
Train loss on 850 batch: 0.272067
Train loss on 900 batch: 0.255524
Train loss on 950 batch: 0.271717
Train loss on 1000 batch: 0.268089
Train loss on 1050 batch: 0.257563
Train loss on 1100 batch: 0.254918
Train loss on 1150 batch: 0.274350
Train loss on 1200 batch: 0.235352
Train loss on 1250 batch: 0.240948
Train loss on 1300 batch: 0.310568
Train loss on 1350 batch: 0.232358
Train loss on 1400 batch: 0.281832
Train loss on 1450 batch: 0.277305
Train loss on 1500 batch: 0.315384
Train loss on 1550 batch: 0.247655
Train loss on 1600 batch: 0.224891
Train loss on 1650 batch: 0.263220
Train loss on 1700 batch: 0.273918
Train loss on 1750 batch: 0.286280
Train loss on 1800 batch: 0.277500
Train loss on 1850 batch: 0.293939
Train loss on 1900 batch: 0.251380
Train loss on 1950 batch: 0.254522
Train loss on 2000 batch: 0.262424
Train loss on 2050 batch: 0.241440
Train loss on 2100 batch: 0.271102
Train loss on 2150 batch: 0.267586
: Epoch: 45 | Training Loss: 0.264880 | Val. Loss: 0.333874 | Val. Kappa Score: 0.7133 | LR: 0.000188 | Estimated time: 555.02
Train loss on 50 batch: 0.230628
Train loss on 100 batch: 0.294886
Train loss on 150 batch: 0.231902
Train loss on 200 batch: 0.282644
Train loss on 250 batch: 0.256752
Train loss on 300 batch: 0.211746
Train loss on 350 batch: 0.305440
Train loss on 400 batch: 0.213310
Train loss on 450 batch: 0.266805
Train loss on 500 batch: 0.307336
Train loss on 550 batch: 0.274634
Train loss on 600 batch: 0.267526
Train loss on 650 batch: 0.272434
Train loss on 700 batch: 0.237285
Train loss on 750 batch: 0.242493
Train loss on 800 batch: 0.298965
Train loss on 850 batch: 0.254366
Train loss on 900 batch: 0.251772
Train loss on 950 batch: 0.245965
Train loss on 1000 batch: 0.235573
Train loss on 1050 batch: 0.258670
Train loss on 1100 batch: 0.253305
Train loss on 1150 batch: 0.297075
Train loss on 1200 batch: 0.258149
Train loss on 1250 batch: 0.247502
Train loss on 1300 batch: 0.280053
Train loss on 1350 batch: 0.288979
Train loss on 1400 batch: 0.280717
Train loss on 1450 batch: 0.286518
Train loss on 1500 batch: 0.248483
Train loss on 1550 batch: 0.284283
Train loss on 1600 batch: 0.293131
Train loss on 1650 batch: 0.257208
Train loss on 1700 batch: 0.305984
Train loss on 1750 batch: 0.235702
Train loss on 1800 batch: 0.282617
Train loss on 1850 batch: 0.252649
Train loss on 1900 batch: 0.220442
Train loss on 1950 batch: 0.266025
Train loss on 2000 batch: 0.273846
Train loss on 2050 batch: 0.249334
Train loss on 2100 batch: 0.282123
Train loss on 2150 batch: 0.261442
: Epoch: 46 | Training Loss: 0.264433 | Val. Loss: 0.330716 | Val. Kappa Score: 0.7143 | LR: 0.000225 | Estimated time: 555.02
Train loss on 50 batch: 0.253303
Train loss on 100 batch: 0.262362
Train loss on 150 batch: 0.267005
Train loss on 200 batch: 0.243606
Train loss on 250 batch: 0.276742
Train loss on 300 batch: 0.287697
Train loss on 350 batch: 0.221803
Train loss on 400 batch: 0.300290
Train loss on 450 batch: 0.298797
Train loss on 500 batch: 0.262755
Train loss on 550 batch: 0.236276
Train loss on 600 batch: 0.228033
Train loss on 650 batch: 0.275233
Train loss on 700 batch: 0.282375
Train loss on 750 batch: 0.264471
Train loss on 800 batch: 0.278124
Train loss on 850 batch: 0.296468
Train loss on 900 batch: 0.301036
Train loss on 950 batch: 0.319864
Train loss on 1000 batch: 0.242391
Train loss on 1050 batch: 0.287667
Train loss on 1100 batch: 0.284236
Train loss on 1150 batch: 0.261519
Train loss on 1200 batch: 0.231457
Train loss on 1250 batch: 0.252878
Train loss on 1300 batch: 0.289108
Train loss on 1350 batch: 0.297519
Train loss on 1400 batch: 0.299151
Train loss on 1450 batch: 0.313742
Train loss on 1500 batch: 0.246509
Train loss on 1550 batch: 0.274239
Train loss on 1600 batch: 0.258647
Train loss on 1650 batch: 0.269784
Train loss on 1700 batch: 0.234471
Train loss on 1750 batch: 0.262122
Train loss on 1800 batch: 0.260716
Train loss on 1850 batch: 0.274476
Train loss on 1900 batch: 0.262581
Train loss on 1950 batch: 0.252246
Train loss on 2000 batch: 0.279244
Train loss on 2050 batch: 0.233513
Train loss on 2100 batch: 0.278261
Train loss on 2150 batch: 0.261245
: Epoch: 47 | Training Loss: 0.269514 | Val. Loss: 0.332063 | Val. Kappa Score: 0.7154 | LR: 0.000263 | Estimated time: 555.15
Train loss on 50 batch: 0.306954
Train loss on 100 batch: 0.270562
Train loss on 150 batch: 0.281876
Train loss on 200 batch: 0.230587
Train loss on 250 batch: 0.217690
Train loss on 300 batch: 0.234074
Train loss on 350 batch: 0.276328
Train loss on 400 batch: 0.288629
Train loss on 450 batch: 0.289550
Train loss on 500 batch: 0.305942
Train loss on 550 batch: 0.304894
Train loss on 600 batch: 0.316135
Train loss on 650 batch: 0.301454
Train loss on 700 batch: 0.233395
Train loss on 750 batch: 0.296946
Train loss on 800 batch: 0.240739
Train loss on 850 batch: 0.297548
Train loss on 900 batch: 0.247472
Train loss on 950 batch: 0.289541
Train loss on 1000 batch: 0.273113
Train loss on 1050 batch: 0.291420
Train loss on 1100 batch: 0.243810
Train loss on 1150 batch: 0.205922
Train loss on 1200 batch: 0.251411
Train loss on 1250 batch: 0.297342
Train loss on 1300 batch: 0.283518
Train loss on 1350 batch: 0.305356
Train loss on 1400 batch: 0.294308
Train loss on 1450 batch: 0.274076
Train loss on 1500 batch: 0.297167
Train loss on 1550 batch: 0.256254
Train loss on 1600 batch: 0.225644
Train loss on 1650 batch: 0.302866
Train loss on 1700 batch: 0.252357
Train loss on 1750 batch: 0.257445
Train loss on 1800 batch: 0.268785
Train loss on 1850 batch: 0.318125
Train loss on 1900 batch: 0.270372
Train loss on 1950 batch: 0.276591
Train loss on 2000 batch: 0.269587
Train loss on 2050 batch: 0.267983
Train loss on 2100 batch: 0.239333
Train loss on 2150 batch: 0.233550
: Epoch: 48 | Training Loss: 0.271364 | Val. Loss: 0.330472 | Val. Kappa Score: 0.7159 | LR: 0.000303 | Estimated time: 554.88
Train loss on 50 batch: 0.228740
Train loss on 100 batch: 0.300081
Train loss on 150 batch: 0.251935
Train loss on 200 batch: 0.267401
Train loss on 250 batch: 0.248138
Train loss on 300 batch: 0.279030
Train loss on 350 batch: 0.286469
Train loss on 400 batch: 0.285507
Train loss on 450 batch: 0.303220
Train loss on 500 batch: 0.230212
Train loss on 550 batch: 0.274914
Train loss on 600 batch: 0.244893
Train loss on 650 batch: 0.314291
Train loss on 700 batch: 0.256198
Train loss on 750 batch: 0.235803
Train loss on 800 batch: 0.272212
Train loss on 850 batch: 0.324577
Train loss on 900 batch: 0.269990
Train loss on 950 batch: 0.280736
Train loss on 1000 batch: 0.260399
Train loss on 1050 batch: 0.266323
Train loss on 1100 batch: 0.312723
Train loss on 1150 batch: 0.302535
Train loss on 1200 batch: 0.270163
Train loss on 1250 batch: 0.292394
Train loss on 1300 batch: 0.273770
Train loss on 1350 batch: 0.262579
Train loss on 1400 batch: 0.272829
Train loss on 1450 batch: 0.303921
Train loss on 1500 batch: 0.299862
Train loss on 1550 batch: 0.263028
Train loss on 1600 batch: 0.272548
Train loss on 1650 batch: 0.216356
Train loss on 1700 batch: 0.279739
Train loss on 1750 batch: 0.269621
Train loss on 1800 batch: 0.236951
Train loss on 1850 batch: 0.272690
Train loss on 1900 batch: 0.330308
Train loss on 1950 batch: 0.302160
Train loss on 2000 batch: 0.325304
Train loss on 2050 batch: 0.360708
Train loss on 2100 batch: 0.251420
Train loss on 2150 batch: 0.300387
: Epoch: 49 | Training Loss: 0.278709 | Val. Loss: 0.485363 | Val. Kappa Score: 0.7124 | LR: 0.000345 | Estimated time: 555.00
Train loss on 50 batch: 0.239191
Train loss on 100 batch: 0.251220
Train loss on 150 batch: 0.285548
Train loss on 200 batch: 0.269217
Train loss on 250 batch: 0.241527
Train loss on 300 batch: 0.268663
Train loss on 350 batch: 0.328927
Train loss on 400 batch: 0.253821
Train loss on 450 batch: 0.273711
Train loss on 500 batch: 0.249396
Train loss on 550 batch: 0.292135
Train loss on 600 batch: 0.288479
Train loss on 650 batch: 0.263451
Train loss on 700 batch: 0.278152
Train loss on 750 batch: 0.301331
Train loss on 800 batch: 0.224914
Train loss on 850 batch: 0.317868
Train loss on 900 batch: 0.282097
Train loss on 950 batch: 0.248910
Train loss on 1000 batch: 0.282283
Train loss on 1050 batch: 0.262719
Train loss on 1100 batch: 0.266934
Train loss on 1150 batch: 0.290200
Train loss on 1200 batch: 0.235263
Train loss on 1250 batch: 0.289715
Train loss on 1300 batch: 0.245772
Train loss on 1350 batch: 0.274697
Train loss on 1400 batch: 0.279965
Train loss on 1450 batch: 0.311117
Train loss on 1500 batch: 0.301635
Train loss on 1550 batch: 0.273451
Train loss on 1600 batch: 0.328556
Train loss on 1650 batch: 0.289852
Train loss on 1700 batch: 0.321962
Train loss on 1750 batch: 0.269643
Train loss on 1800 batch: 0.237501
Train loss on 1850 batch: 0.313764
Train loss on 1900 batch: 0.330247
Train loss on 1950 batch: 0.297221
Train loss on 2000 batch: 0.257983
Train loss on 2050 batch: 0.275907
Train loss on 2100 batch: 0.293732
Train loss on 2150 batch: 0.299428
: Epoch: 50 | Training Loss: 0.279572 | Val. Loss: 0.340186 | Val. Kappa Score: 0.7131 | LR: 0.000389 | Estimated time: 554.97
Train loss on 50 batch: 0.291580
Train loss on 100 batch: 0.301899
Train loss on 150 batch: 0.326881
Train loss on 200 batch: 0.234301
Train loss on 250 batch: 0.336830
Train loss on 300 batch: 0.278033
Train loss on 350 batch: 0.291167
Train loss on 400 batch: 0.278677
Train loss on 450 batch: 0.271689
Train loss on 500 batch: 0.252142
Train loss on 550 batch: 0.257481
Train loss on 600 batch: 0.264821
Train loss on 650 batch: 0.229866
Train loss on 700 batch: 0.330538
Train loss on 750 batch: 0.286126
Train loss on 800 batch: 0.251155
Train loss on 850 batch: 0.311522
Train loss on 900 batch: 0.253257
Train loss on 950 batch: 0.275599
Train loss on 1000 batch: 0.289381
Train loss on 1050 batch: 0.295423
Train loss on 1100 batch: 0.248290
Train loss on 1150 batch: 0.252326
Train loss on 1200 batch: 0.306265
Train loss on 1250 batch: 0.312497
Train loss on 1300 batch: 0.246303
Train loss on 1350 batch: 0.273189
Train loss on 1400 batch: 0.272643
Train loss on 1450 batch: 0.268441
Train loss on 1500 batch: 0.334859
Train loss on 1550 batch: 0.245098
Train loss on 1600 batch: 0.293406
Train loss on 1650 batch: 0.347715
Train loss on 1700 batch: 0.290133
Train loss on 1750 batch: 0.281738
Train loss on 1800 batch: 0.326237
Train loss on 1850 batch: 0.259671
Train loss on 1900 batch: 0.258409
Train loss on 1950 batch: 0.264879
Train loss on 2000 batch: 0.297054
Train loss on 2050 batch: 0.358776
Train loss on 2100 batch: 0.256799
Train loss on 2150 batch: 0.318414
: Epoch: 51 | Training Loss: 0.283864 | Val. Loss: 0.349750 | Val. Kappa Score: 0.7136 | LR: 0.000433 | Estimated time: 555.42
Train loss on 50 batch: 0.272875
Train loss on 100 batch: 0.235627
Train loss on 150 batch: 0.296494
Train loss on 200 batch: 0.340375
Train loss on 250 batch: 0.291040
Train loss on 300 batch: 0.278545
Train loss on 350 batch: 0.304024
Train loss on 400 batch: 0.325429
Train loss on 450 batch: 0.345914
Train loss on 500 batch: 0.298718
Train loss on 550 batch: 0.292626
Train loss on 600 batch: 0.284710
Train loss on 650 batch: 0.278341
Train loss on 700 batch: 0.326857
Train loss on 750 batch: 0.292681
Train loss on 800 batch: 0.303101
Train loss on 850 batch: 0.297339
Train loss on 900 batch: 0.260443
Train loss on 950 batch: 0.246432
Train loss on 1000 batch: 0.285430
Train loss on 1050 batch: 0.271434
Train loss on 1100 batch: 0.268996
Train loss on 1150 batch: 0.237587
Train loss on 1200 batch: 0.298337
Train loss on 1250 batch: 0.323475
Train loss on 1300 batch: 0.282643
Train loss on 1350 batch: 0.282076
Train loss on 1400 batch: 0.339239
Train loss on 1450 batch: 0.317004
Train loss on 1500 batch: 0.285790
Train loss on 1550 batch: 0.273117
Train loss on 1600 batch: 0.244426
Train loss on 1650 batch: 0.259600
Train loss on 1700 batch: 0.280401
Train loss on 1750 batch: 0.286869
Train loss on 1800 batch: 0.271739
Train loss on 1850 batch: 0.271210
Train loss on 1900 batch: 0.305503
Train loss on 1950 batch: 0.320192
Train loss on 2000 batch: 0.306488
Train loss on 2050 batch: 0.298198
Train loss on 2100 batch: 0.244488
Train loss on 2150 batch: 0.312392
: Epoch: 52 | Training Loss: 0.290180 | Val. Loss: 0.368516 | Val. Kappa Score: 0.7145 | LR: 0.000478 | Estimated time: 555.22
Train loss on 50 batch: 0.249222
Train loss on 100 batch: 0.260845
Train loss on 150 batch: 0.275583
Train loss on 200 batch: 0.299939
Train loss on 250 batch: 0.297199
Train loss on 300 batch: 0.315816
Train loss on 350 batch: 0.275655
Train loss on 400 batch: 0.320773
Train loss on 450 batch: 0.273327
Train loss on 500 batch: 0.236408
Train loss on 550 batch: 0.280594
Train loss on 600 batch: 0.340827
Train loss on 650 batch: 0.298085
Train loss on 700 batch: 0.320559
Train loss on 750 batch: 0.292777
Train loss on 800 batch: 0.345645
Train loss on 850 batch: 0.254478
Train loss on 900 batch: 0.292694
Train loss on 950 batch: 0.242852
Train loss on 1000 batch: 0.265319
Train loss on 1050 batch: 0.300867
Train loss on 1100 batch: 0.274644
Train loss on 1150 batch: 0.307682
Train loss on 1200 batch: 0.310376
Train loss on 1250 batch: 0.275791
Train loss on 1300 batch: 0.340708
Train loss on 1350 batch: 0.316570
Train loss on 1400 batch: 0.283744
Train loss on 1450 batch: 0.306879
Train loss on 1500 batch: 0.270153
Train loss on 1550 batch: 0.251726
Train loss on 1600 batch: 0.285409
Train loss on 1650 batch: 0.335023
Train loss on 1700 batch: 0.302046
Train loss on 1750 batch: 0.273104
Train loss on 1800 batch: 0.331411
Train loss on 1850 batch: 0.286815
Train loss on 1900 batch: 0.272159
Train loss on 1950 batch: 0.306934
Train loss on 2000 batch: 0.327036
Train loss on 2050 batch: 0.345969
Train loss on 2100 batch: 0.346117
Train loss on 2150 batch: 0.286960
: Epoch: 53 | Training Loss: 0.296066 | Val. Loss: 0.370150 | Val. Kappa Score: 0.7148 | LR: 0.000522 | Estimated time: 554.88
Train loss on 50 batch: 0.295886
Train loss on 100 batch: 0.291356
Train loss on 150 batch: 0.307761
Train loss on 200 batch: 0.304806
Train loss on 250 batch: 0.255407
Train loss on 300 batch: 0.255998
Train loss on 350 batch: 0.276274
Train loss on 400 batch: 0.300045
Train loss on 450 batch: 0.324516
Train loss on 500 batch: 0.358733
Train loss on 550 batch: 0.289745
Train loss on 600 batch: 0.257146
Train loss on 650 batch: 0.236771
Train loss on 700 batch: 0.298608
Train loss on 750 batch: 0.329483
Train loss on 800 batch: 0.308218
Train loss on 850 batch: 0.296947
Train loss on 900 batch: 0.287215
Train loss on 950 batch: 0.297285
Train loss on 1000 batch: 0.269064
Train loss on 1050 batch: 0.278557
Train loss on 1100 batch: 0.323532
Train loss on 1150 batch: 0.321018
Train loss on 1200 batch: 0.295506
Train loss on 1250 batch: 0.274189
Train loss on 1300 batch: 0.347851
Train loss on 1350 batch: 0.297416
Train loss on 1400 batch: 0.300633
Train loss on 1450 batch: 0.261486
Train loss on 1500 batch: 0.328576
Train loss on 1550 batch: 0.301966
Train loss on 1600 batch: 0.324652
Train loss on 1650 batch: 0.271931
Train loss on 1700 batch: 0.279653
Train loss on 1750 batch: 0.307379
Train loss on 1800 batch: 0.303732
Train loss on 1850 batch: 0.350572
Train loss on 1900 batch: 0.305842
Train loss on 1950 batch: 0.251795
Train loss on 2000 batch: 0.351416
Train loss on 2050 batch: 0.289081
Train loss on 2100 batch: 0.326994
Train loss on 2150 batch: 0.314242
: Epoch: 54 | Training Loss: 0.298702 | Val. Loss: 0.347478 | Val. Kappa Score: 0.7149 | LR: 0.000567 | Estimated time: 554.81
Train loss on 50 batch: 0.282968
Train loss on 100 batch: 0.314142
Train loss on 150 batch: 0.290158
Train loss on 200 batch: 0.322696
Train loss on 250 batch: 0.323277
Train loss on 300 batch: 0.313462
Train loss on 350 batch: 0.292586
Train loss on 400 batch: 0.335737
Train loss on 450 batch: 0.299103
Train loss on 500 batch: 0.354202
Train loss on 550 batch: 0.272116
Train loss on 600 batch: 0.321618
Train loss on 650 batch: 0.301778
Train loss on 700 batch: 0.322951
Train loss on 750 batch: 0.293723
Train loss on 800 batch: 0.338616
Train loss on 850 batch: 0.321542
Train loss on 900 batch: 0.318637
Train loss on 950 batch: 0.276367
Train loss on 1000 batch: 0.347175
Train loss on 1050 batch: 0.294471
Train loss on 1100 batch: 0.308539
Train loss on 1150 batch: 0.269408
Train loss on 1200 batch: 0.332126
Train loss on 1250 batch: 0.287977
Train loss on 1300 batch: 0.329743
Train loss on 1350 batch: 0.332532
Train loss on 1400 batch: 0.295557
Train loss on 1450 batch: 0.320634
Train loss on 1500 batch: 0.316833
Train loss on 1550 batch: 0.274334
Train loss on 1600 batch: 0.225809
Train loss on 1650 batch: 0.367783
Train loss on 1700 batch: 0.298523
Train loss on 1750 batch: 0.344929
Train loss on 1800 batch: 0.350505
Train loss on 1850 batch: 0.292973
Train loss on 1900 batch: 0.346623
Train loss on 1950 batch: 0.247806
Train loss on 2000 batch: 0.324426
Train loss on 2050 batch: 0.277076
Train loss on 2100 batch: 0.269403
Train loss on 2150 batch: 0.311688
: Epoch: 55 | Training Loss: 0.307550 | Val. Loss: 0.323823 | Val. Kappa Score: 0.7156 | LR: 0.000611 | Estimated time: 555.19
Train loss on 50 batch: 0.258615
Train loss on 100 batch: 0.327225
Train loss on 150 batch: 0.311763
Train loss on 200 batch: 0.314272
Train loss on 250 batch: 0.306411
Train loss on 300 batch: 0.272469
Train loss on 350 batch: 0.293881
Train loss on 400 batch: 0.287007
Train loss on 450 batch: 0.322926
Train loss on 500 batch: 0.315312
Train loss on 550 batch: 0.254214
Train loss on 600 batch: 0.282006
Train loss on 650 batch: 0.358120
Train loss on 700 batch: 0.345023
Train loss on 750 batch: 0.303468
Train loss on 800 batch: 0.298272
Train loss on 850 batch: 0.237416
Train loss on 900 batch: 0.320129
Train loss on 950 batch: 0.339131
Train loss on 1000 batch: 0.317797
Train loss on 1050 batch: 0.339362
Train loss on 1100 batch: 0.265706
Train loss on 1150 batch: 0.362520
Train loss on 1200 batch: 0.255639
Train loss on 1250 batch: 0.287212
Train loss on 1300 batch: 0.331307
Train loss on 1350 batch: 0.298885
Train loss on 1400 batch: 0.304483
Train loss on 1450 batch: 0.348541
Train loss on 1500 batch: 0.334099
Train loss on 1550 batch: 0.321289
Train loss on 1600 batch: 0.333360
Train loss on 1650 batch: 0.331629
Train loss on 1700 batch: 0.279238
Train loss on 1750 batch: 0.340760
Train loss on 1800 batch: 0.343574
Train loss on 1850 batch: 0.317874
Train loss on 1900 batch: 0.349465
Train loss on 1950 batch: 0.321559
Train loss on 2000 batch: 0.268797
Train loss on 2050 batch: 0.328982
Train loss on 2100 batch: 0.290221
Train loss on 2150 batch: 0.250697
: Epoch: 56 | Training Loss: 0.308113 | Val. Loss: 0.383420 | Val. Kappa Score: 0.7154 | LR: 0.000655 | Estimated time: 554.88
Train loss on 50 batch: 0.294497
Train loss on 100 batch: 0.277618
Train loss on 150 batch: 0.278999
Train loss on 200 batch: 0.336835
Train loss on 250 batch: 0.334727
Train loss on 300 batch: 0.290030
Train loss on 350 batch: 0.333103
Train loss on 400 batch: 0.272081
Train loss on 450 batch: 0.318213
Train loss on 500 batch: 0.353021
Train loss on 550 batch: 0.272455
Train loss on 600 batch: 0.247484
Train loss on 650 batch: 0.340700
Train loss on 700 batch: 0.276004
Train loss on 750 batch: 0.323736
Train loss on 800 batch: 0.282063
Train loss on 850 batch: 0.384684
Train loss on 900 batch: 0.278488
Train loss on 950 batch: 0.282333
Train loss on 1000 batch: 0.302054
Train loss on 1050 batch: 0.292403
Train loss on 1100 batch: 0.335709
Train loss on 1150 batch: 0.294352
Train loss on 1200 batch: 0.340042
Train loss on 1250 batch: 0.319068
Train loss on 1300 batch: 0.323818
Train loss on 1350 batch: 0.298267
Train loss on 1400 batch: 0.334823
Train loss on 1450 batch: 0.337029
Train loss on 1500 batch: 0.251844
Train loss on 1550 batch: 0.274723
Train loss on 1600 batch: 0.342646
Train loss on 1650 batch: 0.328534
Train loss on 1700 batch: 0.328358
Train loss on 1750 batch: 0.280751
Train loss on 1800 batch: 0.336281
Train loss on 1850 batch: 0.337809
Train loss on 1900 batch: 0.338793
Train loss on 1950 batch: 0.331276
Train loss on 2000 batch: 0.287405
Train loss on 2050 batch: 0.341848
Train loss on 2100 batch: 0.328637
Train loss on 2150 batch: 0.331354
: Epoch: 57 | Training Loss: 0.312208 | Val. Loss: 0.427754 | Val. Kappa Score: 0.7148 | LR: 0.000697 | Estimated time: 555.12
Train loss on 50 batch: 0.256692
Train loss on 100 batch: 0.325487
Train loss on 150 batch: 0.311930
Train loss on 200 batch: 0.323619
Train loss on 250 batch: 0.342590
Train loss on 300 batch: 0.319897
Train loss on 350 batch: 0.300812
Train loss on 400 batch: 0.316381
Train loss on 450 batch: 0.354758
Train loss on 500 batch: 0.329798
Train loss on 550 batch: 0.313867
Train loss on 600 batch: 0.341086
Train loss on 650 batch: 0.314226
Train loss on 700 batch: 0.250522
Train loss on 750 batch: 0.271227
Train loss on 800 batch: 0.297862
Train loss on 850 batch: 0.296541
Train loss on 900 batch: 0.307937
Train loss on 950 batch: 0.376627
Train loss on 1000 batch: 0.342527
Train loss on 1050 batch: 0.315884
Train loss on 1100 batch: 0.312342
Train loss on 1150 batch: 0.322575
Train loss on 1200 batch: 0.358928
Train loss on 1250 batch: 0.315567
Train loss on 1300 batch: 0.275932
Train loss on 1350 batch: 0.301252
Train loss on 1400 batch: 0.346998
Train loss on 1450 batch: 0.326873
Train loss on 1500 batch: 0.285970
Train loss on 1550 batch: 0.291665
Train loss on 1600 batch: 0.346314
Train loss on 1650 batch: 0.274479
Train loss on 1700 batch: 0.321769
Train loss on 1750 batch: 0.287410
Train loss on 1800 batch: 0.345604
Train loss on 1850 batch: 0.365649
Train loss on 1900 batch: 0.322789
Train loss on 1950 batch: 0.297494
Train loss on 2000 batch: 0.312003
Train loss on 2050 batch: 0.240248
Train loss on 2100 batch: 0.291482
Train loss on 2150 batch: 0.297802
: Epoch: 58 | Training Loss: 0.314942 | Val. Loss: 0.379939 | Val. Kappa Score: 0.7149 | LR: 0.000737 | Estimated time: 555.03
Train loss on 50 batch: 0.331370
Train loss on 100 batch: 0.358281
Train loss on 150 batch: 0.293988
Train loss on 200 batch: 0.259648
Train loss on 250 batch: 0.327297
Train loss on 300 batch: 0.307761
Train loss on 350 batch: 0.257925
Train loss on 400 batch: 0.369321
Train loss on 450 batch: 0.390008
Train loss on 500 batch: 0.303509
Train loss on 550 batch: 0.377098
Train loss on 600 batch: 0.340133
Train loss on 650 batch: 0.337140
Train loss on 700 batch: 0.303597
Train loss on 750 batch: 0.324329
Train loss on 800 batch: 0.327552
Train loss on 850 batch: 0.339555
Train loss on 900 batch: 0.344229
Train loss on 950 batch: 0.294793
Train loss on 1000 batch: 0.283515
Train loss on 1050 batch: 0.333170
Train loss on 1100 batch: 0.365228
Train loss on 1150 batch: 0.378796
Train loss on 1200 batch: 0.275623
Train loss on 1250 batch: 0.321827
Train loss on 1300 batch: 0.298383
Train loss on 1350 batch: 0.285142
Train loss on 1400 batch: 0.358046
Train loss on 1450 batch: 0.351601
Train loss on 1500 batch: 0.326942
Train loss on 1550 batch: 0.300896
Train loss on 1600 batch: 0.332475
Train loss on 1650 batch: 0.376346
Train loss on 1700 batch: 0.288852
Train loss on 1750 batch: 0.311018
Train loss on 1800 batch: 0.280924
Train loss on 1850 batch: 0.297763
Train loss on 1900 batch: 0.368617
Train loss on 1950 batch: 0.310230
Train loss on 2000 batch: 0.344969
Train loss on 2050 batch: 0.298371
Train loss on 2100 batch: 0.325542
Train loss on 2150 batch: 0.332512
: Epoch: 59 | Training Loss: 0.324049 | Val. Loss: 0.624530 | Val. Kappa Score: 0.7133 | LR: 0.000775 | Estimated time: 555.10
Train loss on 50 batch: 0.287273
Train loss on 100 batch: 0.274505
Train loss on 150 batch: 0.331381
Train loss on 200 batch: 0.292284
Train loss on 250 batch: 0.352584
Train loss on 300 batch: 0.306365
Train loss on 350 batch: 0.313116
Train loss on 400 batch: 0.319077
Train loss on 450 batch: 0.345381
Train loss on 500 batch: 0.331659
Train loss on 550 batch: 0.329711
Train loss on 600 batch: 0.283264
Train loss on 650 batch: 0.325928
Train loss on 700 batch: 0.312688
Train loss on 750 batch: 0.320484
Train loss on 800 batch: 0.328263
Train loss on 850 batch: 0.334605
Train loss on 900 batch: 0.313575
Train loss on 950 batch: 0.299165
Train loss on 1000 batch: 0.260632
Train loss on 1050 batch: 0.344138
Train loss on 1100 batch: 0.319031
Train loss on 1150 batch: 0.300959
Train loss on 1200 batch: 0.302390
Train loss on 1250 batch: 0.295773
Train loss on 1300 batch: 0.318797
Train loss on 1350 batch: 0.347528
Train loss on 1400 batch: 0.340311
Train loss on 1450 batch: 0.320730
Train loss on 1500 batch: 0.338472
Train loss on 1550 batch: 0.312499
Train loss on 1600 batch: 0.325463
Train loss on 1650 batch: 0.348636
Train loss on 1700 batch: 0.341920
Train loss on 1750 batch: 0.282266
Train loss on 1800 batch: 0.334004
Train loss on 1850 batch: 0.334351
Train loss on 1900 batch: 0.342624
Train loss on 1950 batch: 0.413744
Train loss on 2000 batch: 0.353032
Train loss on 2050 batch: 0.360720
Train loss on 2100 batch: 0.273374
Train loss on 2150 batch: 0.318520
: Epoch: 60 | Training Loss: 0.321013 | Val. Loss: 0.390091 | Val. Kappa Score: 0.7138 | LR: 0.000812 | Estimated time: 555.00
Train loss on 50 batch: 0.279573
Train loss on 100 batch: 0.339769
Train loss on 150 batch: 0.342595
Train loss on 200 batch: 0.314427
Train loss on 250 batch: 0.369240
Train loss on 300 batch: 0.380289
Train loss on 350 batch: 0.298344
Train loss on 400 batch: 0.322405
Train loss on 450 batch: 0.358272
Train loss on 500 batch: 0.321809
Train loss on 550 batch: 0.324919
Train loss on 600 batch: 0.312842
Train loss on 650 batch: 0.338892
Train loss on 700 batch: 0.298924
Train loss on 750 batch: 0.335746
Train loss on 800 batch: 0.350555
Train loss on 850 batch: 0.309271
Train loss on 900 batch: 0.418032
Train loss on 950 batch: 0.336502
Train loss on 1000 batch: 0.376195
Train loss on 1050 batch: 0.288676
Train loss on 1100 batch: 0.291941
Train loss on 1150 batch: 0.330037
Train loss on 1200 batch: 0.320082
Train loss on 1250 batch: 0.383228
Train loss on 1300 batch: 0.313015
Train loss on 1350 batch: 0.291153
Train loss on 1400 batch: 0.364928
Train loss on 1450 batch: 0.341824
Train loss on 1500 batch: 0.340454
Train loss on 1550 batch: 0.347929
Train loss on 1600 batch: 0.342557
Train loss on 1650 batch: 0.293487
Train loss on 1700 batch: 0.310083
Train loss on 1750 batch: 0.329908
Train loss on 1800 batch: 0.298970
Train loss on 1850 batch: 0.276304
Train loss on 1900 batch: 0.365090
Train loss on 1950 batch: 0.298436
Train loss on 2000 batch: 0.383598
Train loss on 2050 batch: 0.337942
Train loss on 2100 batch: 0.308169
Train loss on 2150 batch: 0.345120
: Epoch: 61 | Training Loss: 0.330092 | Val. Loss: 0.434101 | Val. Kappa Score: 0.7132 | LR: 0.000846 | Estimated time: 554.67
Train loss on 50 batch: 0.370295
Train loss on 100 batch: 0.341111
Train loss on 150 batch: 0.315871
Train loss on 200 batch: 0.351222
Train loss on 250 batch: 0.340648
Train loss on 300 batch: 0.340132
Train loss on 350 batch: 0.335567
Train loss on 400 batch: 0.341443
Train loss on 450 batch: 0.307953
Train loss on 500 batch: 0.342675
Train loss on 550 batch: 0.353166
Train loss on 600 batch: 0.351572
Train loss on 650 batch: 0.319626
Train loss on 700 batch: 0.337648
Train loss on 750 batch: 0.315931
Train loss on 800 batch: 0.329839
Train loss on 850 batch: 0.333400
Train loss on 900 batch: 0.295181
Train loss on 950 batch: 0.310120
Train loss on 1000 batch: 0.331453
Train loss on 1050 batch: 0.279223
Train loss on 1100 batch: 0.307193
Train loss on 1150 batch: 0.340432
Train loss on 1200 batch: 0.373367
Train loss on 1250 batch: 0.346282
Train loss on 1300 batch: 0.268082
Train loss on 1350 batch: 0.374913
Train loss on 1400 batch: 0.379359
Train loss on 1450 batch: 0.321734
Train loss on 1500 batch: 0.338139
Train loss on 1550 batch: 0.336254
Train loss on 1600 batch: 0.334812
Train loss on 1650 batch: 0.353321
Train loss on 1700 batch: 0.310495
Train loss on 1750 batch: 0.282428
Train loss on 1800 batch: 0.326555
Train loss on 1850 batch: 0.353471
Train loss on 1900 batch: 0.377685
Train loss on 1950 batch: 0.283055
Train loss on 2000 batch: 0.402914
Train loss on 2050 batch: 0.376593
Train loss on 2100 batch: 0.321461
Train loss on 2150 batch: 0.300811
: Epoch: 62 | Training Loss: 0.333326 | Val. Loss: 0.741499 | Val. Kappa Score: 0.7092 | LR: 0.000877 | Estimated time: 555.10
Train loss on 50 batch: 0.333721
Train loss on 100 batch: 0.339729
Train loss on 150 batch: 0.309138
Train loss on 200 batch: 0.339050
Train loss on 250 batch: 0.333835
Train loss on 300 batch: 0.303702
Train loss on 350 batch: 0.342235
Train loss on 400 batch: 0.375291
Train loss on 450 batch: 0.349139
Train loss on 500 batch: 0.322216
Train loss on 550 batch: 0.419877
Train loss on 600 batch: 0.357040
Train loss on 650 batch: 0.334551
Train loss on 700 batch: 0.268308
Train loss on 750 batch: 0.319333
Train loss on 800 batch: 0.329927
Train loss on 850 batch: 0.310959
Train loss on 900 batch: 0.304228
Train loss on 950 batch: 0.344816
Train loss on 1000 batch: 0.317036
Train loss on 1050 batch: 0.350910
Train loss on 1100 batch: 0.288283
Train loss on 1150 batch: 0.285776
Train loss on 1200 batch: 0.366927
Train loss on 1250 batch: 0.329548
Train loss on 1300 batch: 0.344417
Train loss on 1350 batch: 0.346526
Train loss on 1400 batch: 0.262139
Train loss on 1450 batch: 0.336275
Train loss on 1500 batch: 0.342385
Train loss on 1550 batch: 0.371866
Train loss on 1600 batch: 0.311285
Train loss on 1650 batch: 0.333504
Train loss on 1700 batch: 0.357152
Train loss on 1750 batch: 0.363683
Train loss on 1800 batch: 0.397538
Train loss on 1850 batch: 0.298960
Train loss on 1900 batch: 0.326960
Train loss on 1950 batch: 0.325517
Train loss on 2000 batch: 0.382777
Train loss on 2050 batch: 0.359778
Train loss on 2100 batch: 0.327448
Train loss on 2150 batch: 0.385385
: Epoch: 63 | Training Loss: 0.335864 | Val. Loss: 0.351409 | Val. Kappa Score: 0.7095 | LR: 0.000905 | Estimated time: 554.92
Train loss on 50 batch: 0.346020
Train loss on 100 batch: 0.355024
Train loss on 150 batch: 0.396081
Train loss on 200 batch: 0.367692
Train loss on 250 batch: 0.281971
Train loss on 300 batch: 0.327605
Train loss on 350 batch: 0.379548
Train loss on 400 batch: 0.307246
Train loss on 450 batch: 0.339809
Train loss on 500 batch: 0.303316
Train loss on 550 batch: 0.304125
Train loss on 600 batch: 0.279156
Train loss on 650 batch: 0.362062
Train loss on 700 batch: 0.326505
Train loss on 750 batch: 0.394778
Train loss on 800 batch: 0.339613
Train loss on 850 batch: 0.310012
Train loss on 900 batch: 0.343504
Train loss on 950 batch: 0.302003
Train loss on 1000 batch: 0.327503
Train loss on 1050 batch: 0.318838
Train loss on 1100 batch: 0.326299
Train loss on 1150 batch: 0.276011
Train loss on 1200 batch: 0.349392
Train loss on 1250 batch: 0.353892
Train loss on 1300 batch: 0.370120
Train loss on 1350 batch: 0.361563
Train loss on 1400 batch: 0.319361
Train loss on 1450 batch: 0.291917
Train loss on 1500 batch: 0.353118
Train loss on 1550 batch: 0.400815
Train loss on 1600 batch: 0.354723
Train loss on 1650 batch: 0.338193
Train loss on 1700 batch: 0.303246
Train loss on 1750 batch: 0.307603
Train loss on 1800 batch: 0.349277
Train loss on 1850 batch: 0.302390
Train loss on 1900 batch: 0.312789
Train loss on 1950 batch: 0.355693
Train loss on 2000 batch: 0.360726
Train loss on 2050 batch: 0.355292
Train loss on 2100 batch: 0.327359
Train loss on 2150 batch: 0.302812
: Epoch: 64 | Training Loss: 0.334734 | Val. Loss: 0.387113 | Val. Kappa Score: 0.7099 | LR: 0.000929 | Estimated time: 555.02
Train loss on 50 batch: 0.312841
Train loss on 100 batch: 0.368962
Train loss on 150 batch: 0.307351
Train loss on 200 batch: 0.347214
Train loss on 250 batch: 0.304251
Train loss on 300 batch: 0.317877
Train loss on 350 batch: 0.305101
Train loss on 400 batch: 0.375882
Train loss on 450 batch: 0.295174
Train loss on 500 batch: 0.279115
Train loss on 550 batch: 0.329014
Train loss on 600 batch: 0.342304
Train loss on 650 batch: 0.350429
Train loss on 700 batch: 0.330711
Train loss on 750 batch: 0.385192
Train loss on 800 batch: 0.300280
Train loss on 850 batch: 0.340985
Train loss on 900 batch: 0.347151
Train loss on 950 batch: 0.317140
Train loss on 1000 batch: 0.382071
Train loss on 1050 batch: 0.355579
Train loss on 1100 batch: 0.318753
Train loss on 1150 batch: 0.306606
Train loss on 1200 batch: 0.318855
Train loss on 1250 batch: 0.306276
Train loss on 1300 batch: 0.334576
Train loss on 1350 batch: 0.285432
Train loss on 1400 batch: 0.301535
Train loss on 1450 batch: 0.357271
Train loss on 1500 batch: 0.293368
Train loss on 1550 batch: 0.346988
Train loss on 1600 batch: 0.338070
Train loss on 1650 batch: 0.299895
Train loss on 1700 batch: 0.333987
Train loss on 1750 batch: 0.343672
Train loss on 1800 batch: 0.367456
Train loss on 1850 batch: 0.370996
Train loss on 1900 batch: 0.354239
Train loss on 1950 batch: 0.348369
Train loss on 2000 batch: 0.431027
Train loss on 2050 batch: 0.346197
Train loss on 2100 batch: 0.336180
Train loss on 2150 batch: 0.301665
: Epoch: 65 | Training Loss: 0.333572 | Val. Loss: 0.363084 | Val. Kappa Score: 0.7100 | LR: 0.000950 | Estimated time: 554.96
Train loss on 50 batch: 0.337021
Train loss on 100 batch: 0.369405
Train loss on 150 batch: 0.394656
Train loss on 200 batch: 0.355790
Train loss on 250 batch: 0.351497
Train loss on 300 batch: 0.363537
Train loss on 350 batch: 0.393767
Train loss on 400 batch: 0.348202
Train loss on 450 batch: 0.304270
Train loss on 500 batch: 0.355781
Train loss on 550 batch: 0.326397
Train loss on 600 batch: 0.341048
Train loss on 650 batch: 0.310935
Train loss on 700 batch: 0.375821
Train loss on 750 batch: 0.322726
Train loss on 800 batch: 0.314830
Train loss on 850 batch: 0.301185
Train loss on 900 batch: 0.346837
Train loss on 950 batch: 0.367583
Train loss on 1000 batch: 0.288733
Train loss on 1050 batch: 0.365600
Train loss on 1100 batch: 0.410301
Train loss on 1150 batch: 0.281906
Train loss on 1200 batch: 0.364451
Train loss on 1250 batch: 0.347178
Train loss on 1300 batch: 0.360934
Train loss on 1350 batch: 0.368617
Train loss on 1400 batch: 0.303036
Train loss on 1450 batch: 0.290922
Train loss on 1500 batch: 0.347112
Train loss on 1550 batch: 0.342740
Train loss on 1600 batch: 0.349440
Train loss on 1650 batch: 0.294843
Train loss on 1700 batch: 0.346652
Train loss on 1750 batch: 0.288173
Train loss on 1800 batch: 0.357782
Train loss on 1850 batch: 0.266509
Train loss on 1900 batch: 0.263980
Train loss on 1950 batch: 0.343330
Train loss on 2000 batch: 0.301676
Train loss on 2050 batch: 0.328878
Train loss on 2100 batch: 0.328187
Train loss on 2150 batch: 0.322660
: Epoch: 66 | Training Loss: 0.335749 | Val. Loss: 0.385062 | Val. Kappa Score: 0.7102 | LR: 0.000968 | Estimated time: 554.84
Train loss on 50 batch: 0.341576
Train loss on 100 batch: 0.348262
Train loss on 150 batch: 0.326041
Train loss on 200 batch: 0.381636
Train loss on 250 batch: 0.293934
Train loss on 300 batch: 0.293578
Train loss on 350 batch: 0.390685
Train loss on 400 batch: 0.346421
Train loss on 450 batch: 0.355944
Train loss on 500 batch: 0.293422
Train loss on 550 batch: 0.313494
Train loss on 600 batch: 0.333089
Train loss on 650 batch: 0.307885
Train loss on 700 batch: 0.371611
Train loss on 750 batch: 0.356336
Train loss on 800 batch: 0.355233
Train loss on 850 batch: 0.370658
Train loss on 900 batch: 0.279865
Train loss on 950 batch: 0.268272
Train loss on 1000 batch: 0.372203
Train loss on 1050 batch: 0.338232
Train loss on 1100 batch: 0.357554
Train loss on 1150 batch: 0.373329
Train loss on 1200 batch: 0.386692
Train loss on 1250 batch: 0.358629
Train loss on 1300 batch: 0.318198
Train loss on 1350 batch: 0.325695
Train loss on 1400 batch: 0.318358
Train loss on 1450 batch: 0.346599
Train loss on 1500 batch: 0.310896
Train loss on 1550 batch: 0.303511
Train loss on 1600 batch: 0.396793
Train loss on 1650 batch: 0.399213
Train loss on 1700 batch: 0.292926
Train loss on 1750 batch: 0.347809
Train loss on 1800 batch: 0.330509
Train loss on 1850 batch: 0.306649
Train loss on 1900 batch: 0.344790
Train loss on 1950 batch: 0.378390
Train loss on 2000 batch: 0.357166
Train loss on 2050 batch: 0.367913
Train loss on 2100 batch: 0.375824
Train loss on 2150 batch: 0.342917
: Epoch: 67 | Training Loss: 0.340859 | Val. Loss: 0.500811 | Val. Kappa Score: 0.7096 | LR: 0.000982 | Estimated time: 555.01
Train loss on 50 batch: 0.336536
Train loss on 100 batch: 0.334613
Train loss on 150 batch: 0.296236
Train loss on 200 batch: 0.289463
Train loss on 250 batch: 0.314821
Train loss on 300 batch: 0.317572
Train loss on 350 batch: 0.279846
Train loss on 400 batch: 0.372839
Train loss on 450 batch: 0.359122
Train loss on 500 batch: 0.376411
Train loss on 550 batch: 0.312578
Train loss on 600 batch: 0.346496
Train loss on 650 batch: 0.306430
Train loss on 700 batch: 0.298729
Train loss on 750 batch: 0.393702
Train loss on 800 batch: 0.297400
Train loss on 850 batch: 0.341744
Train loss on 900 batch: 0.367246
Train loss on 950 batch: 0.327947
Train loss on 1000 batch: 0.289832
Train loss on 1050 batch: 0.340866
Train loss on 1100 batch: 0.343209
Train loss on 1150 batch: 0.357800
Train loss on 1200 batch: 0.322630
Train loss on 1250 batch: 0.385080
Train loss on 1300 batch: 0.376491
Train loss on 1350 batch: 0.376294
Train loss on 1400 batch: 0.346073
Train loss on 1450 batch: 0.345778
Train loss on 1500 batch: 0.324189
Train loss on 1550 batch: 0.347071
Train loss on 1600 batch: 0.363517
Train loss on 1650 batch: 0.340702
Train loss on 1700 batch: 0.318821
Train loss on 1750 batch: 0.348667
Train loss on 1800 batch: 0.335873
Train loss on 1850 batch: 0.364074
Train loss on 1900 batch: 0.329835
Train loss on 1950 batch: 0.284283
Train loss on 2000 batch: 0.241373
Train loss on 2050 batch: 0.332165
Train loss on 2100 batch: 0.345769
Train loss on 2150 batch: 0.333266
: Epoch: 68 | Training Loss: 0.333148 | Val. Loss: 0.480721 | Val. Kappa Score: 0.7088 | LR: 0.000992 | Estimated time: 554.63
Train loss on 50 batch: 0.342800
Train loss on 100 batch: 0.330930
Train loss on 150 batch: 0.332664
Train loss on 200 batch: 0.302007
Train loss on 250 batch: 0.307511
Train loss on 300 batch: 0.357124
Train loss on 350 batch: 0.325758
Train loss on 400 batch: 0.389006
Train loss on 450 batch: 0.308778
Train loss on 500 batch: 0.316900
Train loss on 550 batch: 0.368864
Train loss on 600 batch: 0.305567
Train loss on 650 batch: 0.277989
Train loss on 700 batch: 0.320343
Train loss on 750 batch: 0.386617
Train loss on 800 batch: 0.332595
Train loss on 850 batch: 0.329695
Train loss on 900 batch: 0.308677
Train loss on 950 batch: 0.384899
Train loss on 1000 batch: 0.283900
Train loss on 1050 batch: 0.295825
Train loss on 1100 batch: 0.355059
Train loss on 1150 batch: 0.356827
Train loss on 1200 batch: 0.378626
Train loss on 1250 batch: 0.355916
Train loss on 1300 batch: 0.322061
Train loss on 1350 batch: 0.362448
Train loss on 1400 batch: 0.306946
Train loss on 1450 batch: 0.337293
Train loss on 1500 batch: 0.301635
Train loss on 1550 batch: 0.350021
Train loss on 1600 batch: 0.335261
Train loss on 1650 batch: 0.265492
Train loss on 1700 batch: 0.369273
Train loss on 1750 batch: 0.392759
Train loss on 1800 batch: 0.355767
Train loss on 1850 batch: 0.332239
Train loss on 1900 batch: 0.337588
Train loss on 1950 batch: 0.318113
Train loss on 2000 batch: 0.248668
Train loss on 2050 batch: 0.348360
Train loss on 2100 batch: 0.305586
Train loss on 2150 batch: 0.379905
: Epoch: 69 | Training Loss: 0.332217 | Val. Loss: 0.382124 | Val. Kappa Score: 0.7086 | LR: 0.000998 | Estimated time: 554.58
Train loss on 50 batch: 0.293312
Train loss on 100 batch: 0.282191
Train loss on 150 batch: 0.341704
Train loss on 200 batch: 0.349115
Train loss on 250 batch: 0.321667
Train loss on 300 batch: 0.329040
Train loss on 350 batch: 0.324208
Train loss on 400 batch: 0.371805
Train loss on 450 batch: 0.373688
Train loss on 500 batch: 0.310475
Train loss on 550 batch: 0.347983
Train loss on 600 batch: 0.365951
Train loss on 650 batch: 0.360120
Train loss on 700 batch: 0.282554
Train loss on 750 batch: 0.314757
Train loss on 800 batch: 0.309230
Train loss on 850 batch: 0.352146
Train loss on 900 batch: 0.423135
Train loss on 950 batch: 0.354540
Train loss on 1000 batch: 0.324507
Train loss on 1050 batch: 0.331998
Train loss on 1100 batch: 0.375068
Train loss on 1150 batch: 0.354612
Train loss on 1200 batch: 0.321638
Train loss on 1250 batch: 0.332703
Train loss on 1300 batch: 0.290366
Train loss on 1350 batch: 0.295665
Train loss on 1400 batch: 0.267973
Train loss on 1450 batch: 0.392178
Train loss on 1500 batch: 0.283203
Train loss on 1550 batch: 0.364425
Train loss on 1600 batch: 0.331485
Train loss on 1650 batch: 0.350667
Train loss on 1700 batch: 0.333809
Train loss on 1750 batch: 0.303140
Train loss on 1800 batch: 0.354591
Train loss on 1850 batch: 0.342055
Train loss on 1900 batch: 0.315960
Train loss on 1950 batch: 0.315020
Train loss on 2000 batch: 0.320107
Train loss on 2050 batch: 0.410964
Train loss on 2100 batch: 0.348240
Train loss on 2150 batch: 0.343976
: Epoch: 70 | Training Loss: 0.334555 | Val. Loss: 0.343447 | Val. Kappa Score: 0.7091 | LR: 0.001000 | Estimated time: 554.69
Train loss on 50 batch: 0.323148
Train loss on 100 batch: 0.384562
Train loss on 150 batch: 0.271629
Train loss on 200 batch: 0.348133
Train loss on 250 batch: 0.358704
Train loss on 300 batch: 0.367930
Train loss on 350 batch: 0.386338
Train loss on 400 batch: 0.310904
Train loss on 450 batch: 0.366796
Train loss on 500 batch: 0.310881
Train loss on 550 batch: 0.315861
Train loss on 600 batch: 0.337603
Train loss on 650 batch: 0.368414
Train loss on 700 batch: 0.302467
Train loss on 750 batch: 0.336668
Train loss on 800 batch: 0.326753
Train loss on 850 batch: 0.327950
Train loss on 900 batch: 0.352778
Train loss on 950 batch: 0.303248
Train loss on 1000 batch: 0.361815
Train loss on 1050 batch: 0.319302
Train loss on 1100 batch: 0.279910
Train loss on 1150 batch: 0.343397
Train loss on 1200 batch: 0.330435
Train loss on 1250 batch: 0.294282
Train loss on 1300 batch: 0.344633
Train loss on 1350 batch: 0.350675
Train loss on 1400 batch: 0.320231
Train loss on 1450 batch: 0.312699
Train loss on 1500 batch: 0.354315
Train loss on 1550 batch: 0.361691
Train loss on 1600 batch: 0.357951
Train loss on 1650 batch: 0.312011
Train loss on 1700 batch: 0.299841
Train loss on 1750 batch: 0.329113
Train loss on 1800 batch: 0.368906
Train loss on 1850 batch: 0.341693
Train loss on 1900 batch: 0.356423
Train loss on 1950 batch: 0.322968
Train loss on 2000 batch: 0.330063
Train loss on 2050 batch: 0.280742
Train loss on 2100 batch: 0.341006
Train loss on 2150 batch: 0.316030
: Epoch: 71 | Training Loss: 0.332585 | Val. Loss: 0.379894 | Val. Kappa Score: 0.7092 | LR: 0.000998 | Estimated time: 554.90
Train loss on 50 batch: 0.361968
Train loss on 100 batch: 0.356907
Train loss on 150 batch: 0.329827
Train loss on 200 batch: 0.307797
Train loss on 250 batch: 0.301757
Train loss on 300 batch: 0.311977
Train loss on 350 batch: 0.321245
Train loss on 400 batch: 0.277110
Train loss on 450 batch: 0.361475
Train loss on 500 batch: 0.289873
Train loss on 550 batch: 0.321316
Train loss on 600 batch: 0.324491
Train loss on 650 batch: 0.391721
Train loss on 700 batch: 0.305647
Train loss on 750 batch: 0.336436
Train loss on 800 batch: 0.308008
Train loss on 850 batch: 0.307256
Train loss on 900 batch: 0.359422
Train loss on 950 batch: 0.325835
Train loss on 1000 batch: 0.336544
Train loss on 1050 batch: 0.351471
Train loss on 1100 batch: 0.364470
Train loss on 1150 batch: 0.289388
Train loss on 1200 batch: 0.308341
Train loss on 1250 batch: 0.346166
Train loss on 1300 batch: 0.320057
Train loss on 1350 batch: 0.382009
Train loss on 1400 batch: 0.320204
Train loss on 1450 batch: 0.334650
Train loss on 1500 batch: 0.343014
Train loss on 1550 batch: 0.332487
Train loss on 1600 batch: 0.296341
Train loss on 1650 batch: 0.334638
Train loss on 1700 batch: 0.271936
Train loss on 1750 batch: 0.289187
Train loss on 1800 batch: 0.342481
Train loss on 1850 batch: 0.308812
Train loss on 1900 batch: 0.372681
Train loss on 1950 batch: 0.367162
Train loss on 2000 batch: 0.292878
Train loss on 2050 batch: 0.362157
Train loss on 2100 batch: 0.322923
Train loss on 2150 batch: 0.317457
: Epoch: 72 | Training Loss: 0.328465 | Val. Loss: 0.419269 | Val. Kappa Score: 0.7086 | LR: 0.000992 | Estimated time: 554.71
Train loss on 50 batch: 0.335701
Train loss on 100 batch: 0.337779
Train loss on 150 batch: 0.303610
Train loss on 200 batch: 0.295474
Train loss on 250 batch: 0.311728
Train loss on 300 batch: 0.313330
Train loss on 350 batch: 0.306137
Train loss on 400 batch: 0.384832
Train loss on 450 batch: 0.308442
Train loss on 500 batch: 0.314670
Train loss on 550 batch: 0.395692
Train loss on 600 batch: 0.353848
Train loss on 650 batch: 0.385215
Train loss on 700 batch: 0.327780
Train loss on 750 batch: 0.344305
Train loss on 800 batch: 0.314641
Train loss on 850 batch: 0.363360
Train loss on 900 batch: 0.309234
Train loss on 950 batch: 0.342478
Train loss on 1000 batch: 0.375406
Train loss on 1050 batch: 0.353852
Train loss on 1100 batch: 0.321271
Train loss on 1150 batch: 0.334731
Train loss on 1200 batch: 0.335567
Train loss on 1250 batch: 0.305731
Train loss on 1300 batch: 0.331455
Train loss on 1350 batch: 0.292307
Train loss on 1400 batch: 0.293101
Train loss on 1450 batch: 0.313496
Train loss on 1500 batch: 0.282775
Train loss on 1550 batch: 0.344100
Train loss on 1600 batch: 0.298103
Train loss on 1650 batch: 0.321640
Train loss on 1700 batch: 0.319464
Train loss on 1750 batch: 0.334862
Train loss on 1800 batch: 0.467265
Train loss on 1850 batch: 0.437345
Train loss on 1900 batch: 0.375973
Train loss on 1950 batch: 0.318274
Train loss on 2000 batch: 0.362063
Train loss on 2050 batch: 0.363157
Train loss on 2100 batch: 0.373739
Train loss on 2150 batch: 0.356793
: Epoch: 73 | Training Loss: 0.338739 | Val. Loss: 0.481424 | Val. Kappa Score: 0.7074 | LR: 0.000982 | Estimated time: 554.59
Train loss on 50 batch: 0.306368
Train loss on 100 batch: 0.304326
Train loss on 150 batch: 0.311190
Train loss on 200 batch: 0.329048
Train loss on 250 batch: 0.321105
Train loss on 300 batch: 0.311515
Train loss on 350 batch: 0.306645
Train loss on 400 batch: 0.327054
Train loss on 450 batch: 0.291947
Train loss on 500 batch: 0.343782
Train loss on 550 batch: 0.319817
Train loss on 600 batch: 0.325057
Train loss on 650 batch: 0.299000
Train loss on 700 batch: 0.345991
Train loss on 750 batch: 0.378532
Train loss on 800 batch: 0.330240
Train loss on 850 batch: 0.327534
Train loss on 900 batch: 0.337517
Train loss on 950 batch: 0.382990
Train loss on 1000 batch: 0.346147
Train loss on 1050 batch: 0.403473
Train loss on 1100 batch: 0.361017
Train loss on 1150 batch: 0.338315
Train loss on 1200 batch: 0.362316
Train loss on 1250 batch: 0.304680
Train loss on 1300 batch: 0.370772
Train loss on 1350 batch: 0.295169
Train loss on 1400 batch: 0.288664
Train loss on 1450 batch: 0.299252
Train loss on 1500 batch: 0.348355
Train loss on 1550 batch: 0.323489
Train loss on 1600 batch: 0.339912
Train loss on 1650 batch: 0.370677
Train loss on 1700 batch: 0.284775
Train loss on 1750 batch: 0.326103
Train loss on 1800 batch: 0.281340
Train loss on 1850 batch: 0.288666
Train loss on 1900 batch: 0.308045
Train loss on 1950 batch: 0.295191
Train loss on 2000 batch: 0.338993
Train loss on 2050 batch: 0.330509
Train loss on 2100 batch: 0.308394
Train loss on 2150 batch: 0.418338
: Epoch: 74 | Training Loss: 0.327472 | Val. Loss: 0.428531 | Val. Kappa Score: 0.7072 | LR: 0.000968 | Estimated time: 554.96
Train loss on 50 batch: 0.336266
Train loss on 100 batch: 0.298222
Train loss on 150 batch: 0.383713
Train loss on 200 batch: 0.287874
Train loss on 250 batch: 0.342469
Train loss on 300 batch: 0.330116
Train loss on 350 batch: 0.347534
Train loss on 400 batch: 0.316235
Train loss on 450 batch: 0.289230
Train loss on 500 batch: 0.297276
Train loss on 550 batch: 0.346866
Train loss on 600 batch: 0.330096
Train loss on 650 batch: 0.310136
Train loss on 700 batch: 0.274184
Train loss on 750 batch: 0.284207
Train loss on 800 batch: 0.353567
Train loss on 850 batch: 0.322156
Train loss on 900 batch: 0.336738
Train loss on 950 batch: 0.328329
Train loss on 1000 batch: 0.294222
Train loss on 1050 batch: 0.282055
Train loss on 1100 batch: 0.295233
Train loss on 1150 batch: 0.264832
Train loss on 1200 batch: 0.304525
Train loss on 1250 batch: 0.348585
Train loss on 1300 batch: 0.312700
Train loss on 1350 batch: 0.334531
Train loss on 1400 batch: 0.370436
Train loss on 1450 batch: 0.313164
Train loss on 1500 batch: 0.334045
Train loss on 1550 batch: 0.325228
Train loss on 1600 batch: 0.325630
Train loss on 1650 batch: 0.396925
Train loss on 1700 batch: 0.313617
Train loss on 1750 batch: 0.382897
Train loss on 1800 batch: 0.317085
Train loss on 1850 batch: 0.336022
Train loss on 1900 batch: 0.266036
Train loss on 1950 batch: 0.390017
Train loss on 2000 batch: 0.295138
Train loss on 2050 batch: 0.271044
Train loss on 2100 batch: 0.309947
Train loss on 2150 batch: 0.311158
: Epoch: 75 | Training Loss: 0.322636 | Val. Loss: 0.367383 | Val. Kappa Score: 0.7077 | LR: 0.000950 | Estimated time: 554.52
Train loss on 50 batch: 0.284627
Train loss on 100 batch: 0.409704
Train loss on 150 batch: 0.372642
Train loss on 200 batch: 0.332335
Train loss on 250 batch: 0.313298
Train loss on 300 batch: 0.339927
Train loss on 350 batch: 0.334056
Train loss on 400 batch: 0.310310
Train loss on 450 batch: 0.312460
Train loss on 500 batch: 0.350988
Train loss on 550 batch: 0.329869
Train loss on 600 batch: 0.323715
Train loss on 650 batch: 0.328367
Train loss on 700 batch: 0.330729
Train loss on 750 batch: 0.263654
Train loss on 800 batch: 0.285281
Train loss on 850 batch: 0.300770
Train loss on 900 batch: 0.324886
Train loss on 950 batch: 0.253748
Train loss on 1000 batch: 0.304081
Train loss on 1050 batch: 0.343685
Train loss on 1100 batch: 0.324494
Train loss on 1150 batch: 0.265218
Train loss on 1200 batch: 0.317086
Train loss on 1250 batch: 0.400839
Train loss on 1300 batch: 0.340296
Train loss on 1350 batch: 0.348063
Train loss on 1400 batch: 0.284687
Train loss on 1450 batch: 0.303869
Train loss on 1500 batch: 0.258595
Train loss on 1550 batch: 0.298017
Train loss on 1600 batch: 0.303252
Train loss on 1650 batch: 0.301005
Train loss on 1700 batch: 0.371876
Train loss on 1750 batch: 0.336762
Train loss on 1800 batch: 0.311661
Train loss on 1850 batch: 0.352463
Train loss on 1900 batch: 0.332387
Train loss on 1950 batch: 0.351641
Train loss on 2000 batch: 0.313620
Train loss on 2050 batch: 0.394720
Train loss on 2100 batch: 0.338345
Train loss on 2150 batch: 0.318953
: Epoch: 76 | Training Loss: 0.323063 | Val. Loss: 0.411155 | Val. Kappa Score: 0.7074 | LR: 0.000929 | Estimated time: 554.65
Train loss on 50 batch: 0.338752
Train loss on 100 batch: 0.311667
Train loss on 150 batch: 0.257444
Train loss on 200 batch: 0.340976
Train loss on 250 batch: 0.266883
Train loss on 300 batch: 0.330949
Train loss on 350 batch: 0.313954
Train loss on 400 batch: 0.317376
Train loss on 450 batch: 0.350086
Train loss on 500 batch: 0.363563
Train loss on 550 batch: 0.267718
Train loss on 600 batch: 0.326125
Train loss on 650 batch: 0.301391
Train loss on 700 batch: 0.365666
Train loss on 750 batch: 0.360915
Train loss on 800 batch: 0.293526
Train loss on 850 batch: 0.261664
Train loss on 900 batch: 0.275513
Train loss on 950 batch: 0.302830
Train loss on 1000 batch: 0.276533
Train loss on 1050 batch: 0.293649
Train loss on 1100 batch: 0.337162
Train loss on 1150 batch: 0.355048
Train loss on 1200 batch: 0.262982
Train loss on 1250 batch: 0.314840
Train loss on 1300 batch: 0.299985
Train loss on 1350 batch: 0.344086
Train loss on 1400 batch: 0.378249
Train loss on 1450 batch: 0.269698
Train loss on 1500 batch: 0.343325
Train loss on 1550 batch: 0.336166
Train loss on 1600 batch: 0.338039
Train loss on 1650 batch: 0.297979
Train loss on 1700 batch: 0.306435
Train loss on 1750 batch: 0.317022
Train loss on 1800 batch: 0.314296
Train loss on 1850 batch: 0.369238
Train loss on 1900 batch: 0.319881
Train loss on 1950 batch: 0.311490
Train loss on 2000 batch: 0.296783
Train loss on 2050 batch: 0.339766
Train loss on 2100 batch: 0.330687
Train loss on 2150 batch: 0.262063
: Epoch: 77 | Training Loss: 0.314880 | Val. Loss: 0.523653 | Val. Kappa Score: 0.7066 | LR: 0.000905 | Estimated time: 554.92
Train loss on 50 batch: 0.345141
Train loss on 100 batch: 0.357450
Train loss on 150 batch: 0.302742
Train loss on 200 batch: 0.329598
Train loss on 250 batch: 0.297272
Train loss on 300 batch: 0.334885
Train loss on 350 batch: 0.273301
Train loss on 400 batch: 0.330167
Train loss on 450 batch: 0.322124
Train loss on 500 batch: 0.364733
Train loss on 550 batch: 0.370395
Train loss on 600 batch: 0.351792
Train loss on 650 batch: 0.291410
Train loss on 700 batch: 0.253592
Train loss on 750 batch: 0.304772
Train loss on 800 batch: 0.373809
Train loss on 850 batch: 0.318547
Train loss on 900 batch: 0.300498
Train loss on 950 batch: 0.338287
Train loss on 1000 batch: 0.297778
Train loss on 1050 batch: 0.314649
Train loss on 1100 batch: 0.321841
Train loss on 1150 batch: 0.301918
Train loss on 1200 batch: 0.304313
Train loss on 1250 batch: 0.310650
Train loss on 1300 batch: 0.322191
Train loss on 1350 batch: 0.330006
Train loss on 1400 batch: 0.317839
Train loss on 1450 batch: 0.316466
Train loss on 1500 batch: 0.300126
Train loss on 1550 batch: 0.337347
Train loss on 1600 batch: 0.332381
Train loss on 1650 batch: 0.298672
Train loss on 1700 batch: 0.283408
Train loss on 1750 batch: 0.287187
Train loss on 1800 batch: 0.298716
Train loss on 1850 batch: 0.289214
Train loss on 1900 batch: 0.256788
Train loss on 1950 batch: 0.306018
Train loss on 2000 batch: 0.315217
Train loss on 2050 batch: 0.311741
Train loss on 2100 batch: 0.257653
Train loss on 2150 batch: 0.260661
: Epoch: 78 | Training Loss: 0.312344 | Val. Loss: 0.409513 | Val. Kappa Score: 0.7068 | LR: 0.000877 | Estimated time: 554.58
Train loss on 50 batch: 0.358867
Train loss on 100 batch: 0.271878
Train loss on 150 batch: 0.262822
Train loss on 200 batch: 0.340323
Train loss on 250 batch: 0.248510
Train loss on 300 batch: 0.287834
Train loss on 350 batch: 0.289481
Train loss on 400 batch: 0.277460
Train loss on 450 batch: 0.368188
Train loss on 500 batch: 0.344963
Train loss on 550 batch: 0.330237
Train loss on 600 batch: 0.372450
Train loss on 650 batch: 0.350535
Train loss on 700 batch: 0.317691
Train loss on 750 batch: 0.357094
Train loss on 800 batch: 0.344710
Train loss on 850 batch: 0.344728
Train loss on 900 batch: 0.279349
Train loss on 950 batch: 0.348119
Train loss on 1000 batch: 0.300303
Train loss on 1050 batch: 0.284512
Train loss on 1100 batch: 0.328415
Train loss on 1150 batch: 0.303967
Train loss on 1200 batch: 0.306832
Train loss on 1250 batch: 0.284318
Train loss on 1300 batch: 0.292149
Train loss on 1350 batch: 0.314923
Train loss on 1400 batch: 0.269674
Train loss on 1450 batch: 0.269215
Train loss on 1500 batch: 0.307005
Train loss on 1550 batch: 0.348565
Train loss on 1600 batch: 0.331708
Train loss on 1650 batch: 0.276522
Train loss on 1700 batch: 0.326829
Train loss on 1750 batch: 0.289703
Train loss on 1800 batch: 0.332527
Train loss on 1850 batch: 0.300644
Train loss on 1900 batch: 0.302169
Train loss on 1950 batch: 0.314100
Train loss on 2000 batch: 0.394174
Train loss on 2050 batch: 0.279236
Train loss on 2100 batch: 0.311374
Train loss on 2150 batch: 0.275016
: Epoch: 79 | Training Loss: 0.313617 | Val. Loss: 0.384353 | Val. Kappa Score: 0.7071 | LR: 0.000846 | Estimated time: 554.84
Train loss on 50 batch: 0.315617
Train loss on 100 batch: 0.321431
Train loss on 150 batch: 0.305380
Train loss on 200 batch: 0.300743
Train loss on 250 batch: 0.317166
Train loss on 300 batch: 0.280727
Train loss on 350 batch: 0.362205
Train loss on 400 batch: 0.265629
Train loss on 450 batch: 0.320404
Train loss on 500 batch: 0.282590
Train loss on 550 batch: 0.324058
Train loss on 600 batch: 0.290504
Train loss on 650 batch: 0.323300
Train loss on 700 batch: 0.348996
Train loss on 750 batch: 0.298589
Train loss on 800 batch: 0.250022
Train loss on 850 batch: 0.330288
Train loss on 900 batch: 0.283271
Train loss on 950 batch: 0.302854
Train loss on 1000 batch: 0.288839
Train loss on 1050 batch: 0.342383
Train loss on 1100 batch: 0.342022
Train loss on 1150 batch: 0.338056
Train loss on 1200 batch: 0.271038
Train loss on 1250 batch: 0.318552
Train loss on 1300 batch: 0.248191
Train loss on 1350 batch: 0.265076
Train loss on 1400 batch: 0.337760
Train loss on 1450 batch: 0.331141
Train loss on 1500 batch: 0.278738
Train loss on 1550 batch: 0.308877
Train loss on 1600 batch: 0.298737
Train loss on 1650 batch: 0.333288
Train loss on 1700 batch: 0.287991
Train loss on 1750 batch: 0.300275
Train loss on 1800 batch: 0.290355
Train loss on 1850 batch: 0.280530
Train loss on 1900 batch: 0.325639
Train loss on 1950 batch: 0.249189
Train loss on 2000 batch: 0.255441
Train loss on 2050 batch: 0.335172
Train loss on 2100 batch: 0.325702
Train loss on 2150 batch: 0.337385
: Epoch: 80 | Training Loss: 0.306116 | Val. Loss: 0.376195 | Val. Kappa Score: 0.7073 | LR: 0.000812 | Estimated time: 554.66
Train loss on 50 batch: 0.244498
Train loss on 100 batch: 0.316342
Train loss on 150 batch: 0.306200
Train loss on 200 batch: 0.305498
Train loss on 250 batch: 0.316526
Train loss on 300 batch: 0.267652
Train loss on 350 batch: 0.317090
Train loss on 400 batch: 0.286591
Train loss on 450 batch: 0.262038
Train loss on 500 batch: 0.317526
Train loss on 550 batch: 0.314688
Train loss on 600 batch: 0.267820
Train loss on 650 batch: 0.295530
Train loss on 700 batch: 0.372590
Train loss on 750 batch: 0.322618
Train loss on 800 batch: 0.249158
Train loss on 850 batch: 0.277156
Train loss on 900 batch: 0.281183
Train loss on 950 batch: 0.256620
Train loss on 1000 batch: 0.277467
Train loss on 1050 batch: 0.255957
Train loss on 1100 batch: 0.284604
Train loss on 1150 batch: 0.264623
Train loss on 1200 batch: 0.268849
Train loss on 1250 batch: 0.343545
Train loss on 1300 batch: 0.336438
Train loss on 1350 batch: 0.364903
Train loss on 1400 batch: 0.303140
Train loss on 1450 batch: 0.283229
Train loss on 1500 batch: 0.338445
Train loss on 1550 batch: 0.291271
Train loss on 1600 batch: 0.289737
Train loss on 1650 batch: 0.299567
Train loss on 1700 batch: 0.303079
Train loss on 1750 batch: 0.295260
Train loss on 1800 batch: 0.251624
Train loss on 1850 batch: 0.322607
Train loss on 1900 batch: 0.288652
Train loss on 1950 batch: 0.426015
Train loss on 2000 batch: 0.337745
Train loss on 2050 batch: 0.327130
Train loss on 2100 batch: 0.346359
Train loss on 2150 batch: 0.285294
: Epoch: 81 | Training Loss: 0.301865 | Val. Loss: 0.432240 | Val. Kappa Score: 0.7074 | LR: 0.000775 | Estimated time: 554.76
Train loss on 50 batch: 0.283654
Train loss on 100 batch: 0.288077
Train loss on 150 batch: 0.265104
Train loss on 200 batch: 0.283234
Train loss on 250 batch: 0.260089
Train loss on 300 batch: 0.330694
Train loss on 350 batch: 0.284310
Train loss on 400 batch: 0.268652
Train loss on 450 batch: 0.287414
Train loss on 500 batch: 0.335922
Train loss on 550 batch: 0.260028
Train loss on 600 batch: 0.274682
Train loss on 650 batch: 0.317526
Train loss on 700 batch: 0.292233
Train loss on 750 batch: 0.302699
Train loss on 800 batch: 0.273124
Train loss on 850 batch: 0.285571
Train loss on 900 batch: 0.317945
Train loss on 950 batch: 0.312845
Train loss on 1000 batch: 0.288180
Train loss on 1050 batch: 0.293137
Train loss on 1100 batch: 0.274099
Train loss on 1150 batch: 0.272298
Train loss on 1200 batch: 0.285780
Train loss on 1250 batch: 0.286170
Train loss on 1300 batch: 0.308294
Train loss on 1350 batch: 0.316197
Train loss on 1400 batch: 0.305393
Train loss on 1450 batch: 0.284028
Train loss on 1500 batch: 0.259054
Train loss on 1550 batch: 0.279444
Train loss on 1600 batch: 0.268442
Train loss on 1650 batch: 0.307895
Train loss on 1700 batch: 0.275091
Train loss on 1750 batch: 0.289327
Train loss on 1800 batch: 0.273908
Train loss on 1850 batch: 0.269252
Train loss on 1900 batch: 0.309345
Train loss on 1950 batch: 0.304034
Train loss on 2000 batch: 0.354945
Train loss on 2050 batch: 0.317210
Train loss on 2100 batch: 0.314083
Train loss on 2150 batch: 0.339572
: Epoch: 82 | Training Loss: 0.292008 | Val. Loss: 0.327763 | Val. Kappa Score: 0.7079 | LR: 0.000737 | Estimated time: 555.30
Train loss on 50 batch: 0.305858
Train loss on 100 batch: 0.273546
Train loss on 150 batch: 0.328559
Train loss on 200 batch: 0.303896
Train loss on 250 batch: 0.260301
Train loss on 300 batch: 0.317722
Train loss on 350 batch: 0.274031
Train loss on 400 batch: 0.287884
Train loss on 450 batch: 0.282642
Train loss on 500 batch: 0.295573
Train loss on 550 batch: 0.262095
Train loss on 600 batch: 0.293873
Train loss on 650 batch: 0.305525
Train loss on 700 batch: 0.226704
Train loss on 750 batch: 0.214262
Train loss on 800 batch: 0.307842
Train loss on 850 batch: 0.288216
Train loss on 900 batch: 0.292007
Train loss on 950 batch: 0.328346
Train loss on 1000 batch: 0.262820
Train loss on 1050 batch: 0.259437
Train loss on 1100 batch: 0.327107
Train loss on 1150 batch: 0.332343
Train loss on 1200 batch: 0.307136
Train loss on 1250 batch: 0.313159
Train loss on 1300 batch: 0.325513
Train loss on 1350 batch: 0.292900
Train loss on 1400 batch: 0.312690
Train loss on 1450 batch: 0.311788
Train loss on 1500 batch: 0.277663
Train loss on 1550 batch: 0.253900
Train loss on 1600 batch: 0.310704
Train loss on 1650 batch: 0.248552
Train loss on 1700 batch: 0.280122
Train loss on 1750 batch: 0.275514
Train loss on 1800 batch: 0.262929
Train loss on 1850 batch: 0.328298
Train loss on 1900 batch: 0.273530
Train loss on 1950 batch: 0.302593
Train loss on 2000 batch: 0.265248
Train loss on 2050 batch: 0.280188
Train loss on 2100 batch: 0.300941
Train loss on 2150 batch: 0.322737
: Epoch: 83 | Training Loss: 0.291346 | Val. Loss: 0.344347 | Val. Kappa Score: 0.7082 | LR: 0.000697 | Estimated time: 554.71
Train loss on 50 batch: 0.293449
Train loss on 100 batch: 0.282713
Train loss on 150 batch: 0.301530
Train loss on 200 batch: 0.288732
Train loss on 250 batch: 0.311299
Train loss on 300 batch: 0.307740
Train loss on 350 batch: 0.288317
Train loss on 400 batch: 0.317895
Train loss on 450 batch: 0.288770
Train loss on 500 batch: 0.228154
Train loss on 550 batch: 0.350025
Train loss on 600 batch: 0.246959
Train loss on 650 batch: 0.295815
Train loss on 700 batch: 0.315018
Train loss on 750 batch: 0.274324
Train loss on 800 batch: 0.300946
Train loss on 850 batch: 0.300375
Train loss on 900 batch: 0.280843
Train loss on 950 batch: 0.214445
Train loss on 1000 batch: 0.278422
Train loss on 1050 batch: 0.301734
Train loss on 1100 batch: 0.232893
Train loss on 1150 batch: 0.315637
Train loss on 1200 batch: 0.283245
Train loss on 1250 batch: 0.292748
Train loss on 1300 batch: 0.272358
Train loss on 1350 batch: 0.254421
Train loss on 1400 batch: 0.283064
Train loss on 1450 batch: 0.253046
Train loss on 1500 batch: 0.323003
Train loss on 1550 batch: 0.279692
Train loss on 1600 batch: 0.235742
Train loss on 1650 batch: 0.310363
Train loss on 1700 batch: 0.294931
Train loss on 1750 batch: 0.311054
Train loss on 1800 batch: 0.242760
Train loss on 1850 batch: 0.295879
Train loss on 1900 batch: 0.303987
Train loss on 1950 batch: 0.322301
Train loss on 2000 batch: 0.261442
Train loss on 2050 batch: 0.302404
Train loss on 2100 batch: 0.350510
Train loss on 2150 batch: 0.282491
: Epoch: 84 | Training Loss: 0.288221 | Val. Loss: 0.333444 | Val. Kappa Score: 0.7086 | LR: 0.000655 | Estimated time: 554.76
Train loss on 50 batch: 0.247200
Train loss on 100 batch: 0.288441
Train loss on 150 batch: 0.257846
Train loss on 200 batch: 0.241518
Train loss on 250 batch: 0.349794
Train loss on 300 batch: 0.317314
Train loss on 350 batch: 0.280546
Train loss on 400 batch: 0.275584
Train loss on 450 batch: 0.253547
Train loss on 500 batch: 0.250961
Train loss on 550 batch: 0.281801
Train loss on 600 batch: 0.242902
Train loss on 650 batch: 0.272901
Train loss on 700 batch: 0.273308
Train loss on 750 batch: 0.262927
Train loss on 800 batch: 0.330853
Train loss on 850 batch: 0.290518
Train loss on 900 batch: 0.303208
Train loss on 950 batch: 0.238260
Train loss on 1000 batch: 0.298818
Train loss on 1050 batch: 0.273346
Train loss on 1100 batch: 0.320852
Train loss on 1150 batch: 0.212361
Train loss on 1200 batch: 0.258907
Train loss on 1250 batch: 0.319249
Train loss on 1300 batch: 0.285416
Train loss on 1350 batch: 0.265896
Train loss on 1400 batch: 0.308294
Train loss on 1450 batch: 0.342762
Train loss on 1500 batch: 0.295598
Train loss on 1550 batch: 0.247138
Train loss on 1600 batch: 0.273607
Train loss on 1650 batch: 0.272453
Train loss on 1700 batch: 0.273947
Train loss on 1750 batch: 0.249320
Train loss on 1800 batch: 0.311975
Train loss on 1850 batch: 0.288092
Train loss on 1900 batch: 0.271057
Train loss on 1950 batch: 0.234857
Train loss on 2000 batch: 0.261417
Train loss on 2050 batch: 0.258432
Train loss on 2100 batch: 0.276524
Train loss on 2150 batch: 0.274088
: Epoch: 85 | Training Loss: 0.278378 | Val. Loss: 0.364751 | Val. Kappa Score: 0.7087 | LR: 0.000611 | Estimated time: 554.52
Train loss on 50 batch: 0.327308
Train loss on 100 batch: 0.248968
Train loss on 150 batch: 0.293063
Train loss on 200 batch: 0.287493
Train loss on 250 batch: 0.226052
Train loss on 300 batch: 0.297343
Train loss on 350 batch: 0.247499
Train loss on 400 batch: 0.276816
Train loss on 450 batch: 0.227407
Train loss on 500 batch: 0.284916
Train loss on 550 batch: 0.313387
Train loss on 600 batch: 0.294593
Train loss on 650 batch: 0.268337
Train loss on 700 batch: 0.262333
Train loss on 750 batch: 0.246306
Train loss on 800 batch: 0.274282
Train loss on 850 batch: 0.258817
Train loss on 900 batch: 0.308332
Train loss on 950 batch: 0.311175
Train loss on 1000 batch: 0.275151
Train loss on 1050 batch: 0.296970
Train loss on 1100 batch: 0.250120
Train loss on 1150 batch: 0.234286
Train loss on 1200 batch: 0.235392
Train loss on 1250 batch: 0.282212
Train loss on 1300 batch: 0.286455
Train loss on 1350 batch: 0.253744
Train loss on 1400 batch: 0.219399
Train loss on 1450 batch: 0.289779
Train loss on 1500 batch: 0.297679
Train loss on 1550 batch: 0.251593
Train loss on 1600 batch: 0.282947
Train loss on 1650 batch: 0.258979
Train loss on 1700 batch: 0.260622
Train loss on 1750 batch: 0.319591
Train loss on 1800 batch: 0.261011
Train loss on 1850 batch: 0.275271
Train loss on 1900 batch: 0.289430
Train loss on 1950 batch: 0.313342
Train loss on 2000 batch: 0.281763
Train loss on 2050 batch: 0.182820
Train loss on 2100 batch: 0.268126
Train loss on 2150 batch: 0.253666
: Epoch: 86 | Training Loss: 0.272562 | Val. Loss: 0.337621 | Val. Kappa Score: 0.7092 | LR: 0.000567 | Estimated time: 554.74
Train loss on 50 batch: 0.231465
Train loss on 100 batch: 0.283548
Train loss on 150 batch: 0.255041
Train loss on 200 batch: 0.288180
Train loss on 250 batch: 0.271703
Train loss on 300 batch: 0.221337
Train loss on 350 batch: 0.272568
Train loss on 400 batch: 0.215430
Train loss on 450 batch: 0.249745
Train loss on 500 batch: 0.233925
Train loss on 550 batch: 0.268656
Train loss on 600 batch: 0.308739
Train loss on 650 batch: 0.293857
Train loss on 700 batch: 0.285979
Train loss on 750 batch: 0.247488
Train loss on 800 batch: 0.320839
Train loss on 850 batch: 0.269166
Train loss on 900 batch: 0.267069
Train loss on 950 batch: 0.242306
Train loss on 1000 batch: 0.272916
Train loss on 1050 batch: 0.264673
Train loss on 1100 batch: 0.275789
Train loss on 1150 batch: 0.276719
Train loss on 1200 batch: 0.244481
Train loss on 1250 batch: 0.239103
Train loss on 1300 batch: 0.245730
Train loss on 1350 batch: 0.281335
Train loss on 1400 batch: 0.285810
Train loss on 1450 batch: 0.329231
Train loss on 1500 batch: 0.318001
Train loss on 1550 batch: 0.250879
Train loss on 1600 batch: 0.241329
Train loss on 1650 batch: 0.292557
Train loss on 1700 batch: 0.268047
Train loss on 1750 batch: 0.230889
Train loss on 1800 batch: 0.308466
Train loss on 1850 batch: 0.263978
Train loss on 1900 batch: 0.270430
Train loss on 1950 batch: 0.278391
Train loss on 2000 batch: 0.254563
Train loss on 2050 batch: 0.281449
Train loss on 2100 batch: 0.243087
Train loss on 2150 batch: 0.297368
: Epoch: 87 | Training Loss: 0.268145 | Val. Loss: 0.332035 | Val. Kappa Score: 0.7097 | LR: 0.000522 | Estimated time: 554.76
Train loss on 50 batch: 0.243916
Train loss on 100 batch: 0.272332
Train loss on 150 batch: 0.241411
Train loss on 200 batch: 0.258269
Train loss on 250 batch: 0.297804
Train loss on 300 batch: 0.236870
Train loss on 350 batch: 0.296246
Train loss on 400 batch: 0.264031
Train loss on 450 batch: 0.269897
Train loss on 500 batch: 0.232665
Train loss on 550 batch: 0.290035
Train loss on 600 batch: 0.245736
Train loss on 650 batch: 0.256496
Train loss on 700 batch: 0.278298
Train loss on 750 batch: 0.254391
Train loss on 800 batch: 0.237795
Train loss on 850 batch: 0.265044
Train loss on 900 batch: 0.282501
Train loss on 950 batch: 0.231486
Train loss on 1000 batch: 0.245554
Train loss on 1050 batch: 0.270092
Train loss on 1100 batch: 0.260799
Train loss on 1150 batch: 0.269318
Train loss on 1200 batch: 0.303411
Train loss on 1250 batch: 0.253115
Train loss on 1300 batch: 0.269636
Train loss on 1350 batch: 0.195326
Train loss on 1400 batch: 0.287392
Train loss on 1450 batch: 0.290092
Train loss on 1500 batch: 0.256234
Train loss on 1550 batch: 0.273568
Train loss on 1600 batch: 0.249705
Train loss on 1650 batch: 0.288740
Train loss on 1700 batch: 0.258741
Train loss on 1750 batch: 0.292829
Train loss on 1800 batch: 0.256216
Train loss on 1850 batch: 0.305106
Train loss on 1900 batch: 0.270987
Train loss on 1950 batch: 0.258677
Train loss on 2000 batch: 0.260221
Train loss on 2050 batch: 0.302917
Train loss on 2100 batch: 0.271312
Train loss on 2150 batch: 0.272304
: Epoch: 88 | Training Loss: 0.264046 | Val. Loss: 0.318323 | Val. Kappa Score: 0.7102 | LR: 0.000478 | Estimated time: 555.07
Train loss on 50 batch: 0.255530
Train loss on 100 batch: 0.208117
Train loss on 150 batch: 0.250549
Train loss on 200 batch: 0.236113
Train loss on 250 batch: 0.179318
Train loss on 300 batch: 0.280994
Train loss on 350 batch: 0.262375
Train loss on 400 batch: 0.290190
Train loss on 450 batch: 0.276157
Train loss on 500 batch: 0.248615
Train loss on 550 batch: 0.259545
Train loss on 600 batch: 0.263822
Train loss on 650 batch: 0.217098
Train loss on 700 batch: 0.293933
Train loss on 750 batch: 0.276425
Train loss on 800 batch: 0.248679
Train loss on 850 batch: 0.248152
Train loss on 900 batch: 0.228646
Train loss on 950 batch: 0.239028
Train loss on 1000 batch: 0.306599
Train loss on 1050 batch: 0.247667
Train loss on 1100 batch: 0.240933
Train loss on 1150 batch: 0.237554
Train loss on 1200 batch: 0.194823
Train loss on 1250 batch: 0.272655
Train loss on 1300 batch: 0.238813
Train loss on 1350 batch: 0.243094
Train loss on 1400 batch: 0.284162
Train loss on 1450 batch: 0.262048
Train loss on 1500 batch: 0.283394
Train loss on 1550 batch: 0.255376
Train loss on 1600 batch: 0.269957
Train loss on 1650 batch: 0.284321
Train loss on 1700 batch: 0.282738
Train loss on 1750 batch: 0.245390
Train loss on 1800 batch: 0.245629
Train loss on 1850 batch: 0.269680
Train loss on 1900 batch: 0.263666
Train loss on 1950 batch: 0.307553
Train loss on 2000 batch: 0.231370
Train loss on 2050 batch: 0.240506
Train loss on 2100 batch: 0.275575
Train loss on 2150 batch: 0.279938
: Epoch: 89 | Training Loss: 0.256026 | Val. Loss: 0.441757 | Val. Kappa Score: 0.7102 | LR: 0.000433 | Estimated time: 554.61
Train loss on 50 batch: 0.254056
Train loss on 100 batch: 0.247286
Train loss on 150 batch: 0.203923
Train loss on 200 batch: 0.250371
Train loss on 250 batch: 0.248865
Train loss on 300 batch: 0.282495
Train loss on 350 batch: 0.277793
Train loss on 400 batch: 0.228075
Train loss on 450 batch: 0.239431
Train loss on 500 batch: 0.223523
Train loss on 550 batch: 0.255252
Train loss on 600 batch: 0.278373
Train loss on 650 batch: 0.245864
Train loss on 700 batch: 0.240916
Train loss on 750 batch: 0.205913
Train loss on 800 batch: 0.292917
Train loss on 850 batch: 0.225313
Train loss on 900 batch: 0.292470
Train loss on 950 batch: 0.271189
Train loss on 1000 batch: 0.228866
Train loss on 1050 batch: 0.245036
Train loss on 1100 batch: 0.242096
Train loss on 1150 batch: 0.203364
Train loss on 1200 batch: 0.229713
Train loss on 1250 batch: 0.207916
Train loss on 1300 batch: 0.249683
Train loss on 1350 batch: 0.283686
Train loss on 1400 batch: 0.212956
Train loss on 1450 batch: 0.210995
Train loss on 1500 batch: 0.305868
Train loss on 1550 batch: 0.219277
Train loss on 1600 batch: 0.244399
Train loss on 1650 batch: 0.265324
Train loss on 1700 batch: 0.258434
Train loss on 1750 batch: 0.249382
Train loss on 1800 batch: 0.283228
Train loss on 1850 batch: 0.254352
Train loss on 1900 batch: 0.290515
Train loss on 1950 batch: 0.267238
Train loss on 2000 batch: 0.282372
Train loss on 2050 batch: 0.289072
Train loss on 2100 batch: 0.230765
Train loss on 2150 batch: 0.250933
: Epoch: 90 | Training Loss: 0.249625 | Val. Loss: 0.365770 | Val. Kappa Score: 0.7104 | LR: 0.000389 | Estimated time: 555.01
Train loss on 50 batch: 0.272189
Train loss on 100 batch: 0.231917
Train loss on 150 batch: 0.307369
Train loss on 200 batch: 0.256941
Train loss on 250 batch: 0.251994
Train loss on 300 batch: 0.245964
Train loss on 350 batch: 0.275593
Train loss on 400 batch: 0.250825
Train loss on 450 batch: 0.216645
Train loss on 500 batch: 0.224774
Train loss on 550 batch: 0.218201
Train loss on 600 batch: 0.220251
Train loss on 650 batch: 0.254375
Train loss on 700 batch: 0.217308
Train loss on 750 batch: 0.244621
Train loss on 800 batch: 0.250737
Train loss on 850 batch: 0.249849
Train loss on 900 batch: 0.241104
Train loss on 950 batch: 0.272052
Train loss on 1000 batch: 0.251632
Train loss on 1050 batch: 0.269129
Train loss on 1100 batch: 0.241572
Train loss on 1150 batch: 0.242941
Train loss on 1200 batch: 0.248896
Train loss on 1250 batch: 0.250833
Train loss on 1300 batch: 0.186250
Train loss on 1350 batch: 0.251958
Train loss on 1400 batch: 0.276076
Train loss on 1450 batch: 0.188619
Train loss on 1500 batch: 0.259472
Train loss on 1550 batch: 0.210332
Train loss on 1600 batch: 0.271169
Train loss on 1650 batch: 0.249369
Train loss on 1700 batch: 0.259192
Train loss on 1750 batch: 0.248545
Train loss on 1800 batch: 0.282852
Train loss on 1850 batch: 0.242561
Train loss on 1900 batch: 0.237193
Train loss on 1950 batch: 0.236475
Train loss on 2000 batch: 0.245546
Train loss on 2050 batch: 0.249184
Train loss on 2100 batch: 0.229713
Train loss on 2150 batch: 0.255229
: Epoch: 91 | Training Loss: 0.246506 | Val. Loss: 0.396346 | Val. Kappa Score: 0.7106 | LR: 0.000345 | Estimated time: 554.80
Train loss on 50 batch: 0.236060
Train loss on 100 batch: 0.288343
Train loss on 150 batch: 0.237146
Train loss on 200 batch: 0.201651
Train loss on 250 batch: 0.230786
Train loss on 300 batch: 0.236037
Train loss on 350 batch: 0.257215
Train loss on 400 batch: 0.228058
Train loss on 450 batch: 0.188653
Train loss on 500 batch: 0.250501
Train loss on 550 batch: 0.220891
Train loss on 600 batch: 0.196244
Train loss on 650 batch: 0.244083
Train loss on 700 batch: 0.266599
Train loss on 750 batch: 0.222283
Train loss on 800 batch: 0.240718
Train loss on 850 batch: 0.265429
Train loss on 900 batch: 0.212256
Train loss on 950 batch: 0.245612
Train loss on 1000 batch: 0.252606
Train loss on 1050 batch: 0.233242
Train loss on 1100 batch: 0.211522
Train loss on 1150 batch: 0.238380
Train loss on 1200 batch: 0.230368
Train loss on 1250 batch: 0.296429
Train loss on 1300 batch: 0.240634
Train loss on 1350 batch: 0.255497
Train loss on 1400 batch: 0.215791
Train loss on 1450 batch: 0.249903
Train loss on 1500 batch: 0.276959
Train loss on 1550 batch: 0.228131
Train loss on 1600 batch: 0.198632
Train loss on 1650 batch: 0.258006
Train loss on 1700 batch: 0.253007
Train loss on 1750 batch: 0.232628
Train loss on 1800 batch: 0.247781
Train loss on 1850 batch: 0.223645
Train loss on 1900 batch: 0.210815
Train loss on 1950 batch: 0.286048
Train loss on 2000 batch: 0.228226
Train loss on 2050 batch: 0.257741
Train loss on 2100 batch: 0.234968
Train loss on 2150 batch: 0.250741
: Epoch: 92 | Training Loss: 0.239490 | Val. Loss: 0.337177 | Val. Kappa Score: 0.7111 | LR: 0.000303 | Estimated time: 554.91
Train loss on 50 batch: 0.305811
Train loss on 100 batch: 0.260252
Train loss on 150 batch: 0.249931
Train loss on 200 batch: 0.254285
Train loss on 250 batch: 0.195263
Train loss on 300 batch: 0.233178
Train loss on 350 batch: 0.263939
Train loss on 400 batch: 0.224484
Train loss on 450 batch: 0.282597
Train loss on 500 batch: 0.237269
Train loss on 550 batch: 0.234199
Train loss on 600 batch: 0.208682
Train loss on 650 batch: 0.286162
Train loss on 700 batch: 0.235110
Train loss on 750 batch: 0.268847
Train loss on 800 batch: 0.216950
Train loss on 850 batch: 0.234424
Train loss on 900 batch: 0.248942
Train loss on 950 batch: 0.273097
Train loss on 1000 batch: 0.247477
Train loss on 1050 batch: 0.238272
Train loss on 1100 batch: 0.189725
Train loss on 1150 batch: 0.232533
Train loss on 1200 batch: 0.227014
Train loss on 1250 batch: 0.254218
Train loss on 1300 batch: 0.240208
Train loss on 1350 batch: 0.215640
Train loss on 1400 batch: 0.204014
Train loss on 1450 batch: 0.206192
Train loss on 1500 batch: 0.254587
Train loss on 1550 batch: 0.218348
Train loss on 1600 batch: 0.204445
Train loss on 1650 batch: 0.216975
Train loss on 1700 batch: 0.250876
Train loss on 1750 batch: 0.252364
Train loss on 1800 batch: 0.209203
Train loss on 1850 batch: 0.259549
Train loss on 1900 batch: 0.212889
Train loss on 1950 batch: 0.242949
Train loss on 2000 batch: 0.230476
Train loss on 2050 batch: 0.270806
Train loss on 2100 batch: 0.206565
Train loss on 2150 batch: 0.222381
: Epoch: 93 | Training Loss: 0.238049 | Val. Loss: 0.329424 | Val. Kappa Score: 0.7116 | LR: 0.000263 | Estimated time: 554.65
Train loss on 50 batch: 0.258598
Train loss on 100 batch: 0.196232
Train loss on 150 batch: 0.234608
Train loss on 200 batch: 0.217660
Train loss on 250 batch: 0.238569
Train loss on 300 batch: 0.249298
Train loss on 350 batch: 0.238516
Train loss on 400 batch: 0.199021
Train loss on 450 batch: 0.218563
Train loss on 500 batch: 0.228999
Train loss on 550 batch: 0.191197
Train loss on 600 batch: 0.250878
Train loss on 650 batch: 0.211003
Train loss on 700 batch: 0.214502
Train loss on 750 batch: 0.289824
Train loss on 800 batch: 0.229378
Train loss on 850 batch: 0.218159
Train loss on 900 batch: 0.204800
Train loss on 950 batch: 0.241370
Train loss on 1000 batch: 0.226587
Train loss on 1050 batch: 0.201364
Train loss on 1100 batch: 0.258992
Train loss on 1150 batch: 0.256899
Train loss on 1200 batch: 0.242994
Train loss on 1250 batch: 0.247552
Train loss on 1300 batch: 0.202637
Train loss on 1350 batch: 0.215932
Train loss on 1400 batch: 0.234692
Train loss on 1450 batch: 0.208299
Train loss on 1500 batch: 0.206411
Train loss on 1550 batch: 0.225032
Train loss on 1600 batch: 0.252081
Train loss on 1650 batch: 0.230961
Train loss on 1700 batch: 0.260671
Train loss on 1750 batch: 0.205374
Train loss on 1800 batch: 0.234069
Train loss on 1850 batch: 0.244186
Train loss on 1900 batch: 0.233403
Train loss on 1950 batch: 0.200256
Train loss on 2000 batch: 0.257926
Train loss on 2050 batch: 0.204058
Train loss on 2100 batch: 0.246419
Train loss on 2150 batch: 0.217798
: Epoch: 94 | Training Loss: 0.229705 | Val. Loss: 0.352814 | Val. Kappa Score: 0.7120 | LR: 0.000225 | Estimated time: 554.41
Train loss on 50 batch: 0.209795
Train loss on 100 batch: 0.220490
Train loss on 150 batch: 0.205938
Train loss on 200 batch: 0.201056
Train loss on 250 batch: 0.198215
Train loss on 300 batch: 0.219388
Train loss on 350 batch: 0.253629
Train loss on 400 batch: 0.197462
Train loss on 450 batch: 0.230144
Train loss on 500 batch: 0.234018
Train loss on 550 batch: 0.174725
Train loss on 600 batch: 0.259469
Train loss on 650 batch: 0.215905
Train loss on 700 batch: 0.167058
Train loss on 750 batch: 0.255495
Train loss on 800 batch: 0.220383
Train loss on 850 batch: 0.228549
Train loss on 900 batch: 0.227346
Train loss on 950 batch: 0.245470
Train loss on 1000 batch: 0.212738
Train loss on 1050 batch: 0.229052
Train loss on 1100 batch: 0.243250
Train loss on 1150 batch: 0.207335
Train loss on 1200 batch: 0.239067
Train loss on 1250 batch: 0.177062
Train loss on 1300 batch: 0.238029
Train loss on 1350 batch: 0.243282
Train loss on 1400 batch: 0.215960
Train loss on 1450 batch: 0.211075
Train loss on 1500 batch: 0.266894
Train loss on 1550 batch: 0.212669
Train loss on 1600 batch: 0.235525
Train loss on 1650 batch: 0.270478
Train loss on 1700 batch: 0.263745
Train loss on 1750 batch: 0.235036
Train loss on 1800 batch: 0.227621
Train loss on 1850 batch: 0.221397
Train loss on 1900 batch: 0.245866
Train loss on 1950 batch: 0.250842
Train loss on 2000 batch: 0.233868
Train loss on 2050 batch: 0.226360
Train loss on 2100 batch: 0.225075
Train loss on 2150 batch: 0.226566
: Epoch: 95 | Training Loss: 0.226086 | Val. Loss: 0.331497 | Val. Kappa Score: 0.7125 | LR: 0.000188 | Estimated time: 554.66
Train loss on 50 batch: 0.206976
Train loss on 100 batch: 0.210806
Train loss on 150 batch: 0.241120
Train loss on 200 batch: 0.214606
Train loss on 250 batch: 0.250340
Train loss on 300 batch: 0.239018
Train loss on 350 batch: 0.225872
Train loss on 400 batch: 0.195264
Train loss on 450 batch: 0.226411
Train loss on 500 batch: 0.208103
Train loss on 550 batch: 0.223556
Train loss on 600 batch: 0.229194
Train loss on 650 batch: 0.221181
Train loss on 700 batch: 0.231968
Train loss on 750 batch: 0.232525
Train loss on 800 batch: 0.216865
Train loss on 850 batch: 0.179784
Train loss on 900 batch: 0.206914
Train loss on 950 batch: 0.205587
Train loss on 1000 batch: 0.234726
Train loss on 1050 batch: 0.244274
Train loss on 1100 batch: 0.203213
Train loss on 1150 batch: 0.211697
Train loss on 1200 batch: 0.242106
Train loss on 1250 batch: 0.193678
Train loss on 1300 batch: 0.221339
Train loss on 1350 batch: 0.207068
Train loss on 1400 batch: 0.269282
Train loss on 1450 batch: 0.242085
Train loss on 1500 batch: 0.217701
Train loss on 1550 batch: 0.185159
Train loss on 1600 batch: 0.248608
Train loss on 1650 batch: 0.209641
Train loss on 1700 batch: 0.189155
Train loss on 1750 batch: 0.244170
Train loss on 1800 batch: 0.203199
Train loss on 1850 batch: 0.262550
Train loss on 1900 batch: 0.255715
Train loss on 1950 batch: 0.236916
Train loss on 2000 batch: 0.222508
Train loss on 2050 batch: 0.215901
Train loss on 2100 batch: 0.210790
Train loss on 2150 batch: 0.247966
: Epoch: 96 | Training Loss: 0.224150 | Val. Loss: 0.325125 | Val. Kappa Score: 0.7129 | LR: 0.000154 | Estimated time: 554.65
Train loss on 50 batch: 0.232414
Train loss on 100 batch: 0.223852
Train loss on 150 batch: 0.219723
Train loss on 200 batch: 0.245941
Train loss on 250 batch: 0.222597
Train loss on 300 batch: 0.237804
Train loss on 350 batch: 0.198463
Train loss on 400 batch: 0.220935
Train loss on 450 batch: 0.206907
Train loss on 500 batch: 0.197662
Train loss on 550 batch: 0.215970
Train loss on 600 batch: 0.210127
Train loss on 650 batch: 0.206101
Train loss on 700 batch: 0.240053
Train loss on 750 batch: 0.155752
Train loss on 800 batch: 0.248824
Train loss on 850 batch: 0.206898
Train loss on 900 batch: 0.238150
Train loss on 950 batch: 0.230092
Train loss on 1000 batch: 0.240947
Train loss on 1050 batch: 0.201980
Train loss on 1100 batch: 0.211342
Train loss on 1150 batch: 0.189835
Train loss on 1200 batch: 0.198792
Train loss on 1250 batch: 0.169550
Train loss on 1300 batch: 0.182783
Train loss on 1350 batch: 0.227835
Train loss on 1400 batch: 0.246258
Train loss on 1450 batch: 0.214735
Train loss on 1500 batch: 0.235700
Train loss on 1550 batch: 0.242670
Train loss on 1600 batch: 0.235608
Train loss on 1650 batch: 0.252024
Train loss on 1700 batch: 0.253261
Train loss on 1750 batch: 0.203872
Train loss on 1800 batch: 0.181297
Train loss on 1850 batch: 0.222860
Train loss on 1900 batch: 0.202696
Train loss on 1950 batch: 0.213826
Train loss on 2000 batch: 0.218370
Train loss on 2050 batch: 0.240873
Train loss on 2100 batch: 0.275916
Train loss on 2150 batch: 0.240936
: Epoch: 97 | Training Loss: 0.219467 | Val. Loss: 0.318973 | Val. Kappa Score: 0.7134 | LR: 0.000123 | Estimated time: 555.02
Train loss on 50 batch: 0.207069
Train loss on 100 batch: 0.196459
Train loss on 150 batch: 0.164276
Train loss on 200 batch: 0.229945
Train loss on 250 batch: 0.178651
Train loss on 300 batch: 0.221335
Train loss on 350 batch: 0.230327
Train loss on 400 batch: 0.199952
Train loss on 450 batch: 0.187949
Train loss on 500 batch: 0.195838
Train loss on 550 batch: 0.205244
Train loss on 600 batch: 0.218689
Train loss on 650 batch: 0.213446
Train loss on 700 batch: 0.213101
Train loss on 750 batch: 0.222427
Train loss on 800 batch: 0.198518
Train loss on 850 batch: 0.253819
Train loss on 900 batch: 0.203069
Train loss on 950 batch: 0.223282
Train loss on 1000 batch: 0.218719
Train loss on 1050 batch: 0.231269
Train loss on 1100 batch: 0.215278
Train loss on 1150 batch: 0.193850
Train loss on 1200 batch: 0.249733
Train loss on 1250 batch: 0.249282
Train loss on 1300 batch: 0.204584
Train loss on 1350 batch: 0.237145
Train loss on 1400 batch: 0.199860
Train loss on 1450 batch: 0.200815
Train loss on 1500 batch: 0.206975
Train loss on 1550 batch: 0.212495
Train loss on 1600 batch: 0.180309
Train loss on 1650 batch: 0.184929
Train loss on 1700 batch: 0.197506
Train loss on 1750 batch: 0.200917
Train loss on 1800 batch: 0.225890
Train loss on 1850 batch: 0.243877
Train loss on 1900 batch: 0.214837
Train loss on 1950 batch: 0.173924
Train loss on 2000 batch: 0.216474
Train loss on 2050 batch: 0.214594
Train loss on 2100 batch: 0.247113
Train loss on 2150 batch: 0.242240
: Epoch: 98 | Training Loss: 0.212816 | Val. Loss: 0.331663 | Val. Kappa Score: 0.7136 | LR: 0.000095 | Estimated time: 555.27
Train loss on 50 batch: 0.206209
Train loss on 100 batch: 0.213126
Train loss on 150 batch: 0.203032
Train loss on 200 batch: 0.206376
Train loss on 250 batch: 0.192410
Train loss on 300 batch: 0.237692
Train loss on 350 batch: 0.199353
Train loss on 400 batch: 0.212632
Train loss on 450 batch: 0.203614
Train loss on 500 batch: 0.217144
Train loss on 550 batch: 0.243364
Train loss on 600 batch: 0.205998
Train loss on 650 batch: 0.229289
Train loss on 700 batch: 0.209058
Train loss on 750 batch: 0.183514
Train loss on 800 batch: 0.190988
Train loss on 850 batch: 0.245442
Train loss on 900 batch: 0.232013
Train loss on 950 batch: 0.232238
Train loss on 1000 batch: 0.202997
Train loss on 1050 batch: 0.171829
Train loss on 1100 batch: 0.190498
Train loss on 1150 batch: 0.202457
Train loss on 1200 batch: 0.173538
Train loss on 1250 batch: 0.165477
Train loss on 1300 batch: 0.192325
Train loss on 1350 batch: 0.229513
Train loss on 1400 batch: 0.209650
Train loss on 1450 batch: 0.219239
Train loss on 1500 batch: 0.203617
Train loss on 1550 batch: 0.207451
Train loss on 1600 batch: 0.187458
Train loss on 1650 batch: 0.210375
Train loss on 1700 batch: 0.245464
Train loss on 1750 batch: 0.191712
Train loss on 1800 batch: 0.216581
Train loss on 1850 batch: 0.182212
Train loss on 1900 batch: 0.249941
Train loss on 1950 batch: 0.200936
Train loss on 2000 batch: 0.178270
Train loss on 2050 batch: 0.205355
Train loss on 2100 batch: 0.235469
Train loss on 2150 batch: 0.206858
: Epoch: 99 | Training Loss: 0.208443 | Val. Loss: 0.328347 | Val. Kappa Score: 0.7140 | LR: 0.000071 | Estimated time: 554.52
Train loss on 50 batch: 0.205479
Train loss on 100 batch: 0.208449
Train loss on 150 batch: 0.201281
Train loss on 200 batch: 0.216872
Train loss on 250 batch: 0.203479
Train loss on 300 batch: 0.213406
Train loss on 350 batch: 0.206085
Train loss on 400 batch: 0.212706
Train loss on 450 batch: 0.234456
Train loss on 500 batch: 0.232979
Train loss on 550 batch: 0.207592
Train loss on 600 batch: 0.215906
Train loss on 650 batch: 0.200537
Train loss on 700 batch: 0.172188
Train loss on 750 batch: 0.223770
Train loss on 800 batch: 0.185615
Train loss on 850 batch: 0.230721
Train loss on 900 batch: 0.194813
Train loss on 950 batch: 0.187113
Train loss on 1000 batch: 0.214993
Train loss on 1050 batch: 0.208570
Train loss on 1100 batch: 0.234632
Train loss on 1150 batch: 0.181551
Train loss on 1200 batch: 0.183249
Train loss on 1250 batch: 0.172667
Train loss on 1300 batch: 0.199350
Train loss on 1350 batch: 0.194447
Train loss on 1400 batch: 0.189098
Train loss on 1450 batch: 0.228209
Train loss on 1500 batch: 0.180461
Train loss on 1550 batch: 0.172354
Train loss on 1600 batch: 0.196082
Train loss on 1650 batch: 0.228581
Train loss on 1700 batch: 0.215086
Train loss on 1750 batch: 0.248959
Train loss on 1800 batch: 0.197937
Train loss on 1850 batch: 0.199508
Train loss on 1900 batch: 0.187626
Train loss on 1950 batch: 0.225069
Train loss on 2000 batch: 0.222237
Train loss on 2050 batch: 0.226168
Train loss on 2100 batch: 0.218192
Train loss on 2150 batch: 0.205664
: Epoch: 100 | Training Loss: 0.206769 | Val. Loss: 0.327789 | Val. Kappa Score: 0.7144 | LR: 0.000050 | Estimated time: 555.16
Train loss on 50 batch: 0.193478
Train loss on 100 batch: 0.187450
Train loss on 150 batch: 0.277396
Train loss on 200 batch: 0.198730
Train loss on 250 batch: 0.230764
Train loss on 300 batch: 0.166067
Train loss on 350 batch: 0.201705
Train loss on 400 batch: 0.182513
Train loss on 450 batch: 0.222305
Train loss on 500 batch: 0.238909
Train loss on 550 batch: 0.203362
Train loss on 600 batch: 0.208329
Train loss on 650 batch: 0.161239
Train loss on 700 batch: 0.235340
Train loss on 750 batch: 0.167224
Train loss on 800 batch: 0.201510
Train loss on 850 batch: 0.224154
Train loss on 900 batch: 0.263091
Train loss on 950 batch: 0.198063
Train loss on 1000 batch: 0.232312
Train loss on 1050 batch: 0.234303
Train loss on 1100 batch: 0.200424
Train loss on 1150 batch: 0.206462
Train loss on 1200 batch: 0.186281
Train loss on 1250 batch: 0.178066
Train loss on 1300 batch: 0.197681
Train loss on 1350 batch: 0.224896
Train loss on 1400 batch: 0.191565
Train loss on 1450 batch: 0.185884
Train loss on 1500 batch: 0.198396
Train loss on 1550 batch: 0.169589
Train loss on 1600 batch: 0.228028
Train loss on 1650 batch: 0.212636
Train loss on 1700 batch: 0.242372
Train loss on 1750 batch: 0.174281
Train loss on 1800 batch: 0.209286
Train loss on 1850 batch: 0.194010
Train loss on 1900 batch: 0.188443
Train loss on 1950 batch: 0.196530
Train loss on 2000 batch: 0.227254
Train loss on 2050 batch: 0.187442
Train loss on 2100 batch: 0.189129
Train loss on 2150 batch: 0.216574
: Epoch: 101 | Training Loss: 0.204475 | Val. Loss: 0.326668 | Val. Kappa Score: 0.7148 | LR: 0.000032 | Estimated time: 555.09
Train loss on 50 batch: 0.180429
Train loss on 100 batch: 0.193762
Train loss on 150 batch: 0.169428
Train loss on 200 batch: 0.206427
Train loss on 250 batch: 0.222241
Train loss on 300 batch: 0.170199
Train loss on 350 batch: 0.216066
Train loss on 400 batch: 0.179146
Train loss on 450 batch: 0.188798
Train loss on 500 batch: 0.189690
Train loss on 550 batch: 0.215644
Train loss on 600 batch: 0.209337
Train loss on 650 batch: 0.197201
Train loss on 700 batch: 0.170809
Train loss on 750 batch: 0.195701
Train loss on 800 batch: 0.179858
Train loss on 850 batch: 0.226730
Train loss on 900 batch: 0.185785
Train loss on 950 batch: 0.240272
Train loss on 1000 batch: 0.200685
Train loss on 1050 batch: 0.213481
Train loss on 1100 batch: 0.216358
Train loss on 1150 batch: 0.196639
Train loss on 1200 batch: 0.175116
Train loss on 1250 batch: 0.196914
Train loss on 1300 batch: 0.172583
Train loss on 1350 batch: 0.223365
Train loss on 1400 batch: 0.258661
Train loss on 1450 batch: 0.205222
Train loss on 1500 batch: 0.194774
Train loss on 1550 batch: 0.200478
Train loss on 1600 batch: 0.226866
Train loss on 1650 batch: 0.187816
Train loss on 1700 batch: 0.227615
Train loss on 1750 batch: 0.185379
Train loss on 1800 batch: 0.175670
Train loss on 1850 batch: 0.254926
Train loss on 1900 batch: 0.181066
Train loss on 1950 batch: 0.207906
Train loss on 2000 batch: 0.157754
Train loss on 2050 batch: 0.219931
Train loss on 2100 batch: 0.233147
Train loss on 2150 batch: 0.207607
: Epoch: 102 | Training Loss: 0.201652 | Val. Loss: 0.325325 | Val. Kappa Score: 0.7152 | LR: 0.000018 | Estimated time: 554.98
Train loss on 50 batch: 0.225906
Train loss on 100 batch: 0.205998
Train loss on 150 batch: 0.230606
Train loss on 200 batch: 0.221124
Train loss on 250 batch: 0.220639
Train loss on 300 batch: 0.184913
Train loss on 350 batch: 0.174747
Train loss on 400 batch: 0.186332
Train loss on 450 batch: 0.198503
Train loss on 500 batch: 0.171552
Train loss on 550 batch: 0.205803
Train loss on 600 batch: 0.214336
Train loss on 650 batch: 0.175096
Train loss on 700 batch: 0.209503
Train loss on 750 batch: 0.240371
Train loss on 800 batch: 0.210942
Train loss on 850 batch: 0.217251
Train loss on 900 batch: 0.180908
Train loss on 950 batch: 0.177406
Train loss on 1000 batch: 0.197718
Train loss on 1050 batch: 0.213620
Train loss on 1100 batch: 0.199683
Train loss on 1150 batch: 0.184908
Train loss on 1200 batch: 0.185355
Train loss on 1250 batch: 0.199117
Train loss on 1300 batch: 0.233724
Train loss on 1350 batch: 0.205781
Train loss on 1400 batch: 0.211999
Train loss on 1450 batch: 0.204923
Train loss on 1500 batch: 0.198497
Train loss on 1550 batch: 0.177671
Train loss on 1600 batch: 0.225156
Train loss on 1650 batch: 0.181684
Train loss on 1700 batch: 0.203212
Train loss on 1750 batch: 0.165138
Train loss on 1800 batch: 0.248779
Train loss on 1850 batch: 0.182275
Train loss on 1900 batch: 0.190543
Train loss on 1950 batch: 0.186824
Train loss on 2000 batch: 0.200003
Train loss on 2050 batch: 0.223764
Train loss on 2100 batch: 0.220051
Train loss on 2150 batch: 0.193265
: Epoch: 103 | Training Loss: 0.201389 | Val. Loss: 0.326413 | Val. Kappa Score: 0.7156 | LR: 0.000008 | Estimated time: 555.01
Train loss on 50 batch: 0.181987
Train loss on 100 batch: 0.222908
Train loss on 150 batch: 0.192688
Train loss on 200 batch: 0.192833
Train loss on 250 batch: 0.188970
Train loss on 300 batch: 0.235126
Train loss on 350 batch: 0.175562
Train loss on 400 batch: 0.179388
Train loss on 450 batch: 0.179826
Train loss on 500 batch: 0.183752
Train loss on 550 batch: 0.174131
Train loss on 600 batch: 0.181075
Train loss on 650 batch: 0.196787
Train loss on 700 batch: 0.215895
Train loss on 750 batch: 0.159935
Train loss on 800 batch: 0.268943
Train loss on 850 batch: 0.183787
Train loss on 900 batch: 0.220660
Train loss on 950 batch: 0.148224
Train loss on 1000 batch: 0.209515
Train loss on 1050 batch: 0.158772
Train loss on 1100 batch: 0.224858
Train loss on 1150 batch: 0.198683
Train loss on 1200 batch: 0.226119
Train loss on 1250 batch: 0.225605
Train loss on 1300 batch: 0.223020
Train loss on 1350 batch: 0.201360
Train loss on 1400 batch: 0.190805
Train loss on 1450 batch: 0.195223
Train loss on 1500 batch: 0.209653
Train loss on 1550 batch: 0.226313
Train loss on 1600 batch: 0.205497
Train loss on 1650 batch: 0.210882
Train loss on 1700 batch: 0.202162
Train loss on 1750 batch: 0.160783
Train loss on 1800 batch: 0.193703
Train loss on 1850 batch: 0.210435
Train loss on 1900 batch: 0.188714
Train loss on 1950 batch: 0.190109
Train loss on 2000 batch: 0.189774
Train loss on 2050 batch: 0.191010
Train loss on 2100 batch: 0.209535
Train loss on 2150 batch: 0.191945
: Epoch: 104 | Training Loss: 0.197989 | Val. Loss: 0.325603 | Val. Kappa Score: 0.7160 | LR: 0.000002 | Estimated time: 554.42
Train loss on 50 batch: 0.185387
Train loss on 100 batch: 0.173135
Train loss on 150 batch: 0.197773
Train loss on 200 batch: 0.225649
Train loss on 250 batch: 0.150264
Train loss on 300 batch: 0.176057
Train loss on 350 batch: 0.247156
Train loss on 400 batch: 0.191983
Train loss on 450 batch: 0.178992
Train loss on 500 batch: 0.195958
Train loss on 550 batch: 0.209757
Train loss on 600 batch: 0.210118
Train loss on 650 batch: 0.168635
Train loss on 700 batch: 0.172083
Train loss on 750 batch: 0.187988
Train loss on 800 batch: 0.220971
Train loss on 850 batch: 0.238593
Train loss on 900 batch: 0.201061
Train loss on 950 batch: 0.206771
Train loss on 1000 batch: 0.152852
Train loss on 1050 batch: 0.168363
Train loss on 1100 batch: 0.202284
Train loss on 1150 batch: 0.197996
Train loss on 1200 batch: 0.222723
Train loss on 1250 batch: 0.209592
Train loss on 1300 batch: 0.236517
Train loss on 1350 batch: 0.191290
Train loss on 1400 batch: 0.222060
Train loss on 1450 batch: 0.250238
Train loss on 1500 batch: 0.217513
Train loss on 1550 batch: 0.198766
Train loss on 1600 batch: 0.163799
Train loss on 1650 batch: 0.197123
Train loss on 1700 batch: 0.191474
Train loss on 1750 batch: 0.195156
Train loss on 1800 batch: 0.226300
Train loss on 1850 batch: 0.186117
Train loss on 1900 batch: 0.178296
Train loss on 1950 batch: 0.209670
Train loss on 2000 batch: 0.206734
Train loss on 2050 batch: 0.184685
Train loss on 2100 batch: 0.189062
Train loss on 2150 batch: 0.211057
: Epoch: 105 | Training Loss: 0.200314 | Val. Loss: 0.326498 | Val. Kappa Score: 0.7164 | LR: 0.000000 | Estimated time: 554.77
Train loss on 50 batch: 0.200893
Train loss on 100 batch: 0.193121
Train loss on 150 batch: 0.205175
Train loss on 200 batch: 0.225509
Train loss on 250 batch: 0.209911
Train loss on 300 batch: 0.211184
Train loss on 350 batch: 0.221340
Train loss on 400 batch: 0.189080
Train loss on 450 batch: 0.199071
Train loss on 500 batch: 0.188185
Train loss on 550 batch: 0.201848
Train loss on 600 batch: 0.194666
Train loss on 650 batch: 0.223282
Train loss on 700 batch: 0.207560
Train loss on 750 batch: 0.207115
Train loss on 800 batch: 0.215396
Train loss on 850 batch: 0.188749
Train loss on 900 batch: 0.178402
Train loss on 950 batch: 0.215322
Train loss on 1000 batch: 0.233162
Train loss on 1050 batch: 0.202791
Train loss on 1100 batch: 0.232552
Train loss on 1150 batch: 0.181020
Train loss on 1200 batch: 0.203174
Train loss on 1250 batch: 0.190559
Train loss on 1300 batch: 0.184169
Train loss on 1350 batch: 0.178851
Train loss on 1400 batch: 0.199995
Train loss on 1450 batch: 0.198201
Train loss on 1500 batch: 0.192090
Train loss on 1550 batch: 0.175074
Train loss on 1600 batch: 0.170657
Train loss on 1650 batch: 0.225925
Train loss on 1700 batch: 0.169942
Train loss on 1750 batch: 0.157104
Train loss on 1800 batch: 0.191779
Train loss on 1850 batch: 0.228353
Train loss on 1900 batch: 0.198814
Train loss on 1950 batch: 0.195755
Train loss on 2000 batch: 0.192057
Train loss on 2050 batch: 0.217162
Train loss on 2100 batch: 0.197203
Train loss on 2150 batch: 0.178707
: Epoch: 106 | Training Loss: 0.199963 | Val. Loss: 0.327088 | Val. Kappa Score: 0.7165 | LR: 0.000002 | Estimated time: 554.66
Train loss on 50 batch: 0.178852
Train loss on 100 batch: 0.210238
Train loss on 150 batch: 0.225669
Train loss on 200 batch: 0.224446
Train loss on 250 batch: 0.207202
Train loss on 300 batch: 0.184614
Train loss on 350 batch: 0.171478
Train loss on 400 batch: 0.174625
Train loss on 450 batch: 0.197489
Train loss on 500 batch: 0.187934
Train loss on 550 batch: 0.157597
Train loss on 600 batch: 0.253936
Train loss on 650 batch: 0.219734
Train loss on 700 batch: 0.191316
Train loss on 750 batch: 0.188864
Train loss on 800 batch: 0.220873
Train loss on 850 batch: 0.145271
Train loss on 900 batch: 0.193856
Train loss on 950 batch: 0.186889
Train loss on 1000 batch: 0.168884
Train loss on 1050 batch: 0.188446
Train loss on 1100 batch: 0.180090
Train loss on 1150 batch: 0.171587
Train loss on 1200 batch: 0.218960
Train loss on 1250 batch: 0.183417
Train loss on 1300 batch: 0.181362
Train loss on 1350 batch: 0.205488
Train loss on 1400 batch: 0.186001
Train loss on 1450 batch: 0.213260
Train loss on 1500 batch: 0.217682
Train loss on 1550 batch: 0.186736
Train loss on 1600 batch: 0.190769
Train loss on 1650 batch: 0.205832
Train loss on 1700 batch: 0.199560
Train loss on 1750 batch: 0.228110
Train loss on 1800 batch: 0.229732
Train loss on 1850 batch: 0.222235
Train loss on 1900 batch: 0.205252
Train loss on 1950 batch: 0.207625
Train loss on 2000 batch: 0.207024
Train loss on 2050 batch: 0.225472
Train loss on 2100 batch: 0.219234
Train loss on 2150 batch: 0.179320
: Epoch: 107 | Training Loss: 0.199227 | Val. Loss: 0.325505 | Val. Kappa Score: 0.7168 | LR: 0.000008 | Estimated time: 554.93
Train loss on 50 batch: 0.208504
Train loss on 100 batch: 0.227291
Train loss on 150 batch: 0.248741
Train loss on 200 batch: 0.166954
Train loss on 250 batch: 0.181634
Train loss on 300 batch: 0.195474
Train loss on 350 batch: 0.177698
Train loss on 400 batch: 0.181917
Train loss on 450 batch: 0.211936
Train loss on 500 batch: 0.193577
Train loss on 550 batch: 0.211946
Train loss on 600 batch: 0.217733
Train loss on 650 batch: 0.186297
Train loss on 700 batch: 0.194264
Train loss on 750 batch: 0.186003
Train loss on 800 batch: 0.196678
Train loss on 850 batch: 0.181690
Train loss on 900 batch: 0.171856
Train loss on 950 batch: 0.190007
Train loss on 1000 batch: 0.206141
Train loss on 1050 batch: 0.183583
Train loss on 1100 batch: 0.165375
Train loss on 1150 batch: 0.249597
Train loss on 1200 batch: 0.204197
Train loss on 1250 batch: 0.190954
Train loss on 1300 batch: 0.213963
Train loss on 1350 batch: 0.211764
Train loss on 1400 batch: 0.231889
Train loss on 1450 batch: 0.198563
Train loss on 1500 batch: 0.175576
Train loss on 1550 batch: 0.159213
Train loss on 1600 batch: 0.211035
Train loss on 1650 batch: 0.224649
Train loss on 1700 batch: 0.231982
Train loss on 1750 batch: 0.180130
Train loss on 1800 batch: 0.225752
Train loss on 1850 batch: 0.168326
Train loss on 1900 batch: 0.185318
Train loss on 1950 batch: 0.184694
Train loss on 2000 batch: 0.202657
Train loss on 2050 batch: 0.223233
Train loss on 2100 batch: 0.173272
Train loss on 2150 batch: 0.195883
: Epoch: 108 | Training Loss: 0.197556 | Val. Loss: 0.327191 | Val. Kappa Score: 0.7172 | LR: 0.000018 | Estimated time: 554.96
Train loss on 50 batch: 0.212949
Train loss on 100 batch: 0.215728
Train loss on 150 batch: 0.179026
Train loss on 200 batch: 0.201353
Train loss on 250 batch: 0.208415
Train loss on 300 batch: 0.241581
Train loss on 350 batch: 0.172749
Train loss on 400 batch: 0.183981
Train loss on 450 batch: 0.197188
Train loss on 500 batch: 0.190027
Train loss on 550 batch: 0.207459
Train loss on 600 batch: 0.194906
Train loss on 650 batch: 0.182909
Train loss on 700 batch: 0.201533
Train loss on 750 batch: 0.245386
Train loss on 800 batch: 0.191553
Train loss on 850 batch: 0.191692
Train loss on 900 batch: 0.207773
Train loss on 950 batch: 0.170663
Train loss on 1000 batch: 0.218627
Train loss on 1050 batch: 0.188554
Train loss on 1100 batch: 0.205091
Train loss on 1150 batch: 0.239888
Train loss on 1200 batch: 0.186099
Train loss on 1250 batch: 0.180458
Train loss on 1300 batch: 0.194884
Train loss on 1350 batch: 0.202907
Train loss on 1400 batch: 0.214547
Train loss on 1450 batch: 0.199825
Train loss on 1500 batch: 0.199735
Train loss on 1550 batch: 0.190738
Train loss on 1600 batch: 0.176684
Train loss on 1650 batch: 0.198576
Train loss on 1700 batch: 0.204171
Train loss on 1750 batch: 0.201969
Train loss on 1800 batch: 0.222727
Train loss on 1850 batch: 0.188356
Train loss on 1900 batch: 0.209102
Train loss on 1950 batch: 0.199698
Train loss on 2000 batch: 0.182080
Train loss on 2050 batch: 0.183046
Train loss on 2100 batch: 0.233437
Train loss on 2150 batch: 0.190539
: Epoch: 109 | Training Loss: 0.199606 | Val. Loss: 0.324334 | Val. Kappa Score: 0.7176 | LR: 0.000032 | Estimated time: 554.78
Train loss on 50 batch: 0.223065
Train loss on 100 batch: 0.190225
Train loss on 150 batch: 0.206706
Train loss on 200 batch: 0.195295
Train loss on 250 batch: 0.197323
Train loss on 300 batch: 0.219054
Train loss on 350 batch: 0.192329
Train loss on 400 batch: 0.199159
Train loss on 450 batch: 0.210427
Train loss on 500 batch: 0.209302
Train loss on 550 batch: 0.230103
Train loss on 600 batch: 0.209070
Train loss on 650 batch: 0.212036
Train loss on 700 batch: 0.207900
Train loss on 750 batch: 0.134394
Train loss on 800 batch: 0.224849
Train loss on 850 batch: 0.185948
Train loss on 900 batch: 0.238655
Train loss on 950 batch: 0.198021
Train loss on 1000 batch: 0.178090
Train loss on 1050 batch: 0.191441
Train loss on 1100 batch: 0.191889
Train loss on 1150 batch: 0.207976
Train loss on 1200 batch: 0.180186
Train loss on 1250 batch: 0.233001
Train loss on 1300 batch: 0.189438
Train loss on 1350 batch: 0.195045
Train loss on 1400 batch: 0.186829
Train loss on 1450 batch: 0.164402
Train loss on 1500 batch: 0.196987
Train loss on 1550 batch: 0.213008
Train loss on 1600 batch: 0.184080
Train loss on 1650 batch: 0.186434
Train loss on 1700 batch: 0.208069
Train loss on 1750 batch: 0.215439
Train loss on 1800 batch: 0.188284
Train loss on 1850 batch: 0.208139
Train loss on 1900 batch: 0.184777
Train loss on 1950 batch: 0.191580
Train loss on 2000 batch: 0.183930
Train loss on 2050 batch: 0.190387
Train loss on 2100 batch: 0.221163
Train loss on 2150 batch: 0.205871
: Epoch: 110 | Training Loss: 0.199631 | Val. Loss: 0.324673 | Val. Kappa Score: 0.7180 | LR: 0.000050 | Estimated time: 554.93
Train loss on 50 batch: 0.184754
Train loss on 100 batch: 0.203153
Train loss on 150 batch: 0.217799
Train loss on 200 batch: 0.209507
Train loss on 250 batch: 0.192723
Train loss on 300 batch: 0.187307
Train loss on 350 batch: 0.219332
Train loss on 400 batch: 0.216962
Train loss on 450 batch: 0.198514
Train loss on 500 batch: 0.209642
Train loss on 550 batch: 0.177631
Train loss on 600 batch: 0.196256
Train loss on 650 batch: 0.208224
Train loss on 700 batch: 0.198328
Train loss on 750 batch: 0.206742
Train loss on 800 batch: 0.195762
Train loss on 850 batch: 0.232757
Train loss on 900 batch: 0.181319
Train loss on 950 batch: 0.199607
Train loss on 1000 batch: 0.197312
Train loss on 1050 batch: 0.211690
Train loss on 1100 batch: 0.193415
Train loss on 1150 batch: 0.170280
Train loss on 1200 batch: 0.178649
Train loss on 1250 batch: 0.209947
Train loss on 1300 batch: 0.175582
Train loss on 1350 batch: 0.183589
Train loss on 1400 batch: 0.215845
Train loss on 1450 batch: 0.164135
Train loss on 1500 batch: 0.226871
Train loss on 1550 batch: 0.248751
Train loss on 1600 batch: 0.216167
Train loss on 1650 batch: 0.228020
Train loss on 1700 batch: 0.199362
Train loss on 1750 batch: 0.149152
Train loss on 1800 batch: 0.203422
Train loss on 1850 batch: 0.199534
Train loss on 1900 batch: 0.180122
Train loss on 1950 batch: 0.213402
Train loss on 2000 batch: 0.205859
Train loss on 2050 batch: 0.239890
Train loss on 2100 batch: 0.196406
Train loss on 2150 batch: 0.216291
: Epoch: 111 | Training Loss: 0.201260 | Val. Loss: 0.330436 | Val. Kappa Score: 0.7183 | LR: 0.000071 | Estimated time: 554.89
Train loss on 50 batch: 0.191090
Train loss on 100 batch: 0.252708
Train loss on 150 batch: 0.199290
Train loss on 200 batch: 0.201078
Train loss on 250 batch: 0.208974
Train loss on 300 batch: 0.158331
Train loss on 350 batch: 0.192280
Train loss on 400 batch: 0.172758
Train loss on 450 batch: 0.220675
Train loss on 500 batch: 0.210759
Train loss on 550 batch: 0.184669
Train loss on 600 batch: 0.220826
Train loss on 650 batch: 0.163927
Train loss on 700 batch: 0.171018
Train loss on 750 batch: 0.167755
Train loss on 800 batch: 0.224092
Train loss on 850 batch: 0.159180
Train loss on 900 batch: 0.182573
Train loss on 950 batch: 0.182127
Train loss on 1000 batch: 0.226228
Train loss on 1050 batch: 0.180073
Train loss on 1100 batch: 0.212477
Train loss on 1150 batch: 0.213928
Train loss on 1200 batch: 0.198484
Train loss on 1250 batch: 0.195348
Train loss on 1300 batch: 0.213222
Train loss on 1350 batch: 0.195990
Train loss on 1400 batch: 0.203302
Train loss on 1450 batch: 0.239602
Train loss on 1500 batch: 0.190635
Train loss on 1550 batch: 0.208565
Train loss on 1600 batch: 0.213271
Train loss on 1650 batch: 0.223737
Train loss on 1700 batch: 0.197692
Train loss on 1750 batch: 0.234405
Train loss on 1800 batch: 0.197573
Train loss on 1850 batch: 0.215100
Train loss on 1900 batch: 0.181860
Train loss on 1950 batch: 0.185894
Train loss on 2000 batch: 0.201459
Train loss on 2050 batch: 0.199730
Train loss on 2100 batch: 0.143582
Train loss on 2150 batch: 0.197172
: Epoch: 112 | Training Loss: 0.197563 | Val. Loss: 0.326623 | Val. Kappa Score: 0.7186 | LR: 0.000095 | Estimated time: 555.05
Train loss on 50 batch: 0.194391
Train loss on 100 batch: 0.251581
Train loss on 150 batch: 0.188774
Train loss on 200 batch: 0.200526
Train loss on 250 batch: 0.219297
Train loss on 300 batch: 0.202298
Train loss on 350 batch: 0.185450
Train loss on 400 batch: 0.207076
Train loss on 450 batch: 0.151476
Train loss on 500 batch: 0.212465
Train loss on 550 batch: 0.210924
Train loss on 600 batch: 0.209011
Train loss on 650 batch: 0.204879
Train loss on 700 batch: 0.227622
Train loss on 750 batch: 0.215128
Train loss on 800 batch: 0.193493
Train loss on 850 batch: 0.181750
Train loss on 900 batch: 0.165828
Train loss on 950 batch: 0.202405
Train loss on 1000 batch: 0.193471
Train loss on 1050 batch: 0.207035
Train loss on 1100 batch: 0.193876
Train loss on 1150 batch: 0.201431
Train loss on 1200 batch: 0.167554
Train loss on 1250 batch: 0.174806
Train loss on 1300 batch: 0.227654
Train loss on 1350 batch: 0.176711
Train loss on 1400 batch: 0.184272
Train loss on 1450 batch: 0.196840
Train loss on 1500 batch: 0.207351
Train loss on 1550 batch: 0.171857
Train loss on 1600 batch: 0.231920
Train loss on 1650 batch: 0.226570
Train loss on 1700 batch: 0.224528
Train loss on 1750 batch: 0.198032
Train loss on 1800 batch: 0.161334
Train loss on 1850 batch: 0.223339
Train loss on 1900 batch: 0.204333
Train loss on 1950 batch: 0.195061
Train loss on 2000 batch: 0.219237
Train loss on 2050 batch: 0.199289
Train loss on 2100 batch: 0.199090
Train loss on 2150 batch: 0.173447
: Epoch: 113 | Training Loss: 0.200560 | Val. Loss: 0.330147 | Val. Kappa Score: 0.7189 | LR: 0.000123 | Estimated time: 554.59
Train loss on 50 batch: 0.251751
Train loss on 100 batch: 0.201675
Train loss on 150 batch: 0.194241
Train loss on 200 batch: 0.191555
Train loss on 250 batch: 0.232042
Train loss on 300 batch: 0.191836
Train loss on 350 batch: 0.241967
Train loss on 400 batch: 0.169030
Train loss on 450 batch: 0.223310
Train loss on 500 batch: 0.182739
Train loss on 550 batch: 0.178298
Train loss on 600 batch: 0.199738
Train loss on 650 batch: 0.187147
Train loss on 700 batch: 0.210841
Train loss on 750 batch: 0.203276
Train loss on 800 batch: 0.174671
Train loss on 850 batch: 0.198612
Train loss on 900 batch: 0.210321
Train loss on 950 batch: 0.208822
Train loss on 1000 batch: 0.181470
Train loss on 1050 batch: 0.165989
Train loss on 1100 batch: 0.249365
Train loss on 1150 batch: 0.222409
Train loss on 1200 batch: 0.178699
Train loss on 1250 batch: 0.171778
Train loss on 1300 batch: 0.211953
Train loss on 1350 batch: 0.185047
Train loss on 1400 batch: 0.228772
Train loss on 1450 batch: 0.185317
Train loss on 1500 batch: 0.222770
Train loss on 1550 batch: 0.253574
Train loss on 1600 batch: 0.204030
Train loss on 1650 batch: 0.185655
Train loss on 1700 batch: 0.184098
Train loss on 1750 batch: 0.221851
Train loss on 1800 batch: 0.198937
Train loss on 1850 batch: 0.255355
Train loss on 1900 batch: 0.191288
Train loss on 1950 batch: 0.201086
Train loss on 2000 batch: 0.198698
Train loss on 2050 batch: 0.187011
Train loss on 2100 batch: 0.198564
Train loss on 2150 batch: 0.202762
: Epoch: 114 | Training Loss: 0.202455 | Val. Loss: 0.335816 | Val. Kappa Score: 0.7191 | LR: 0.000154 | Estimated time: 554.94
Train loss on 50 batch: 0.197001
Train loss on 100 batch: 0.207093
Train loss on 150 batch: 0.149373
Train loss on 200 batch: 0.219904
Train loss on 250 batch: 0.187365
Train loss on 300 batch: 0.206303
Train loss on 350 batch: 0.183202
Train loss on 400 batch: 0.176352
Train loss on 450 batch: 0.207476
Train loss on 500 batch: 0.194779
Train loss on 550 batch: 0.214755
Train loss on 600 batch: 0.217019
Train loss on 650 batch: 0.198939
Train loss on 700 batch: 0.227347
Train loss on 750 batch: 0.201803
Train loss on 800 batch: 0.239407
Train loss on 850 batch: 0.214498
Train loss on 900 batch: 0.169071
Train loss on 950 batch: 0.235885
Train loss on 1000 batch: 0.182208
Train loss on 1050 batch: 0.211579
Train loss on 1100 batch: 0.178286
Train loss on 1150 batch: 0.181788
Train loss on 1200 batch: 0.250688
Train loss on 1250 batch: 0.195696
Train loss on 1300 batch: 0.234256
Train loss on 1350 batch: 0.197847
Train loss on 1400 batch: 0.190865
Train loss on 1450 batch: 0.241477
Train loss on 1500 batch: 0.211134
Train loss on 1550 batch: 0.219800
Train loss on 1600 batch: 0.190695
Train loss on 1650 batch: 0.264635
Train loss on 1700 batch: 0.183966
Train loss on 1750 batch: 0.188450
Train loss on 1800 batch: 0.219342
Train loss on 1850 batch: 0.179138
Train loss on 1900 batch: 0.232392
Train loss on 1950 batch: 0.207055
Train loss on 2000 batch: 0.179658
Train loss on 2050 batch: 0.201539
Train loss on 2100 batch: 0.213089
Train loss on 2150 batch: 0.198015
: Epoch: 115 | Training Loss: 0.203756 | Val. Loss: 0.333327 | Val. Kappa Score: 0.7194 | LR: 0.000188 | Estimated time: 554.75
Train loss on 50 batch: 0.242906
Train loss on 100 batch: 0.204377
Train loss on 150 batch: 0.214260
Train loss on 200 batch: 0.187226
Train loss on 250 batch: 0.185720
Train loss on 300 batch: 0.164016
Train loss on 350 batch: 0.173086
Train loss on 400 batch: 0.223483
Train loss on 450 batch: 0.206225
Train loss on 500 batch: 0.202130
Train loss on 550 batch: 0.210196
Train loss on 600 batch: 0.215343
Train loss on 650 batch: 0.231580
Train loss on 700 batch: 0.182989
Train loss on 750 batch: 0.250266
Train loss on 800 batch: 0.218753
Train loss on 850 batch: 0.182928
Train loss on 900 batch: 0.189606
Train loss on 950 batch: 0.215988
Train loss on 1000 batch: 0.248743
Train loss on 1050 batch: 0.214667
Train loss on 1100 batch: 0.183828
Train loss on 1150 batch: 0.178496
Train loss on 1200 batch: 0.222916
Train loss on 1250 batch: 0.189117
Train loss on 1300 batch: 0.232554
Train loss on 1350 batch: 0.205084
Train loss on 1400 batch: 0.165664
Train loss on 1450 batch: 0.215517
Train loss on 1500 batch: 0.196356
Train loss on 1550 batch: 0.181738
Train loss on 1600 batch: 0.227497
Train loss on 1650 batch: 0.232215
Train loss on 1700 batch: 0.182576
Train loss on 1750 batch: 0.213817
Train loss on 1800 batch: 0.197006
Train loss on 1850 batch: 0.191632
Train loss on 1900 batch: 0.214519
Train loss on 1950 batch: 0.204730
Train loss on 2000 batch: 0.224333
Train loss on 2050 batch: 0.190275
Train loss on 2100 batch: 0.222716
Train loss on 2150 batch: 0.216664
: Epoch: 116 | Training Loss: 0.207226 | Val. Loss: 0.348802 | Val. Kappa Score: 0.7196 | LR: 0.000225 | Estimated time: 554.86
Train loss on 50 batch: 0.196780
Train loss on 100 batch: 0.218158
Train loss on 150 batch: 0.203313
Train loss on 200 batch: 0.190803
Train loss on 250 batch: 0.233168
Train loss on 300 batch: 0.207612
Train loss on 350 batch: 0.219418
Train loss on 400 batch: 0.221047
Train loss on 450 batch: 0.167272
Train loss on 500 batch: 0.185552
Train loss on 550 batch: 0.209097
Train loss on 600 batch: 0.242824
Train loss on 650 batch: 0.180222
Train loss on 700 batch: 0.204486
Train loss on 750 batch: 0.197018
Train loss on 800 batch: 0.214842
Train loss on 850 batch: 0.216138
Train loss on 900 batch: 0.211068
Train loss on 950 batch: 0.260219
Train loss on 1000 batch: 0.212803
Train loss on 1050 batch: 0.214259
Train loss on 1100 batch: 0.207562
Train loss on 1150 batch: 0.169333
Train loss on 1200 batch: 0.213689
Train loss on 1250 batch: 0.236728
Train loss on 1300 batch: 0.184504
Train loss on 1350 batch: 0.230420
Train loss on 1400 batch: 0.205539
Train loss on 1450 batch: 0.198281
Train loss on 1500 batch: 0.167421
Train loss on 1550 batch: 0.214320
Train loss on 1600 batch: 0.217184
Train loss on 1650 batch: 0.205453
Train loss on 1700 batch: 0.190052
Train loss on 1750 batch: 0.225533
Train loss on 1800 batch: 0.169791
Train loss on 1850 batch: 0.208384
Train loss on 1900 batch: 0.256282
Train loss on 1950 batch: 0.212262
Train loss on 2000 batch: 0.226377
Train loss on 2050 batch: 0.222735
Train loss on 2100 batch: 0.259773
Train loss on 2150 batch: 0.211085
: Epoch: 117 | Training Loss: 0.209906 | Val. Loss: 0.338336 | Val. Kappa Score: 0.7197 | LR: 0.000263 | Estimated time: 555.22
Train loss on 50 batch: 0.187778
Train loss on 100 batch: 0.219184
Train loss on 150 batch: 0.217539
Train loss on 200 batch: 0.221015
Train loss on 250 batch: 0.225844
Train loss on 300 batch: 0.192355
Train loss on 350 batch: 0.224674
Train loss on 400 batch: 0.203340
Train loss on 450 batch: 0.193699
Train loss on 500 batch: 0.240969
Train loss on 550 batch: 0.209116
Train loss on 600 batch: 0.230887
Train loss on 650 batch: 0.215838
Train loss on 700 batch: 0.232939
Train loss on 750 batch: 0.196634
Train loss on 800 batch: 0.233736
Train loss on 850 batch: 0.248090
Train loss on 900 batch: 0.224810
Train loss on 950 batch: 0.204439
Train loss on 1000 batch: 0.207938
Train loss on 1050 batch: 0.181505
Train loss on 1100 batch: 0.224425
Train loss on 1150 batch: 0.200912
Train loss on 1200 batch: 0.230486
Train loss on 1250 batch: 0.199995
Train loss on 1300 batch: 0.201169
Train loss on 1350 batch: 0.180733
Train loss on 1400 batch: 0.241164
Train loss on 1450 batch: 0.196575
Train loss on 1500 batch: 0.182766
Train loss on 1550 batch: 0.210837
Train loss on 1600 batch: 0.199701
Train loss on 1650 batch: 0.198855
Train loss on 1700 batch: 0.207471
Train loss on 1750 batch: 0.237833
Train loss on 1800 batch: 0.199523
Train loss on 1850 batch: 0.206064
Train loss on 1900 batch: 0.209007
Train loss on 1950 batch: 0.259180
Train loss on 2000 batch: 0.187803
Train loss on 2050 batch: 0.195907
Train loss on 2100 batch: 0.241759
Train loss on 2150 batch: 0.203463
: Epoch: 118 | Training Loss: 0.211265 | Val. Loss: 0.361336 | Val. Kappa Score: 0.7198 | LR: 0.000303 | Estimated time: 554.98
Train loss on 50 batch: 0.196137
Train loss on 100 batch: 0.206749
Train loss on 150 batch: 0.196122
Train loss on 200 batch: 0.208417
Train loss on 250 batch: 0.200165
Train loss on 300 batch: 0.271747
Train loss on 350 batch: 0.247273
Train loss on 400 batch: 0.197089
Train loss on 450 batch: 0.259510
Train loss on 500 batch: 0.238229
Train loss on 550 batch: 0.210720
Train loss on 600 batch: 0.210713
Train loss on 650 batch: 0.229410
Train loss on 700 batch: 0.202373
Train loss on 750 batch: 0.204937
Train loss on 800 batch: 0.226700
Train loss on 850 batch: 0.221502
Train loss on 900 batch: 0.261609
Train loss on 950 batch: 0.197368
Train loss on 1000 batch: 0.190665
Train loss on 1050 batch: 0.201095
Train loss on 1100 batch: 0.160980
Train loss on 1150 batch: 0.165818
Train loss on 1200 batch: 0.214986
Train loss on 1250 batch: 0.211112
Train loss on 1300 batch: 0.221583
Train loss on 1350 batch: 0.217554
Train loss on 1400 batch: 0.220335
Train loss on 1450 batch: 0.175990
Train loss on 1500 batch: 0.220668
Train loss on 1550 batch: 0.196517
Train loss on 1600 batch: 0.230890
Train loss on 1650 batch: 0.209108
Train loss on 1700 batch: 0.249091
Train loss on 1750 batch: 0.204154
Train loss on 1800 batch: 0.249488
Train loss on 1850 batch: 0.217409
Train loss on 1900 batch: 0.221018
Train loss on 1950 batch: 0.235137
Train loss on 2000 batch: 0.198510
Train loss on 2050 batch: 0.180298
Train loss on 2100 batch: 0.200557
Train loss on 2150 batch: 0.261864
: Epoch: 119 | Training Loss: 0.214312 | Val. Loss: 0.373543 | Val. Kappa Score: 0.7199 | LR: 0.000345 | Estimated time: 554.54
Train loss on 50 batch: 0.243565
Train loss on 100 batch: 0.250097
Train loss on 150 batch: 0.206122
Train loss on 200 batch: 0.190331
Train loss on 250 batch: 0.228531
Train loss on 300 batch: 0.236218
Train loss on 350 batch: 0.203142
Train loss on 400 batch: 0.243809
Train loss on 450 batch: 0.183509
Train loss on 500 batch: 0.220096
Train loss on 550 batch: 0.210593
Train loss on 600 batch: 0.215706
Train loss on 650 batch: 0.254970
Train loss on 700 batch: 0.209885
Train loss on 750 batch: 0.223369
Train loss on 800 batch: 0.197622
Train loss on 850 batch: 0.205585
Train loss on 900 batch: 0.197818
Train loss on 950 batch: 0.216106
Train loss on 1000 batch: 0.216797
Train loss on 1050 batch: 0.222385
Train loss on 1100 batch: 0.199303
Train loss on 1150 batch: 0.161340
Train loss on 1200 batch: 0.190333
Train loss on 1250 batch: 0.209766
Train loss on 1300 batch: 0.260642
Train loss on 1350 batch: 0.177633
Train loss on 1400 batch: 0.253341
Train loss on 1450 batch: 0.245291
Train loss on 1500 batch: 0.266677
Train loss on 1550 batch: 0.216616
Train loss on 1600 batch: 0.232872
Train loss on 1650 batch: 0.245358
Train loss on 1700 batch: 0.221664
Train loss on 1750 batch: 0.202675
Train loss on 1800 batch: 0.203964
Train loss on 1850 batch: 0.215201
Train loss on 1900 batch: 0.244463
Train loss on 1950 batch: 0.199036
Train loss on 2000 batch: 0.228956
Train loss on 2050 batch: 0.232003
Train loss on 2100 batch: 0.200425
Train loss on 2150 batch: 0.198678
: Epoch: 120 | Training Loss: 0.218409 | Val. Loss: 0.333110 | Val. Kappa Score: 0.7202 | LR: 0.000389 | Estimated time: 555.09
Train loss on 50 batch: 0.211288
Train loss on 100 batch: 0.227482
Train loss on 150 batch: 0.250260
Train loss on 200 batch: 0.195767
Train loss on 250 batch: 0.197814
Train loss on 300 batch: 0.188416
Train loss on 350 batch: 0.189407
Train loss on 400 batch: 0.229136
Train loss on 450 batch: 0.222608
Train loss on 500 batch: 0.241649
Train loss on 550 batch: 0.265857
Train loss on 600 batch: 0.229400
Train loss on 650 batch: 0.211492
Train loss on 700 batch: 0.212949
Train loss on 750 batch: 0.169578
Train loss on 800 batch: 0.207219
Train loss on 850 batch: 0.245376
Train loss on 900 batch: 0.291380
Train loss on 950 batch: 0.183451
Train loss on 1000 batch: 0.200696
Train loss on 1050 batch: 0.229859
Train loss on 1100 batch: 0.224236
Train loss on 1150 batch: 0.201441
Train loss on 1200 batch: 0.214743
Train loss on 1250 batch: 0.227275
Train loss on 1300 batch: 0.230325
Train loss on 1350 batch: 0.262030
Train loss on 1400 batch: 0.192776
Train loss on 1450 batch: 0.221483
Train loss on 1500 batch: 0.238293
Train loss on 1550 batch: 0.224054
Train loss on 1600 batch: 0.212679
Train loss on 1650 batch: 0.220873
Train loss on 1700 batch: 0.224768
Train loss on 1750 batch: 0.265523
Train loss on 1800 batch: 0.234126
Train loss on 1850 batch: 0.259298
Train loss on 1900 batch: 0.255584
Train loss on 1950 batch: 0.251834
Train loss on 2000 batch: 0.218086
Train loss on 2050 batch: 0.203045
Train loss on 2100 batch: 0.249283
Train loss on 2150 batch: 0.249097
: Epoch: 121 | Training Loss: 0.225937 | Val. Loss: 0.403780 | Val. Kappa Score: 0.7202 | LR: 0.000433 | Estimated time: 554.94
Train loss on 50 batch: 0.208126
Train loss on 100 batch: 0.221011
Train loss on 150 batch: 0.225557
Train loss on 200 batch: 0.188542
Train loss on 250 batch: 0.225055
Train loss on 300 batch: 0.252111
Train loss on 350 batch: 0.247608
Train loss on 400 batch: 0.207929
Train loss on 450 batch: 0.241148
Train loss on 500 batch: 0.185162
Train loss on 550 batch: 0.259953
Train loss on 600 batch: 0.200363
Train loss on 650 batch: 0.249666
Train loss on 700 batch: 0.220711
Train loss on 750 batch: 0.203448
Train loss on 800 batch: 0.229748
Train loss on 850 batch: 0.250080
Train loss on 900 batch: 0.211855
Train loss on 950 batch: 0.237660
Train loss on 1000 batch: 0.198964
Train loss on 1050 batch: 0.245502
Train loss on 1100 batch: 0.238395
Train loss on 1150 batch: 0.235909
Train loss on 1200 batch: 0.229035
Train loss on 1250 batch: 0.206047
Train loss on 1300 batch: 0.233225
Train loss on 1350 batch: 0.187252
Train loss on 1400 batch: 0.160365
Train loss on 1450 batch: 0.251858
Train loss on 1500 batch: 0.226019
Train loss on 1550 batch: 0.220670
Train loss on 1600 batch: 0.252130
Train loss on 1650 batch: 0.211924
Train loss on 1700 batch: 0.235693
Train loss on 1750 batch: 0.238257
Train loss on 1800 batch: 0.235841
Train loss on 1850 batch: 0.229667
Train loss on 1900 batch: 0.263846
Train loss on 1950 batch: 0.229874
Train loss on 2000 batch: 0.226510
Train loss on 2050 batch: 0.220049
Train loss on 2100 batch: 0.228085
Train loss on 2150 batch: 0.255887
: Epoch: 122 | Training Loss: 0.226881 | Val. Loss: 0.372436 | Val. Kappa Score: 0.7203 | LR: 0.000478 | Estimated time: 554.81
Train loss on 50 batch: 0.269703
Train loss on 100 batch: 0.240820
Train loss on 150 batch: 0.234405
Train loss on 200 batch: 0.234136
Train loss on 250 batch: 0.223441
Train loss on 300 batch: 0.291414
Train loss on 350 batch: 0.240806
Train loss on 400 batch: 0.236344
Train loss on 450 batch: 0.207424
Train loss on 500 batch: 0.195049
Train loss on 550 batch: 0.219338
Train loss on 600 batch: 0.220421
Train loss on 650 batch: 0.237477
Train loss on 700 batch: 0.290533
Train loss on 750 batch: 0.187299
Train loss on 800 batch: 0.206475
Train loss on 850 batch: 0.244348
Train loss on 900 batch: 0.228135
Train loss on 950 batch: 0.213697
Train loss on 1000 batch: 0.196563
Train loss on 1050 batch: 0.211008
Train loss on 1100 batch: 0.225326
Train loss on 1150 batch: 0.218737
Train loss on 1200 batch: 0.236926
Train loss on 1250 batch: 0.219075
Train loss on 1300 batch: 0.208560
Train loss on 1350 batch: 0.246773
Train loss on 1400 batch: 0.221364
Train loss on 1450 batch: 0.223705
Train loss on 1500 batch: 0.246009
Train loss on 1550 batch: 0.205209
Train loss on 1600 batch: 0.194971
Train loss on 1650 batch: 0.296634
Train loss on 1700 batch: 0.249813
Train loss on 1750 batch: 0.233668
Train loss on 1800 batch: 0.233061
Train loss on 1850 batch: 0.256921
Train loss on 1900 batch: 0.273645
Train loss on 1950 batch: 0.229173
Train loss on 2000 batch: 0.196401
Train loss on 2050 batch: 0.231164
Train loss on 2100 batch: 0.221356
Train loss on 2150 batch: 0.201562
: Epoch: 123 | Training Loss: 0.229771 | Val. Loss: 0.356456 | Val. Kappa Score: 0.7205 | LR: 0.000522 | Estimated time: 554.66
Train loss on 50 batch: 0.245779
Train loss on 100 batch: 0.216012
Train loss on 150 batch: 0.292502
Train loss on 200 batch: 0.229951
Train loss on 250 batch: 0.205313
Train loss on 300 batch: 0.263426
Train loss on 350 batch: 0.219851
Train loss on 400 batch: 0.216561
Train loss on 450 batch: 0.295832
Train loss on 500 batch: 0.242134
Train loss on 550 batch: 0.227362
Train loss on 600 batch: 0.226451
Train loss on 650 batch: 0.217209
Train loss on 700 batch: 0.186237
Train loss on 750 batch: 0.249259
Train loss on 800 batch: 0.243821
Train loss on 850 batch: 0.214652
Train loss on 900 batch: 0.241159
Train loss on 950 batch: 0.255306
Train loss on 1000 batch: 0.277767
Train loss on 1050 batch: 0.279374
Train loss on 1100 batch: 0.188180
Train loss on 1150 batch: 0.240587
Train loss on 1200 batch: 0.251974
Train loss on 1250 batch: 0.237921
Train loss on 1300 batch: 0.250600
Train loss on 1350 batch: 0.246175
Train loss on 1400 batch: 0.266748
Train loss on 1450 batch: 0.216080
Train loss on 1500 batch: 0.245244
Train loss on 1550 batch: 0.179093
Train loss on 1600 batch: 0.190293
Train loss on 1650 batch: 0.284603
Train loss on 1700 batch: 0.220431
Train loss on 1750 batch: 0.233760
Train loss on 1800 batch: 0.247417
Train loss on 1850 batch: 0.246307
Train loss on 1900 batch: 0.235280
Train loss on 1950 batch: 0.236387
Train loss on 2000 batch: 0.204253
Train loss on 2050 batch: 0.240959
Train loss on 2100 batch: 0.225939
Train loss on 2150 batch: 0.225864
: Epoch: 124 | Training Loss: 0.235630 | Val. Loss: 0.368923 | Val. Kappa Score: 0.7207 | LR: 0.000567 | Estimated time: 555.07
Train loss on 50 batch: 0.236234
Train loss on 100 batch: 0.207265
Train loss on 150 batch: 0.219687
Train loss on 200 batch: 0.213491
Train loss on 250 batch: 0.219924
Train loss on 300 batch: 0.264910
Train loss on 350 batch: 0.199106
Train loss on 400 batch: 0.230325
Train loss on 450 batch: 0.226439
Train loss on 500 batch: 0.221606
Train loss on 550 batch: 0.222743
Train loss on 600 batch: 0.251671
Train loss on 650 batch: 0.214459
Train loss on 700 batch: 0.247172
Train loss on 750 batch: 0.203466
Train loss on 800 batch: 0.236103
Train loss on 850 batch: 0.209045
Train loss on 900 batch: 0.212915
Train loss on 950 batch: 0.258226
Train loss on 1000 batch: 0.240771
Train loss on 1050 batch: 0.227395
Train loss on 1100 batch: 0.298238
Train loss on 1150 batch: 0.247543
Train loss on 1200 batch: 0.198612
Train loss on 1250 batch: 0.243152
Train loss on 1300 batch: 0.186182
Train loss on 1350 batch: 0.233726
Train loss on 1400 batch: 0.211659
Train loss on 1450 batch: 0.261025
Train loss on 1500 batch: 0.217360
Train loss on 1550 batch: 0.208382
Train loss on 1600 batch: 0.272458
Train loss on 1650 batch: 0.266248
Train loss on 1700 batch: 0.235893
Train loss on 1750 batch: 0.237093
Train loss on 1800 batch: 0.290261
Train loss on 1850 batch: 0.268589
Train loss on 1900 batch: 0.281819
Train loss on 1950 batch: 0.246110
Train loss on 2000 batch: 0.318228
Train loss on 2050 batch: 0.283802
Train loss on 2100 batch: 0.254757
Train loss on 2150 batch: 0.273509
: Epoch: 125 | Training Loss: 0.239493 | Val. Loss: 0.392107 | Val. Kappa Score: 0.7208 | LR: 0.000611 | Estimated time: 554.69
Train loss on 50 batch: 0.217035
Train loss on 100 batch: 0.193636
Train loss on 150 batch: 0.274411
Train loss on 200 batch: 0.237586
Train loss on 250 batch: 0.209703
Train loss on 300 batch: 0.211766
Train loss on 350 batch: 0.219326
Train loss on 400 batch: 0.290501
Train loss on 450 batch: 0.212793
Train loss on 500 batch: 0.242783
Train loss on 550 batch: 0.226967
Train loss on 600 batch: 0.251068
Train loss on 650 batch: 0.199542
Train loss on 700 batch: 0.221184
Train loss on 750 batch: 0.227582
Train loss on 800 batch: 0.241160
Train loss on 850 batch: 0.233263
Train loss on 900 batch: 0.239446
Train loss on 950 batch: 0.250298
Train loss on 1000 batch: 0.300786
Train loss on 1050 batch: 0.222475
Train loss on 1100 batch: 0.241931
Train loss on 1150 batch: 0.237363
Train loss on 1200 batch: 0.239142
Train loss on 1250 batch: 0.239388
Train loss on 1300 batch: 0.286666
Train loss on 1350 batch: 0.279374
Train loss on 1400 batch: 0.245671
Train loss on 1450 batch: 0.226304
Train loss on 1500 batch: 0.227366
Train loss on 1550 batch: 0.217935
Train loss on 1600 batch: 0.234923
Train loss on 1650 batch: 0.204279
Train loss on 1700 batch: 0.292223
Train loss on 1750 batch: 0.235439
Train loss on 1800 batch: 0.233511
Train loss on 1850 batch: 0.312771
Train loss on 1900 batch: 0.293396
Train loss on 1950 batch: 0.230813
Train loss on 2000 batch: 0.256169
Train loss on 2050 batch: 0.249290
Train loss on 2100 batch: 0.240621
Train loss on 2150 batch: 0.247560
: Epoch: 126 | Training Loss: 0.241826 | Val. Loss: 0.391520 | Val. Kappa Score: 0.7208 | LR: 0.000655 | Estimated time: 554.85
Train loss on 50 batch: 0.252712
Train loss on 100 batch: 0.246977
Train loss on 150 batch: 0.226086
Train loss on 200 batch: 0.234612
Train loss on 250 batch: 0.231289
Train loss on 300 batch: 0.230623
Train loss on 350 batch: 0.246492
Train loss on 400 batch: 0.256716
Train loss on 450 batch: 0.214913
Train loss on 500 batch: 0.253242
Train loss on 550 batch: 0.213531
Train loss on 600 batch: 0.237794
Train loss on 650 batch: 0.241095
Train loss on 700 batch: 0.224327
Train loss on 750 batch: 0.253744
Train loss on 800 batch: 0.253245
Train loss on 850 batch: 0.247767
Train loss on 900 batch: 0.250645
Train loss on 950 batch: 0.234567
Train loss on 1000 batch: 0.210394
Train loss on 1050 batch: 0.265496
Train loss on 1100 batch: 0.256472
Train loss on 1150 batch: 0.288639
Train loss on 1200 batch: 0.217128
Train loss on 1250 batch: 0.212289
Train loss on 1300 batch: 0.217369
Train loss on 1350 batch: 0.246106
Train loss on 1400 batch: 0.208551
Train loss on 1450 batch: 0.269175
Train loss on 1500 batch: 0.287344
Train loss on 1550 batch: 0.232576
Train loss on 1600 batch: 0.272490
Train loss on 1650 batch: 0.275095
Train loss on 1700 batch: 0.274543
Train loss on 1750 batch: 0.305464
Train loss on 1800 batch: 0.295494
Train loss on 1850 batch: 0.249941
Train loss on 1900 batch: 0.269665
Train loss on 1950 batch: 0.255956
Train loss on 2000 batch: 0.268070
Train loss on 2050 batch: 0.275067
Train loss on 2100 batch: 0.279491
Train loss on 2150 batch: 0.268449
: Epoch: 127 | Training Loss: 0.249168 | Val. Loss: 0.387009 | Val. Kappa Score: 0.7207 | LR: 0.000697 | Estimated time: 555.30
Train loss on 50 batch: 0.263598
Train loss on 100 batch: 0.233859
Train loss on 150 batch: 0.247531
Train loss on 200 batch: 0.212614
Train loss on 250 batch: 0.224076
Train loss on 300 batch: 0.250480
Train loss on 350 batch: 0.209007
Train loss on 400 batch: 0.252228
Train loss on 450 batch: 0.208841
Train loss on 500 batch: 0.265134
Train loss on 550 batch: 0.247029
Train loss on 600 batch: 0.216768
Train loss on 650 batch: 0.255534
Train loss on 700 batch: 0.237614
Train loss on 750 batch: 0.264055
Train loss on 800 batch: 0.259652
Train loss on 850 batch: 0.268533
Train loss on 900 batch: 0.249888
Train loss on 950 batch: 0.223000
Train loss on 1000 batch: 0.271216
Train loss on 1050 batch: 0.328974
Train loss on 1100 batch: 0.231247
Train loss on 1150 batch: 0.228007
Train loss on 1200 batch: 0.239357
Train loss on 1250 batch: 0.226700
Train loss on 1300 batch: 0.201592
Train loss on 1350 batch: 0.252751
Train loss on 1400 batch: 0.197210
Train loss on 1450 batch: 0.303407
Train loss on 1500 batch: 0.260180
Train loss on 1550 batch: 0.260286
Train loss on 1600 batch: 0.312989
Train loss on 1650 batch: 0.286673
Train loss on 1700 batch: 0.256026
Train loss on 1750 batch: 0.269845
Train loss on 1800 batch: 0.280942
Train loss on 1850 batch: 0.261850
Train loss on 1900 batch: 0.233587
Train loss on 1950 batch: 0.278807
Train loss on 2000 batch: 0.291991
Train loss on 2050 batch: 0.256489
Train loss on 2100 batch: 0.269892
Train loss on 2150 batch: 0.264147
: Epoch: 128 | Training Loss: 0.252427 | Val. Loss: 0.340003 | Val. Kappa Score: 0.7208 | LR: 0.000737 | Estimated time: 555.31
Train loss on 50 batch: 0.270721
Train loss on 100 batch: 0.269146
Train loss on 150 batch: 0.224116
Train loss on 200 batch: 0.275255
Train loss on 250 batch: 0.239536
Train loss on 300 batch: 0.287478
Train loss on 350 batch: 0.293192
Train loss on 400 batch: 0.237574
Train loss on 450 batch: 0.255204
Train loss on 500 batch: 0.285238
Train loss on 550 batch: 0.297107
Train loss on 600 batch: 0.263387
Train loss on 650 batch: 0.215169
Train loss on 700 batch: 0.276293
Train loss on 750 batch: 0.338536
Train loss on 800 batch: 0.273062
Train loss on 850 batch: 0.232740
Train loss on 900 batch: 0.265664
Train loss on 950 batch: 0.278732
Train loss on 1000 batch: 0.219726
Train loss on 1050 batch: 0.241953
Train loss on 1100 batch: 0.258628
Train loss on 1150 batch: 0.261131
Train loss on 1200 batch: 0.234816
Train loss on 1250 batch: 0.230871
Train loss on 1300 batch: 0.227187
Train loss on 1350 batch: 0.239387
Train loss on 1400 batch: 0.247198
Train loss on 1450 batch: 0.316594
Train loss on 1500 batch: 0.292203
Train loss on 1550 batch: 0.251845
Train loss on 1600 batch: 0.238495
Train loss on 1650 batch: 0.230051
Train loss on 1700 batch: 0.262503
Train loss on 1750 batch: 0.249784
Train loss on 1800 batch: 0.254674
Train loss on 1850 batch: 0.291046
Train loss on 1900 batch: 0.265217
Train loss on 1950 batch: 0.300635
Train loss on 2000 batch: 0.282204
Train loss on 2050 batch: 0.249473
Train loss on 2100 batch: 0.302614
Train loss on 2150 batch: 0.222413
: Epoch: 129 | Training Loss: 0.261547 | Val. Loss: 0.357154 | Val. Kappa Score: 0.7209 | LR: 0.000775 | Estimated time: 554.89
Train loss on 50 batch: 0.241232
Train loss on 100 batch: 0.244936
Train loss on 150 batch: 0.246563
Train loss on 200 batch: 0.255165
Train loss on 250 batch: 0.251431
Train loss on 300 batch: 0.282098
Train loss on 350 batch: 0.233862
Train loss on 400 batch: 0.233075
Train loss on 450 batch: 0.265596
Train loss on 500 batch: 0.274964
Train loss on 550 batch: 0.264986
Train loss on 600 batch: 0.230140
Train loss on 650 batch: 0.299961
Train loss on 700 batch: 0.233421
Train loss on 750 batch: 0.243894
Train loss on 800 batch: 0.251628
Train loss on 850 batch: 0.276134
Train loss on 900 batch: 0.249903
Train loss on 950 batch: 0.247221
Train loss on 1000 batch: 0.258622
Train loss on 1050 batch: 0.294484
Train loss on 1100 batch: 0.285807
Train loss on 1150 batch: 0.248712
Train loss on 1200 batch: 0.236678
Train loss on 1250 batch: 0.295533
Train loss on 1300 batch: 0.305698
Train loss on 1350 batch: 0.304282
Train loss on 1400 batch: 0.293997
Train loss on 1450 batch: 0.299825
Train loss on 1500 batch: 0.250669
Train loss on 1550 batch: 0.241104
Train loss on 1600 batch: 0.283993
Train loss on 1650 batch: 0.294913
Train loss on 1700 batch: 0.244033
Train loss on 1750 batch: 0.326167
Train loss on 1800 batch: 0.279028
Train loss on 1850 batch: 0.265659
Train loss on 1900 batch: 0.262720
Train loss on 1950 batch: 0.248352
Train loss on 2000 batch: 0.270964
Train loss on 2050 batch: 0.279166
Train loss on 2100 batch: 0.293884
Train loss on 2150 batch: 0.287876
: Epoch: 130 | Training Loss: 0.265622 | Val. Loss: 0.352739 | Val. Kappa Score: 0.7210 | LR: 0.000812 | Estimated time: 555.23
Train loss on 50 batch: 0.235597
Train loss on 100 batch: 0.287890
Train loss on 150 batch: 0.309151
Train loss on 200 batch: 0.305415
Train loss on 250 batch: 0.258094
Train loss on 300 batch: 0.286948
Train loss on 350 batch: 0.216598
Train loss on 400 batch: 0.342511
Train loss on 450 batch: 0.274453
Train loss on 500 batch: 0.259502
Train loss on 550 batch: 0.262194
Train loss on 600 batch: 0.258830
Train loss on 650 batch: 0.254242
Train loss on 700 batch: 0.277845
Train loss on 750 batch: 0.281820
Train loss on 800 batch: 0.223031
Train loss on 850 batch: 0.301042
Train loss on 900 batch: 0.243299
Train loss on 950 batch: 0.259538
Train loss on 1000 batch: 0.272345
Train loss on 1050 batch: 0.280167
Train loss on 1100 batch: 0.254732
Train loss on 1150 batch: 0.216279
Train loss on 1200 batch: 0.272847
Train loss on 1250 batch: 0.246845
Train loss on 1300 batch: 0.257203
Train loss on 1350 batch: 0.269658
Train loss on 1400 batch: 0.237471
Train loss on 1450 batch: 0.217732
Train loss on 1500 batch: 0.248957
Train loss on 1550 batch: 0.270117
Train loss on 1600 batch: 0.262810
Train loss on 1650 batch: 0.294956
Train loss on 1700 batch: 0.262474
Train loss on 1750 batch: 0.283583
Train loss on 1800 batch: 0.264489
Train loss on 1850 batch: 0.286369
Train loss on 1900 batch: 0.272372
Train loss on 1950 batch: 0.260233
Train loss on 2000 batch: 0.296349
Train loss on 2050 batch: 0.292260
Train loss on 2100 batch: 0.326128
Train loss on 2150 batch: 0.293341
: Epoch: 131 | Training Loss: 0.268112 | Val. Loss: 0.365444 | Val. Kappa Score: 0.7210 | LR: 0.000846 | Estimated time: 555.02
Train loss on 50 batch: 0.233511
Train loss on 100 batch: 0.269112
Train loss on 150 batch: 0.284059
Train loss on 200 batch: 0.310561
Train loss on 250 batch: 0.267697
Train loss on 300 batch: 0.243284
Train loss on 350 batch: 0.259912
Train loss on 400 batch: 0.286179
Train loss on 450 batch: 0.287845
Train loss on 500 batch: 0.250078
Train loss on 550 batch: 0.265884
Train loss on 600 batch: 0.305466
Train loss on 650 batch: 0.266192
Train loss on 700 batch: 0.267860
Train loss on 750 batch: 0.242080
Train loss on 800 batch: 0.267375
Train loss on 850 batch: 0.261208
Train loss on 900 batch: 0.247969
Train loss on 950 batch: 0.322257
Train loss on 1000 batch: 0.271311
Train loss on 1050 batch: 0.337093
Train loss on 1100 batch: 0.224251
Train loss on 1150 batch: 0.289880
Train loss on 1200 batch: 0.241345
Train loss on 1250 batch: 0.224247
Train loss on 1300 batch: 0.228183
Train loss on 1350 batch: 0.315870
Train loss on 1400 batch: 0.255449
Train loss on 1450 batch: 0.283839
Train loss on 1500 batch: 0.288206
Train loss on 1550 batch: 0.239337
Train loss on 1600 batch: 0.339591
Train loss on 1650 batch: 0.337866
Train loss on 1700 batch: 0.301668
Train loss on 1750 batch: 0.282808
Train loss on 1800 batch: 0.315658
Train loss on 1850 batch: 0.260518
Train loss on 1900 batch: 0.256052
Train loss on 1950 batch: 0.296826
Train loss on 2000 batch: 0.265826
Train loss on 2050 batch: 0.260023
Train loss on 2100 batch: 0.268753
Train loss on 2150 batch: 0.285388
: Epoch: 132 | Training Loss: 0.274268 | Val. Loss: 0.343166 | Val. Kappa Score: 0.7212 | LR: 0.000877 | Estimated time: 554.86
Train loss on 50 batch: 0.257166
Train loss on 100 batch: 0.280849
Train loss on 150 batch: 0.231702
Train loss on 200 batch: 0.282205
Train loss on 250 batch: 0.258540
Train loss on 300 batch: 0.291706
Train loss on 350 batch: 0.254646
Train loss on 400 batch: 0.221431
Train loss on 450 batch: 0.292585
Train loss on 500 batch: 0.250578
Train loss on 550 batch: 0.326153
Train loss on 600 batch: 0.223779
Train loss on 650 batch: 0.269075
Train loss on 700 batch: 0.277744
Train loss on 750 batch: 0.253547
Train loss on 800 batch: 0.296031
Train loss on 850 batch: 0.296049
Train loss on 900 batch: 0.294358
Train loss on 950 batch: 0.254048
Train loss on 1000 batch: 0.243644
Train loss on 1050 batch: 0.266211
Train loss on 1100 batch: 0.252592
Train loss on 1150 batch: 0.261117
Train loss on 1200 batch: 0.238496
Train loss on 1250 batch: 0.333067
Train loss on 1300 batch: 0.372254
Train loss on 1350 batch: 0.309499
Train loss on 1400 batch: 0.318686
Train loss on 1450 batch: 0.285398
Train loss on 1500 batch: 0.268150
Train loss on 1550 batch: 0.279740
Train loss on 1600 batch: 0.238122
Train loss on 1650 batch: 0.262804
Train loss on 1700 batch: 0.264242
Train loss on 1750 batch: 0.307449
Train loss on 1800 batch: 0.228409
Train loss on 1850 batch: 0.275740
Train loss on 1900 batch: 0.250458
Train loss on 1950 batch: 0.278114
Train loss on 2000 batch: 0.287074
Train loss on 2050 batch: 0.252869
Train loss on 2100 batch: 0.258518
Train loss on 2150 batch: 0.234728
: Epoch: 133 | Training Loss: 0.271563 | Val. Loss: 0.351055 | Val. Kappa Score: 0.7213 | LR: 0.000905 | Estimated time: 554.97
Train loss on 50 batch: 0.275719
Train loss on 100 batch: 0.262289
Train loss on 150 batch: 0.291347
Train loss on 200 batch: 0.260870
Train loss on 250 batch: 0.258246
Train loss on 300 batch: 0.247035
Train loss on 350 batch: 0.303478
Train loss on 400 batch: 0.243709
Train loss on 450 batch: 0.246558
Train loss on 500 batch: 0.270220
Train loss on 550 batch: 0.286684
Train loss on 600 batch: 0.265105
Train loss on 650 batch: 0.325371
Train loss on 700 batch: 0.318283
Train loss on 750 batch: 0.283481
Train loss on 800 batch: 0.282518
Train loss on 850 batch: 0.280944
Train loss on 900 batch: 0.285182
Train loss on 950 batch: 0.289887
Train loss on 1000 batch: 0.326798
Train loss on 1050 batch: 0.315261
Train loss on 1100 batch: 0.293144
Train loss on 1150 batch: 0.258712
Train loss on 1200 batch: 0.244103
Train loss on 1250 batch: 0.303281
Train loss on 1300 batch: 0.269017
Train loss on 1350 batch: 0.305107
Train loss on 1400 batch: 0.316221
Train loss on 1450 batch: 0.294530
Train loss on 1500 batch: 0.294185
Train loss on 1550 batch: 0.288884
Train loss on 1600 batch: 0.284655
Train loss on 1650 batch: 0.262121
Train loss on 1700 batch: 0.250676
Train loss on 1750 batch: 0.302330
Train loss on 1800 batch: 0.278587
Train loss on 1850 batch: 0.272723
Train loss on 1900 batch: 0.279940
Train loss on 1950 batch: 0.231366
Train loss on 2000 batch: 0.256686
Train loss on 2050 batch: 0.289613
Train loss on 2100 batch: 0.257518
Train loss on 2150 batch: 0.264008
: Epoch: 134 | Training Loss: 0.280268 | Val. Loss: 0.398116 | Val. Kappa Score: 0.7213 | LR: 0.000929 | Estimated time: 555.07
Train loss on 50 batch: 0.328298
Train loss on 100 batch: 0.293537
Train loss on 150 batch: 0.265498
Train loss on 200 batch: 0.304975
Train loss on 250 batch: 0.294723
Train loss on 300 batch: 0.272614
Train loss on 350 batch: 0.276864
Train loss on 400 batch: 0.235553
Train loss on 450 batch: 0.247683
Train loss on 500 batch: 0.344236
Train loss on 550 batch: 0.281126
Train loss on 600 batch: 0.251874
Train loss on 650 batch: 0.285273
Train loss on 700 batch: 0.267612
Train loss on 750 batch: 0.245854
Train loss on 800 batch: 0.283569
Train loss on 850 batch: 0.268833
Train loss on 900 batch: 0.282873
Train loss on 950 batch: 0.265457
Train loss on 1000 batch: 0.287695
Train loss on 1050 batch: 0.257552
Train loss on 1100 batch: 0.305257
Train loss on 1150 batch: 0.273874
Train loss on 1200 batch: 0.291239
Train loss on 1250 batch: 0.299758
Train loss on 1300 batch: 0.289799
Train loss on 1350 batch: 0.309000
Train loss on 1400 batch: 0.312865
Train loss on 1450 batch: 0.281489
Train loss on 1500 batch: 0.246666
Train loss on 1550 batch: 0.240765
Train loss on 1600 batch: 0.261508
Train loss on 1650 batch: 0.294641
Train loss on 1700 batch: 0.304363
Train loss on 1750 batch: 0.296851
Train loss on 1800 batch: 0.259720
Train loss on 1850 batch: 0.255440
Train loss on 1900 batch: 0.267647
Train loss on 1950 batch: 0.266410
Train loss on 2000 batch: 0.263671
Train loss on 2050 batch: 0.315600
Train loss on 2100 batch: 0.274266
Train loss on 2150 batch: 0.254364
: Epoch: 135 | Training Loss: 0.280106 | Val. Loss: 0.378192 | Val. Kappa Score: 0.7213 | LR: 0.000950 | Estimated time: 554.89
Train loss on 50 batch: 0.229071
Train loss on 100 batch: 0.309853
Train loss on 150 batch: 0.292768
Train loss on 200 batch: 0.264725
Train loss on 250 batch: 0.267309
Train loss on 300 batch: 0.278903
Train loss on 350 batch: 0.299692
Train loss on 400 batch: 0.270742
Train loss on 450 batch: 0.222247
Train loss on 500 batch: 0.312346
Train loss on 550 batch: 0.241132
Train loss on 600 batch: 0.318203
Train loss on 650 batch: 0.272669
Train loss on 700 batch: 0.291199
Train loss on 750 batch: 0.279743
Train loss on 800 batch: 0.257456
Train loss on 850 batch: 0.279923
Train loss on 900 batch: 0.282172
Train loss on 950 batch: 0.334289
Train loss on 1000 batch: 0.250259
Train loss on 1050 batch: 0.227958
Train loss on 1100 batch: 0.246885
Train loss on 1150 batch: 0.227271
Train loss on 1200 batch: 0.310148
Train loss on 1250 batch: 0.283554
Train loss on 1300 batch: 0.306487
Train loss on 1350 batch: 0.285362
Train loss on 1400 batch: 0.321933
Train loss on 1450 batch: 0.252755
Train loss on 1500 batch: 0.294167
Train loss on 1550 batch: 0.268183
Train loss on 1600 batch: 0.296341
Train loss on 1650 batch: 0.274237
Train loss on 1700 batch: 0.304305
Train loss on 1750 batch: 0.280392
Train loss on 1800 batch: 0.246909
Train loss on 1850 batch: 0.303910
Train loss on 1900 batch: 0.355902
Train loss on 1950 batch: 0.302292
Train loss on 2000 batch: 0.290147
Train loss on 2050 batch: 0.315255
Train loss on 2100 batch: 0.328880
Train loss on 2150 batch: 0.292589
: Epoch: 136 | Training Loss: 0.282946 | Val. Loss: 0.460935 | Val. Kappa Score: 0.7210 | LR: 0.000968 | Estimated time: 555.09
Train loss on 50 batch: 0.261498
Train loss on 100 batch: 0.271078
Train loss on 150 batch: 0.315085
Train loss on 200 batch: 0.340619
Train loss on 250 batch: 0.284596
Train loss on 300 batch: 0.284887
Train loss on 350 batch: 0.334047
Train loss on 400 batch: 0.277801
Train loss on 450 batch: 0.300331
Train loss on 500 batch: 0.249588
Train loss on 550 batch: 0.249492
Train loss on 600 batch: 0.275142
Train loss on 650 batch: 0.341616
Train loss on 700 batch: 0.271632
Train loss on 750 batch: 0.258233
Train loss on 800 batch: 0.312988
Train loss on 850 batch: 0.266000
Train loss on 900 batch: 0.278244
Train loss on 950 batch: 0.262168
Train loss on 1000 batch: 0.273890
Train loss on 1050 batch: 0.273382
Train loss on 1100 batch: 0.324694
Train loss on 1150 batch: 0.274634
Train loss on 1200 batch: 0.294744
Train loss on 1250 batch: 0.271810
Train loss on 1300 batch: 0.311086
Train loss on 1350 batch: 0.299243
Train loss on 1400 batch: 0.237173
Train loss on 1450 batch: 0.285650
Train loss on 1500 batch: 0.256453
Train loss on 1550 batch: 0.309263
Train loss on 1600 batch: 0.229771
Train loss on 1650 batch: 0.292830
Train loss on 1700 batch: 0.287584
Train loss on 1750 batch: 0.325476
Train loss on 1800 batch: 0.310524
Train loss on 1850 batch: 0.253974
Train loss on 1900 batch: 0.290308
Train loss on 1950 batch: 0.282831
Train loss on 2000 batch: 0.298299
Train loss on 2050 batch: 0.305724
Train loss on 2100 batch: 0.280024
Train loss on 2150 batch: 0.319553
: Epoch: 137 | Training Loss: 0.286580 | Val. Loss: 0.387411 | Val. Kappa Score: 0.7212 | LR: 0.000982 | Estimated time: 554.92
Train loss on 50 batch: 0.259341
Train loss on 100 batch: 0.258697
Train loss on 150 batch: 0.294528
Train loss on 200 batch: 0.259334
Train loss on 250 batch: 0.308334
Train loss on 300 batch: 0.278840
Train loss on 350 batch: 0.237241
Train loss on 400 batch: 0.255838
Train loss on 450 batch: 0.322707
Train loss on 500 batch: 0.273605
Train loss on 550 batch: 0.263334
Train loss on 600 batch: 0.283310
Train loss on 650 batch: 0.302637
Train loss on 700 batch: 0.273802
Train loss on 750 batch: 0.233069
Train loss on 800 batch: 0.265201
Train loss on 850 batch: 0.314097
Train loss on 900 batch: 0.281777
Train loss on 950 batch: 0.286361
Train loss on 1000 batch: 0.318660
Train loss on 1050 batch: 0.289722
Train loss on 1100 batch: 0.269204
Train loss on 1150 batch: 0.291335
Train loss on 1200 batch: 0.293878
Train loss on 1250 batch: 0.331996
Train loss on 1300 batch: 0.312854
Train loss on 1350 batch: 0.322667
Train loss on 1400 batch: 0.265204
Train loss on 1450 batch: 0.273041
Train loss on 1500 batch: 0.258586
Train loss on 1550 batch: 0.268376
Train loss on 1600 batch: 0.292335
Train loss on 1650 batch: 0.322080
Train loss on 1700 batch: 0.293692
Train loss on 1750 batch: 0.293078
Train loss on 1800 batch: 0.303567
Train loss on 1850 batch: 0.320527
Train loss on 1900 batch: 0.292074
Train loss on 1950 batch: 0.291118
Train loss on 2000 batch: 0.265465
Train loss on 2050 batch: 0.296086
Train loss on 2100 batch: 0.287752
Train loss on 2150 batch: 0.275455
: Epoch: 138 | Training Loss: 0.284706 | Val. Loss: 0.396812 | Val. Kappa Score: 0.7211 | LR: 0.000992 | Estimated time: 554.91
Train loss on 50 batch: 0.278293
Train loss on 100 batch: 0.273893
Train loss on 150 batch: 0.301577
Train loss on 200 batch: 0.289702
Train loss on 250 batch: 0.315720
Train loss on 300 batch: 0.266466
Train loss on 350 batch: 0.348096
Train loss on 400 batch: 0.336171
Train loss on 450 batch: 0.281077
Train loss on 500 batch: 0.285762
Train loss on 550 batch: 0.246577
Train loss on 600 batch: 0.237443
Train loss on 650 batch: 0.270744
Train loss on 700 batch: 0.283397
Train loss on 750 batch: 0.297542
Train loss on 800 batch: 0.249394
Train loss on 850 batch: 0.295666
Train loss on 900 batch: 0.214751
Train loss on 950 batch: 0.313369
Train loss on 1000 batch: 0.287507
Train loss on 1050 batch: 0.268373
Train loss on 1100 batch: 0.289321
Train loss on 1150 batch: 0.306867
Train loss on 1200 batch: 0.245753
Train loss on 1250 batch: 0.259860
Train loss on 1300 batch: 0.274399
Train loss on 1350 batch: 0.267059
Train loss on 1400 batch: 0.268524
Train loss on 1450 batch: 0.281578
Train loss on 1500 batch: 0.295921
Train loss on 1550 batch: 0.286923
Train loss on 1600 batch: 0.321286
Train loss on 1650 batch: 0.259694
Train loss on 1700 batch: 0.263700
Train loss on 1750 batch: 0.270138
Train loss on 1800 batch: 0.274120
Train loss on 1850 batch: 0.314246
Train loss on 1900 batch: 0.286925
Train loss on 1950 batch: 0.232274
Train loss on 2000 batch: 0.289777
Train loss on 2050 batch: 0.289332
Train loss on 2100 batch: 0.272459
Train loss on 2150 batch: 0.310121
: Epoch: 139 | Training Loss: 0.281330 | Val. Loss: 0.383372 | Val. Kappa Score: 0.7212 | LR: 0.000998 | Estimated time: 555.14
Train loss on 50 batch: 0.236205
Train loss on 100 batch: 0.280403
Train loss on 150 batch: 0.221864
Train loss on 200 batch: 0.328791
Train loss on 250 batch: 0.261935
Train loss on 300 batch: 0.235341
Train loss on 350 batch: 0.332359
Train loss on 400 batch: 0.309544
Train loss on 450 batch: 0.279196
Train loss on 500 batch: 0.290101
Train loss on 550 batch: 0.261186
Train loss on 600 batch: 0.269380
Train loss on 650 batch: 0.291850
Train loss on 700 batch: 0.296395
Train loss on 750 batch: 0.318525
Train loss on 800 batch: 0.279814
Train loss on 850 batch: 0.261538
Train loss on 900 batch: 0.227646
Train loss on 950 batch: 0.267727
Train loss on 1000 batch: 0.233298
Train loss on 1050 batch: 0.264960
Train loss on 1100 batch: 0.310990
Train loss on 1150 batch: 0.287079
Train loss on 1200 batch: 0.251177
Train loss on 1250 batch: 0.211979
Train loss on 1300 batch: 0.265902
Train loss on 1350 batch: 0.290383
Train loss on 1400 batch: 0.322029
Train loss on 1450 batch: 0.295425
Train loss on 1500 batch: 0.260292
Train loss on 1550 batch: 0.279378
Train loss on 1600 batch: 0.342740
Train loss on 1650 batch: 0.317173
Train loss on 1700 batch: 0.306284
Train loss on 1750 batch: 0.329933
Train loss on 1800 batch: 0.287695
Train loss on 1850 batch: 0.286897
Train loss on 1900 batch: 0.321516
Train loss on 1950 batch: 0.364978
Train loss on 2000 batch: 0.305016
Train loss on 2050 batch: 0.273661
Train loss on 2100 batch: 0.244289
Train loss on 2150 batch: 0.274423
: Epoch: 140 | Training Loss: 0.282576 | Val. Loss: 0.361898 | Val. Kappa Score: 0.7212 | LR: 0.001000 | Estimated time: 554.77
Train loss on 50 batch: 0.250916
Train loss on 100 batch: 0.292198
Train loss on 150 batch: 0.281438
Train loss on 200 batch: 0.285268
Train loss on 250 batch: 0.268673
Train loss on 300 batch: 0.310587
Train loss on 350 batch: 0.334138
Train loss on 400 batch: 0.305335
Train loss on 450 batch: 0.235836
Train loss on 500 batch: 0.235147
Train loss on 550 batch: 0.271462
Train loss on 600 batch: 0.278016
Train loss on 650 batch: 0.291392
Train loss on 700 batch: 0.322017
Train loss on 750 batch: 0.297184
Train loss on 800 batch: 0.266166
Train loss on 850 batch: 0.291029
Train loss on 900 batch: 0.279696
Train loss on 950 batch: 0.299241
Train loss on 1000 batch: 0.352569
Train loss on 1050 batch: 0.298364
Train loss on 1100 batch: 0.273111
Train loss on 1150 batch: 0.295022
Train loss on 1200 batch: 0.346959
Train loss on 1250 batch: 0.243516
Train loss on 1300 batch: 0.260365
Train loss on 1350 batch: 0.260229
Train loss on 1400 batch: 0.310470
Train loss on 1450 batch: 0.334064
Train loss on 1500 batch: 0.237595
Train loss on 1550 batch: 0.259621
Train loss on 1600 batch: 0.276684
Train loss on 1650 batch: 0.264869
Train loss on 1700 batch: 0.263457
Train loss on 1750 batch: 0.296078
Train loss on 1800 batch: 0.259636
Train loss on 1850 batch: 0.341900
Train loss on 1900 batch: 0.344865
Train loss on 1950 batch: 0.265247
Train loss on 2000 batch: 0.278870
Train loss on 2050 batch: 0.256943
Train loss on 2100 batch: 0.326105
Train loss on 2150 batch: 0.316021
: Epoch: 141 | Training Loss: 0.287066 | Val. Loss: 0.381644 | Val. Kappa Score: 0.7214 | LR: 0.000998 | Estimated time: 554.79
Train loss on 50 batch: 0.300864
Train loss on 100 batch: 0.277784
Train loss on 150 batch: 0.259685
Train loss on 200 batch: 0.318473
Train loss on 250 batch: 0.268135
Train loss on 300 batch: 0.282922
Train loss on 350 batch: 0.260183
Train loss on 400 batch: 0.259856
Train loss on 450 batch: 0.273559
Train loss on 500 batch: 0.260028
Train loss on 550 batch: 0.290221
Train loss on 600 batch: 0.285993
Train loss on 650 batch: 0.319710
Train loss on 700 batch: 0.268114
Train loss on 750 batch: 0.273442
Train loss on 800 batch: 0.299699
Train loss on 850 batch: 0.277589
Train loss on 900 batch: 0.298883
Train loss on 950 batch: 0.266098
Train loss on 1000 batch: 0.271714
Train loss on 1050 batch: 0.334905
Train loss on 1100 batch: 0.336422
Train loss on 1150 batch: 0.273763
Train loss on 1200 batch: 0.276338
Train loss on 1250 batch: 0.271094
Train loss on 1300 batch: 0.281247
Train loss on 1350 batch: 0.258591
Train loss on 1400 batch: 0.284348
Train loss on 1450 batch: 0.283934
Train loss on 1500 batch: 0.283564
Train loss on 1550 batch: 0.296725
Train loss on 1600 batch: 0.260869
Train loss on 1650 batch: 0.306244
Train loss on 1700 batch: 0.264199
Train loss on 1750 batch: 0.305830
Train loss on 1800 batch: 0.278607
Train loss on 1850 batch: 0.300846
Train loss on 1900 batch: 0.294594
Train loss on 1950 batch: 0.343963
Train loss on 2000 batch: 0.271686
Train loss on 2050 batch: 0.247509
Train loss on 2100 batch: 0.256930
Train loss on 2150 batch: 0.271320
: Epoch: 142 | Training Loss: 0.285583 | Val. Loss: 0.426824 | Val. Kappa Score: 0.7213 | LR: 0.000992 | Estimated time: 554.82
Train loss on 50 batch: 0.330255
Train loss on 100 batch: 0.283502
Train loss on 150 batch: 0.331328
Train loss on 200 batch: 0.309197
Train loss on 250 batch: 0.247618
Train loss on 300 batch: 0.237059
Train loss on 350 batch: 0.307224
Train loss on 400 batch: 0.259707
Train loss on 450 batch: 0.280569
Train loss on 500 batch: 0.257112
Train loss on 550 batch: 0.237585
Train loss on 600 batch: 0.253734
Train loss on 650 batch: 0.301041
Train loss on 700 batch: 0.255433
Train loss on 750 batch: 0.302721
Train loss on 800 batch: 0.301482
Train loss on 850 batch: 0.282665
Train loss on 900 batch: 0.282246
Train loss on 950 batch: 0.267717
Train loss on 1000 batch: 0.366057
Train loss on 1050 batch: 0.274724
Train loss on 1100 batch: 0.287278
Train loss on 1150 batch: 0.281893
Train loss on 1200 batch: 0.274181
Train loss on 1250 batch: 0.278870
Train loss on 1300 batch: 0.314779
Train loss on 1350 batch: 0.264550
Train loss on 1400 batch: 0.310094
Train loss on 1450 batch: 0.256221
Train loss on 1500 batch: 0.297835
Train loss on 1550 batch: 0.277665
Train loss on 1600 batch: 0.268493
Train loss on 1650 batch: 0.286331
Train loss on 1700 batch: 0.288020
Train loss on 1750 batch: 0.242801
Train loss on 1800 batch: 0.256553
Train loss on 1850 batch: 0.264328
Train loss on 1900 batch: 0.299454
Train loss on 1950 batch: 0.246359
Train loss on 2000 batch: 0.283865
Train loss on 2050 batch: 0.280415
Train loss on 2100 batch: 0.273127
Train loss on 2150 batch: 0.261897
: Epoch: 143 | Training Loss: 0.282127 | Val. Loss: 0.344672 | Val. Kappa Score: 0.7214 | LR: 0.000982 | Estimated time: 554.93
Train loss on 50 batch: 0.242564
Train loss on 100 batch: 0.309078
Train loss on 150 batch: 0.314788
Train loss on 200 batch: 0.295518
Train loss on 250 batch: 0.267968
Train loss on 300 batch: 0.304475
Train loss on 350 batch: 0.324967
Train loss on 400 batch: 0.280016
Train loss on 450 batch: 0.290653
Train loss on 500 batch: 0.235059
Train loss on 550 batch: 0.274309
Train loss on 600 batch: 0.243792
Train loss on 650 batch: 0.280502
Train loss on 700 batch: 0.245272
Train loss on 750 batch: 0.254214
Train loss on 800 batch: 0.281593
Train loss on 850 batch: 0.287859
Train loss on 900 batch: 0.239708
Train loss on 950 batch: 0.292086
Train loss on 1000 batch: 0.307562
Train loss on 1050 batch: 0.266176
Train loss on 1100 batch: 0.211001
Train loss on 1150 batch: 0.301752
Train loss on 1200 batch: 0.322605
Train loss on 1250 batch: 0.282911
Train loss on 1300 batch: 0.269433
Train loss on 1350 batch: 0.286553
Train loss on 1400 batch: 0.255073
Train loss on 1450 batch: 0.295541
Train loss on 1500 batch: 0.292841
Train loss on 1550 batch: 0.237667
Train loss on 1600 batch: 0.293786
Train loss on 1650 batch: 0.278877
Train loss on 1700 batch: 0.295806
Train loss on 1750 batch: 0.255839
Train loss on 1800 batch: 0.289530
Train loss on 1850 batch: 0.262305
Train loss on 1900 batch: 0.252965
Train loss on 1950 batch: 0.300264
Train loss on 2000 batch: 0.261090
Train loss on 2050 batch: 0.301173
Train loss on 2100 batch: 0.299400
Train loss on 2150 batch: 0.376234
: Epoch: 144 | Training Loss: 0.281422 | Val. Loss: 0.339479 | Val. Kappa Score: 0.7215 | LR: 0.000968 | Estimated time: 554.79
Train loss on 50 batch: 0.273460
Train loss on 100 batch: 0.289789
Train loss on 150 batch: 0.265364
Train loss on 200 batch: 0.312373
Train loss on 250 batch: 0.252742
Train loss on 300 batch: 0.311423
Train loss on 350 batch: 0.285710
Train loss on 400 batch: 0.295642
Train loss on 450 batch: 0.244467
Train loss on 500 batch: 0.279464
Train loss on 550 batch: 0.282084
Train loss on 600 batch: 0.278631
Train loss on 650 batch: 0.276595
Train loss on 700 batch: 0.255297
Train loss on 750 batch: 0.253646
Train loss on 800 batch: 0.279026
Train loss on 850 batch: 0.319606
Train loss on 900 batch: 0.301351
Train loss on 950 batch: 0.284638
Train loss on 1000 batch: 0.294325
Train loss on 1050 batch: 0.268290
Train loss on 1100 batch: 0.281110
Train loss on 1150 batch: 0.268407
Train loss on 1200 batch: 0.248320
Train loss on 1250 batch: 0.261137
Train loss on 1300 batch: 0.282709
Train loss on 1350 batch: 0.270819
Train loss on 1400 batch: 0.273824
Train loss on 1450 batch: 0.287820
Train loss on 1500 batch: 0.328987
Train loss on 1550 batch: 0.282263
Train loss on 1600 batch: 0.279468
Train loss on 1650 batch: 0.294107
Train loss on 1700 batch: 0.307599
Train loss on 1750 batch: 0.303761
Train loss on 1800 batch: 0.264797
Train loss on 1850 batch: 0.314324
Train loss on 1900 batch: 0.291865
Train loss on 1950 batch: 0.288095
Train loss on 2000 batch: 0.322887
Train loss on 2050 batch: 0.223293
Train loss on 2100 batch: 0.290338
Train loss on 2150 batch: 0.260207
: Epoch: 145 | Training Loss: 0.282865 | Val. Loss: 0.365512 | Val. Kappa Score: 0.7217 | LR: 0.000950 | Estimated time: 554.92
Train loss on 50 batch: 0.221811
Train loss on 100 batch: 0.264623
Train loss on 150 batch: 0.281278
Train loss on 200 batch: 0.278983
Train loss on 250 batch: 0.290245
Train loss on 300 batch: 0.235271
Train loss on 350 batch: 0.285108
Train loss on 400 batch: 0.267163
Train loss on 450 batch: 0.307782
Train loss on 500 batch: 0.273793
Train loss on 550 batch: 0.312975
Train loss on 600 batch: 0.257206
Train loss on 650 batch: 0.274070
Train loss on 700 batch: 0.312582
Train loss on 750 batch: 0.291119
Train loss on 800 batch: 0.276752
Train loss on 850 batch: 0.251730
Train loss on 900 batch: 0.257375
Train loss on 950 batch: 0.303897
Train loss on 1000 batch: 0.286976
Train loss on 1050 batch: 0.266390
Train loss on 1100 batch: 0.273218
Train loss on 1150 batch: 0.235312
Train loss on 1200 batch: 0.296683
Train loss on 1250 batch: 0.287863
Train loss on 1300 batch: 0.296920
Train loss on 1350 batch: 0.315555
Train loss on 1400 batch: 0.282995
Train loss on 1450 batch: 0.263260
Train loss on 1500 batch: 0.218071
Train loss on 1550 batch: 0.288499
Train loss on 1600 batch: 0.302110
Train loss on 1650 batch: 0.293484
Train loss on 1700 batch: 0.262372
Train loss on 1750 batch: 0.283640
Train loss on 1800 batch: 0.308683
Train loss on 1850 batch: 0.270938
Train loss on 1900 batch: 0.286700
Train loss on 1950 batch: 0.269313
Train loss on 2000 batch: 0.288984
Train loss on 2050 batch: 0.284348
Train loss on 2100 batch: 0.317274
Train loss on 2150 batch: 0.239127
: Epoch: 146 | Training Loss: 0.279824 | Val. Loss: 0.404248 | Val. Kappa Score: 0.7215 | LR: 0.000929 | Estimated time: 554.75
Train loss on 50 batch: 0.281922
Train loss on 100 batch: 0.272198
Train loss on 150 batch: 0.279182
Train loss on 200 batch: 0.241737
Train loss on 250 batch: 0.297119
Train loss on 300 batch: 0.273757
Train loss on 350 batch: 0.293705
Train loss on 400 batch: 0.258785
Train loss on 450 batch: 0.263045
Train loss on 500 batch: 0.235631
Train loss on 550 batch: 0.310281
Train loss on 600 batch: 0.242239
Train loss on 650 batch: 0.270102
Train loss on 700 batch: 0.286884
Train loss on 750 batch: 0.248104
Train loss on 800 batch: 0.312235
Train loss on 850 batch: 0.264616
Train loss on 900 batch: 0.290039
Train loss on 950 batch: 0.286529
Train loss on 1000 batch: 0.285329
Train loss on 1050 batch: 0.269761
Train loss on 1100 batch: 0.253606
Train loss on 1150 batch: 0.251442
Train loss on 1200 batch: 0.286538
Train loss on 1250 batch: 0.323662
Train loss on 1300 batch: 0.293295
Train loss on 1350 batch: 0.270972
Train loss on 1400 batch: 0.251076
Train loss on 1450 batch: 0.258899
Train loss on 1500 batch: 0.293981
Train loss on 1550 batch: 0.243436
Train loss on 1600 batch: 0.296201
Train loss on 1650 batch: 0.319140
Train loss on 1700 batch: 0.278836
Train loss on 1750 batch: 0.255681
Train loss on 1800 batch: 0.292209
Train loss on 1850 batch: 0.239269
Train loss on 1900 batch: 0.276589
Train loss on 1950 batch: 0.306661
Train loss on 2000 batch: 0.302723
Train loss on 2050 batch: 0.267564
Train loss on 2100 batch: 0.254519
Train loss on 2150 batch: 0.276120
: Epoch: 147 | Training Loss: 0.275567 | Val. Loss: 0.354575 | Val. Kappa Score: 0.7214 | LR: 0.000905 | Estimated time: 555.18
Train loss on 50 batch: 0.222051
Train loss on 100 batch: 0.308390
Train loss on 150 batch: 0.242690
Train loss on 200 batch: 0.269777
Train loss on 250 batch: 0.286381
Train loss on 300 batch: 0.256160
Train loss on 350 batch: 0.295878
Train loss on 400 batch: 0.253356
Train loss on 450 batch: 0.243563
Train loss on 500 batch: 0.253336
Train loss on 550 batch: 0.254800
Train loss on 600 batch: 0.236434
Train loss on 650 batch: 0.242247
Train loss on 700 batch: 0.256242
Train loss on 750 batch: 0.226083
Train loss on 800 batch: 0.245783
Train loss on 850 batch: 0.248643
Train loss on 900 batch: 0.292245
Train loss on 950 batch: 0.293807
Train loss on 1000 batch: 0.287529
Train loss on 1050 batch: 0.275733
Train loss on 1100 batch: 0.254967
Train loss on 1150 batch: 0.285326
Train loss on 1200 batch: 0.257886
Train loss on 1250 batch: 0.269005
Train loss on 1300 batch: 0.278836
Train loss on 1350 batch: 0.265551
Train loss on 1400 batch: 0.240519
Train loss on 1450 batch: 0.254110
Train loss on 1500 batch: 0.306729
Train loss on 1550 batch: 0.271213
Train loss on 1600 batch: 0.265720
Train loss on 1650 batch: 0.252131
Train loss on 1700 batch: 0.310791
Train loss on 1750 batch: 0.269439
Train loss on 1800 batch: 0.250296
Train loss on 1850 batch: 0.279070
Train loss on 1900 batch: 0.243076
Train loss on 1950 batch: 0.297571
Train loss on 2000 batch: 0.267070
Train loss on 2050 batch: 0.341882
Train loss on 2100 batch: 0.274630
Train loss on 2150 batch: 0.296457
: Epoch: 148 | Training Loss: 0.267969 | Val. Loss: 0.405175 | Val. Kappa Score: 0.7213 | LR: 0.000877 | Estimated time: 555.16
Train loss on 50 batch: 0.234431
Train loss on 100 batch: 0.257659
Train loss on 150 batch: 0.239042
Train loss on 200 batch: 0.249567
Train loss on 250 batch: 0.209886
Train loss on 300 batch: 0.286710
Train loss on 350 batch: 0.233143
Train loss on 400 batch: 0.247609
Train loss on 450 batch: 0.258821
Train loss on 500 batch: 0.184637
Train loss on 550 batch: 0.269569
Train loss on 600 batch: 0.291851
Train loss on 650 batch: 0.281848
Train loss on 700 batch: 0.249445
Train loss on 750 batch: 0.264540
Train loss on 800 batch: 0.260547
Train loss on 850 batch: 0.297218
Train loss on 900 batch: 0.247217
Train loss on 950 batch: 0.252812
Train loss on 1000 batch: 0.298714
Train loss on 1050 batch: 0.254867
Train loss on 1100 batch: 0.291893
Train loss on 1150 batch: 0.265164
Train loss on 1200 batch: 0.249302
Train loss on 1250 batch: 0.220252
Train loss on 1300 batch: 0.259194
Train loss on 1350 batch: 0.240576
Train loss on 1400 batch: 0.294264
Train loss on 1450 batch: 0.295132
Train loss on 1500 batch: 0.276031
Train loss on 1550 batch: 0.327283
Train loss on 1600 batch: 0.324129
Train loss on 1650 batch: 0.228657
Train loss on 1700 batch: 0.303261
Train loss on 1750 batch: 0.262085
Train loss on 1800 batch: 0.268505
Train loss on 1850 batch: 0.316794
Train loss on 1900 batch: 0.263516
Train loss on 1950 batch: 0.300590
Train loss on 2000 batch: 0.238553
Train loss on 2050 batch: 0.325985
Train loss on 2100 batch: 0.238002
Train loss on 2150 batch: 0.303841
: Epoch: 149 | Training Loss: 0.266192 | Val. Loss: 0.344335 | Val. Kappa Score: 0.7214 | LR: 0.000846 | Estimated time: 555.07
Train loss on 50 batch: 0.273071
Train loss on 100 batch: 0.249553
Train loss on 150 batch: 0.249628
Train loss on 200 batch: 0.272901
Train loss on 250 batch: 0.255171
Train loss on 300 batch: 0.306133
Train loss on 350 batch: 0.293933
Train loss on 400 batch: 0.239727
Train loss on 450 batch: 0.229423
Train loss on 500 batch: 0.235713
Train loss on 550 batch: 0.232174
Train loss on 600 batch: 0.280482
Train loss on 650 batch: 0.277869
Train loss on 700 batch: 0.271975
Train loss on 750 batch: 0.295042
Train loss on 800 batch: 0.272245
Train loss on 850 batch: 0.332044
Train loss on 900 batch: 0.253300
Train loss on 950 batch: 0.226806
Train loss on 1000 batch: 0.304867
Train loss on 1050 batch: 0.279849
Train loss on 1100 batch: 0.298137
Train loss on 1150 batch: 0.276796
Train loss on 1200 batch: 0.246366
Train loss on 1250 batch: 0.236718
Train loss on 1300 batch: 0.238638
Train loss on 1350 batch: 0.274575
Train loss on 1400 batch: 0.290464
Train loss on 1450 batch: 0.278996
Train loss on 1500 batch: 0.292138
Train loss on 1550 batch: 0.237565
Train loss on 1600 batch: 0.286978
Train loss on 1650 batch: 0.261383
Train loss on 1700 batch: 0.231321
Train loss on 1750 batch: 0.256044
Train loss on 1800 batch: 0.241578
Train loss on 1850 batch: 0.292696
Train loss on 1900 batch: 0.241722
Train loss on 1950 batch: 0.270064
Train loss on 2000 batch: 0.308529
Train loss on 2050 batch: 0.303183
Train loss on 2100 batch: 0.262565
Train loss on 2150 batch: 0.283842
: Epoch: 150 | Training Loss: 0.267365 | Val. Loss: 0.345285 | Val. Kappa Score: 0.7214 | LR: 0.000812 | Estimated time: 555.00
Train loss on 50 batch: 0.257702
Train loss on 100 batch: 0.247884
Train loss on 150 batch: 0.260680
Train loss on 200 batch: 0.233991
Train loss on 250 batch: 0.223215
Train loss on 300 batch: 0.249715
Train loss on 350 batch: 0.210253
Train loss on 400 batch: 0.269597
Train loss on 450 batch: 0.266866
Train loss on 500 batch: 0.239348
Train loss on 550 batch: 0.265988
Train loss on 600 batch: 0.233435
Train loss on 650 batch: 0.274749
Train loss on 700 batch: 0.293139
Train loss on 750 batch: 0.237911
Train loss on 800 batch: 0.240954
Train loss on 850 batch: 0.255520
Train loss on 900 batch: 0.257359
Train loss on 950 batch: 0.299251
Train loss on 1000 batch: 0.279254
Train loss on 1050 batch: 0.247182
Train loss on 1100 batch: 0.230644
Train loss on 1150 batch: 0.247927
Train loss on 1200 batch: 0.255208
Train loss on 1250 batch: 0.285213
Train loss on 1300 batch: 0.263758
Train loss on 1350 batch: 0.232192
Train loss on 1400 batch: 0.261086
Train loss on 1450 batch: 0.269616
Train loss on 1500 batch: 0.272389
Train loss on 1550 batch: 0.286012
Train loss on 1600 batch: 0.246579
Train loss on 1650 batch: 0.280837
Train loss on 1700 batch: 0.269276
Train loss on 1750 batch: 0.309572
Train loss on 1800 batch: 0.260662
Train loss on 1850 batch: 0.293944
Train loss on 1900 batch: 0.277646
Train loss on 1950 batch: 0.302987
Train loss on 2000 batch: 0.249805
Train loss on 2050 batch: 0.301311
Train loss on 2100 batch: 0.216217
Train loss on 2150 batch: 0.289852
: Epoch: 151 | Training Loss: 0.261306 | Val. Loss: 0.418939 | Val. Kappa Score: 0.7214 | LR: 0.000775 | Estimated time: 554.66
Train loss on 50 batch: 0.284407
Train loss on 100 batch: 0.237773
Train loss on 150 batch: 0.266992
Train loss on 200 batch: 0.277592
Train loss on 250 batch: 0.212935
Train loss on 300 batch: 0.250997
Train loss on 350 batch: 0.255946
Train loss on 400 batch: 0.260628
Train loss on 450 batch: 0.255427
Train loss on 500 batch: 0.214500
Train loss on 550 batch: 0.225414
Train loss on 600 batch: 0.220856
Train loss on 650 batch: 0.206482
Train loss on 700 batch: 0.290854
Train loss on 750 batch: 0.221048
Train loss on 800 batch: 0.223486
Train loss on 850 batch: 0.262281
Train loss on 900 batch: 0.237439
Train loss on 950 batch: 0.207848
Train loss on 1000 batch: 0.211083
Train loss on 1050 batch: 0.266470
Train loss on 1100 batch: 0.236258
Train loss on 1150 batch: 0.218403
Train loss on 1200 batch: 0.265298
Train loss on 1250 batch: 0.316542
Train loss on 1300 batch: 0.260681
Train loss on 1350 batch: 0.260657
Train loss on 1400 batch: 0.275445
Train loss on 1450 batch: 0.237816
Train loss on 1500 batch: 0.258725
Train loss on 1550 batch: 0.218745
Train loss on 1600 batch: 0.255305
Train loss on 1650 batch: 0.290868
Train loss on 1700 batch: 0.218523
Train loss on 1750 batch: 0.209992
Train loss on 1800 batch: 0.284093
Train loss on 1850 batch: 0.210595
Train loss on 1900 batch: 0.244406
Train loss on 1950 batch: 0.250660
Train loss on 2000 batch: 0.288979
Train loss on 2050 batch: 0.265739
Train loss on 2100 batch: 0.282138
Train loss on 2150 batch: 0.251886
: Epoch: 152 | Training Loss: 0.249637 | Val. Loss: 0.341329 | Val. Kappa Score: 0.7214 | LR: 0.000737 | Estimated time: 554.64
Train loss on 50 batch: 0.235324
Train loss on 100 batch: 0.261537
Train loss on 150 batch: 0.222206
Train loss on 200 batch: 0.255456
Train loss on 250 batch: 0.246210
Train loss on 300 batch: 0.256070
Train loss on 350 batch: 0.284750
Train loss on 400 batch: 0.256703
Train loss on 450 batch: 0.248482
Train loss on 500 batch: 0.240372
Train loss on 550 batch: 0.248586
Train loss on 600 batch: 0.250125
Train loss on 650 batch: 0.270310
Train loss on 700 batch: 0.263415
Train loss on 750 batch: 0.227350
Train loss on 800 batch: 0.264570
Train loss on 850 batch: 0.230553
Train loss on 900 batch: 0.280916
Train loss on 950 batch: 0.215853
Train loss on 1000 batch: 0.241349
Train loss on 1050 batch: 0.270274
Train loss on 1100 batch: 0.253852
Train loss on 1150 batch: 0.271744
Train loss on 1200 batch: 0.247668
Train loss on 1250 batch: 0.245361
Train loss on 1300 batch: 0.258149
Train loss on 1350 batch: 0.238048
Train loss on 1400 batch: 0.271526
Train loss on 1450 batch: 0.245457
Train loss on 1500 batch: 0.215936
Train loss on 1550 batch: 0.256583
Train loss on 1600 batch: 0.275968
Train loss on 1650 batch: 0.299240
Train loss on 1700 batch: 0.220405
Train loss on 1750 batch: 0.260117
Train loss on 1800 batch: 0.248358
Train loss on 1850 batch: 0.225946
Train loss on 1900 batch: 0.297946
Train loss on 1950 batch: 0.210447
Train loss on 2000 batch: 0.239665
Train loss on 2050 batch: 0.276476
Train loss on 2100 batch: 0.235856
Train loss on 2150 batch: 0.223039
: Epoch: 153 | Training Loss: 0.249849 | Val. Loss: 0.373677 | Val. Kappa Score: 0.7216 | LR: 0.000697 | Estimated time: 555.05
Train loss on 50 batch: 0.246239
Train loss on 100 batch: 0.279925
Train loss on 150 batch: 0.237947
Train loss on 200 batch: 0.247039
Train loss on 250 batch: 0.222273
Train loss on 300 batch: 0.181836
Train loss on 350 batch: 0.229093
Train loss on 400 batch: 0.231916
Train loss on 450 batch: 0.283653
Train loss on 500 batch: 0.251430
Train loss on 550 batch: 0.297255
Train loss on 600 batch: 0.245320
Train loss on 650 batch: 0.218677
Train loss on 700 batch: 0.232499
Train loss on 750 batch: 0.241939
Train loss on 800 batch: 0.226924
Train loss on 850 batch: 0.235281
Train loss on 900 batch: 0.260142
Train loss on 950 batch: 0.215578
Train loss on 1000 batch: 0.260229
Train loss on 1050 batch: 0.243386
Train loss on 1100 batch: 0.211199
Train loss on 1150 batch: 0.248884
Train loss on 1200 batch: 0.241017
Train loss on 1250 batch: 0.250563
Train loss on 1300 batch: 0.248408
Train loss on 1350 batch: 0.256618
Train loss on 1400 batch: 0.245012
Train loss on 1450 batch: 0.235226
Train loss on 1500 batch: 0.241670
Train loss on 1550 batch: 0.250184
Train loss on 1600 batch: 0.229025
Train loss on 1650 batch: 0.230824
Train loss on 1700 batch: 0.238080
Train loss on 1750 batch: 0.281662
Train loss on 1800 batch: 0.282801
Train loss on 1850 batch: 0.249373
Train loss on 1900 batch: 0.265098
Train loss on 1950 batch: 0.279390
Train loss on 2000 batch: 0.235171
Train loss on 2050 batch: 0.228199
Train loss on 2100 batch: 0.293330
Train loss on 2150 batch: 0.252027
: Epoch: 154 | Training Loss: 0.247501 | Val. Loss: 0.327329 | Val. Kappa Score: 0.7217 | LR: 0.000655 | Estimated time: 555.04
Train loss on 50 batch: 0.217026
Train loss on 100 batch: 0.287716
Train loss on 150 batch: 0.229141
Train loss on 200 batch: 0.247270
Train loss on 250 batch: 0.202132
Train loss on 300 batch: 0.216436
Train loss on 350 batch: 0.253881
Train loss on 400 batch: 0.236509
Train loss on 450 batch: 0.235011
Train loss on 500 batch: 0.242436
Train loss on 550 batch: 0.257868
Train loss on 600 batch: 0.232904
Train loss on 650 batch: 0.260809
Train loss on 700 batch: 0.211149
Train loss on 750 batch: 0.190318
Train loss on 800 batch: 0.249829
Train loss on 850 batch: 0.240050
Train loss on 900 batch: 0.228014
Train loss on 950 batch: 0.234805
Train loss on 1000 batch: 0.236474
Train loss on 1050 batch: 0.242068
Train loss on 1100 batch: 0.210758
Train loss on 1150 batch: 0.269673
Train loss on 1200 batch: 0.279635
Train loss on 1250 batch: 0.252914
Train loss on 1300 batch: 0.245931
Train loss on 1350 batch: 0.225108
Train loss on 1400 batch: 0.220081
Train loss on 1450 batch: 0.241368
Train loss on 1500 batch: 0.235030
Train loss on 1550 batch: 0.224099
Train loss on 1600 batch: 0.244629
Train loss on 1650 batch: 0.238761
Train loss on 1700 batch: 0.234269
Train loss on 1750 batch: 0.272964
Train loss on 1800 batch: 0.190763
Train loss on 1850 batch: 0.227833
Train loss on 1900 batch: 0.221379
Train loss on 1950 batch: 0.245994
Train loss on 2000 batch: 0.280200
Train loss on 2050 batch: 0.256552
Train loss on 2100 batch: 0.259281
Train loss on 2150 batch: 0.247499
: Epoch: 155 | Training Loss: 0.238599 | Val. Loss: 0.385535 | Val. Kappa Score: 0.7217 | LR: 0.000611 | Estimated time: 554.96
Train loss on 50 batch: 0.254965
Train loss on 100 batch: 0.209307
Train loss on 150 batch: 0.225096
Train loss on 200 batch: 0.204724
Train loss on 250 batch: 0.248653
Train loss on 300 batch: 0.224217
Train loss on 350 batch: 0.218788
Train loss on 400 batch: 0.234090
Train loss on 450 batch: 0.214438
Train loss on 500 batch: 0.226072
Train loss on 550 batch: 0.236774
Train loss on 600 batch: 0.228339
Train loss on 650 batch: 0.227137
Train loss on 700 batch: 0.198554
Train loss on 750 batch: 0.220724
Train loss on 800 batch: 0.203566
Train loss on 850 batch: 0.224066
Train loss on 900 batch: 0.248442
Train loss on 950 batch: 0.257192
Train loss on 1000 batch: 0.231054
Train loss on 1050 batch: 0.210147
Train loss on 1100 batch: 0.236456
Train loss on 1150 batch: 0.258192
Train loss on 1200 batch: 0.188981
Train loss on 1250 batch: 0.207409
Train loss on 1300 batch: 0.208117
Train loss on 1350 batch: 0.214094
Train loss on 1400 batch: 0.264210
Train loss on 1450 batch: 0.223834
Train loss on 1500 batch: 0.257421
Train loss on 1550 batch: 0.253023
Train loss on 1600 batch: 0.249426
Train loss on 1650 batch: 0.219329
Train loss on 1700 batch: 0.252677
Train loss on 1750 batch: 0.216940
Train loss on 1800 batch: 0.248642
Train loss on 1850 batch: 0.260156
Train loss on 1900 batch: 0.237689
Train loss on 1950 batch: 0.246754
Train loss on 2000 batch: 0.259691
Train loss on 2050 batch: 0.211774
Train loss on 2100 batch: 0.240618
Train loss on 2150 batch: 0.317845
: Epoch: 156 | Training Loss: 0.232224 | Val. Loss: 0.351581 | Val. Kappa Score: 0.7217 | LR: 0.000567 | Estimated time: 555.24
Train loss on 50 batch: 0.217528
Train loss on 100 batch: 0.256020
Train loss on 150 batch: 0.195427
Train loss on 200 batch: 0.216013
Train loss on 250 batch: 0.200063
Train loss on 300 batch: 0.183983
Train loss on 350 batch: 0.187525
Train loss on 400 batch: 0.199225
Train loss on 450 batch: 0.223271
Train loss on 500 batch: 0.243570
Train loss on 550 batch: 0.244881
Train loss on 600 batch: 0.253627
Train loss on 650 batch: 0.217959
Train loss on 700 batch: 0.258823
Train loss on 750 batch: 0.234125
Train loss on 800 batch: 0.262113
Train loss on 850 batch: 0.224678
Train loss on 900 batch: 0.201921
Train loss on 950 batch: 0.232906
Train loss on 1000 batch: 0.240858
Train loss on 1050 batch: 0.203590
Train loss on 1100 batch: 0.206157
Train loss on 1150 batch: 0.223481
Train loss on 1200 batch: 0.263541
Train loss on 1250 batch: 0.245941
Train loss on 1300 batch: 0.216318
Train loss on 1350 batch: 0.245301
Train loss on 1400 batch: 0.266231
Train loss on 1450 batch: 0.223509
Train loss on 1500 batch: 0.224148
Train loss on 1550 batch: 0.220749
Train loss on 1600 batch: 0.266368
Train loss on 1650 batch: 0.221266
Train loss on 1700 batch: 0.253385
Train loss on 1750 batch: 0.185326
Train loss on 1800 batch: 0.283574
Train loss on 1850 batch: 0.239680
Train loss on 1900 batch: 0.214669
Train loss on 1950 batch: 0.226791
Train loss on 2000 batch: 0.292101
Train loss on 2050 batch: 0.207469
Train loss on 2100 batch: 0.244004
Train loss on 2150 batch: 0.229888
: Epoch: 157 | Training Loss: 0.229546 | Val. Loss: 0.342837 | Val. Kappa Score: 0.7219 | LR: 0.000522 | Estimated time: 554.86
Train loss on 50 batch: 0.223633
Train loss on 100 batch: 0.253587
Train loss on 150 batch: 0.204525
Train loss on 200 batch: 0.216275
Train loss on 250 batch: 0.248955
Train loss on 300 batch: 0.179753
Train loss on 350 batch: 0.202391
Train loss on 400 batch: 0.164776
Train loss on 450 batch: 0.222269
Train loss on 500 batch: 0.191002
Train loss on 550 batch: 0.196476
Train loss on 600 batch: 0.210658
Train loss on 650 batch: 0.190203
Train loss on 700 batch: 0.227640
Train loss on 750 batch: 0.216605
Train loss on 800 batch: 0.275768
Train loss on 850 batch: 0.230172
Train loss on 900 batch: 0.223077
Train loss on 950 batch: 0.199356
Train loss on 1000 batch: 0.220213
Train loss on 1050 batch: 0.209474
Train loss on 1100 batch: 0.218681
Train loss on 1150 batch: 0.202362
Train loss on 1200 batch: 0.187010
Train loss on 1250 batch: 0.234806
Train loss on 1300 batch: 0.215839
Train loss on 1350 batch: 0.223006
Train loss on 1400 batch: 0.225725
Train loss on 1450 batch: 0.281211
Train loss on 1500 batch: 0.237349
Train loss on 1550 batch: 0.281260
Train loss on 1600 batch: 0.251734
Train loss on 1650 batch: 0.230356
Train loss on 1700 batch: 0.231351
Train loss on 1750 batch: 0.230159
Train loss on 1800 batch: 0.233852
Train loss on 1850 batch: 0.225910
Train loss on 1900 batch: 0.237676
Train loss on 1950 batch: 0.240882
Train loss on 2000 batch: 0.204746
Train loss on 2050 batch: 0.203630
Train loss on 2100 batch: 0.269217
Train loss on 2150 batch: 0.220133
: Epoch: 158 | Training Loss: 0.222911 | Val. Loss: 0.354359 | Val. Kappa Score: 0.7221 | LR: 0.000478 | Estimated time: 554.85
Train loss on 50 batch: 0.186896
Train loss on 100 batch: 0.213488
Train loss on 150 batch: 0.195588
Train loss on 200 batch: 0.248868
Train loss on 250 batch: 0.209038
Train loss on 300 batch: 0.193467
Train loss on 350 batch: 0.207594
Train loss on 400 batch: 0.247355
Train loss on 450 batch: 0.219608
Train loss on 500 batch: 0.208697
Train loss on 550 batch: 0.203721
Train loss on 600 batch: 0.209246
Train loss on 650 batch: 0.222343
Train loss on 700 batch: 0.226839
Train loss on 750 batch: 0.228589
Train loss on 800 batch: 0.209791
Train loss on 850 batch: 0.261849
Train loss on 900 batch: 0.204117
Train loss on 950 batch: 0.238484
Train loss on 1000 batch: 0.197374
Train loss on 1050 batch: 0.275536
Train loss on 1100 batch: 0.237015
Train loss on 1150 batch: 0.219533
Train loss on 1200 batch: 0.188141
Train loss on 1250 batch: 0.218747
Train loss on 1300 batch: 0.185926
Train loss on 1350 batch: 0.225075
Train loss on 1400 batch: 0.221531
Train loss on 1450 batch: 0.188040
Train loss on 1500 batch: 0.175714
Train loss on 1550 batch: 0.234766
Train loss on 1600 batch: 0.234564
Train loss on 1650 batch: 0.214869
Train loss on 1700 batch: 0.218700
Train loss on 1750 batch: 0.209398
Train loss on 1800 batch: 0.189560
Train loss on 1850 batch: 0.234136
Train loss on 1900 batch: 0.244066
Train loss on 1950 batch: 0.212476
Train loss on 2000 batch: 0.271417
Train loss on 2050 batch: 0.233772
Train loss on 2100 batch: 0.216868
Train loss on 2150 batch: 0.223884
: Epoch: 159 | Training Loss: 0.218751 | Val. Loss: 0.330454 | Val. Kappa Score: 0.7222 | LR: 0.000433 | Estimated time: 554.81
Train loss on 50 batch: 0.199172
Train loss on 100 batch: 0.216496
Train loss on 150 batch: 0.233642
Train loss on 200 batch: 0.194389
Train loss on 250 batch: 0.264342
Train loss on 300 batch: 0.239551
Train loss on 350 batch: 0.234458
Train loss on 400 batch: 0.203154
Train loss on 450 batch: 0.187144
Train loss on 500 batch: 0.298843
Train loss on 550 batch: 0.231006
Train loss on 600 batch: 0.191758
Train loss on 650 batch: 0.184179
Train loss on 700 batch: 0.182091
Train loss on 750 batch: 0.178477
Train loss on 800 batch: 0.184241
Train loss on 850 batch: 0.218572
Train loss on 900 batch: 0.270792
Train loss on 950 batch: 0.194509
Train loss on 1000 batch: 0.243024
Train loss on 1050 batch: 0.211828
Train loss on 1100 batch: 0.237445
Train loss on 1150 batch: 0.207371
Train loss on 1200 batch: 0.192615
Train loss on 1250 batch: 0.223683
Train loss on 1300 batch: 0.170313
Train loss on 1350 batch: 0.226642
Train loss on 1400 batch: 0.207306
Train loss on 1450 batch: 0.200633
Train loss on 1500 batch: 0.194677
Train loss on 1550 batch: 0.219917
Train loss on 1600 batch: 0.227282
Train loss on 1650 batch: 0.187908
Train loss on 1700 batch: 0.194935
Train loss on 1750 batch: 0.217884
Train loss on 1800 batch: 0.199080
Train loss on 1850 batch: 0.207351
Train loss on 1900 batch: 0.233410
Train loss on 1950 batch: 0.206343
Train loss on 2000 batch: 0.199032
Train loss on 2050 batch: 0.210570
Train loss on 2100 batch: 0.221114
Train loss on 2150 batch: 0.217134
: Epoch: 160 | Training Loss: 0.213007 | Val. Loss: 0.335153 | Val. Kappa Score: 0.7223 | LR: 0.000389 | Estimated time: 554.85
Train loss on 50 batch: 0.225227
Train loss on 100 batch: 0.231839
Train loss on 150 batch: 0.219677
Train loss on 200 batch: 0.208106
Train loss on 250 batch: 0.209687
Train loss on 300 batch: 0.196146
Train loss on 350 batch: 0.172274
Train loss on 400 batch: 0.208212
Train loss on 450 batch: 0.223427
Train loss on 500 batch: 0.181836
Train loss on 550 batch: 0.218608
Train loss on 600 batch: 0.206999
Train loss on 650 batch: 0.193810
Train loss on 700 batch: 0.213503
Train loss on 750 batch: 0.191838
Train loss on 800 batch: 0.176694
Train loss on 850 batch: 0.215112
Train loss on 900 batch: 0.209477
Train loss on 950 batch: 0.185736
Train loss on 1000 batch: 0.185068
Train loss on 1050 batch: 0.190513
Train loss on 1100 batch: 0.188853
Train loss on 1150 batch: 0.260402
Train loss on 1200 batch: 0.202584
Train loss on 1250 batch: 0.234423
Train loss on 1300 batch: 0.192967
Train loss on 1350 batch: 0.173776
Train loss on 1400 batch: 0.212613
Train loss on 1450 batch: 0.201320
Train loss on 1500 batch: 0.217719
Train loss on 1550 batch: 0.204204
Train loss on 1600 batch: 0.222946
Train loss on 1650 batch: 0.247280
Train loss on 1700 batch: 0.185287
Train loss on 1750 batch: 0.207789
Train loss on 1800 batch: 0.193508
Train loss on 1850 batch: 0.178712
Train loss on 1900 batch: 0.249912
Train loss on 1950 batch: 0.239678
Train loss on 2000 batch: 0.195891
Train loss on 2050 batch: 0.232043
Train loss on 2100 batch: 0.247616
Train loss on 2150 batch: 0.209588
: Epoch: 161 | Training Loss: 0.209389 | Val. Loss: 0.333833 | Val. Kappa Score: 0.7224 | LR: 0.000345 | Estimated time: 555.14
Train loss on 50 batch: 0.187663
Train loss on 100 batch: 0.170101
Train loss on 150 batch: 0.192365
Train loss on 200 batch: 0.215225
Train loss on 250 batch: 0.230332
Train loss on 300 batch: 0.204809
Train loss on 350 batch: 0.198541
Train loss on 400 batch: 0.230668
Train loss on 450 batch: 0.180918
Train loss on 500 batch: 0.184877
Train loss on 550 batch: 0.217317
Train loss on 600 batch: 0.191238
Train loss on 650 batch: 0.201065
Train loss on 700 batch: 0.195769
Train loss on 750 batch: 0.203974
Train loss on 800 batch: 0.166608
Train loss on 850 batch: 0.184004
Train loss on 900 batch: 0.208651
Train loss on 950 batch: 0.173840
Train loss on 1000 batch: 0.228167
Train loss on 1050 batch: 0.227348
Train loss on 1100 batch: 0.179320
Train loss on 1150 batch: 0.185275
Train loss on 1200 batch: 0.210611
Train loss on 1250 batch: 0.189229
Train loss on 1300 batch: 0.220535
Train loss on 1350 batch: 0.172230
Train loss on 1400 batch: 0.217763
Train loss on 1450 batch: 0.190325
Train loss on 1500 batch: 0.201704
Train loss on 1550 batch: 0.175560
Train loss on 1600 batch: 0.170754
Train loss on 1650 batch: 0.196227
Train loss on 1700 batch: 0.240610
Train loss on 1750 batch: 0.222990
Train loss on 1800 batch: 0.186250
Train loss on 1850 batch: 0.198617
Train loss on 1900 batch: 0.197221
Train loss on 1950 batch: 0.222952
Train loss on 2000 batch: 0.180803
Train loss on 2050 batch: 0.198884
Train loss on 2100 batch: 0.219220
Train loss on 2150 batch: 0.187918
: Epoch: 162 | Training Loss: 0.200044 | Val. Loss: 0.335688 | Val. Kappa Score: 0.7225 | LR: 0.000303 | Estimated time: 555.16
Train loss on 50 batch: 0.194513
Train loss on 100 batch: 0.211102
Train loss on 150 batch: 0.154421
Train loss on 200 batch: 0.192759
Train loss on 250 batch: 0.200088
Train loss on 300 batch: 0.171664
Train loss on 350 batch: 0.200457
Train loss on 400 batch: 0.172940
Train loss on 450 batch: 0.162399
Train loss on 500 batch: 0.176829
Train loss on 550 batch: 0.202017
Train loss on 600 batch: 0.171554
Train loss on 650 batch: 0.180657
Train loss on 700 batch: 0.196536
Train loss on 750 batch: 0.197647
Train loss on 800 batch: 0.190846
Train loss on 850 batch: 0.206846
Train loss on 900 batch: 0.217996
Train loss on 950 batch: 0.193369
Train loss on 1000 batch: 0.199514
Train loss on 1050 batch: 0.224861
Train loss on 1100 batch: 0.211637
Train loss on 1150 batch: 0.183080
Train loss on 1200 batch: 0.145026
Train loss on 1250 batch: 0.205443
Train loss on 1300 batch: 0.192352
Train loss on 1350 batch: 0.268823
Train loss on 1400 batch: 0.223082
Train loss on 1450 batch: 0.168328
Train loss on 1500 batch: 0.193021
Train loss on 1550 batch: 0.196644
Train loss on 1600 batch: 0.220581
Train loss on 1650 batch: 0.217362
Train loss on 1700 batch: 0.209372
Train loss on 1750 batch: 0.218227
Train loss on 1800 batch: 0.216525
Train loss on 1850 batch: 0.210647
Train loss on 1900 batch: 0.184294
Train loss on 1950 batch: 0.226189
Train loss on 2000 batch: 0.242471
Train loss on 2050 batch: 0.152152
Train loss on 2100 batch: 0.207736
Train loss on 2150 batch: 0.230944
: Epoch: 163 | Training Loss: 0.199123 | Val. Loss: 0.338793 | Val. Kappa Score: 0.7227 | LR: 0.000263 | Estimated time: 554.94
Train loss on 50 batch: 0.163712
Train loss on 100 batch: 0.160398
Train loss on 150 batch: 0.183748
Train loss on 200 batch: 0.216823
Train loss on 250 batch: 0.165429
Train loss on 300 batch: 0.174616
Train loss on 350 batch: 0.184783
Train loss on 400 batch: 0.172951
Train loss on 450 batch: 0.175405
Train loss on 500 batch: 0.177968
Train loss on 550 batch: 0.214864
Train loss on 600 batch: 0.199360
Train loss on 650 batch: 0.198967
Train loss on 700 batch: 0.205619
Train loss on 750 batch: 0.188536
Train loss on 800 batch: 0.193952
Train loss on 850 batch: 0.201323
Train loss on 900 batch: 0.239649
Train loss on 950 batch: 0.204059
Train loss on 1000 batch: 0.191372
Train loss on 1050 batch: 0.191054
Train loss on 1100 batch: 0.205113
Train loss on 1150 batch: 0.195682
Train loss on 1200 batch: 0.192934
Train loss on 1250 batch: 0.190247
Train loss on 1300 batch: 0.205544
Train loss on 1350 batch: 0.188186
Train loss on 1400 batch: 0.204545
Train loss on 1450 batch: 0.183359
Train loss on 1500 batch: 0.143088
Train loss on 1550 batch: 0.167208
Train loss on 1600 batch: 0.173285
Train loss on 1650 batch: 0.180970
Train loss on 1700 batch: 0.246609
Train loss on 1750 batch: 0.177367
Train loss on 1800 batch: 0.184581
Train loss on 1850 batch: 0.221633
Train loss on 1900 batch: 0.192489
Train loss on 1950 batch: 0.195721
Train loss on 2000 batch: 0.188262
Train loss on 2050 batch: 0.225670
Train loss on 2100 batch: 0.183422
Train loss on 2150 batch: 0.178443
: Epoch: 164 | Training Loss: 0.190570 | Val. Loss: 0.332965 | Val. Kappa Score: 0.7229 | LR: 0.000225 | Estimated time: 554.78
Train loss on 50 batch: 0.145368
Train loss on 100 batch: 0.162170
Train loss on 150 batch: 0.172557
Train loss on 200 batch: 0.177894
Train loss on 250 batch: 0.230991
Train loss on 300 batch: 0.161994
Train loss on 350 batch: 0.171419
Train loss on 400 batch: 0.161287
Train loss on 450 batch: 0.170699
Train loss on 500 batch: 0.192316
Train loss on 550 batch: 0.179591
Train loss on 600 batch: 0.213866
Train loss on 650 batch: 0.149074
Train loss on 700 batch: 0.140557
Train loss on 750 batch: 0.182895
Train loss on 800 batch: 0.172575
Train loss on 850 batch: 0.184275
Train loss on 900 batch: 0.245176
Train loss on 950 batch: 0.193477
Train loss on 1000 batch: 0.220934
Train loss on 1050 batch: 0.181098
Train loss on 1100 batch: 0.195643
Train loss on 1150 batch: 0.186163
Train loss on 1200 batch: 0.173446
Train loss on 1250 batch: 0.206954
Train loss on 1300 batch: 0.231918
Train loss on 1350 batch: 0.198946
Train loss on 1400 batch: 0.218986
Train loss on 1450 batch: 0.194044
Train loss on 1500 batch: 0.189766
Train loss on 1550 batch: 0.161308
Train loss on 1600 batch: 0.181340
Train loss on 1650 batch: 0.176661
Train loss on 1700 batch: 0.147478
Train loss on 1750 batch: 0.186422
Train loss on 1800 batch: 0.166594
Train loss on 1850 batch: 0.182490
Train loss on 1900 batch: 0.186660
Train loss on 1950 batch: 0.213600
Train loss on 2000 batch: 0.191117
Train loss on 2050 batch: 0.162620
Train loss on 2100 batch: 0.164210
Train loss on 2150 batch: 0.175834
: Epoch: 165 | Training Loss: 0.182911 | Val. Loss: 0.338144 | Val. Kappa Score: 0.7229 | LR: 0.000188 | Estimated time: 555.05
Train loss on 50 batch: 0.159784
Train loss on 100 batch: 0.195787
Train loss on 150 batch: 0.180830
Train loss on 200 batch: 0.128878
Train loss on 250 batch: 0.211963
Train loss on 300 batch: 0.146919
Train loss on 350 batch: 0.185257
Train loss on 400 batch: 0.153081
Train loss on 450 batch: 0.197892
Train loss on 500 batch: 0.210384
Train loss on 550 batch: 0.215320
Train loss on 600 batch: 0.177531
Train loss on 650 batch: 0.177724
Train loss on 700 batch: 0.177642
Train loss on 750 batch: 0.217549
Train loss on 800 batch: 0.156641
Train loss on 850 batch: 0.178297
Train loss on 900 batch: 0.154431
Train loss on 950 batch: 0.162757
Train loss on 1000 batch: 0.197137
Train loss on 1050 batch: 0.181068
Train loss on 1100 batch: 0.205760
Train loss on 1150 batch: 0.158756
Train loss on 1200 batch: 0.156612
Train loss on 1250 batch: 0.238887
Train loss on 1300 batch: 0.189575
Train loss on 1350 batch: 0.197279
Train loss on 1400 batch: 0.172770
Train loss on 1450 batch: 0.224210
Train loss on 1500 batch: 0.199765
Train loss on 1550 batch: 0.155736
Train loss on 1600 batch: 0.177826
Train loss on 1650 batch: 0.186428
Train loss on 1700 batch: 0.197105
Train loss on 1750 batch: 0.186429
Train loss on 1800 batch: 0.203035
Train loss on 1850 batch: 0.212310
Train loss on 1900 batch: 0.176427
Train loss on 1950 batch: 0.176637
Train loss on 2000 batch: 0.185272
Train loss on 2050 batch: 0.162544
Train loss on 2100 batch: 0.161005
Train loss on 2150 batch: 0.151004
: Epoch: 166 | Training Loss: 0.183158 | Val. Loss: 0.345370 | Val. Kappa Score: 0.7231 | LR: 0.000154 | Estimated time: 555.06
Train loss on 50 batch: 0.167720
Train loss on 100 batch: 0.199524
Train loss on 150 batch: 0.165175
Train loss on 200 batch: 0.152667
Train loss on 250 batch: 0.171584
Train loss on 300 batch: 0.160900
Train loss on 350 batch: 0.195540
Train loss on 400 batch: 0.176120
Train loss on 450 batch: 0.177772
Train loss on 500 batch: 0.179759
Train loss on 550 batch: 0.180531
Train loss on 600 batch: 0.197482
Train loss on 650 batch: 0.186692
Train loss on 700 batch: 0.189329
Train loss on 750 batch: 0.195358
Train loss on 800 batch: 0.144208
Train loss on 850 batch: 0.212186
Train loss on 900 batch: 0.183155
Train loss on 950 batch: 0.138388
Train loss on 1000 batch: 0.190799
Train loss on 1050 batch: 0.177331
Train loss on 1100 batch: 0.181263
Train loss on 1150 batch: 0.157541
Train loss on 1200 batch: 0.174672
Train loss on 1250 batch: 0.171566
Train loss on 1300 batch: 0.167317
Train loss on 1350 batch: 0.174169
Train loss on 1400 batch: 0.183677
Train loss on 1450 batch: 0.204958
Train loss on 1500 batch: 0.211899
Train loss on 1550 batch: 0.175582
Train loss on 1600 batch: 0.183935
Train loss on 1650 batch: 0.187056
Train loss on 1700 batch: 0.173101
Train loss on 1750 batch: 0.184297
Train loss on 1800 batch: 0.168894
Train loss on 1850 batch: 0.189768
Train loss on 1900 batch: 0.169701
Train loss on 1950 batch: 0.177427
Train loss on 2000 batch: 0.183478
Train loss on 2050 batch: 0.160361
Train loss on 2100 batch: 0.185208
Train loss on 2150 batch: 0.149411
: Epoch: 167 | Training Loss: 0.177657 | Val. Loss: 0.333075 | Val. Kappa Score: 0.7232 | LR: 0.000123 | Estimated time: 554.75
Train loss on 50 batch: 0.180519
Train loss on 100 batch: 0.168893
Train loss on 150 batch: 0.156110
Train loss on 200 batch: 0.185616
Train loss on 250 batch: 0.174730
Train loss on 300 batch: 0.184399
Train loss on 350 batch: 0.158302
Train loss on 400 batch: 0.161034
Train loss on 450 batch: 0.220144
Train loss on 500 batch: 0.193968
Train loss on 550 batch: 0.177200
Train loss on 600 batch: 0.159685
Train loss on 650 batch: 0.168621
Train loss on 700 batch: 0.162776
Train loss on 750 batch: 0.171659
Train loss on 800 batch: 0.164559
Train loss on 850 batch: 0.156747
Train loss on 900 batch: 0.151912
Train loss on 950 batch: 0.180529
Train loss on 1000 batch: 0.162682
Train loss on 1050 batch: 0.162978
Train loss on 1100 batch: 0.158431
Train loss on 1150 batch: 0.199888
Train loss on 1200 batch: 0.165198
Train loss on 1250 batch: 0.175311
Train loss on 1300 batch: 0.167205
Train loss on 1350 batch: 0.182286
Train loss on 1400 batch: 0.169199
Train loss on 1450 batch: 0.161555
Train loss on 1500 batch: 0.220820
Train loss on 1550 batch: 0.195758
Train loss on 1600 batch: 0.192096
Train loss on 1650 batch: 0.223721
Train loss on 1700 batch: 0.174952
Train loss on 1750 batch: 0.163542
Train loss on 1800 batch: 0.173010
Train loss on 1850 batch: 0.150390
Train loss on 1900 batch: 0.142508
Train loss on 1950 batch: 0.182988
Train loss on 2000 batch: 0.180559
Train loss on 2050 batch: 0.201005
Train loss on 2100 batch: 0.166187
Train loss on 2150 batch: 0.153021
: Epoch: 168 | Training Loss: 0.174419 | Val. Loss: 0.332494 | Val. Kappa Score: 0.7234 | LR: 0.000095 | Estimated time: 554.90
Train loss on 50 batch: 0.151898
Train loss on 100 batch: 0.154122
Train loss on 150 batch: 0.171318
Train loss on 200 batch: 0.160225
Train loss on 250 batch: 0.196939
Train loss on 300 batch: 0.196547
Train loss on 350 batch: 0.178920
Train loss on 400 batch: 0.158421
Train loss on 450 batch: 0.153440
Train loss on 500 batch: 0.191321
Train loss on 550 batch: 0.159406
Train loss on 600 batch: 0.171672
Train loss on 650 batch: 0.154681
Train loss on 700 batch: 0.147472
Train loss on 750 batch: 0.132236
Train loss on 800 batch: 0.177764
Train loss on 850 batch: 0.174021
Train loss on 900 batch: 0.139478
Train loss on 950 batch: 0.139235
Train loss on 1000 batch: 0.193182
Train loss on 1050 batch: 0.179188
Train loss on 1100 batch: 0.169842
Train loss on 1150 batch: 0.201675
Train loss on 1200 batch: 0.170216
Train loss on 1250 batch: 0.191994
Train loss on 1300 batch: 0.176387
Train loss on 1350 batch: 0.202138
Train loss on 1400 batch: 0.188361
Train loss on 1450 batch: 0.158164
Train loss on 1500 batch: 0.185391
Train loss on 1550 batch: 0.174291
Train loss on 1600 batch: 0.180127
Train loss on 1650 batch: 0.185932
Train loss on 1700 batch: 0.155157
Train loss on 1750 batch: 0.173447
Train loss on 1800 batch: 0.203778
Train loss on 1850 batch: 0.177966
Train loss on 1900 batch: 0.204426
Train loss on 1950 batch: 0.168451
Train loss on 2000 batch: 0.165107
Train loss on 2050 batch: 0.180579
Train loss on 2100 batch: 0.156175
Train loss on 2150 batch: 0.145703
: Epoch: 169 | Training Loss: 0.172046 | Val. Loss: 0.335885 | Val. Kappa Score: 0.7235 | LR: 0.000071 | Estimated time: 554.85
Train loss on 50 batch: 0.194479
Train loss on 100 batch: 0.143692
Train loss on 150 batch: 0.160747
Train loss on 200 batch: 0.206878
Train loss on 250 batch: 0.161795
Train loss on 300 batch: 0.206434
Train loss on 350 batch: 0.152540
Train loss on 400 batch: 0.116992
Train loss on 450 batch: 0.158819
Train loss on 500 batch: 0.182464
Train loss on 550 batch: 0.192059
Train loss on 600 batch: 0.176195
Train loss on 650 batch: 0.161307
Train loss on 700 batch: 0.207646
Train loss on 750 batch: 0.160338
Train loss on 800 batch: 0.163502
Train loss on 850 batch: 0.156335
Train loss on 900 batch: 0.213218
Train loss on 950 batch: 0.164079
Train loss on 1000 batch: 0.200804
Train loss on 1050 batch: 0.147826
Train loss on 1100 batch: 0.173982
Train loss on 1150 batch: 0.163076
Train loss on 1200 batch: 0.183106
Train loss on 1250 batch: 0.180511
Train loss on 1300 batch: 0.152054
Train loss on 1350 batch: 0.152713
Train loss on 1400 batch: 0.172605
Train loss on 1450 batch: 0.174912
Train loss on 1500 batch: 0.137851
Train loss on 1550 batch: 0.175841
Train loss on 1600 batch: 0.185372
Train loss on 1650 batch: 0.145573
Train loss on 1700 batch: 0.172218
Train loss on 1750 batch: 0.168611
Train loss on 1800 batch: 0.184248
Train loss on 1850 batch: 0.154470
Train loss on 1900 batch: 0.156106
Train loss on 1950 batch: 0.147572
Train loss on 2000 batch: 0.189843
Train loss on 2050 batch: 0.188665
Train loss on 2100 batch: 0.150412
Train loss on 2150 batch: 0.193627
: Epoch: 170 | Training Loss: 0.170435 | Val. Loss: 0.335686 | Val. Kappa Score: 0.7237 | LR: 0.000050 | Estimated time: 554.95
Train loss on 50 batch: 0.151389
Train loss on 100 batch: 0.165792
Train loss on 150 batch: 0.137132
Train loss on 200 batch: 0.151659
Train loss on 250 batch: 0.203024
Train loss on 300 batch: 0.171222
Train loss on 350 batch: 0.167846
Train loss on 400 batch: 0.188863
Train loss on 450 batch: 0.136179
Train loss on 500 batch: 0.173709
Train loss on 550 batch: 0.158651
Train loss on 600 batch: 0.168189
Train loss on 650 batch: 0.166199
Train loss on 700 batch: 0.165362
Train loss on 750 batch: 0.191627
Train loss on 800 batch: 0.146766
Train loss on 850 batch: 0.142227
Train loss on 900 batch: 0.204191
Train loss on 950 batch: 0.169202
Train loss on 1000 batch: 0.165606
Train loss on 1050 batch: 0.182820
Train loss on 1100 batch: 0.158913
Train loss on 1150 batch: 0.164584
Train loss on 1200 batch: 0.162602
Train loss on 1250 batch: 0.198631
Train loss on 1300 batch: 0.174866
Train loss on 1350 batch: 0.168877
Train loss on 1400 batch: 0.183458
Train loss on 1450 batch: 0.181568
Train loss on 1500 batch: 0.176825
Train loss on 1550 batch: 0.144278
Train loss on 1600 batch: 0.157578
Train loss on 1650 batch: 0.177781
Train loss on 1700 batch: 0.147039
Train loss on 1750 batch: 0.177653
Train loss on 1800 batch: 0.146156
Train loss on 1850 batch: 0.154922
Train loss on 1900 batch: 0.194859
Train loss on 1950 batch: 0.140711
Train loss on 2000 batch: 0.149367
Train loss on 2050 batch: 0.199556
Train loss on 2100 batch: 0.184512
Train loss on 2150 batch: 0.164568
: Epoch: 171 | Training Loss: 0.167261 | Val. Loss: 0.329168 | Val. Kappa Score: 0.7238 | LR: 0.000032 | Estimated time: 554.73
Train loss on 50 batch: 0.166988
Train loss on 100 batch: 0.155689
Train loss on 150 batch: 0.175082
Train loss on 200 batch: 0.154284
Train loss on 250 batch: 0.155532
Train loss on 300 batch: 0.155497
Train loss on 350 batch: 0.167365
Train loss on 400 batch: 0.180196
Train loss on 450 batch: 0.167609
Train loss on 500 batch: 0.201856
Train loss on 550 batch: 0.130234
Train loss on 600 batch: 0.153149
Train loss on 650 batch: 0.158700
Train loss on 700 batch: 0.171654
Train loss on 750 batch: 0.163889
Train loss on 800 batch: 0.175925
Train loss on 850 batch: 0.188618
Train loss on 900 batch: 0.171045
Train loss on 950 batch: 0.209361
Train loss on 1000 batch: 0.157731
Train loss on 1050 batch: 0.171936
Train loss on 1100 batch: 0.161835
Train loss on 1150 batch: 0.166578
Train loss on 1200 batch: 0.196141
Train loss on 1250 batch: 0.147584
Train loss on 1300 batch: 0.177692
Train loss on 1350 batch: 0.179702
Train loss on 1400 batch: 0.157092
Train loss on 1450 batch: 0.160900
Train loss on 1500 batch: 0.176345
Train loss on 1550 batch: 0.179917
Train loss on 1600 batch: 0.175741
Train loss on 1650 batch: 0.148263
Train loss on 1700 batch: 0.145428
Train loss on 1750 batch: 0.142155
Train loss on 1800 batch: 0.165819
Train loss on 1850 batch: 0.160961
Train loss on 1900 batch: 0.148669
Train loss on 1950 batch: 0.176483
Train loss on 2000 batch: 0.188047
Train loss on 2050 batch: 0.188397
Train loss on 2100 batch: 0.163400
Train loss on 2150 batch: 0.128325
: Epoch: 172 | Training Loss: 0.166601 | Val. Loss: 0.332952 | Val. Kappa Score: 0.7240 | LR: 0.000018 | Estimated time: 555.15
Train loss on 50 batch: 0.157956
Train loss on 100 batch: 0.187469
Train loss on 150 batch: 0.225047
Train loss on 200 batch: 0.138541
Train loss on 250 batch: 0.169894
Train loss on 300 batch: 0.142338
Train loss on 350 batch: 0.180197
Train loss on 400 batch: 0.162267
Train loss on 450 batch: 0.159428
Train loss on 500 batch: 0.154555
Train loss on 550 batch: 0.176512
Train loss on 600 batch: 0.138831
Train loss on 650 batch: 0.192548
Train loss on 700 batch: 0.159044
Train loss on 750 batch: 0.169273
Train loss on 800 batch: 0.135552
Train loss on 850 batch: 0.178824
Train loss on 900 batch: 0.176450
Train loss on 950 batch: 0.165510
Train loss on 1000 batch: 0.187843
Train loss on 1050 batch: 0.163167
Train loss on 1100 batch: 0.181990
Train loss on 1150 batch: 0.139496
Train loss on 1200 batch: 0.166121
Train loss on 1250 batch: 0.172992
Train loss on 1300 batch: 0.153976
Train loss on 1350 batch: 0.177480
Train loss on 1400 batch: 0.154847
Train loss on 1450 batch: 0.160903
Train loss on 1500 batch: 0.171281
Train loss on 1550 batch: 0.182871
Train loss on 1600 batch: 0.148368
Train loss on 1650 batch: 0.146562
Train loss on 1700 batch: 0.165872
Train loss on 1750 batch: 0.151424
Train loss on 1800 batch: 0.137128
Train loss on 1850 batch: 0.155112
Train loss on 1900 batch: 0.132442
Train loss on 1950 batch: 0.152527
Train loss on 2000 batch: 0.186080
Train loss on 2050 batch: 0.174178
Train loss on 2100 batch: 0.176921
Train loss on 2150 batch: 0.153063
: Epoch: 173 | Training Loss: 0.164711 | Val. Loss: 0.332268 | Val. Kappa Score: 0.7242 | LR: 0.000008 | Estimated time: 554.70
Train loss on 50 batch: 0.165336
Train loss on 100 batch: 0.183692
Train loss on 150 batch: 0.178164
Train loss on 200 batch: 0.179194
Train loss on 250 batch: 0.158147
Train loss on 300 batch: 0.147411
Train loss on 350 batch: 0.131858
Train loss on 400 batch: 0.148703
Train loss on 450 batch: 0.151272
Train loss on 500 batch: 0.178908
Train loss on 550 batch: 0.156980
Train loss on 600 batch: 0.194663
Train loss on 650 batch: 0.177758
Train loss on 700 batch: 0.173024
Train loss on 750 batch: 0.169591
Train loss on 800 batch: 0.138900
Train loss on 850 batch: 0.134097
Train loss on 900 batch: 0.212937
Train loss on 950 batch: 0.147639
Train loss on 1000 batch: 0.157426
Train loss on 1050 batch: 0.184386
Train loss on 1100 batch: 0.183874
Train loss on 1150 batch: 0.187416
Train loss on 1200 batch: 0.137008
Train loss on 1250 batch: 0.149705
Train loss on 1300 batch: 0.168163
Train loss on 1350 batch: 0.160465
Train loss on 1400 batch: 0.145678
Train loss on 1450 batch: 0.161437
Train loss on 1500 batch: 0.212101
Train loss on 1550 batch: 0.145906
Train loss on 1600 batch: 0.143847
Train loss on 1650 batch: 0.126574
Train loss on 1700 batch: 0.139169
Train loss on 1750 batch: 0.154001
Train loss on 1800 batch: 0.172511
Train loss on 1850 batch: 0.176887
Train loss on 1900 batch: 0.120059
Train loss on 1950 batch: 0.198106
Train loss on 2000 batch: 0.133908
Train loss on 2050 batch: 0.147931
Train loss on 2100 batch: 0.181054
Train loss on 2150 batch: 0.166843
: Epoch: 174 | Training Loss: 0.161448 | Val. Loss: 0.332454 | Val. Kappa Score: 0.7244 | LR: 0.000002 | Estimated time: 554.66
Train loss on 50 batch: 0.193929
Train loss on 100 batch: 0.190086
Train loss on 150 batch: 0.158223
Train loss on 200 batch: 0.124528
Train loss on 250 batch: 0.145536
Train loss on 300 batch: 0.180369
Train loss on 350 batch: 0.212797
Train loss on 400 batch: 0.161408
Train loss on 450 batch: 0.150604
Train loss on 500 batch: 0.150978
Train loss on 550 batch: 0.157138
Train loss on 600 batch: 0.144763
Train loss on 650 batch: 0.175044
Train loss on 700 batch: 0.192489
Train loss on 750 batch: 0.126415
Train loss on 800 batch: 0.150042
Train loss on 850 batch: 0.160187
Train loss on 900 batch: 0.133198
Train loss on 950 batch: 0.165863
Train loss on 1000 batch: 0.135639
Train loss on 1050 batch: 0.158127
Train loss on 1100 batch: 0.153330
Train loss on 1150 batch: 0.185724
Train loss on 1200 batch: 0.155746
Train loss on 1250 batch: 0.174561
Train loss on 1300 batch: 0.181339
Train loss on 1350 batch: 0.185139
Train loss on 1400 batch: 0.169402
Train loss on 1450 batch: 0.178643
Train loss on 1500 batch: 0.166529
Train loss on 1550 batch: 0.155878
Train loss on 1600 batch: 0.140990
Train loss on 1650 batch: 0.161527
Train loss on 1700 batch: 0.172375
Train loss on 1750 batch: 0.140727
Train loss on 1800 batch: 0.148783
Train loss on 1850 batch: 0.138577
Train loss on 1900 batch: 0.162888
Train loss on 1950 batch: 0.146146
Train loss on 2000 batch: 0.159968
Train loss on 2050 batch: 0.189845
Train loss on 2100 batch: 0.186908
Train loss on 2150 batch: 0.191980
: Epoch: 175 | Training Loss: 0.162657 | Val. Loss: 0.330490 | Val. Kappa Score: 0.7245 | LR: 0.000000 | Estimated time: 555.00
Train loss on 50 batch: 0.142002
Train loss on 100 batch: 0.192310
Train loss on 150 batch: 0.178518
Train loss on 200 batch: 0.185230
Train loss on 250 batch: 0.171488
Train loss on 300 batch: 0.165274
Train loss on 350 batch: 0.147139
Train loss on 400 batch: 0.164594
Train loss on 450 batch: 0.177181
Train loss on 500 batch: 0.157377
Train loss on 550 batch: 0.143791
Train loss on 600 batch: 0.154122
Train loss on 650 batch: 0.143030
Train loss on 700 batch: 0.164729
Train loss on 750 batch: 0.145142
Train loss on 800 batch: 0.159333
Train loss on 850 batch: 0.180695
Train loss on 900 batch: 0.144691
Train loss on 950 batch: 0.133170
Train loss on 1000 batch: 0.168586
Train loss on 1050 batch: 0.184004
Train loss on 1100 batch: 0.156730
Train loss on 1150 batch: 0.145567
Train loss on 1200 batch: 0.186370
Train loss on 1250 batch: 0.169654
Train loss on 1300 batch: 0.159907
Train loss on 1350 batch: 0.169026
Train loss on 1400 batch: 0.146810
Train loss on 1450 batch: 0.202833
Train loss on 1500 batch: 0.131138
Train loss on 1550 batch: 0.126668
Train loss on 1600 batch: 0.157127
Train loss on 1650 batch: 0.183829
Train loss on 1700 batch: 0.193035
Train loss on 1750 batch: 0.136198
Train loss on 1800 batch: 0.137762
Train loss on 1850 batch: 0.154469
Train loss on 1900 batch: 0.164048
Train loss on 1950 batch: 0.195814
Train loss on 2000 batch: 0.148572
Train loss on 2050 batch: 0.147178
Train loss on 2100 batch: 0.168292
Train loss on 2150 batch: 0.150695
: Epoch: 176 | Training Loss: 0.160659 | Val. Loss: 0.334783 | Val. Kappa Score: 0.7247 | LR: 0.000002 | Estimated time: 554.95
Train loss on 50 batch: 0.138397
Train loss on 100 batch: 0.149520
Train loss on 150 batch: 0.204061
Train loss on 200 batch: 0.157398
Train loss on 250 batch: 0.186724
Train loss on 300 batch: 0.161187
Train loss on 350 batch: 0.188780
Train loss on 400 batch: 0.122210
Train loss on 450 batch: 0.134400
Train loss on 500 batch: 0.151187
Train loss on 550 batch: 0.184124
Train loss on 600 batch: 0.169157
Train loss on 650 batch: 0.173205
Train loss on 700 batch: 0.161606
Train loss on 750 batch: 0.129060
Train loss on 800 batch: 0.138609
Train loss on 850 batch: 0.164222
Train loss on 900 batch: 0.182705
Train loss on 950 batch: 0.121705
Train loss on 1000 batch: 0.148973
Train loss on 1050 batch: 0.172444
Train loss on 1100 batch: 0.169410
Train loss on 1150 batch: 0.176321
Train loss on 1200 batch: 0.205875
Train loss on 1250 batch: 0.154879
Train loss on 1300 batch: 0.157667
Train loss on 1350 batch: 0.160962
Train loss on 1400 batch: 0.172561
Train loss on 1450 batch: 0.178090
Train loss on 1500 batch: 0.154370
Train loss on 1550 batch: 0.177752
Train loss on 1600 batch: 0.143060
Train loss on 1650 batch: 0.150014
Train loss on 1700 batch: 0.175202
Train loss on 1750 batch: 0.139805
Train loss on 1800 batch: 0.161679
Train loss on 1850 batch: 0.174744
Train loss on 1900 batch: 0.147144
Train loss on 1950 batch: 0.154788
Train loss on 2000 batch: 0.169357
Train loss on 2050 batch: 0.162713
Train loss on 2100 batch: 0.163125
Train loss on 2150 batch: 0.177829
: Epoch: 177 | Training Loss: 0.161975 | Val. Loss: 0.333203 | Val. Kappa Score: 0.7248 | LR: 0.000008 | Estimated time: 554.84
Train loss on 50 batch: 0.140434
Train loss on 100 batch: 0.186817
Train loss on 150 batch: 0.150010
Train loss on 200 batch: 0.177689
Train loss on 250 batch: 0.148979
Train loss on 300 batch: 0.145047
Train loss on 350 batch: 0.140756
Train loss on 400 batch: 0.151797
Train loss on 450 batch: 0.161832
Train loss on 500 batch: 0.166983
Train loss on 550 batch: 0.189198
Train loss on 600 batch: 0.191691
Train loss on 650 batch: 0.177489
Train loss on 700 batch: 0.209896
Train loss on 750 batch: 0.128648
Train loss on 800 batch: 0.169071
Train loss on 850 batch: 0.132452
Train loss on 900 batch: 0.149504
Train loss on 950 batch: 0.173723
Train loss on 1000 batch: 0.136373
Train loss on 1050 batch: 0.193638
Train loss on 1100 batch: 0.152430
Train loss on 1150 batch: 0.153638
Train loss on 1200 batch: 0.156337
Train loss on 1250 batch: 0.154691
Train loss on 1300 batch: 0.178699
Train loss on 1350 batch: 0.133025
Train loss on 1400 batch: 0.154736
Train loss on 1450 batch: 0.155457
Train loss on 1500 batch: 0.151573
Train loss on 1550 batch: 0.180091
Train loss on 1600 batch: 0.159641
Train loss on 1650 batch: 0.157916
Train loss on 1700 batch: 0.155592
Train loss on 1750 batch: 0.147399
Train loss on 1800 batch: 0.179559
Train loss on 1850 batch: 0.171460
Train loss on 1900 batch: 0.177919
Train loss on 1950 batch: 0.146607
Train loss on 2000 batch: 0.174632
Train loss on 2050 batch: 0.145007
Train loss on 2100 batch: 0.165530
Train loss on 2150 batch: 0.162752
: Epoch: 178 | Training Loss: 0.162217 | Val. Loss: 0.333459 | Val. Kappa Score: 0.7249 | LR: 0.000018 | Estimated time: 555.27
Train loss on 50 batch: 0.115569
Train loss on 100 batch: 0.156659
Train loss on 150 batch: 0.146108
Train loss on 200 batch: 0.164905
Train loss on 250 batch: 0.168069
Train loss on 300 batch: 0.156106
Train loss on 350 batch: 0.187401
Train loss on 400 batch: 0.140781
Train loss on 450 batch: 0.147918
Train loss on 500 batch: 0.164130
Train loss on 550 batch: 0.195509
Train loss on 600 batch: 0.163492
Train loss on 650 batch: 0.186326
Train loss on 700 batch: 0.181393
Train loss on 750 batch: 0.150368
Train loss on 800 batch: 0.191222
Train loss on 850 batch: 0.165607
Train loss on 900 batch: 0.168628
Train loss on 950 batch: 0.171235
Train loss on 1000 batch: 0.148124
Train loss on 1050 batch: 0.197589
Train loss on 1100 batch: 0.172548
Train loss on 1150 batch: 0.148674
Train loss on 1200 batch: 0.199894
Train loss on 1250 batch: 0.109998
Train loss on 1300 batch: 0.172626
Train loss on 1350 batch: 0.149227
Train loss on 1400 batch: 0.199803
Train loss on 1450 batch: 0.131625
Train loss on 1500 batch: 0.169200
Train loss on 1550 batch: 0.138392
Train loss on 1600 batch: 0.143007
Train loss on 1650 batch: 0.160139
Train loss on 1700 batch: 0.161337
Train loss on 1750 batch: 0.161757
Train loss on 1800 batch: 0.144469
Train loss on 1850 batch: 0.155426
Train loss on 1900 batch: 0.168002
Train loss on 1950 batch: 0.127988
Train loss on 2000 batch: 0.155950
Train loss on 2050 batch: 0.160821
Train loss on 2100 batch: 0.185852
Train loss on 2150 batch: 0.157592
: Epoch: 179 | Training Loss: 0.161917 | Val. Loss: 0.332341 | Val. Kappa Score: 0.7252 | LR: 0.000032 | Estimated time: 555.30
Train loss on 50 batch: 0.170719
Train loss on 100 batch: 0.182842
Train loss on 150 batch: 0.164413
Train loss on 200 batch: 0.150850
Train loss on 250 batch: 0.181578
Train loss on 300 batch: 0.197421
Train loss on 350 batch: 0.124890
Train loss on 400 batch: 0.174133
Train loss on 450 batch: 0.166045
Train loss on 500 batch: 0.168607
Train loss on 550 batch: 0.192634
Train loss on 600 batch: 0.151424
Train loss on 650 batch: 0.168514
Train loss on 700 batch: 0.125982
Train loss on 750 batch: 0.134855
Train loss on 800 batch: 0.150849
Train loss on 850 batch: 0.175304
Train loss on 900 batch: 0.158809
Train loss on 950 batch: 0.138198
Train loss on 1000 batch: 0.171149
Train loss on 1050 batch: 0.156186
Train loss on 1100 batch: 0.144179
Train loss on 1150 batch: 0.141121
Train loss on 1200 batch: 0.148471
Train loss on 1250 batch: 0.177967
Train loss on 1300 batch: 0.191208
Train loss on 1350 batch: 0.189106
Train loss on 1400 batch: 0.144364
Train loss on 1450 batch: 0.138429
Train loss on 1500 batch: 0.187824
Train loss on 1550 batch: 0.171167
Train loss on 1600 batch: 0.165587
Train loss on 1650 batch: 0.168794
Train loss on 1700 batch: 0.134946
Train loss on 1750 batch: 0.169790
Train loss on 1800 batch: 0.155541
Train loss on 1850 batch: 0.175273
Train loss on 1900 batch: 0.171238
Train loss on 1950 batch: 0.152468
Train loss on 2000 batch: 0.185385
Train loss on 2050 batch: 0.155482
Train loss on 2100 batch: 0.159437
Train loss on 2150 batch: 0.153677
: Epoch: 180 | Training Loss: 0.161969 | Val. Loss: 0.328136 | Val. Kappa Score: 0.7253 | LR: 0.000050 | Estimated time: 554.89
Train loss on 50 batch: 0.149510
Train loss on 100 batch: 0.158270
Train loss on 150 batch: 0.160868
Train loss on 200 batch: 0.204715
Train loss on 250 batch: 0.151970
Train loss on 300 batch: 0.173633
Train loss on 350 batch: 0.182578
Train loss on 400 batch: 0.157062
Train loss on 450 batch: 0.182688
Train loss on 500 batch: 0.147508
Train loss on 550 batch: 0.151415
Train loss on 600 batch: 0.147864
Train loss on 650 batch: 0.170873
Train loss on 700 batch: 0.185271
Train loss on 750 batch: 0.193649
Train loss on 800 batch: 0.163673
Train loss on 850 batch: 0.156579
Train loss on 900 batch: 0.162563
Train loss on 950 batch: 0.191150
Train loss on 1000 batch: 0.153785
Train loss on 1050 batch: 0.142154
Train loss on 1100 batch: 0.150212
Train loss on 1150 batch: 0.158212
Train loss on 1200 batch: 0.166221
Train loss on 1250 batch: 0.184244
Train loss on 1300 batch: 0.146209
Train loss on 1350 batch: 0.134723
Train loss on 1400 batch: 0.167620
Train loss on 1450 batch: 0.173862
Train loss on 1500 batch: 0.145991
Train loss on 1550 batch: 0.169001
Train loss on 1600 batch: 0.142763
Train loss on 1650 batch: 0.134589
Train loss on 1700 batch: 0.153921
Train loss on 1750 batch: 0.177437
Train loss on 1800 batch: 0.180359
Train loss on 1850 batch: 0.186151
Train loss on 1900 batch: 0.177428
Train loss on 1950 batch: 0.148901
Train loss on 2000 batch: 0.164799
Train loss on 2050 batch: 0.144021
Train loss on 2100 batch: 0.181331
Train loss on 2150 batch: 0.181387
: Epoch: 181 | Training Loss: 0.164281 | Val. Loss: 0.331559 | Val. Kappa Score: 0.7254 | LR: 0.000071 | Estimated time: 555.34
Train loss on 50 batch: 0.132729
Train loss on 100 batch: 0.152460
Train loss on 150 batch: 0.154993
Train loss on 200 batch: 0.181883
Train loss on 250 batch: 0.185417
Train loss on 300 batch: 0.146139
Train loss on 350 batch: 0.157873
Train loss on 400 batch: 0.187809
Train loss on 450 batch: 0.118236
Train loss on 500 batch: 0.179395
Train loss on 550 batch: 0.153972
Train loss on 600 batch: 0.162398
Train loss on 650 batch: 0.184000
Train loss on 700 batch: 0.151669
Train loss on 750 batch: 0.183305
Train loss on 800 batch: 0.179509
Train loss on 850 batch: 0.149775
Train loss on 900 batch: 0.137219
Train loss on 950 batch: 0.154932
Train loss on 1000 batch: 0.160883
Train loss on 1050 batch: 0.117217
Train loss on 1100 batch: 0.131692
Train loss on 1150 batch: 0.155896
Train loss on 1200 batch: 0.154479
Train loss on 1250 batch: 0.194841
Train loss on 1300 batch: 0.136835
Train loss on 1350 batch: 0.188098
Train loss on 1400 batch: 0.177646
Train loss on 1450 batch: 0.177184
Train loss on 1500 batch: 0.173677
Train loss on 1550 batch: 0.152756
Train loss on 1600 batch: 0.168007
Train loss on 1650 batch: 0.182710
Train loss on 1700 batch: 0.127563
Train loss on 1750 batch: 0.200237
Train loss on 1800 batch: 0.159123
Train loss on 1850 batch: 0.145769
Train loss on 1900 batch: 0.172532
Train loss on 1950 batch: 0.216767
Train loss on 2000 batch: 0.188653
Train loss on 2050 batch: 0.150185
Train loss on 2100 batch: 0.215626
Train loss on 2150 batch: 0.193572
: Epoch: 182 | Training Loss: 0.164844 | Val. Loss: 0.330208 | Val. Kappa Score: 0.7256 | LR: 0.000095 | Estimated time: 554.99
Train loss on 50 batch: 0.142925
Train loss on 100 batch: 0.166331
Train loss on 150 batch: 0.160516
Train loss on 200 batch: 0.195125
Train loss on 250 batch: 0.129797
Train loss on 300 batch: 0.120987
Train loss on 350 batch: 0.151515
Train loss on 400 batch: 0.170045
Train loss on 450 batch: 0.153158
Train loss on 500 batch: 0.158538
Train loss on 550 batch: 0.188577
Train loss on 600 batch: 0.171435
Train loss on 650 batch: 0.180907
Train loss on 700 batch: 0.172140
Train loss on 750 batch: 0.163560
Train loss on 800 batch: 0.165056
Train loss on 850 batch: 0.175888
Train loss on 900 batch: 0.132762
Train loss on 950 batch: 0.146013
Train loss on 1000 batch: 0.163437
Train loss on 1050 batch: 0.145256
Train loss on 1100 batch: 0.192206
Train loss on 1150 batch: 0.175574
Train loss on 1200 batch: 0.191475
Train loss on 1250 batch: 0.141385
Train loss on 1300 batch: 0.171907
Train loss on 1350 batch: 0.142988
Train loss on 1400 batch: 0.150569
Train loss on 1450 batch: 0.167181
Train loss on 1500 batch: 0.186927
Train loss on 1550 batch: 0.176792
Train loss on 1600 batch: 0.191345
Train loss on 1650 batch: 0.144397
Train loss on 1700 batch: 0.144782
Train loss on 1750 batch: 0.170307
Train loss on 1800 batch: 0.177988
Train loss on 1850 batch: 0.178445
Train loss on 1900 batch: 0.179450
Train loss on 1950 batch: 0.174998
Train loss on 2000 batch: 0.175769
Train loss on 2050 batch: 0.186504
Train loss on 2100 batch: 0.206201
Train loss on 2150 batch: 0.170958
: Epoch: 183 | Training Loss: 0.167236 | Val. Loss: 0.329627 | Val. Kappa Score: 0.7257 | LR: 0.000123 | Estimated time: 554.97
Train loss on 50 batch: 0.143984
Train loss on 100 batch: 0.155253
Train loss on 150 batch: 0.176507
Train loss on 200 batch: 0.146116
Train loss on 250 batch: 0.151521
Train loss on 300 batch: 0.148039
Train loss on 350 batch: 0.168650
Train loss on 400 batch: 0.194698
Train loss on 450 batch: 0.162062
Train loss on 500 batch: 0.176593
Train loss on 550 batch: 0.192325
Train loss on 600 batch: 0.155872
Train loss on 650 batch: 0.143728
Train loss on 700 batch: 0.158287
Train loss on 750 batch: 0.158204
Train loss on 800 batch: 0.138748
Train loss on 850 batch: 0.197956
Train loss on 900 batch: 0.170121
Train loss on 950 batch: 0.150971
Train loss on 1000 batch: 0.168816
Train loss on 1050 batch: 0.172233
Train loss on 1100 batch: 0.186777
Train loss on 1150 batch: 0.167973
Train loss on 1200 batch: 0.160353
Train loss on 1250 batch: 0.165168
Train loss on 1300 batch: 0.150031
Train loss on 1350 batch: 0.178702
Train loss on 1400 batch: 0.150045
Train loss on 1450 batch: 0.148214
Train loss on 1500 batch: 0.169097
Train loss on 1550 batch: 0.156918
Train loss on 1600 batch: 0.179457
Train loss on 1650 batch: 0.166713
Train loss on 1700 batch: 0.136791
Train loss on 1750 batch: 0.179446
Train loss on 1800 batch: 0.165911
Train loss on 1850 batch: 0.140645
Train loss on 1900 batch: 0.176134
Train loss on 1950 batch: 0.165758
Train loss on 2000 batch: 0.187935
Train loss on 2050 batch: 0.156973
Train loss on 2100 batch: 0.175091
Train loss on 2150 batch: 0.192983
: Epoch: 184 | Training Loss: 0.164132 | Val. Loss: 0.329470 | Val. Kappa Score: 0.7259 | LR: 0.000154 | Estimated time: 554.88
Train loss on 50 batch: 0.154786
Train loss on 100 batch: 0.174596
Train loss on 150 batch: 0.142649
Train loss on 200 batch: 0.184940
Train loss on 250 batch: 0.179594
Train loss on 300 batch: 0.179728
Train loss on 350 batch: 0.160451
Train loss on 400 batch: 0.150812
Train loss on 450 batch: 0.178548
Train loss on 500 batch: 0.123032
Train loss on 550 batch: 0.167363
Train loss on 600 batch: 0.141738
Train loss on 650 batch: 0.179021
Train loss on 700 batch: 0.192170
Train loss on 750 batch: 0.155735
Train loss on 800 batch: 0.158796
Train loss on 850 batch: 0.163345
Train loss on 900 batch: 0.180002
Train loss on 950 batch: 0.139977
Train loss on 1000 batch: 0.162614
Train loss on 1050 batch: 0.173457
Train loss on 1100 batch: 0.148263
Train loss on 1150 batch: 0.138076
Train loss on 1200 batch: 0.217466
Train loss on 1250 batch: 0.154144
Train loss on 1300 batch: 0.182223
Train loss on 1350 batch: 0.188405
Train loss on 1400 batch: 0.174576
Train loss on 1450 batch: 0.182856
Train loss on 1500 batch: 0.162853
Train loss on 1550 batch: 0.213800
Train loss on 1600 batch: 0.136414
Train loss on 1650 batch: 0.132422
Train loss on 1700 batch: 0.154102
Train loss on 1750 batch: 0.185880
Train loss on 1800 batch: 0.166426
Train loss on 1850 batch: 0.171488
Train loss on 1900 batch: 0.192543
Train loss on 1950 batch: 0.146342
Train loss on 2000 batch: 0.162669
Train loss on 2050 batch: 0.166612
Train loss on 2100 batch: 0.201413
Train loss on 2150 batch: 0.171877
: Epoch: 185 | Training Loss: 0.168193 | Val. Loss: 0.343502 | Val. Kappa Score: 0.7259 | LR: 0.000188 | Estimated time: 555.10
Train loss on 50 batch: 0.172091
Train loss on 100 batch: 0.175752
Train loss on 150 batch: 0.188446
Train loss on 200 batch: 0.179913
Train loss on 250 batch: 0.143580
Train loss on 300 batch: 0.185832
Train loss on 350 batch: 0.168063
Train loss on 400 batch: 0.179378
Train loss on 450 batch: 0.152564
Train loss on 500 batch: 0.158811
Train loss on 550 batch: 0.186358
Train loss on 600 batch: 0.160483
Train loss on 650 batch: 0.170000
Train loss on 700 batch: 0.162155
Train loss on 750 batch: 0.174912
Train loss on 800 batch: 0.173225
Train loss on 850 batch: 0.181651
Train loss on 900 batch: 0.169349
Train loss on 950 batch: 0.170354
Train loss on 1000 batch: 0.152437
Train loss on 1050 batch: 0.148998
Train loss on 1100 batch: 0.167761
Train loss on 1150 batch: 0.155750
Train loss on 1200 batch: 0.141698
Train loss on 1250 batch: 0.157252
Train loss on 1300 batch: 0.176352
Train loss on 1350 batch: 0.188078
Train loss on 1400 batch: 0.146476
Train loss on 1450 batch: 0.135297
Train loss on 1500 batch: 0.154681
Train loss on 1550 batch: 0.181499
Train loss on 1600 batch: 0.171449
Train loss on 1650 batch: 0.179716
Train loss on 1700 batch: 0.194365
Train loss on 1750 batch: 0.174523
Train loss on 1800 batch: 0.198355
Train loss on 1850 batch: 0.176407
Train loss on 1900 batch: 0.165103
Train loss on 1950 batch: 0.175942
Train loss on 2000 batch: 0.204770
Train loss on 2050 batch: 0.144294
Train loss on 2100 batch: 0.189919
Train loss on 2150 batch: 0.173285
: Epoch: 186 | Training Loss: 0.169733 | Val. Loss: 0.343175 | Val. Kappa Score: 0.7260 | LR: 0.000225 | Estimated time: 555.59
Train loss on 50 batch: 0.160484
Train loss on 100 batch: 0.175711
Train loss on 150 batch: 0.174704
Train loss on 200 batch: 0.201598
Train loss on 250 batch: 0.151323
Train loss on 300 batch: 0.166037
Train loss on 350 batch: 0.140870
Train loss on 400 batch: 0.159260
Train loss on 450 batch: 0.172800
Train loss on 500 batch: 0.160677
Train loss on 550 batch: 0.160277
Train loss on 600 batch: 0.185700
Train loss on 650 batch: 0.181517
Train loss on 700 batch: 0.196327
Train loss on 750 batch: 0.209947
Train loss on 800 batch: 0.181619
Train loss on 850 batch: 0.149049
Train loss on 900 batch: 0.157573
Train loss on 950 batch: 0.167269
Train loss on 1000 batch: 0.159876
Train loss on 1050 batch: 0.177704
Train loss on 1100 batch: 0.155844
Train loss on 1150 batch: 0.167981
Train loss on 1200 batch: 0.175890
Train loss on 1250 batch: 0.177012
Train loss on 1300 batch: 0.151834
Train loss on 1350 batch: 0.166211
Train loss on 1400 batch: 0.172614
Train loss on 1450 batch: 0.171880
Train loss on 1500 batch: 0.161907
Train loss on 1550 batch: 0.173896
Train loss on 1600 batch: 0.190908
Train loss on 1650 batch: 0.165462
Train loss on 1700 batch: 0.169528
Train loss on 1750 batch: 0.156045
Train loss on 1800 batch: 0.180257
Train loss on 1850 batch: 0.183293
Train loss on 1900 batch: 0.182754
Train loss on 1950 batch: 0.183984
Train loss on 2000 batch: 0.170269
Train loss on 2050 batch: 0.197805
Train loss on 2100 batch: 0.190035
Train loss on 2150 batch: 0.160274
: Epoch: 187 | Training Loss: 0.171371 | Val. Loss: 0.359482 | Val. Kappa Score: 0.7261 | LR: 0.000263 | Estimated time: 555.08
Train loss on 50 batch: 0.168126
Train loss on 100 batch: 0.179063
Train loss on 150 batch: 0.172502
Train loss on 200 batch: 0.192192
Train loss on 250 batch: 0.201061
Train loss on 300 batch: 0.162725
Train loss on 350 batch: 0.173041
Train loss on 400 batch: 0.162106
Train loss on 450 batch: 0.171109
Train loss on 500 batch: 0.172542
Train loss on 550 batch: 0.222859
Train loss on 600 batch: 0.152293
Train loss on 650 batch: 0.169472
Train loss on 700 batch: 0.175784
Train loss on 750 batch: 0.172402
Train loss on 800 batch: 0.175461
Train loss on 850 batch: 0.148380
Train loss on 900 batch: 0.192069
Train loss on 950 batch: 0.152753
Train loss on 1000 batch: 0.117060
Train loss on 1050 batch: 0.179750
Train loss on 1100 batch: 0.170671
Train loss on 1150 batch: 0.157782
Train loss on 1200 batch: 0.168248
Train loss on 1250 batch: 0.183346
Train loss on 1300 batch: 0.154184
Train loss on 1350 batch: 0.123236
Train loss on 1400 batch: 0.183275
Train loss on 1450 batch: 0.213707
Train loss on 1500 batch: 0.185217
Train loss on 1550 batch: 0.183044
Train loss on 1600 batch: 0.167348
Train loss on 1650 batch: 0.149090
Train loss on 1700 batch: 0.209277
Train loss on 1750 batch: 0.160224
Train loss on 1800 batch: 0.194947
Train loss on 1850 batch: 0.168567
Train loss on 1900 batch: 0.151589
Train loss on 1950 batch: 0.134728
Train loss on 2000 batch: 0.184020
Train loss on 2050 batch: 0.156075
Train loss on 2100 batch: 0.169852
Train loss on 2150 batch: 0.174413
: Epoch: 188 | Training Loss: 0.172232 | Val. Loss: 0.342914 | Val. Kappa Score: 0.7261 | LR: 0.000303 | Estimated time: 555.18
Train loss on 50 batch: 0.174219
Train loss on 100 batch: 0.188823
Train loss on 150 batch: 0.168811
Train loss on 200 batch: 0.181474
Train loss on 250 batch: 0.194993
Train loss on 300 batch: 0.192747
Train loss on 350 batch: 0.178232
Train loss on 400 batch: 0.184138
Train loss on 450 batch: 0.163129
Train loss on 500 batch: 0.184068
Train loss on 550 batch: 0.180048
Train loss on 600 batch: 0.168719
Train loss on 650 batch: 0.179342
Train loss on 700 batch: 0.166087
Train loss on 750 batch: 0.157817
Train loss on 800 batch: 0.159356
Train loss on 850 batch: 0.189900
Train loss on 900 batch: 0.145732
Train loss on 950 batch: 0.188076
Train loss on 1000 batch: 0.200196
Train loss on 1050 batch: 0.193834
Train loss on 1100 batch: 0.165291
Train loss on 1150 batch: 0.171669
Train loss on 1200 batch: 0.167610
Train loss on 1250 batch: 0.179226
Train loss on 1300 batch: 0.172403
Train loss on 1350 batch: 0.180459
Train loss on 1400 batch: 0.178831
Train loss on 1450 batch: 0.180933
Train loss on 1500 batch: 0.194753
Train loss on 1550 batch: 0.210493
Train loss on 1600 batch: 0.184220
Train loss on 1650 batch: 0.202403
Train loss on 1700 batch: 0.206718
Train loss on 1750 batch: 0.198996
Train loss on 1800 batch: 0.185931
Train loss on 1850 batch: 0.162850
Train loss on 1900 batch: 0.186600
Train loss on 1950 batch: 0.190059
Train loss on 2000 batch: 0.166461
Train loss on 2050 batch: 0.157450
Train loss on 2100 batch: 0.141964
Train loss on 2150 batch: 0.203580
: Epoch: 189 | Training Loss: 0.179166 | Val. Loss: 0.339117 | Val. Kappa Score: 0.7262 | LR: 0.000345 | Estimated time: 555.04
Train loss on 50 batch: 0.174688
Train loss on 100 batch: 0.160948
Train loss on 150 batch: 0.171430
Train loss on 200 batch: 0.175711
Train loss on 250 batch: 0.172866
Train loss on 300 batch: 0.184083
Train loss on 350 batch: 0.185794
Train loss on 400 batch: 0.233175
Train loss on 450 batch: 0.139475
Train loss on 500 batch: 0.156844
Train loss on 550 batch: 0.193844
Train loss on 600 batch: 0.187515
Train loss on 650 batch: 0.179397
Train loss on 700 batch: 0.153725
Train loss on 750 batch: 0.184651
Train loss on 800 batch: 0.225719
Train loss on 850 batch: 0.191758
Train loss on 900 batch: 0.195845
Train loss on 950 batch: 0.204356
Train loss on 1000 batch: 0.196537
Train loss on 1050 batch: 0.179842
Train loss on 1100 batch: 0.190415
Train loss on 1150 batch: 0.213124
Train loss on 1200 batch: 0.185583
Train loss on 1250 batch: 0.172333
Train loss on 1300 batch: 0.177690
Train loss on 1350 batch: 0.176649
Train loss on 1400 batch: 0.189307
Train loss on 1450 batch: 0.170615
Train loss on 1500 batch: 0.179704
Train loss on 1550 batch: 0.175777
Train loss on 1600 batch: 0.162995
Train loss on 1650 batch: 0.131913
Train loss on 1700 batch: 0.215350
Train loss on 1750 batch: 0.148478
Train loss on 1800 batch: 0.181935
Train loss on 1850 batch: 0.180941
Train loss on 1900 batch: 0.216166
Train loss on 1950 batch: 0.147616
Train loss on 2000 batch: 0.184990
Train loss on 2050 batch: 0.160875
Train loss on 2100 batch: 0.177507
Train loss on 2150 batch: 0.192833
: Epoch: 190 | Training Loss: 0.181219 | Val. Loss: 0.348329 | Val. Kappa Score: 0.7264 | LR: 0.000389 | Estimated time: 555.14
Train loss on 50 batch: 0.195339
Train loss on 100 batch: 0.152004
Train loss on 150 batch: 0.174143
Train loss on 200 batch: 0.173441
Train loss on 250 batch: 0.152299
Train loss on 300 batch: 0.191984
Train loss on 350 batch: 0.205122
Train loss on 400 batch: 0.153534
Train loss on 450 batch: 0.186865
Train loss on 500 batch: 0.178424
Train loss on 550 batch: 0.180715
Train loss on 600 batch: 0.148783
Train loss on 650 batch: 0.229915
Train loss on 700 batch: 0.176669
Train loss on 750 batch: 0.153290
Train loss on 800 batch: 0.211424
Train loss on 850 batch: 0.183616
Train loss on 900 batch: 0.178432
Train loss on 950 batch: 0.208407
Train loss on 1000 batch: 0.194764
Train loss on 1050 batch: 0.185313
Train loss on 1100 batch: 0.170158
Train loss on 1150 batch: 0.205781
Train loss on 1200 batch: 0.216866
Train loss on 1250 batch: 0.159347
Train loss on 1300 batch: 0.148876
Train loss on 1350 batch: 0.184612
Train loss on 1400 batch: 0.167774
Train loss on 1450 batch: 0.209490
Train loss on 1500 batch: 0.160263
Train loss on 1550 batch: 0.178867
Train loss on 1600 batch: 0.187762
Train loss on 1650 batch: 0.183494
Train loss on 1700 batch: 0.178701
Train loss on 1750 batch: 0.230034
Train loss on 1800 batch: 0.191113
Train loss on 1850 batch: 0.176340
Train loss on 1900 batch: 0.168523
Train loss on 1950 batch: 0.176598
Train loss on 2000 batch: 0.167030
Train loss on 2050 batch: 0.158820
Train loss on 2100 batch: 0.196627
Train loss on 2150 batch: 0.196009
: Epoch: 191 | Training Loss: 0.182850 | Val. Loss: 0.343992 | Val. Kappa Score: 0.7265 | LR: 0.000433 | Estimated time: 555.15
Train loss on 50 batch: 0.175938
Train loss on 100 batch: 0.194693
Train loss on 150 batch: 0.164193
Train loss on 200 batch: 0.164437
Train loss on 250 batch: 0.174899
Train loss on 300 batch: 0.181195
Train loss on 350 batch: 0.199453
Train loss on 400 batch: 0.199117
Train loss on 450 batch: 0.181642
Train loss on 500 batch: 0.180328
Train loss on 550 batch: 0.186318
Train loss on 600 batch: 0.222283
Train loss on 650 batch: 0.182918
Train loss on 700 batch: 0.188917
Train loss on 750 batch: 0.214108
Train loss on 800 batch: 0.160288
Train loss on 850 batch: 0.206553
Train loss on 900 batch: 0.271270
Train loss on 950 batch: 0.143694
Train loss on 1000 batch: 0.185204
Train loss on 1050 batch: 0.175213
Train loss on 1100 batch: 0.189588
Train loss on 1150 batch: 0.168015
Train loss on 1200 batch: 0.215069
Train loss on 1250 batch: 0.183876
Train loss on 1300 batch: 0.186266
Train loss on 1350 batch: 0.215022
Train loss on 1400 batch: 0.135840
Train loss on 1450 batch: 0.162292
Train loss on 1500 batch: 0.199501
Train loss on 1550 batch: 0.182454
Train loss on 1600 batch: 0.234862
Train loss on 1650 batch: 0.165901
Train loss on 1700 batch: 0.199851
Train loss on 1750 batch: 0.192709
Train loss on 1800 batch: 0.174632
Train loss on 1850 batch: 0.207143
Train loss on 1900 batch: 0.193653
Train loss on 1950 batch: 0.156030
Train loss on 2000 batch: 0.194884
Train loss on 2050 batch: 0.171540
Train loss on 2100 batch: 0.205688
Train loss on 2150 batch: 0.189975
: Epoch: 192 | Training Loss: 0.189001 | Val. Loss: 0.352147 | Val. Kappa Score: 0.7265 | LR: 0.000478 | Estimated time: 555.27
Train loss on 50 batch: 0.196074
Train loss on 100 batch: 0.190795
Train loss on 150 batch: 0.174181
Train loss on 200 batch: 0.177420
Train loss on 250 batch: 0.197169
Train loss on 300 batch: 0.168720
Train loss on 350 batch: 0.190857
Train loss on 400 batch: 0.217113
Train loss on 450 batch: 0.185053
Train loss on 500 batch: 0.186095
Train loss on 550 batch: 0.185757
Train loss on 600 batch: 0.203645
Train loss on 650 batch: 0.205159
Train loss on 700 batch: 0.192444
Train loss on 750 batch: 0.165141
Train loss on 800 batch: 0.198225
Train loss on 850 batch: 0.187254
Train loss on 900 batch: 0.207425
Train loss on 950 batch: 0.228152
Train loss on 1000 batch: 0.186834
Train loss on 1050 batch: 0.201273
Train loss on 1100 batch: 0.177547
Train loss on 1150 batch: 0.208849
Train loss on 1200 batch: 0.184631
Train loss on 1250 batch: 0.227123
Train loss on 1300 batch: 0.185227
Train loss on 1350 batch: 0.206205
Train loss on 1400 batch: 0.183281
Train loss on 1450 batch: 0.184197
Train loss on 1500 batch: 0.152830
Train loss on 1550 batch: 0.240716
Train loss on 1600 batch: 0.203917
Train loss on 1650 batch: 0.186345
Train loss on 1700 batch: 0.188130
Train loss on 1750 batch: 0.154531
Train loss on 1800 batch: 0.177005
Train loss on 1850 batch: 0.183577
Train loss on 1900 batch: 0.240396
Train loss on 1950 batch: 0.199969
Train loss on 2000 batch: 0.194513
Train loss on 2050 batch: 0.274736
Train loss on 2100 batch: 0.175990
Train loss on 2150 batch: 0.203417
: Epoch: 193 | Training Loss: 0.196085 | Val. Loss: 0.349406 | Val. Kappa Score: 0.7264 | LR: 0.000522 | Estimated time: 554.96
Train loss on 50 batch: 0.169660
Train loss on 100 batch: 0.163876
Train loss on 150 batch: 0.208656
Train loss on 200 batch: 0.168521
Train loss on 250 batch: 0.203636
Train loss on 300 batch: 0.166726
Train loss on 350 batch: 0.163212
Train loss on 400 batch: 0.202170
Train loss on 450 batch: 0.188495
Train loss on 500 batch: 0.199211
Train loss on 550 batch: 0.190217
Train loss on 600 batch: 0.214015
Train loss on 650 batch: 0.233795
Train loss on 700 batch: 0.168189
Train loss on 750 batch: 0.209396
Train loss on 800 batch: 0.203023
Train loss on 850 batch: 0.214655
Train loss on 900 batch: 0.186297
Train loss on 950 batch: 0.232092
Train loss on 1000 batch: 0.193504
Train loss on 1050 batch: 0.196974
Train loss on 1100 batch: 0.190941
Train loss on 1150 batch: 0.204731
Train loss on 1200 batch: 0.183474
Train loss on 1250 batch: 0.203755
Train loss on 1300 batch: 0.198117
Train loss on 1350 batch: 0.178601
Train loss on 1400 batch: 0.210062
Train loss on 1450 batch: 0.211899
Train loss on 1500 batch: 0.216069
Train loss on 1550 batch: 0.194493
Train loss on 1600 batch: 0.185061
Train loss on 1650 batch: 0.201059
Train loss on 1700 batch: 0.178295
Train loss on 1750 batch: 0.213896
Train loss on 1800 batch: 0.168961
Train loss on 1850 batch: 0.174764
Train loss on 1900 batch: 0.226975
Train loss on 1950 batch: 0.215129
Train loss on 2000 batch: 0.213557
Train loss on 2050 batch: 0.244122
Train loss on 2100 batch: 0.162294
Train loss on 2150 batch: 0.176729
: Epoch: 194 | Training Loss: 0.196519 | Val. Loss: 0.335330 | Val. Kappa Score: 0.7266 | LR: 0.000567 | Estimated time: 554.94
Train loss on 50 batch: 0.183071
Train loss on 100 batch: 0.199177
Train loss on 150 batch: 0.195443
Train loss on 200 batch: 0.162262
Train loss on 250 batch: 0.212528
Train loss on 300 batch: 0.202289
Train loss on 350 batch: 0.187232
Train loss on 400 batch: 0.177136
Train loss on 450 batch: 0.156423
Train loss on 500 batch: 0.208718
Train loss on 550 batch: 0.190043
Train loss on 600 batch: 0.211165
Train loss on 650 batch: 0.221923
Train loss on 700 batch: 0.199434
Train loss on 750 batch: 0.212645
Train loss on 800 batch: 0.184695
Train loss on 850 batch: 0.215713
Train loss on 900 batch: 0.193517
Train loss on 950 batch: 0.172505
Train loss on 1000 batch: 0.243107
Train loss on 1050 batch: 0.217894
Train loss on 1100 batch: 0.210629
Train loss on 1150 batch: 0.222662
Train loss on 1200 batch: 0.182216
Train loss on 1250 batch: 0.264371
Train loss on 1300 batch: 0.227594
Train loss on 1350 batch: 0.164962
Train loss on 1400 batch: 0.172182
Train loss on 1450 batch: 0.197897
Train loss on 1500 batch: 0.194009
Train loss on 1550 batch: 0.246706
Train loss on 1600 batch: 0.212101
Train loss on 1650 batch: 0.209259
Train loss on 1700 batch: 0.216620
Train loss on 1750 batch: 0.238738
Train loss on 1800 batch: 0.192928
Train loss on 1850 batch: 0.177976
Train loss on 1900 batch: 0.225297
Train loss on 1950 batch: 0.201940
Train loss on 2000 batch: 0.209256
Train loss on 2050 batch: 0.188656
Train loss on 2100 batch: 0.201167
Train loss on 2150 batch: 0.234046
: Epoch: 195 | Training Loss: 0.203212 | Val. Loss: 0.430569 | Val. Kappa Score: 0.7265 | LR: 0.000611 | Estimated time: 555.16
Train loss on 50 batch: 0.186884
Train loss on 100 batch: 0.187934
Train loss on 150 batch: 0.202075
Train loss on 200 batch: 0.194154
Train loss on 250 batch: 0.194319
Train loss on 300 batch: 0.209897
Train loss on 350 batch: 0.198911
Train loss on 400 batch: 0.184504
Train loss on 450 batch: 0.216444
Train loss on 500 batch: 0.184225
Train loss on 550 batch: 0.224669
Train loss on 600 batch: 0.233869
Train loss on 650 batch: 0.193737
Train loss on 700 batch: 0.213410
Train loss on 750 batch: 0.211965
Train loss on 800 batch: 0.187092
Train loss on 850 batch: 0.185745
Train loss on 900 batch: 0.199407
Train loss on 950 batch: 0.229033
Train loss on 1000 batch: 0.165928
Train loss on 1050 batch: 0.204745
Train loss on 1100 batch: 0.291082
Train loss on 1150 batch: 0.209264
Train loss on 1200 batch: 0.223052
Train loss on 1250 batch: 0.196690
Train loss on 1300 batch: 0.218402
Train loss on 1350 batch: 0.175335
Train loss on 1400 batch: 0.172290
Train loss on 1450 batch: 0.184148
Train loss on 1500 batch: 0.209069
Train loss on 1550 batch: 0.197170
Train loss on 1600 batch: 0.221286
Train loss on 1650 batch: 0.244236
Train loss on 1700 batch: 0.209390
Train loss on 1750 batch: 0.212713
Train loss on 1800 batch: 0.226621
Train loss on 1850 batch: 0.226708
Train loss on 1900 batch: 0.235258
Train loss on 1950 batch: 0.195258
Train loss on 2000 batch: 0.227683
Train loss on 2050 batch: 0.230294
Train loss on 2100 batch: 0.200756
Train loss on 2150 batch: 0.230896
: Epoch: 196 | Training Loss: 0.208168 | Val. Loss: 0.350018 | Val. Kappa Score: 0.7266 | LR: 0.000655 | Estimated time: 555.32
Train loss on 50 batch: 0.152758
Train loss on 100 batch: 0.211297
Train loss on 150 batch: 0.171503
Train loss on 200 batch: 0.238370
Train loss on 250 batch: 0.185412
Train loss on 300 batch: 0.244946
Train loss on 350 batch: 0.192375
Train loss on 400 batch: 0.156028
Train loss on 450 batch: 0.205585
Train loss on 500 batch: 0.224784
Train loss on 550 batch: 0.175574
Train loss on 600 batch: 0.256076
Train loss on 650 batch: 0.214085
Train loss on 700 batch: 0.211230
Train loss on 750 batch: 0.248494
Train loss on 800 batch: 0.227313
Train loss on 850 batch: 0.226131
Train loss on 900 batch: 0.201612
Train loss on 950 batch: 0.218586
Train loss on 1000 batch: 0.195229
Train loss on 1050 batch: 0.168719
Train loss on 1100 batch: 0.189330
Train loss on 1150 batch: 0.202139
Train loss on 1200 batch: 0.213732
Train loss on 1250 batch: 0.280761
Train loss on 1300 batch: 0.228781
Train loss on 1350 batch: 0.220774
Train loss on 1400 batch: 0.164590
Train loss on 1450 batch: 0.230478
Train loss on 1500 batch: 0.258385
Train loss on 1550 batch: 0.220575
Train loss on 1600 batch: 0.227843
Train loss on 1650 batch: 0.224709
Train loss on 1700 batch: 0.249071
Train loss on 1750 batch: 0.183032
Train loss on 1800 batch: 0.177438
Train loss on 1850 batch: 0.206671
Train loss on 1900 batch: 0.188693
Train loss on 1950 batch: 0.210154
Train loss on 2000 batch: 0.217663
Train loss on 2050 batch: 0.251321
Train loss on 2100 batch: 0.209843
Train loss on 2150 batch: 0.224629
: Epoch: 197 | Training Loss: 0.213059 | Val. Loss: 0.340216 | Val. Kappa Score: 0.7267 | LR: 0.000697 | Estimated time: 555.14
Train loss on 50 batch: 0.163450
Train loss on 100 batch: 0.203867
Train loss on 150 batch: 0.194167
Train loss on 200 batch: 0.213656
Train loss on 250 batch: 0.185090
Train loss on 300 batch: 0.214458
Train loss on 350 batch: 0.230796
Train loss on 400 batch: 0.217465
Train loss on 450 batch: 0.219323
Train loss on 500 batch: 0.229576
Train loss on 550 batch: 0.251942
Train loss on 600 batch: 0.215616
Train loss on 650 batch: 0.196108
Train loss on 700 batch: 0.234248
Train loss on 750 batch: 0.221517
Train loss on 800 batch: 0.231264
Train loss on 850 batch: 0.215194
Train loss on 900 batch: 0.204002
Train loss on 950 batch: 0.264299
Train loss on 1000 batch: 0.169588
Train loss on 1050 batch: 0.214897
Train loss on 1100 batch: 0.254387
Train loss on 1150 batch: 0.218511
Train loss on 1200 batch: 0.186245
Train loss on 1250 batch: 0.279567
Train loss on 1300 batch: 0.241473
Train loss on 1350 batch: 0.232701
Train loss on 1400 batch: 0.221393
Train loss on 1450 batch: 0.193592
Train loss on 1500 batch: 0.252809
Train loss on 1550 batch: 0.232936
Train loss on 1600 batch: 0.231505
Train loss on 1650 batch: 0.270854
Train loss on 1700 batch: 0.246042
Train loss on 1750 batch: 0.229961
Train loss on 1800 batch: 0.204915
Train loss on 1850 batch: 0.231198
Train loss on 1900 batch: 0.230676
Train loss on 1950 batch: 0.253523
Train loss on 2000 batch: 0.224761
Train loss on 2050 batch: 0.223849
Train loss on 2100 batch: 0.312172
Train loss on 2150 batch: 0.198049
: Epoch: 198 | Training Loss: 0.224004 | Val. Loss: 0.385980 | Val. Kappa Score: 0.7265 | LR: 0.000737 | Estimated time: 555.36
Train loss on 50 batch: 0.190282
Train loss on 100 batch: 0.240136
Train loss on 150 batch: 0.194770
Train loss on 200 batch: 0.213811
Train loss on 250 batch: 0.241997
Train loss on 300 batch: 0.187912
Train loss on 350 batch: 0.226305
Train loss on 400 batch: 0.198787
Train loss on 450 batch: 0.248422
Train loss on 500 batch: 0.201319
Train loss on 550 batch: 0.212790
Train loss on 600 batch: 0.218485
Train loss on 650 batch: 0.219311
Train loss on 700 batch: 0.232037
Train loss on 750 batch: 0.219362
Train loss on 800 batch: 0.224472
Train loss on 850 batch: 0.272135
Train loss on 900 batch: 0.206117
Train loss on 950 batch: 0.211986
Train loss on 1000 batch: 0.204279
Train loss on 1050 batch: 0.235467
Train loss on 1100 batch: 0.227121
Train loss on 1150 batch: 0.207574
Train loss on 1200 batch: 0.197925
Train loss on 1250 batch: 0.265394
Train loss on 1300 batch: 0.211625
Train loss on 1350 batch: 0.210463
Train loss on 1400 batch: 0.208643
Train loss on 1450 batch: 0.248311
Train loss on 1500 batch: 0.253058
Train loss on 1550 batch: 0.233567
Train loss on 1600 batch: 0.172476
Train loss on 1650 batch: 0.214868
Train loss on 1700 batch: 0.229397
Train loss on 1750 batch: 0.207604
Train loss on 1800 batch: 0.233948
Train loss on 1850 batch: 0.198156
Train loss on 1900 batch: 0.221848
Train loss on 1950 batch: 0.215847
Train loss on 2000 batch: 0.238633
Train loss on 2050 batch: 0.222492
Train loss on 2100 batch: 0.227781
Train loss on 2150 batch: 0.223140
: Epoch: 199 | Training Loss: 0.220824 | Val. Loss: 0.368863 | Val. Kappa Score: 0.7265 | LR: 0.000775 | Estimated time: 555.22
Train loss on 50 batch: 0.203393
Train loss on 100 batch: 0.191917
Train loss on 150 batch: 0.212310
Train loss on 200 batch: 0.175542
Train loss on 250 batch: 0.209051
Train loss on 300 batch: 0.246664
Train loss on 350 batch: 0.164701
Train loss on 400 batch: 0.264713
Train loss on 450 batch: 0.210157
Train loss on 500 batch: 0.234575
Train loss on 550 batch: 0.177013
Train loss on 600 batch: 0.213743
Train loss on 650 batch: 0.235971
Train loss on 700 batch: 0.232297
Train loss on 750 batch: 0.255105
Train loss on 800 batch: 0.199373
Train loss on 850 batch: 0.278721
Train loss on 900 batch: 0.231551
Train loss on 950 batch: 0.208788
Train loss on 1000 batch: 0.206330
Train loss on 1050 batch: 0.254882
Train loss on 1100 batch: 0.255086
Train loss on 1150 batch: 0.176173
Train loss on 1200 batch: 0.203752
Train loss on 1250 batch: 0.200241
Train loss on 1300 batch: 0.244488
Train loss on 1350 batch: 0.237658
Train loss on 1400 batch: 0.222749
Train loss on 1450 batch: 0.217773
Train loss on 1500 batch: 0.245871
Train loss on 1550 batch: 0.219455
Train loss on 1600 batch: 0.208820
Train loss on 1650 batch: 0.240035
Train loss on 1700 batch: 0.219510
Train loss on 1750 batch: 0.239583
Train loss on 1800 batch: 0.201058
Train loss on 1850 batch: 0.223388
Train loss on 1900 batch: 0.249988
Train loss on 1950 batch: 0.238041
Train loss on 2000 batch: 0.223772
Train loss on 2050 batch: 0.243070
Train loss on 2100 batch: 0.282252
Train loss on 2150 batch: 0.231762
: Epoch: 200 | Training Loss: 0.224304 | Val. Loss: 0.376411 | Val. Kappa Score: 0.7265 | LR: 0.000812 | Estimated time: 555.45
Train loss on 50 batch: 0.206135
Train loss on 100 batch: 0.231915
Train loss on 150 batch: 0.208849
Train loss on 200 batch: 0.270172
Train loss on 250 batch: 0.229015
Train loss on 300 batch: 0.245418
Train loss on 350 batch: 0.228148
Train loss on 400 batch: 0.198183
Train loss on 450 batch: 0.230956
Train loss on 500 batch: 0.244612
Train loss on 550 batch: 0.223709
Train loss on 600 batch: 0.296171
Train loss on 650 batch: 0.217713
Train loss on 700 batch: 0.187634
Train loss on 750 batch: 0.220091
Train loss on 800 batch: 0.238664
Train loss on 850 batch: 0.225218
Train loss on 900 batch: 0.239716
Train loss on 950 batch: 0.209243
Train loss on 1000 batch: 0.191276
Train loss on 1050 batch: 0.205299
Train loss on 1100 batch: 0.212520
Train loss on 1150 batch: 0.219825
Train loss on 1200 batch: 0.236277
Train loss on 1250 batch: 0.230020
Train loss on 1300 batch: 0.205326
Train loss on 1350 batch: 0.251712
Train loss on 1400 batch: 0.247178
Train loss on 1450 batch: 0.201637
Train loss on 1500 batch: 0.240448
Train loss on 1550 batch: 0.208021
Train loss on 1600 batch: 0.264382
Train loss on 1650 batch: 0.272142
Train loss on 1700 batch: 0.230714
Train loss on 1750 batch: 0.248207
Train loss on 1800 batch: 0.265963
Train loss on 1850 batch: 0.229183
Train loss on 1900 batch: 0.242115
Train loss on 1950 batch: 0.234439
Train loss on 2000 batch: 0.250494
Train loss on 2050 batch: 0.244648
Train loss on 2100 batch: 0.228720
Train loss on 2150 batch: 0.239305
: Epoch: 201 | Training Loss: 0.232541 | Val. Loss: 0.365410 | Val. Kappa Score: 0.7265 | LR: 0.000846 | Estimated time: 555.12
Train loss on 50 batch: 0.224574
Train loss on 100 batch: 0.208530
Train loss on 150 batch: 0.226465
Train loss on 200 batch: 0.216678
Train loss on 250 batch: 0.228123
Train loss on 300 batch: 0.257541
Train loss on 350 batch: 0.207304
Train loss on 400 batch: 0.164281
Train loss on 450 batch: 0.227234
Train loss on 500 batch: 0.218768
Train loss on 550 batch: 0.175329
Train loss on 600 batch: 0.305118
Train loss on 650 batch: 0.217021
Train loss on 700 batch: 0.230544
Train loss on 750 batch: 0.256793
Train loss on 800 batch: 0.250547
Train loss on 850 batch: 0.280553
Train loss on 900 batch: 0.236941
Train loss on 950 batch: 0.232235
Train loss on 1000 batch: 0.217868
Train loss on 1050 batch: 0.284242
Train loss on 1100 batch: 0.262194
Train loss on 1150 batch: 0.254694
Train loss on 1200 batch: 0.255418
Train loss on 1250 batch: 0.317291
Train loss on 1300 batch: 0.263293
Train loss on 1350 batch: 0.255301
Train loss on 1400 batch: 0.192780
Train loss on 1450 batch: 0.281887
Train loss on 1500 batch: 0.220350
Train loss on 1550 batch: 0.196592
Train loss on 1600 batch: 0.217096
Train loss on 1650 batch: 0.206766
Train loss on 1700 batch: 0.239536
Train loss on 1750 batch: 0.231327
Train loss on 1800 batch: 0.232531
Train loss on 1850 batch: 0.255706
Train loss on 1900 batch: 0.233504
Train loss on 1950 batch: 0.251425
Train loss on 2000 batch: 0.251660
Train loss on 2050 batch: 0.237364
Train loss on 2100 batch: 0.208197
Train loss on 2150 batch: 0.236655
: Epoch: 202 | Training Loss: 0.237903 | Val. Loss: 0.394717 | Val. Kappa Score: 0.7266 | LR: 0.000877 | Estimated time: 555.05
Train loss on 50 batch: 0.218758
Train loss on 100 batch: 0.203125
Train loss on 150 batch: 0.222630
Train loss on 200 batch: 0.187864
Train loss on 250 batch: 0.208241
Train loss on 300 batch: 0.205313
Train loss on 350 batch: 0.205917
Train loss on 400 batch: 0.231707
Train loss on 450 batch: 0.219065
Train loss on 500 batch: 0.261942
Train loss on 550 batch: 0.211419
Train loss on 600 batch: 0.227395
Train loss on 650 batch: 0.190329
Train loss on 700 batch: 0.203817
Train loss on 750 batch: 0.254954
Train loss on 800 batch: 0.242344
Train loss on 850 batch: 0.228998
Train loss on 900 batch: 0.247972
Train loss on 950 batch: 0.263661
Train loss on 1000 batch: 0.272712
Train loss on 1050 batch: 0.238146
Train loss on 1100 batch: 0.241805
Train loss on 1150 batch: 0.271278
Train loss on 1200 batch: 0.248975
Train loss on 1250 batch: 0.245577
Train loss on 1300 batch: 0.278373
Train loss on 1350 batch: 0.283871
Train loss on 1400 batch: 0.281179
Train loss on 1450 batch: 0.259647
Train loss on 1500 batch: 0.260879
Train loss on 1550 batch: 0.235202
Train loss on 1600 batch: 0.247050
Train loss on 1650 batch: 0.274266
Train loss on 1700 batch: 0.245179
Train loss on 1750 batch: 0.252604
Train loss on 1800 batch: 0.235233
Train loss on 1850 batch: 0.210542
Train loss on 1900 batch: 0.259641
Train loss on 1950 batch: 0.256408
Train loss on 2000 batch: 0.262856
Train loss on 2050 batch: 0.233789
Train loss on 2100 batch: 0.261655
Train loss on 2150 batch: 0.231807
: Epoch: 203 | Training Loss: 0.240068 | Val. Loss: 0.383564 | Val. Kappa Score: 0.7266 | LR: 0.000905 | Estimated time: 554.99
Train loss on 50 batch: 0.223970
Train loss on 100 batch: 0.242044
Train loss on 150 batch: 0.214108
Train loss on 200 batch: 0.221096
Train loss on 250 batch: 0.269496
Train loss on 300 batch: 0.211287
Train loss on 350 batch: 0.232930
Train loss on 400 batch: 0.203875
Train loss on 450 batch: 0.234684
Train loss on 500 batch: 0.220083
Train loss on 550 batch: 0.201916
Train loss on 600 batch: 0.173913
Train loss on 650 batch: 0.260065
Train loss on 700 batch: 0.194821
Train loss on 750 batch: 0.266969
Train loss on 800 batch: 0.232876
Train loss on 850 batch: 0.247029
Train loss on 900 batch: 0.288975
Train loss on 950 batch: 0.279159
Train loss on 1000 batch: 0.205675
Train loss on 1050 batch: 0.266027
Train loss on 1100 batch: 0.194980
Train loss on 1150 batch: 0.231126
Train loss on 1200 batch: 0.214706
Train loss on 1250 batch: 0.295387
Train loss on 1300 batch: 0.251070
Train loss on 1350 batch: 0.258153
Train loss on 1400 batch: 0.215381
Train loss on 1450 batch: 0.278601
Train loss on 1500 batch: 0.228471
Train loss on 1550 batch: 0.242544
Train loss on 1600 batch: 0.275512
Train loss on 1650 batch: 0.225926
Train loss on 1700 batch: 0.254850
Train loss on 1750 batch: 0.208388
Train loss on 1800 batch: 0.256649
Train loss on 1850 batch: 0.226414
Train loss on 1900 batch: 0.247112
Train loss on 1950 batch: 0.224630
Train loss on 2000 batch: 0.258192
Train loss on 2050 batch: 0.246499
Train loss on 2100 batch: 0.269037
Train loss on 2150 batch: 0.261983
: Epoch: 204 | Training Loss: 0.240961 | Val. Loss: 0.341167 | Val. Kappa Score: 0.7267 | LR: 0.000929 | Estimated time: 555.11
Train loss on 50 batch: 0.229850
Train loss on 100 batch: 0.210865
Train loss on 150 batch: 0.248198
Train loss on 200 batch: 0.188954
Train loss on 250 batch: 0.252181
Train loss on 300 batch: 0.184526
Train loss on 350 batch: 0.243216
Train loss on 400 batch: 0.250479
Train loss on 450 batch: 0.225960
Train loss on 500 batch: 0.261597
Train loss on 550 batch: 0.266281
Train loss on 600 batch: 0.269661
Train loss on 650 batch: 0.224440
Train loss on 700 batch: 0.274472
Train loss on 750 batch: 0.194610
Train loss on 800 batch: 0.223378
Train loss on 850 batch: 0.239055
Train loss on 900 batch: 0.208858
Train loss on 950 batch: 0.253356
Train loss on 1000 batch: 0.306016
Train loss on 1050 batch: 0.309367
Train loss on 1100 batch: 0.293067
Train loss on 1150 batch: 0.280250
Train loss on 1200 batch: 0.271381
Train loss on 1250 batch: 0.248297
Train loss on 1300 batch: 0.263898
Train loss on 1350 batch: 0.278824
Train loss on 1400 batch: 0.273814
Train loss on 1450 batch: 0.240738
Train loss on 1500 batch: 0.272163
Train loss on 1550 batch: 0.226303
Train loss on 1600 batch: 0.238518
Train loss on 1650 batch: 0.324994
Train loss on 1700 batch: 0.266725
Train loss on 1750 batch: 0.284714
Train loss on 1800 batch: 0.229640
Train loss on 1850 batch: 0.257866
Train loss on 1900 batch: 0.264751
Train loss on 1950 batch: 0.215732
Train loss on 2000 batch: 0.210097
Train loss on 2050 batch: 0.328628
Train loss on 2100 batch: 0.226196
Train loss on 2150 batch: 0.237755
: Epoch: 205 | Training Loss: 0.250539 | Val. Loss: 0.367525 | Val. Kappa Score: 0.7267 | LR: 0.000950 | Estimated time: 555.21
Train loss on 50 batch: 0.242353
Train loss on 100 batch: 0.233880
Train loss on 150 batch: 0.267049
Train loss on 200 batch: 0.212595
Train loss on 250 batch: 0.268113
Train loss on 300 batch: 0.298809
Train loss on 350 batch: 0.254008
Train loss on 400 batch: 0.288954
Train loss on 450 batch: 0.230349
Train loss on 500 batch: 0.300477
Train loss on 550 batch: 0.263047
Train loss on 600 batch: 0.241711
Train loss on 650 batch: 0.239486
Train loss on 700 batch: 0.257608
Train loss on 750 batch: 0.260925
Train loss on 800 batch: 0.241504
Train loss on 850 batch: 0.211801
Train loss on 900 batch: 0.185043
Train loss on 950 batch: 0.210690
Train loss on 1000 batch: 0.269118
Train loss on 1050 batch: 0.280681
Train loss on 1100 batch: 0.255053
Train loss on 1150 batch: 0.276207
Train loss on 1200 batch: 0.288585
Train loss on 1250 batch: 0.240392
Train loss on 1300 batch: 0.261236
Train loss on 1350 batch: 0.262972
Train loss on 1400 batch: 0.250711
Train loss on 1450 batch: 0.263032
Train loss on 1500 batch: 0.263191
Train loss on 1550 batch: 0.259376
Train loss on 1600 batch: 0.266559
Train loss on 1650 batch: 0.261864
Train loss on 1700 batch: 0.306362
Train loss on 1750 batch: 0.250247
Train loss on 1800 batch: 0.270807
Train loss on 1850 batch: 0.249074
Train loss on 1900 batch: 0.243575
Train loss on 1950 batch: 0.258955
Train loss on 2000 batch: 0.342349
Train loss on 2050 batch: 0.233605
Train loss on 2100 batch: 0.292229
Train loss on 2150 batch: 0.240466
: Epoch: 206 | Training Loss: 0.257690 | Val. Loss: 0.368858 | Val. Kappa Score: 0.7267 | LR: 0.000968 | Estimated time: 555.08
Train loss on 50 batch: 0.282736
Train loss on 100 batch: 0.225324
Train loss on 150 batch: 0.268522
Train loss on 200 batch: 0.265874
Train loss on 250 batch: 0.236872
Train loss on 300 batch: 0.231753
Train loss on 350 batch: 0.206814
Train loss on 400 batch: 0.231560
Train loss on 450 batch: 0.260793
Train loss on 500 batch: 0.252852
Train loss on 550 batch: 0.237872
Train loss on 600 batch: 0.285684
Train loss on 650 batch: 0.265572
Train loss on 700 batch: 0.228436
Train loss on 750 batch: 0.233704
Train loss on 800 batch: 0.280502
Train loss on 850 batch: 0.222648
Train loss on 900 batch: 0.280746
Train loss on 950 batch: 0.233617
Train loss on 1000 batch: 0.216743
Train loss on 1050 batch: 0.243589
Train loss on 1100 batch: 0.256370
Train loss on 1150 batch: 0.257334
Train loss on 1200 batch: 0.280096
Train loss on 1250 batch: 0.219307
Train loss on 1300 batch: 0.251331
Train loss on 1350 batch: 0.231069
Train loss on 1400 batch: 0.234760
Train loss on 1450 batch: 0.302102
Train loss on 1500 batch: 0.279620
Train loss on 1550 batch: 0.281231
Train loss on 1600 batch: 0.261078
Train loss on 1650 batch: 0.243021
Train loss on 1700 batch: 0.275590
Train loss on 1750 batch: 0.248272
Train loss on 1800 batch: 0.243865
Train loss on 1850 batch: 0.228197
Train loss on 1900 batch: 0.217175
Train loss on 1950 batch: 0.240242
Train loss on 2000 batch: 0.288204
Train loss on 2050 batch: 0.283816
Train loss on 2100 batch: 0.254781
Train loss on 2150 batch: 0.227396
: Epoch: 207 | Training Loss: 0.250736 | Val. Loss: 0.375991 | Val. Kappa Score: 0.7266 | LR: 0.000982 | Estimated time: 555.12
Train loss on 50 batch: 0.247912
Train loss on 100 batch: 0.215189
Train loss on 150 batch: 0.265802
Train loss on 200 batch: 0.241008
Train loss on 250 batch: 0.240965
Train loss on 300 batch: 0.195359
Train loss on 350 batch: 0.235547
Train loss on 400 batch: 0.233588
Train loss on 450 batch: 0.242008
Train loss on 500 batch: 0.303612
Train loss on 550 batch: 0.291540
Train loss on 600 batch: 0.251388
Train loss on 650 batch: 0.264805
Train loss on 700 batch: 0.233535
Train loss on 750 batch: 0.268110
Train loss on 800 batch: 0.231010
Train loss on 850 batch: 0.270055
Train loss on 900 batch: 0.241269
Train loss on 950 batch: 0.263666
Train loss on 1000 batch: 0.281188
Train loss on 1050 batch: 0.243544
Train loss on 1100 batch: 0.244816
Train loss on 1150 batch: 0.288861
Train loss on 1200 batch: 0.227243
Train loss on 1250 batch: 0.259577
Train loss on 1300 batch: 0.276594
Train loss on 1350 batch: 0.242968
Train loss on 1400 batch: 0.233725
Train loss on 1450 batch: 0.282186
Train loss on 1500 batch: 0.306430
Train loss on 1550 batch: 0.223937
Train loss on 1600 batch: 0.224660
Train loss on 1650 batch: 0.279704
Train loss on 1700 batch: 0.280521
Train loss on 1750 batch: 0.264745
Train loss on 1800 batch: 0.276963
Train loss on 1850 batch: 0.287327
Train loss on 1900 batch: 0.234017
Train loss on 1950 batch: 0.300418
Train loss on 2000 batch: 0.208201
Train loss on 2050 batch: 0.269566
Train loss on 2100 batch: 0.269622
Train loss on 2150 batch: 0.245199
: Epoch: 208 | Training Loss: 0.255663 | Val. Loss: 0.359909 | Val. Kappa Score: 0.7265 | LR: 0.000992 | Estimated time: 554.94
Train loss on 50 batch: 0.225455
Train loss on 100 batch: 0.243603
Train loss on 150 batch: 0.190835
Train loss on 200 batch: 0.225483
Train loss on 250 batch: 0.236755
Train loss on 300 batch: 0.282417
Train loss on 350 batch: 0.313354
Train loss on 400 batch: 0.236079
Train loss on 450 batch: 0.244643
Train loss on 500 batch: 0.233416
Train loss on 550 batch: 0.254232
Train loss on 600 batch: 0.261913
Train loss on 650 batch: 0.278068
Train loss on 700 batch: 0.246676
Train loss on 750 batch: 0.263762
Train loss on 800 batch: 0.229315
Train loss on 850 batch: 0.281062
Train loss on 900 batch: 0.231160
Train loss on 950 batch: 0.282521
Train loss on 1000 batch: 0.266594
Train loss on 1050 batch: 0.193901
Train loss on 1100 batch: 0.259193
Train loss on 1150 batch: 0.229200
Train loss on 1200 batch: 0.290289
Train loss on 1250 batch: 0.265273
Train loss on 1300 batch: 0.253639
Train loss on 1350 batch: 0.270126
Train loss on 1400 batch: 0.282628
Train loss on 1450 batch: 0.237175
Train loss on 1500 batch: 0.247695
Train loss on 1550 batch: 0.270540
Train loss on 1600 batch: 0.214922
Train loss on 1650 batch: 0.239720
Train loss on 1700 batch: 0.224064
Train loss on 1750 batch: 0.297525
Train loss on 1800 batch: 0.246426
Train loss on 1850 batch: 0.254062
Train loss on 1900 batch: 0.231756
Train loss on 1950 batch: 0.280888
Train loss on 2000 batch: 0.272336
Train loss on 2050 batch: 0.248769
Train loss on 2100 batch: 0.256790
Train loss on 2150 batch: 0.229576
: Epoch: 209 | Training Loss: 0.251227 | Val. Loss: 0.360347 | Val. Kappa Score: 0.7266 | LR: 0.000998 | Estimated time: 555.09
Train loss on 50 batch: 0.263047
Train loss on 100 batch: 0.225638
Train loss on 150 batch: 0.256031
Train loss on 200 batch: 0.244075
Train loss on 250 batch: 0.274494
Train loss on 300 batch: 0.253968
Train loss on 350 batch: 0.259880
Train loss on 400 batch: 0.211515
Train loss on 450 batch: 0.237241
Train loss on 500 batch: 0.273157
Train loss on 550 batch: 0.219540
Train loss on 600 batch: 0.252336
Train loss on 650 batch: 0.222716
Train loss on 700 batch: 0.272381
Train loss on 750 batch: 0.274429
Train loss on 800 batch: 0.269526
Train loss on 850 batch: 0.280855
Train loss on 900 batch: 0.372379
Train loss on 950 batch: 0.215826
Train loss on 1000 batch: 0.229313
Train loss on 1050 batch: 0.236945
Train loss on 1100 batch: 0.252728
Train loss on 1150 batch: 0.275608
Train loss on 1200 batch: 0.253959
Train loss on 1250 batch: 0.257394
Train loss on 1300 batch: 0.213258
Train loss on 1350 batch: 0.209611
Train loss on 1400 batch: 0.240793
Train loss on 1450 batch: 0.282208
Train loss on 1500 batch: 0.241291
Train loss on 1550 batch: 0.243889
Train loss on 1600 batch: 0.295074
Train loss on 1650 batch: 0.275247
Train loss on 1700 batch: 0.243383
Train loss on 1750 batch: 0.307869
Train loss on 1800 batch: 0.247545
Train loss on 1850 batch: 0.284394
Train loss on 1900 batch: 0.313623
Train loss on 1950 batch: 0.229467
Train loss on 2000 batch: 0.277074
Train loss on 2050 batch: 0.280452
Train loss on 2100 batch: 0.272427
Train loss on 2150 batch: 0.256840
: Epoch: 210 | Training Loss: 0.259128 | Val. Loss: 0.385768 | Val. Kappa Score: 0.7266 | LR: 0.001000 | Estimated time: 555.51
Train loss on 50 batch: 0.251731
Train loss on 100 batch: 0.247409
Train loss on 150 batch: 0.247294
Train loss on 200 batch: 0.243785
Train loss on 250 batch: 0.254642
Train loss on 300 batch: 0.224021
Train loss on 350 batch: 0.280847
Train loss on 400 batch: 0.255291
Train loss on 450 batch: 0.225769
Train loss on 500 batch: 0.247087
Train loss on 550 batch: 0.228698
Train loss on 600 batch: 0.287106
Train loss on 650 batch: 0.244301
Train loss on 700 batch: 0.317633
Train loss on 750 batch: 0.209623
Train loss on 800 batch: 0.262697
Train loss on 850 batch: 0.217891
Train loss on 900 batch: 0.294574
Train loss on 950 batch: 0.231843
Train loss on 1000 batch: 0.240333
Train loss on 1050 batch: 0.275730
Train loss on 1100 batch: 0.258283
Train loss on 1150 batch: 0.277987
Train loss on 1200 batch: 0.246250
Train loss on 1250 batch: 0.240357
Train loss on 1300 batch: 0.294164
Train loss on 1350 batch: 0.282855
Train loss on 1400 batch: 0.228470
Train loss on 1450 batch: 0.256227
Train loss on 1500 batch: 0.252688
Train loss on 1550 batch: 0.271173
Train loss on 1600 batch: 0.270904
Train loss on 1650 batch: 0.240005
Train loss on 1700 batch: 0.247311
Train loss on 1750 batch: 0.266811
Train loss on 1800 batch: 0.240996
Train loss on 1850 batch: 0.251319
Train loss on 1900 batch: 0.292191
Train loss on 1950 batch: 0.234298
Train loss on 2000 batch: 0.184358
Train loss on 2050 batch: 0.234626
Train loss on 2100 batch: 0.285142
Train loss on 2150 batch: 0.274002
: Epoch: 211 | Training Loss: 0.253383 | Val. Loss: 0.395144 | Val. Kappa Score: 0.7266 | LR: 0.000998 | Estimated time: 555.29
Train loss on 50 batch: 0.232421
Train loss on 100 batch: 0.223214
Train loss on 150 batch: 0.258287
Train loss on 200 batch: 0.270476
Train loss on 250 batch: 0.310984
Train loss on 300 batch: 0.267686
Train loss on 350 batch: 0.308130
Train loss on 400 batch: 0.242917
Train loss on 450 batch: 0.268038
Train loss on 500 batch: 0.247076
Train loss on 550 batch: 0.272087
Train loss on 600 batch: 0.241893
Train loss on 650 batch: 0.253463
Train loss on 700 batch: 0.212958
Train loss on 750 batch: 0.224943
Train loss on 800 batch: 0.233875
Train loss on 850 batch: 0.273313
Train loss on 900 batch: 0.217096
Train loss on 950 batch: 0.213925
Train loss on 1000 batch: 0.232897
Train loss on 1050 batch: 0.234822
Train loss on 1100 batch: 0.266939
Train loss on 1150 batch: 0.291839
Train loss on 1200 batch: 0.250724
Train loss on 1250 batch: 0.218121
Train loss on 1300 batch: 0.246367
Train loss on 1350 batch: 0.238120
Train loss on 1400 batch: 0.232669
Train loss on 1450 batch: 0.322042
Train loss on 1500 batch: 0.286213
Train loss on 1550 batch: 0.261623
Train loss on 1600 batch: 0.264502
Train loss on 1650 batch: 0.301376
Train loss on 1700 batch: 0.210491
Train loss on 1750 batch: 0.223185
Train loss on 1800 batch: 0.242386
Train loss on 1850 batch: 0.270186
Train loss on 1900 batch: 0.222376
Train loss on 1950 batch: 0.200379
Train loss on 2000 batch: 0.299332
Train loss on 2050 batch: 0.261492
Train loss on 2100 batch: 0.241999
Train loss on 2150 batch: 0.260932
: Epoch: 212 | Training Loss: 0.251856 | Val. Loss: 0.368580 | Val. Kappa Score: 0.7266 | LR: 0.000992 | Estimated time: 554.81
Train loss on 50 batch: 0.220199
Train loss on 100 batch: 0.233450
Train loss on 150 batch: 0.231217
Train loss on 200 batch: 0.252032
Train loss on 250 batch: 0.236180
Train loss on 300 batch: 0.222424
Train loss on 350 batch: 0.264341
Train loss on 400 batch: 0.258180
Train loss on 450 batch: 0.256078
Train loss on 500 batch: 0.250986
Train loss on 550 batch: 0.259778
Train loss on 600 batch: 0.253023
Train loss on 650 batch: 0.263277
Train loss on 700 batch: 0.236990
Train loss on 750 batch: 0.281241
Train loss on 800 batch: 0.289000
Train loss on 850 batch: 0.330601
Train loss on 900 batch: 0.243250
Train loss on 950 batch: 0.238495
Train loss on 1000 batch: 0.226635
Train loss on 1050 batch: 0.283599
Train loss on 1100 batch: 0.261368
Train loss on 1150 batch: 0.264761
Train loss on 1200 batch: 0.277766
Train loss on 1250 batch: 0.211774
Train loss on 1300 batch: 0.271452
Train loss on 1350 batch: 0.254992
Train loss on 1400 batch: 0.256445
Train loss on 1450 batch: 0.264123
Train loss on 1500 batch: 0.238909
Train loss on 1550 batch: 0.272210
Train loss on 1600 batch: 0.248945
Train loss on 1650 batch: 0.185025
Train loss on 1700 batch: 0.266454
Train loss on 1750 batch: 0.294156
Train loss on 1800 batch: 0.267019
Train loss on 1850 batch: 0.272491
Train loss on 1900 batch: 0.321275
Train loss on 1950 batch: 0.271276
Train loss on 2000 batch: 0.301602
Train loss on 2050 batch: 0.201223
Train loss on 2100 batch: 0.224620
Train loss on 2150 batch: 0.250119
: Epoch: 213 | Training Loss: 0.255389 | Val. Loss: 0.344816 | Val. Kappa Score: 0.7267 | LR: 0.000982 | Estimated time: 555.12
Train loss on 50 batch: 0.283030
Train loss on 100 batch: 0.269272
Train loss on 150 batch: 0.279884
Train loss on 200 batch: 0.249492
Train loss on 250 batch: 0.188222
Train loss on 300 batch: 0.238523
Train loss on 350 batch: 0.246952
Train loss on 400 batch: 0.261922
Train loss on 450 batch: 0.248906
Train loss on 500 batch: 0.247982
Train loss on 550 batch: 0.265888
Train loss on 600 batch: 0.247943
Train loss on 650 batch: 0.260148
Train loss on 700 batch: 0.239982
Train loss on 750 batch: 0.267909
Train loss on 800 batch: 0.285042
Train loss on 850 batch: 0.285108
Train loss on 900 batch: 0.239113
Train loss on 950 batch: 0.231893
Train loss on 1000 batch: 0.226822
Train loss on 1050 batch: 0.251633
Train loss on 1100 batch: 0.249093
Train loss on 1150 batch: 0.287151
Train loss on 1200 batch: 0.249586
Train loss on 1250 batch: 0.247360
Train loss on 1300 batch: 0.252055
Train loss on 1350 batch: 0.251986
Train loss on 1400 batch: 0.218831
Train loss on 1450 batch: 0.295950
Train loss on 1500 batch: 0.254945
Train loss on 1550 batch: 0.269294
Train loss on 1600 batch: 0.265511
Train loss on 1650 batch: 0.274247
Train loss on 1700 batch: 0.235416
Train loss on 1750 batch: 0.244131
Train loss on 1800 batch: 0.246478
Train loss on 1850 batch: 0.235127
Train loss on 1900 batch: 0.273040
Train loss on 1950 batch: 0.240445
Train loss on 2000 batch: 0.260420
Train loss on 2050 batch: 0.254301
Train loss on 2100 batch: 0.207972
Train loss on 2150 batch: 0.252041
: Epoch: 214 | Training Loss: 0.253219 | Val. Loss: 0.375598 | Val. Kappa Score: 0.7267 | LR: 0.000968 | Estimated time: 555.03
Train loss on 50 batch: 0.263801
Train loss on 100 batch: 0.175263
Train loss on 150 batch: 0.270254
Train loss on 200 batch: 0.211092
Train loss on 250 batch: 0.232890
Train loss on 300 batch: 0.222496
Train loss on 350 batch: 0.235961
Train loss on 400 batch: 0.250630
Train loss on 450 batch: 0.235804
Train loss on 500 batch: 0.275919
Train loss on 550 batch: 0.235350
Train loss on 600 batch: 0.269375
Train loss on 650 batch: 0.248199
Train loss on 700 batch: 0.241758
Train loss on 750 batch: 0.239999
Train loss on 800 batch: 0.228025
Train loss on 850 batch: 0.289063
Train loss on 900 batch: 0.272192
Train loss on 950 batch: 0.287215
Train loss on 1000 batch: 0.264128
Train loss on 1050 batch: 0.239094
Train loss on 1100 batch: 0.253294
Train loss on 1150 batch: 0.234131
Train loss on 1200 batch: 0.233792
Train loss on 1250 batch: 0.266615
Train loss on 1300 batch: 0.302992
Train loss on 1350 batch: 0.219651
Train loss on 1400 batch: 0.282330
Train loss on 1450 batch: 0.247609
Train loss on 1500 batch: 0.315753
Train loss on 1550 batch: 0.248365
Train loss on 1600 batch: 0.224982
Train loss on 1650 batch: 0.258462
Train loss on 1700 batch: 0.280176
Train loss on 1750 batch: 0.265545
Train loss on 1800 batch: 0.241386
Train loss on 1850 batch: 0.203013
Train loss on 1900 batch: 0.226187
Train loss on 1950 batch: 0.252267
Train loss on 2000 batch: 0.246122
Train loss on 2050 batch: 0.251281
Train loss on 2100 batch: 0.234329
Train loss on 2150 batch: 0.254427
: Epoch: 215 | Training Loss: 0.249748 | Val. Loss: 0.341745 | Val. Kappa Score: 0.7268 | LR: 0.000950 | Estimated time: 555.17
Train loss on 50 batch: 0.293656
Train loss on 100 batch: 0.214944
Train loss on 150 batch: 0.213692
Train loss on 200 batch: 0.247385
Train loss on 250 batch: 0.228821
Train loss on 300 batch: 0.244296
Train loss on 350 batch: 0.211388
Train loss on 400 batch: 0.267537
Train loss on 450 batch: 0.256191
Train loss on 500 batch: 0.269459
Train loss on 550 batch: 0.259337
Train loss on 600 batch: 0.251393
Train loss on 650 batch: 0.216013
Train loss on 700 batch: 0.222815
Train loss on 750 batch: 0.223685
Train loss on 800 batch: 0.287785
Train loss on 850 batch: 0.240237
Train loss on 900 batch: 0.206880
Train loss on 950 batch: 0.241009
Train loss on 1000 batch: 0.204650
Train loss on 1050 batch: 0.267421
Train loss on 1100 batch: 0.229869
Train loss on 1150 batch: 0.238390
Train loss on 1200 batch: 0.270216
Train loss on 1250 batch: 0.260940
Train loss on 1300 batch: 0.250632
Train loss on 1350 batch: 0.225862
Train loss on 1400 batch: 0.278975
Train loss on 1450 batch: 0.272696
Train loss on 1500 batch: 0.185489
Train loss on 1550 batch: 0.235480
Train loss on 1600 batch: 0.277270
Train loss on 1650 batch: 0.242657
Train loss on 1700 batch: 0.264061
Train loss on 1750 batch: 0.207454
Train loss on 1800 batch: 0.245236
Train loss on 1850 batch: 0.229867
Train loss on 1900 batch: 0.269513
Train loss on 1950 batch: 0.264908
Train loss on 2000 batch: 0.261190
Train loss on 2050 batch: 0.269220
Train loss on 2100 batch: 0.245613
Train loss on 2150 batch: 0.267173
: Epoch: 216 | Training Loss: 0.244521 | Val. Loss: 0.348432 | Val. Kappa Score: 0.7268 | LR: 0.000929 | Estimated time: 554.79
Train loss on 50 batch: 0.229051
Train loss on 100 batch: 0.238977
Train loss on 150 batch: 0.249210
Train loss on 200 batch: 0.251930
Train loss on 250 batch: 0.230308
Train loss on 300 batch: 0.234504
Train loss on 350 batch: 0.288415
Train loss on 400 batch: 0.251781
Train loss on 450 batch: 0.247244
Train loss on 500 batch: 0.252144
Train loss on 550 batch: 0.200212
Train loss on 600 batch: 0.238855
Train loss on 650 batch: 0.271609
Train loss on 700 batch: 0.217132
Train loss on 750 batch: 0.249106
Train loss on 800 batch: 0.323743
Train loss on 850 batch: 0.238373
Train loss on 900 batch: 0.212207
Train loss on 950 batch: 0.252654
Train loss on 1000 batch: 0.263750
Train loss on 1050 batch: 0.230934
Train loss on 1100 batch: 0.191803
Train loss on 1150 batch: 0.233525
Train loss on 1200 batch: 0.236290
Train loss on 1250 batch: 0.233319
Train loss on 1300 batch: 0.267958
Train loss on 1350 batch: 0.221791
Train loss on 1400 batch: 0.269637
Train loss on 1450 batch: 0.257646
Train loss on 1500 batch: 0.248758
Train loss on 1550 batch: 0.229475
Train loss on 1600 batch: 0.212629
Train loss on 1650 batch: 0.227560
Train loss on 1700 batch: 0.255089
Train loss on 1750 batch: 0.232545
Train loss on 1800 batch: 0.260639
Train loss on 1850 batch: 0.232297
Train loss on 1900 batch: 0.227475
Train loss on 1950 batch: 0.286534
Train loss on 2000 batch: 0.224526
Train loss on 2050 batch: 0.255036
Train loss on 2100 batch: 0.240069
Train loss on 2150 batch: 0.236275
: Epoch: 217 | Training Loss: 0.243172 | Val. Loss: 0.353685 | Val. Kappa Score: 0.7269 | LR: 0.000905 | Estimated time: 555.14
Train loss on 50 batch: 0.243364
Train loss on 100 batch: 0.236367
Train loss on 150 batch: 0.206963
Train loss on 200 batch: 0.256278
Train loss on 250 batch: 0.241500
Train loss on 300 batch: 0.264564
Train loss on 350 batch: 0.236128
Train loss on 400 batch: 0.205593
Train loss on 450 batch: 0.276004
Train loss on 500 batch: 0.249301
Train loss on 550 batch: 0.282643
Train loss on 600 batch: 0.257331
Train loss on 650 batch: 0.211519
Train loss on 700 batch: 0.220640
Train loss on 750 batch: 0.223843
Train loss on 800 batch: 0.277904
Train loss on 850 batch: 0.269085
Train loss on 900 batch: 0.251690
Train loss on 950 batch: 0.225870
Train loss on 1000 batch: 0.267257
Train loss on 1050 batch: 0.292318
Train loss on 1100 batch: 0.225896
Train loss on 1150 batch: 0.232461
Train loss on 1200 batch: 0.249109
Train loss on 1250 batch: 0.234674
Train loss on 1300 batch: 0.294531
Train loss on 1350 batch: 0.203964
Train loss on 1400 batch: 0.274788
Train loss on 1450 batch: 0.211919
Train loss on 1500 batch: 0.245026
Train loss on 1550 batch: 0.252404
Train loss on 1600 batch: 0.238911
Train loss on 1650 batch: 0.261480
Train loss on 1700 batch: 0.200450
Train loss on 1750 batch: 0.259230
Train loss on 1800 batch: 0.218844
Train loss on 1850 batch: 0.210670
Train loss on 1900 batch: 0.247791
Train loss on 1950 batch: 0.252321
Train loss on 2000 batch: 0.269003
Train loss on 2050 batch: 0.257548
Train loss on 2100 batch: 0.267090
Train loss on 2150 batch: 0.271996
: Epoch: 218 | Training Loss: 0.245100 | Val. Loss: 0.358805 | Val. Kappa Score: 0.7268 | LR: 0.000877 | Estimated time: 554.95
Train loss on 50 batch: 0.241773
Train loss on 100 batch: 0.204564
Train loss on 150 batch: 0.202757
Train loss on 200 batch: 0.237709
Train loss on 250 batch: 0.251074
Train loss on 300 batch: 0.230538
Train loss on 350 batch: 0.294373
Train loss on 400 batch: 0.232637
Train loss on 450 batch: 0.216074
Train loss on 500 batch: 0.227676
Train loss on 550 batch: 0.255198
Train loss on 600 batch: 0.245095
Train loss on 650 batch: 0.261673
Train loss on 700 batch: 0.272917
Train loss on 750 batch: 0.256959
Train loss on 800 batch: 0.255213
Train loss on 850 batch: 0.233451
Train loss on 900 batch: 0.162282
Train loss on 950 batch: 0.215033
Train loss on 1000 batch: 0.237736
Train loss on 1050 batch: 0.227703
Train loss on 1100 batch: 0.238039
Train loss on 1150 batch: 0.243644
Train loss on 1200 batch: 0.223825
Train loss on 1250 batch: 0.200947
Train loss on 1300 batch: 0.232882
Train loss on 1350 batch: 0.247011
Train loss on 1400 batch: 0.217960
Train loss on 1450 batch: 0.213980
Train loss on 1500 batch: 0.260294
Train loss on 1550 batch: 0.314763
Train loss on 1600 batch: 0.214891
Train loss on 1650 batch: 0.213111
Train loss on 1700 batch: 0.252288
Train loss on 1750 batch: 0.236621
Train loss on 1800 batch: 0.243162
Train loss on 1850 batch: 0.219036
Train loss on 1900 batch: 0.203715
Train loss on 1950 batch: 0.259393
Train loss on 2000 batch: 0.252162
Train loss on 2050 batch: 0.287797
Train loss on 2100 batch: 0.284495
Train loss on 2150 batch: 0.208047
: Epoch: 219 | Training Loss: 0.238575 | Val. Loss: 0.365366 | Val. Kappa Score: 0.7267 | LR: 0.000846 | Estimated time: 555.15
Train loss on 50 batch: 0.223899
Train loss on 100 batch: 0.210419
Train loss on 150 batch: 0.237913
Train loss on 200 batch: 0.246679
Train loss on 250 batch: 0.257985
Train loss on 300 batch: 0.229505
Train loss on 350 batch: 0.241773
Train loss on 400 batch: 0.229673
Train loss on 450 batch: 0.245638
Train loss on 500 batch: 0.198874
Train loss on 550 batch: 0.258465
Train loss on 600 batch: 0.216232
Train loss on 650 batch: 0.231725
Train loss on 700 batch: 0.202224
Train loss on 750 batch: 0.227646
Train loss on 800 batch: 0.221974
Train loss on 850 batch: 0.221268
Train loss on 900 batch: 0.204743
Train loss on 950 batch: 0.234098
Train loss on 1000 batch: 0.234606
Train loss on 1050 batch: 0.210845
Train loss on 1100 batch: 0.201114
Train loss on 1150 batch: 0.226222
Train loss on 1200 batch: 0.267960
Train loss on 1250 batch: 0.210120
Train loss on 1300 batch: 0.256958
Train loss on 1350 batch: 0.232179
Train loss on 1400 batch: 0.217878
Train loss on 1450 batch: 0.204169
Train loss on 1500 batch: 0.265437
Train loss on 1550 batch: 0.246262
Train loss on 1600 batch: 0.254558
Train loss on 1650 batch: 0.212852
Train loss on 1700 batch: 0.240469
Train loss on 1750 batch: 0.251052
Train loss on 1800 batch: 0.245929
Train loss on 1850 batch: 0.203430
Train loss on 1900 batch: 0.224634
Train loss on 1950 batch: 0.230913
Train loss on 2000 batch: 0.267327
Train loss on 2050 batch: 0.262733
Train loss on 2100 batch: 0.235345
Train loss on 2150 batch: 0.300147
: Epoch: 220 | Training Loss: 0.233980 | Val. Loss: 0.430065 | Val. Kappa Score: 0.7265 | LR: 0.000812 | Estimated time: 555.37
Train loss on 50 batch: 0.238361
Train loss on 100 batch: 0.246863
Train loss on 150 batch: 0.221753
Train loss on 200 batch: 0.268296
Train loss on 250 batch: 0.256318
Train loss on 300 batch: 0.220568
Train loss on 350 batch: 0.288354
Train loss on 400 batch: 0.277395
Train loss on 450 batch: 0.175346
Train loss on 500 batch: 0.218987
Train loss on 550 batch: 0.235848
Train loss on 600 batch: 0.201289
Train loss on 650 batch: 0.228891
Train loss on 700 batch: 0.205042
Train loss on 750 batch: 0.226339
Train loss on 800 batch: 0.213856
Train loss on 850 batch: 0.238444
Train loss on 900 batch: 0.208637
Train loss on 950 batch: 0.221562
Train loss on 1000 batch: 0.221824
Train loss on 1050 batch: 0.199289
Train loss on 1100 batch: 0.212208
Train loss on 1150 batch: 0.274069
Train loss on 1200 batch: 0.219893
Train loss on 1250 batch: 0.250155
Train loss on 1300 batch: 0.200198
Train loss on 1350 batch: 0.230286
Train loss on 1400 batch: 0.222847
Train loss on 1450 batch: 0.253717
Train loss on 1500 batch: 0.225284
Train loss on 1550 batch: 0.252133
Train loss on 1600 batch: 0.197097
Train loss on 1650 batch: 0.237258
Train loss on 1700 batch: 0.224377
Train loss on 1750 batch: 0.202011
Train loss on 1800 batch: 0.231661
Train loss on 1850 batch: 0.211018
Train loss on 1900 batch: 0.216961
Train loss on 1950 batch: 0.221298
Train loss on 2000 batch: 0.261419
Train loss on 2050 batch: 0.244812
Train loss on 2100 batch: 0.216071
Train loss on 2150 batch: 0.214375
: Epoch: 221 | Training Loss: 0.227976 | Val. Loss: 0.352976 | Val. Kappa Score: 0.7266 | LR: 0.000775 | Estimated time: 555.14
Train loss on 50 batch: 0.234526
Train loss on 100 batch: 0.222619
Train loss on 150 batch: 0.214473
Train loss on 200 batch: 0.203850
Train loss on 250 batch: 0.186370
Train loss on 300 batch: 0.210339
Train loss on 350 batch: 0.191275
Train loss on 400 batch: 0.242541
Train loss on 450 batch: 0.238303
Train loss on 500 batch: 0.223188
Train loss on 550 batch: 0.252285
Train loss on 600 batch: 0.248032
Train loss on 650 batch: 0.219137
Train loss on 700 batch: 0.236419
Train loss on 750 batch: 0.254847
Train loss on 800 batch: 0.245162
Train loss on 850 batch: 0.230018
Train loss on 900 batch: 0.223714
Train loss on 950 batch: 0.222773
Train loss on 1000 batch: 0.215384
Train loss on 1050 batch: 0.209733
Train loss on 1100 batch: 0.234285
Train loss on 1150 batch: 0.201594
Train loss on 1200 batch: 0.246810
Train loss on 1250 batch: 0.211754
Train loss on 1300 batch: 0.252970
Train loss on 1350 batch: 0.215128
Train loss on 1400 batch: 0.222434
Train loss on 1450 batch: 0.266634
Train loss on 1500 batch: 0.241188
Train loss on 1550 batch: 0.201882
Train loss on 1600 batch: 0.183763
Train loss on 1650 batch: 0.218294
Train loss on 1700 batch: 0.240279
Train loss on 1750 batch: 0.233815
Train loss on 1800 batch: 0.190798
Train loss on 1850 batch: 0.233269
Train loss on 1900 batch: 0.229562
Train loss on 1950 batch: 0.227876
Train loss on 2000 batch: 0.290493
Train loss on 2050 batch: 0.238157
Train loss on 2100 batch: 0.236043
Train loss on 2150 batch: 0.226000
: Epoch: 222 | Training Loss: 0.227026 | Val. Loss: 0.337423 | Val. Kappa Score: 0.7267 | LR: 0.000737 | Estimated time: 555.37
Train loss on 50 batch: 0.171445
Train loss on 100 batch: 0.182820
Train loss on 150 batch: 0.241044
Train loss on 200 batch: 0.218117
Train loss on 250 batch: 0.182521
Train loss on 300 batch: 0.198448
Train loss on 350 batch: 0.229434
Train loss on 400 batch: 0.231601
Train loss on 450 batch: 0.239217
Train loss on 500 batch: 0.186989
Train loss on 550 batch: 0.254750
Train loss on 600 batch: 0.196832
Train loss on 650 batch: 0.217740
Train loss on 700 batch: 0.214351
Train loss on 750 batch: 0.231677
Train loss on 800 batch: 0.187863
Train loss on 850 batch: 0.238542
Train loss on 900 batch: 0.250281
Train loss on 950 batch: 0.223706
Train loss on 1000 batch: 0.206723
Train loss on 1050 batch: 0.195395
Train loss on 1100 batch: 0.257772
Train loss on 1150 batch: 0.203786
Train loss on 1200 batch: 0.213880
Train loss on 1250 batch: 0.229977
Train loss on 1300 batch: 0.237015
Train loss on 1350 batch: 0.251611
Train loss on 1400 batch: 0.216835
Train loss on 1450 batch: 0.263112
Train loss on 1500 batch: 0.229850
Train loss on 1550 batch: 0.195366
Train loss on 1600 batch: 0.237304
Train loss on 1650 batch: 0.239877
Train loss on 1700 batch: 0.259163
Train loss on 1750 batch: 0.202307
Train loss on 1800 batch: 0.213696
Train loss on 1850 batch: 0.212421
Train loss on 1900 batch: 0.240355
Train loss on 1950 batch: 0.228630
Train loss on 2000 batch: 0.266683
Train loss on 2050 batch: 0.220653
Train loss on 2100 batch: 0.184737
Train loss on 2150 batch: 0.199298
: Epoch: 223 | Training Loss: 0.221388 | Val. Loss: 0.353247 | Val. Kappa Score: 0.7268 | LR: 0.000697 | Estimated time: 555.31
Train loss on 50 batch: 0.226178
Train loss on 100 batch: 0.240813
Train loss on 150 batch: 0.199661
Train loss on 200 batch: 0.202730
Train loss on 250 batch: 0.214209
Train loss on 300 batch: 0.202377
Train loss on 350 batch: 0.232390
Train loss on 400 batch: 0.230565
Train loss on 450 batch: 0.219143
Train loss on 500 batch: 0.206716
Train loss on 550 batch: 0.208901
Train loss on 600 batch: 0.202316
Train loss on 650 batch: 0.213713
Train loss on 700 batch: 0.183965
Train loss on 750 batch: 0.211370
Train loss on 800 batch: 0.225696
Train loss on 850 batch: 0.176277
Train loss on 900 batch: 0.193835
Train loss on 950 batch: 0.250227
Train loss on 1000 batch: 0.204025
Train loss on 1050 batch: 0.258547
Train loss on 1100 batch: 0.213922
Train loss on 1150 batch: 0.202726
Train loss on 1200 batch: 0.211595
Train loss on 1250 batch: 0.186040
Train loss on 1300 batch: 0.187607
Train loss on 1350 batch: 0.214949
Train loss on 1400 batch: 0.228554
Train loss on 1450 batch: 0.214277
Train loss on 1500 batch: 0.233813
Train loss on 1550 batch: 0.255350
Train loss on 1600 batch: 0.203694
Train loss on 1650 batch: 0.218682
Train loss on 1700 batch: 0.233874
Train loss on 1750 batch: 0.232721
Train loss on 1800 batch: 0.190010
Train loss on 1850 batch: 0.250323
Train loss on 1900 batch: 0.215128
Train loss on 1950 batch: 0.225020
Train loss on 2000 batch: 0.240826
Train loss on 2050 batch: 0.190506
Train loss on 2100 batch: 0.236768
Train loss on 2150 batch: 0.229986
: Epoch: 224 | Training Loss: 0.216304 | Val. Loss: 0.383058 | Val. Kappa Score: 0.7267 | LR: 0.000655 | Estimated time: 555.35
Train loss on 50 batch: 0.195077
Train loss on 100 batch: 0.222773
Train loss on 150 batch: 0.212915
Train loss on 200 batch: 0.197165
Train loss on 250 batch: 0.199024
Train loss on 300 batch: 0.207942
Train loss on 350 batch: 0.211599
Train loss on 400 batch: 0.225661
Train loss on 450 batch: 0.229309
Train loss on 500 batch: 0.252290
Train loss on 550 batch: 0.211580
Train loss on 600 batch: 0.211793
Train loss on 650 batch: 0.215887
Train loss on 700 batch: 0.197016
Train loss on 750 batch: 0.169057
Train loss on 800 batch: 0.188165
Train loss on 850 batch: 0.244633
Train loss on 900 batch: 0.167194
Train loss on 950 batch: 0.255691
Train loss on 1000 batch: 0.179133
Train loss on 1050 batch: 0.196884
Train loss on 1100 batch: 0.233944
Train loss on 1150 batch: 0.264927
Train loss on 1200 batch: 0.167589
Train loss on 1250 batch: 0.227237
Train loss on 1300 batch: 0.173312
Train loss on 1350 batch: 0.178329
Train loss on 1400 batch: 0.211494
Train loss on 1450 batch: 0.223894
Train loss on 1500 batch: 0.231323
Train loss on 1550 batch: 0.193006
Train loss on 1600 batch: 0.178871
Train loss on 1650 batch: 0.206725
Train loss on 1700 batch: 0.208435
Train loss on 1750 batch: 0.173742
Train loss on 1800 batch: 0.277139
Train loss on 1850 batch: 0.197792
Train loss on 1900 batch: 0.181823
Train loss on 1950 batch: 0.216280
Train loss on 2000 batch: 0.224304
Train loss on 2050 batch: 0.191161
Train loss on 2100 batch: 0.233060
Train loss on 2150 batch: 0.204359
: Epoch: 225 | Training Loss: 0.209527 | Val. Loss: 0.332673 | Val. Kappa Score: 0.7268 | LR: 0.000611 | Estimated time: 555.29
Train loss on 50 batch: 0.205669
Train loss on 100 batch: 0.225210
Train loss on 150 batch: 0.203378
Train loss on 200 batch: 0.186039
Train loss on 250 batch: 0.177184
Train loss on 300 batch: 0.181477
Train loss on 350 batch: 0.223131
Train loss on 400 batch: 0.203725
Train loss on 450 batch: 0.239054
Train loss on 500 batch: 0.187257
Train loss on 550 batch: 0.170364
Train loss on 600 batch: 0.221665
Train loss on 650 batch: 0.201870
Train loss on 700 batch: 0.195929
Train loss on 750 batch: 0.192932
Train loss on 800 batch: 0.240659
Train loss on 850 batch: 0.214508
Train loss on 900 batch: 0.204449
Train loss on 950 batch: 0.216763
Train loss on 1000 batch: 0.247979
Train loss on 1050 batch: 0.207847
Train loss on 1100 batch: 0.207017
Train loss on 1150 batch: 0.239445
Train loss on 1200 batch: 0.234069
Train loss on 1250 batch: 0.204238
Train loss on 1300 batch: 0.211684
Train loss on 1350 batch: 0.227888
Train loss on 1400 batch: 0.205252
Train loss on 1450 batch: 0.255660
Train loss on 1500 batch: 0.178395
Train loss on 1550 batch: 0.238424
Train loss on 1600 batch: 0.218673
Train loss on 1650 batch: 0.217508
Train loss on 1700 batch: 0.217509
Train loss on 1750 batch: 0.164911
Train loss on 1800 batch: 0.209350
Train loss on 1850 batch: 0.161710
Train loss on 1900 batch: 0.220121
Train loss on 1950 batch: 0.252738
Train loss on 2000 batch: 0.193515
Train loss on 2050 batch: 0.189245
Train loss on 2100 batch: 0.199172
Train loss on 2150 batch: 0.191305
: Epoch: 226 | Training Loss: 0.209280 | Val. Loss: 0.357174 | Val. Kappa Score: 0.7269 | LR: 0.000567 | Estimated time: 555.31
Train loss on 50 batch: 0.192051
Train loss on 100 batch: 0.181365
Train loss on 150 batch: 0.186504
Train loss on 200 batch: 0.177784
Train loss on 250 batch: 0.179471
Train loss on 300 batch: 0.180681
Train loss on 350 batch: 0.173792
Train loss on 400 batch: 0.197028
Train loss on 450 batch: 0.196666
Train loss on 500 batch: 0.201491
Train loss on 550 batch: 0.173875
Train loss on 600 batch: 0.227961
Train loss on 650 batch: 0.199442
Train loss on 700 batch: 0.189417
Train loss on 750 batch: 0.175561
Train loss on 800 batch: 0.202404
Train loss on 850 batch: 0.200510
Train loss on 900 batch: 0.185625
Train loss on 950 batch: 0.235115
Train loss on 1000 batch: 0.209074
Train loss on 1050 batch: 0.185411
Train loss on 1100 batch: 0.237263
Train loss on 1150 batch: 0.195736
Train loss on 1200 batch: 0.163536
Train loss on 1250 batch: 0.199007
Train loss on 1300 batch: 0.180734
Train loss on 1350 batch: 0.230563
Train loss on 1400 batch: 0.185202
Train loss on 1450 batch: 0.194206
Train loss on 1500 batch: 0.223798
Train loss on 1550 batch: 0.193568
Train loss on 1600 batch: 0.229043
Train loss on 1650 batch: 0.219055
Train loss on 1700 batch: 0.234558
Train loss on 1750 batch: 0.179921
Train loss on 1800 batch: 0.182351
Train loss on 1850 batch: 0.180178
Train loss on 1900 batch: 0.237010
Train loss on 1950 batch: 0.189235
Train loss on 2000 batch: 0.188503
Train loss on 2050 batch: 0.237588
Train loss on 2100 batch: 0.207739
Train loss on 2150 batch: 0.237394
: Epoch: 227 | Training Loss: 0.199511 | Val. Loss: 0.339771 | Val. Kappa Score: 0.7269 | LR: 0.000522 | Estimated time: 555.08
Train loss on 50 batch: 0.206655
Train loss on 100 batch: 0.210379
Train loss on 150 batch: 0.207446
Train loss on 200 batch: 0.196174
Train loss on 250 batch: 0.202622
Train loss on 300 batch: 0.188616
Train loss on 350 batch: 0.165247
Train loss on 400 batch: 0.257883
Train loss on 450 batch: 0.218931
Train loss on 500 batch: 0.172212
Train loss on 550 batch: 0.182548
Train loss on 600 batch: 0.186817
Train loss on 650 batch: 0.189876
Train loss on 700 batch: 0.198125
Train loss on 750 batch: 0.213127
Train loss on 800 batch: 0.211454
Train loss on 850 batch: 0.165006
Train loss on 900 batch: 0.188792
Train loss on 950 batch: 0.201008
Train loss on 1000 batch: 0.196770
Train loss on 1050 batch: 0.156729
Train loss on 1100 batch: 0.161845
Train loss on 1150 batch: 0.212381
Train loss on 1200 batch: 0.207407
Train loss on 1250 batch: 0.232226
Train loss on 1300 batch: 0.164999
Train loss on 1350 batch: 0.163019
Train loss on 1400 batch: 0.170777
Train loss on 1450 batch: 0.233531
Train loss on 1500 batch: 0.210990
Train loss on 1550 batch: 0.220200
Train loss on 1600 batch: 0.161708
Train loss on 1650 batch: 0.192983
Train loss on 1700 batch: 0.188806
Train loss on 1750 batch: 0.205576
Train loss on 1800 batch: 0.196310
Train loss on 1850 batch: 0.157702
Train loss on 1900 batch: 0.200917
Train loss on 1950 batch: 0.181703
Train loss on 2000 batch: 0.213887
Train loss on 2050 batch: 0.206176
Train loss on 2100 batch: 0.201066
Train loss on 2150 batch: 0.203360
: Epoch: 228 | Training Loss: 0.195523 | Val. Loss: 0.348343 | Val. Kappa Score: 0.7270 | LR: 0.000478 | Estimated time: 555.47
Train loss on 50 batch: 0.170738
Train loss on 100 batch: 0.199938
Train loss on 150 batch: 0.185410
Train loss on 200 batch: 0.174073
Train loss on 250 batch: 0.210879
Train loss on 300 batch: 0.165763
Train loss on 350 batch: 0.182231
Train loss on 400 batch: 0.196011
Train loss on 450 batch: 0.187873
Train loss on 500 batch: 0.174926
Train loss on 550 batch: 0.161544
Train loss on 600 batch: 0.212809
Train loss on 650 batch: 0.195034
Train loss on 700 batch: 0.184082
Train loss on 750 batch: 0.214800
Train loss on 800 batch: 0.167504
Train loss on 850 batch: 0.191404
Train loss on 900 batch: 0.203358
Train loss on 950 batch: 0.192533
Train loss on 1000 batch: 0.203151
Train loss on 1050 batch: 0.226636
Train loss on 1100 batch: 0.173296
Train loss on 1150 batch: 0.169335
Train loss on 1200 batch: 0.203632
Train loss on 1250 batch: 0.175714
Train loss on 1300 batch: 0.217511
Train loss on 1350 batch: 0.207673
Train loss on 1400 batch: 0.179224
Train loss on 1450 batch: 0.182078
Train loss on 1500 batch: 0.197068
Train loss on 1550 batch: 0.203310
Train loss on 1600 batch: 0.199727
Train loss on 1650 batch: 0.163859
Train loss on 1700 batch: 0.172172
Train loss on 1750 batch: 0.163777
Train loss on 1800 batch: 0.185888
Train loss on 1850 batch: 0.200358
Train loss on 1900 batch: 0.176336
Train loss on 1950 batch: 0.211779
Train loss on 2000 batch: 0.167312
Train loss on 2050 batch: 0.166672
Train loss on 2100 batch: 0.208262
Train loss on 2150 batch: 0.169090
: Epoch: 229 | Training Loss: 0.188840 | Val. Loss: 0.368443 | Val. Kappa Score: 0.7270 | LR: 0.000433 | Estimated time: 555.24
Train loss on 50 batch: 0.175558
Train loss on 100 batch: 0.157326
Train loss on 150 batch: 0.182889
Train loss on 200 batch: 0.187933
Train loss on 250 batch: 0.191106
Train loss on 300 batch: 0.163715
Train loss on 350 batch: 0.199541
Train loss on 400 batch: 0.184863
Train loss on 450 batch: 0.167536
Train loss on 500 batch: 0.170084
Train loss on 550 batch: 0.182489
Train loss on 600 batch: 0.183299
Train loss on 650 batch: 0.181077
Train loss on 700 batch: 0.159221
Train loss on 750 batch: 0.159832
Train loss on 800 batch: 0.232367
Train loss on 850 batch: 0.187421
Train loss on 900 batch: 0.205361
Train loss on 950 batch: 0.175033
Train loss on 1000 batch: 0.183858
Train loss on 1050 batch: 0.208175
Train loss on 1100 batch: 0.196940
Train loss on 1150 batch: 0.167818
Train loss on 1200 batch: 0.184772
Train loss on 1250 batch: 0.183824
Train loss on 1300 batch: 0.197594
Train loss on 1350 batch: 0.176767
Train loss on 1400 batch: 0.190782
Train loss on 1450 batch: 0.202389
Train loss on 1500 batch: 0.180625
Train loss on 1550 batch: 0.146216
Train loss on 1600 batch: 0.166361
Train loss on 1650 batch: 0.173419
Train loss on 1700 batch: 0.183638
Train loss on 1750 batch: 0.153845
Train loss on 1800 batch: 0.164971
Train loss on 1850 batch: 0.181393
Train loss on 1900 batch: 0.187826
Train loss on 1950 batch: 0.229528
Train loss on 2000 batch: 0.190209
Train loss on 2050 batch: 0.185219
Train loss on 2100 batch: 0.166810
Train loss on 2150 batch: 0.169992
: Epoch: 230 | Training Loss: 0.181865 | Val. Loss: 0.355178 | Val. Kappa Score: 0.7271 | LR: 0.000389 | Estimated time: 555.47
Train loss on 50 batch: 0.172146
Train loss on 100 batch: 0.161392
Train loss on 150 batch: 0.205254
Train loss on 200 batch: 0.164082
Train loss on 250 batch: 0.197624
Train loss on 300 batch: 0.135209
Train loss on 350 batch: 0.181104
Train loss on 400 batch: 0.139591
Train loss on 450 batch: 0.159395
Train loss on 500 batch: 0.149267
Train loss on 550 batch: 0.185614
Train loss on 600 batch: 0.154647
Train loss on 650 batch: 0.199016
Train loss on 700 batch: 0.156589
Train loss on 750 batch: 0.196861
Train loss on 800 batch: 0.168603
Train loss on 850 batch: 0.174131
Train loss on 900 batch: 0.216150
Train loss on 950 batch: 0.197387
Train loss on 1000 batch: 0.165749
Train loss on 1050 batch: 0.178066
Train loss on 1100 batch: 0.171992
Train loss on 1150 batch: 0.156318
Train loss on 1200 batch: 0.196423
Train loss on 1250 batch: 0.198979
Train loss on 1300 batch: 0.211382
Train loss on 1350 batch: 0.161214
Train loss on 1400 batch: 0.129519
Train loss on 1450 batch: 0.157940
Train loss on 1500 batch: 0.151132
Train loss on 1550 batch: 0.190943
Train loss on 1600 batch: 0.179521
Train loss on 1650 batch: 0.219763
Train loss on 1700 batch: 0.186596
Train loss on 1750 batch: 0.205129
Train loss on 1800 batch: 0.198968
Train loss on 1850 batch: 0.171915
Train loss on 1900 batch: 0.149669
Train loss on 1950 batch: 0.179365
Train loss on 2000 batch: 0.162538
Train loss on 2050 batch: 0.171461
Train loss on 2100 batch: 0.178058
Train loss on 2150 batch: 0.192329
: Epoch: 231 | Training Loss: 0.175779 | Val. Loss: 0.353341 | Val. Kappa Score: 0.7272 | LR: 0.000345 | Estimated time: 555.55
Train loss on 50 batch: 0.177916
Train loss on 100 batch: 0.177426
Train loss on 150 batch: 0.149240
Train loss on 200 batch: 0.148693
Train loss on 250 batch: 0.128515
Train loss on 300 batch: 0.163026
Train loss on 350 batch: 0.179399
Train loss on 400 batch: 0.170126
Train loss on 450 batch: 0.197249
Train loss on 500 batch: 0.160554
Train loss on 550 batch: 0.154039
Train loss on 600 batch: 0.174663
Train loss on 650 batch: 0.215210
Train loss on 700 batch: 0.171564
Train loss on 750 batch: 0.170984
Train loss on 800 batch: 0.169842
Train loss on 850 batch: 0.156566
Train loss on 900 batch: 0.170034
Train loss on 950 batch: 0.161895
Train loss on 1000 batch: 0.189199
Train loss on 1050 batch: 0.171888
Train loss on 1100 batch: 0.133599
Train loss on 1150 batch: 0.178769
Train loss on 1200 batch: 0.180409
Train loss on 1250 batch: 0.166910
Train loss on 1300 batch: 0.195733
Train loss on 1350 batch: 0.193043
Train loss on 1400 batch: 0.188915
Train loss on 1450 batch: 0.186195
Train loss on 1500 batch: 0.180392
Train loss on 1550 batch: 0.194943
Train loss on 1600 batch: 0.157525
Train loss on 1650 batch: 0.215202
Train loss on 1700 batch: 0.173087
Train loss on 1750 batch: 0.145183
Train loss on 1800 batch: 0.180819
Train loss on 1850 batch: 0.179698
Train loss on 1900 batch: 0.179351
Train loss on 1950 batch: 0.167295
Train loss on 2000 batch: 0.159832
Train loss on 2050 batch: 0.179332
Train loss on 2100 batch: 0.135404
Train loss on 2150 batch: 0.160171
: Epoch: 232 | Training Loss: 0.172538 | Val. Loss: 0.340555 | Val. Kappa Score: 0.7272 | LR: 0.000303 | Estimated time: 555.13
Train loss on 50 batch: 0.176227
Train loss on 100 batch: 0.156398
Train loss on 150 batch: 0.190424
Train loss on 200 batch: 0.176033
Train loss on 250 batch: 0.187070
Train loss on 300 batch: 0.132632
Train loss on 350 batch: 0.186945
Train loss on 400 batch: 0.163878
Train loss on 450 batch: 0.155924
Train loss on 500 batch: 0.150843
Train loss on 550 batch: 0.162378
Train loss on 600 batch: 0.162850
Train loss on 650 batch: 0.165255
Train loss on 700 batch: 0.150631
Train loss on 750 batch: 0.179342
Train loss on 800 batch: 0.143121
Train loss on 850 batch: 0.168517
Train loss on 900 batch: 0.156219
Train loss on 950 batch: 0.179783
Train loss on 1000 batch: 0.164061
Train loss on 1050 batch: 0.168256
Train loss on 1100 batch: 0.171982
Train loss on 1150 batch: 0.179551
Train loss on 1200 batch: 0.189342
Train loss on 1250 batch: 0.166279
Train loss on 1300 batch: 0.144172
Train loss on 1350 batch: 0.180206
Train loss on 1400 batch: 0.189196
Train loss on 1450 batch: 0.144847
Train loss on 1500 batch: 0.161921
Train loss on 1550 batch: 0.155710
Train loss on 1600 batch: 0.162855
Train loss on 1650 batch: 0.212861
Train loss on 1700 batch: 0.170066
Train loss on 1750 batch: 0.175875
Train loss on 1800 batch: 0.159237
Train loss on 1850 batch: 0.190343
Train loss on 1900 batch: 0.146912
Train loss on 1950 batch: 0.178070
Train loss on 2000 batch: 0.159837
Train loss on 2050 batch: 0.173251
Train loss on 2100 batch: 0.184847
Train loss on 2150 batch: 0.142423
: Epoch: 233 | Training Loss: 0.169394 | Val. Loss: 0.352642 | Val. Kappa Score: 0.7273 | LR: 0.000263 | Estimated time: 555.21
Train loss on 50 batch: 0.168485
Train loss on 100 batch: 0.140340
Train loss on 150 batch: 0.190144
Train loss on 200 batch: 0.167534
Train loss on 250 batch: 0.185483
Train loss on 300 batch: 0.156949
Train loss on 350 batch: 0.161888
Train loss on 400 batch: 0.153481
Train loss on 450 batch: 0.152590
Train loss on 500 batch: 0.165295
Train loss on 550 batch: 0.191644
Train loss on 600 batch: 0.132597
Train loss on 650 batch: 0.172387
Train loss on 700 batch: 0.134952
Train loss on 750 batch: 0.151864
Train loss on 800 batch: 0.172817
Train loss on 850 batch: 0.151695
Train loss on 900 batch: 0.171739
Train loss on 950 batch: 0.171357
Train loss on 1000 batch: 0.159652
Train loss on 1050 batch: 0.137394
Train loss on 1100 batch: 0.180296
Train loss on 1150 batch: 0.131550
Train loss on 1200 batch: 0.164050
Train loss on 1250 batch: 0.180009
Train loss on 1300 batch: 0.149582
Train loss on 1350 batch: 0.156341
Train loss on 1400 batch: 0.137308
Train loss on 1450 batch: 0.156491
Train loss on 1500 batch: 0.170708
Train loss on 1550 batch: 0.138631
Train loss on 1600 batch: 0.181728
Train loss on 1650 batch: 0.186271
Train loss on 1700 batch: 0.151393
Train loss on 1750 batch: 0.168294
Train loss on 1800 batch: 0.147275
Train loss on 1850 batch: 0.196806
Train loss on 1900 batch: 0.156354
Train loss on 1950 batch: 0.157320
Train loss on 2000 batch: 0.178858
Train loss on 2050 batch: 0.171966
Train loss on 2100 batch: 0.158836
Train loss on 2150 batch: 0.182354
: Epoch: 234 | Training Loss: 0.162177 | Val. Loss: 0.361754 | Val. Kappa Score: 0.7273 | LR: 0.000225 | Estimated time: 555.45
Train loss on 50 batch: 0.170201
Train loss on 100 batch: 0.155701
Train loss on 150 batch: 0.123137
Train loss on 200 batch: 0.187173
Train loss on 250 batch: 0.161377
Train loss on 300 batch: 0.148261
Train loss on 350 batch: 0.170298
Train loss on 400 batch: 0.130846
Train loss on 450 batch: 0.173806
Train loss on 500 batch: 0.156820
Train loss on 550 batch: 0.165316
Train loss on 600 batch: 0.141196
Train loss on 650 batch: 0.161886
Train loss on 700 batch: 0.171462
Train loss on 750 batch: 0.150705
Train loss on 800 batch: 0.159432
Train loss on 850 batch: 0.178349
Train loss on 900 batch: 0.173582
Train loss on 950 batch: 0.158908
Train loss on 1000 batch: 0.162889
Train loss on 1050 batch: 0.159991
Train loss on 1100 batch: 0.136660
Train loss on 1150 batch: 0.170832
Train loss on 1200 batch: 0.189465
Train loss on 1250 batch: 0.169574
Train loss on 1300 batch: 0.150029
Train loss on 1350 batch: 0.156719
Train loss on 1400 batch: 0.154392
Train loss on 1450 batch: 0.151738
Train loss on 1500 batch: 0.155706
Train loss on 1550 batch: 0.159951
Train loss on 1600 batch: 0.159576
Train loss on 1650 batch: 0.144173
Train loss on 1700 batch: 0.177002
Train loss on 1750 batch: 0.145973
Train loss on 1800 batch: 0.184091
Train loss on 1850 batch: 0.153962
Train loss on 1900 batch: 0.125288
Train loss on 1950 batch: 0.160520
Train loss on 2000 batch: 0.156433
Train loss on 2050 batch: 0.145825
Train loss on 2100 batch: 0.182770
Train loss on 2150 batch: 0.147264
: Epoch: 235 | Training Loss: 0.158904 | Val. Loss: 0.371190 | Val. Kappa Score: 0.7273 | LR: 0.000188 | Estimated time: 555.32
Train loss on 50 batch: 0.141709
Train loss on 100 batch: 0.148900
Train loss on 150 batch: 0.135601
Train loss on 200 batch: 0.150524
Train loss on 250 batch: 0.165441
Train loss on 300 batch: 0.141060
Train loss on 350 batch: 0.149493
Train loss on 400 batch: 0.171857
Train loss on 450 batch: 0.158021
Train loss on 500 batch: 0.142122
Train loss on 550 batch: 0.154352
Train loss on 600 batch: 0.166994
Train loss on 650 batch: 0.134936
Train loss on 700 batch: 0.168937
Train loss on 750 batch: 0.155364
Train loss on 800 batch: 0.155005
Train loss on 850 batch: 0.133222
Train loss on 900 batch: 0.182602
Train loss on 950 batch: 0.156150
Train loss on 1000 batch: 0.164441
Train loss on 1050 batch: 0.173476
Train loss on 1100 batch: 0.156029
Train loss on 1150 batch: 0.138730
Train loss on 1200 batch: 0.149379
Train loss on 1250 batch: 0.166343
Train loss on 1300 batch: 0.155939
Train loss on 1350 batch: 0.146374
Train loss on 1400 batch: 0.117788
Train loss on 1450 batch: 0.150187
Train loss on 1500 batch: 0.157682
Train loss on 1550 batch: 0.122933
Train loss on 1600 batch: 0.176292
Train loss on 1650 batch: 0.192263
Train loss on 1700 batch: 0.182093
Train loss on 1750 batch: 0.169381
Train loss on 1800 batch: 0.154318
Train loss on 1850 batch: 0.138252
Train loss on 1900 batch: 0.170625
Train loss on 1950 batch: 0.141657
Train loss on 2000 batch: 0.150479
Train loss on 2050 batch: 0.157864
Train loss on 2100 batch: 0.149101
Train loss on 2150 batch: 0.165747
: Epoch: 236 | Training Loss: 0.154703 | Val. Loss: 0.352808 | Val. Kappa Score: 0.7273 | LR: 0.000154 | Estimated time: 555.35
Train loss on 50 batch: 0.135915
Train loss on 100 batch: 0.137497
Train loss on 150 batch: 0.129782
Train loss on 200 batch: 0.132954
Train loss on 250 batch: 0.136741
Train loss on 300 batch: 0.182140
Train loss on 350 batch: 0.148467
Train loss on 400 batch: 0.159688
Train loss on 450 batch: 0.120334
Train loss on 500 batch: 0.133228
Train loss on 550 batch: 0.138961
Train loss on 600 batch: 0.136013
Train loss on 650 batch: 0.163829
Train loss on 700 batch: 0.146047
Train loss on 750 batch: 0.140804
Train loss on 800 batch: 0.209287
Train loss on 850 batch: 0.179720
Train loss on 900 batch: 0.177688
Train loss on 950 batch: 0.140470
Train loss on 1000 batch: 0.149223
Train loss on 1050 batch: 0.149595
Train loss on 1100 batch: 0.144793
Train loss on 1150 batch: 0.145625
Train loss on 1200 batch: 0.185008
Train loss on 1250 batch: 0.171135
Train loss on 1300 batch: 0.126407
Train loss on 1350 batch: 0.140828
Train loss on 1400 batch: 0.161318
Train loss on 1450 batch: 0.170890
Train loss on 1500 batch: 0.173758
Train loss on 1550 batch: 0.118953
Train loss on 1600 batch: 0.162697
Train loss on 1650 batch: 0.134391
Train loss on 1700 batch: 0.146362
Train loss on 1750 batch: 0.159509
Train loss on 1800 batch: 0.171202
Train loss on 1850 batch: 0.133748
Train loss on 1900 batch: 0.142945
Train loss on 1950 batch: 0.146232
Train loss on 2000 batch: 0.168019
Train loss on 2050 batch: 0.135934
Train loss on 2100 batch: 0.160127
Train loss on 2150 batch: 0.148034
: Epoch: 237 | Training Loss: 0.152251 | Val. Loss: 0.360953 | Val. Kappa Score: 0.7273 | LR: 0.000123 | Estimated time: 554.97
Train loss on 50 batch: 0.138673
Train loss on 100 batch: 0.129520
Train loss on 150 batch: 0.132467
Train loss on 200 batch: 0.154045
Train loss on 250 batch: 0.146739
Train loss on 300 batch: 0.130766
Train loss on 350 batch: 0.160762
Train loss on 400 batch: 0.149579
Train loss on 450 batch: 0.124418
Train loss on 500 batch: 0.129507
Train loss on 550 batch: 0.129518
Train loss on 600 batch: 0.158221
Train loss on 650 batch: 0.152494
Train loss on 700 batch: 0.151929
Train loss on 750 batch: 0.198960
Train loss on 800 batch: 0.173288
Train loss on 850 batch: 0.156210
Train loss on 900 batch: 0.140423
Train loss on 950 batch: 0.114881
Train loss on 1000 batch: 0.140188
Train loss on 1050 batch: 0.151090
Train loss on 1100 batch: 0.159605
Train loss on 1150 batch: 0.153369
Train loss on 1200 batch: 0.178258
Train loss on 1250 batch: 0.174181
Train loss on 1300 batch: 0.148776
Train loss on 1350 batch: 0.130953
Train loss on 1400 batch: 0.147063
Train loss on 1450 batch: 0.145732
Train loss on 1500 batch: 0.158986
Train loss on 1550 batch: 0.133442
Train loss on 1600 batch: 0.169861
Train loss on 1650 batch: 0.165856
Train loss on 1700 batch: 0.143240
Train loss on 1750 batch: 0.128606
Train loss on 1800 batch: 0.154886
Train loss on 1850 batch: 0.130249
Train loss on 1900 batch: 0.144088
Train loss on 1950 batch: 0.118217
Train loss on 2000 batch: 0.162682
Train loss on 2050 batch: 0.146770
Train loss on 2100 batch: 0.134849
Train loss on 2150 batch: 0.144990
: Epoch: 238 | Training Loss: 0.147375 | Val. Loss: 0.356861 | Val. Kappa Score: 0.7274 | LR: 0.000095 | Estimated time: 555.38
Train loss on 50 batch: 0.135103
Train loss on 100 batch: 0.147539
Train loss on 150 batch: 0.127229
Train loss on 200 batch: 0.168378
Train loss on 250 batch: 0.158505
Train loss on 300 batch: 0.147110
Train loss on 350 batch: 0.133934
Train loss on 400 batch: 0.161306
Train loss on 450 batch: 0.168233
Train loss on 500 batch: 0.164295
Train loss on 550 batch: 0.164082
Train loss on 600 batch: 0.122999
Train loss on 650 batch: 0.158991
Train loss on 700 batch: 0.143340
Train loss on 750 batch: 0.157709
Train loss on 800 batch: 0.160362
Train loss on 850 batch: 0.152468
Train loss on 900 batch: 0.164624
Train loss on 950 batch: 0.142610
Train loss on 1000 batch: 0.121000
Train loss on 1050 batch: 0.122938
Train loss on 1100 batch: 0.131962
Train loss on 1150 batch: 0.130163
Train loss on 1200 batch: 0.164151
Train loss on 1250 batch: 0.124592
Train loss on 1300 batch: 0.156672
Train loss on 1350 batch: 0.143872
Train loss on 1400 batch: 0.150395
Train loss on 1450 batch: 0.138850
Train loss on 1500 batch: 0.118932
Train loss on 1550 batch: 0.144304
Train loss on 1600 batch: 0.130061
Train loss on 1650 batch: 0.152498
Train loss on 1700 batch: 0.140130
Train loss on 1750 batch: 0.129705
Train loss on 1800 batch: 0.141492
Train loss on 1850 batch: 0.136190
Train loss on 1900 batch: 0.133376
Train loss on 1950 batch: 0.148596
Train loss on 2000 batch: 0.147959
Train loss on 2050 batch: 0.151022
Train loss on 2100 batch: 0.138638
Train loss on 2150 batch: 0.135313
: Epoch: 239 | Training Loss: 0.143455 | Val. Loss: 0.355030 | Val. Kappa Score: 0.7274 | LR: 0.000071 | Estimated time: 555.27
Train loss on 50 batch: 0.159872
Train loss on 100 batch: 0.163367
Train loss on 150 batch: 0.139209
Train loss on 200 batch: 0.122932
Train loss on 250 batch: 0.143295
Train loss on 300 batch: 0.141018
Train loss on 350 batch: 0.133253
Train loss on 400 batch: 0.154610
Train loss on 450 batch: 0.153472
Train loss on 500 batch: 0.149723
Train loss on 550 batch: 0.171037
Train loss on 600 batch: 0.153751
Train loss on 650 batch: 0.134921
Train loss on 700 batch: 0.168490
Train loss on 750 batch: 0.151853
Train loss on 800 batch: 0.130336
Train loss on 850 batch: 0.120309
Train loss on 900 batch: 0.172948
Train loss on 950 batch: 0.130422
Train loss on 1000 batch: 0.134663
Train loss on 1050 batch: 0.134696
Train loss on 1100 batch: 0.152886
Train loss on 1150 batch: 0.177876
Train loss on 1200 batch: 0.143000
Train loss on 1250 batch: 0.140769
Train loss on 1300 batch: 0.135023
Train loss on 1350 batch: 0.143108
Train loss on 1400 batch: 0.123417
Train loss on 1450 batch: 0.140333
Train loss on 1500 batch: 0.139372
Train loss on 1550 batch: 0.123078
Train loss on 1600 batch: 0.127080
Train loss on 1650 batch: 0.115548
Train loss on 1700 batch: 0.143830
Train loss on 1750 batch: 0.163300
Train loss on 1800 batch: 0.143954
Train loss on 1850 batch: 0.134613
Train loss on 1900 batch: 0.130262
Train loss on 1950 batch: 0.161624
Train loss on 2000 batch: 0.140727
Train loss on 2050 batch: 0.120401
Train loss on 2100 batch: 0.115270
Train loss on 2150 batch: 0.124548
: Epoch: 240 | Training Loss: 0.142968 | Val. Loss: 0.345729 | Val. Kappa Score: 0.7275 | LR: 0.000050 | Estimated time: 555.14
Train loss on 50 batch: 0.167111
Train loss on 100 batch: 0.155642
Train loss on 150 batch: 0.121898
Train loss on 200 batch: 0.140082
Train loss on 250 batch: 0.128996
Train loss on 300 batch: 0.127059
Train loss on 350 batch: 0.152171
Train loss on 400 batch: 0.153411
Train loss on 450 batch: 0.134443
Train loss on 500 batch: 0.133024
Train loss on 550 batch: 0.141990
Train loss on 600 batch: 0.127093
Train loss on 650 batch: 0.139226
Train loss on 700 batch: 0.152069
Train loss on 750 batch: 0.125533
Train loss on 800 batch: 0.128464
Train loss on 850 batch: 0.144361
Train loss on 900 batch: 0.135751
Train loss on 950 batch: 0.153600
Train loss on 1000 batch: 0.135473
Train loss on 1050 batch: 0.137437
Train loss on 1100 batch: 0.139077
Train loss on 1150 batch: 0.123549
Train loss on 1200 batch: 0.142223
Train loss on 1250 batch: 0.129023
Train loss on 1300 batch: 0.114110
Train loss on 1350 batch: 0.133069
Train loss on 1400 batch: 0.170980
Train loss on 1450 batch: 0.163462
Train loss on 1500 batch: 0.154405
Train loss on 1550 batch: 0.126643
Train loss on 1600 batch: 0.148657
Train loss on 1650 batch: 0.174245
Train loss on 1700 batch: 0.120741
Train loss on 1750 batch: 0.136418
Train loss on 1800 batch: 0.144728
Train loss on 1850 batch: 0.138028
Train loss on 1900 batch: 0.140599
Train loss on 1950 batch: 0.134511
Train loss on 2000 batch: 0.150552
Train loss on 2050 batch: 0.118344
Train loss on 2100 batch: 0.127954
Train loss on 2150 batch: 0.140534
: Epoch: 241 | Training Loss: 0.139452 | Val. Loss: 0.347084 | Val. Kappa Score: 0.7275 | LR: 0.000032 | Estimated time: 555.41
Train loss on 50 batch: 0.146952
Train loss on 100 batch: 0.166422
Train loss on 150 batch: 0.136368
Train loss on 200 batch: 0.146324
Train loss on 250 batch: 0.138753
Train loss on 300 batch: 0.151432
Train loss on 350 batch: 0.146631
Train loss on 400 batch: 0.130708
Train loss on 450 batch: 0.131095
Train loss on 500 batch: 0.149271
Train loss on 550 batch: 0.116784
Train loss on 600 batch: 0.110403
Train loss on 650 batch: 0.133587
Train loss on 700 batch: 0.125283
Train loss on 750 batch: 0.143720
Train loss on 800 batch: 0.168367
Train loss on 850 batch: 0.141566
Train loss on 900 batch: 0.124736
Train loss on 950 batch: 0.141798
Train loss on 1000 batch: 0.141334
Train loss on 1050 batch: 0.146209
Train loss on 1100 batch: 0.139815
Train loss on 1150 batch: 0.136593
Train loss on 1200 batch: 0.138579
Train loss on 1250 batch: 0.161822
Train loss on 1300 batch: 0.128076
Train loss on 1350 batch: 0.127905
Train loss on 1400 batch: 0.124378
Train loss on 1450 batch: 0.122854
Train loss on 1500 batch: 0.117608
Train loss on 1550 batch: 0.118290
Train loss on 1600 batch: 0.163694
Train loss on 1650 batch: 0.134595
Train loss on 1700 batch: 0.145949
Train loss on 1750 batch: 0.149825
Train loss on 1800 batch: 0.150566
Train loss on 1850 batch: 0.147517
Train loss on 1900 batch: 0.171822
Train loss on 1950 batch: 0.144370
Train loss on 2000 batch: 0.156123
Train loss on 2050 batch: 0.132067
Train loss on 2100 batch: 0.137232
Train loss on 2150 batch: 0.150252
: Epoch: 242 | Training Loss: 0.140314 | Val. Loss: 0.344926 | Val. Kappa Score: 0.7276 | LR: 0.000018 | Estimated time: 554.89
Train loss on 50 batch: 0.139787
Train loss on 100 batch: 0.131752
Train loss on 150 batch: 0.145683
Train loss on 200 batch: 0.126452
Train loss on 250 batch: 0.116816
Train loss on 300 batch: 0.154447
Train loss on 350 batch: 0.152401
Train loss on 400 batch: 0.125448
Train loss on 450 batch: 0.143073
Train loss on 500 batch: 0.139624
Train loss on 550 batch: 0.127549
Train loss on 600 batch: 0.143891
Train loss on 650 batch: 0.120383
Train loss on 700 batch: 0.153434
Train loss on 750 batch: 0.145911
Train loss on 800 batch: 0.129228
Train loss on 850 batch: 0.161997
Train loss on 900 batch: 0.121426
Train loss on 950 batch: 0.163143
Train loss on 1000 batch: 0.133906
Train loss on 1050 batch: 0.124729
Train loss on 1100 batch: 0.123998
Train loss on 1150 batch: 0.130755
Train loss on 1200 batch: 0.109090
Train loss on 1250 batch: 0.119201
Train loss on 1300 batch: 0.136104
Train loss on 1350 batch: 0.134357
Train loss on 1400 batch: 0.133195
Train loss on 1450 batch: 0.132518
Train loss on 1500 batch: 0.154023
Train loss on 1550 batch: 0.128097
Train loss on 1600 batch: 0.147458
Train loss on 1650 batch: 0.151431
Train loss on 1700 batch: 0.151016
Train loss on 1750 batch: 0.148053
Train loss on 1800 batch: 0.125007
Train loss on 1850 batch: 0.097955
Train loss on 1900 batch: 0.128016
Train loss on 1950 batch: 0.128912
Train loss on 2000 batch: 0.161683
Train loss on 2050 batch: 0.139412
Train loss on 2100 batch: 0.132546
Train loss on 2150 batch: 0.166580
: Epoch: 243 | Training Loss: 0.136365 | Val. Loss: 0.346981 | Val. Kappa Score: 0.7276 | LR: 0.000008 | Estimated time: 555.08
Train loss on 50 batch: 0.118860
Train loss on 100 batch: 0.139951
Train loss on 150 batch: 0.118406
Train loss on 200 batch: 0.153007
Train loss on 250 batch: 0.148189
Train loss on 300 batch: 0.160664
Train loss on 350 batch: 0.150197
Train loss on 400 batch: 0.170435
Train loss on 450 batch: 0.120520
Train loss on 500 batch: 0.110979
Train loss on 550 batch: 0.120176
Train loss on 600 batch: 0.155249
Train loss on 650 batch: 0.151534
Train loss on 700 batch: 0.127386
Train loss on 750 batch: 0.140933
Train loss on 800 batch: 0.111996
Train loss on 850 batch: 0.151629
Train loss on 900 batch: 0.135632
Train loss on 950 batch: 0.145926
Train loss on 1000 batch: 0.133347
Train loss on 1050 batch: 0.139258
Train loss on 1100 batch: 0.111849
Train loss on 1150 batch: 0.128662
Train loss on 1200 batch: 0.142942
Train loss on 1250 batch: 0.147324
Train loss on 1300 batch: 0.132868
Train loss on 1350 batch: 0.124837
Train loss on 1400 batch: 0.129226
Train loss on 1450 batch: 0.139879
Train loss on 1500 batch: 0.122188
Train loss on 1550 batch: 0.137737
Train loss on 1600 batch: 0.152399
Train loss on 1650 batch: 0.140935
Train loss on 1700 batch: 0.126286
Train loss on 1750 batch: 0.137395
Train loss on 1800 batch: 0.127343
Train loss on 1850 batch: 0.135385
Train loss on 1900 batch: 0.123901
Train loss on 1950 batch: 0.141760
Train loss on 2000 batch: 0.126260
Train loss on 2050 batch: 0.150249
Train loss on 2100 batch: 0.158013
Train loss on 2150 batch: 0.114778
: Epoch: 244 | Training Loss: 0.135488 | Val. Loss: 0.347163 | Val. Kappa Score: 0.7277 | LR: 0.000002 | Estimated time: 555.29
Train loss on 50 batch: 0.146103
Train loss on 100 batch: 0.123872
Train loss on 150 batch: 0.133856
Train loss on 200 batch: 0.124410
Train loss on 250 batch: 0.154711
Train loss on 300 batch: 0.115942
Train loss on 350 batch: 0.129740
Train loss on 400 batch: 0.154358
Train loss on 450 batch: 0.153854
Train loss on 500 batch: 0.142548
Train loss on 550 batch: 0.148230
Train loss on 600 batch: 0.139914
Train loss on 650 batch: 0.134762
Train loss on 700 batch: 0.147073
Train loss on 750 batch: 0.118753
Train loss on 800 batch: 0.146602
Train loss on 850 batch: 0.137052
Train loss on 900 batch: 0.160799
Train loss on 950 batch: 0.142939
Train loss on 1000 batch: 0.139241
Train loss on 1050 batch: 0.130955
Train loss on 1100 batch: 0.123738
Train loss on 1150 batch: 0.141355
Train loss on 1200 batch: 0.133568
Train loss on 1250 batch: 0.151796
Train loss on 1300 batch: 0.143738
Train loss on 1350 batch: 0.142569
Train loss on 1400 batch: 0.148267
Train loss on 1450 batch: 0.127412
Train loss on 1500 batch: 0.134717
Train loss on 1550 batch: 0.152463
Train loss on 1600 batch: 0.134450
Train loss on 1650 batch: 0.129014
Train loss on 1700 batch: 0.111855
Train loss on 1750 batch: 0.149960
Train loss on 1800 batch: 0.155906
Train loss on 1850 batch: 0.149995
Train loss on 1900 batch: 0.125013
Train loss on 1950 batch: 0.133286
Train loss on 2000 batch: 0.135134
Train loss on 2050 batch: 0.139404
Train loss on 2100 batch: 0.155771
Train loss on 2150 batch: 0.114054
: Epoch: 245 | Training Loss: 0.138035 | Val. Loss: 0.349276 | Val. Kappa Score: 0.7278 | LR: 0.000000 | Estimated time: 555.33
Train loss on 50 batch: 0.110521
Train loss on 100 batch: 0.130718
Train loss on 150 batch: 0.131334
Train loss on 200 batch: 0.134952
Train loss on 250 batch: 0.160798
Train loss on 300 batch: 0.128341
Train loss on 350 batch: 0.189513
Train loss on 400 batch: 0.144891
Train loss on 450 batch: 0.130680
Train loss on 500 batch: 0.119038
Train loss on 550 batch: 0.122494
Train loss on 600 batch: 0.150642
Train loss on 650 batch: 0.153120
Train loss on 700 batch: 0.144549
Train loss on 750 batch: 0.128388
Train loss on 800 batch: 0.153131
Train loss on 850 batch: 0.126214
Train loss on 900 batch: 0.124979
Train loss on 950 batch: 0.169262
Train loss on 1000 batch: 0.149473
Train loss on 1050 batch: 0.147729
Train loss on 1100 batch: 0.126554
Train loss on 1150 batch: 0.100930
Train loss on 1200 batch: 0.134183
Train loss on 1250 batch: 0.116227
Train loss on 1300 batch: 0.143359
Train loss on 1350 batch: 0.129174
Train loss on 1400 batch: 0.159631
Train loss on 1450 batch: 0.152601
Train loss on 1500 batch: 0.140541
Train loss on 1550 batch: 0.137290
Train loss on 1600 batch: 0.144392
Train loss on 1650 batch: 0.154303
Train loss on 1700 batch: 0.136711
Train loss on 1750 batch: 0.152707
Train loss on 1800 batch: 0.165223
Train loss on 1850 batch: 0.112362
Train loss on 1900 batch: 0.141969
Train loss on 1950 batch: 0.143138
Train loss on 2000 batch: 0.129827
Train loss on 2050 batch: 0.119880
Train loss on 2100 batch: 0.127027
Train loss on 2150 batch: 0.117364
: Epoch: 246 | Training Loss: 0.137059 | Val. Loss: 0.346959 | Val. Kappa Score: 0.7279 | LR: 0.000002 | Estimated time: 555.06
Train loss on 50 batch: 0.119884
Train loss on 100 batch: 0.136573
Train loss on 150 batch: 0.138759
Train loss on 200 batch: 0.112712
Train loss on 250 batch: 0.127835
Train loss on 300 batch: 0.148351
Train loss on 350 batch: 0.134677
Train loss on 400 batch: 0.139426
Train loss on 450 batch: 0.112810
Train loss on 500 batch: 0.120023
Train loss on 550 batch: 0.143232
Train loss on 600 batch: 0.131407
Train loss on 650 batch: 0.156068
Train loss on 700 batch: 0.148762
Train loss on 750 batch: 0.123988
Train loss on 800 batch: 0.142011
Train loss on 850 batch: 0.142874
Train loss on 900 batch: 0.155667
Train loss on 950 batch: 0.141007
Train loss on 1000 batch: 0.133154
Train loss on 1050 batch: 0.124678
Train loss on 1100 batch: 0.155221
Train loss on 1150 batch: 0.149516
Train loss on 1200 batch: 0.151891
Train loss on 1250 batch: 0.153080
Train loss on 1300 batch: 0.132994
Train loss on 1350 batch: 0.139038
Train loss on 1400 batch: 0.139226
Train loss on 1450 batch: 0.115074
Train loss on 1500 batch: 0.162872
Train loss on 1550 batch: 0.141069
Train loss on 1600 batch: 0.095474
Train loss on 1650 batch: 0.156503
Train loss on 1700 batch: 0.144602
Train loss on 1750 batch: 0.131013
Train loss on 1800 batch: 0.105330
Train loss on 1850 batch: 0.148467
Train loss on 1900 batch: 0.132060
Train loss on 1950 batch: 0.130031
Train loss on 2000 batch: 0.141428
Train loss on 2050 batch: 0.131839
Train loss on 2100 batch: 0.120838
Train loss on 2150 batch: 0.149420
: Epoch: 247 | Training Loss: 0.136696 | Val. Loss: 0.347441 | Val. Kappa Score: 0.7279 | LR: 0.000008 | Estimated time: 555.08
Train loss on 50 batch: 0.138717
Train loss on 100 batch: 0.136710
Train loss on 150 batch: 0.130465
Train loss on 200 batch: 0.143801
Train loss on 250 batch: 0.127911
Train loss on 300 batch: 0.142414
Train loss on 350 batch: 0.146530
Train loss on 400 batch: 0.138042
Train loss on 450 batch: 0.146661
Train loss on 500 batch: 0.134360
Train loss on 550 batch: 0.120941
Train loss on 600 batch: 0.169752
Train loss on 650 batch: 0.135130
Train loss on 700 batch: 0.179074
Train loss on 750 batch: 0.169942
Train loss on 800 batch: 0.130798
Train loss on 850 batch: 0.122917
Train loss on 900 batch: 0.130701
Train loss on 950 batch: 0.110809
Train loss on 1000 batch: 0.130997
Train loss on 1050 batch: 0.125402
Train loss on 1100 batch: 0.125642
Train loss on 1150 batch: 0.164174
Train loss on 1200 batch: 0.122103
Train loss on 1250 batch: 0.139116
Train loss on 1300 batch: 0.127265
Train loss on 1350 batch: 0.123308
Train loss on 1400 batch: 0.123216
Train loss on 1450 batch: 0.133752
Train loss on 1500 batch: 0.166496
Train loss on 1550 batch: 0.154855
Train loss on 1600 batch: 0.139499
Train loss on 1650 batch: 0.136803
Train loss on 1700 batch: 0.109316
Train loss on 1750 batch: 0.135876
Train loss on 1800 batch: 0.146547
Train loss on 1850 batch: 0.158810
Train loss on 1900 batch: 0.131428
Train loss on 1950 batch: 0.102800
Train loss on 2000 batch: 0.125811
Train loss on 2050 batch: 0.142773
Train loss on 2100 batch: 0.098734
Train loss on 2150 batch: 0.130608
: Epoch: 248 | Training Loss: 0.136244 | Val. Loss: 0.347226 | Val. Kappa Score: 0.7280 | LR: 0.000018 | Estimated time: 555.20
Train loss on 50 batch: 0.134080
Train loss on 100 batch: 0.165704
Train loss on 150 batch: 0.147703
Train loss on 200 batch: 0.109746
Train loss on 250 batch: 0.137498
Train loss on 300 batch: 0.115793
Train loss on 350 batch: 0.132631
Train loss on 400 batch: 0.119548
Train loss on 450 batch: 0.159332
Train loss on 500 batch: 0.127601
Train loss on 550 batch: 0.142991
Train loss on 600 batch: 0.134272
Train loss on 650 batch: 0.152560
Train loss on 700 batch: 0.131344
Train loss on 750 batch: 0.133614
Train loss on 800 batch: 0.149122
Train loss on 850 batch: 0.134008
Train loss on 900 batch: 0.151148
Train loss on 950 batch: 0.127061
Train loss on 1000 batch: 0.167572
Train loss on 1050 batch: 0.132168
Train loss on 1100 batch: 0.120012
Train loss on 1150 batch: 0.132713
Train loss on 1200 batch: 0.126468
Train loss on 1250 batch: 0.129518
Train loss on 1300 batch: 0.121261
Train loss on 1350 batch: 0.145384
Train loss on 1400 batch: 0.122695
Train loss on 1450 batch: 0.161362
Train loss on 1500 batch: 0.133287
Train loss on 1550 batch: 0.103900
Train loss on 1600 batch: 0.141887
Train loss on 1650 batch: 0.134424
Train loss on 1700 batch: 0.139000
Train loss on 1750 batch: 0.150174
Train loss on 1800 batch: 0.142188
Train loss on 1850 batch: 0.139511
Train loss on 1900 batch: 0.129850
Train loss on 1950 batch: 0.138564
Train loss on 2000 batch: 0.094916
Train loss on 2050 batch: 0.150764
Train loss on 2100 batch: 0.138278
Train loss on 2150 batch: 0.165322
: Epoch: 249 | Training Loss: 0.136528 | Val. Loss: 0.350023 | Val. Kappa Score: 0.7281 | LR: 0.000032 | Estimated time: 555.30
Train loss on 50 batch: 0.130170
Train loss on 100 batch: 0.111016
Train loss on 150 batch: 0.122331
Train loss on 200 batch: 0.132021
Train loss on 250 batch: 0.128643
Train loss on 300 batch: 0.140294
Train loss on 350 batch: 0.113720
Train loss on 400 batch: 0.128409
Train loss on 450 batch: 0.112155
Train loss on 500 batch: 0.143080
Train loss on 550 batch: 0.123090
Train loss on 600 batch: 0.130953
Train loss on 650 batch: 0.142644
Train loss on 700 batch: 0.128456
Train loss on 750 batch: 0.150506
Train loss on 800 batch: 0.115502
Train loss on 850 batch: 0.126255
Train loss on 900 batch: 0.114150
Train loss on 950 batch: 0.136628
Train loss on 1000 batch: 0.128355
Train loss on 1050 batch: 0.166303
Train loss on 1100 batch: 0.148711
Train loss on 1150 batch: 0.158671
Train loss on 1200 batch: 0.135685
Train loss on 1250 batch: 0.127951
Train loss on 1300 batch: 0.146982
Train loss on 1350 batch: 0.146060
Train loss on 1400 batch: 0.135297
Train loss on 1450 batch: 0.145110
Train loss on 1500 batch: 0.131347
Train loss on 1550 batch: 0.171985
Train loss on 1600 batch: 0.139245
Train loss on 1650 batch: 0.160498
Train loss on 1700 batch: 0.133214
Train loss on 1750 batch: 0.150827
Train loss on 1800 batch: 0.144665
Train loss on 1850 batch: 0.147871
Train loss on 1900 batch: 0.145447
Train loss on 1950 batch: 0.146559
Train loss on 2000 batch: 0.174920
Train loss on 2050 batch: 0.143023
Train loss on 2100 batch: 0.115060
Train loss on 2150 batch: 0.133660
: Epoch: 250 | Training Loss: 0.136749 | Val. Loss: 0.346104 | Val. Kappa Score: 0.7281 | LR: 0.000050 | Estimated time: 555.72
Train loss on 50 batch: 0.151976
Train loss on 100 batch: 0.133943
Train loss on 150 batch: 0.127680
Train loss on 200 batch: 0.160865
Train loss on 250 batch: 0.126318
Train loss on 300 batch: 0.124192
Train loss on 350 batch: 0.134684
Train loss on 400 batch: 0.144096
Train loss on 450 batch: 0.124702
Train loss on 500 batch: 0.117218
Train loss on 550 batch: 0.117632
Train loss on 600 batch: 0.101094
Train loss on 650 batch: 0.157329
Train loss on 700 batch: 0.165812
Train loss on 750 batch: 0.140215
Train loss on 800 batch: 0.138508
Train loss on 850 batch: 0.157148
Train loss on 900 batch: 0.130251
Train loss on 950 batch: 0.103812
Train loss on 1000 batch: 0.180874
Train loss on 1050 batch: 0.126869
Train loss on 1100 batch: 0.141412
Train loss on 1150 batch: 0.159876
Train loss on 1200 batch: 0.159178
Train loss on 1250 batch: 0.161550
Train loss on 1300 batch: 0.151121
Train loss on 1350 batch: 0.139811
Train loss on 1400 batch: 0.097196
Train loss on 1450 batch: 0.134967
Train loss on 1500 batch: 0.148854
Train loss on 1550 batch: 0.135903
Train loss on 1600 batch: 0.140827
Train loss on 1650 batch: 0.125241
Train loss on 1700 batch: 0.108068
Train loss on 1750 batch: 0.146914
Train loss on 1800 batch: 0.131530
Train loss on 1850 batch: 0.128089
Train loss on 1900 batch: 0.121921
Train loss on 1950 batch: 0.141920
Train loss on 2000 batch: 0.134439
Train loss on 2050 batch: 0.101112
Train loss on 2100 batch: 0.149079
Train loss on 2150 batch: 0.151620
: Epoch: 251 | Training Loss: 0.137118 | Val. Loss: 0.343468 | Val. Kappa Score: 0.7281 | LR: 0.000071 | Estimated time: 555.60
Train loss on 50 batch: 0.128708
Train loss on 100 batch: 0.147125
Train loss on 150 batch: 0.132681
Train loss on 200 batch: 0.146931
Train loss on 250 batch: 0.121066
Train loss on 300 batch: 0.122049
Train loss on 350 batch: 0.116498
Train loss on 400 batch: 0.133068
Train loss on 450 batch: 0.124466
Train loss on 500 batch: 0.133169
Train loss on 550 batch: 0.143041
Train loss on 600 batch: 0.156488
Train loss on 650 batch: 0.127847
Train loss on 700 batch: 0.124767
Train loss on 750 batch: 0.141882
Train loss on 800 batch: 0.164960
Train loss on 850 batch: 0.162508
Train loss on 900 batch: 0.170584
Train loss on 950 batch: 0.129456
Train loss on 1000 batch: 0.129458
Train loss on 1050 batch: 0.157083
Train loss on 1100 batch: 0.154198
Train loss on 1150 batch: 0.136996
Train loss on 1200 batch: 0.114188
Train loss on 1250 batch: 0.130531
Train loss on 1300 batch: 0.114733
Train loss on 1350 batch: 0.153183
Train loss on 1400 batch: 0.130072
Train loss on 1450 batch: 0.114154
Train loss on 1500 batch: 0.190267
Train loss on 1550 batch: 0.109766
Train loss on 1600 batch: 0.127496
Train loss on 1650 batch: 0.132431
Train loss on 1700 batch: 0.115675
Train loss on 1750 batch: 0.143460
Train loss on 1800 batch: 0.134214
Train loss on 1850 batch: 0.157514
Train loss on 1900 batch: 0.123889
Train loss on 1950 batch: 0.126788
Train loss on 2000 batch: 0.164072
Train loss on 2050 batch: 0.153829
Train loss on 2100 batch: 0.136670
Train loss on 2150 batch: 0.141452
: Epoch: 252 | Training Loss: 0.137122 | Val. Loss: 0.346375 | Val. Kappa Score: 0.7282 | LR: 0.000095 | Estimated time: 555.36
Train loss on 50 batch: 0.143139
Train loss on 100 batch: 0.126316
Train loss on 150 batch: 0.134465
Train loss on 200 batch: 0.132529
Train loss on 250 batch: 0.132698
Train loss on 300 batch: 0.153657
Train loss on 350 batch: 0.140413
Train loss on 400 batch: 0.146974
Train loss on 450 batch: 0.145097
Train loss on 500 batch: 0.143324
Train loss on 550 batch: 0.161967
Train loss on 600 batch: 0.182632
Train loss on 650 batch: 0.131692
Train loss on 700 batch: 0.137203
Train loss on 750 batch: 0.142424
Train loss on 800 batch: 0.150855
Train loss on 850 batch: 0.125245
Train loss on 900 batch: 0.141306
Train loss on 950 batch: 0.147273
Train loss on 1000 batch: 0.140106
Train loss on 1050 batch: 0.153674
Train loss on 1100 batch: 0.118269
Train loss on 1150 batch: 0.150765
Train loss on 1200 batch: 0.137266
Train loss on 1250 batch: 0.140981
Train loss on 1300 batch: 0.126597
Train loss on 1350 batch: 0.156307
Train loss on 1400 batch: 0.152178
Train loss on 1450 batch: 0.132975
Train loss on 1500 batch: 0.150117
Train loss on 1550 batch: 0.129801
Train loss on 1600 batch: 0.162297
Train loss on 1650 batch: 0.108359
Train loss on 1700 batch: 0.144266
Train loss on 1750 batch: 0.122276
Train loss on 1800 batch: 0.132892
Train loss on 1850 batch: 0.120040
Train loss on 1900 batch: 0.168926
Train loss on 1950 batch: 0.130305
Train loss on 2000 batch: 0.122403
Train loss on 2050 batch: 0.127182
Train loss on 2100 batch: 0.142841
Train loss on 2150 batch: 0.125687
: Epoch: 253 | Training Loss: 0.139656 | Val. Loss: 0.346599 | Val. Kappa Score: 0.7282 | LR: 0.000123 | Estimated time: 555.14
Train loss on 50 batch: 0.142102
Train loss on 100 batch: 0.090425
Train loss on 150 batch: 0.132234
Train loss on 200 batch: 0.123307
Train loss on 250 batch: 0.114230
Train loss on 300 batch: 0.157044
Train loss on 350 batch: 0.124849
Train loss on 400 batch: 0.103566
Train loss on 450 batch: 0.136272
Train loss on 500 batch: 0.141446
Train loss on 550 batch: 0.131229
Train loss on 600 batch: 0.130922
Train loss on 650 batch: 0.142872
Train loss on 700 batch: 0.128042
Train loss on 750 batch: 0.136607
Train loss on 800 batch: 0.154934
Train loss on 850 batch: 0.161753
Train loss on 900 batch: 0.166441
Train loss on 950 batch: 0.125940
Train loss on 1000 batch: 0.127179
Train loss on 1050 batch: 0.110449
Train loss on 1100 batch: 0.087397
Train loss on 1150 batch: 0.134851
Train loss on 1200 batch: 0.198930
Train loss on 1250 batch: 0.134333
Train loss on 1300 batch: 0.151642
Train loss on 1350 batch: 0.173016
Train loss on 1400 batch: 0.141735
Train loss on 1450 batch: 0.166472
Train loss on 1500 batch: 0.116512
Train loss on 1550 batch: 0.141110
Train loss on 1600 batch: 0.172306
Train loss on 1650 batch: 0.140923
Train loss on 1700 batch: 0.128938
Train loss on 1750 batch: 0.114596
Train loss on 1800 batch: 0.129571
Train loss on 1850 batch: 0.163499
Train loss on 1900 batch: 0.171924
Train loss on 1950 batch: 0.178821
Train loss on 2000 batch: 0.156606
Train loss on 2050 batch: 0.147245
Train loss on 2100 batch: 0.139837
Train loss on 2150 batch: 0.131604
: Epoch: 254 | Training Loss: 0.138893 | Val. Loss: 0.347565 | Val. Kappa Score: 0.7283 | LR: 0.000154 | Estimated time: 555.42
Train loss on 50 batch: 0.118510
Train loss on 100 batch: 0.116710
Train loss on 150 batch: 0.156795
Train loss on 200 batch: 0.176009
Train loss on 250 batch: 0.129488
Train loss on 300 batch: 0.146467
Train loss on 350 batch: 0.118876
Train loss on 400 batch: 0.143675
Train loss on 450 batch: 0.139216
Train loss on 500 batch: 0.144806
Train loss on 550 batch: 0.142412
Train loss on 600 batch: 0.158307
Train loss on 650 batch: 0.149241
Train loss on 700 batch: 0.155953
Train loss on 750 batch: 0.143711
Train loss on 800 batch: 0.115464
Train loss on 850 batch: 0.111569
Train loss on 900 batch: 0.134176
Train loss on 950 batch: 0.136135
Train loss on 1000 batch: 0.176244
Train loss on 1050 batch: 0.109844
Train loss on 1100 batch: 0.160408
Train loss on 1150 batch: 0.129846
Train loss on 1200 batch: 0.112145
Train loss on 1250 batch: 0.161764
Train loss on 1300 batch: 0.149429
Train loss on 1350 batch: 0.149573
Train loss on 1400 batch: 0.143247
Train loss on 1450 batch: 0.102237
Train loss on 1500 batch: 0.139365
Train loss on 1550 batch: 0.169420
Train loss on 1600 batch: 0.128127
Train loss on 1650 batch: 0.145630
Train loss on 1700 batch: 0.141600
Train loss on 1750 batch: 0.148501
Train loss on 1800 batch: 0.143180
Train loss on 1850 batch: 0.141656
Train loss on 1900 batch: 0.125720
Train loss on 1950 batch: 0.142466
Train loss on 2000 batch: 0.114367
Train loss on 2050 batch: 0.141213
Train loss on 2100 batch: 0.118192
Train loss on 2150 batch: 0.138215
: Epoch: 255 | Training Loss: 0.138786 | Val. Loss: 0.354494 | Val. Kappa Score: 0.7284 | LR: 0.000188 | Estimated time: 555.25
Train loss on 50 batch: 0.157089
Train loss on 100 batch: 0.126326
Train loss on 150 batch: 0.120838
Train loss on 200 batch: 0.145740
Train loss on 250 batch: 0.161353
Train loss on 300 batch: 0.143005
Train loss on 350 batch: 0.127231
Train loss on 400 batch: 0.152653
Train loss on 450 batch: 0.152537
Train loss on 500 batch: 0.129449
Train loss on 550 batch: 0.134138
Train loss on 600 batch: 0.131946
Train loss on 650 batch: 0.151088
Train loss on 700 batch: 0.152403
Train loss on 750 batch: 0.163650
Train loss on 800 batch: 0.125188
Train loss on 850 batch: 0.128566
Train loss on 900 batch: 0.155234
Train loss on 950 batch: 0.130578
Train loss on 1000 batch: 0.156075
Train loss on 1050 batch: 0.128742
Train loss on 1100 batch: 0.146490
Train loss on 1150 batch: 0.152313
Train loss on 1200 batch: 0.153234
Train loss on 1250 batch: 0.173927
Train loss on 1300 batch: 0.135804
Train loss on 1350 batch: 0.140269
Train loss on 1400 batch: 0.145199
Train loss on 1450 batch: 0.124049
Train loss on 1500 batch: 0.153757
Train loss on 1550 batch: 0.143808
Train loss on 1600 batch: 0.134988
Train loss on 1650 batch: 0.129958
Train loss on 1700 batch: 0.133999
Train loss on 1750 batch: 0.150011
Train loss on 1800 batch: 0.141414
Train loss on 1850 batch: 0.143212
Train loss on 1900 batch: 0.135969
Train loss on 1950 batch: 0.143419
Train loss on 2000 batch: 0.127251
Train loss on 2050 batch: 0.171993
Train loss on 2100 batch: 0.155052
Train loss on 2150 batch: 0.151967
: Epoch: 256 | Training Loss: 0.142652 | Val. Loss: 0.358164 | Val. Kappa Score: 0.7284 | LR: 0.000225 | Estimated time: 555.38
Train loss on 50 batch: 0.191768
Train loss on 100 batch: 0.159893
Train loss on 150 batch: 0.117809
Train loss on 200 batch: 0.131274
Train loss on 250 batch: 0.140395
Train loss on 300 batch: 0.123374
Train loss on 350 batch: 0.154372
Train loss on 400 batch: 0.132137
Train loss on 450 batch: 0.143918
Train loss on 500 batch: 0.141054
Train loss on 550 batch: 0.132020
Train loss on 600 batch: 0.133729
Train loss on 650 batch: 0.169506
Train loss on 700 batch: 0.153904
Train loss on 750 batch: 0.137060
Train loss on 800 batch: 0.137550
Train loss on 850 batch: 0.173539
Train loss on 900 batch: 0.122682
Train loss on 950 batch: 0.177687
Train loss on 1000 batch: 0.140358
Train loss on 1050 batch: 0.156762
Train loss on 1100 batch: 0.157430
Train loss on 1150 batch: 0.152797
Train loss on 1200 batch: 0.100975
Train loss on 1250 batch: 0.169918
Train loss on 1300 batch: 0.170343
Train loss on 1350 batch: 0.155697
Train loss on 1400 batch: 0.124156
Train loss on 1450 batch: 0.161493
Train loss on 1500 batch: 0.136296
Train loss on 1550 batch: 0.141867
Train loss on 1600 batch: 0.143681
Train loss on 1650 batch: 0.156322
Train loss on 1700 batch: 0.101671
Train loss on 1750 batch: 0.152174
Train loss on 1800 batch: 0.108710
Train loss on 1850 batch: 0.168352
Train loss on 1900 batch: 0.134673
Train loss on 1950 batch: 0.155472
Train loss on 2000 batch: 0.136744
Train loss on 2050 batch: 0.171442
Train loss on 2100 batch: 0.142858
Train loss on 2150 batch: 0.139454
: Epoch: 257 | Training Loss: 0.144876 | Val. Loss: 0.353747 | Val. Kappa Score: 0.7284 | LR: 0.000263 | Estimated time: 555.39
Train loss on 50 batch: 0.154520
Train loss on 100 batch: 0.117472
Train loss on 150 batch: 0.144914
Train loss on 200 batch: 0.130425
Train loss on 250 batch: 0.127991
Train loss on 300 batch: 0.179866
Train loss on 350 batch: 0.161027
Train loss on 400 batch: 0.146808
Train loss on 450 batch: 0.177805
Train loss on 500 batch: 0.158252
Train loss on 550 batch: 0.143115
Train loss on 600 batch: 0.151697
Train loss on 650 batch: 0.160954
Train loss on 700 batch: 0.173779
Train loss on 750 batch: 0.145136
Train loss on 800 batch: 0.149775
Train loss on 850 batch: 0.152621
Train loss on 900 batch: 0.141683
Train loss on 950 batch: 0.112862
Train loss on 1000 batch: 0.136853
Train loss on 1050 batch: 0.164358
Train loss on 1100 batch: 0.102156
Train loss on 1150 batch: 0.139491
Train loss on 1200 batch: 0.150647
Train loss on 1250 batch: 0.145639
Train loss on 1300 batch: 0.139704
Train loss on 1350 batch: 0.163964
Train loss on 1400 batch: 0.134718
Train loss on 1450 batch: 0.156993
Train loss on 1500 batch: 0.170678
Train loss on 1550 batch: 0.164902
Train loss on 1600 batch: 0.144573
Train loss on 1650 batch: 0.124072
Train loss on 1700 batch: 0.151041
Train loss on 1750 batch: 0.122859
Train loss on 1800 batch: 0.154002
Train loss on 1850 batch: 0.163906
Train loss on 1900 batch: 0.118743
Train loss on 1950 batch: 0.156243
Train loss on 2000 batch: 0.164281
Train loss on 2050 batch: 0.157241
Train loss on 2100 batch: 0.187203
Train loss on 2150 batch: 0.142528
: Epoch: 258 | Training Loss: 0.148548 | Val. Loss: 0.345870 | Val. Kappa Score: 0.7285 | LR: 0.000303 | Estimated time: 555.29
Train loss on 50 batch: 0.127587
Train loss on 100 batch: 0.154021
Train loss on 150 batch: 0.141844
Train loss on 200 batch: 0.159866
Train loss on 250 batch: 0.130932
Train loss on 300 batch: 0.129546
Train loss on 350 batch: 0.169219
Train loss on 400 batch: 0.139131
Train loss on 450 batch: 0.103262
Train loss on 500 batch: 0.151468
Train loss on 550 batch: 0.140955
Train loss on 600 batch: 0.148648
Train loss on 650 batch: 0.109972
Train loss on 700 batch: 0.153033
Train loss on 750 batch: 0.143553
Train loss on 800 batch: 0.141872
Train loss on 850 batch: 0.125462
Train loss on 900 batch: 0.166047
Train loss on 950 batch: 0.141435
Train loss on 1000 batch: 0.173108
Train loss on 1050 batch: 0.142370
Train loss on 1100 batch: 0.142373
Train loss on 1150 batch: 0.137600
Train loss on 1200 batch: 0.127514
Train loss on 1250 batch: 0.175413
Train loss on 1300 batch: 0.154750
Train loss on 1350 batch: 0.156993
Train loss on 1400 batch: 0.173178
Train loss on 1450 batch: 0.175707
Train loss on 1500 batch: 0.160942
Train loss on 1550 batch: 0.131744
Train loss on 1600 batch: 0.170826
Train loss on 1650 batch: 0.153347
Train loss on 1700 batch: 0.146035
Train loss on 1750 batch: 0.138284
Train loss on 1800 batch: 0.145848
Train loss on 1850 batch: 0.143014
Train loss on 1900 batch: 0.153218
Train loss on 1950 batch: 0.169417
Train loss on 2000 batch: 0.162290
Train loss on 2050 batch: 0.133039
Train loss on 2100 batch: 0.157811
Train loss on 2150 batch: 0.173181
: Epoch: 259 | Training Loss: 0.148548 | Val. Loss: 0.360302 | Val. Kappa Score: 0.7285 | LR: 0.000345 | Estimated time: 555.12
Train loss on 50 batch: 0.180463
Train loss on 100 batch: 0.170622
Train loss on 150 batch: 0.155891
Train loss on 200 batch: 0.150353
Train loss on 250 batch: 0.140622
Train loss on 300 batch: 0.144540
Train loss on 350 batch: 0.150049
Train loss on 400 batch: 0.120784
Train loss on 450 batch: 0.150253
Train loss on 500 batch: 0.130262
Train loss on 550 batch: 0.129894
Train loss on 600 batch: 0.165673
Train loss on 650 batch: 0.133461
Train loss on 700 batch: 0.190507
Train loss on 750 batch: 0.176820
Train loss on 800 batch: 0.177725
Train loss on 850 batch: 0.123318
Train loss on 900 batch: 0.166899
Train loss on 950 batch: 0.124310
Train loss on 1000 batch: 0.178445
Train loss on 1050 batch: 0.204073
Train loss on 1100 batch: 0.130731
Train loss on 1150 batch: 0.137100
Train loss on 1200 batch: 0.166548
Train loss on 1250 batch: 0.148726
Train loss on 1300 batch: 0.149350
Train loss on 1350 batch: 0.163703
Train loss on 1400 batch: 0.155968
Train loss on 1450 batch: 0.164347
Train loss on 1500 batch: 0.161927
Train loss on 1550 batch: 0.164224
Train loss on 1600 batch: 0.142605
Train loss on 1650 batch: 0.147993
Train loss on 1700 batch: 0.180120
Train loss on 1750 batch: 0.149773
Train loss on 1800 batch: 0.156824
Train loss on 1850 batch: 0.145752
Train loss on 1900 batch: 0.136925
Train loss on 1950 batch: 0.192645
Train loss on 2000 batch: 0.165984
Train loss on 2050 batch: 0.142107
Train loss on 2100 batch: 0.153482
Train loss on 2150 batch: 0.145816
: Epoch: 260 | Training Loss: 0.154378 | Val. Loss: 0.362059 | Val. Kappa Score: 0.7285 | LR: 0.000389 | Estimated time: 555.18
Train loss on 50 batch: 0.131816
Train loss on 100 batch: 0.132299
Train loss on 150 batch: 0.154182
Train loss on 200 batch: 0.137761
Train loss on 250 batch: 0.162338
Train loss on 300 batch: 0.141732
Train loss on 350 batch: 0.125139
Train loss on 400 batch: 0.172692
Train loss on 450 batch: 0.160611
Train loss on 500 batch: 0.175387
Train loss on 550 batch: 0.166891
Train loss on 600 batch: 0.122884
Train loss on 650 batch: 0.149746
Train loss on 700 batch: 0.114385
Train loss on 750 batch: 0.157922
Train loss on 800 batch: 0.167596
Train loss on 850 batch: 0.166110
Train loss on 900 batch: 0.170049
Train loss on 950 batch: 0.160116
Train loss on 1000 batch: 0.162534
Train loss on 1050 batch: 0.175611
Train loss on 1100 batch: 0.203606
Train loss on 1150 batch: 0.174175
Train loss on 1200 batch: 0.186320
Train loss on 1250 batch: 0.158275
Train loss on 1300 batch: 0.149272
Train loss on 1350 batch: 0.144921
Train loss on 1400 batch: 0.167391
Train loss on 1450 batch: 0.183223
Train loss on 1500 batch: 0.193092
Train loss on 1550 batch: 0.184348
Train loss on 1600 batch: 0.141348
Train loss on 1650 batch: 0.162659
Train loss on 1700 batch: 0.160313
Train loss on 1750 batch: 0.159105
Train loss on 1800 batch: 0.163484
Train loss on 1850 batch: 0.134511
Train loss on 1900 batch: 0.145646
Train loss on 1950 batch: 0.170946
Train loss on 2000 batch: 0.152018
Train loss on 2050 batch: 0.175176
Train loss on 2100 batch: 0.190800
Train loss on 2150 batch: 0.128956
: Epoch: 261 | Training Loss: 0.159241 | Val. Loss: 0.337970 | Val. Kappa Score: 0.7285 | LR: 0.000433 | Estimated time: 555.28
Train loss on 50 batch: 0.169643
Train loss on 100 batch: 0.168061
Train loss on 150 batch: 0.202461
Train loss on 200 batch: 0.143078
Train loss on 250 batch: 0.136179
Train loss on 300 batch: 0.141313
Train loss on 350 batch: 0.140172
Train loss on 400 batch: 0.147436
Train loss on 450 batch: 0.180805
Train loss on 500 batch: 0.143682
Train loss on 550 batch: 0.157536
Train loss on 600 batch: 0.140968
Train loss on 650 batch: 0.164464
Train loss on 700 batch: 0.132204
Train loss on 750 batch: 0.173984
Train loss on 800 batch: 0.140984
Train loss on 850 batch: 0.151330
Train loss on 900 batch: 0.167789
Train loss on 950 batch: 0.168105
Train loss on 1000 batch: 0.157406
Train loss on 1050 batch: 0.195609
Train loss on 1100 batch: 0.190752
Train loss on 1150 batch: 0.134756
Train loss on 1200 batch: 0.169491
Train loss on 1250 batch: 0.145152
Train loss on 1300 batch: 0.157078
Train loss on 1350 batch: 0.146311
Train loss on 1400 batch: 0.151020
Train loss on 1450 batch: 0.150399
Train loss on 1500 batch: 0.215819
Train loss on 1550 batch: 0.168377
Train loss on 1600 batch: 0.175415
Train loss on 1650 batch: 0.149757
Train loss on 1700 batch: 0.167134
Train loss on 1750 batch: 0.174936
Train loss on 1800 batch: 0.163273
Train loss on 1850 batch: 0.144349
Train loss on 1900 batch: 0.124433
Train loss on 1950 batch: 0.177765
Train loss on 2000 batch: 0.187323
Train loss on 2050 batch: 0.149519
Train loss on 2100 batch: 0.181276
Train loss on 2150 batch: 0.140491
: Epoch: 262 | Training Loss: 0.160261 | Val. Loss: 0.353804 | Val. Kappa Score: 0.7286 | LR: 0.000478 | Estimated time: 554.72
Train loss on 50 batch: 0.156007
Train loss on 100 batch: 0.170980
Train loss on 150 batch: 0.170555
Train loss on 200 batch: 0.167137
Train loss on 250 batch: 0.139873
Train loss on 300 batch: 0.192078
Train loss on 350 batch: 0.159811
Train loss on 400 batch: 0.154801
Train loss on 450 batch: 0.149199
Train loss on 500 batch: 0.166007
Train loss on 550 batch: 0.146398
Train loss on 600 batch: 0.138963
Train loss on 650 batch: 0.122527
Train loss on 700 batch: 0.172744
Train loss on 750 batch: 0.192378
Train loss on 800 batch: 0.160810
Train loss on 850 batch: 0.177982
Train loss on 900 batch: 0.146074
Train loss on 950 batch: 0.158390
Train loss on 1000 batch: 0.172934
Train loss on 1050 batch: 0.168117
Train loss on 1100 batch: 0.180817
Train loss on 1150 batch: 0.153494
Train loss on 1200 batch: 0.149328
Train loss on 1250 batch: 0.151780
Train loss on 1300 batch: 0.181165
Train loss on 1350 batch: 0.150799
Train loss on 1400 batch: 0.160597
Train loss on 1450 batch: 0.206366
Train loss on 1500 batch: 0.187805
Train loss on 1550 batch: 0.173233
Train loss on 1600 batch: 0.156547
Train loss on 1650 batch: 0.188714
Train loss on 1700 batch: 0.153013
Train loss on 1750 batch: 0.172569
Train loss on 1800 batch: 0.207538
Train loss on 1850 batch: 0.182288
Train loss on 1900 batch: 0.154576
Train loss on 1950 batch: 0.179012
Train loss on 2000 batch: 0.182560
Train loss on 2050 batch: 0.134832
Train loss on 2100 batch: 0.190117
Train loss on 2150 batch: 0.192268
: Epoch: 263 | Training Loss: 0.166998 | Val. Loss: 0.336897 | Val. Kappa Score: 0.7287 | LR: 0.000522 | Estimated time: 555.20
Train loss on 50 batch: 0.137828
Train loss on 100 batch: 0.171246
Train loss on 150 batch: 0.203552
Train loss on 200 batch: 0.149252
Train loss on 250 batch: 0.179991
Train loss on 300 batch: 0.150304
Train loss on 350 batch: 0.161046
Train loss on 400 batch: 0.175111
Train loss on 450 batch: 0.170401
Train loss on 500 batch: 0.153569
Train loss on 550 batch: 0.177850
Train loss on 600 batch: 0.146168
Train loss on 650 batch: 0.169532
Train loss on 700 batch: 0.187065
Train loss on 750 batch: 0.171581
Train loss on 800 batch: 0.172962
Train loss on 850 batch: 0.181808
Train loss on 900 batch: 0.182624
Train loss on 950 batch: 0.190157
Train loss on 1000 batch: 0.142297
Train loss on 1050 batch: 0.189128
Train loss on 1100 batch: 0.177212
Train loss on 1150 batch: 0.163009
Train loss on 1200 batch: 0.164382
Train loss on 1250 batch: 0.165470
Train loss on 1300 batch: 0.156824
Train loss on 1350 batch: 0.173726
Train loss on 1400 batch: 0.162367
Train loss on 1450 batch: 0.182552
Train loss on 1500 batch: 0.175685
Train loss on 1550 batch: 0.163708
Train loss on 1600 batch: 0.167335
Train loss on 1650 batch: 0.135475
Train loss on 1700 batch: 0.162922
Train loss on 1750 batch: 0.165304
Train loss on 1800 batch: 0.191518
Train loss on 1850 batch: 0.146089
Train loss on 1900 batch: 0.141295
Train loss on 1950 batch: 0.185969
Train loss on 2000 batch: 0.197893
Train loss on 2050 batch: 0.173941
Train loss on 2100 batch: 0.189546
Train loss on 2150 batch: 0.144698
: Epoch: 264 | Training Loss: 0.168081 | Val. Loss: 0.382579 | Val. Kappa Score: 0.7287 | LR: 0.000567 | Estimated time: 555.11
Train loss on 50 batch: 0.139766
Train loss on 100 batch: 0.170281
Train loss on 150 batch: 0.128298
Train loss on 200 batch: 0.182904
Train loss on 250 batch: 0.149492
Train loss on 300 batch: 0.179139
Train loss on 350 batch: 0.144672
Train loss on 400 batch: 0.168084
Train loss on 450 batch: 0.153381
Train loss on 500 batch: 0.164984
Train loss on 550 batch: 0.200045
Train loss on 600 batch: 0.148897
Train loss on 650 batch: 0.147218
Train loss on 700 batch: 0.159067
Train loss on 750 batch: 0.178320
Train loss on 800 batch: 0.202378
Train loss on 850 batch: 0.204886
Train loss on 900 batch: 0.191818
Train loss on 950 batch: 0.228429
Train loss on 1000 batch: 0.172755
Train loss on 1050 batch: 0.177454
Train loss on 1100 batch: 0.135731
Train loss on 1150 batch: 0.192189
Train loss on 1200 batch: 0.177151
Train loss on 1250 batch: 0.182019
Train loss on 1300 batch: 0.190761
Train loss on 1350 batch: 0.214656
Train loss on 1400 batch: 0.204873
Train loss on 1450 batch: 0.191629
Train loss on 1500 batch: 0.171374
Train loss on 1550 batch: 0.244069
Train loss on 1600 batch: 0.172879
Train loss on 1650 batch: 0.171851
Train loss on 1700 batch: 0.131980
Train loss on 1750 batch: 0.198403
Train loss on 1800 batch: 0.178610
Train loss on 1850 batch: 0.201413
Train loss on 1900 batch: 0.167417
Train loss on 1950 batch: 0.165157
Train loss on 2000 batch: 0.196661
Train loss on 2050 batch: 0.162033
Train loss on 2100 batch: 0.170612
Train loss on 2150 batch: 0.167540
: Epoch: 265 | Training Loss: 0.177010 | Val. Loss: 0.353858 | Val. Kappa Score: 0.7287 | LR: 0.000611 | Estimated time: 555.13
Train loss on 50 batch: 0.194652
Train loss on 100 batch: 0.151357
Train loss on 150 batch: 0.145870
Train loss on 200 batch: 0.172218
Train loss on 250 batch: 0.153603
Train loss on 300 batch: 0.171528
Train loss on 350 batch: 0.167596
Train loss on 400 batch: 0.202791
Train loss on 450 batch: 0.201165
Train loss on 500 batch: 0.180924
Train loss on 550 batch: 0.168972
Train loss on 600 batch: 0.166297
Train loss on 650 batch: 0.169522
Train loss on 700 batch: 0.179411
Train loss on 750 batch: 0.200925
Train loss on 800 batch: 0.227569
Train loss on 850 batch: 0.225356
Train loss on 900 batch: 0.184597
Train loss on 950 batch: 0.188146
Train loss on 1000 batch: 0.155824
Train loss on 1050 batch: 0.190903
Train loss on 1100 batch: 0.183072
Train loss on 1150 batch: 0.161080
Train loss on 1200 batch: 0.171992
Train loss on 1250 batch: 0.156764
Train loss on 1300 batch: 0.216388
Train loss on 1350 batch: 0.190592
Train loss on 1400 batch: 0.200758
Train loss on 1450 batch: 0.174408
Train loss on 1500 batch: 0.215370
Train loss on 1550 batch: 0.209201
Train loss on 1600 batch: 0.187132
Train loss on 1650 batch: 0.175347
Train loss on 1700 batch: 0.176760
Train loss on 1750 batch: 0.194604
Train loss on 1800 batch: 0.169090
Train loss on 1850 batch: 0.163940
Train loss on 1900 batch: 0.158501
Train loss on 1950 batch: 0.205744
Train loss on 2000 batch: 0.156591
Train loss on 2050 batch: 0.161310
Train loss on 2100 batch: 0.158741
Train loss on 2150 batch: 0.178591
: Epoch: 266 | Training Loss: 0.181097 | Val. Loss: 0.351740 | Val. Kappa Score: 0.7288 | LR: 0.000655 | Estimated time: 555.27
Train loss on 50 batch: 0.172127
Train loss on 100 batch: 0.188756
Train loss on 150 batch: 0.149088
Train loss on 200 batch: 0.196019
Train loss on 250 batch: 0.178264
Train loss on 300 batch: 0.249265
Train loss on 350 batch: 0.186440
Train loss on 400 batch: 0.180367
Train loss on 450 batch: 0.169561
Train loss on 500 batch: 0.201496
Train loss on 550 batch: 0.176330
Train loss on 600 batch: 0.171973
Train loss on 650 batch: 0.188557
Train loss on 700 batch: 0.217854
Train loss on 750 batch: 0.162672
Train loss on 800 batch: 0.187610
Train loss on 850 batch: 0.175228
Train loss on 900 batch: 0.194090
Train loss on 950 batch: 0.187178
Train loss on 1000 batch: 0.185818
Train loss on 1050 batch: 0.172602
Train loss on 1100 batch: 0.140121
Train loss on 1150 batch: 0.188833
Train loss on 1200 batch: 0.182230
Train loss on 1250 batch: 0.218731
Train loss on 1300 batch: 0.180168
Train loss on 1350 batch: 0.180187
Train loss on 1400 batch: 0.175177
Train loss on 1450 batch: 0.203927
Train loss on 1500 batch: 0.183576
Train loss on 1550 batch: 0.160713
Train loss on 1600 batch: 0.246126
Train loss on 1650 batch: 0.230513
Train loss on 1700 batch: 0.197047
Train loss on 1750 batch: 0.196748
Train loss on 1800 batch: 0.157894
Train loss on 1850 batch: 0.180028
Train loss on 1900 batch: 0.181244
Train loss on 1950 batch: 0.163631
Train loss on 2000 batch: 0.158663
Train loss on 2050 batch: 0.162496
Train loss on 2100 batch: 0.260162
Train loss on 2150 batch: 0.165914
: Epoch: 267 | Training Loss: 0.186121 | Val. Loss: 0.384143 | Val. Kappa Score: 0.7287 | LR: 0.000697 | Estimated time: 555.22
Train loss on 50 batch: 0.165818
Train loss on 100 batch: 0.163841
Train loss on 150 batch: 0.168417
Train loss on 200 batch: 0.164041
Train loss on 250 batch: 0.179901
Train loss on 300 batch: 0.118573
Train loss on 350 batch: 0.165657
Train loss on 400 batch: 0.170023
Train loss on 450 batch: 0.192017
Train loss on 500 batch: 0.186537
Train loss on 550 batch: 0.182231
Train loss on 600 batch: 0.195942
Train loss on 650 batch: 0.187306
Train loss on 700 batch: 0.182786
Train loss on 750 batch: 0.189797
Train loss on 800 batch: 0.173880
Train loss on 850 batch: 0.148490
Train loss on 900 batch: 0.190840
Train loss on 950 batch: 0.196385
Train loss on 1000 batch: 0.197226
Train loss on 1050 batch: 0.198731
Train loss on 1100 batch: 0.182314
Train loss on 1150 batch: 0.181915
Train loss on 1200 batch: 0.215341
Train loss on 1250 batch: 0.216093
Train loss on 1300 batch: 0.239694
Train loss on 1350 batch: 0.189381
Train loss on 1400 batch: 0.190938
Train loss on 1450 batch: 0.180915
Train loss on 1500 batch: 0.206123
Train loss on 1550 batch: 0.230723
Train loss on 1600 batch: 0.237840
Train loss on 1650 batch: 0.181166
Train loss on 1700 batch: 0.217875
Train loss on 1750 batch: 0.215766
Train loss on 1800 batch: 0.192802
Train loss on 1850 batch: 0.212861
Train loss on 1900 batch: 0.191923
Train loss on 1950 batch: 0.211616
Train loss on 2000 batch: 0.192936
Train loss on 2050 batch: 0.210911
Train loss on 2100 batch: 0.173359
Train loss on 2150 batch: 0.215238
: Epoch: 268 | Training Loss: 0.190089 | Val. Loss: 0.360050 | Val. Kappa Score: 0.7288 | LR: 0.000737 | Estimated time: 555.30
Train loss on 50 batch: 0.193855
Train loss on 100 batch: 0.197921
Train loss on 150 batch: 0.179406
Train loss on 200 batch: 0.179053
Train loss on 250 batch: 0.180463
Train loss on 300 batch: 0.173487
Train loss on 350 batch: 0.185687
Train loss on 400 batch: 0.194472
Train loss on 450 batch: 0.156189
Train loss on 500 batch: 0.147628
Train loss on 550 batch: 0.169661
Train loss on 600 batch: 0.177636
Train loss on 650 batch: 0.182002
Train loss on 700 batch: 0.181750
Train loss on 750 batch: 0.180262
Train loss on 800 batch: 0.182418
Train loss on 850 batch: 0.208853
Train loss on 900 batch: 0.190894
Train loss on 950 batch: 0.187430
Train loss on 1000 batch: 0.214377
Train loss on 1050 batch: 0.199264
Train loss on 1100 batch: 0.188230
Train loss on 1150 batch: 0.198675
Train loss on 1200 batch: 0.209095
Train loss on 1250 batch: 0.179408
Train loss on 1300 batch: 0.188087
Train loss on 1350 batch: 0.185050
Train loss on 1400 batch: 0.198416
Train loss on 1450 batch: 0.238873
Train loss on 1500 batch: 0.176750
Train loss on 1550 batch: 0.201247
Train loss on 1600 batch: 0.235424
Train loss on 1650 batch: 0.197393
Train loss on 1700 batch: 0.182943
Train loss on 1750 batch: 0.193207
Train loss on 1800 batch: 0.186647
Train loss on 1850 batch: 0.222073
Train loss on 1900 batch: 0.206404
Train loss on 1950 batch: 0.237495
Train loss on 2000 batch: 0.198059
Train loss on 2050 batch: 0.236089
Train loss on 2100 batch: 0.189265
Train loss on 2150 batch: 0.230593
: Epoch: 269 | Training Loss: 0.193688 | Val. Loss: 0.376477 | Val. Kappa Score: 0.7288 | LR: 0.000775 | Estimated time: 554.92
Train loss on 50 batch: 0.172613
Train loss on 100 batch: 0.177276
Train loss on 150 batch: 0.194997
Train loss on 200 batch: 0.191888
Train loss on 250 batch: 0.241672
Train loss on 300 batch: 0.206847
Train loss on 350 batch: 0.222154
Train loss on 400 batch: 0.181394
Train loss on 450 batch: 0.186906
Train loss on 500 batch: 0.216331
Train loss on 550 batch: 0.208773
Train loss on 600 batch: 0.211236
Train loss on 650 batch: 0.198607
Train loss on 700 batch: 0.210219
Train loss on 750 batch: 0.213287
Train loss on 800 batch: 0.180258
Train loss on 850 batch: 0.223855
Train loss on 900 batch: 0.202910
Train loss on 950 batch: 0.197334
Train loss on 1000 batch: 0.229769
Train loss on 1050 batch: 0.203001
Train loss on 1100 batch: 0.255397
Train loss on 1150 batch: 0.194372
Train loss on 1200 batch: 0.181834
Train loss on 1250 batch: 0.217552
Train loss on 1300 batch: 0.209403
Train loss on 1350 batch: 0.185291
Train loss on 1400 batch: 0.210693
Train loss on 1450 batch: 0.186298
Train loss on 1500 batch: 0.217901
Train loss on 1550 batch: 0.203809
Train loss on 1600 batch: 0.173489
Train loss on 1650 batch: 0.181985
Train loss on 1700 batch: 0.230123
Train loss on 1750 batch: 0.223421
Train loss on 1800 batch: 0.198667
Train loss on 1850 batch: 0.204965
Train loss on 1900 batch: 0.178315
Train loss on 1950 batch: 0.204887
Train loss on 2000 batch: 0.185449
Train loss on 2050 batch: 0.194068
Train loss on 2100 batch: 0.202981
Train loss on 2150 batch: 0.194163
: Epoch: 270 | Training Loss: 0.203168 | Val. Loss: 0.376553 | Val. Kappa Score: 0.7288 | LR: 0.000812 | Estimated time: 555.19
Train loss on 50 batch: 0.179088
Train loss on 100 batch: 0.225507
Train loss on 150 batch: 0.175653
Train loss on 200 batch: 0.203398
Train loss on 250 batch: 0.200560
Train loss on 300 batch: 0.221569
Train loss on 350 batch: 0.229650
Train loss on 400 batch: 0.171112
Train loss on 450 batch: 0.202062
Train loss on 500 batch: 0.207118
Train loss on 550 batch: 0.192885
Train loss on 600 batch: 0.198198
Train loss on 650 batch: 0.176290
Train loss on 700 batch: 0.174419
Train loss on 750 batch: 0.196922
Train loss on 800 batch: 0.233076
Train loss on 850 batch: 0.212448
Train loss on 900 batch: 0.211346
Train loss on 950 batch: 0.208080
Train loss on 1000 batch: 0.229466
Train loss on 1050 batch: 0.203275
Train loss on 1100 batch: 0.177956
Train loss on 1150 batch: 0.205278
Train loss on 1200 batch: 0.182821
Train loss on 1250 batch: 0.232629
Train loss on 1300 batch: 0.198814
Train loss on 1350 batch: 0.221202
Train loss on 1400 batch: 0.182738
Train loss on 1450 batch: 0.187369
Train loss on 1500 batch: 0.195748
Train loss on 1550 batch: 0.228172
Train loss on 1600 batch: 0.203509
Train loss on 1650 batch: 0.177729
Train loss on 1700 batch: 0.195739
Train loss on 1750 batch: 0.171413
Train loss on 1800 batch: 0.184027
Train loss on 1850 batch: 0.221687
Train loss on 1900 batch: 0.222704
Train loss on 1950 batch: 0.150691
Train loss on 2000 batch: 0.271092
Train loss on 2050 batch: 0.228064
Train loss on 2100 batch: 0.244471
Train loss on 2150 batch: 0.153690
: Epoch: 271 | Training Loss: 0.201871 | Val. Loss: 0.396415 | Val. Kappa Score: 0.7288 | LR: 0.000846 | Estimated time: 555.02
Train loss on 50 batch: 0.181560
Train loss on 100 batch: 0.178684
Train loss on 150 batch: 0.224535
Train loss on 200 batch: 0.238877
Train loss on 250 batch: 0.305924
Train loss on 300 batch: 0.227324
Train loss on 350 batch: 0.189454
Train loss on 400 batch: 0.198972
Train loss on 450 batch: 0.203255
Train loss on 500 batch: 0.224277
Train loss on 550 batch: 0.219205
Train loss on 600 batch: 0.229212
Train loss on 650 batch: 0.265740
Train loss on 700 batch: 0.228250
Train loss on 750 batch: 0.227766
Train loss on 800 batch: 0.199286
Train loss on 850 batch: 0.229415
Train loss on 900 batch: 0.209419
Train loss on 950 batch: 0.203067
Train loss on 1000 batch: 0.224096
Train loss on 1050 batch: 0.249435
Train loss on 1100 batch: 0.186852
Train loss on 1150 batch: 0.189915
Train loss on 1200 batch: 0.201264
Train loss on 1250 batch: 0.241040
Train loss on 1300 batch: 0.231216
Train loss on 1350 batch: 0.203866
Train loss on 1400 batch: 0.214437
Train loss on 1450 batch: 0.196350
Train loss on 1500 batch: 0.242105
Train loss on 1550 batch: 0.186006
Train loss on 1600 batch: 0.264470
Train loss on 1650 batch: 0.226232
Train loss on 1700 batch: 0.188653
Train loss on 1750 batch: 0.179313
Train loss on 1800 batch: 0.204571
Train loss on 1850 batch: 0.190944
Train loss on 1900 batch: 0.209155
Train loss on 1950 batch: 0.209959
Train loss on 2000 batch: 0.190719
Train loss on 2050 batch: 0.222107
Train loss on 2100 batch: 0.246893
Train loss on 2150 batch: 0.176750
: Epoch: 272 | Training Loss: 0.217159 | Val. Loss: 0.406082 | Val. Kappa Score: 0.7286 | LR: 0.000877 | Estimated time: 555.42
Train loss on 50 batch: 0.227818
Train loss on 100 batch: 0.164937
Train loss on 150 batch: 0.189518
Train loss on 200 batch: 0.175368
Train loss on 250 batch: 0.207484
Train loss on 300 batch: 0.241003
Train loss on 350 batch: 0.199123
Train loss on 400 batch: 0.222654
Train loss on 450 batch: 0.199387
Train loss on 500 batch: 0.252519
Train loss on 550 batch: 0.238330
Train loss on 600 batch: 0.220528
Train loss on 650 batch: 0.240980
Train loss on 700 batch: 0.168362
Train loss on 750 batch: 0.211471
Train loss on 800 batch: 0.246644
Train loss on 850 batch: 0.206633
Train loss on 900 batch: 0.196459
Train loss on 950 batch: 0.200913
Train loss on 1000 batch: 0.187992
Train loss on 1050 batch: 0.233191
Train loss on 1100 batch: 0.211395
Train loss on 1150 batch: 0.219050
Train loss on 1200 batch: 0.240573
Train loss on 1250 batch: 0.177091
Train loss on 1300 batch: 0.232359
Train loss on 1350 batch: 0.179732
Train loss on 1400 batch: 0.202104
Train loss on 1450 batch: 0.212825
Train loss on 1500 batch: 0.228404
Train loss on 1550 batch: 0.188023
Train loss on 1600 batch: 0.271328
Train loss on 1650 batch: 0.238703
Train loss on 1700 batch: 0.257055
Train loss on 1750 batch: 0.191269
Train loss on 1800 batch: 0.254398
Train loss on 1850 batch: 0.233864
Train loss on 1900 batch: 0.249542
Train loss on 1950 batch: 0.223768
Train loss on 2000 batch: 0.213346
Train loss on 2050 batch: 0.242529
Train loss on 2100 batch: 0.217926
Train loss on 2150 batch: 0.264894
: Epoch: 273 | Training Loss: 0.217376 | Val. Loss: 0.349489 | Val. Kappa Score: 0.7286 | LR: 0.000905 | Estimated time: 555.29
Train loss on 50 batch: 0.224073
Train loss on 100 batch: 0.197498
Train loss on 150 batch: 0.196732
Train loss on 200 batch: 0.180224
Train loss on 250 batch: 0.205877
Train loss on 300 batch: 0.187020
Train loss on 350 batch: 0.190944
Train loss on 400 batch: 0.229830
Train loss on 450 batch: 0.284490
Train loss on 500 batch: 0.234824
Train loss on 550 batch: 0.224986
Train loss on 600 batch: 0.191002
Train loss on 650 batch: 0.287517
Train loss on 700 batch: 0.202753
Train loss on 750 batch: 0.175497
Train loss on 800 batch: 0.207980
Train loss on 850 batch: 0.252752
Train loss on 900 batch: 0.210265
Train loss on 950 batch: 0.208390
Train loss on 1000 batch: 0.239940
Train loss on 1050 batch: 0.191801
Train loss on 1100 batch: 0.250738
Train loss on 1150 batch: 0.216715
Train loss on 1200 batch: 0.224551
Train loss on 1250 batch: 0.210048
Train loss on 1300 batch: 0.217443
Train loss on 1350 batch: 0.226053
Train loss on 1400 batch: 0.198710
Train loss on 1450 batch: 0.235404
Train loss on 1500 batch: 0.195823
Train loss on 1550 batch: 0.262034
Train loss on 1600 batch: 0.254075
Train loss on 1650 batch: 0.213300
Train loss on 1700 batch: 0.186801
Train loss on 1750 batch: 0.201455
Train loss on 1800 batch: 0.189030
Train loss on 1850 batch: 0.221532
Train loss on 1900 batch: 0.226914
Train loss on 1950 batch: 0.208752
Train loss on 2000 batch: 0.259843
Train loss on 2050 batch: 0.250153
Train loss on 2100 batch: 0.244809
Train loss on 2150 batch: 0.232006
: Epoch: 274 | Training Loss: 0.219838 | Val. Loss: 0.349389 | Val. Kappa Score: 0.7287 | LR: 0.000929 | Estimated time: 555.31
Train loss on 50 batch: 0.218023
Train loss on 100 batch: 0.241002
Train loss on 150 batch: 0.211580
Train loss on 200 batch: 0.199907
Train loss on 250 batch: 0.200308
Train loss on 300 batch: 0.206606
Train loss on 350 batch: 0.201033
Train loss on 400 batch: 0.255176
Train loss on 450 batch: 0.208831
Train loss on 500 batch: 0.171206
Train loss on 550 batch: 0.227773
Train loss on 600 batch: 0.210843
Train loss on 650 batch: 0.197021
Train loss on 700 batch: 0.207598
Train loss on 750 batch: 0.221655
Train loss on 800 batch: 0.200858
Train loss on 850 batch: 0.220498
Train loss on 900 batch: 0.235780
Train loss on 950 batch: 0.198684
Train loss on 1000 batch: 0.219632
Train loss on 1050 batch: 0.208132
Train loss on 1100 batch: 0.222917
Train loss on 1150 batch: 0.193954
Train loss on 1200 batch: 0.233780
Train loss on 1250 batch: 0.268250
Train loss on 1300 batch: 0.193122
Train loss on 1350 batch: 0.221174
Train loss on 1400 batch: 0.258044
Train loss on 1450 batch: 0.232898
Train loss on 1500 batch: 0.188194
Train loss on 1550 batch: 0.250879
Train loss on 1600 batch: 0.267500
Train loss on 1650 batch: 0.270971
Train loss on 1700 batch: 0.281581
Train loss on 1750 batch: 0.260408
Train loss on 1800 batch: 0.244599
Train loss on 1850 batch: 0.211717
Train loss on 1900 batch: 0.196435
Train loss on 1950 batch: 0.229197
Train loss on 2000 batch: 0.231116
Train loss on 2050 batch: 0.224929
Train loss on 2100 batch: 0.189074
Train loss on 2150 batch: 0.241186
: Epoch: 275 | Training Loss: 0.223360 | Val. Loss: 0.357092 | Val. Kappa Score: 0.7287 | LR: 0.000950 | Estimated time: 555.08
Train loss on 50 batch: 0.223637
Train loss on 100 batch: 0.205124
Train loss on 150 batch: 0.195076
Train loss on 200 batch: 0.174080
Train loss on 250 batch: 0.222737
Train loss on 300 batch: 0.225741
Train loss on 350 batch: 0.207230
Train loss on 400 batch: 0.258234
Train loss on 450 batch: 0.201741
Train loss on 500 batch: 0.210315
Train loss on 550 batch: 0.211599
Train loss on 600 batch: 0.256601
Train loss on 650 batch: 0.198813
Train loss on 700 batch: 0.215511
Train loss on 750 batch: 0.198196
Train loss on 800 batch: 0.239525
Train loss on 850 batch: 0.215069
Train loss on 900 batch: 0.181482
Train loss on 950 batch: 0.227015
Train loss on 1000 batch: 0.217313
Train loss on 1050 batch: 0.177182
Train loss on 1100 batch: 0.208069
Train loss on 1150 batch: 0.218363
Train loss on 1200 batch: 0.223089
Train loss on 1250 batch: 0.252818
Train loss on 1300 batch: 0.258073
Train loss on 1350 batch: 0.233230
Train loss on 1400 batch: 0.223255
Train loss on 1450 batch: 0.266026
Train loss on 1500 batch: 0.203290
Train loss on 1550 batch: 0.220334
Train loss on 1600 batch: 0.282215
Train loss on 1650 batch: 0.257370
Train loss on 1700 batch: 0.237340
Train loss on 1750 batch: 0.223076
Train loss on 1800 batch: 0.184803
Train loss on 1850 batch: 0.218417
Train loss on 1900 batch: 0.203336
Train loss on 1950 batch: 0.252048
Train loss on 2000 batch: 0.223153
Train loss on 2050 batch: 0.258172
Train loss on 2100 batch: 0.244775
Train loss on 2150 batch: 0.187291
: Epoch: 276 | Training Loss: 0.220924 | Val. Loss: 0.363942 | Val. Kappa Score: 0.7286 | LR: 0.000968 | Estimated time: 555.18
Train loss on 50 batch: 0.200558
Train loss on 100 batch: 0.192049
Train loss on 150 batch: 0.259285
Train loss on 200 batch: 0.218356
Train loss on 250 batch: 0.187616
Train loss on 300 batch: 0.240863
Train loss on 350 batch: 0.208488
Train loss on 400 batch: 0.215414
Train loss on 450 batch: 0.221576
Train loss on 500 batch: 0.234859
Train loss on 550 batch: 0.233714
Train loss on 600 batch: 0.225223
Train loss on 650 batch: 0.235760
Train loss on 700 batch: 0.205430
Train loss on 750 batch: 0.225045
Train loss on 800 batch: 0.259920
Train loss on 850 batch: 0.211951
Train loss on 900 batch: 0.208261
Train loss on 950 batch: 0.194206
Train loss on 1000 batch: 0.243817
Train loss on 1050 batch: 0.210836
Train loss on 1100 batch: 0.287321
Train loss on 1150 batch: 0.223488
Train loss on 1200 batch: 0.204849
Train loss on 1250 batch: 0.243408
Train loss on 1300 batch: 0.248325
Train loss on 1350 batch: 0.253086
Train loss on 1400 batch: 0.246124
Train loss on 1450 batch: 0.245229
Train loss on 1500 batch: 0.273390
Train loss on 1550 batch: 0.212288
Train loss on 1600 batch: 0.233825
Train loss on 1650 batch: 0.227115
Train loss on 1700 batch: 0.261463
Train loss on 1750 batch: 0.215300
Train loss on 1800 batch: 0.201271
Train loss on 1850 batch: 0.229421
Train loss on 1900 batch: 0.271026
Train loss on 1950 batch: 0.215781
Train loss on 2000 batch: 0.219341
Train loss on 2050 batch: 0.254032
Train loss on 2100 batch: 0.230381
Train loss on 2150 batch: 0.220604
: Epoch: 277 | Training Loss: 0.228576 | Val. Loss: 0.373125 | Val. Kappa Score: 0.7286 | LR: 0.000982 | Estimated time: 555.26
Train loss on 50 batch: 0.216604
Train loss on 100 batch: 0.245167
Train loss on 150 batch: 0.217228
Train loss on 200 batch: 0.218736
Train loss on 250 batch: 0.189895
Train loss on 300 batch: 0.177657
Train loss on 350 batch: 0.248800
Train loss on 400 batch: 0.259029
Train loss on 450 batch: 0.237893
Train loss on 500 batch: 0.228765
Train loss on 550 batch: 0.270290
Train loss on 600 batch: 0.235921
Train loss on 650 batch: 0.248641
Train loss on 700 batch: 0.226822
Train loss on 750 batch: 0.275224
Train loss on 800 batch: 0.258998
Train loss on 850 batch: 0.277941
Train loss on 900 batch: 0.239682
Train loss on 950 batch: 0.191803
Train loss on 1000 batch: 0.226354
Train loss on 1050 batch: 0.256463
Train loss on 1100 batch: 0.190403
Train loss on 1150 batch: 0.250284
Train loss on 1200 batch: 0.258132
Train loss on 1250 batch: 0.171498
Train loss on 1300 batch: 0.220667
Train loss on 1350 batch: 0.231294
Train loss on 1400 batch: 0.213736
Train loss on 1450 batch: 0.199376
Train loss on 1500 batch: 0.214531
Train loss on 1550 batch: 0.255346
Train loss on 1600 batch: 0.202695
Train loss on 1650 batch: 0.259542
Train loss on 1700 batch: 0.241281
Train loss on 1750 batch: 0.207360
Train loss on 1800 batch: 0.200798
Train loss on 1850 batch: 0.212395
Train loss on 1900 batch: 0.228240
Train loss on 1950 batch: 0.243653
Train loss on 2000 batch: 0.262924
Train loss on 2050 batch: 0.264675
Train loss on 2100 batch: 0.261174
Train loss on 2150 batch: 0.259168
: Epoch: 278 | Training Loss: 0.232179 | Val. Loss: 0.369141 | Val. Kappa Score: 0.7287 | LR: 0.000992 | Estimated time: 555.22
Train loss on 50 batch: 0.214194
Train loss on 100 batch: 0.266592
Train loss on 150 batch: 0.225989
Train loss on 200 batch: 0.205410
Train loss on 250 batch: 0.195505
Train loss on 300 batch: 0.216811
Train loss on 350 batch: 0.248979
Train loss on 400 batch: 0.236908
Train loss on 450 batch: 0.241223
Train loss on 500 batch: 0.242435
Train loss on 550 batch: 0.157273
Train loss on 600 batch: 0.203339
Train loss on 650 batch: 0.230595
Train loss on 700 batch: 0.225494
Train loss on 750 batch: 0.220472
Train loss on 800 batch: 0.207398
Train loss on 850 batch: 0.253094
Train loss on 900 batch: 0.226377
Train loss on 950 batch: 0.211134
Train loss on 1000 batch: 0.192645
Train loss on 1050 batch: 0.243343
Train loss on 1100 batch: 0.211088
Train loss on 1150 batch: 0.226870
Train loss on 1200 batch: 0.235023
Train loss on 1250 batch: 0.230175
Train loss on 1300 batch: 0.247599
Train loss on 1350 batch: 0.217589
Train loss on 1400 batch: 0.205061
Train loss on 1450 batch: 0.241022
Train loss on 1500 batch: 0.266502
Train loss on 1550 batch: 0.246005
Train loss on 1600 batch: 0.239781
Train loss on 1650 batch: 0.211520
Train loss on 1700 batch: 0.232796
Train loss on 1750 batch: 0.254544
Train loss on 1800 batch: 0.229485
Train loss on 1850 batch: 0.214921
Train loss on 1900 batch: 0.226055
Train loss on 1950 batch: 0.223967
Train loss on 2000 batch: 0.262627
Train loss on 2050 batch: 0.221963
Train loss on 2100 batch: 0.236051
Train loss on 2150 batch: 0.217566
: Epoch: 279 | Training Loss: 0.226845 | Val. Loss: 0.333522 | Val. Kappa Score: 0.7287 | LR: 0.000998 | Estimated time: 555.47
Train loss on 50 batch: 0.202754
Train loss on 100 batch: 0.220117
Train loss on 150 batch: 0.207146
Train loss on 200 batch: 0.189420
Train loss on 250 batch: 0.236665
Train loss on 300 batch: 0.285116
Train loss on 350 batch: 0.211153
Train loss on 400 batch: 0.233613
Train loss on 450 batch: 0.224363
Train loss on 500 batch: 0.230689
Train loss on 550 batch: 0.230062
Train loss on 600 batch: 0.218367
Train loss on 650 batch: 0.244043
Train loss on 700 batch: 0.234081
Train loss on 750 batch: 0.220909
Train loss on 800 batch: 0.269048
Train loss on 850 batch: 0.177185
Train loss on 900 batch: 0.202391
Train loss on 950 batch: 0.195705
Train loss on 1000 batch: 0.278217
Train loss on 1050 batch: 0.239006
Train loss on 1100 batch: 0.249251
Train loss on 1150 batch: 0.236872
Train loss on 1200 batch: 0.206773
Train loss on 1250 batch: 0.218979
Train loss on 1300 batch: 0.205164
Train loss on 1350 batch: 0.255482
Train loss on 1400 batch: 0.207118
Train loss on 1450 batch: 0.249969
Train loss on 1500 batch: 0.234342
Train loss on 1550 batch: 0.246043
Train loss on 1600 batch: 0.237094
Train loss on 1650 batch: 0.215713
Train loss on 1700 batch: 0.217694
Train loss on 1750 batch: 0.308228
Train loss on 1800 batch: 0.286986
Train loss on 1850 batch: 0.232295
Train loss on 1900 batch: 0.217534
Train loss on 1950 batch: 0.248721
Train loss on 2000 batch: 0.257696
Train loss on 2050 batch: 0.272823
Train loss on 2100 batch: 0.269972
Train loss on 2150 batch: 0.251354
: Epoch: 280 | Training Loss: 0.234043 | Val. Loss: 0.357127 | Val. Kappa Score: 0.7287 | LR: 0.001000 | Estimated time: 555.57
Train loss on 50 batch: 0.217423
Train loss on 100 batch: 0.224370
Train loss on 150 batch: 0.256522
Train loss on 200 batch: 0.277036
Train loss on 250 batch: 0.239883
Train loss on 300 batch: 0.179829
Train loss on 350 batch: 0.208514
Train loss on 400 batch: 0.275028
Train loss on 450 batch: 0.251030
Train loss on 500 batch: 0.218622
Train loss on 550 batch: 0.237670
Train loss on 600 batch: 0.208948
Train loss on 650 batch: 0.235639
Train loss on 700 batch: 0.243531
Train loss on 750 batch: 0.167794
Train loss on 800 batch: 0.226362
Train loss on 850 batch: 0.205288
Train loss on 900 batch: 0.206201
Train loss on 950 batch: 0.257382
Train loss on 1000 batch: 0.184313
Train loss on 1050 batch: 0.244547
Train loss on 1100 batch: 0.191216
Train loss on 1150 batch: 0.203231
Train loss on 1200 batch: 0.204409
Train loss on 1250 batch: 0.212708
Train loss on 1300 batch: 0.263065
Train loss on 1350 batch: 0.214549
Train loss on 1400 batch: 0.245830
Train loss on 1450 batch: 0.257199
Train loss on 1500 batch: 0.202036
Train loss on 1550 batch: 0.243419
Train loss on 1600 batch: 0.249736
Train loss on 1650 batch: 0.209124
Train loss on 1700 batch: 0.231905
Train loss on 1750 batch: 0.272589
Train loss on 1800 batch: 0.205177
Train loss on 1850 batch: 0.228579
Train loss on 1900 batch: 0.242855
Train loss on 1950 batch: 0.264330
Train loss on 2000 batch: 0.224337
Train loss on 2050 batch: 0.224520
Train loss on 2100 batch: 0.232016
Train loss on 2150 batch: 0.272240
: Epoch: 281 | Training Loss: 0.229049 | Val. Loss: 0.365995 | Val. Kappa Score: 0.7288 | LR: 0.000998 | Estimated time: 555.35
Train loss on 50 batch: 0.192577
Train loss on 100 batch: 0.208612
Train loss on 150 batch: 0.207164
Train loss on 200 batch: 0.187682
Train loss on 250 batch: 0.207400
Train loss on 300 batch: 0.253792
Train loss on 350 batch: 0.180364
Train loss on 400 batch: 0.190652
Train loss on 450 batch: 0.199262
Train loss on 500 batch: 0.217951
Train loss on 550 batch: 0.231372
Train loss on 600 batch: 0.227471
Train loss on 650 batch: 0.242288
Train loss on 700 batch: 0.222744
Train loss on 750 batch: 0.226019
Train loss on 800 batch: 0.225116
Train loss on 850 batch: 0.190042
Train loss on 900 batch: 0.207059
Train loss on 950 batch: 0.219386
Train loss on 1000 batch: 0.195951
Train loss on 1050 batch: 0.209817
Train loss on 1100 batch: 0.221703
Train loss on 1150 batch: 0.218602
Train loss on 1200 batch: 0.230974
Train loss on 1250 batch: 0.243185
Train loss on 1300 batch: 0.233331
Train loss on 1350 batch: 0.228320
Train loss on 1400 batch: 0.207336
Train loss on 1450 batch: 0.238572
Train loss on 1500 batch: 0.209316
Train loss on 1550 batch: 0.265199
Train loss on 1600 batch: 0.293614
Train loss on 1650 batch: 0.244761
Train loss on 1700 batch: 0.222422
Train loss on 1750 batch: 0.283539
Train loss on 1800 batch: 0.247059
Train loss on 1850 batch: 0.254815
Train loss on 1900 batch: 0.223920
Train loss on 1950 batch: 0.231331
Train loss on 2000 batch: 0.243748
Train loss on 2050 batch: 0.228266
Train loss on 2100 batch: 0.267152
Train loss on 2150 batch: 0.260521
: Epoch: 282 | Training Loss: 0.225686 | Val. Loss: 0.373071 | Val. Kappa Score: 0.7287 | LR: 0.000992 | Estimated time: 554.73
Train loss on 50 batch: 0.217376
Train loss on 100 batch: 0.209858
Train loss on 150 batch: 0.210874
Train loss on 200 batch: 0.211216
Train loss on 250 batch: 0.195280
Train loss on 300 batch: 0.223190
Train loss on 350 batch: 0.206429
Train loss on 400 batch: 0.187273
Train loss on 450 batch: 0.199738
Train loss on 500 batch: 0.216650
Train loss on 550 batch: 0.221659
Train loss on 600 batch: 0.229875
Train loss on 650 batch: 0.190608
Train loss on 700 batch: 0.218902
Train loss on 750 batch: 0.196384
Train loss on 800 batch: 0.248740
Train loss on 850 batch: 0.239325
Train loss on 900 batch: 0.241137
Train loss on 950 batch: 0.210135
Train loss on 1000 batch: 0.218992
Train loss on 1050 batch: 0.200563
Train loss on 1100 batch: 0.198868
Train loss on 1150 batch: 0.247562
Train loss on 1200 batch: 0.242139
Train loss on 1250 batch: 0.210781
Train loss on 1300 batch: 0.217058
Train loss on 1350 batch: 0.256708
Train loss on 1400 batch: 0.184609
Train loss on 1450 batch: 0.227494
Train loss on 1500 batch: 0.229484
Train loss on 1550 batch: 0.247104
Train loss on 1600 batch: 0.225361
Train loss on 1650 batch: 0.252255
Train loss on 1700 batch: 0.290513
Train loss on 1750 batch: 0.267113
Train loss on 1800 batch: 0.213808
Train loss on 1850 batch: 0.261741
Train loss on 1900 batch: 0.199340
Train loss on 1950 batch: 0.240154
Train loss on 2000 batch: 0.242589
Train loss on 2050 batch: 0.267313
Train loss on 2100 batch: 0.248055
Train loss on 2150 batch: 0.233359
: Epoch: 283 | Training Loss: 0.225286 | Val. Loss: 0.388779 | Val. Kappa Score: 0.7288 | LR: 0.000982 | Estimated time: 554.99
Train loss on 50 batch: 0.214571
Train loss on 100 batch: 0.210720
Train loss on 150 batch: 0.243738
Train loss on 200 batch: 0.281800
Train loss on 250 batch: 0.225502
Train loss on 300 batch: 0.213766
Train loss on 350 batch: 0.216319
Train loss on 400 batch: 0.249300
Train loss on 450 batch: 0.271190
Train loss on 500 batch: 0.245192
Train loss on 550 batch: 0.261977
Train loss on 600 batch: 0.243358
Train loss on 650 batch: 0.227408
Train loss on 700 batch: 0.259795
Train loss on 750 batch: 0.276360
Train loss on 800 batch: 0.253405
Train loss on 850 batch: 0.225129
Train loss on 900 batch: 0.236849
Train loss on 950 batch: 0.254326
Train loss on 1000 batch: 0.206350
Train loss on 1050 batch: 0.189219
Train loss on 1100 batch: 0.217913
Train loss on 1150 batch: 0.181526
Train loss on 1200 batch: 0.201909
Train loss on 1250 batch: 0.207056
Train loss on 1300 batch: 0.184484
Train loss on 1350 batch: 0.271186
Train loss on 1400 batch: 0.196221
Train loss on 1450 batch: 0.281725
Train loss on 1500 batch: 0.231912
Train loss on 1550 batch: 0.235291
Train loss on 1600 batch: 0.233793
Train loss on 1650 batch: 0.223966
Train loss on 1700 batch: 0.235178
Train loss on 1750 batch: 0.221364
Train loss on 1800 batch: 0.217634
Train loss on 1850 batch: 0.208368
Train loss on 1900 batch: 0.256771
Train loss on 1950 batch: 0.211691
Train loss on 2000 batch: 0.234741
Train loss on 2050 batch: 0.249712
Train loss on 2100 batch: 0.243521
Train loss on 2150 batch: 0.231895
: Epoch: 284 | Training Loss: 0.232848 | Val. Loss: 0.368621 | Val. Kappa Score: 0.7289 | LR: 0.000968 | Estimated time: 555.11
time_estimated: 157651.49
n-epochs: 284
time_estimated: 157651.52
----------------------------------------

Experiment N: 104: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 03:14:56
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb9d102470>
early-stopping-patience: 250
parameters-amount: 28342833
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.819424
Train loss on 100 batch: 0.944711
Train loss on 150 batch: 0.912022
Train loss on 200 batch: 0.786232
Train loss on 250 batch: 0.773992
best-train-loss: 0.997329
best-valid-loss: 0.577452
best-kappa: 0.7869
: Epoch: 1 | Training Loss: 0.997329 | Val. Loss: 0.577452 | Val. Kappa Score: 0.7869 | LR: 0.000998 | Estimated time: 73.37
Train loss on 50 batch: 0.672110
Train loss on 100 batch: 0.660184
Train loss on 150 batch: 0.686543
Train loss on 200 batch: 0.582157
Train loss on 250 batch: 0.640551
best-train-loss: 0.670371
best-valid-loss: 0.552744
best-kappa: 0.8047
: Epoch: 2 | Training Loss: 0.670371 | Val. Loss: 0.552744 | Val. Kappa Score: 0.8047 | LR: 0.000992 | Estimated time: 72.98
Train loss on 50 batch: 0.719654
Train loss on 100 batch: 0.681518
Train loss on 150 batch: 0.664501
Train loss on 200 batch: 0.657429
Train loss on 250 batch: 0.647850
best-train-loss: 0.663089
best-valid-loss: 0.483183
best-kappa: 0.8135
: Epoch: 3 | Training Loss: 0.663089 | Val. Loss: 0.483183 | Val. Kappa Score: 0.8135 | LR: 0.000982 | Estimated time: 73.19
Train loss on 50 batch: 0.550974
Train loss on 100 batch: 0.615109
Train loss on 150 batch: 0.621621
Train loss on 200 batch: 0.586511
Train loss on 250 batch: 0.582234
: Epoch: 4 | Training Loss: 0.613994 | Val. Loss: 0.673683 | Val. Kappa Score: 0.8071 | LR: 0.000968 | Estimated time: 73.13
Train loss on 50 batch: 0.507379
Train loss on 100 batch: 0.611831
Train loss on 150 batch: 0.642768
Train loss on 200 batch: 0.564554
Train loss on 250 batch: 0.516177
: Epoch: 5 | Training Loss: 0.589291 | Val. Loss: 0.554172 | Val. Kappa Score: 0.8086 | LR: 0.000950 | Estimated time: 73.27
Train loss on 50 batch: 0.620213
Train loss on 100 batch: 0.623933
Train loss on 150 batch: 0.489096
Train loss on 200 batch: 0.484434
Train loss on 250 batch: 0.517564
: Epoch: 6 | Training Loss: 0.542760 | Val. Loss: 0.488537 | Val. Kappa Score: 0.8103 | LR: 0.000929 | Estimated time: 72.98
Train loss on 50 batch: 0.470622
Train loss on 100 batch: 0.492471
Train loss on 150 batch: 0.495993
Train loss on 200 batch: 0.492371
Train loss on 250 batch: 0.556769
: Epoch: 7 | Training Loss: 0.511954 | Val. Loss: 0.664244 | Val. Kappa Score: 0.8014 | LR: 0.000905 | Estimated time: 72.98
Train loss on 50 batch: 0.533535
Train loss on 100 batch: 0.445277
Train loss on 150 batch: 0.477343
Train loss on 200 batch: 0.476722
Train loss on 250 batch: 0.414350
: Epoch: 8 | Training Loss: 0.471908 | Val. Loss: 0.493270 | Val. Kappa Score: 0.8060 | LR: 0.000877 | Estimated time: 72.94
Train loss on 50 batch: 0.488148
Train loss on 100 batch: 0.465174
Train loss on 150 batch: 0.487322
Train loss on 200 batch: 0.429226
Train loss on 250 batch: 0.474915
: Epoch: 9 | Training Loss: 0.473167 | Val. Loss: 0.594934 | Val. Kappa Score: 0.8064 | LR: 0.000846 | Estimated time: 72.91
Train loss on 50 batch: 0.436801
Train loss on 100 batch: 0.436929
Train loss on 150 batch: 0.537171
Train loss on 200 batch: 0.394742
Train loss on 250 batch: 0.437327
best-train-loss: 0.451438
best-valid-loss: 0.469878
best-kappa: 0.8096
: Epoch: 10 | Training Loss: 0.451438 | Val. Loss: 0.469878 | Val. Kappa Score: 0.8096 | LR: 0.000812 | Estimated time: 72.94
Train loss on 50 batch: 0.454513
Train loss on 100 batch: 0.417728
Train loss on 150 batch: 0.425259
Train loss on 200 batch: 0.413164
Train loss on 250 batch: 0.411896
best-train-loss: 0.410767
best-valid-loss: 0.441070
best-kappa: 0.8140
: Epoch: 11 | Training Loss: 0.410767 | Val. Loss: 0.441070 | Val. Kappa Score: 0.8140 | LR: 0.000775 | Estimated time: 73.01
Train loss on 50 batch: 0.407733
Train loss on 100 batch: 0.379068
Train loss on 150 batch: 0.373382
Train loss on 200 batch: 0.363157
Train loss on 250 batch: 0.361749
best-train-loss: 0.384834
best-valid-loss: 0.404536
best-kappa: 0.8179
: Epoch: 12 | Training Loss: 0.384834 | Val. Loss: 0.404536 | Val. Kappa Score: 0.8179 | LR: 0.000737 | Estimated time: 72.98
Train loss on 50 batch: 0.409421
Train loss on 100 batch: 0.397251
Train loss on 150 batch: 0.451572
Train loss on 200 batch: 0.363748
Train loss on 250 batch: 0.354320
best-train-loss: 0.408639
best-valid-loss: 0.391125
best-kappa: 0.8215
: Epoch: 13 | Training Loss: 0.408639 | Val. Loss: 0.391125 | Val. Kappa Score: 0.8215 | LR: 0.000697 | Estimated time: 73.04
Train loss on 50 batch: 0.377030
Train loss on 100 batch: 0.421362
Train loss on 150 batch: 0.374159
Train loss on 200 batch: 0.371369
Train loss on 250 batch: 0.304634
: Epoch: 14 | Training Loss: 0.363855 | Val. Loss: 0.398595 | Val. Kappa Score: 0.8252 | LR: 0.000655 | Estimated time: 72.90
Train loss on 50 batch: 0.312204
Train loss on 100 batch: 0.309721
Train loss on 150 batch: 0.370135
Train loss on 200 batch: 0.427233
Train loss on 250 batch: 0.353573
: Epoch: 15 | Training Loss: 0.369990 | Val. Loss: 0.405706 | Val. Kappa Score: 0.8282 | LR: 0.000611 | Estimated time: 72.91
Train loss on 50 batch: 0.317472
Train loss on 100 batch: 0.341936
Train loss on 150 batch: 0.324139
Train loss on 200 batch: 0.332966
Train loss on 250 batch: 0.304638
: Epoch: 16 | Training Loss: 0.330280 | Val. Loss: 0.417029 | Val. Kappa Score: 0.8308 | LR: 0.000567 | Estimated time: 72.90
Train loss on 50 batch: 0.308036
Train loss on 100 batch: 0.278742
Train loss on 150 batch: 0.291307
Train loss on 200 batch: 0.336308
Train loss on 250 batch: 0.309047
: Epoch: 17 | Training Loss: 0.326568 | Val. Loss: 0.439028 | Val. Kappa Score: 0.8306 | LR: 0.000522 | Estimated time: 73.03
Train loss on 50 batch: 0.315537
Train loss on 100 batch: 0.322629
Train loss on 150 batch: 0.308078
Train loss on 200 batch: 0.324116
Train loss on 250 batch: 0.238734
: Epoch: 18 | Training Loss: 0.307356 | Val. Loss: 0.417981 | Val. Kappa Score: 0.8323 | LR: 0.000478 | Estimated time: 72.85
Train loss on 50 batch: 0.317279
Train loss on 100 batch: 0.257788
Train loss on 150 batch: 0.254443
Train loss on 200 batch: 0.266128
Train loss on 250 batch: 0.281275
best-train-loss: 0.277621
best-valid-loss: 0.370913
best-kappa: 0.8337
: Epoch: 19 | Training Loss: 0.277621 | Val. Loss: 0.370913 | Val. Kappa Score: 0.8337 | LR: 0.000433 | Estimated time: 72.97
Train loss on 50 batch: 0.257044
Train loss on 100 batch: 0.235059
Train loss on 150 batch: 0.256588
Train loss on 200 batch: 0.245552
Train loss on 250 batch: 0.238934
: Epoch: 20 | Training Loss: 0.251352 | Val. Loss: 0.399211 | Val. Kappa Score: 0.8357 | LR: 0.000389 | Estimated time: 72.93
Train loss on 50 batch: 0.245990
Train loss on 100 batch: 0.251386
Train loss on 150 batch: 0.212451
Train loss on 200 batch: 0.269649
Train loss on 250 batch: 0.224811
: Epoch: 21 | Training Loss: 0.262636 | Val. Loss: 0.372074 | Val. Kappa Score: 0.8376 | LR: 0.000345 | Estimated time: 72.92
Train loss on 50 batch: 0.243519
Train loss on 100 batch: 0.215910
Train loss on 150 batch: 0.235114
Train loss on 200 batch: 0.261168
Train loss on 250 batch: 0.251097
: Epoch: 22 | Training Loss: 0.239398 | Val. Loss: 0.391170 | Val. Kappa Score: 0.8393 | LR: 0.000303 | Estimated time: 73.03
Train loss on 50 batch: 0.224686
Train loss on 100 batch: 0.165090
Train loss on 150 batch: 0.211123
Train loss on 200 batch: 0.197387
Train loss on 250 batch: 0.219579
: Epoch: 23 | Training Loss: 0.201890 | Val. Loss: 0.375413 | Val. Kappa Score: 0.8400 | LR: 0.000263 | Estimated time: 72.99
Train loss on 50 batch: 0.183949
Train loss on 100 batch: 0.159785
Train loss on 150 batch: 0.205076
Train loss on 200 batch: 0.183636
Train loss on 250 batch: 0.189086
: Epoch: 24 | Training Loss: 0.192748 | Val. Loss: 0.391207 | Val. Kappa Score: 0.8405 | LR: 0.000225 | Estimated time: 72.99
Train loss on 50 batch: 0.171622
Train loss on 100 batch: 0.217535
Train loss on 150 batch: 0.147220
Train loss on 200 batch: 0.185499
Train loss on 250 batch: 0.191207
: Epoch: 25 | Training Loss: 0.196322 | Val. Loss: 0.385555 | Val. Kappa Score: 0.8421 | LR: 0.000188 | Estimated time: 72.97
Train loss on 50 batch: 0.155436
Train loss on 100 batch: 0.198382
Train loss on 150 batch: 0.172039
Train loss on 200 batch: 0.143343
Train loss on 250 batch: 0.165871
: Epoch: 26 | Training Loss: 0.166016 | Val. Loss: 0.392230 | Val. Kappa Score: 0.8433 | LR: 0.000154 | Estimated time: 73.05
Train loss on 50 batch: 0.147520
Train loss on 100 batch: 0.176627
Train loss on 150 batch: 0.141344
Train loss on 200 batch: 0.139521
Train loss on 250 batch: 0.129012
best-train-loss: 0.148127
best-valid-loss: 0.360742
best-kappa: 0.8448
: Epoch: 27 | Training Loss: 0.148127 | Val. Loss: 0.360742 | Val. Kappa Score: 0.8448 | LR: 0.000123 | Estimated time: 72.91
Train loss on 50 batch: 0.148003
Train loss on 100 batch: 0.142112
Train loss on 150 batch: 0.153583
Train loss on 200 batch: 0.123896
Train loss on 250 batch: 0.144683
: Epoch: 28 | Training Loss: 0.142962 | Val. Loss: 0.378686 | Val. Kappa Score: 0.8461 | LR: 0.000095 | Estimated time: 72.88
Train loss on 50 batch: 0.133013
Train loss on 100 batch: 0.144393
Train loss on 150 batch: 0.157169
Train loss on 200 batch: 0.127549
Train loss on 250 batch: 0.113750
: Epoch: 29 | Training Loss: 0.142296 | Val. Loss: 0.369551 | Val. Kappa Score: 0.8470 | LR: 0.000071 | Estimated time: 72.95
Train loss on 50 batch: 0.121910
Train loss on 100 batch: 0.117429
Train loss on 150 batch: 0.139101
Train loss on 200 batch: 0.148963
Train loss on 250 batch: 0.125801
: Epoch: 30 | Training Loss: 0.134113 | Val. Loss: 0.388672 | Val. Kappa Score: 0.8472 | LR: 0.000050 | Estimated time: 73.00
Train loss on 50 batch: 0.129726
Train loss on 100 batch: 0.119828
Train loss on 150 batch: 0.131934
Train loss on 200 batch: 0.112932
Train loss on 250 batch: 0.123061
: Epoch: 31 | Training Loss: 0.124771 | Val. Loss: 0.394182 | Val. Kappa Score: 0.8482 | LR: 0.000032 | Estimated time: 72.95
Train loss on 50 batch: 0.119015
Train loss on 100 batch: 0.106462
Train loss on 150 batch: 0.118310
Train loss on 200 batch: 0.127663
Train loss on 250 batch: 0.105732
: Epoch: 32 | Training Loss: 0.122813 | Val. Loss: 0.383289 | Val. Kappa Score: 0.8490 | LR: 0.000018 | Estimated time: 72.97
Train loss on 50 batch: 0.112281
Train loss on 100 batch: 0.129819
Train loss on 150 batch: 0.104939
Train loss on 200 batch: 0.110222
Train loss on 250 batch: 0.117576
: Epoch: 33 | Training Loss: 0.121237 | Val. Loss: 0.384303 | Val. Kappa Score: 0.8500 | LR: 0.000008 | Estimated time: 73.00
Train loss on 50 batch: 0.108876
Train loss on 100 batch: 0.105897
Train loss on 150 batch: 0.114243
Train loss on 200 batch: 0.118397
Train loss on 250 batch: 0.103635
: Epoch: 34 | Training Loss: 0.120727 | Val. Loss: 0.375334 | Val. Kappa Score: 0.8510 | LR: 0.000002 | Estimated time: 73.02
Train loss on 50 batch: 0.105287
Train loss on 100 batch: 0.113751
Train loss on 150 batch: 0.114601
Train loss on 200 batch: 0.111363
Train loss on 250 batch: 0.111116
: Epoch: 35 | Training Loss: 0.111890 | Val. Loss: 0.378273 | Val. Kappa Score: 0.8519 | LR: 0.000000 | Estimated time: 73.03
Train loss on 50 batch: 0.104193
Train loss on 100 batch: 0.102146
Train loss on 150 batch: 0.125857
Train loss on 200 batch: 0.109138
Train loss on 250 batch: 0.112805
: Epoch: 36 | Training Loss: 0.112825 | Val. Loss: 0.373838 | Val. Kappa Score: 0.8528 | LR: 0.000002 | Estimated time: 73.04
Train loss on 50 batch: 0.108800
Train loss on 100 batch: 0.114862
Train loss on 150 batch: 0.118753
Train loss on 200 batch: 0.100804
Train loss on 250 batch: 0.111436
: Epoch: 37 | Training Loss: 0.113226 | Val. Loss: 0.373839 | Val. Kappa Score: 0.8536 | LR: 0.000008 | Estimated time: 73.00
Train loss on 50 batch: 0.100824
Train loss on 100 batch: 0.116312
Train loss on 150 batch: 0.098265
Train loss on 200 batch: 0.112482
Train loss on 250 batch: 0.115664
: Epoch: 38 | Training Loss: 0.119355 | Val. Loss: 0.380173 | Val. Kappa Score: 0.8542 | LR: 0.000018 | Estimated time: 72.94
Train loss on 50 batch: 0.107107
Train loss on 100 batch: 0.110902
Train loss on 150 batch: 0.108950
Train loss on 200 batch: 0.127810
Train loss on 250 batch: 0.113647
: Epoch: 39 | Training Loss: 0.116877 | Val. Loss: 0.384835 | Val. Kappa Score: 0.8547 | LR: 0.000032 | Estimated time: 73.05
Train loss on 50 batch: 0.114469
Train loss on 100 batch: 0.106415
Train loss on 150 batch: 0.100903
Train loss on 200 batch: 0.103493
Train loss on 250 batch: 0.131051
: Epoch: 40 | Training Loss: 0.120987 | Val. Loss: 0.374937 | Val. Kappa Score: 0.8554 | LR: 0.000050 | Estimated time: 72.97
Train loss on 50 batch: 0.116106
Train loss on 100 batch: 0.118093
Train loss on 150 batch: 0.112020
Train loss on 200 batch: 0.097431
Train loss on 250 batch: 0.101900
: Epoch: 41 | Training Loss: 0.121908 | Val. Loss: 0.383715 | Val. Kappa Score: 0.8558 | LR: 0.000071 | Estimated time: 72.96
Train loss on 50 batch: 0.131406
Train loss on 100 batch: 0.091148
Train loss on 150 batch: 0.135721
Train loss on 200 batch: 0.116430
Train loss on 250 batch: 0.114987
: Epoch: 42 | Training Loss: 0.118181 | Val. Loss: 0.396542 | Val. Kappa Score: 0.8561 | LR: 0.000095 | Estimated time: 72.91
Train loss on 50 batch: 0.110186
Train loss on 100 batch: 0.123011
Train loss on 150 batch: 0.099779
Train loss on 200 batch: 0.097872
Train loss on 250 batch: 0.144977
: Epoch: 43 | Training Loss: 0.111882 | Val. Loss: 0.410617 | Val. Kappa Score: 0.8557 | LR: 0.000123 | Estimated time: 73.04
Train loss on 50 batch: 0.108918
Train loss on 100 batch: 0.093923
Train loss on 150 batch: 0.091760
Train loss on 200 batch: 0.110263
Train loss on 250 batch: 0.133731
: Epoch: 44 | Training Loss: 0.114076 | Val. Loss: 0.388289 | Val. Kappa Score: 0.8563 | LR: 0.000154 | Estimated time: 73.04
Train loss on 50 batch: 0.108159
Train loss on 100 batch: 0.119312
Train loss on 150 batch: 0.123094
Train loss on 200 batch: 0.116289
Train loss on 250 batch: 0.112006
: Epoch: 45 | Training Loss: 0.119972 | Val. Loss: 0.406463 | Val. Kappa Score: 0.8566 | LR: 0.000188 | Estimated time: 72.96
Train loss on 50 batch: 0.121178
Train loss on 100 batch: 0.134589
Train loss on 150 batch: 0.117572
Train loss on 200 batch: 0.119734
Train loss on 250 batch: 0.115543
: Epoch: 46 | Training Loss: 0.122882 | Val. Loss: 0.413953 | Val. Kappa Score: 0.8567 | LR: 0.000225 | Estimated time: 72.90
Train loss on 50 batch: 0.126023
Train loss on 100 batch: 0.130417
Train loss on 150 batch: 0.140147
Train loss on 200 batch: 0.109624
Train loss on 250 batch: 0.140876
: Epoch: 47 | Training Loss: 0.135055 | Val. Loss: 0.414802 | Val. Kappa Score: 0.8566 | LR: 0.000263 | Estimated time: 72.95
Train loss on 50 batch: 0.140072
Train loss on 100 batch: 0.121628
Train loss on 150 batch: 0.140984
Train loss on 200 batch: 0.139191
Train loss on 250 batch: 0.140050
: Epoch: 48 | Training Loss: 0.146658 | Val. Loss: 0.443129 | Val. Kappa Score: 0.8568 | LR: 0.000303 | Estimated time: 73.01
Train loss on 50 batch: 0.149321
Train loss on 100 batch: 0.142102
Train loss on 150 batch: 0.140104
Train loss on 200 batch: 0.127875
Train loss on 250 batch: 0.123723
: Epoch: 49 | Training Loss: 0.156427 | Val. Loss: 0.441577 | Val. Kappa Score: 0.8568 | LR: 0.000345 | Estimated time: 73.09
Train loss on 50 batch: 0.147813
Train loss on 100 batch: 0.164699
Train loss on 150 batch: 0.134251
Train loss on 200 batch: 0.146966
Train loss on 250 batch: 0.157230
: Epoch: 50 | Training Loss: 0.155779 | Val. Loss: 0.443713 | Val. Kappa Score: 0.8570 | LR: 0.000389 | Estimated time: 73.01
Train loss on 50 batch: 0.154727
Train loss on 100 batch: 0.144099
Train loss on 150 batch: 0.106213
Train loss on 200 batch: 0.164302
Train loss on 250 batch: 0.122658
: Epoch: 51 | Training Loss: 0.145692 | Val. Loss: 0.525453 | Val. Kappa Score: 0.8568 | LR: 0.000433 | Estimated time: 73.10
Train loss on 50 batch: 0.164081
Train loss on 100 batch: 0.144318
Train loss on 150 batch: 0.165420
Train loss on 200 batch: 0.151873
Train loss on 250 batch: 0.157494
: Epoch: 52 | Training Loss: 0.165509 | Val. Loss: 0.452662 | Val. Kappa Score: 0.8568 | LR: 0.000478 | Estimated time: 72.96
Train loss on 50 batch: 0.196350
Train loss on 100 batch: 0.171454
Train loss on 150 batch: 0.161441
Train loss on 200 batch: 0.172876
Train loss on 250 batch: 0.180728
: Epoch: 53 | Training Loss: 0.185967 | Val. Loss: 0.497296 | Val. Kappa Score: 0.8567 | LR: 0.000522 | Estimated time: 73.05
Train loss on 50 batch: 0.197337
Train loss on 100 batch: 0.192552
Train loss on 150 batch: 0.173415
Train loss on 200 batch: 0.183320
Train loss on 250 batch: 0.203475
: Epoch: 54 | Training Loss: 0.194616 | Val. Loss: 0.463122 | Val. Kappa Score: 0.8568 | LR: 0.000567 | Estimated time: 72.98
Train loss on 50 batch: 0.212152
Train loss on 100 batch: 0.226060
Train loss on 150 batch: 0.198880
Train loss on 200 batch: 0.200230
Train loss on 250 batch: 0.177200
: Epoch: 55 | Training Loss: 0.211605 | Val. Loss: 0.464799 | Val. Kappa Score: 0.8566 | LR: 0.000611 | Estimated time: 73.04
Train loss on 50 batch: 0.180124
Train loss on 100 batch: 0.185622
Train loss on 150 batch: 0.198958
Train loss on 200 batch: 0.221622
Train loss on 250 batch: 0.218400
: Epoch: 56 | Training Loss: 0.201068 | Val. Loss: 0.453132 | Val. Kappa Score: 0.8565 | LR: 0.000655 | Estimated time: 73.05
Train loss on 50 batch: 0.238649
Train loss on 100 batch: 0.217592
Train loss on 150 batch: 0.229487
Train loss on 200 batch: 0.172480
Train loss on 250 batch: 0.242095
: Epoch: 57 | Training Loss: 0.235597 | Val. Loss: 0.503113 | Val. Kappa Score: 0.8563 | LR: 0.000697 | Estimated time: 73.02
Train loss on 50 batch: 0.322932
Train loss on 100 batch: 0.256043
Train loss on 150 batch: 0.302192
Train loss on 200 batch: 0.260277
Train loss on 250 batch: 0.241657
: Epoch: 58 | Training Loss: 0.272643 | Val. Loss: 0.449613 | Val. Kappa Score: 0.8563 | LR: 0.000737 | Estimated time: 72.97
Train loss on 50 batch: 0.215138
Train loss on 100 batch: 0.233562
Train loss on 150 batch: 0.202823
Train loss on 200 batch: 0.226853
Train loss on 250 batch: 0.269137
: Epoch: 59 | Training Loss: 0.231345 | Val. Loss: 0.380943 | Val. Kappa Score: 0.8567 | LR: 0.000775 | Estimated time: 72.93
Train loss on 50 batch: 0.200586
Train loss on 100 batch: 0.258136
Train loss on 150 batch: 0.221557
Train loss on 200 batch: 0.230490
Train loss on 250 batch: 0.239975
: Epoch: 60 | Training Loss: 0.268736 | Val. Loss: 0.529514 | Val. Kappa Score: 0.8559 | LR: 0.000812 | Estimated time: 72.93
Train loss on 50 batch: 0.392107
Train loss on 100 batch: 0.292006
Train loss on 150 batch: 0.281850
Train loss on 200 batch: 0.237726
Train loss on 250 batch: 0.252078
: Epoch: 61 | Training Loss: 0.286376 | Val. Loss: 0.484026 | Val. Kappa Score: 0.8557 | LR: 0.000846 | Estimated time: 73.01
Train loss on 50 batch: 0.294547
Train loss on 100 batch: 0.235777
Train loss on 150 batch: 0.223637
Train loss on 200 batch: 0.241356
Train loss on 250 batch: 0.220243
: Epoch: 62 | Training Loss: 0.246221 | Val. Loss: 0.478842 | Val. Kappa Score: 0.8558 | LR: 0.000877 | Estimated time: 72.95
Train loss on 50 batch: 0.190781
Train loss on 100 batch: 0.229651
Train loss on 150 batch: 0.193453
Train loss on 200 batch: 0.286762
Train loss on 250 batch: 0.325881
: Epoch: 63 | Training Loss: 0.247938 | Val. Loss: 0.555108 | Val. Kappa Score: 0.8552 | LR: 0.000905 | Estimated time: 73.02
Train loss on 50 batch: 0.273748
Train loss on 100 batch: 0.229860
Train loss on 150 batch: 0.258995
Train loss on 200 batch: 0.270190
Train loss on 250 batch: 0.257671
: Epoch: 64 | Training Loss: 0.276023 | Val. Loss: 0.512937 | Val. Kappa Score: 0.8550 | LR: 0.000929 | Estimated time: 72.98
Train loss on 50 batch: 0.361870
Train loss on 100 batch: 0.269610
Train loss on 150 batch: 0.229734
Train loss on 200 batch: 0.305959
Train loss on 250 batch: 0.281220
: Epoch: 65 | Training Loss: 0.286945 | Val. Loss: 0.492307 | Val. Kappa Score: 0.8549 | LR: 0.000950 | Estimated time: 72.94
Train loss on 50 batch: 0.341222
Train loss on 100 batch: 0.303085
Train loss on 150 batch: 0.287950
Train loss on 200 batch: 0.231889
Train loss on 250 batch: 0.247059
: Epoch: 66 | Training Loss: 0.293377 | Val. Loss: 0.637031 | Val. Kappa Score: 0.8539 | LR: 0.000968 | Estimated time: 73.05
Train loss on 50 batch: 0.260230
Train loss on 100 batch: 0.209187
Train loss on 150 batch: 0.229664
Train loss on 200 batch: 0.226535
Train loss on 250 batch: 0.262805
: Epoch: 67 | Training Loss: 0.249138 | Val. Loss: 0.599693 | Val. Kappa Score: 0.8531 | LR: 0.000982 | Estimated time: 73.01
Train loss on 50 batch: 0.203421
Train loss on 100 batch: 0.256864
Train loss on 150 batch: 0.270376
Train loss on 200 batch: 0.269668
Train loss on 250 batch: 0.283652
: Epoch: 68 | Training Loss: 0.262562 | Val. Loss: 0.418487 | Val. Kappa Score: 0.8533 | LR: 0.000992 | Estimated time: 72.95
Train loss on 50 batch: 0.253301
Train loss on 100 batch: 0.239923
Train loss on 150 batch: 0.193562
Train loss on 200 batch: 0.214890
Train loss on 250 batch: 0.209934
: Epoch: 69 | Training Loss: 0.242081 | Val. Loss: 0.647218 | Val. Kappa Score: 0.8523 | LR: 0.000998 | Estimated time: 72.97
Train loss on 50 batch: 0.251805
Train loss on 100 batch: 0.239277
Train loss on 150 batch: 0.226689
Train loss on 200 batch: 0.236349
Train loss on 250 batch: 0.193340
: Epoch: 70 | Training Loss: 0.235593 | Val. Loss: 0.433823 | Val. Kappa Score: 0.8523 | LR: 0.001000 | Estimated time: 73.03
Train loss on 50 batch: 0.221828
Train loss on 100 batch: 0.211614
Train loss on 150 batch: 0.226299
Train loss on 200 batch: 0.175978
Train loss on 250 batch: 0.262452
: Epoch: 71 | Training Loss: 0.228700 | Val. Loss: 0.459358 | Val. Kappa Score: 0.8524 | LR: 0.000998 | Estimated time: 73.14
Train loss on 50 batch: 0.240763
Train loss on 100 batch: 0.218373
Train loss on 150 batch: 0.273521
Train loss on 200 batch: 0.260622
Train loss on 250 batch: 0.230047
: Epoch: 72 | Training Loss: 0.243661 | Val. Loss: 0.494446 | Val. Kappa Score: 0.8521 | LR: 0.000992 | Estimated time: 72.93
Train loss on 50 batch: 0.186007
Train loss on 100 batch: 0.219441
Train loss on 150 batch: 0.220520
Train loss on 200 batch: 0.225235
Train loss on 250 batch: 0.238747
: Epoch: 73 | Training Loss: 0.243635 | Val. Loss: 0.476742 | Val. Kappa Score: 0.8520 | LR: 0.000982 | Estimated time: 73.08
Train loss on 50 batch: 0.301694
Train loss on 100 batch: 0.286085
Train loss on 150 batch: 0.268410
Train loss on 200 batch: 0.295900
Train loss on 250 batch: 0.260091
: Epoch: 74 | Training Loss: 0.303718 | Val. Loss: 0.435446 | Val. Kappa Score: 0.8520 | LR: 0.000968 | Estimated time: 73.00
Train loss on 50 batch: 0.349632
Train loss on 100 batch: 0.233570
Train loss on 150 batch: 0.301736
Train loss on 200 batch: 0.261656
Train loss on 250 batch: 0.290183
: Epoch: 75 | Training Loss: 0.286482 | Val. Loss: 0.455299 | Val. Kappa Score: 0.8519 | LR: 0.000950 | Estimated time: 72.98
Train loss on 50 batch: 0.272988
Train loss on 100 batch: 0.198975
Train loss on 150 batch: 0.223984
Train loss on 200 batch: 0.203140
Train loss on 250 batch: 0.225361
: Epoch: 76 | Training Loss: 0.232371 | Val. Loss: 0.587932 | Val. Kappa Score: 0.8513 | LR: 0.000929 | Estimated time: 72.95
Train loss on 50 batch: 0.186766
Train loss on 100 batch: 0.189726
Train loss on 150 batch: 0.199576
Train loss on 200 batch: 0.183366
Train loss on 250 batch: 0.189336
: Epoch: 77 | Training Loss: 0.193180 | Val. Loss: 0.478448 | Val. Kappa Score: 0.8511 | LR: 0.000905 | Estimated time: 72.96
Train loss on 50 batch: 0.186075
Train loss on 100 batch: 0.174691
Train loss on 150 batch: 0.162392
Train loss on 200 batch: 0.212980
Train loss on 250 batch: 0.212062
: Epoch: 78 | Training Loss: 0.187219 | Val. Loss: 0.557179 | Val. Kappa Score: 0.8507 | LR: 0.000877 | Estimated time: 72.92
Train loss on 50 batch: 0.192508
Train loss on 100 batch: 0.183102
Train loss on 150 batch: 0.171042
Train loss on 200 batch: 0.165189
Train loss on 250 batch: 0.173052
: Epoch: 79 | Training Loss: 0.184794 | Val. Loss: 0.733998 | Val. Kappa Score: 0.8495 | LR: 0.000846 | Estimated time: 73.02
Train loss on 50 batch: 0.206169
Train loss on 100 batch: 0.162160
Train loss on 150 batch: 0.224549
Train loss on 200 batch: 0.248976
Train loss on 250 batch: 0.195454
: Epoch: 80 | Training Loss: 0.225177 | Val. Loss: 0.444533 | Val. Kappa Score: 0.8496 | LR: 0.000812 | Estimated time: 73.01
Train loss on 50 batch: 0.227247
Train loss on 100 batch: 0.198932
Train loss on 150 batch: 0.203640
Train loss on 200 batch: 0.169802
Train loss on 250 batch: 0.210347
: Epoch: 81 | Training Loss: 0.195186 | Val. Loss: 0.482914 | Val. Kappa Score: 0.8494 | LR: 0.000775 | Estimated time: 73.06
Train loss on 50 batch: 0.152940
Train loss on 100 batch: 0.150463
Train loss on 150 batch: 0.178088
Train loss on 200 batch: 0.188341
Train loss on 250 batch: 0.186472
: Epoch: 82 | Training Loss: 0.180290 | Val. Loss: 0.535765 | Val. Kappa Score: 0.8494 | LR: 0.000737 | Estimated time: 72.96
Train loss on 50 batch: 0.182531
Train loss on 100 batch: 0.112996
Train loss on 150 batch: 0.162139
Train loss on 200 batch: 0.159821
Train loss on 250 batch: 0.180598
: Epoch: 83 | Training Loss: 0.161924 | Val. Loss: 0.483454 | Val. Kappa Score: 0.8493 | LR: 0.000697 | Estimated time: 73.01
Train loss on 50 batch: 0.194777
Train loss on 100 batch: 0.178753
Train loss on 150 batch: 0.131300
Train loss on 200 batch: 0.121568
Train loss on 250 batch: 0.136191
: Epoch: 84 | Training Loss: 0.167480 | Val. Loss: 0.466582 | Val. Kappa Score: 0.8494 | LR: 0.000655 | Estimated time: 73.04
Train loss on 50 batch: 0.143591
Train loss on 100 batch: 0.130426
Train loss on 150 batch: 0.132245
Train loss on 200 batch: 0.146834
Train loss on 250 batch: 0.119624
: Epoch: 85 | Training Loss: 0.137870 | Val. Loss: 0.429797 | Val. Kappa Score: 0.8493 | LR: 0.000611 | Estimated time: 72.97
Train loss on 50 batch: 0.137373
Train loss on 100 batch: 0.134259
Train loss on 150 batch: 0.131735
Train loss on 200 batch: 0.122723
Train loss on 250 batch: 0.112384
: Epoch: 86 | Training Loss: 0.136793 | Val. Loss: 0.472507 | Val. Kappa Score: 0.8493 | LR: 0.000567 | Estimated time: 73.03
Train loss on 50 batch: 0.119479
Train loss on 100 batch: 0.131382
Train loss on 150 batch: 0.116116
Train loss on 200 batch: 0.112549
Train loss on 250 batch: 0.134758
: Epoch: 87 | Training Loss: 0.116544 | Val. Loss: 0.385372 | Val. Kappa Score: 0.8496 | LR: 0.000522 | Estimated time: 73.06
Train loss on 50 batch: 0.082166
Train loss on 100 batch: 0.097536
Train loss on 150 batch: 0.094721
Train loss on 200 batch: 0.109247
Train loss on 250 batch: 0.126340
: Epoch: 88 | Training Loss: 0.098925 | Val. Loss: 0.395132 | Val. Kappa Score: 0.8499 | LR: 0.000478 | Estimated time: 72.97
Train loss on 50 batch: 0.105839
Train loss on 100 batch: 0.094884
Train loss on 150 batch: 0.087339
Train loss on 200 batch: 0.083631
Train loss on 250 batch: 0.098683
: Epoch: 89 | Training Loss: 0.098723 | Val. Loss: 0.473788 | Val. Kappa Score: 0.8498 | LR: 0.000433 | Estimated time: 72.94
Train loss on 50 batch: 0.105364
Train loss on 100 batch: 0.086165
Train loss on 150 batch: 0.088637
Train loss on 200 batch: 0.082429
Train loss on 250 batch: 0.086818
: Epoch: 90 | Training Loss: 0.085772 | Val. Loss: 0.442674 | Val. Kappa Score: 0.8500 | LR: 0.000389 | Estimated time: 73.00
Train loss on 50 batch: 0.087756
Train loss on 100 batch: 0.066559
Train loss on 150 batch: 0.070917
Train loss on 200 batch: 0.077827
Train loss on 250 batch: 0.072358
: Epoch: 91 | Training Loss: 0.090319 | Val. Loss: 0.414401 | Val. Kappa Score: 0.8501 | LR: 0.000345 | Estimated time: 73.12
Train loss on 50 batch: 0.089210
Train loss on 100 batch: 0.084285
Train loss on 150 batch: 0.103148
Train loss on 200 batch: 0.081210
Train loss on 250 batch: 0.075085
: Epoch: 92 | Training Loss: 0.092500 | Val. Loss: 0.390154 | Val. Kappa Score: 0.8503 | LR: 0.000303 | Estimated time: 73.71
Train loss on 50 batch: 0.089890
Train loss on 100 batch: 0.061569
Train loss on 150 batch: 0.073465
Train loss on 200 batch: 0.083967
Train loss on 250 batch: 0.082774
: Epoch: 93 | Training Loss: 0.082885 | Val. Loss: 0.414033 | Val. Kappa Score: 0.8505 | LR: 0.000263 | Estimated time: 72.92
Train loss on 50 batch: 0.064456
Train loss on 100 batch: 0.060788
Train loss on 150 batch: 0.066669
Train loss on 200 batch: 0.071158
Train loss on 250 batch: 0.057531
: Epoch: 94 | Training Loss: 0.069805 | Val. Loss: 0.401350 | Val. Kappa Score: 0.8506 | LR: 0.000225 | Estimated time: 72.93
Train loss on 50 batch: 0.069045
Train loss on 100 batch: 0.056746
Train loss on 150 batch: 0.069079
Train loss on 200 batch: 0.060637
Train loss on 250 batch: 0.058321
: Epoch: 95 | Training Loss: 0.063901 | Val. Loss: 0.404264 | Val. Kappa Score: 0.8508 | LR: 0.000188 | Estimated time: 72.95
Train loss on 50 batch: 0.056523
Train loss on 100 batch: 0.057828
Train loss on 150 batch: 0.046748
Train loss on 200 batch: 0.048323
Train loss on 250 batch: 0.049299
: Epoch: 96 | Training Loss: 0.054970 | Val. Loss: 0.422116 | Val. Kappa Score: 0.8510 | LR: 0.000154 | Estimated time: 73.00
Train loss on 50 batch: 0.049410
Train loss on 100 batch: 0.058231
Train loss on 150 batch: 0.042336
Train loss on 200 batch: 0.040387
Train loss on 250 batch: 0.056507
: Epoch: 97 | Training Loss: 0.062815 | Val. Loss: 0.415438 | Val. Kappa Score: 0.8512 | LR: 0.000123 | Estimated time: 73.00
Train loss on 50 batch: 0.053208
Train loss on 100 batch: 0.050538
Train loss on 150 batch: 0.044819
Train loss on 200 batch: 0.054943
Train loss on 250 batch: 0.051346
: Epoch: 98 | Training Loss: 0.049420 | Val. Loss: 0.416927 | Val. Kappa Score: 0.8514 | LR: 0.000095 | Estimated time: 72.95
Train loss on 50 batch: 0.049135
Train loss on 100 batch: 0.057305
Train loss on 150 batch: 0.042450
Train loss on 200 batch: 0.033986
Train loss on 250 batch: 0.048242
: Epoch: 99 | Training Loss: 0.046300 | Val. Loss: 0.452775 | Val. Kappa Score: 0.8515 | LR: 0.000071 | Estimated time: 73.00
Train loss on 50 batch: 0.058383
Train loss on 100 batch: 0.043511
Train loss on 150 batch: 0.039860
Train loss on 200 batch: 0.047392
Train loss on 250 batch: 0.048310
: Epoch: 100 | Training Loss: 0.047467 | Val. Loss: 0.428218 | Val. Kappa Score: 0.8518 | LR: 0.000050 | Estimated time: 72.94
Train loss on 50 batch: 0.054703
Train loss on 100 batch: 0.043035
Train loss on 150 batch: 0.047458
Train loss on 200 batch: 0.039441
Train loss on 250 batch: 0.040133
: Epoch: 101 | Training Loss: 0.047431 | Val. Loss: 0.417894 | Val. Kappa Score: 0.8519 | LR: 0.000032 | Estimated time: 72.94
Train loss on 50 batch: 0.036879
Train loss on 100 batch: 0.041615
Train loss on 150 batch: 0.042982
Train loss on 200 batch: 0.050243
Train loss on 250 batch: 0.035411
: Epoch: 102 | Training Loss: 0.039613 | Val. Loss: 0.414306 | Val. Kappa Score: 0.8522 | LR: 0.000018 | Estimated time: 73.07
Train loss on 50 batch: 0.041186
Train loss on 100 batch: 0.045993
Train loss on 150 batch: 0.034959
Train loss on 200 batch: 0.036988
Train loss on 250 batch: 0.037399
: Epoch: 103 | Training Loss: 0.049072 | Val. Loss: 0.414372 | Val. Kappa Score: 0.8523 | LR: 0.000008 | Estimated time: 72.98
Train loss on 50 batch: 0.031436
Train loss on 100 batch: 0.037850
Train loss on 150 batch: 0.034668
Train loss on 200 batch: 0.041407
Train loss on 250 batch: 0.039671
: Epoch: 104 | Training Loss: 0.040410 | Val. Loss: 0.419092 | Val. Kappa Score: 0.8524 | LR: 0.000002 | Estimated time: 72.94
Train loss on 50 batch: 0.040033
Train loss on 100 batch: 0.043412
Train loss on 150 batch: 0.038633
Train loss on 200 batch: 0.040811
Train loss on 250 batch: 0.036341
: Epoch: 105 | Training Loss: 0.039639 | Val. Loss: 0.423015 | Val. Kappa Score: 0.8525 | LR: 0.000000 | Estimated time: 73.01
Train loss on 50 batch: 0.042007
Train loss on 100 batch: 0.035793
Train loss on 150 batch: 0.035115
Train loss on 200 batch: 0.035681
Train loss on 250 batch: 0.048579
: Epoch: 106 | Training Loss: 0.044202 | Val. Loss: 0.413602 | Val. Kappa Score: 0.8527 | LR: 0.000002 | Estimated time: 73.00
Train loss on 50 batch: 0.033450
Train loss on 100 batch: 0.035080
Train loss on 150 batch: 0.046808
Train loss on 200 batch: 0.037454
Train loss on 250 batch: 0.033238
: Epoch: 107 | Training Loss: 0.037241 | Val. Loss: 0.426038 | Val. Kappa Score: 0.8528 | LR: 0.000008 | Estimated time: 72.94
Train loss on 50 batch: 0.047593
Train loss on 100 batch: 0.043972
Train loss on 150 batch: 0.034676
Train loss on 200 batch: 0.038218
Train loss on 250 batch: 0.035413
: Epoch: 108 | Training Loss: 0.039488 | Val. Loss: 0.430890 | Val. Kappa Score: 0.8530 | LR: 0.000018 | Estimated time: 72.93
Train loss on 50 batch: 0.042838
Train loss on 100 batch: 0.037031
Train loss on 150 batch: 0.036789
Train loss on 200 batch: 0.042531
Train loss on 250 batch: 0.037431
: Epoch: 109 | Training Loss: 0.045120 | Val. Loss: 0.420999 | Val. Kappa Score: 0.8532 | LR: 0.000032 | Estimated time: 72.92
Train loss on 50 batch: 0.037349
Train loss on 100 batch: 0.035085
Train loss on 150 batch: 0.035470
Train loss on 200 batch: 0.041441
Train loss on 250 batch: 0.045959
: Epoch: 110 | Training Loss: 0.047226 | Val. Loss: 0.410247 | Val. Kappa Score: 0.8534 | LR: 0.000050 | Estimated time: 72.93
Train loss on 50 batch: 0.031514
Train loss on 100 batch: 0.031047
Train loss on 150 batch: 0.035628
Train loss on 200 batch: 0.045259
Train loss on 250 batch: 0.034860
: Epoch: 111 | Training Loss: 0.035396 | Val. Loss: 0.422989 | Val. Kappa Score: 0.8535 | LR: 0.000071 | Estimated time: 72.96
Train loss on 50 batch: 0.036051
Train loss on 100 batch: 0.039911
Train loss on 150 batch: 0.043136
Train loss on 200 batch: 0.043383
Train loss on 250 batch: 0.042254
: Epoch: 112 | Training Loss: 0.041101 | Val. Loss: 0.428917 | Val. Kappa Score: 0.8535 | LR: 0.000095 | Estimated time: 73.03
Train loss on 50 batch: 0.034109
Train loss on 100 batch: 0.039918
Train loss on 150 batch: 0.048744
Train loss on 200 batch: 0.043890
Train loss on 250 batch: 0.037538
: Epoch: 113 | Training Loss: 0.039713 | Val. Loss: 0.413898 | Val. Kappa Score: 0.8537 | LR: 0.000123 | Estimated time: 73.00
Train loss on 50 batch: 0.042421
Train loss on 100 batch: 0.047352
Train loss on 150 batch: 0.035963
Train loss on 200 batch: 0.032663
Train loss on 250 batch: 0.032341
: Epoch: 114 | Training Loss: 0.043574 | Val. Loss: 0.419506 | Val. Kappa Score: 0.8538 | LR: 0.000154 | Estimated time: 72.94
Train loss on 50 batch: 0.038670
Train loss on 100 batch: 0.039607
Train loss on 150 batch: 0.050773
Train loss on 200 batch: 0.044218
Train loss on 250 batch: 0.040504
: Epoch: 115 | Training Loss: 0.043322 | Val. Loss: 0.422199 | Val. Kappa Score: 0.8540 | LR: 0.000188 | Estimated time: 72.98
Train loss on 50 batch: 0.040196
Train loss on 100 batch: 0.042782
Train loss on 150 batch: 0.038650
Train loss on 200 batch: 0.059665
Train loss on 250 batch: 0.042066
: Epoch: 116 | Training Loss: 0.043583 | Val. Loss: 0.413842 | Val. Kappa Score: 0.8540 | LR: 0.000225 | Estimated time: 73.03
Train loss on 50 batch: 0.046156
Train loss on 100 batch: 0.054116
Train loss on 150 batch: 0.048244
Train loss on 200 batch: 0.053551
Train loss on 250 batch: 0.055769
: Epoch: 117 | Training Loss: 0.068075 | Val. Loss: 0.434183 | Val. Kappa Score: 0.8541 | LR: 0.000263 | Estimated time: 73.02
Train loss on 50 batch: 0.077985
Train loss on 100 batch: 0.074228
Train loss on 150 batch: 0.048483
Train loss on 200 batch: 0.052671
Train loss on 250 batch: 0.061615
: Epoch: 118 | Training Loss: 0.062005 | Val. Loss: 0.469835 | Val. Kappa Score: 0.8541 | LR: 0.000303 | Estimated time: 73.06
Train loss on 50 batch: 0.067379
Train loss on 100 batch: 0.049551
Train loss on 150 batch: 0.050443
Train loss on 200 batch: 0.069136
Train loss on 250 batch: 0.063079
: Epoch: 119 | Training Loss: 0.060559 | Val. Loss: 0.394176 | Val. Kappa Score: 0.8542 | LR: 0.000345 | Estimated time: 73.03
Train loss on 50 batch: 0.060914
Train loss on 100 batch: 0.066333
Train loss on 150 batch: 0.063156
Train loss on 200 batch: 0.053058
Train loss on 250 batch: 0.052792
: Epoch: 120 | Training Loss: 0.096735 | Val. Loss: 0.469133 | Val. Kappa Score: 0.8543 | LR: 0.000389 | Estimated time: 72.98
Train loss on 50 batch: 0.116941
Train loss on 100 batch: 0.099108
Train loss on 150 batch: 0.077702
Train loss on 200 batch: 0.066877
Train loss on 250 batch: 0.068190
: Epoch: 121 | Training Loss: 0.111485 | Val. Loss: 0.445503 | Val. Kappa Score: 0.8543 | LR: 0.000433 | Estimated time: 72.96
Train loss on 50 batch: 0.109540
Train loss on 100 batch: 0.090542
Train loss on 150 batch: 0.068252
Train loss on 200 batch: 0.098965
Train loss on 250 batch: 0.086105
: Epoch: 122 | Training Loss: 0.092586 | Val. Loss: 0.490028 | Val. Kappa Score: 0.8542 | LR: 0.000478 | Estimated time: 73.00
Train loss on 50 batch: 0.067129
Train loss on 100 batch: 0.073741
Train loss on 150 batch: 0.080274
Train loss on 200 batch: 0.091450
Train loss on 250 batch: 0.078295
: Epoch: 123 | Training Loss: 0.090217 | Val. Loss: 0.460472 | Val. Kappa Score: 0.8542 | LR: 0.000522 | Estimated time: 72.95
Train loss on 50 batch: 0.081685
Train loss on 100 batch: 0.093604
Train loss on 150 batch: 0.098696
Train loss on 200 batch: 0.090829
Train loss on 250 batch: 0.085187
: Epoch: 124 | Training Loss: 0.093088 | Val. Loss: 0.501233 | Val. Kappa Score: 0.8542 | LR: 0.000567 | Estimated time: 73.03
Train loss on 50 batch: 0.091702
Train loss on 100 batch: 0.098565
Train loss on 150 batch: 0.088335
Train loss on 200 batch: 0.073838
Train loss on 250 batch: 0.073046
: Epoch: 125 | Training Loss: 0.090426 | Val. Loss: 0.470491 | Val. Kappa Score: 0.8542 | LR: 0.000611 | Estimated time: 73.01
Train loss on 50 batch: 0.087003
Train loss on 100 batch: 0.103538
Train loss on 150 batch: 0.117844
Train loss on 200 batch: 0.086427
Train loss on 250 batch: 0.088629
: Epoch: 126 | Training Loss: 0.103661 | Val. Loss: 0.487193 | Val. Kappa Score: 0.8541 | LR: 0.000655 | Estimated time: 73.10
Train loss on 50 batch: 0.108984
Train loss on 100 batch: 0.093582
Train loss on 150 batch: 0.120980
Train loss on 200 batch: 0.085733
Train loss on 250 batch: 0.176607
: Epoch: 127 | Training Loss: 0.122704 | Val. Loss: 0.528315 | Val. Kappa Score: 0.8540 | LR: 0.000697 | Estimated time: 72.92
Train loss on 50 batch: 0.103500
Train loss on 100 batch: 0.146909
Train loss on 150 batch: 0.125783
Train loss on 200 batch: 0.128890
Train loss on 250 batch: 0.149203
: Epoch: 128 | Training Loss: 0.143171 | Val. Loss: 0.464368 | Val. Kappa Score: 0.8539 | LR: 0.000737 | Estimated time: 72.94
Train loss on 50 batch: 0.185516
Train loss on 100 batch: 0.118218
Train loss on 150 batch: 0.154746
Train loss on 200 batch: 0.148941
Train loss on 250 batch: 0.122424
: Epoch: 129 | Training Loss: 0.137156 | Val. Loss: 0.435258 | Val. Kappa Score: 0.8540 | LR: 0.000775 | Estimated time: 72.98
Train loss on 50 batch: 0.115271
Train loss on 100 batch: 0.101375
Train loss on 150 batch: 0.110461
Train loss on 200 batch: 0.089843
Train loss on 250 batch: 0.092202
: Epoch: 130 | Training Loss: 0.099505 | Val. Loss: 0.461919 | Val. Kappa Score: 0.8541 | LR: 0.000812 | Estimated time: 72.98
Train loss on 50 batch: 0.094728
Train loss on 100 batch: 0.128334
Train loss on 150 batch: 0.116435
Train loss on 200 batch: 0.137489
Train loss on 250 batch: 0.120252
: Epoch: 131 | Training Loss: 0.128315 | Val. Loss: 0.475747 | Val. Kappa Score: 0.8540 | LR: 0.000846 | Estimated time: 73.03
Train loss on 50 batch: 0.157020
Train loss on 100 batch: 0.156158
Train loss on 150 batch: 0.150556
Train loss on 200 batch: 0.155751
Train loss on 250 batch: 0.200343
: Epoch: 132 | Training Loss: 0.164012 | Val. Loss: 0.577387 | Val. Kappa Score: 0.8539 | LR: 0.000877 | Estimated time: 72.96
Train loss on 50 batch: 0.169837
Train loss on 100 batch: 0.133924
Train loss on 150 batch: 0.143105
Train loss on 200 batch: 0.131802
Train loss on 250 batch: 0.127419
: Epoch: 133 | Training Loss: 0.150913 | Val. Loss: 0.534125 | Val. Kappa Score: 0.8537 | LR: 0.000905 | Estimated time: 72.92
Train loss on 50 batch: 0.132507
Train loss on 100 batch: 0.115333
Train loss on 150 batch: 0.155155
Train loss on 200 batch: 0.133198
Train loss on 250 batch: 0.130690
: Epoch: 134 | Training Loss: 0.150416 | Val. Loss: 0.429541 | Val. Kappa Score: 0.8537 | LR: 0.000929 | Estimated time: 73.04
Train loss on 50 batch: 0.166820
Train loss on 100 batch: 0.147666
Train loss on 150 batch: 0.131421
Train loss on 200 batch: 0.150850
Train loss on 250 batch: 0.132365
: Epoch: 135 | Training Loss: 0.151623 | Val. Loss: 0.489029 | Val. Kappa Score: 0.8536 | LR: 0.000950 | Estimated time: 73.00
Train loss on 50 batch: 0.171455
Train loss on 100 batch: 0.155954
Train loss on 150 batch: 0.161417
Train loss on 200 batch: 0.209389
Train loss on 250 batch: 0.157986
: Epoch: 136 | Training Loss: 0.167652 | Val. Loss: 0.459331 | Val. Kappa Score: 0.8537 | LR: 0.000968 | Estimated time: 72.95
Train loss on 50 batch: 0.156258
Train loss on 100 batch: 0.158110
Train loss on 150 batch: 0.140506
Train loss on 200 batch: 0.193161
Train loss on 250 batch: 0.157585
: Epoch: 137 | Training Loss: 0.182833 | Val. Loss: 0.458950 | Val. Kappa Score: 0.8537 | LR: 0.000982 | Estimated time: 73.07
Train loss on 50 batch: 0.169730
Train loss on 100 batch: 0.140589
Train loss on 150 batch: 0.133264
Train loss on 200 batch: 0.141515
Train loss on 250 batch: 0.151428
: Epoch: 138 | Training Loss: 0.164922 | Val. Loss: 0.399352 | Val. Kappa Score: 0.8538 | LR: 0.000992 | Estimated time: 73.00
Train loss on 50 batch: 0.156967
Train loss on 100 batch: 0.180385
Train loss on 150 batch: 0.193715
Train loss on 200 batch: 0.149055
Train loss on 250 batch: 0.132558
: Epoch: 139 | Training Loss: 0.159879 | Val. Loss: 0.477725 | Val. Kappa Score: 0.8538 | LR: 0.000998 | Estimated time: 73.04
Train loss on 50 batch: 0.155034
Train loss on 100 batch: 0.152089
Train loss on 150 batch: 0.161503
Train loss on 200 batch: 0.168908
Train loss on 250 batch: 0.136373
: Epoch: 140 | Training Loss: 0.159247 | Val. Loss: 0.632452 | Val. Kappa Score: 0.8537 | LR: 0.001000 | Estimated time: 72.93
Train loss on 50 batch: 0.141826
Train loss on 100 batch: 0.119370
Train loss on 150 batch: 0.135677
Train loss on 200 batch: 0.146502
Train loss on 250 batch: 0.167562
: Epoch: 141 | Training Loss: 0.152017 | Val. Loss: 0.482970 | Val. Kappa Score: 0.8537 | LR: 0.000998 | Estimated time: 73.08
Train loss on 50 batch: 0.147660
Train loss on 100 batch: 0.126405
Train loss on 150 batch: 0.169692
Train loss on 200 batch: 0.142536
Train loss on 250 batch: 0.161727
: Epoch: 142 | Training Loss: 0.163261 | Val. Loss: 0.527620 | Val. Kappa Score: 0.8536 | LR: 0.000992 | Estimated time: 72.99
Train loss on 50 batch: 0.176296
Train loss on 100 batch: 0.190675
Train loss on 150 batch: 0.158477
Train loss on 200 batch: 0.148151
Train loss on 250 batch: 0.141056
: Epoch: 143 | Training Loss: 0.156376 | Val. Loss: 0.471100 | Val. Kappa Score: 0.8535 | LR: 0.000982 | Estimated time: 72.93
Train loss on 50 batch: 0.109963
Train loss on 100 batch: 0.129431
Train loss on 150 batch: 0.138531
Train loss on 200 batch: 0.163604
Train loss on 250 batch: 0.157577
: Epoch: 144 | Training Loss: 0.147110 | Val. Loss: 0.482925 | Val. Kappa Score: 0.8534 | LR: 0.000968 | Estimated time: 72.97
Train loss on 50 batch: 0.222325
Train loss on 100 batch: 0.166776
Train loss on 150 batch: 0.199669
Train loss on 200 batch: 0.131361
Train loss on 250 batch: 0.130735
: Epoch: 145 | Training Loss: 0.165759 | Val. Loss: 0.420313 | Val. Kappa Score: 0.8536 | LR: 0.000950 | Estimated time: 72.99
Train loss on 50 batch: 0.105322
Train loss on 100 batch: 0.119260
Train loss on 150 batch: 0.139581
Train loss on 200 batch: 0.134902
Train loss on 250 batch: 0.121938
: Epoch: 146 | Training Loss: 0.127410 | Val. Loss: 0.487084 | Val. Kappa Score: 0.8536 | LR: 0.000929 | Estimated time: 73.04
Train loss on 50 batch: 0.115670
Train loss on 100 batch: 0.109997
Train loss on 150 batch: 0.123114
Train loss on 200 batch: 0.123293
Train loss on 250 batch: 0.113976
: Epoch: 147 | Training Loss: 0.158395 | Val. Loss: 0.516885 | Val. Kappa Score: 0.8535 | LR: 0.000905 | Estimated time: 72.99
Train loss on 50 batch: 0.328630
Train loss on 100 batch: 0.190816
Train loss on 150 batch: 0.153715
Train loss on 200 batch: 0.155339
Train loss on 250 batch: 0.138269
: Epoch: 148 | Training Loss: 0.178845 | Val. Loss: 0.553385 | Val. Kappa Score: 0.8534 | LR: 0.000877 | Estimated time: 73.04
Train loss on 50 batch: 0.115795
Train loss on 100 batch: 0.146934
Train loss on 150 batch: 0.119471
Train loss on 200 batch: 0.138149
Train loss on 250 batch: 0.140038
: Epoch: 149 | Training Loss: 0.135783 | Val. Loss: 0.447980 | Val. Kappa Score: 0.8534 | LR: 0.000846 | Estimated time: 73.00
Train loss on 50 batch: 0.126165
Train loss on 100 batch: 0.111872
Train loss on 150 batch: 0.113352
Train loss on 200 batch: 0.089755
Train loss on 250 batch: 0.078829
: Epoch: 150 | Training Loss: 0.107874 | Val. Loss: 0.507715 | Val. Kappa Score: 0.8532 | LR: 0.000812 | Estimated time: 72.94
Train loss on 50 batch: 0.091473
Train loss on 100 batch: 0.103180
Train loss on 150 batch: 0.088877
Train loss on 200 batch: 0.124128
Train loss on 250 batch: 0.123387
: Epoch: 151 | Training Loss: 0.104541 | Val. Loss: 0.411791 | Val. Kappa Score: 0.8533 | LR: 0.000775 | Estimated time: 72.96
Train loss on 50 batch: 0.122837
Train loss on 100 batch: 0.119580
Train loss on 150 batch: 0.080849
Train loss on 200 batch: 0.089922
Train loss on 250 batch: 0.079979
: Epoch: 152 | Training Loss: 0.096852 | Val. Loss: 0.446530 | Val. Kappa Score: 0.8533 | LR: 0.000737 | Estimated time: 72.89
Train loss on 50 batch: 0.061419
Train loss on 100 batch: 0.082253
Train loss on 150 batch: 0.076211
Train loss on 200 batch: 0.074490
Train loss on 250 batch: 0.095423
: Epoch: 153 | Training Loss: 0.082539 | Val. Loss: 0.462083 | Val. Kappa Score: 0.8534 | LR: 0.000697 | Estimated time: 73.02
Train loss on 50 batch: 0.100116
Train loss on 100 batch: 0.081717
Train loss on 150 batch: 0.081768
Train loss on 200 batch: 0.076552
Train loss on 250 batch: 0.079115
: Epoch: 154 | Training Loss: 0.083178 | Val. Loss: 0.461520 | Val. Kappa Score: 0.8534 | LR: 0.000655 | Estimated time: 72.95
Train loss on 50 batch: 0.068395
Train loss on 100 batch: 0.061385
Train loss on 150 batch: 0.090943
Train loss on 200 batch: 0.063235
Train loss on 250 batch: 0.058258
: Epoch: 155 | Training Loss: 0.069339 | Val. Loss: 0.445315 | Val. Kappa Score: 0.8534 | LR: 0.000611 | Estimated time: 72.85
Train loss on 50 batch: 0.070903
Train loss on 100 batch: 0.067264
Train loss on 150 batch: 0.083425
Train loss on 200 batch: 0.083498
Train loss on 250 batch: 0.074172
: Epoch: 156 | Training Loss: 0.097926 | Val. Loss: 0.461007 | Val. Kappa Score: 0.8535 | LR: 0.000567 | Estimated time: 73.05
Train loss on 50 batch: 0.085893
Train loss on 100 batch: 0.106006
Train loss on 150 batch: 0.087758
Train loss on 200 batch: 0.091308
Train loss on 250 batch: 0.081158
: Epoch: 157 | Training Loss: 0.109332 | Val. Loss: 0.416651 | Val. Kappa Score: 0.8536 | LR: 0.000522 | Estimated time: 73.00
Train loss on 50 batch: 0.096152
Train loss on 100 batch: 0.069371
Train loss on 150 batch: 0.056156
Train loss on 200 batch: 0.062534
Train loss on 250 batch: 0.070399
: Epoch: 158 | Training Loss: 0.073405 | Val. Loss: 0.496399 | Val. Kappa Score: 0.8535 | LR: 0.000478 | Estimated time: 72.99
Train loss on 50 batch: 0.057092
Train loss on 100 batch: 0.047223
Train loss on 150 batch: 0.055391
Train loss on 200 batch: 0.055305
Train loss on 250 batch: 0.040887
: Epoch: 159 | Training Loss: 0.052474 | Val. Loss: 0.461030 | Val. Kappa Score: 0.8534 | LR: 0.000433 | Estimated time: 72.93
Train loss on 50 batch: 0.051458
Train loss on 100 batch: 0.046374
Train loss on 150 batch: 0.052548
Train loss on 200 batch: 0.056560
Train loss on 250 batch: 0.047521
: Epoch: 160 | Training Loss: 0.051106 | Val. Loss: 0.456833 | Val. Kappa Score: 0.8534 | LR: 0.000389 | Estimated time: 72.97
Train loss on 50 batch: 0.052814
Train loss on 100 batch: 0.049142
Train loss on 150 batch: 0.038995
Train loss on 200 batch: 0.032806
Train loss on 250 batch: 0.039803
: Epoch: 161 | Training Loss: 0.057733 | Val. Loss: 0.447802 | Val. Kappa Score: 0.8535 | LR: 0.000345 | Estimated time: 72.97
Train loss on 50 batch: 0.075074
Train loss on 100 batch: 0.042831
Train loss on 150 batch: 0.040700
Train loss on 200 batch: 0.049644
Train loss on 250 batch: 0.043867
: Epoch: 162 | Training Loss: 0.049064 | Val. Loss: 0.498806 | Val. Kappa Score: 0.8535 | LR: 0.000303 | Estimated time: 72.95
Train loss on 50 batch: 0.035929
Train loss on 100 batch: 0.049311
Train loss on 150 batch: 0.050800
Train loss on 200 batch: 0.046183
Train loss on 250 batch: 0.045976
: Epoch: 163 | Training Loss: 0.050522 | Val. Loss: 0.425216 | Val. Kappa Score: 0.8535 | LR: 0.000263 | Estimated time: 73.03
Train loss on 50 batch: 0.049160
Train loss on 100 batch: 0.039858
Train loss on 150 batch: 0.048134
Train loss on 200 batch: 0.038240
Train loss on 250 batch: 0.050954
: Epoch: 164 | Training Loss: 0.053015 | Val. Loss: 0.442612 | Val. Kappa Score: 0.8536 | LR: 0.000225 | Estimated time: 73.00
Train loss on 50 batch: 0.038694
Train loss on 100 batch: 0.035544
Train loss on 150 batch: 0.041016
Train loss on 200 batch: 0.026103
Train loss on 250 batch: 0.032531
: Epoch: 165 | Training Loss: 0.036511 | Val. Loss: 0.433239 | Val. Kappa Score: 0.8536 | LR: 0.000188 | Estimated time: 72.96
Train loss on 50 batch: 0.035783
Train loss on 100 batch: 0.041309
Train loss on 150 batch: 0.032851
Train loss on 200 batch: 0.025701
Train loss on 250 batch: 0.024098
: Epoch: 166 | Training Loss: 0.035015 | Val. Loss: 0.430004 | Val. Kappa Score: 0.8537 | LR: 0.000154 | Estimated time: 73.00
Train loss on 50 batch: 0.030483
Train loss on 100 batch: 0.027401
Train loss on 150 batch: 0.037514
Train loss on 200 batch: 0.026432
Train loss on 250 batch: 0.035484
: Epoch: 167 | Training Loss: 0.042019 | Val. Loss: 0.483190 | Val. Kappa Score: 0.8537 | LR: 0.000123 | Estimated time: 72.87
Train loss on 50 batch: 0.028720
Train loss on 100 batch: 0.028669
Train loss on 150 batch: 0.027063
Train loss on 200 batch: 0.029614
Train loss on 250 batch: 0.032918
: Epoch: 168 | Training Loss: 0.040067 | Val. Loss: 0.454806 | Val. Kappa Score: 0.8537 | LR: 0.000095 | Estimated time: 73.00
Train loss on 50 batch: 0.031431
Train loss on 100 batch: 0.029869
Train loss on 150 batch: 0.024168
Train loss on 200 batch: 0.028289
Train loss on 250 batch: 0.022642
: Epoch: 169 | Training Loss: 0.043705 | Val. Loss: 0.436641 | Val. Kappa Score: 0.8537 | LR: 0.000071 | Estimated time: 72.96
Train loss on 50 batch: 0.025456
Train loss on 100 batch: 0.022194
Train loss on 150 batch: 0.034645
Train loss on 200 batch: 0.022924
Train loss on 250 batch: 0.022402
: Epoch: 170 | Training Loss: 0.025664 | Val. Loss: 0.435800 | Val. Kappa Score: 0.8537 | LR: 0.000050 | Estimated time: 73.01
Train loss on 50 batch: 0.022234
Train loss on 100 batch: 0.024366
Train loss on 150 batch: 0.028974
Train loss on 200 batch: 0.028333
Train loss on 250 batch: 0.020681
: Epoch: 171 | Training Loss: 0.031614 | Val. Loss: 0.454941 | Val. Kappa Score: 0.8538 | LR: 0.000032 | Estimated time: 72.94
Train loss on 50 batch: 0.020559
Train loss on 100 batch: 0.026787
Train loss on 150 batch: 0.024542
Train loss on 200 batch: 0.022926
Train loss on 250 batch: 0.024809
: Epoch: 172 | Training Loss: 0.024462 | Val. Loss: 0.438342 | Val. Kappa Score: 0.8538 | LR: 0.000018 | Estimated time: 72.98
Train loss on 50 batch: 0.024298
Train loss on 100 batch: 0.022619
Train loss on 150 batch: 0.023858
Train loss on 200 batch: 0.026251
Train loss on 250 batch: 0.022712
: Epoch: 173 | Training Loss: 0.024291 | Val. Loss: 0.442687 | Val. Kappa Score: 0.8539 | LR: 0.000008 | Estimated time: 73.06
Train loss on 50 batch: 0.024362
Train loss on 100 batch: 0.019709
Train loss on 150 batch: 0.019952
Train loss on 200 batch: 0.024242
Train loss on 250 batch: 0.024633
: Epoch: 174 | Training Loss: 0.023726 | Val. Loss: 0.441312 | Val. Kappa Score: 0.8539 | LR: 0.000002 | Estimated time: 72.99
Train loss on 50 batch: 0.020639
Train loss on 100 batch: 0.030759
Train loss on 150 batch: 0.020512
Train loss on 200 batch: 0.024928
Train loss on 250 batch: 0.017982
: Epoch: 175 | Training Loss: 0.042117 | Val. Loss: 0.436686 | Val. Kappa Score: 0.8540 | LR: 0.000000 | Estimated time: 72.96
Train loss on 50 batch: 0.029423
Train loss on 100 batch: 0.022088
Train loss on 150 batch: 0.019435
Train loss on 200 batch: 0.020718
Train loss on 250 batch: 0.018084
: Epoch: 176 | Training Loss: 0.022790 | Val. Loss: 0.435702 | Val. Kappa Score: 0.8540 | LR: 0.000002 | Estimated time: 73.07
Train loss on 50 batch: 0.023847
Train loss on 100 batch: 0.019702
Train loss on 150 batch: 0.024209
Train loss on 200 batch: 0.022552
Train loss on 250 batch: 0.027016
: Epoch: 177 | Training Loss: 0.029367 | Val. Loss: 0.451474 | Val. Kappa Score: 0.8540 | LR: 0.000008 | Estimated time: 72.99
Train loss on 50 batch: 0.019011
Train loss on 100 batch: 0.020549
Train loss on 150 batch: 0.023224
Train loss on 200 batch: 0.026889
Train loss on 250 batch: 0.022884
: Epoch: 178 | Training Loss: 0.030647 | Val. Loss: 0.452557 | Val. Kappa Score: 0.8540 | LR: 0.000018 | Estimated time: 73.03
Train loss on 50 batch: 0.032952
Train loss on 100 batch: 0.018131
Train loss on 150 batch: 0.025664
Train loss on 200 batch: 0.020069
Train loss on 250 batch: 0.027229
: Epoch: 179 | Training Loss: 0.035043 | Val. Loss: 0.445891 | Val. Kappa Score: 0.8540 | LR: 0.000032 | Estimated time: 72.95
Train loss on 50 batch: 0.028499
Train loss on 100 batch: 0.023057
Train loss on 150 batch: 0.027739
Train loss on 200 batch: 0.020057
Train loss on 250 batch: 0.017913
: Epoch: 180 | Training Loss: 0.030327 | Val. Loss: 0.451746 | Val. Kappa Score: 0.8541 | LR: 0.000050 | Estimated time: 73.00
Train loss on 50 batch: 0.031021
Train loss on 100 batch: 0.019517
Train loss on 150 batch: 0.022461
Train loss on 200 batch: 0.018863
Train loss on 250 batch: 0.018093
: Epoch: 181 | Training Loss: 0.022289 | Val. Loss: 0.437818 | Val. Kappa Score: 0.8541 | LR: 0.000071 | Estimated time: 72.95
Train loss on 50 batch: 0.022729
Train loss on 100 batch: 0.021706
Train loss on 150 batch: 0.022397
Train loss on 200 batch: 0.027652
Train loss on 250 batch: 0.030515
: Epoch: 182 | Training Loss: 0.026378 | Val. Loss: 0.438914 | Val. Kappa Score: 0.8542 | LR: 0.000095 | Estimated time: 72.91
Train loss on 50 batch: 0.032277
Train loss on 100 batch: 0.018556
Train loss on 150 batch: 0.027025
Train loss on 200 batch: 0.023948
Train loss on 250 batch: 0.021011
: Epoch: 183 | Training Loss: 0.024934 | Val. Loss: 0.428109 | Val. Kappa Score: 0.8542 | LR: 0.000123 | Estimated time: 72.95
Train loss on 50 batch: 0.030045
Train loss on 100 batch: 0.022273
Train loss on 150 batch: 0.020578
Train loss on 200 batch: 0.031935
Train loss on 250 batch: 0.028389
: Epoch: 184 | Training Loss: 0.039682 | Val. Loss: 0.452397 | Val. Kappa Score: 0.8543 | LR: 0.000154 | Estimated time: 73.04
Train loss on 50 batch: 0.029933
Train loss on 100 batch: 0.029614
Train loss on 150 batch: 0.033538
Train loss on 200 batch: 0.023205
Train loss on 250 batch: 0.024136
: Epoch: 185 | Training Loss: 0.033298 | Val. Loss: 0.459214 | Val. Kappa Score: 0.8543 | LR: 0.000188 | Estimated time: 72.95
Train loss on 50 batch: 0.035847
Train loss on 100 batch: 0.024988
Train loss on 150 batch: 0.024727
Train loss on 200 batch: 0.032999
Train loss on 250 batch: 0.025113
: Epoch: 186 | Training Loss: 0.029405 | Val. Loss: 0.424975 | Val. Kappa Score: 0.8544 | LR: 0.000225 | Estimated time: 72.92
Train loss on 50 batch: 0.027248
Train loss on 100 batch: 0.039686
Train loss on 150 batch: 0.022099
Train loss on 200 batch: 0.033118
Train loss on 250 batch: 0.033269
: Epoch: 187 | Training Loss: 0.029330 | Val. Loss: 0.423989 | Val. Kappa Score: 0.8544 | LR: 0.000263 | Estimated time: 72.97
Train loss on 50 batch: 0.033761
Train loss on 100 batch: 0.027614
Train loss on 150 batch: 0.034251
Train loss on 200 batch: 0.037650
Train loss on 250 batch: 0.028031
: Epoch: 188 | Training Loss: 0.034251 | Val. Loss: 0.445219 | Val. Kappa Score: 0.8545 | LR: 0.000303 | Estimated time: 73.01
Train loss on 50 batch: 0.044680
Train loss on 100 batch: 0.045363
Train loss on 150 batch: 0.032958
Train loss on 200 batch: 0.036779
Train loss on 250 batch: 0.034924
: Epoch: 189 | Training Loss: 0.061461 | Val. Loss: 0.454371 | Val. Kappa Score: 0.8545 | LR: 0.000345 | Estimated time: 72.98
Train loss on 50 batch: 0.051332
Train loss on 100 batch: 0.033848
Train loss on 150 batch: 0.029187
Train loss on 200 batch: 0.041438
Train loss on 250 batch: 0.058260
: Epoch: 190 | Training Loss: 0.049366 | Val. Loss: 0.500864 | Val. Kappa Score: 0.8546 | LR: 0.000389 | Estimated time: 73.09
Train loss on 50 batch: 0.045350
Train loss on 100 batch: 0.037884
Train loss on 150 batch: 0.038315
Train loss on 200 batch: 0.034544
Train loss on 250 batch: 0.035365
: Epoch: 191 | Training Loss: 0.043945 | Val. Loss: 0.482898 | Val. Kappa Score: 0.8546 | LR: 0.000433 | Estimated time: 73.02
Train loss on 50 batch: 0.050427
Train loss on 100 batch: 0.047524
Train loss on 150 batch: 0.036882
Train loss on 200 batch: 0.060497
Train loss on 250 batch: 0.068985
: Epoch: 192 | Training Loss: 0.062357 | Val. Loss: 0.513474 | Val. Kappa Score: 0.8545 | LR: 0.000478 | Estimated time: 72.90
Train loss on 50 batch: 0.069861
Train loss on 100 batch: 0.062789
Train loss on 150 batch: 0.069512
Train loss on 200 batch: 0.088612
Train loss on 250 batch: 0.101654
: Epoch: 193 | Training Loss: 0.081248 | Val. Loss: 0.495670 | Val. Kappa Score: 0.8545 | LR: 0.000522 | Estimated time: 72.98
Train loss on 50 batch: 0.066193
Train loss on 100 batch: 0.100438
Train loss on 150 batch: 0.077584
Train loss on 200 batch: 0.085363
Train loss on 250 batch: 0.092107
: Epoch: 194 | Training Loss: 0.090875 | Val. Loss: 0.442250 | Val. Kappa Score: 0.8545 | LR: 0.000567 | Estimated time: 72.98
Train loss on 50 batch: 0.097621
Train loss on 100 batch: 0.063588
Train loss on 150 batch: 0.076588
Train loss on 200 batch: 0.078763
Train loss on 250 batch: 0.086633
: Epoch: 195 | Training Loss: 0.077705 | Val. Loss: 0.411623 | Val. Kappa Score: 0.8546 | LR: 0.000611 | Estimated time: 73.12
Train loss on 50 batch: 0.089072
Train loss on 100 batch: 0.089921
Train loss on 150 batch: 0.070228
Train loss on 200 batch: 0.084234
Train loss on 250 batch: 0.077712
: Epoch: 196 | Training Loss: 0.079825 | Val. Loss: 0.456288 | Val. Kappa Score: 0.8546 | LR: 0.000655 | Estimated time: 72.99
Train loss on 50 batch: 0.065878
Train loss on 100 batch: 0.054072
Train loss on 150 batch: 0.059969
Train loss on 200 batch: 0.075866
Train loss on 250 batch: 0.077147
: Epoch: 197 | Training Loss: 0.065008 | Val. Loss: 0.427911 | Val. Kappa Score: 0.8546 | LR: 0.000697 | Estimated time: 73.06
Train loss on 50 batch: 0.062997
Train loss on 100 batch: 0.043341
Train loss on 150 batch: 0.066258
Train loss on 200 batch: 0.049190
Train loss on 250 batch: 0.093022
: Epoch: 198 | Training Loss: 0.067514 | Val. Loss: 0.462113 | Val. Kappa Score: 0.8546 | LR: 0.000737 | Estimated time: 73.03
Train loss on 50 batch: 0.093633
Train loss on 100 batch: 0.073038
Train loss on 150 batch: 0.107935
Train loss on 200 batch: 0.092881
Train loss on 250 batch: 0.069418
: Epoch: 199 | Training Loss: 0.088702 | Val. Loss: 0.453737 | Val. Kappa Score: 0.8547 | LR: 0.000775 | Estimated time: 73.01
Train loss on 50 batch: 0.058008
Train loss on 100 batch: 0.055435
Train loss on 150 batch: 0.070258
Train loss on 200 batch: 0.072359
Train loss on 250 batch: 0.055910
: Epoch: 200 | Training Loss: 0.063664 | Val. Loss: 0.447225 | Val. Kappa Score: 0.8546 | LR: 0.000812 | Estimated time: 72.92
Train loss on 50 batch: 0.074551
Train loss on 100 batch: 0.091549
Train loss on 150 batch: 0.094887
Train loss on 200 batch: 0.185769
Train loss on 250 batch: 0.150741
: Epoch: 201 | Training Loss: 0.133283 | Val. Loss: 0.449077 | Val. Kappa Score: 0.8547 | LR: 0.000846 | Estimated time: 72.97
Train loss on 50 batch: 0.128725
Train loss on 100 batch: 0.127730
Train loss on 150 batch: 0.149583
Train loss on 200 batch: 0.113516
Train loss on 250 batch: 0.143303
: Epoch: 202 | Training Loss: 0.131532 | Val. Loss: 0.451779 | Val. Kappa Score: 0.8546 | LR: 0.000877 | Estimated time: 72.93
Train loss on 50 batch: 0.120951
Train loss on 100 batch: 0.090897
Train loss on 150 batch: 0.102745
Train loss on 200 batch: 0.090678
Train loss on 250 batch: 0.098731
: Epoch: 203 | Training Loss: 0.098726 | Val. Loss: 0.506099 | Val. Kappa Score: 0.8546 | LR: 0.000905 | Estimated time: 73.19
Train loss on 50 batch: 0.080945
Train loss on 100 batch: 0.070566
Train loss on 150 batch: 0.088784
Train loss on 200 batch: 0.084957
Train loss on 250 batch: 0.101036
: Epoch: 204 | Training Loss: 0.098176 | Val. Loss: 0.431999 | Val. Kappa Score: 0.8546 | LR: 0.000929 | Estimated time: 72.98
Train loss on 50 batch: 0.107418
Train loss on 100 batch: 0.079332
Train loss on 150 batch: 0.085868
Train loss on 200 batch: 0.081770
Train loss on 250 batch: 0.091156
: Epoch: 205 | Training Loss: 0.099709 | Val. Loss: 0.427600 | Val. Kappa Score: 0.8547 | LR: 0.000950 | Estimated time: 72.89
Train loss on 50 batch: 0.128394
Train loss on 100 batch: 0.090219
Train loss on 150 batch: 0.098676
Train loss on 200 batch: 0.141154
Train loss on 250 batch: 0.131261
: Epoch: 206 | Training Loss: 0.130137 | Val. Loss: 0.457819 | Val. Kappa Score: 0.8546 | LR: 0.000968 | Estimated time: 72.98
Train loss on 50 batch: 0.112426
Train loss on 100 batch: 0.093569
Train loss on 150 batch: 0.167177
Train loss on 200 batch: 0.119685
Train loss on 250 batch: 0.137292
: Epoch: 207 | Training Loss: 0.125658 | Val. Loss: 0.534251 | Val. Kappa Score: 0.8545 | LR: 0.000982 | Estimated time: 72.92
Train loss on 50 batch: 0.104123
Train loss on 100 batch: 0.095378
Train loss on 150 batch: 0.103097
Train loss on 200 batch: 0.086944
Train loss on 250 batch: 0.081989
: Epoch: 208 | Training Loss: 0.099444 | Val. Loss: 0.519730 | Val. Kappa Score: 0.8544 | LR: 0.000992 | Estimated time: 72.93
Train loss on 50 batch: 0.092287
Train loss on 100 batch: 0.119259
Train loss on 150 batch: 0.108960
Train loss on 200 batch: 0.124052
Train loss on 250 batch: 0.167933
: Epoch: 209 | Training Loss: 0.134764 | Val. Loss: 0.461670 | Val. Kappa Score: 0.8545 | LR: 0.000998 | Estimated time: 73.03
Train loss on 50 batch: 0.117493
Train loss on 100 batch: 0.079692
Train loss on 150 batch: 0.152443
Train loss on 200 batch: 0.141729
Train loss on 250 batch: 0.122343
: Epoch: 210 | Training Loss: 0.130188 | Val. Loss: 0.471496 | Val. Kappa Score: 0.8545 | LR: 0.001000 | Estimated time: 72.94
Train loss on 50 batch: 0.127908
Train loss on 100 batch: 0.126145
Train loss on 150 batch: 0.126361
Train loss on 200 batch: 0.100960
Train loss on 250 batch: 0.152168
: Epoch: 211 | Training Loss: 0.134747 | Val. Loss: 0.546113 | Val. Kappa Score: 0.8543 | LR: 0.000998 | Estimated time: 73.03
Train loss on 50 batch: 0.147621
Train loss on 100 batch: 0.114577
Train loss on 150 batch: 0.114836
Train loss on 200 batch: 0.108190
Train loss on 250 batch: 0.098989
: Epoch: 212 | Training Loss: 0.114179 | Val. Loss: 0.461501 | Val. Kappa Score: 0.8543 | LR: 0.000992 | Estimated time: 73.03
Train loss on 50 batch: 0.108345
Train loss on 100 batch: 0.105326
Train loss on 150 batch: 0.122149
Train loss on 200 batch: 0.111633
Train loss on 250 batch: 0.088827
: Epoch: 213 | Training Loss: 0.134209 | Val. Loss: 0.602431 | Val. Kappa Score: 0.8541 | LR: 0.000982 | Estimated time: 72.94
Train loss on 50 batch: 0.210658
Train loss on 100 batch: 0.132492
Train loss on 150 batch: 0.107244
Train loss on 200 batch: 0.118768
Train loss on 250 batch: 0.170857
: Epoch: 214 | Training Loss: 0.155783 | Val. Loss: 0.497284 | Val. Kappa Score: 0.8541 | LR: 0.000968 | Estimated time: 72.89
Train loss on 50 batch: 0.125239
Train loss on 100 batch: 0.105197
Train loss on 150 batch: 0.143142
Train loss on 200 batch: 0.114558
Train loss on 250 batch: 0.098372
: Epoch: 215 | Training Loss: 0.117110 | Val. Loss: 0.445692 | Val. Kappa Score: 0.8541 | LR: 0.000950 | Estimated time: 72.94
Train loss on 50 batch: 0.102672
Train loss on 100 batch: 0.094332
Train loss on 150 batch: 0.095764
Train loss on 200 batch: 0.111378
Train loss on 250 batch: 0.105223
: Epoch: 216 | Training Loss: 0.100576 | Val. Loss: 0.452665 | Val. Kappa Score: 0.8541 | LR: 0.000929 | Estimated time: 72.94
Train loss on 50 batch: 0.089418
Train loss on 100 batch: 0.063446
Train loss on 150 batch: 0.077387
Train loss on 200 batch: 0.085439
Train loss on 250 batch: 0.072380
: Epoch: 217 | Training Loss: 0.098658 | Val. Loss: 0.475470 | Val. Kappa Score: 0.8541 | LR: 0.000905 | Estimated time: 73.02
Train loss on 50 batch: 0.200542
Train loss on 100 batch: 0.100114
Train loss on 150 batch: 0.083041
Train loss on 200 batch: 0.110078
Train loss on 250 batch: 0.095307
: Epoch: 218 | Training Loss: 0.114574 | Val. Loss: 0.461379 | Val. Kappa Score: 0.8542 | LR: 0.000877 | Estimated time: 72.97
Train loss on 50 batch: 0.067351
Train loss on 100 batch: 0.086663
Train loss on 150 batch: 0.100618
Train loss on 200 batch: 0.075475
Train loss on 250 batch: 0.099991
: Epoch: 219 | Training Loss: 0.099137 | Val. Loss: 0.509303 | Val. Kappa Score: 0.8542 | LR: 0.000846 | Estimated time: 73.04
Train loss on 50 batch: 0.149944
Train loss on 100 batch: 0.117331
Train loss on 150 batch: 0.125350
Train loss on 200 batch: 0.098595
Train loss on 250 batch: 0.113593
: Epoch: 220 | Training Loss: 0.123360 | Val. Loss: 0.439579 | Val. Kappa Score: 0.8542 | LR: 0.000812 | Estimated time: 73.01
Train loss on 50 batch: 0.078571
Train loss on 100 batch: 0.066392
Train loss on 150 batch: 0.098205
Train loss on 200 batch: 0.077859
Train loss on 250 batch: 0.093323
: Epoch: 221 | Training Loss: 0.084467 | Val. Loss: 0.423621 | Val. Kappa Score: 0.8543 | LR: 0.000775 | Estimated time: 72.94
Train loss on 50 batch: 0.077304
Train loss on 100 batch: 0.078799
Train loss on 150 batch: 0.068544
Train loss on 200 batch: 0.064712
Train loss on 250 batch: 0.064577
: Epoch: 222 | Training Loss: 0.070271 | Val. Loss: 0.423816 | Val. Kappa Score: 0.8543 | LR: 0.000737 | Estimated time: 72.94
Train loss on 50 batch: 0.048884
Train loss on 100 batch: 0.056932
Train loss on 150 batch: 0.073038
Train loss on 200 batch: 0.053636
Train loss on 250 batch: 0.054362
: Epoch: 223 | Training Loss: 0.056151 | Val. Loss: 0.421851 | Val. Kappa Score: 0.8544 | LR: 0.000697 | Estimated time: 72.91
Train loss on 50 batch: 0.055389
Train loss on 100 batch: 0.042102
Train loss on 150 batch: 0.046917
Train loss on 200 batch: 0.050042
Train loss on 250 batch: 0.051034
: Epoch: 224 | Training Loss: 0.068277 | Val. Loss: 0.412297 | Val. Kappa Score: 0.8544 | LR: 0.000655 | Estimated time: 72.97
Train loss on 50 batch: 0.117048
Train loss on 100 batch: 0.067063
Train loss on 150 batch: 0.057070
Train loss on 200 batch: 0.058281
Train loss on 250 batch: 0.052696
: Epoch: 225 | Training Loss: 0.078486 | Val. Loss: 0.406600 | Val. Kappa Score: 0.8545 | LR: 0.000611 | Estimated time: 72.95
Train loss on 50 batch: 0.053469
Train loss on 100 batch: 0.066155
Train loss on 150 batch: 0.064214
Train loss on 200 batch: 0.079721
Train loss on 250 batch: 0.059803
: Epoch: 226 | Training Loss: 0.060328 | Val. Loss: 0.433520 | Val. Kappa Score: 0.8546 | LR: 0.000567 | Estimated time: 72.98
Train loss on 50 batch: 0.074380
Train loss on 100 batch: 0.051339
Train loss on 150 batch: 0.044663
Train loss on 200 batch: 0.046827
Train loss on 250 batch: 0.033873
: Epoch: 227 | Training Loss: 0.054347 | Val. Loss: 0.404455 | Val. Kappa Score: 0.8546 | LR: 0.000522 | Estimated time: 72.96
Train loss on 50 batch: 0.053566
Train loss on 100 batch: 0.047579
Train loss on 150 batch: 0.048654
Train loss on 200 batch: 0.050812
Train loss on 250 batch: 0.045829
: Epoch: 228 | Training Loss: 0.046646 | Val. Loss: 0.398330 | Val. Kappa Score: 0.8547 | LR: 0.000478 | Estimated time: 73.06
Train loss on 50 batch: 0.041966
Train loss on 100 batch: 0.045835
Train loss on 150 batch: 0.050031
Train loss on 200 batch: 0.039627
Train loss on 250 batch: 0.046417
: Epoch: 229 | Training Loss: 0.061684 | Val. Loss: 0.368959 | Val. Kappa Score: 0.8548 | LR: 0.000433 | Estimated time: 72.93
Train loss on 50 batch: 0.085799
Train loss on 100 batch: 0.045373
Train loss on 150 batch: 0.028238
Train loss on 200 batch: 0.036658
Train loss on 250 batch: 0.042153
: Epoch: 230 | Training Loss: 0.047837 | Val. Loss: 0.426053 | Val. Kappa Score: 0.8549 | LR: 0.000389 | Estimated time: 72.98
Train loss on 50 batch: 0.036486
Train loss on 100 batch: 0.049979
Train loss on 150 batch: 0.048171
Train loss on 200 batch: 0.036356
Train loss on 250 batch: 0.039030
: Epoch: 231 | Training Loss: 0.048617 | Val. Loss: 0.440070 | Val. Kappa Score: 0.8549 | LR: 0.000345 | Estimated time: 73.01
Train loss on 50 batch: 0.038389
Train loss on 100 batch: 0.037674
Train loss on 150 batch: 0.033923
Train loss on 200 batch: 0.034188
Train loss on 250 batch: 0.029313
: Epoch: 232 | Training Loss: 0.037633 | Val. Loss: 0.452901 | Val. Kappa Score: 0.8549 | LR: 0.000303 | Estimated time: 73.00
Train loss on 50 batch: 0.033058
Train loss on 100 batch: 0.025869
Train loss on 150 batch: 0.031121
Train loss on 200 batch: 0.021468
Train loss on 250 batch: 0.030275
: Epoch: 233 | Training Loss: 0.027922 | Val. Loss: 0.405483 | Val. Kappa Score: 0.8550 | LR: 0.000263 | Estimated time: 72.97
Train loss on 50 batch: 0.022174
Train loss on 100 batch: 0.032547
Train loss on 150 batch: 0.023331
Train loss on 200 batch: 0.032469
Train loss on 250 batch: 0.029454
: Epoch: 234 | Training Loss: 0.030951 | Val. Loss: 0.400177 | Val. Kappa Score: 0.8551 | LR: 0.000225 | Estimated time: 73.00
Train loss on 50 batch: 0.026171
Train loss on 100 batch: 0.022823
Train loss on 150 batch: 0.026653
Train loss on 200 batch: 0.029283
Train loss on 250 batch: 0.019631
: Epoch: 235 | Training Loss: 0.028545 | Val. Loss: 0.396287 | Val. Kappa Score: 0.8552 | LR: 0.000188 | Estimated time: 72.99
Train loss on 50 batch: 0.024110
Train loss on 100 batch: 0.028935
Train loss on 150 batch: 0.019134
Train loss on 200 batch: 0.026627
Train loss on 250 batch: 0.030281
: Epoch: 236 | Training Loss: 0.025965 | Val. Loss: 0.400142 | Val. Kappa Score: 0.8552 | LR: 0.000154 | Estimated time: 73.00
Train loss on 50 batch: 0.020000
Train loss on 100 batch: 0.022921
Train loss on 150 batch: 0.020335
Train loss on 200 batch: 0.022306
Train loss on 250 batch: 0.031789
: Epoch: 237 | Training Loss: 0.022580 | Val. Loss: 0.386867 | Val. Kappa Score: 0.8553 | LR: 0.000123 | Estimated time: 72.96
Train loss on 50 batch: 0.024567
Train loss on 100 batch: 0.023405
Train loss on 150 batch: 0.018386
Train loss on 200 batch: 0.018925
Train loss on 250 batch: 0.024798
: Epoch: 238 | Training Loss: 0.021484 | Val. Loss: 0.401552 | Val. Kappa Score: 0.8554 | LR: 0.000095 | Estimated time: 73.09
Train loss on 50 batch: 0.021050
Train loss on 100 batch: 0.026877
Train loss on 150 batch: 0.018607
Train loss on 200 batch: 0.014738
Train loss on 250 batch: 0.018486
: Epoch: 239 | Training Loss: 0.029752 | Val. Loss: 0.392256 | Val. Kappa Score: 0.8554 | LR: 0.000071 | Estimated time: 72.94
Train loss on 50 batch: 0.023889
Train loss on 100 batch: 0.023492
Train loss on 150 batch: 0.021860
Train loss on 200 batch: 0.022506
Train loss on 250 batch: 0.016989
: Epoch: 240 | Training Loss: 0.021391 | Val. Loss: 0.388968 | Val. Kappa Score: 0.8555 | LR: 0.000050 | Estimated time: 72.92
Train loss on 50 batch: 0.023757
Train loss on 100 batch: 0.015966
Train loss on 150 batch: 0.024809
Train loss on 200 batch: 0.019141
Train loss on 250 batch: 0.021052
: Epoch: 241 | Training Loss: 0.022904 | Val. Loss: 0.386754 | Val. Kappa Score: 0.8556 | LR: 0.000032 | Estimated time: 72.97
Train loss on 50 batch: 0.020208
Train loss on 100 batch: 0.017991
Train loss on 150 batch: 0.018450
Train loss on 200 batch: 0.022239
Train loss on 250 batch: 0.023097
: Epoch: 242 | Training Loss: 0.029788 | Val. Loss: 0.390005 | Val. Kappa Score: 0.8557 | LR: 0.000018 | Estimated time: 72.95
Train loss on 50 batch: 0.019847
Train loss on 100 batch: 0.024739
Train loss on 150 batch: 0.022069
Train loss on 200 batch: 0.019464
Train loss on 250 batch: 0.017000
: Epoch: 243 | Training Loss: 0.020440 | Val. Loss: 0.387712 | Val. Kappa Score: 0.8558 | LR: 0.000008 | Estimated time: 73.04
Train loss on 50 batch: 0.022105
Train loss on 100 batch: 0.016106
Train loss on 150 batch: 0.014994
Train loss on 200 batch: 0.019205
Train loss on 250 batch: 0.020515
: Epoch: 244 | Training Loss: 0.018089 | Val. Loss: 0.389680 | Val. Kappa Score: 0.8559 | LR: 0.000002 | Estimated time: 73.02
Train loss on 50 batch: 0.017871
Train loss on 100 batch: 0.015369
Train loss on 150 batch: 0.019072
Train loss on 200 batch: 0.018801
Train loss on 250 batch: 0.017714
: Epoch: 245 | Training Loss: 0.023521 | Val. Loss: 0.386800 | Val. Kappa Score: 0.8560 | LR: 0.000000 | Estimated time: 73.02
Train loss on 50 batch: 0.018965
Train loss on 100 batch: 0.026074
Train loss on 150 batch: 0.028483
Train loss on 200 batch: 0.018001
Train loss on 250 batch: 0.017329
: Epoch: 246 | Training Loss: 0.020522 | Val. Loss: 0.386184 | Val. Kappa Score: 0.8561 | LR: 0.000002 | Estimated time: 72.97
Train loss on 50 batch: 0.016905
Train loss on 100 batch: 0.015122
Train loss on 150 batch: 0.017812
Train loss on 200 batch: 0.022080
Train loss on 250 batch: 0.028028
: Epoch: 247 | Training Loss: 0.020404 | Val. Loss: 0.391448 | Val. Kappa Score: 0.8562 | LR: 0.000008 | Estimated time: 72.94
Train loss on 50 batch: 0.016592
Train loss on 100 batch: 0.013489
Train loss on 150 batch: 0.014738
Train loss on 200 batch: 0.020498
Train loss on 250 batch: 0.026053
: Epoch: 248 | Training Loss: 0.017607 | Val. Loss: 0.405443 | Val. Kappa Score: 0.8563 | LR: 0.000018 | Estimated time: 72.97
Train loss on 50 batch: 0.012933
Train loss on 100 batch: 0.022534
Train loss on 150 batch: 0.016152
Train loss on 200 batch: 0.021786
Train loss on 250 batch: 0.018436
: Epoch: 249 | Training Loss: 0.017982 | Val. Loss: 0.391345 | Val. Kappa Score: 0.8564 | LR: 0.000032 | Estimated time: 72.94
Train loss on 50 batch: 0.014267
Train loss on 100 batch: 0.019161
Train loss on 150 batch: 0.012085
Train loss on 200 batch: 0.016955
Train loss on 250 batch: 0.020326
: Epoch: 250 | Training Loss: 0.018876 | Val. Loss: 0.404722 | Val. Kappa Score: 0.8564 | LR: 0.000050 | Estimated time: 73.05
Train loss on 50 batch: 0.017829
Train loss on 100 batch: 0.021317
Train loss on 150 batch: 0.015316
Train loss on 200 batch: 0.019874
Train loss on 250 batch: 0.022903
: Epoch: 251 | Training Loss: 0.021031 | Val. Loss: 0.393381 | Val. Kappa Score: 0.8565 | LR: 0.000071 | Estimated time: 72.95
Train loss on 50 batch: 0.019665
Train loss on 100 batch: 0.020189
Train loss on 150 batch: 0.019408
Train loss on 200 batch: 0.013357
Train loss on 250 batch: 0.016089
: Epoch: 252 | Training Loss: 0.024591 | Val. Loss: 0.394970 | Val. Kappa Score: 0.8566 | LR: 0.000095 | Estimated time: 73.03
Train loss on 50 batch: 0.021805
Train loss on 100 batch: 0.021290
Train loss on 150 batch: 0.023561
Train loss on 200 batch: 0.017631
Train loss on 250 batch: 0.016096
: Epoch: 253 | Training Loss: 0.043145 | Val. Loss: 0.403104 | Val. Kappa Score: 0.8566 | LR: 0.000123 | Estimated time: 72.95
Train loss on 50 batch: 0.020608
Train loss on 100 batch: 0.017701
Train loss on 150 batch: 0.018926
Train loss on 200 batch: 0.029325
Train loss on 250 batch: 0.014469
: Epoch: 254 | Training Loss: 0.022886 | Val. Loss: 0.392501 | Val. Kappa Score: 0.8568 | LR: 0.000154 | Estimated time: 72.99
Train loss on 50 batch: 0.019572
Train loss on 100 batch: 0.023600
Train loss on 150 batch: 0.017664
Train loss on 200 batch: 0.024446
Train loss on 250 batch: 0.025434
: Epoch: 255 | Training Loss: 0.047949 | Val. Loss: 0.402554 | Val. Kappa Score: 0.8568 | LR: 0.000188 | Estimated time: 73.01
Train loss on 50 batch: 0.037820
Train loss on 100 batch: 0.020155
Train loss on 150 batch: 0.019706
Train loss on 200 batch: 0.026322
Train loss on 250 batch: 0.022089
: Epoch: 256 | Training Loss: 0.025244 | Val. Loss: 0.394838 | Val. Kappa Score: 0.8569 | LR: 0.000225 | Estimated time: 72.98
Train loss on 50 batch: 0.018030
Train loss on 100 batch: 0.028285
Train loss on 150 batch: 0.017252
Train loss on 200 batch: 0.018133
Train loss on 250 batch: 0.019205
: Epoch: 257 | Training Loss: 0.028207 | Val. Loss: 0.390984 | Val. Kappa Score: 0.8570 | LR: 0.000263 | Estimated time: 73.12
Train loss on 50 batch: 0.022614
Train loss on 100 batch: 0.026530
Train loss on 150 batch: 0.026956
Train loss on 200 batch: 0.031834
Train loss on 250 batch: 0.019875
: Epoch: 258 | Training Loss: 0.025526 | Val. Loss: 0.398997 | Val. Kappa Score: 0.8571 | LR: 0.000303 | Estimated time: 72.96
Train loss on 50 batch: 0.020865
Train loss on 100 batch: 0.022620
Train loss on 150 batch: 0.022615
Train loss on 200 batch: 0.035679
Train loss on 250 batch: 0.016337
: Epoch: 259 | Training Loss: 0.041170 | Val. Loss: 0.462242 | Val. Kappa Score: 0.8571 | LR: 0.000345 | Estimated time: 73.00
Train loss on 50 batch: 0.029371
Train loss on 100 batch: 0.034960
Train loss on 150 batch: 0.026951
Train loss on 200 batch: 0.016777
Train loss on 250 batch: 0.034686
: Epoch: 260 | Training Loss: 0.031871 | Val. Loss: 0.470903 | Val. Kappa Score: 0.8571 | LR: 0.000389 | Estimated time: 73.00
Train loss on 50 batch: 0.033132
Train loss on 100 batch: 0.028068
Train loss on 150 batch: 0.030824
Train loss on 200 batch: 0.029783
Train loss on 250 batch: 0.028254
: Epoch: 261 | Training Loss: 0.028588 | Val. Loss: 0.439601 | Val. Kappa Score: 0.8571 | LR: 0.000433 | Estimated time: 72.93
Train loss on 50 batch: 0.025643
Train loss on 100 batch: 0.022473
Train loss on 150 batch: 0.027385
Train loss on 200 batch: 0.034990
Train loss on 250 batch: 0.030716
: Epoch: 262 | Training Loss: 0.034590 | Val. Loss: 0.431408 | Val. Kappa Score: 0.8572 | LR: 0.000478 | Estimated time: 72.95
Train loss on 50 batch: 0.069967
Train loss on 100 batch: 0.072242
Train loss on 150 batch: 0.054572
Train loss on 200 batch: 0.059656
Train loss on 250 batch: 0.041137
: Epoch: 263 | Training Loss: 0.069194 | Val. Loss: 0.457203 | Val. Kappa Score: 0.8572 | LR: 0.000522 | Estimated time: 73.00
Train loss on 50 batch: 0.088198
Train loss on 100 batch: 0.053739
Train loss on 150 batch: 0.063579
Train loss on 200 batch: 0.055148
Train loss on 250 batch: 0.046502
: Epoch: 264 | Training Loss: 0.060581 | Val. Loss: 0.413884 | Val. Kappa Score: 0.8573 | LR: 0.000567 | Estimated time: 72.97
Train loss on 50 batch: 0.035069
Train loss on 100 batch: 0.048394
Train loss on 150 batch: 0.068666
Train loss on 200 batch: 0.052471
Train loss on 250 batch: 0.057773
: Epoch: 265 | Training Loss: 0.053477 | Val. Loss: 0.461565 | Val. Kappa Score: 0.8573 | LR: 0.000611 | Estimated time: 72.96
Train loss on 50 batch: 0.064437
Train loss on 100 batch: 0.069226
Train loss on 150 batch: 0.060534
Train loss on 200 batch: 0.044393
Train loss on 250 batch: 0.043762
: Epoch: 266 | Training Loss: 0.054960 | Val. Loss: 0.498789 | Val. Kappa Score: 0.8573 | LR: 0.000655 | Estimated time: 73.05
Train loss on 50 batch: 0.048071
Train loss on 100 batch: 0.032595
Train loss on 150 batch: 0.055408
Train loss on 200 batch: 0.059058
Train loss on 250 batch: 0.068434
: Epoch: 267 | Training Loss: 0.068499 | Val. Loss: 0.425970 | Val. Kappa Score: 0.8574 | LR: 0.000697 | Estimated time: 72.96
Train loss on 50 batch: 0.089870
Train loss on 100 batch: 0.071648
Train loss on 150 batch: 0.046635
Train loss on 200 batch: 0.058724
Train loss on 250 batch: 0.046821
: Epoch: 268 | Training Loss: 0.068326 | Val. Loss: 0.466954 | Val. Kappa Score: 0.8574 | LR: 0.000737 | Estimated time: 73.06
Train loss on 50 batch: 0.085267
Train loss on 100 batch: 0.053989
Train loss on 150 batch: 0.060867
Train loss on 200 batch: 0.035955
Train loss on 250 batch: 0.044259
: Epoch: 269 | Training Loss: 0.060177 | Val. Loss: 0.467898 | Val. Kappa Score: 0.8574 | LR: 0.000775 | Estimated time: 72.95
Train loss on 50 batch: 0.063746
Train loss on 100 batch: 0.067170
Train loss on 150 batch: 0.070735
Train loss on 200 batch: 0.081651
Train loss on 250 batch: 0.081239
: Epoch: 270 | Training Loss: 0.090088 | Val. Loss: 0.493918 | Val. Kappa Score: 0.8573 | LR: 0.000812 | Estimated time: 72.97
Train loss on 50 batch: 0.126749
Train loss on 100 batch: 0.084048
Train loss on 150 batch: 0.066246
Train loss on 200 batch: 0.064422
Train loss on 250 batch: 0.077943
: Epoch: 271 | Training Loss: 0.093252 | Val. Loss: 0.586804 | Val. Kappa Score: 0.8572 | LR: 0.000846 | Estimated time: 72.92
Train loss on 50 batch: 0.150391
Train loss on 100 batch: 0.107260
Train loss on 150 batch: 0.132612
Train loss on 200 batch: 0.097547
Train loss on 250 batch: 0.084994
: Epoch: 272 | Training Loss: 0.113078 | Val. Loss: 0.596114 | Val. Kappa Score: 0.8571 | LR: 0.000877 | Estimated time: 72.97
Train loss on 50 batch: 0.090572
Train loss on 100 batch: 0.102179
Train loss on 150 batch: 0.080257
Train loss on 200 batch: 0.080553
Train loss on 250 batch: 0.104012
: Epoch: 273 | Training Loss: 0.098637 | Val. Loss: 0.524700 | Val. Kappa Score: 0.8570 | LR: 0.000905 | Estimated time: 72.99
Train loss on 50 batch: 0.126130
Train loss on 100 batch: 0.166867
Train loss on 150 batch: 0.102573
Train loss on 200 batch: 0.099953
Train loss on 250 batch: 0.112345
: Epoch: 274 | Training Loss: 0.119691 | Val. Loss: 0.457732 | Val. Kappa Score: 0.8570 | LR: 0.000929 | Estimated time: 73.00
Train loss on 50 batch: 0.080462
Train loss on 100 batch: 0.067956
Train loss on 150 batch: 0.075468
Train loss on 200 batch: 0.089344
Train loss on 250 batch: 0.090111
: Epoch: 275 | Training Loss: 0.085639 | Val. Loss: 0.476046 | Val. Kappa Score: 0.8570 | LR: 0.000950 | Estimated time: 73.03
Train loss on 50 batch: 0.070941
Train loss on 100 batch: 0.081049
Train loss on 150 batch: 0.074185
Train loss on 200 batch: 0.064066
Train loss on 250 batch: 0.064226
: Epoch: 276 | Training Loss: 0.080631 | Val. Loss: 0.459529 | Val. Kappa Score: 0.8570 | LR: 0.000968 | Estimated time: 73.13
Train loss on 50 batch: 0.115180
Train loss on 100 batch: 0.097228
Train loss on 150 batch: 0.110719
Train loss on 200 batch: 0.096679
Train loss on 250 batch: 0.116766
: Epoch: 277 | Training Loss: 0.111310 | Val. Loss: 0.596303 | Val. Kappa Score: 0.8569 | LR: 0.000982 | Estimated time: 72.99
time_estimated: 20226.67
n-epochs: 277
time_estimated: 20226.70
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:22:47
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb9d102748>
early-stopping-patience: 250
parameters-amount: 28342833
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:23:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7efb95f9bbe0>
early-stopping-patience: 250
parameters-amount: 28342833
n-epochs: 1000
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030221
Train loss on 100 batch: 0.576435
Train loss on 150 batch: 0.583337
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:27:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1026a0>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030221
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:28:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102710>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:30:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f9eb00>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.989915
Train loss on 100 batch: 0.574436
Train loss on 150 batch: 0.555587
----------------------------------------

Experiment N: 105: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 11:57:54
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1066a0>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.989915
Train loss on 100 batch: 0.574436
Train loss on 150 batch: 0.555587
best-train-loss: 0.644807
best-valid-loss: 0.609474
best-kappa: 0.8345
: Epoch: 1 | Training Loss: 0.644807 | Val. Loss: 0.609474 | Val. Kappa Score: 0.8345 | LR: 0.001000 | Estimated time: 361.23
Train loss on 50 batch: 0.432953
Train loss on 100 batch: 0.463140
Train loss on 150 batch: 0.393421
best-train-loss: 0.443114
best-valid-loss: 0.427166
best-kappa: 0.8434
: Epoch: 2 | Training Loss: 0.443114 | Val. Loss: 0.427166 | Val. Kappa Score: 0.8434 | LR: 0.001000 | Estimated time: 366.71
Train loss on 50 batch: 0.389297
Train loss on 100 batch: 0.389884
Train loss on 150 batch: 0.407097
best-train-loss: 0.393972
best-valid-loss: 0.399459
best-kappa: 0.8483
: Epoch: 3 | Training Loss: 0.393972 | Val. Loss: 0.399459 | Val. Kappa Score: 0.8483 | LR: 0.001000 | Estimated time: 366.06
Train loss on 50 batch: 0.405837
Train loss on 100 batch: 0.382784
Train loss on 150 batch: 0.343771
: Epoch: 4 | Training Loss: 0.424102 | Val. Loss: 0.610744 | Val. Kappa Score: 0.8410 | LR: 0.001000 | Estimated time: 364.56
Train loss on 50 batch: 0.505764
Train loss on 100 batch: 0.449925
Train loss on 150 batch: 0.355769
: Epoch: 5 | Training Loss: 0.428029 | Val. Loss: 0.405499 | Val. Kappa Score: 0.8446 | LR: 0.001000 | Estimated time: 363.82
Train loss on 50 batch: 0.389376
Train loss on 100 batch: 0.343476
Train loss on 150 batch: 0.345110
: Epoch: 6 | Training Loss: 0.347891 | Val. Loss: 0.415941 | Val. Kappa Score: 0.8436 | LR: 0.000500 | Estimated time: 363.66
Train loss on 50 batch: 0.342061
Train loss on 100 batch: 0.261768
Train loss on 150 batch: 0.243066
best-train-loss: 0.280193
best-valid-loss: 0.307360
best-kappa: 0.8502
: Epoch: 7 | Training Loss: 0.280193 | Val. Loss: 0.307360 | Val. Kappa Score: 0.8502 | LR: 0.000500 | Estimated time: 362.97
Train loss on 50 batch: 0.219160
Train loss on 100 batch: 0.268553
Train loss on 150 batch: 0.222918
best-train-loss: 0.253006
best-valid-loss: 0.280771
best-kappa: 0.8567
: Epoch: 8 | Training Loss: 0.253006 | Val. Loss: 0.280771 | Val. Kappa Score: 0.8567 | LR: 0.000500 | Estimated time: 364.86
Train loss on 50 batch: 0.229301
Train loss on 100 batch: 0.269003
Train loss on 150 batch: 0.269853
best-train-loss: 0.250266
best-valid-loss: 0.245164
best-kappa: 0.8621
: Epoch: 9 | Training Loss: 0.250266 | Val. Loss: 0.245164 | Val. Kappa Score: 0.8621 | LR: 0.000500 | Estimated time: 363.24
Train loss on 50 batch: 0.210855
Train loss on 100 batch: 0.253116
Train loss on 150 batch: 0.229196
: Epoch: 10 | Training Loss: 0.281010 | Val. Loss: 0.275751 | Val. Kappa Score: 0.8642 | LR: 0.000500 | Estimated time: 364.00
Train loss on 50 batch: 0.213223
Train loss on 100 batch: 0.244354
Train loss on 150 batch: 0.218814
: Epoch: 11 | Training Loss: 0.241132 | Val. Loss: 0.316945 | Val. Kappa Score: 0.8650 | LR: 0.000500 | Estimated time: 362.88
Train loss on 50 batch: 0.178734
Train loss on 100 batch: 0.219368
Train loss on 150 batch: 0.229321
: Epoch: 12 | Training Loss: 0.217151 | Val. Loss: 0.317845 | Val. Kappa Score: 0.8670 | LR: 0.000250 | Estimated time: 364.22
Train loss on 50 batch: 0.183352
Train loss on 100 batch: 0.202932
Train loss on 150 batch: 0.148590
: Epoch: 13 | Training Loss: 0.184307 | Val. Loss: 0.278094 | Val. Kappa Score: 0.8691 | LR: 0.000250 | Estimated time: 364.71
Train loss on 50 batch: 0.149620
Train loss on 100 batch: 0.163821
Train loss on 150 batch: 0.184032
: Epoch: 14 | Training Loss: 0.171060 | Val. Loss: 0.277007 | Val. Kappa Score: 0.8706 | LR: 0.000250 | Estimated time: 363.95
Train loss on 50 batch: 0.165637
Train loss on 100 batch: 0.146409
Train loss on 150 batch: 0.176515
: Epoch: 15 | Training Loss: 0.166432 | Val. Loss: 0.309546 | Val. Kappa Score: 0.8714 | LR: 0.000125 | Estimated time: 364.61
Train loss on 50 batch: 0.162273
Train loss on 100 batch: 0.140559
Train loss on 150 batch: 0.124441
: Epoch: 16 | Training Loss: 0.146308 | Val. Loss: 0.286610 | Val. Kappa Score: 0.8725 | LR: 0.000125 | Estimated time: 363.68
Train loss on 50 batch: 0.140769
Train loss on 100 batch: 0.130374
Train loss on 150 batch: 0.122950
: Epoch: 17 | Training Loss: 0.132862 | Val. Loss: 0.285501 | Val. Kappa Score: 0.8737 | LR: 0.000125 | Estimated time: 364.81
time_estimated: 6190.93
n-epochs: 17
time_estimated: 6190.96
----------------------------------------

Experiment N: 106: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 19:11:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102710>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
----------------------------------------

Experiment N: 106: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.19 19:16:52
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109320>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030046
Train loss on 100 batch: 0.586831
Train loss on 150 batch: 0.580255
best-train-loss: 0.665435
best-valid-loss: 1.326636
best-kappa: 0.7651
: Epoch: 1 | Training Loss: 0.665435 | Val. Loss: 1.326636 | Val. Kappa Score: 0.7651 | LR: 0.001000 | Estimated time: 161.31
Train loss on 50 batch: 0.449549
Train loss on 100 batch: 0.435404
Train loss on 150 batch: 0.361379
best-train-loss: 0.432199
best-valid-loss: 0.543168
best-kappa: 0.7858
: Epoch: 2 | Training Loss: 0.432199 | Val. Loss: 0.543168 | Val. Kappa Score: 0.7858 | LR: 0.001000 | Estimated time: 161.60
Train loss on 50 batch: 0.423319
Train loss on 100 batch: 0.399756
Train loss on 150 batch: 0.364026
best-train-loss: 0.380944
best-valid-loss: 0.366600
best-kappa: 0.8129
: Epoch: 3 | Training Loss: 0.380944 | Val. Loss: 0.366600 | Val. Kappa Score: 0.8129 | LR: 0.001000 | Estimated time: 161.01
Train loss on 50 batch: 0.364863
Train loss on 100 batch: 0.380144
Train loss on 150 batch: 0.360145
: Epoch: 4 | Training Loss: 0.428705 | Val. Loss: 0.489810 | Val. Kappa Score: 0.8219 | LR: 0.001000 | Estimated time: 161.88
Train loss on 50 batch: 0.484715
Train loss on 100 batch: 0.412367
Train loss on 150 batch: 0.324609
best-train-loss: 0.392967
best-valid-loss: 0.335885
best-kappa: 0.8317
: Epoch: 5 | Training Loss: 0.392967 | Val. Loss: 0.335885 | Val. Kappa Score: 0.8317 | LR: 0.001000 | Estimated time: 164.57
Train loss on 50 batch: 0.361138
Train loss on 100 batch: 0.356139
Train loss on 150 batch: 0.306932
: Epoch: 6 | Training Loss: 0.327079 | Val. Loss: 0.368782 | Val. Kappa Score: 0.8356 | LR: 0.001000 | Estimated time: 162.13
Train loss on 50 batch: 0.295400
Train loss on 100 batch: 0.310049
Train loss on 150 batch: 0.291446
: Epoch: 7 | Training Loss: 0.298691 | Val. Loss: 0.341159 | Val. Kappa Score: 0.8413 | LR: 0.001000 | Estimated time: 162.07
Train loss on 50 batch: 0.223803
Train loss on 100 batch: 0.295861
Train loss on 150 batch: 0.229797
best-train-loss: 0.269009
best-valid-loss: 0.291919
best-kappa: 0.8488
: Epoch: 8 | Training Loss: 0.269009 | Val. Loss: 0.291919 | Val. Kappa Score: 0.8488 | LR: 0.001000 | Estimated time: 162.95
Train loss on 50 batch: 0.305776
Train loss on 100 batch: 0.294219
Train loss on 150 batch: 0.300754
: Epoch: 9 | Training Loss: 0.281489 | Val. Loss: 0.298043 | Val. Kappa Score: 0.8540 | LR: 0.001000 | Estimated time: 163.14
Train loss on 50 batch: 0.277760
Train loss on 100 batch: 0.275769
Train loss on 150 batch: 0.269332
: Epoch: 10 | Training Loss: 0.320186 | Val. Loss: 0.529154 | Val. Kappa Score: 0.8505 | LR: 0.001000 | Estimated time: 161.93
Train loss on 50 batch: 0.231201
Train loss on 100 batch: 0.262909
Train loss on 150 batch: 0.258703
: Epoch: 11 | Training Loss: 0.266063 | Val. Loss: 0.342369 | Val. Kappa Score: 0.8513 | LR: 0.000500 | Estimated time: 162.30
Train loss on 50 batch: 0.208425
Train loss on 100 batch: 0.204581
Train loss on 150 batch: 0.219633
best-train-loss: 0.206895
best-valid-loss: 0.288563
best-kappa: 0.8545
: Epoch: 12 | Training Loss: 0.206895 | Val. Loss: 0.288563 | Val. Kappa Score: 0.8545 | LR: 0.000500 | Estimated time: 162.36
Train loss on 50 batch: 0.169204
Train loss on 100 batch: 0.197592
Train loss on 150 batch: 0.167289
: Epoch: 13 | Training Loss: 0.184733 | Val. Loss: 0.322753 | Val. Kappa Score: 0.8565 | LR: 0.000500 | Estimated time: 162.52
Train loss on 50 batch: 0.167027
Train loss on 100 batch: 0.177333
Train loss on 150 batch: 0.186429
best-train-loss: 0.187420
best-valid-loss: 0.258331
best-kappa: 0.8591
: Epoch: 14 | Training Loss: 0.187420 | Val. Loss: 0.258331 | Val. Kappa Score: 0.8591 | LR: 0.000500 | Estimated time: 161.54
Train loss on 50 batch: 0.192590
Train loss on 100 batch: 0.167882
Train loss on 150 batch: 0.175879
: Epoch: 15 | Training Loss: 0.175295 | Val. Loss: 0.265204 | Val. Kappa Score: 0.8615 | LR: 0.000500 | Estimated time: 162.44
Train loss on 50 batch: 0.154178
Train loss on 100 batch: 0.160911
Train loss on 150 batch: 0.151612
: Epoch: 16 | Training Loss: 0.160343 | Val. Loss: 0.280640 | Val. Kappa Score: 0.8633 | LR: 0.000500 | Estimated time: 163.90
Train loss on 50 batch: 0.157393
Train loss on 100 batch: 0.178989
Train loss on 150 batch: 0.141800
: Epoch: 17 | Training Loss: 0.153797 | Val. Loss: 0.280461 | Val. Kappa Score: 0.8649 | LR: 0.000250 | Estimated time: 163.59
Train loss on 50 batch: 0.141988
Train loss on 100 batch: 0.114305
Train loss on 150 batch: 0.144631
: Epoch: 18 | Training Loss: 0.135787 | Val. Loss: 0.292559 | Val. Kappa Score: 0.8664 | LR: 0.000250 | Estimated time: 161.47
Train loss on 50 batch: 0.113783
Train loss on 100 batch: 0.126746
Train loss on 150 batch: 0.129936
: Epoch: 19 | Training Loss: 0.124354 | Val. Loss: 0.325431 | Val. Kappa Score: 0.8670 | LR: 0.000250 | Estimated time: 163.20
Train loss on 50 batch: 0.090148
Train loss on 100 batch: 0.129997
Train loss on 150 batch: 0.106481
: Epoch: 20 | Training Loss: 0.105528 | Val. Loss: 0.293291 | Val. Kappa Score: 0.8681 | LR: 0.000125 | Estimated time: 162.56
Train loss on 50 batch: 0.114185
Train loss on 100 batch: 0.093087
Train loss on 150 batch: 0.113215
: Epoch: 21 | Training Loss: 0.133135 | Val. Loss: 0.293414 | Val. Kappa Score: 0.8693 | LR: 0.000125 | Estimated time: 162.59
Train loss on 50 batch: 0.095567
Train loss on 100 batch: 0.100810
Train loss on 150 batch: 0.094607
: Epoch: 22 | Training Loss: 0.099033 | Val. Loss: 0.315510 | Val. Kappa Score: 0.8704 | LR: 0.000125 | Estimated time: 163.10
time_estimated: 3575.37
n-epochs: 22
time_estimated: 3575.39
----------------------------------------

Experiment N: 107: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.19 22:43:08
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb960046a0>
early-stopping-patience: 8
parameters-amount: 6514465
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.028885
Train loss on 100 batch: 0.599102
Train loss on 150 batch: 0.559601
best-train-loss: 0.658378
best-valid-loss: 0.948875
best-kappa: 0.7831
: Epoch: 1 | Training Loss: 0.658378 | Val. Loss: 0.948875 | Val. Kappa Score: 0.7831 | LR: 0.001000 | Estimated time: 164.60
Train loss on 50 batch: 0.387162
Train loss on 100 batch: 0.386757
Train loss on 150 batch: 0.359085
best-train-loss: 0.393700
best-valid-loss: 0.485069
best-kappa: 0.8047
: Epoch: 2 | Training Loss: 0.393700 | Val. Loss: 0.485069 | Val. Kappa Score: 0.8047 | LR: 0.001000 | Estimated time: 162.67
Train loss on 50 batch: 0.347913
Train loss on 100 batch: 0.398153
Train loss on 150 batch: 0.346642
best-train-loss: 0.375122
best-valid-loss: 0.383797
best-kappa: 0.8258
: Epoch: 3 | Training Loss: 0.375122 | Val. Loss: 0.383797 | Val. Kappa Score: 0.8258 | LR: 0.001000 | Estimated time: 159.52
Train loss on 50 batch: 0.331912
Train loss on 100 batch: 0.345393
Train loss on 150 batch: 0.306890
: Epoch: 4 | Training Loss: 0.367299 | Val. Loss: 0.599775 | Val. Kappa Score: 0.8310 | LR: 0.001000 | Estimated time: 169.04
Train loss on 50 batch: 0.376567
Train loss on 100 batch: 0.376387
Train loss on 150 batch: 0.285513
best-train-loss: 0.348996
best-valid-loss: 0.325941
best-kappa: 0.8406
: Epoch: 5 | Training Loss: 0.348996 | Val. Loss: 0.325941 | Val. Kappa Score: 0.8406 | LR: 0.001000 | Estimated time: 169.80
Train loss on 50 batch: 0.350963
Train loss on 100 batch: 0.303681
Train loss on 150 batch: 0.324733
: Epoch: 6 | Training Loss: 0.309362 | Val. Loss: 0.361500 | Val. Kappa Score: 0.8453 | LR: 0.001000 | Estimated time: 169.21
Train loss on 50 batch: 0.298112
Train loss on 100 batch: 0.272711
Train loss on 150 batch: 0.230824
best-train-loss: 0.273488
best-valid-loss: 0.301400
best-kappa: 0.8520
: Epoch: 7 | Training Loss: 0.273488 | Val. Loss: 0.301400 | Val. Kappa Score: 0.8520 | LR: 0.001000 | Estimated time: 162.02
Train loss on 50 batch: 0.207250
Train loss on 100 batch: 0.270188
Train loss on 150 batch: 0.227549
: Epoch: 8 | Training Loss: 0.243687 | Val. Loss: 0.305911 | Val. Kappa Score: 0.8561 | LR: 0.001000 | Estimated time: 161.70
Train loss on 50 batch: 0.261984
Train loss on 100 batch: 0.246224
Train loss on 150 batch: 0.262004
: Epoch: 9 | Training Loss: 0.250217 | Val. Loss: 0.309279 | Val. Kappa Score: 0.8606 | LR: 0.001000 | Estimated time: 160.61
Train loss on 50 batch: 0.206416
Train loss on 100 batch: 0.238228
Train loss on 150 batch: 0.255471
: Epoch: 10 | Training Loss: 0.278097 | Val. Loss: 0.427433 | Val. Kappa Score: 0.8617 | LR: 0.000500 | Estimated time: 161.64
Train loss on 50 batch: 0.200798
Train loss on 100 batch: 0.206720
Train loss on 150 batch: 0.175059
: Epoch: 11 | Training Loss: 0.192904 | Val. Loss: 0.318487 | Val. Kappa Score: 0.8630 | LR: 0.000500 | Estimated time: 160.76
Train loss on 50 batch: 0.145857
Train loss on 100 batch: 0.146108
Train loss on 150 batch: 0.179491
: Epoch: 12 | Training Loss: 0.173715 | Val. Loss: 0.317707 | Val. Kappa Score: 0.8642 | LR: 0.000500 | Estimated time: 162.09
Train loss on 50 batch: 0.163115
Train loss on 100 batch: 0.156898
Train loss on 150 batch: 0.137469
best-train-loss: 0.160671
best-valid-loss: 0.279780
best-kappa: 0.8662
: Epoch: 13 | Training Loss: 0.160671 | Val. Loss: 0.279780 | Val. Kappa Score: 0.8662 | LR: 0.000500 | Estimated time: 160.60
Train loss on 50 batch: 0.151109
Train loss on 100 batch: 0.150198
Train loss on 150 batch: 0.167024
: Epoch: 14 | Training Loss: 0.168060 | Val. Loss: 0.297522 | Val. Kappa Score: 0.8678 | LR: 0.000500 | Estimated time: 159.51
Train loss on 50 batch: 0.162640
Train loss on 100 batch: 0.141104
Train loss on 150 batch: 0.154624
: Epoch: 15 | Training Loss: 0.163699 | Val. Loss: 0.285535 | Val. Kappa Score: 0.8691 | LR: 0.000500 | Estimated time: 159.85
Train loss on 50 batch: 0.135731
Train loss on 100 batch: 0.130741
Train loss on 150 batch: 0.143383
: Epoch: 16 | Training Loss: 0.136702 | Val. Loss: 0.282471 | Val. Kappa Score: 0.8703 | LR: 0.000250 | Estimated time: 159.94
Train loss on 50 batch: 0.150816
Train loss on 100 batch: 0.129731
Train loss on 150 batch: 0.101040
: Epoch: 17 | Training Loss: 0.134344 | Val. Loss: 0.285494 | Val. Kappa Score: 0.8719 | LR: 0.000250 | Estimated time: 159.86
Train loss on 50 batch: 0.112886
Train loss on 100 batch: 0.095201
Train loss on 150 batch: 0.133467
: Epoch: 18 | Training Loss: 0.114673 | Val. Loss: 0.286851 | Val. Kappa Score: 0.8732 | LR: 0.000250 | Estimated time: 162.36
Train loss on 50 batch: 0.093160
Train loss on 100 batch: 0.120752
Train loss on 150 batch: 0.109161
: Epoch: 19 | Training Loss: 0.118682 | Val. Loss: 0.286130 | Val. Kappa Score: 0.8739 | LR: 0.000125 | Estimated time: 160.59
Train loss on 50 batch: 0.084379
Train loss on 100 batch: 0.107172
Train loss on 150 batch: 0.093975
: Epoch: 20 | Training Loss: 0.096197 | Val. Loss: 0.285570 | Val. Kappa Score: 0.8745 | LR: 0.000125 | Estimated time: 160.36
Train loss on 50 batch: 0.089966
Train loss on 100 batch: 0.082019
Train loss on 150 batch: 0.092606
: Epoch: 21 | Training Loss: 0.107162 | Val. Loss: 0.282325 | Val. Kappa Score: 0.8758 | LR: 0.000125 | Estimated time: 159.35
time_estimated: 3406.84
n-epochs: 21
time_estimated: 3406.88
----------------------------------------

Experiment N: 108: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.19 23:47:05
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96002908>
early-stopping-patience: 8
parameters-amount: 6514465
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.028891
Train loss on 100 batch: 0.599149
Train loss on 150 batch: 0.559649
best-train-loss: 0.658423
best-valid-loss: 0.954326
best-kappa: 0.7825
: Epoch: 1 | Training Loss: 0.658423 | Val. Loss: 0.954326 | Val. Kappa Score: 0.7825 | LR: 0.001000 | Estimated time: 22.20
Train loss on 50 batch: 0.387373
Train loss on 100 batch: 0.386958
Train loss on 150 batch: 0.360229
best-train-loss: 0.394367
best-valid-loss: 0.487561
best-kappa: 0.8035
: Epoch: 2 | Training Loss: 0.394367 | Val. Loss: 0.487561 | Val. Kappa Score: 0.8035 | LR: 0.001000 | Estimated time: 21.89
Train loss on 50 batch: 0.349346
Train loss on 100 batch: 0.398463
Train loss on 150 batch: 0.348443
best-train-loss: 0.376754
best-valid-loss: 0.380880
best-kappa: 0.8269
: Epoch: 3 | Training Loss: 0.376754 | Val. Loss: 0.380880 | Val. Kappa Score: 0.8269 | LR: 0.001000 | Estimated time: 21.73
Train loss on 50 batch: 0.332188
Train loss on 100 batch: 0.347893
Train loss on 150 batch: 0.305317
: Epoch: 4 | Training Loss: 0.369639 | Val. Loss: 0.534154 | Val. Kappa Score: 0.8350 | LR: 0.001000 | Estimated time: 22.01
Train loss on 50 batch: 0.374473
Train loss on 100 batch: 0.397900
Train loss on 150 batch: 0.294333
best-train-loss: 0.358725
best-valid-loss: 0.341532
best-kappa: 0.8428
: Epoch: 5 | Training Loss: 0.358725 | Val. Loss: 0.341532 | Val. Kappa Score: 0.8428 | LR: 0.001000 | Estimated time: 21.68
Train loss on 50 batch: 0.343743
Train loss on 100 batch: 0.305829
Train loss on 150 batch: 0.332652
: Epoch: 6 | Training Loss: 0.309819 | Val. Loss: 0.395890 | Val. Kappa Score: 0.8435 | LR: 0.001000 | Estimated time: 21.77
Train loss on 50 batch: 0.298918
Train loss on 100 batch: 0.289065
Train loss on 150 batch: 0.246166
best-train-loss: 0.286077
best-valid-loss: 0.328252
best-kappa: 0.8487
: Epoch: 7 | Training Loss: 0.286077 | Val. Loss: 0.328252 | Val. Kappa Score: 0.8487 | LR: 0.001000 | Estimated time: 22.55
Train loss on 50 batch: 0.215262
Train loss on 100 batch: 0.286758
Train loss on 150 batch: 0.249716
best-train-loss: 0.253686
best-valid-loss: 0.321219
best-kappa: 0.8534
: Epoch: 8 | Training Loss: 0.253686 | Val. Loss: 0.321219 | Val. Kappa Score: 0.8534 | LR: 0.001000 | Estimated time: 22.28
Train loss on 50 batch: 0.289028
Train loss on 100 batch: 0.280281
Train loss on 150 batch: 0.264384
: Epoch: 9 | Training Loss: 0.266995 | Val. Loss: 0.344290 | Val. Kappa Score: 0.8574 | LR: 0.001000 | Estimated time: 22.46
Train loss on 50 batch: 0.219015
Train loss on 100 batch: 0.281083
Train loss on 150 batch: 0.267880
: Epoch: 10 | Training Loss: 0.316096 | Val. Loss: 0.583872 | Val. Kappa Score: 0.8517 | LR: 0.001000 | Estimated time: 22.18
Train loss on 50 batch: 0.276504
Train loss on 100 batch: 0.273979
Train loss on 150 batch: 0.279900
: Epoch: 11 | Training Loss: 0.276817 | Val. Loss: 0.341747 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 22.54
Train loss on 50 batch: 0.193548
Train loss on 100 batch: 0.204078
Train loss on 150 batch: 0.211873
: Epoch: 12 | Training Loss: 0.211181 | Val. Loss: 0.330307 | Val. Kappa Score: 0.8551 | LR: 0.000500 | Estimated time: 22.45
Train loss on 50 batch: 0.183545
Train loss on 100 batch: 0.193337
Train loss on 150 batch: 0.168576
best-train-loss: 0.189200
best-valid-loss: 0.282805
best-kappa: 0.8585
: Epoch: 13 | Training Loss: 0.189200 | Val. Loss: 0.282805 | Val. Kappa Score: 0.8585 | LR: 0.000500 | Estimated time: 21.96
Train loss on 50 batch: 0.175852
Train loss on 100 batch: 0.163638
Train loss on 150 batch: 0.194058
: Epoch: 14 | Training Loss: 0.186916 | Val. Loss: 0.295174 | Val. Kappa Score: 0.8608 | LR: 0.000500 | Estimated time: 22.06
Train loss on 50 batch: 0.208636
Train loss on 100 batch: 0.165842
Train loss on 150 batch: 0.182372
: Epoch: 15 | Training Loss: 0.191072 | Val. Loss: 0.292585 | Val. Kappa Score: 0.8625 | LR: 0.000500 | Estimated time: 21.95
Train loss on 50 batch: 0.155841
Train loss on 100 batch: 0.162615
Train loss on 150 batch: 0.174404
: Epoch: 16 | Training Loss: 0.164994 | Val. Loss: 0.305634 | Val. Kappa Score: 0.8636 | LR: 0.000250 | Estimated time: 22.23
Train loss on 50 batch: 0.152983
Train loss on 100 batch: 0.141420
Train loss on 150 batch: 0.129676
: Epoch: 17 | Training Loss: 0.143833 | Val. Loss: 0.284349 | Val. Kappa Score: 0.8655 | LR: 0.000250 | Estimated time: 22.13
Train loss on 50 batch: 0.127814
Train loss on 100 batch: 0.103044
Train loss on 150 batch: 0.134824
: Epoch: 18 | Training Loss: 0.125877 | Val. Loss: 0.292093 | Val. Kappa Score: 0.8663 | LR: 0.000250 | Estimated time: 22.30
Train loss on 50 batch: 0.102956
Train loss on 100 batch: 0.131842
Train loss on 150 batch: 0.125238
: Epoch: 19 | Training Loss: 0.128950 | Val. Loss: 0.290105 | Val. Kappa Score: 0.8678 | LR: 0.000125 | Estimated time: 22.10
Train loss on 50 batch: 0.098664
Train loss on 100 batch: 0.111279
Train loss on 150 batch: 0.104930
: Epoch: 20 | Training Loss: 0.107818 | Val. Loss: 0.285121 | Val. Kappa Score: 0.8693 | LR: 0.000125 | Estimated time: 22.29
Train loss on 50 batch: 0.112986
Train loss on 100 batch: 0.103798
Train loss on 150 batch: 0.115330
best-train-loss: 0.133184
best-valid-loss: 0.276302
best-kappa: 0.8707
: Epoch: 21 | Training Loss: 0.133184 | Val. Loss: 0.276302 | Val. Kappa Score: 0.8707 | LR: 0.000125 | Estimated time: 22.12
Train loss on 50 batch: 0.088579
Train loss on 100 batch: 0.106622
Train loss on 150 batch: 0.104053
: Epoch: 22 | Training Loss: 0.109160 | Val. Loss: 0.289708 | Val. Kappa Score: 0.8721 | LR: 0.000125 | Estimated time: 22.21
Train loss on 50 batch: 0.100366
Train loss on 100 batch: 0.089236
Train loss on 150 batch: 0.110053
: Epoch: 23 | Training Loss: 0.100065 | Val. Loss: 0.310984 | Val. Kappa Score: 0.8726 | LR: 0.000125 | Estimated time: 22.05
Train loss on 50 batch: 0.086059
Train loss on 100 batch: 0.100382
Train loss on 150 batch: 0.094374
: Epoch: 24 | Training Loss: 0.147556 | Val. Loss: 0.302123 | Val. Kappa Score: 0.8734 | LR: 0.000063 | Estimated time: 22.32
Train loss on 50 batch: 0.079064
Train loss on 100 batch: 0.074809
Train loss on 150 batch: 0.088284
: Epoch: 25 | Training Loss: 0.085840 | Val. Loss: 0.295472 | Val. Kappa Score: 0.8746 | LR: 0.000063 | Estimated time: 22.32
Train loss on 50 batch: 0.094224
Train loss on 100 batch: 0.061645
Train loss on 150 batch: 0.079533
: Epoch: 26 | Training Loss: 0.086217 | Val. Loss: 0.297476 | Val. Kappa Score: 0.8754 | LR: 0.000063 | Estimated time: 21.94
Train loss on 50 batch: 0.072143
Train loss on 100 batch: 0.110610
Train loss on 150 batch: 0.077114
: Epoch: 27 | Training Loss: 0.084630 | Val. Loss: 0.289464 | Val. Kappa Score: 0.8760 | LR: 0.000031 | Estimated time: 22.29
Train loss on 50 batch: 0.082516
Train loss on 100 batch: 0.079593
Train loss on 150 batch: 0.069650
: Epoch: 28 | Training Loss: 0.077839 | Val. Loss: 0.294167 | Val. Kappa Score: 0.8765 | LR: 0.000031 | Estimated time: 22.21
Train loss on 50 batch: 0.066873
Train loss on 100 batch: 0.079694
Train loss on 150 batch: 0.068449
: Epoch: 29 | Training Loss: 0.072215 | Val. Loss: 0.296428 | Val. Kappa Score: 0.8769 | LR: 0.000031 | Estimated time: 22.36
time_estimated: 643.59
n-epochs: 29
time_estimated: 643.62
----------------------------------------

Experiment N: 109: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 00:01:59
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d103860>
early-stopping-patience: 8
parameters-amount: 30442033
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.894629
Train loss on 100 batch: 0.940483
Train loss on 150 batch: 0.675687
----------------------------------------

Experiment N: 109: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 00:08:44
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102710>
early-stopping-patience: 8
parameters-amount: 30442033
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.894629
Train loss on 100 batch: 0.940483
Train loss on 150 batch: 0.675687
----------------------------------------

Experiment N: 109: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 00:35:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1027b8>
early-stopping-patience: 8
parameters-amount: 30442033
n-epochs: 100
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 3.801793
Train loss on 100 batch: 1.118175
Train loss on 150 batch: 0.841237
Train loss on 200 batch: 0.789276
Train loss on 250 batch: 0.815569
Train loss on 300 batch: 0.669252
Train loss on 350 batch: 0.650182
----------------------------------------

Experiment N: 109: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:14:06
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102780>
early-stopping-patience: 8
parameters-amount: 30439985
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.448945
Train loss on 100 batch: 0.719188
Train loss on 150 batch: 0.598687
best-train-loss: 0.814768
best-valid-loss: 0.475276
best-kappa: 0.8459
: Epoch: 1 | Training Loss: 0.814768 | Val. Loss: 0.475276 | Val. Kappa Score: 0.8459 | LR: 0.001000 | Estimated time: 51.38
Train loss on 50 batch: 0.474098
Train loss on 100 batch: 0.469623
Train loss on 150 batch: 0.436410
: Epoch: 2 | Training Loss: 0.480105 | Val. Loss: 0.606509 | Val. Kappa Score: 0.8108 | LR: 0.001000 | Estimated time: 50.95
Train loss on 50 batch: 0.452080
Train loss on 100 batch: 0.501287
Train loss on 150 batch: 0.411513
best-train-loss: 0.439760
best-valid-loss: 0.382649
best-kappa: 0.8241
: Epoch: 3 | Training Loss: 0.439760 | Val. Loss: 0.382649 | Val. Kappa Score: 0.8241 | LR: 0.001000 | Estimated time: 50.29
Train loss on 50 batch: 0.409853
Train loss on 100 batch: 0.382632
Train loss on 150 batch: 0.413935
: Epoch: 4 | Training Loss: 0.466713 | Val. Loss: 0.548230 | Val. Kappa Score: 0.8255 | LR: 0.001000 | Estimated time: 49.42
Train loss on 50 batch: 0.591890
Train loss on 100 batch: 0.526008
Train loss on 150 batch: 0.375557
best-train-loss: 0.481039
best-valid-loss: 0.320884
best-kappa: 0.8381
: Epoch: 5 | Training Loss: 0.481039 | Val. Loss: 0.320884 | Val. Kappa Score: 0.8381 | LR: 0.001000 | Estimated time: 49.48
Train loss on 50 batch: 0.415494
Train loss on 100 batch: 0.345596
Train loss on 150 batch: 0.340740
: Epoch: 6 | Training Loss: 0.370971 | Val. Loss: 0.447501 | Val. Kappa Score: 0.8345 | LR: 0.001000 | Estimated time: 49.44
Train loss on 50 batch: 0.370148
Train loss on 100 batch: 0.340708
Train loss on 150 batch: 0.311684
: Epoch: 7 | Training Loss: 0.333959 | Val. Loss: 0.379292 | Val. Kappa Score: 0.8392 | LR: 0.001000 | Estimated time: 49.20
Train loss on 50 batch: 0.323079
Train loss on 100 batch: 0.354797
Train loss on 150 batch: 0.278309
best-train-loss: 0.334173
best-valid-loss: 0.291263
best-kappa: 0.8450
: Epoch: 8 | Training Loss: 0.334173 | Val. Loss: 0.291263 | Val. Kappa Score: 0.8450 | LR: 0.001000 | Estimated time: 49.17
Train loss on 50 batch: 0.364779
Train loss on 100 batch: 0.315731
Train loss on 150 batch: 0.331943
: Epoch: 9 | Training Loss: 0.328434 | Val. Loss: 0.585564 | Val. Kappa Score: 0.8455 | LR: 0.001000 | Estimated time: 49.13
Train loss on 50 batch: 0.346142
Train loss on 100 batch: 0.401324
Train loss on 150 batch: 0.292753
: Epoch: 10 | Training Loss: 0.411673 | Val. Loss: 0.411642 | Val. Kappa Score: 0.8461 | LR: 0.001000 | Estimated time: 49.16
Train loss on 50 batch: 0.434515
Train loss on 100 batch: 0.369691
Train loss on 150 batch: 0.306860
: Epoch: 11 | Training Loss: 0.381751 | Val. Loss: 0.386691 | Val. Kappa Score: 0.8471 | LR: 0.000500 | Estimated time: 49.17
Train loss on 50 batch: 0.245489
Train loss on 100 batch: 0.258048
Train loss on 150 batch: 0.251734
best-train-loss: 0.252792
best-valid-loss: 0.276844
best-kappa: 0.8500
: Epoch: 12 | Training Loss: 0.252792 | Val. Loss: 0.276844 | Val. Kappa Score: 0.8500 | LR: 0.000500 | Estimated time: 49.28
Train loss on 50 batch: 0.180565
Train loss on 100 batch: 0.255590
Train loss on 150 batch: 0.247832
: Epoch: 13 | Training Loss: 0.229744 | Val. Loss: 0.302017 | Val. Kappa Score: 0.8536 | LR: 0.000500 | Estimated time: 49.52
Train loss on 50 batch: 0.233385
Train loss on 100 batch: 0.208784
Train loss on 150 batch: 0.245028
best-train-loss: 0.224350
best-valid-loss: 0.259116
best-kappa: 0.8567
: Epoch: 14 | Training Loss: 0.224350 | Val. Loss: 0.259116 | Val. Kappa Score: 0.8567 | LR: 0.000500 | Estimated time: 49.43
Train loss on 50 batch: 0.229836
Train loss on 100 batch: 0.199995
Train loss on 150 batch: 0.225939
: Epoch: 15 | Training Loss: 0.216915 | Val. Loss: 0.362959 | Val. Kappa Score: 0.8566 | LR: 0.000500 | Estimated time: 49.48
Train loss on 50 batch: 0.194992
Train loss on 100 batch: 0.196610
Train loss on 150 batch: 0.165227
: Epoch: 16 | Training Loss: 0.190658 | Val. Loss: 0.276356 | Val. Kappa Score: 0.8582 | LR: 0.000500 | Estimated time: 49.43
Train loss on 50 batch: 0.176320
Train loss on 100 batch: 0.212674
Train loss on 150 batch: 0.185808
: Epoch: 17 | Training Loss: 0.190905 | Val. Loss: 0.296037 | Val. Kappa Score: 0.8594 | LR: 0.000250 | Estimated time: 49.39
Train loss on 50 batch: 0.172627
Train loss on 100 batch: 0.121609
Train loss on 150 batch: 0.149247
: Epoch: 18 | Training Loss: 0.150606 | Val. Loss: 0.283392 | Val. Kappa Score: 0.8611 | LR: 0.000250 | Estimated time: 49.36
Train loss on 50 batch: 0.129086
Train loss on 100 batch: 0.145655
Train loss on 150 batch: 0.141250
: Epoch: 19 | Training Loss: 0.138386 | Val. Loss: 0.324221 | Val. Kappa Score: 0.8620 | LR: 0.000250 | Estimated time: 49.50
Train loss on 50 batch: 0.121623
Train loss on 100 batch: 0.157220
Train loss on 150 batch: 0.161458
: Epoch: 20 | Training Loss: 0.141672 | Val. Loss: 0.302347 | Val. Kappa Score: 0.8632 | LR: 0.000125 | Estimated time: 49.47
Train loss on 50 batch: 0.114377
Train loss on 100 batch: 0.094578
Train loss on 150 batch: 0.127369
: Epoch: 21 | Training Loss: 0.139273 | Val. Loss: 0.299374 | Val. Kappa Score: 0.8643 | LR: 0.000125 | Estimated time: 49.50
Train loss on 50 batch: 0.103318
Train loss on 100 batch: 0.113886
Train loss on 150 batch: 0.097422
: Epoch: 22 | Training Loss: 0.105479 | Val. Loss: 0.304270 | Val. Kappa Score: 0.8655 | LR: 0.000125 | Estimated time: 49.52
time_estimated: 1091.81
n-epochs: 22
time_estimated: 1091.85
----------------------------------------

Experiment N: 110: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:33:34
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1037b8>
early-stopping-patience: 8
parameters-amount: 29390385
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.305075
Train loss on 100 batch: 0.655098
Train loss on 150 batch: 0.604219
best-train-loss: 0.767090
best-valid-loss: 0.504515
best-kappa: 0.8366
: Epoch: 1 | Training Loss: 0.767090 | Val. Loss: 0.504515 | Val. Kappa Score: 0.8366 | LR: 0.001000 | Estimated time: 50.26
Train loss on 50 batch: 0.417926
Train loss on 100 batch: 0.468069
Train loss on 150 batch: 0.384124
: Epoch: 2 | Training Loss: 0.450517 | Val. Loss: 0.762301 | Val. Kappa Score: 0.7584 | LR: 0.001000 | Estimated time: 49.60
Train loss on 50 batch: 0.424570
Train loss on 100 batch: 0.472294
Train loss on 150 batch: 0.389171
best-train-loss: 0.417981
best-valid-loss: 0.332193
best-kappa: 0.7998
: Epoch: 3 | Training Loss: 0.417981 | Val. Loss: 0.332193 | Val. Kappa Score: 0.7998 | LR: 0.001000 | Estimated time: 49.76
Train loss on 50 batch: 0.375431
Train loss on 100 batch: 0.421401
Train loss on 150 batch: 0.395589
: Epoch: 4 | Training Loss: 0.440717 | Val. Loss: 0.670865 | Val. Kappa Score: 0.8039 | LR: 0.001000 | Estimated time: 49.61
Train loss on 50 batch: 0.500001
Train loss on 100 batch: 0.419856
Train loss on 150 batch: 0.327123
: Epoch: 5 | Training Loss: 0.419519 | Val. Loss: 0.656143 | Val. Kappa Score: 0.8078 | LR: 0.001000 | Estimated time: 49.63
Train loss on 50 batch: 0.411748
Train loss on 100 batch: 0.328228
Train loss on 150 batch: 0.374983
: Epoch: 6 | Training Loss: 0.371191 | Val. Loss: 0.504419 | Val. Kappa Score: 0.8092 | LR: 0.000500 | Estimated time: 49.61
Train loss on 50 batch: 0.367214
Train loss on 100 batch: 0.295713
Train loss on 150 batch: 0.225873
best-train-loss: 0.301812
best-valid-loss: 0.285209
best-kappa: 0.8221
: Epoch: 7 | Training Loss: 0.301812 | Val. Loss: 0.285209 | Val. Kappa Score: 0.8221 | LR: 0.000500 | Estimated time: 49.53
Train loss on 50 batch: 0.216576
Train loss on 100 batch: 0.257643
Train loss on 150 batch: 0.226501
: Epoch: 8 | Training Loss: 0.242390 | Val. Loss: 0.285830 | Val. Kappa Score: 0.8316 | LR: 0.000500 | Estimated time: 49.70
Train loss on 50 batch: 0.215510
Train loss on 100 batch: 0.270486
Train loss on 150 batch: 0.267530
best-train-loss: 0.242110
best-valid-loss: 0.279767
best-kappa: 0.8388
: Epoch: 9 | Training Loss: 0.242110 | Val. Loss: 0.279767 | Val. Kappa Score: 0.8388 | LR: 0.000500 | Estimated time: 49.68
Train loss on 50 batch: 0.212497
Train loss on 100 batch: 0.225671
Train loss on 150 batch: 0.233926
: Epoch: 10 | Training Loss: 0.273990 | Val. Loss: 0.419498 | Val. Kappa Score: 0.8404 | LR: 0.000500 | Estimated time: 49.66
Train loss on 50 batch: 0.244973
Train loss on 100 batch: 0.231094
Train loss on 150 batch: 0.205413
: Epoch: 11 | Training Loss: 0.241891 | Val. Loss: 0.285017 | Val. Kappa Score: 0.8448 | LR: 0.000500 | Estimated time: 49.76
Train loss on 50 batch: 0.190201
Train loss on 100 batch: 0.202103
Train loss on 150 batch: 0.219413
: Epoch: 12 | Training Loss: 0.224481 | Val. Loss: 0.320612 | Val. Kappa Score: 0.8477 | LR: 0.000250 | Estimated time: 49.76
Train loss on 50 batch: 0.169244
Train loss on 100 batch: 0.185209
Train loss on 150 batch: 0.150608
: Epoch: 13 | Training Loss: 0.173013 | Val. Loss: 0.300762 | Val. Kappa Score: 0.8504 | LR: 0.000250 | Estimated time: 49.68
Train loss on 50 batch: 0.161408
Train loss on 100 batch: 0.150603
Train loss on 150 batch: 0.171293
best-train-loss: 0.171607
best-valid-loss: 0.274634
best-kappa: 0.8534
: Epoch: 14 | Training Loss: 0.171607 | Val. Loss: 0.274634 | Val. Kappa Score: 0.8534 | LR: 0.000250 | Estimated time: 49.75
Train loss on 50 batch: 0.184404
Train loss on 100 batch: 0.145067
Train loss on 150 batch: 0.170431
: Epoch: 15 | Training Loss: 0.163565 | Val. Loss: 0.313490 | Val. Kappa Score: 0.8547 | LR: 0.000250 | Estimated time: 49.76
Train loss on 50 batch: 0.157447
Train loss on 100 batch: 0.144527
Train loss on 150 batch: 0.140697
: Epoch: 16 | Training Loss: 0.148993 | Val. Loss: 0.318259 | Val. Kappa Score: 0.8560 | LR: 0.000250 | Estimated time: 49.76
Train loss on 50 batch: 0.144937
Train loss on 100 batch: 0.153217
Train loss on 150 batch: 0.136808
: Epoch: 17 | Training Loss: 0.141609 | Val. Loss: 0.287213 | Val. Kappa Score: 0.8582 | LR: 0.000125 | Estimated time: 49.62
Train loss on 50 batch: 0.115478
Train loss on 100 batch: 0.099672
Train loss on 150 batch: 0.129617
: Epoch: 18 | Training Loss: 0.114201 | Val. Loss: 0.313330 | Val. Kappa Score: 0.8597 | LR: 0.000125 | Estimated time: 49.68
Train loss on 50 batch: 0.090700
Train loss on 100 batch: 0.123272
Train loss on 150 batch: 0.112203
: Epoch: 19 | Training Loss: 0.108133 | Val. Loss: 0.319159 | Val. Kappa Score: 0.8611 | LR: 0.000125 | Estimated time: 49.78
Train loss on 50 batch: 0.091549
Train loss on 100 batch: 0.114258
Train loss on 150 batch: 0.087704
: Epoch: 20 | Training Loss: 0.096251 | Val. Loss: 0.303709 | Val. Kappa Score: 0.8620 | LR: 0.000063 | Estimated time: 49.69
Train loss on 50 batch: 0.099257
Train loss on 100 batch: 0.085015
Train loss on 150 batch: 0.090035
: Epoch: 21 | Training Loss: 0.113648 | Val. Loss: 0.291980 | Val. Kappa Score: 0.8633 | LR: 0.000063 | Estimated time: 49.75
Train loss on 50 batch: 0.090122
Train loss on 100 batch: 0.089278
Train loss on 150 batch: 0.081241
: Epoch: 22 | Training Loss: 0.087010 | Val. Loss: 0.297126 | Val. Kappa Score: 0.8645 | LR: 0.000063 | Estimated time: 49.67
time_estimated: 1094.74
n-epochs: 22
time_estimated: 1094.76
----------------------------------------

Experiment N: 111: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:53:08
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102400>
early-stopping-patience: 8
parameters-amount: 28341809
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 111: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:53:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1028d0>
early-stopping-patience: 8
parameters-amount: 28341809
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 111: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:53:54
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1027f0>
early-stopping-patience: 8
parameters-amount: 28341809
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 111: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:54:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d103438>
early-stopping-patience: 8
parameters-amount: 28341809
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 111: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 01:55:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102630>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.175308
Train loss on 100 batch: 0.734548
Train loss on 150 batch: 0.664419
best-train-loss: 0.797433
best-valid-loss: 0.410241
best-kappa: 0.8542
: Epoch: 1 | Training Loss: 0.797433 | Val. Loss: 0.410241 | Val. Kappa Score: 0.8542 | LR: 0.001000 | Estimated time: 49.79
Train loss on 50 batch: 0.542186
Train loss on 100 batch: 0.535956
Train loss on 150 batch: 0.454568
: Epoch: 2 | Training Loss: 0.534356 | Val. Loss: 0.750924 | Val. Kappa Score: 0.8150 | LR: 0.001000 | Estimated time: 49.27
Train loss on 50 batch: 0.463396
Train loss on 100 batch: 0.445715
Train loss on 150 batch: 0.452151
best-train-loss: 0.445392
best-valid-loss: 0.366535
best-kappa: 0.8292
: Epoch: 3 | Training Loss: 0.445392 | Val. Loss: 0.366535 | Val. Kappa Score: 0.8292 | LR: 0.001000 | Estimated time: 49.22
Train loss on 50 batch: 0.405408
Train loss on 100 batch: 0.427396
Train loss on 150 batch: 0.436946
: Epoch: 4 | Training Loss: 0.513678 | Val. Loss: 0.492043 | Val. Kappa Score: 0.8353 | LR: 0.001000 | Estimated time: 49.11
Train loss on 50 batch: 0.534189
Train loss on 100 batch: 0.514352
Train loss on 150 batch: 0.376494
: Epoch: 5 | Training Loss: 0.454423 | Val. Loss: 0.403136 | Val. Kappa Score: 0.8378 | LR: 0.001000 | Estimated time: 49.16
Train loss on 50 batch: 0.384884
Train loss on 100 batch: 0.373659
Train loss on 150 batch: 0.362829
best-train-loss: 0.355832
best-valid-loss: 0.355914
best-kappa: 0.8408
: Epoch: 6 | Training Loss: 0.355832 | Val. Loss: 0.355914 | Val. Kappa Score: 0.8408 | LR: 0.001000 | Estimated time: 49.13
Train loss on 50 batch: 0.359275
Train loss on 100 batch: 0.364838
Train loss on 150 batch: 0.399436
best-train-loss: 0.373181
best-valid-loss: 0.344471
best-kappa: 0.8449
: Epoch: 7 | Training Loss: 0.373181 | Val. Loss: 0.344471 | Val. Kappa Score: 0.8449 | LR: 0.001000 | Estimated time: 49.29
Train loss on 50 batch: 0.289940
Train loss on 100 batch: 0.381446
Train loss on 150 batch: 0.316975
best-train-loss: 0.337724
best-valid-loss: 0.330102
best-kappa: 0.8487
: Epoch: 8 | Training Loss: 0.337724 | Val. Loss: 0.330102 | Val. Kappa Score: 0.8487 | LR: 0.001000 | Estimated time: 49.06
Train loss on 50 batch: 0.328698
Train loss on 100 batch: 0.376530
Train loss on 150 batch: 0.403529
best-train-loss: 0.357364
best-valid-loss: 0.269128
best-kappa: 0.8548
: Epoch: 9 | Training Loss: 0.357364 | Val. Loss: 0.269128 | Val. Kappa Score: 0.8548 | LR: 0.001000 | Estimated time: 49.10
Train loss on 50 batch: 0.325285
Train loss on 100 batch: 0.328916
Train loss on 150 batch: 0.318820
: Epoch: 10 | Training Loss: 0.378416 | Val. Loss: 0.987065 | Val. Kappa Score: 0.8428 | LR: 0.001000 | Estimated time: 49.10
Train loss on 50 batch: 0.423851
Train loss on 100 batch: 0.380397
Train loss on 150 batch: 0.363399
: Epoch: 11 | Training Loss: 0.376017 | Val. Loss: 0.333684 | Val. Kappa Score: 0.8460 | LR: 0.001000 | Estimated time: 49.10
Train loss on 50 batch: 0.303986
Train loss on 100 batch: 0.322040
Train loss on 150 batch: 0.311996
: Epoch: 12 | Training Loss: 0.311413 | Val. Loss: 0.356851 | Val. Kappa Score: 0.8473 | LR: 0.000500 | Estimated time: 49.10
Train loss on 50 batch: 0.248939
Train loss on 100 batch: 0.287068
Train loss on 150 batch: 0.252537
: Epoch: 13 | Training Loss: 0.262659 | Val. Loss: 0.272490 | Val. Kappa Score: 0.8516 | LR: 0.000500 | Estimated time: 49.06
Train loss on 50 batch: 0.247503
Train loss on 100 batch: 0.233485
Train loss on 150 batch: 0.263045
best-train-loss: 0.248240
best-valid-loss: 0.234105
best-kappa: 0.8558
: Epoch: 14 | Training Loss: 0.248240 | Val. Loss: 0.234105 | Val. Kappa Score: 0.8558 | LR: 0.000500 | Estimated time: 49.13
Train loss on 50 batch: 0.257050
Train loss on 100 batch: 0.234305
Train loss on 150 batch: 0.244510
: Epoch: 15 | Training Loss: 0.236519 | Val. Loss: 0.274563 | Val. Kappa Score: 0.8590 | LR: 0.000500 | Estimated time: 49.13
Train loss on 50 batch: 0.223399
Train loss on 100 batch: 0.226114
Train loss on 150 batch: 0.219745
: Epoch: 16 | Training Loss: 0.232607 | Val. Loss: 0.243675 | Val. Kappa Score: 0.8621 | LR: 0.000500 | Estimated time: 49.01
Train loss on 50 batch: 0.237049
Train loss on 100 batch: 0.226265
Train loss on 150 batch: 0.196608
: Epoch: 17 | Training Loss: 0.221692 | Val. Loss: 0.273769 | Val. Kappa Score: 0.8636 | LR: 0.000250 | Estimated time: 49.04
Train loss on 50 batch: 0.180207
Train loss on 100 batch: 0.174368
Train loss on 150 batch: 0.196365
: Epoch: 18 | Training Loss: 0.186600 | Val. Loss: 0.249474 | Val. Kappa Score: 0.8653 | LR: 0.000250 | Estimated time: 49.11
Train loss on 50 batch: 0.153655
Train loss on 100 batch: 0.182700
Train loss on 150 batch: 0.188263
: Epoch: 19 | Training Loss: 0.177749 | Val. Loss: 0.281438 | Val. Kappa Score: 0.8667 | LR: 0.000250 | Estimated time: 49.05
Train loss on 50 batch: 0.135912
Train loss on 100 batch: 0.185681
Train loss on 150 batch: 0.162049
: Epoch: 20 | Training Loss: 0.159579 | Val. Loss: 0.272997 | Val. Kappa Score: 0.8682 | LR: 0.000125 | Estimated time: 49.10
Train loss on 50 batch: 0.169509
Train loss on 100 batch: 0.147109
Train loss on 150 batch: 0.168027
: Epoch: 21 | Training Loss: 0.168357 | Val. Loss: 0.254827 | Val. Kappa Score: 0.8695 | LR: 0.000125 | Estimated time: 49.06
Train loss on 50 batch: 0.127778
Train loss on 100 batch: 0.148318
Train loss on 150 batch: 0.158327
: Epoch: 22 | Training Loss: 0.142812 | Val. Loss: 0.280836 | Val. Kappa Score: 0.8707 | LR: 0.000125 | Estimated time: 49.06
time_estimated: 1082.36
n-epochs: 22
time_estimated: 1082.39
----------------------------------------

Experiment N: 112: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 14:09:15
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102780>
early-stopping-patience: 8
parameters-amount: 28342833
n-epochs: 100
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 112: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 14:10:22
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fa0b38>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 112: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 14:11:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d106710>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 112: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 14:12:30
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1076a0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 112: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 14:14:31
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d106668>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.023063
Train loss on 100 batch: 0.614248
Train loss on 150 batch: 0.587014
best-train-loss: 0.672107
best-valid-loss: 0.432940
best-kappa: 0.8618
: Epoch: 1 | Training Loss: 0.672107 | Val. Loss: 0.432940 | Val. Kappa Score: 0.8618 | LR: 0.001000 | Estimated time: 166.04
Train loss on 50 batch: 0.419223
Train loss on 100 batch: 0.435417
Train loss on 150 batch: 0.398995
best-train-loss: 0.431888
best-valid-loss: 0.311495
best-kappa: 0.8728
: Epoch: 2 | Training Loss: 0.431888 | Val. Loss: 0.311495 | Val. Kappa Score: 0.8728 | LR: 0.001000 | Estimated time: 162.38
Train loss on 50 batch: 0.408509
Train loss on 100 batch: 0.417704
Train loss on 150 batch: 0.384119
: Epoch: 3 | Training Loss: 0.387161 | Val. Loss: 0.372193 | Val. Kappa Score: 0.8732 | LR: 0.001000 | Estimated time: 162.91
Train loss on 50 batch: 0.372222
Train loss on 100 batch: 0.362339
Train loss on 150 batch: 0.361056
: Epoch: 4 | Training Loss: 0.429162 | Val. Loss: 0.591470 | Val. Kappa Score: 0.8659 | LR: 0.001000 | Estimated time: 162.80
Train loss on 50 batch: 0.517526
Train loss on 100 batch: 0.437335
Train loss on 150 batch: 0.313616
: Epoch: 5 | Training Loss: 0.406211 | Val. Loss: 0.513992 | Val. Kappa Score: 0.8700 | LR: 0.000500 | Estimated time: 165.04
Train loss on 50 batch: 0.315125
Train loss on 100 batch: 0.312412
Train loss on 150 batch: 0.278045
: Epoch: 6 | Training Loss: 0.280997 | Val. Loss: 0.345566 | Val. Kappa Score: 0.8706 | LR: 0.000500 | Estimated time: 163.58
Train loss on 50 batch: 0.283696
Train loss on 100 batch: 0.249179
Train loss on 150 batch: 0.232373
best-train-loss: 0.252643
best-valid-loss: 0.270197
best-kappa: 0.8734
: Epoch: 7 | Training Loss: 0.252643 | Val. Loss: 0.270197 | Val. Kappa Score: 0.8734 | LR: 0.000500 | Estimated time: 163.84
Train loss on 50 batch: 0.204837
Train loss on 100 batch: 0.261483
Train loss on 150 batch: 0.206638
: Epoch: 8 | Training Loss: 0.243754 | Val. Loss: 0.285820 | Val. Kappa Score: 0.8760 | LR: 0.000500 | Estimated time: 163.02
Train loss on 50 batch: 0.245544
Train loss on 100 batch: 0.275447
Train loss on 150 batch: 0.251254
: Epoch: 9 | Training Loss: 0.245103 | Val. Loss: 0.277355 | Val. Kappa Score: 0.8790 | LR: 0.000500 | Estimated time: 162.78
Train loss on 50 batch: 0.206367
Train loss on 100 batch: 0.215329
Train loss on 150 batch: 0.247231
: Epoch: 10 | Training Loss: 0.282173 | Val. Loss: 0.300423 | Val. Kappa Score: 0.8795 | LR: 0.000250 | Estimated time: 162.35
Train loss on 50 batch: 0.187712
Train loss on 100 batch: 0.213580
Train loss on 150 batch: 0.193445
: Epoch: 11 | Training Loss: 0.200203 | Val. Loss: 0.270827 | Val. Kappa Score: 0.8808 | LR: 0.000250 | Estimated time: 162.91
Train loss on 50 batch: 0.151342
Train loss on 100 batch: 0.158548
Train loss on 150 batch: 0.174062
best-train-loss: 0.172847
best-valid-loss: 0.269449
best-kappa: 0.8820
: Epoch: 12 | Training Loss: 0.172847 | Val. Loss: 0.269449 | Val. Kappa Score: 0.8820 | LR: 0.000250 | Estimated time: 163.42
Train loss on 50 batch: 0.147694
Train loss on 100 batch: 0.187841
Train loss on 150 batch: 0.151309
: Epoch: 13 | Training Loss: 0.169708 | Val. Loss: 0.315690 | Val. Kappa Score: 0.8829 | LR: 0.000250 | Estimated time: 162.90
Train loss on 50 batch: 0.150396
Train loss on 100 batch: 0.153238
Train loss on 150 batch: 0.171868
best-train-loss: 0.165180
best-valid-loss: 0.263259
best-kappa: 0.8836
: Epoch: 14 | Training Loss: 0.165180 | Val. Loss: 0.263259 | Val. Kappa Score: 0.8836 | LR: 0.000250 | Estimated time: 162.50
Train loss on 50 batch: 0.166053
Train loss on 100 batch: 0.153760
Train loss on 150 batch: 0.159666
: Epoch: 15 | Training Loss: 0.160886 | Val. Loss: 0.264520 | Val. Kappa Score: 0.8846 | LR: 0.000250 | Estimated time: 162.98
Train loss on 50 batch: 0.143460
Train loss on 100 batch: 0.157674
Train loss on 150 batch: 0.160538
: Epoch: 16 | Training Loss: 0.151494 | Val. Loss: 0.272775 | Val. Kappa Score: 0.8854 | LR: 0.000250 | Estimated time: 163.24
Train loss on 50 batch: 0.152381
Train loss on 100 batch: 0.152793
Train loss on 150 batch: 0.132269
: Epoch: 17 | Training Loss: 0.140704 | Val. Loss: 0.282395 | Val. Kappa Score: 0.8860 | LR: 0.000125 | Estimated time: 164.38
Train loss on 50 batch: 0.108801
Train loss on 100 batch: 0.092335
Train loss on 150 batch: 0.133927
: Epoch: 18 | Training Loss: 0.115238 | Val. Loss: 0.276241 | Val. Kappa Score: 0.8865 | LR: 0.000125 | Estimated time: 162.80
Train loss on 50 batch: 0.094406
Train loss on 100 batch: 0.123227
Train loss on 150 batch: 0.116944
: Epoch: 19 | Training Loss: 0.112203 | Val. Loss: 0.272337 | Val. Kappa Score: 0.8873 | LR: 0.000125 | Estimated time: 163.83
Train loss on 50 batch: 0.093263
Train loss on 100 batch: 0.101504
Train loss on 150 batch: 0.100503
: Epoch: 20 | Training Loss: 0.094095 | Val. Loss: 0.272176 | Val. Kappa Score: 0.8878 | LR: 0.000063 | Estimated time: 162.21
Train loss on 50 batch: 0.091378
Train loss on 100 batch: 0.078144
Train loss on 150 batch: 0.092470
: Epoch: 21 | Training Loss: 0.108593 | Val. Loss: 0.267186 | Val. Kappa Score: 0.8886 | LR: 0.000063 | Estimated time: 163.00
Train loss on 50 batch: 0.073995
Train loss on 100 batch: 0.092317
Train loss on 150 batch: 0.094314
best-train-loss: 0.084013
best-valid-loss: 0.262158
best-kappa: 0.8895
: Epoch: 22 | Training Loss: 0.084013 | Val. Loss: 0.262158 | Val. Kappa Score: 0.8895 | LR: 0.000063 | Estimated time: 164.74
Train loss on 50 batch: 0.092145
Train loss on 100 batch: 0.069948
Train loss on 150 batch: 0.083365
: Epoch: 23 | Training Loss: 0.090120 | Val. Loss: 0.273860 | Val. Kappa Score: 0.8900 | LR: 0.000063 | Estimated time: 162.79
Train loss on 50 batch: 0.081955
Train loss on 100 batch: 0.075814
Train loss on 150 batch: 0.076653
: Epoch: 24 | Training Loss: 0.140970 | Val. Loss: 0.277943 | Val. Kappa Score: 0.8902 | LR: 0.000063 | Estimated time: 162.79
Train loss on 50 batch: 0.079126
Train loss on 100 batch: 0.081641
Train loss on 150 batch: 0.087422
: Epoch: 25 | Training Loss: 0.085655 | Val. Loss: 0.268402 | Val. Kappa Score: 0.8907 | LR: 0.000031 | Estimated time: 162.07
Train loss on 50 batch: 0.085372
Train loss on 100 batch: 0.058597
Train loss on 150 batch: 0.071006
: Epoch: 26 | Training Loss: 0.083282 | Val. Loss: 0.274820 | Val. Kappa Score: 0.8911 | LR: 0.000031 | Estimated time: 162.35
Train loss on 50 batch: 0.062233
Train loss on 100 batch: 0.083244
Train loss on 150 batch: 0.054842
: Epoch: 27 | Training Loss: 0.063975 | Val. Loss: 0.274869 | Val. Kappa Score: 0.8913 | LR: 0.000031 | Estimated time: 162.88
Train loss on 50 batch: 0.066650
Train loss on 100 batch: 0.069177
Train loss on 150 batch: 0.067334
: Epoch: 28 | Training Loss: 0.066266 | Val. Loss: 0.275979 | Val. Kappa Score: 0.8913 | LR: 0.000016 | Estimated time: 163.35
Train loss on 50 batch: 0.064348
Train loss on 100 batch: 0.065881
Train loss on 150 batch: 0.068145
: Epoch: 29 | Training Loss: 0.064000 | Val. Loss: 0.279542 | Val. Kappa Score: 0.8915 | LR: 0.000016 | Estimated time: 162.11
Train loss on 50 batch: 0.059528
Train loss on 100 batch: 0.064807
Train loss on 150 batch: 0.059404
: Epoch: 30 | Training Loss: 0.062858 | Val. Loss: 0.275604 | Val. Kappa Score: 0.8917 | LR: 0.000016 | Estimated time: 163.79
Train loss on 50 batch: 0.063237
Train loss on 100 batch: 0.067708
Train loss on 150 batch: 0.057392
: Epoch: 31 | Training Loss: 0.081482 | Val. Loss: 0.274734 | Val. Kappa Score: 0.8919 | LR: 0.000008 | Estimated time: 162.22
Train loss on 50 batch: 0.060772
Train loss on 100 batch: 0.057575
Train loss on 150 batch: 0.055717
: Epoch: 32 | Training Loss: 0.060832 | Val. Loss: 0.274645 | Val. Kappa Score: 0.8920 | LR: 0.000008 | Estimated time: 162.71
time_estimated: 5222.13
n-epochs: 32
time_estimated: 5222.15
----------------------------------------

Experiment N: 113: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.20 16:36:04
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1015f8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.963213
Train loss on 100 batch: 0.644400
Train loss on 150 batch: 0.601161
best-train-loss: 0.669926
best-valid-loss: 0.517660
best-kappa: 0.8348
: Epoch: 1 | Training Loss: 0.669926 | Val. Loss: 0.517660 | Val. Kappa Score: 0.8348 | LR: 0.001000 | Estimated time: 161.84
Train loss on 50 batch: 0.426047
Train loss on 100 batch: 0.430223
Train loss on 150 batch: 0.403505
: Epoch: 2 | Training Loss: 0.435569 | Val. Loss: 0.584131 | Val. Kappa Score: 0.8136 | LR: 0.001000 | Estimated time: 160.65
Train loss on 50 batch: 0.410072
Train loss on 100 batch: 0.386945
Train loss on 150 batch: 0.365153
best-train-loss: 0.391932
best-valid-loss: 0.403122
best-kappa: 0.8303
: Epoch: 3 | Training Loss: 0.391932 | Val. Loss: 0.403122 | Val. Kappa Score: 0.8303 | LR: 0.001000 | Estimated time: 160.14
Train loss on 50 batch: 0.361838
Train loss on 100 batch: 0.386281
Train loss on 150 batch: 0.364642
: Epoch: 4 | Training Loss: 0.423004 | Val. Loss: 0.430777 | Val. Kappa Score: 0.8324 | LR: 0.001000 | Estimated time: 160.73
Train loss on 50 batch: 0.417600
Train loss on 100 batch: 0.421786
Train loss on 150 batch: 0.320234
best-train-loss: 0.385162
best-valid-loss: 0.356583
best-kappa: 0.8399
: Epoch: 5 | Training Loss: 0.385162 | Val. Loss: 0.356583 | Val. Kappa Score: 0.8399 | LR: 0.001000 | Estimated time: 161.64
Train loss on 50 batch: 0.380966
Train loss on 100 batch: 0.335119
Train loss on 150 batch: 0.338106
: Epoch: 6 | Training Loss: 0.334242 | Val. Loss: 0.392098 | Val. Kappa Score: 0.8436 | LR: 0.001000 | Estimated time: 160.84
Train loss on 50 batch: 0.313466
Train loss on 100 batch: 0.291020
Train loss on 150 batch: 0.286959
best-train-loss: 0.295958
best-valid-loss: 0.318780
best-kappa: 0.8501
: Epoch: 7 | Training Loss: 0.295958 | Val. Loss: 0.318780 | Val. Kappa Score: 0.8501 | LR: 0.001000 | Estimated time: 160.48
Train loss on 50 batch: 0.222631
Train loss on 100 batch: 0.288925
Train loss on 150 batch: 0.259546
best-train-loss: 0.270419
best-valid-loss: 0.277482
best-kappa: 0.8559
: Epoch: 8 | Training Loss: 0.270419 | Val. Loss: 0.277482 | Val. Kappa Score: 0.8559 | LR: 0.001000 | Estimated time: 160.91
Train loss on 50 batch: 0.259630
Train loss on 100 batch: 0.303596
Train loss on 150 batch: 0.300580
: Epoch: 9 | Training Loss: 0.286266 | Val. Loss: 0.301249 | Val. Kappa Score: 0.8590 | LR: 0.001000 | Estimated time: 161.10
Train loss on 50 batch: 0.265122
Train loss on 100 batch: 0.305040
Train loss on 150 batch: 0.273646
: Epoch: 10 | Training Loss: 0.333219 | Val. Loss: 0.353181 | Val. Kappa Score: 0.8588 | LR: 0.001000 | Estimated time: 160.50
Train loss on 50 batch: 0.266809
Train loss on 100 batch: 0.281155
Train loss on 150 batch: 0.263775
best-train-loss: 0.276091
best-valid-loss: 0.264551
best-kappa: 0.8615
: Epoch: 11 | Training Loss: 0.276091 | Val. Loss: 0.264551 | Val. Kappa Score: 0.8615 | LR: 0.001000 | Estimated time: 160.82
Train loss on 50 batch: 0.228140
Train loss on 100 batch: 0.239868
Train loss on 150 batch: 0.263478
: Epoch: 12 | Training Loss: 0.256024 | Val. Loss: 0.345508 | Val. Kappa Score: 0.8622 | LR: 0.001000 | Estimated time: 160.61
Train loss on 50 batch: 0.231674
Train loss on 100 batch: 0.266311
Train loss on 150 batch: 0.277714
: Epoch: 13 | Training Loss: 0.275286 | Val. Loss: 0.325473 | Val. Kappa Score: 0.8633 | LR: 0.001000 | Estimated time: 160.93
Train loss on 50 batch: 0.229879
Train loss on 100 batch: 0.257609
Train loss on 150 batch: 0.269278
: Epoch: 14 | Training Loss: 0.259432 | Val. Loss: 0.279389 | Val. Kappa Score: 0.8657 | LR: 0.000500 | Estimated time: 161.43
Train loss on 50 batch: 0.240047
Train loss on 100 batch: 0.215640
Train loss on 150 batch: 0.202882
: Epoch: 15 | Training Loss: 0.214415 | Val. Loss: 0.287160 | Val. Kappa Score: 0.8672 | LR: 0.000500 | Estimated time: 160.37
Train loss on 50 batch: 0.175783
Train loss on 100 batch: 0.193405
Train loss on 150 batch: 0.202003
: Epoch: 16 | Training Loss: 0.193902 | Val. Loss: 0.276801 | Val. Kappa Score: 0.8688 | LR: 0.000500 | Estimated time: 160.95
Train loss on 50 batch: 0.198777
Train loss on 100 batch: 0.161063
Train loss on 150 batch: 0.150579
: Epoch: 17 | Training Loss: 0.181521 | Val. Loss: 0.269261 | Val. Kappa Score: 0.8702 | LR: 0.000250 | Estimated time: 161.11
Train loss on 50 batch: 0.150879
Train loss on 100 batch: 0.125416
Train loss on 150 batch: 0.171988
: Epoch: 18 | Training Loss: 0.151672 | Val. Loss: 0.300085 | Val. Kappa Score: 0.8706 | LR: 0.000250 | Estimated time: 160.60
Train loss on 50 batch: 0.133425
Train loss on 100 batch: 0.162632
Train loss on 150 batch: 0.159337
: Epoch: 19 | Training Loss: 0.156135 | Val. Loss: 0.285590 | Val. Kappa Score: 0.8714 | LR: 0.000250 | Estimated time: 160.74
Train loss on 50 batch: 0.132830
Train loss on 100 batch: 0.152479
Train loss on 150 batch: 0.131528
: Epoch: 20 | Training Loss: 0.139122 | Val. Loss: 0.280641 | Val. Kappa Score: 0.8722 | LR: 0.000125 | Estimated time: 160.26
Train loss on 50 batch: 0.142451
Train loss on 100 batch: 0.112825
Train loss on 150 batch: 0.135451
: Epoch: 21 | Training Loss: 0.150219 | Val. Loss: 0.280709 | Val. Kappa Score: 0.8732 | LR: 0.000125 | Estimated time: 159.94
time_estimated: 3377.39
n-epochs: 21
time_estimated: 3377.42
----------------------------------------

Experiment N: 114: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.20 18:39:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d103828>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.941805
Train loss on 100 batch: 0.554741
Train loss on 150 batch: 0.585250
best-train-loss: 0.630347
best-valid-loss: 0.441193
best-kappa: 0.8456
: Epoch: 1 | Training Loss: 0.630347 | Val. Loss: 0.441193 | Val. Kappa Score: 0.8456 | LR: 0.001000 | Estimated time: 174.99
Train loss on 50 batch: 0.437405
Train loss on 100 batch: 0.457084
Train loss on 150 batch: 0.335346
: Epoch: 2 | Training Loss: 0.436251 | Val. Loss: 0.453653 | Val. Kappa Score: 0.8344 | LR: 0.001000 | Estimated time: 173.26
Train loss on 50 batch: 0.409032
Train loss on 100 batch: 0.388984
Train loss on 150 batch: 0.385352
: Epoch: 3 | Training Loss: 0.387347 | Val. Loss: 0.458981 | Val. Kappa Score: 0.8477 | LR: 0.001000 | Estimated time: 178.24
Train loss on 50 batch: 0.425215
Train loss on 100 batch: 0.383975
Train loss on 150 batch: 0.338122
: Epoch: 4 | Training Loss: 0.409770 | Val. Loss: 0.627114 | Val. Kappa Score: 0.8562 | LR: 0.000500 | Estimated time: 179.06
Train loss on 50 batch: 0.373245
Train loss on 100 batch: 0.311043
Train loss on 150 batch: 0.253338
best-train-loss: 0.315024
best-valid-loss: 0.318457
best-kappa: 0.8637
: Epoch: 5 | Training Loss: 0.315024 | Val. Loss: 0.318457 | Val. Kappa Score: 0.8637 | LR: 0.000500 | Estimated time: 179.92
Train loss on 50 batch: 0.260848
Train loss on 100 batch: 0.266627
Train loss on 150 batch: 0.240765
best-train-loss: 0.258041
best-valid-loss: 0.285447
best-kappa: 0.8677
: Epoch: 6 | Training Loss: 0.258041 | Val. Loss: 0.285447 | Val. Kappa Score: 0.8677 | LR: 0.000500 | Estimated time: 174.47
Train loss on 50 batch: 0.264586
Train loss on 100 batch: 0.253840
Train loss on 150 batch: 0.229722
best-train-loss: 0.253441
best-valid-loss: 0.283526
best-kappa: 0.8703
: Epoch: 7 | Training Loss: 0.253441 | Val. Loss: 0.283526 | Val. Kappa Score: 0.8703 | LR: 0.000500 | Estimated time: 180.98
Train loss on 50 batch: 0.204800
Train loss on 100 batch: 0.237210
Train loss on 150 batch: 0.201892
: Epoch: 8 | Training Loss: 0.217973 | Val. Loss: 0.285966 | Val. Kappa Score: 0.8736 | LR: 0.000500 | Estimated time: 177.90
Train loss on 50 batch: 0.191898
Train loss on 100 batch: 0.238205
Train loss on 150 batch: 0.243402
best-train-loss: 0.218789
best-valid-loss: 0.269207
best-kappa: 0.8766
: Epoch: 9 | Training Loss: 0.218789 | Val. Loss: 0.269207 | Val. Kappa Score: 0.8766 | LR: 0.000500 | Estimated time: 179.67
Train loss on 50 batch: 0.180965
Train loss on 100 batch: 0.216209
Train loss on 150 batch: 0.213856
: Epoch: 10 | Training Loss: 0.247014 | Val. Loss: 0.380134 | Val. Kappa Score: 0.8759 | LR: 0.000500 | Estimated time: 172.49
Train loss on 50 batch: 0.246071
Train loss on 100 batch: 0.240695
Train loss on 150 batch: 0.208886
: Epoch: 11 | Training Loss: 0.248920 | Val. Loss: 0.435819 | Val. Kappa Score: 0.8745 | LR: 0.000500 | Estimated time: 170.01
Train loss on 50 batch: 0.191965
Train loss on 100 batch: 0.201504
Train loss on 150 batch: 0.195855
: Epoch: 12 | Training Loss: 0.215869 | Val. Loss: 0.365429 | Val. Kappa Score: 0.8737 | LR: 0.000250 | Estimated time: 169.21
Train loss on 50 batch: 0.165962
Train loss on 100 batch: 0.176596
Train loss on 150 batch: 0.143304
: Epoch: 13 | Training Loss: 0.170891 | Val. Loss: 0.316585 | Val. Kappa Score: 0.8753 | LR: 0.000250 | Estimated time: 169.52
Train loss on 50 batch: 0.138031
Train loss on 100 batch: 0.136138
Train loss on 150 batch: 0.166849
: Epoch: 14 | Training Loss: 0.158471 | Val. Loss: 0.288456 | Val. Kappa Score: 0.8767 | LR: 0.000250 | Estimated time: 169.06
Train loss on 50 batch: 0.158984
Train loss on 100 batch: 0.149155
Train loss on 150 batch: 0.150987
: Epoch: 15 | Training Loss: 0.148745 | Val. Loss: 0.278847 | Val. Kappa Score: 0.8789 | LR: 0.000125 | Estimated time: 169.16
Train loss on 50 batch: 0.121481
Train loss on 100 batch: 0.126561
Train loss on 150 batch: 0.109205
: Epoch: 16 | Training Loss: 0.119871 | Val. Loss: 0.271821 | Val. Kappa Score: 0.8800 | LR: 0.000125 | Estimated time: 174.16
Train loss on 50 batch: 0.124752
Train loss on 100 batch: 0.107288
Train loss on 150 batch: 0.098823
: Epoch: 17 | Training Loss: 0.111432 | Val. Loss: 0.283860 | Val. Kappa Score: 0.8808 | LR: 0.000125 | Estimated time: 173.02
Train loss on 50 batch: 0.097904
Train loss on 100 batch: 0.102133
Train loss on 150 batch: 0.106606
best-train-loss: 0.106745
best-valid-loss: 0.263581
best-kappa: 0.8812
: Epoch: 18 | Training Loss: 0.106745 | Val. Loss: 0.263581 | Val. Kappa Score: 0.8812 | LR: 0.000125 | Estimated time: 169.44
Train loss on 50 batch: 0.088097
Train loss on 100 batch: 0.118765
Train loss on 150 batch: 0.107599
: Epoch: 19 | Training Loss: 0.106210 | Val. Loss: 0.278962 | Val. Kappa Score: 0.8817 | LR: 0.000125 | Estimated time: 171.20
Train loss on 50 batch: 0.104466
Train loss on 100 batch: 0.106138
Train loss on 150 batch: 0.090501
: Epoch: 20 | Training Loss: 0.101397 | Val. Loss: 0.274547 | Val. Kappa Score: 0.8823 | LR: 0.000125 | Estimated time: 175.96
Train loss on 50 batch: 0.098343
Train loss on 100 batch: 0.089977
Train loss on 150 batch: 0.105242
: Epoch: 21 | Training Loss: 0.114735 | Val. Loss: 0.265525 | Val. Kappa Score: 0.8833 | LR: 0.000063 | Estimated time: 175.45
Train loss on 50 batch: 0.073751
Train loss on 100 batch: 0.093908
Train loss on 150 batch: 0.101850
: Epoch: 22 | Training Loss: 0.089326 | Val. Loss: 0.282283 | Val. Kappa Score: 0.8839 | LR: 0.000063 | Estimated time: 169.46
Train loss on 50 batch: 0.078025
Train loss on 100 batch: 0.063644
Train loss on 150 batch: 0.080231
: Epoch: 23 | Training Loss: 0.078799 | Val. Loss: 0.277111 | Val. Kappa Score: 0.8845 | LR: 0.000063 | Estimated time: 169.85
Train loss on 50 batch: 0.078431
Train loss on 100 batch: 0.092808
Train loss on 150 batch: 0.068520
: Epoch: 24 | Training Loss: 0.119396 | Val. Loss: 0.280900 | Val. Kappa Score: 0.8846 | LR: 0.000031 | Estimated time: 170.32
Train loss on 50 batch: 0.066729
Train loss on 100 batch: 0.068488
Train loss on 150 batch: 0.072683
: Epoch: 25 | Training Loss: 0.075023 | Val. Loss: 0.267996 | Val. Kappa Score: 0.8851 | LR: 0.000031 | Estimated time: 170.79
Train loss on 50 batch: 0.074669
Train loss on 100 batch: 0.056965
Train loss on 150 batch: 0.064955
: Epoch: 26 | Training Loss: 0.077823 | Val. Loss: 0.272385 | Val. Kappa Score: 0.8855 | LR: 0.000031 | Estimated time: 169.31
Train loss on 50 batch: 0.067648
Train loss on 100 batch: 0.081460
Train loss on 150 batch: 0.062846
: Epoch: 27 | Training Loss: 0.069325 | Val. Loss: 0.264726 | Val. Kappa Score: 0.8859 | LR: 0.000016 | Estimated time: 169.30
Train loss on 50 batch: 0.064884
Train loss on 100 batch: 0.068732
Train loss on 150 batch: 0.077031
: Epoch: 28 | Training Loss: 0.069377 | Val. Loss: 0.265920 | Val. Kappa Score: 0.8859 | LR: 0.000016 | Estimated time: 169.73
time_estimated: 4847.07
n-epochs: 28
time_estimated: 4847.10
----------------------------------------

Experiment N: 115: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 20:09:52
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1026d8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 115: 



EXPERIMENT WITH BATCH_SIZE: 4, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 20:10:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d108780>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.389493
Train loss on 100 batch: 1.265262
Train loss on 150 batch: 1.019726
Train loss on 200 batch: 0.787024
Train loss on 250 batch: 0.880855
Train loss on 300 batch: 0.852920
Train loss on 350 batch: 0.931522
Train loss on 400 batch: 0.807976
Train loss on 450 batch: 0.729776
Train loss on 500 batch: 0.573048
Train loss on 550 batch: 0.701685
Train loss on 600 batch: 0.533392
Train loss on 650 batch: 0.542655
Train loss on 700 batch: 0.683356
best-train-loss: 0.820012
best-valid-loss: 0.518673
best-kappa: 0.7446
: Epoch: 1 | Training Loss: 0.820012 | Val. Loss: 0.518673 | Val. Kappa Score: 0.7446 | LR: 0.001000 | Estimated time: 249.84
Train loss on 50 batch: 0.624193
Train loss on 100 batch: 0.520357
Train loss on 150 batch: 0.525283
Train loss on 200 batch: 0.477133
Train loss on 250 batch: 0.729924
Train loss on 300 batch: 0.448085
Train loss on 350 batch: 0.486896
Train loss on 400 batch: 0.422209
Train loss on 450 batch: 0.599533
Train loss on 500 batch: 0.422553
Train loss on 550 batch: 0.471645
Train loss on 600 batch: 0.395766
Train loss on 650 batch: 0.484796
Train loss on 700 batch: 0.777216
best-train-loss: 0.533738
best-valid-loss: 0.516189
best-kappa: 0.7630
: Epoch: 2 | Training Loss: 0.533738 | Val. Loss: 0.516189 | Val. Kappa Score: 0.7630 | LR: 0.001000 | Estimated time: 248.60
Train loss on 50 batch: 0.448932
Train loss on 100 batch: 0.539275
Train loss on 150 batch: 0.484813
Train loss on 200 batch: 0.578208
Train loss on 250 batch: 0.317063
Train loss on 300 batch: 0.551647
Train loss on 350 batch: 0.535889
Train loss on 400 batch: 0.495149
Train loss on 450 batch: 0.470686
Train loss on 500 batch: 0.426504
Train loss on 550 batch: 0.432498
Train loss on 600 batch: 0.484221
Train loss on 650 batch: 0.484100
Train loss on 700 batch: 0.441981
best-train-loss: 0.471804
best-valid-loss: 0.387299
best-kappa: 0.7761
: Epoch: 3 | Training Loss: 0.471804 | Val. Loss: 0.387299 | Val. Kappa Score: 0.7761 | LR: 0.001000 | Estimated time: 248.07
Train loss on 50 batch: 0.382644
Train loss on 100 batch: 0.413190
Train loss on 150 batch: 0.397682
Train loss on 200 batch: 0.391521
Train loss on 250 batch: 0.380724
Train loss on 300 batch: 0.395929
Train loss on 350 batch: 0.349177
Train loss on 400 batch: 0.588332
Train loss on 450 batch: 0.394511
Train loss on 500 batch: 0.492470
Train loss on 550 batch: 0.396188
Train loss on 600 batch: 0.417721
Train loss on 650 batch: 0.434134
Train loss on 700 batch: 0.420500
: Epoch: 4 | Training Loss: 0.423118 | Val. Loss: 1.532809 | Val. Kappa Score: 0.7266 | LR: 0.001000 | Estimated time: 251.09
Train loss on 50 batch: 0.492902
Train loss on 100 batch: 0.403705
Train loss on 150 batch: 0.389243
Train loss on 200 batch: 0.375924
Train loss on 250 batch: 0.275223
Train loss on 300 batch: 0.472980
Train loss on 350 batch: 0.392873
Train loss on 400 batch: 0.487466
Train loss on 450 batch: 0.298820
Train loss on 500 batch: 0.338329
Train loss on 550 batch: 0.368247
Train loss on 600 batch: 0.329938
Train loss on 650 batch: 0.320744
Train loss on 700 batch: 0.350485
best-train-loss: 0.384089
best-valid-loss: 0.324736
best-kappa: 0.7420
: Epoch: 5 | Training Loss: 0.384089 | Val. Loss: 0.324736 | Val. Kappa Score: 0.7420 | LR: 0.001000 | Estimated time: 248.65
Train loss on 50 batch: 0.713968
Train loss on 100 batch: 0.391821
Train loss on 150 batch: 0.327163
Train loss on 200 batch: 0.398253
Train loss on 250 batch: 0.445102
Train loss on 300 batch: 0.372013
Train loss on 350 batch: 0.382464
Train loss on 400 batch: 0.468712
Train loss on 450 batch: 0.330307
Train loss on 500 batch: 0.272972
Train loss on 550 batch: 0.371717
Train loss on 600 batch: 0.394174
Train loss on 650 batch: 0.451922
Train loss on 700 batch: 0.336409
: Epoch: 6 | Training Loss: 0.392018 | Val. Loss: 0.368623 | Val. Kappa Score: 0.7470 | LR: 0.001000 | Estimated time: 247.23
Train loss on 50 batch: 0.435787
Train loss on 100 batch: 0.340188
Train loss on 150 batch: 0.391361
Train loss on 200 batch: 0.448060
Train loss on 250 batch: 0.290469
Train loss on 300 batch: 0.421564
Train loss on 350 batch: 0.340841
Train loss on 400 batch: 0.481683
Train loss on 450 batch: 0.448558
Train loss on 500 batch: 0.314647
Train loss on 550 batch: 0.369075
Train loss on 600 batch: 0.398135
Train loss on 650 batch: 0.368932
----------------------------------------

Experiment N: 116: 



EXPERIMENT WITH BATCH_SIZE: 4, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.20 20:38:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102748>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.504872
Train loss on 100 batch: 1.234949
Train loss on 150 batch: 0.861846
Train loss on 200 batch: 0.902999
Train loss on 250 batch: 0.871733
Train loss on 300 batch: 0.805948
Train loss on 350 batch: 0.925894
Train loss on 400 batch: 0.752995
Train loss on 450 batch: 0.882588
Train loss on 500 batch: 0.628724
Train loss on 550 batch: 0.708650
Train loss on 600 batch: 0.491090
Train loss on 650 batch: 0.555950
Train loss on 700 batch: 0.604893
best-train-loss: 0.821587
best-valid-loss: 3.796923
best-kappa: 0.6422
: Epoch: 1 | Training Loss: 0.821587 | Val. Loss: 3.796923 | Val. Kappa Score: 0.6422 | LR: 0.001000 | Estimated time: 250.88
Train loss on 50 batch: 0.741250
Train loss on 100 batch: 0.461678
Train loss on 150 batch: 0.520219
Train loss on 200 batch: 0.500947
Train loss on 250 batch: 0.671675
Train loss on 300 batch: 0.489124
Train loss on 350 batch: 0.505376
Train loss on 400 batch: 0.405246
Train loss on 450 batch: 0.577061
Train loss on 500 batch: 0.445234
Train loss on 550 batch: 0.482327
Train loss on 600 batch: 0.530839
Train loss on 650 batch: 0.456439
Train loss on 700 batch: 0.638298
best-train-loss: 0.523626
best-valid-loss: 0.472639
best-kappa: 0.6689
: Epoch: 2 | Training Loss: 0.523626 | Val. Loss: 0.472639 | Val. Kappa Score: 0.6689 | LR: 0.001000 | Estimated time: 250.15
Train loss on 50 batch: 0.352774
Train loss on 100 batch: 0.587278
Train loss on 150 batch: 0.511915
Train loss on 200 batch: 0.546046
Train loss on 250 batch: 0.325753
Train loss on 300 batch: 0.577750
Train loss on 350 batch: 0.461059
Train loss on 400 batch: 0.492142
Train loss on 450 batch: 0.404772
Train loss on 500 batch: 0.440934
Train loss on 550 batch: 0.444515
Train loss on 600 batch: 0.502736
Train loss on 650 batch: 0.440502
Train loss on 700 batch: 0.442955
best-train-loss: 0.458104
best-valid-loss: 0.378679
best-kappa: 0.7154
: Epoch: 3 | Training Loss: 0.458104 | Val. Loss: 0.378679 | Val. Kappa Score: 0.7154 | LR: 0.001000 | Estimated time: 250.48
Train loss on 50 batch: 0.387494
Train loss on 100 batch: 0.413775
Train loss on 150 batch: 0.454474
Train loss on 200 batch: 0.387810
Train loss on 250 batch: 0.390472
Train loss on 300 batch: 0.332811
Train loss on 350 batch: 0.321895
Train loss on 400 batch: 0.552364
Train loss on 450 batch: 0.439636
Train loss on 500 batch: 0.532224
Train loss on 550 batch: 0.468996
Train loss on 600 batch: 0.504602
Train loss on 650 batch: 0.412100
Train loss on 700 batch: 0.393823
: Epoch: 4 | Training Loss: 0.431433 | Val. Loss: 0.696519 | Val. Kappa Score: 0.7115 | LR: 0.001000 | Estimated time: 251.05
Train loss on 50 batch: 0.435554
Train loss on 100 batch: 0.457220
Train loss on 150 batch: 0.408042
Train loss on 200 batch: 0.361241
Train loss on 250 batch: 0.281275
Train loss on 300 batch: 0.431619
Train loss on 350 batch: 0.461840
Train loss on 400 batch: 0.537303
Train loss on 450 batch: 0.312503
Train loss on 500 batch: 0.338819
Train loss on 550 batch: 0.370847
Train loss on 600 batch: 0.356410
Train loss on 650 batch: 0.348977
Train loss on 700 batch: 0.390646
best-train-loss: 0.401456
best-valid-loss: 0.361473
best-kappa: 0.7232
: Epoch: 5 | Training Loss: 0.401456 | Val. Loss: 0.361473 | Val. Kappa Score: 0.7232 | LR: 0.001000 | Estimated time: 251.97
Train loss on 50 batch: 0.606406
Train loss on 100 batch: 0.495228
Train loss on 150 batch: 0.306716
Train loss on 200 batch: 0.367694
Train loss on 250 batch: 0.450179
Train loss on 300 batch: 0.348277
Train loss on 350 batch: 0.381314
Train loss on 400 batch: 0.432247
Train loss on 450 batch: 0.299706
Train loss on 500 batch: 0.290383
Train loss on 550 batch: 0.357080
Train loss on 600 batch: 0.405870
Train loss on 650 batch: 0.425721
Train loss on 700 batch: 0.370888
best-train-loss: 0.382546
best-valid-loss: 0.331390
best-kappa: 0.7326
: Epoch: 6 | Training Loss: 0.382546 | Val. Loss: 0.331390 | Val. Kappa Score: 0.7326 | LR: 0.001000 | Estimated time: 251.69
Train loss on 50 batch: 0.421177
Train loss on 100 batch: 0.315192
Train loss on 150 batch: 0.399569
Train loss on 200 batch: 0.374619
Train loss on 250 batch: 0.345584
Train loss on 300 batch: 0.534178
Train loss on 350 batch: 0.268288
Train loss on 400 batch: 0.416240
Train loss on 450 batch: 0.485517
Train loss on 500 batch: 0.357099
Train loss on 550 batch: 0.418757
Train loss on 600 batch: 0.463888
Train loss on 650 batch: 0.339229
Train loss on 700 batch: 0.467132
best-train-loss: 0.393999
best-valid-loss: 0.326151
best-kappa: 0.7397
: Epoch: 7 | Training Loss: 0.393999 | Val. Loss: 0.326151 | Val. Kappa Score: 0.7397 | LR: 0.001000 | Estimated time: 254.46
Train loss on 50 batch: 0.264695
Train loss on 100 batch: 0.335076
Train loss on 150 batch: 0.400453
Train loss on 200 batch: 0.431924
Train loss on 250 batch: 0.498693
Train loss on 300 batch: 0.435078
Train loss on 350 batch: 0.315384
Train loss on 400 batch: 0.327784
Train loss on 450 batch: 0.326561
Train loss on 500 batch: 0.367830
Train loss on 550 batch: 0.342994
Train loss on 600 batch: 0.276406
Train loss on 650 batch: 0.261757
Train loss on 700 batch: 0.405743
: Epoch: 8 | Training Loss: 0.354825 | Val. Loss: 0.431712 | Val. Kappa Score: 0.7439 | LR: 0.001000 | Estimated time: 259.38
Train loss on 50 batch: 0.588060
Train loss on 100 batch: 0.347788
Train loss on 150 batch: 0.173587
Train loss on 200 batch: 0.429564
Train loss on 250 batch: 0.348578
Train loss on 300 batch: 0.460859
Train loss on 350 batch: 0.434679
Train loss on 400 batch: 0.314139
Train loss on 450 batch: 0.337000
Train loss on 500 batch: 0.280515
Train loss on 550 batch: 0.471462
Train loss on 600 batch: 0.372364
Train loss on 650 batch: 0.245779
Train loss on 700 batch: 0.437081
: Epoch: 9 | Training Loss: 0.374088 | Val. Loss: 0.373734 | Val. Kappa Score: 0.7448 | LR: 0.001000 | Estimated time: 259.60
Train loss on 50 batch: 0.284457
Train loss on 100 batch: 0.307324
Train loss on 150 batch: 0.386866
Train loss on 200 batch: 0.355821
Train loss on 250 batch: 0.299651
Train loss on 300 batch: 0.460922
Train loss on 350 batch: 0.471307
Train loss on 400 batch: 0.313491
Train loss on 450 batch: 0.380612
Train loss on 500 batch: 0.266896
Train loss on 550 batch: 0.406309
Train loss on 600 batch: 0.343913
Train loss on 650 batch: 0.388957
Train loss on 700 batch: 0.345972
: Epoch: 10 | Training Loss: 0.359136 | Val. Loss: 0.421352 | Val. Kappa Score: 0.7517 | LR: 0.000500 | Estimated time: 259.41
Train loss on 50 batch: 0.396084
Train loss on 100 batch: 0.232893
Train loss on 150 batch: 0.269441
Train loss on 200 batch: 0.292220
Train loss on 250 batch: 0.251015
Train loss on 300 batch: 0.266309
Train loss on 350 batch: 0.316790
Train loss on 400 batch: 0.309390
Train loss on 450 batch: 0.250599
Train loss on 500 batch: 0.257129
Train loss on 550 batch: 0.349833
Train loss on 600 batch: 0.296440
Train loss on 650 batch: 0.326411
Train loss on 700 batch: 0.280336
: Epoch: 11 | Training Loss: 0.293449 | Val. Loss: 0.404153 | Val. Kappa Score: 0.7566 | LR: 0.000500 | Estimated time: 258.59
Train loss on 50 batch: 0.239345
Train loss on 100 batch: 0.140424
Train loss on 150 batch: 0.296469
Train loss on 200 batch: 0.284373
Train loss on 250 batch: 0.258467
Train loss on 300 batch: 0.243011
Train loss on 350 batch: 0.218197
Train loss on 400 batch: 0.274287
Train loss on 450 batch: 0.398473
Train loss on 500 batch: 0.249262
Train loss on 550 batch: 0.194524
Train loss on 600 batch: 0.290721
Train loss on 650 batch: 0.245107
Train loss on 700 batch: 0.270368
: Epoch: 12 | Training Loss: 0.263469 | Val. Loss: 0.338866 | Val. Kappa Score: 0.7603 | LR: 0.000500 | Estimated time: 255.35
Train loss on 50 batch: 0.302673
Train loss on 100 batch: 0.199765
Train loss on 150 batch: 0.252460
Train loss on 200 batch: 0.268962
Train loss on 250 batch: 0.372438
Train loss on 300 batch: 0.251312
Train loss on 350 batch: 0.359333
Train loss on 400 batch: 0.273444
Train loss on 450 batch: 0.268095
Train loss on 500 batch: 0.288832
Train loss on 550 batch: 0.240137
Train loss on 600 batch: 0.262339
Train loss on 650 batch: 0.197967
Train loss on 700 batch: 0.364357
: Epoch: 13 | Training Loss: 0.272006 | Val. Loss: 0.378391 | Val. Kappa Score: 0.7645 | LR: 0.000250 | Estimated time: 248.36
Train loss on 50 batch: 0.218755
Train loss on 100 batch: 0.220143
Train loss on 150 batch: 0.254712
Train loss on 200 batch: 0.182107
Train loss on 250 batch: 0.259518
Train loss on 300 batch: 0.156987
Train loss on 350 batch: 0.239616
Train loss on 400 batch: 0.252832
Train loss on 450 batch: 0.253343
Train loss on 500 batch: 0.306947
Train loss on 550 batch: 0.171188
Train loss on 600 batch: 0.245920
Train loss on 650 batch: 0.194249
Train loss on 700 batch: 0.229088
best-train-loss: 0.242984
best-valid-loss: 0.307106
best-kappa: 0.7676
: Epoch: 14 | Training Loss: 0.242984 | Val. Loss: 0.307106 | Val. Kappa Score: 0.7676 | LR: 0.000250 | Estimated time: 249.40
Train loss on 50 batch: 0.218705
Train loss on 100 batch: 0.285154
Train loss on 150 batch: 0.177010
Train loss on 200 batch: 0.280598
Train loss on 250 batch: 0.172714
Train loss on 300 batch: 0.254833
Train loss on 350 batch: 0.266753
Train loss on 400 batch: 0.197173
Train loss on 450 batch: 0.250650
Train loss on 500 batch: 0.190677
Train loss on 550 batch: 0.275892
Train loss on 600 batch: 0.214664
Train loss on 650 batch: 0.184063
Train loss on 700 batch: 0.281221
: Epoch: 15 | Training Loss: 0.226930 | Val. Loss: 0.309378 | Val. Kappa Score: 0.7715 | LR: 0.000250 | Estimated time: 248.07
Train loss on 50 batch: 0.251371
Train loss on 100 batch: 0.182043
Train loss on 150 batch: 0.236601
Train loss on 200 batch: 0.213611
Train loss on 250 batch: 0.190978
Train loss on 300 batch: 0.187741
Train loss on 350 batch: 0.240821
Train loss on 400 batch: 0.198359
Train loss on 450 batch: 0.284736
Train loss on 500 batch: 0.273108
Train loss on 550 batch: 0.235963
Train loss on 600 batch: 0.241132
Train loss on 650 batch: 0.219452
Train loss on 700 batch: 0.172509
: Epoch: 16 | Training Loss: 0.224212 | Val. Loss: 0.867138 | Val. Kappa Score: 0.7625 | LR: 0.000250 | Estimated time: 248.14
Train loss on 50 batch: 0.328002
Train loss on 100 batch: 0.234341
Train loss on 150 batch: 0.191707
Train loss on 200 batch: 0.272126
Train loss on 250 batch: 0.185176
Train loss on 300 batch: 0.282737
Train loss on 350 batch: 0.241329
Train loss on 400 batch: 0.164074
Train loss on 450 batch: 0.181701
Train loss on 500 batch: 0.271107
Train loss on 550 batch: 0.169991
Train loss on 600 batch: 0.174426
Train loss on 650 batch: 0.235289
Train loss on 700 batch: 0.215520
best-train-loss: 0.227210
best-valid-loss: 0.288661
best-kappa: 0.7656
: Epoch: 17 | Training Loss: 0.227210 | Val. Loss: 0.288661 | Val. Kappa Score: 0.7656 | LR: 0.000250 | Estimated time: 248.65
Train loss on 50 batch: 0.185820
Train loss on 100 batch: 0.252689
Train loss on 150 batch: 0.208816
Train loss on 200 batch: 0.218651
Train loss on 250 batch: 0.156225
Train loss on 300 batch: 0.207973
Train loss on 350 batch: 0.215983
Train loss on 400 batch: 0.173856
Train loss on 450 batch: 0.169963
Train loss on 500 batch: 0.285566
Train loss on 550 batch: 0.274856
Train loss on 600 batch: 0.196020
Train loss on 650 batch: 0.242328
Train loss on 700 batch: 0.249692
: Epoch: 18 | Training Loss: 0.214648 | Val. Loss: 0.289169 | Val. Kappa Score: 0.7693 | LR: 0.000250 | Estimated time: 248.95
Train loss on 50 batch: 0.188986
Train loss on 100 batch: 0.203134
Train loss on 150 batch: 0.179541
Train loss on 200 batch: 0.137486
Train loss on 250 batch: 0.197100
Train loss on 300 batch: 0.256178
Train loss on 350 batch: 0.189055
Train loss on 400 batch: 0.221689
Train loss on 450 batch: 0.186502
Train loss on 500 batch: 0.245188
Train loss on 550 batch: 0.262748
Train loss on 600 batch: 0.189899
Train loss on 650 batch: 0.248095
Train loss on 700 batch: 0.234211
best-train-loss: 0.211355
best-valid-loss: 0.268379
best-kappa: 0.7727
: Epoch: 19 | Training Loss: 0.211355 | Val. Loss: 0.268379 | Val. Kappa Score: 0.7727 | LR: 0.000250 | Estimated time: 247.83
Train loss on 50 batch: 0.157915
Train loss on 100 batch: 0.191450
Train loss on 150 batch: 0.195205
Train loss on 200 batch: 0.199295
Train loss on 250 batch: 0.185263
Train loss on 300 batch: 0.255524
Train loss on 350 batch: 0.274273
Train loss on 400 batch: 0.203375
Train loss on 450 batch: 0.229120
Train loss on 500 batch: 0.181062
Train loss on 550 batch: 0.172792
Train loss on 600 batch: 0.229615
Train loss on 650 batch: 0.221942
Train loss on 700 batch: 0.170745
best-train-loss: 0.201074
best-valid-loss: 0.264781
best-kappa: 0.7761
: Epoch: 20 | Training Loss: 0.201074 | Val. Loss: 0.264781 | Val. Kappa Score: 0.7761 | LR: 0.000250 | Estimated time: 252.54
Train loss on 50 batch: 0.171571
Train loss on 100 batch: 0.206295
Train loss on 150 batch: 0.206615
Train loss on 200 batch: 0.215248
Train loss on 250 batch: 0.206985
Train loss on 300 batch: 0.211261
Train loss on 350 batch: 0.235813
Train loss on 400 batch: 0.216875
Train loss on 450 batch: 0.196114
Train loss on 500 batch: 0.234132
Train loss on 550 batch: 0.225899
Train loss on 600 batch: 0.155464
Train loss on 650 batch: 0.194225
Train loss on 700 batch: 0.194052
: Epoch: 21 | Training Loss: 0.206193 | Val. Loss: 0.276930 | Val. Kappa Score: 0.7789 | LR: 0.000250 | Estimated time: 253.20
Train loss on 50 batch: 0.116317
Train loss on 100 batch: 0.181623
Train loss on 150 batch: 0.189268
Train loss on 200 batch: 0.174160
Train loss on 250 batch: 0.258344
Train loss on 300 batch: 0.179478
Train loss on 350 batch: 0.214597
Train loss on 400 batch: 0.224381
Train loss on 450 batch: 0.205550
Train loss on 500 batch: 0.224073
Train loss on 550 batch: 0.177382
Train loss on 600 batch: 0.213724
Train loss on 650 batch: 0.175750
Train loss on 700 batch: 0.208064
: Epoch: 22 | Training Loss: 0.194252 | Val. Loss: 0.271635 | Val. Kappa Score: 0.7814 | LR: 0.000250 | Estimated time: 251.80
Train loss on 50 batch: 0.119203
Train loss on 100 batch: 0.200168
Train loss on 150 batch: 0.222695
Train loss on 200 batch: 0.203836
Train loss on 250 batch: 0.191581
Train loss on 300 batch: 0.215633
Train loss on 350 batch: 0.219696
Train loss on 400 batch: 0.182025
Train loss on 450 batch: 0.186106
Train loss on 500 batch: 0.197711
Train loss on 550 batch: 0.242516
Train loss on 600 batch: 0.146504
Train loss on 650 batch: 0.190806
Train loss on 700 batch: 0.203656
: Epoch: 23 | Training Loss: 0.190447 | Val. Loss: 0.291357 | Val. Kappa Score: 0.7849 | LR: 0.000125 | Estimated time: 250.98
Train loss on 50 batch: 0.208472
Train loss on 100 batch: 0.220865
Train loss on 150 batch: 0.159643
Train loss on 200 batch: 0.189712
Train loss on 250 batch: 0.200631
Train loss on 300 batch: 0.172118
Train loss on 350 batch: 0.125880
Train loss on 400 batch: 0.178580
Train loss on 450 batch: 0.171854
Train loss on 500 batch: 0.224225
Train loss on 550 batch: 0.156638
Train loss on 600 batch: 0.125042
Train loss on 650 batch: 0.166905
Train loss on 700 batch: 0.234435
best-train-loss: 0.181404
best-valid-loss: 0.249054
best-kappa: 0.7879
: Epoch: 24 | Training Loss: 0.181404 | Val. Loss: 0.249054 | Val. Kappa Score: 0.7879 | LR: 0.000125 | Estimated time: 250.67
Train loss on 50 batch: 0.185138
Train loss on 100 batch: 0.179502
Train loss on 150 batch: 0.136770
Train loss on 200 batch: 0.142530
Train loss on 250 batch: 0.154018
Train loss on 300 batch: 0.179658
Train loss on 350 batch: 0.181150
Train loss on 400 batch: 0.147162
Train loss on 450 batch: 0.207697
Train loss on 500 batch: 0.176828
Train loss on 550 batch: 0.218128
Train loss on 600 batch: 0.161976
Train loss on 650 batch: 0.223926
Train loss on 700 batch: 0.206841
best-train-loss: 0.176984
best-valid-loss: 0.241886
best-kappa: 0.7910
: Epoch: 25 | Training Loss: 0.176984 | Val. Loss: 0.241886 | Val. Kappa Score: 0.7910 | LR: 0.000125 | Estimated time: 250.30
Train loss on 50 batch: 0.166140
Train loss on 100 batch: 0.163219
Train loss on 150 batch: 0.184892
Train loss on 200 batch: 0.170978
Train loss on 250 batch: 0.111045
Train loss on 300 batch: 0.156073
Train loss on 350 batch: 0.144474
Train loss on 400 batch: 0.128461
Train loss on 450 batch: 0.163899
Train loss on 500 batch: 0.162126
Train loss on 550 batch: 0.219036
Train loss on 600 batch: 0.166266
Train loss on 650 batch: 0.201463
Train loss on 700 batch: 0.189474
: Epoch: 26 | Training Loss: 0.167600 | Val. Loss: 0.245911 | Val. Kappa Score: 0.7940 | LR: 0.000125 | Estimated time: 249.91
Train loss on 50 batch: 0.186438
Train loss on 100 batch: 0.117584
Train loss on 150 batch: 0.175152
Train loss on 200 batch: 0.248037
Train loss on 250 batch: 0.173680
Train loss on 300 batch: 0.205374
Train loss on 350 batch: 0.207356
Train loss on 400 batch: 0.161475
Train loss on 450 batch: 0.207710
Train loss on 500 batch: 0.139508
Train loss on 550 batch: 0.150205
Train loss on 600 batch: 0.144078
Train loss on 650 batch: 0.147771
Train loss on 700 batch: 0.144354
: Epoch: 27 | Training Loss: 0.171315 | Val. Loss: 0.280342 | Val. Kappa Score: 0.7952 | LR: 0.000125 | Estimated time: 250.40
Train loss on 50 batch: 0.165881
Train loss on 100 batch: 0.143838
Train loss on 150 batch: 0.222577
Train loss on 200 batch: 0.142055
Train loss on 250 batch: 0.145540
Train loss on 300 batch: 0.180258
Train loss on 350 batch: 0.138793
Train loss on 400 batch: 0.182739
Train loss on 450 batch: 0.170763
Train loss on 500 batch: 0.225952
Train loss on 550 batch: 0.096995
Train loss on 600 batch: 0.115860
Train loss on 650 batch: 0.233833
Train loss on 700 batch: 0.153759
: Epoch: 28 | Training Loss: 0.163882 | Val. Loss: 0.259212 | Val. Kappa Score: 0.7962 | LR: 0.000063 | Estimated time: 247.14
Train loss on 50 batch: 0.174610
Train loss on 100 batch: 0.118983
Train loss on 150 batch: 0.127182
Train loss on 200 batch: 0.110585
Train loss on 250 batch: 0.151913
Train loss on 300 batch: 0.166431
Train loss on 350 batch: 0.164298
Train loss on 400 batch: 0.182181
Train loss on 450 batch: 0.181024
Train loss on 500 batch: 0.123397
Train loss on 550 batch: 0.105536
Train loss on 600 batch: 0.147840
Train loss on 650 batch: 0.212653
Train loss on 700 batch: 0.140943
: Epoch: 29 | Training Loss: 0.149493 | Val. Loss: 0.244522 | Val. Kappa Score: 0.7978 | LR: 0.000063 | Estimated time: 248.46
Train loss on 50 batch: 0.139855
Train loss on 100 batch: 0.116939
Train loss on 150 batch: 0.149605
Train loss on 200 batch: 0.124583
Train loss on 250 batch: 0.165349
Train loss on 300 batch: 0.128606
Train loss on 350 batch: 0.128031
Train loss on 400 batch: 0.156655
Train loss on 450 batch: 0.139109
Train loss on 500 batch: 0.191615
Train loss on 550 batch: 0.117664
Train loss on 600 batch: 0.147022
Train loss on 650 batch: 0.226003
Train loss on 700 batch: 0.106361
: Epoch: 30 | Training Loss: 0.143699 | Val. Loss: 0.251697 | Val. Kappa Score: 0.7989 | LR: 0.000063 | Estimated time: 248.10
Train loss on 50 batch: 0.122376
Train loss on 100 batch: 0.101156
Train loss on 150 batch: 0.135643
Train loss on 200 batch: 0.152108
Train loss on 250 batch: 0.150741
Train loss on 300 batch: 0.176763
Train loss on 350 batch: 0.170456
Train loss on 400 batch: 0.157838
Train loss on 450 batch: 0.140378
Train loss on 500 batch: 0.142911
Train loss on 550 batch: 0.165185
Train loss on 600 batch: 0.112335
Train loss on 650 batch: 0.115876
Train loss on 700 batch: 0.177523
: Epoch: 31 | Training Loss: 0.143189 | Val. Loss: 0.252555 | Val. Kappa Score: 0.8004 | LR: 0.000031 | Estimated time: 251.17
Train loss on 50 batch: 0.129462
Train loss on 100 batch: 0.142838
Train loss on 150 batch: 0.148019
Train loss on 200 batch: 0.168803
Train loss on 250 batch: 0.124508
Train loss on 300 batch: 0.204388
Train loss on 350 batch: 0.151266
Train loss on 400 batch: 0.144253
Train loss on 450 batch: 0.119810
Train loss on 500 batch: 0.156536
Train loss on 550 batch: 0.180531
Train loss on 600 batch: 0.099948
Train loss on 650 batch: 0.157787
Train loss on 700 batch: 0.113943
: Epoch: 32 | Training Loss: 0.145676 | Val. Loss: 0.247721 | Val. Kappa Score: 0.8017 | LR: 0.000031 | Estimated time: 248.50
Train loss on 50 batch: 0.117851
Train loss on 100 batch: 0.179747
Train loss on 150 batch: 0.148494
Train loss on 200 batch: 0.129938
Train loss on 250 batch: 0.157557
Train loss on 300 batch: 0.134119
Train loss on 350 batch: 0.153304
Train loss on 400 batch: 0.166044
Train loss on 450 batch: 0.109651
Train loss on 500 batch: 0.135173
Train loss on 550 batch: 0.101875
Train loss on 600 batch: 0.142291
Train loss on 650 batch: 0.136860
Train loss on 700 batch: 0.164819
: Epoch: 33 | Training Loss: 0.144650 | Val. Loss: 0.242374 | Val. Kappa Score: 0.8038 | LR: 0.000031 | Estimated time: 247.34
Train loss on 50 batch: 0.098001
Train loss on 100 batch: 0.128575
Train loss on 150 batch: 0.127902
Train loss on 200 batch: 0.142560
Train loss on 250 batch: 0.148512
Train loss on 300 batch: 0.124197
Train loss on 350 batch: 0.193363
Train loss on 400 batch: 0.130666
Train loss on 450 batch: 0.125526
Train loss on 500 batch: 0.175459
Train loss on 550 batch: 0.118027
Train loss on 600 batch: 0.123996
Train loss on 650 batch: 0.152713
Train loss on 700 batch: 0.148886
: Epoch: 34 | Training Loss: 0.136228 | Val. Loss: 0.245611 | Val. Kappa Score: 0.8052 | LR: 0.000016 | Estimated time: 247.97
Train loss on 50 batch: 0.103110
Train loss on 100 batch: 0.119112
Train loss on 150 batch: 0.142229
Train loss on 200 batch: 0.113094
Train loss on 250 batch: 0.179048
Train loss on 300 batch: 0.100309
Train loss on 350 batch: 0.169538
Train loss on 400 batch: 0.115515
Train loss on 450 batch: 0.137859
Train loss on 500 batch: 0.111765
Train loss on 550 batch: 0.164947
Train loss on 600 batch: 0.117003
Train loss on 650 batch: 0.133790
Train loss on 700 batch: 0.125733
: Epoch: 35 | Training Loss: 0.137855 | Val. Loss: 0.248364 | Val. Kappa Score: 0.8068 | LR: 0.000016 | Estimated time: 247.87
time_estimated: 8790.89
n-epochs: 35
time_estimated: 8790.93
----------------------------------------

Experiment N: 117: 



EXPERIMENT WITH BATCH_SIZE: 4, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.08.20 23:27:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1076d8>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 150
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 117: 



EXPERIMENT WITH BATCH_SIZE: 2, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.08.20 23:28:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d107748>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 150
batch-size: 2
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.909128
Train loss on 100 batch: 1.523180
Train loss on 150 batch: 1.543104
Train loss on 200 batch: 1.662833
Train loss on 250 batch: 1.048772
Train loss on 300 batch: 1.373534
Train loss on 350 batch: 1.014587
Train loss on 400 batch: 1.331108
Train loss on 450 batch: 1.232272
Train loss on 500 batch: 1.024969
Train loss on 550 batch: 0.959362
Train loss on 600 batch: 1.220074
Train loss on 650 batch: 1.208573
Train loss on 700 batch: 1.078958
Train loss on 750 batch: 0.904415
Train loss on 800 batch: 0.935908
Train loss on 850 batch: 1.237744
Train loss on 900 batch: 1.028419
Train loss on 950 batch: 0.592082
Train loss on 1000 batch: 0.531915
Train loss on 1050 batch: 0.813217
Train loss on 1100 batch: 0.752359
Train loss on 1150 batch: 0.489792
Train loss on 1200 batch: 0.714784
Train loss on 1250 batch: 0.490164
Train loss on 1300 batch: 0.688990
Train loss on 1350 batch: 0.746954
Train loss on 1400 batch: 0.835390
Train loss on 1450 batch: 0.584583
best-train-loss: 1.011771
best-valid-loss: 0.613028
best-kappa: 0.4417
: Epoch: 1 | Training Loss: 1.011771 | Val. Loss: 0.613028 | Val. Kappa Score: 0.4417 | LR: 0.001000 | Estimated time: 418.36
Train loss on 50 batch: 0.626560
Train loss on 100 batch: 0.717463
Train loss on 150 batch: 0.477219
Train loss on 200 batch: 0.619066
Train loss on 250 batch: 0.602128
Train loss on 300 batch: 0.589446
Train loss on 350 batch: 0.665668
Train loss on 400 batch: 0.568912
Train loss on 450 batch: 0.989337
Train loss on 500 batch: 0.786681
Train loss on 550 batch: 0.564598
Train loss on 600 batch: 0.570329
Train loss on 650 batch: 0.469696
Train loss on 700 batch: 0.773348
Train loss on 750 batch: 0.475282
Train loss on 800 batch: 0.415427
Train loss on 850 batch: 0.591686
Train loss on 900 batch: 0.880874
Train loss on 950 batch: 0.514903
Train loss on 1000 batch: 0.492397
Train loss on 1050 batch: 0.446963
Train loss on 1100 batch: 0.463309
Train loss on 1150 batch: 0.432251
Train loss on 1200 batch: 0.626312
Train loss on 1250 batch: 0.758261
Train loss on 1300 batch: 0.580083
Train loss on 1350 batch: 0.749579
Train loss on 1400 batch: 0.908585
Train loss on 1450 batch: 0.614783
: Epoch: 2 | Training Loss: 0.616854 | Val. Loss: 0.674285 | Val. Kappa Score: 0.4788 | LR: 0.001000 | Estimated time: 412.71
Train loss on 50 batch: 0.363648
Train loss on 100 batch: 0.584992
Train loss on 150 batch: 0.495876
Train loss on 200 batch: 0.727895
Train loss on 250 batch: 0.570405
Train loss on 300 batch: 0.427410
Train loss on 350 batch: 0.493465
Train loss on 400 batch: 0.725495
Train loss on 450 batch: 0.223382
Train loss on 500 batch: 0.564031
Train loss on 550 batch: 0.748853
Train loss on 600 batch: 0.600938
Train loss on 650 batch: 0.829280
Train loss on 700 batch: 0.569506
Train loss on 750 batch: 0.533748
Train loss on 800 batch: 0.717444
Train loss on 850 batch: 0.389517
Train loss on 900 batch: 0.578592
Train loss on 950 batch: 0.566717
Train loss on 1000 batch: 0.552166
Train loss on 1050 batch: 0.739177
Train loss on 1100 batch: 0.556022
Train loss on 1150 batch: 0.425208
Train loss on 1200 batch: 0.628032
Train loss on 1250 batch: 0.569554
Train loss on 1300 batch: 0.572757
Train loss on 1350 batch: 0.417468
Train loss on 1400 batch: 0.505703
Train loss on 1450 batch: 0.434370
best-train-loss: 0.552753
best-valid-loss: 0.457757
best-kappa: 0.5267
: Epoch: 3 | Training Loss: 0.552753 | Val. Loss: 0.457757 | Val. Kappa Score: 0.5267 | LR: 0.001000 | Estimated time: 401.18
Train loss on 50 batch: 0.409976
Train loss on 100 batch: 0.660571
Train loss on 150 batch: 0.657619
Train loss on 200 batch: 0.493241
Train loss on 250 batch: 0.545754
Train loss on 300 batch: 0.611269
Train loss on 350 batch: 0.478952
Train loss on 400 batch: 0.524618
Train loss on 450 batch: 0.533884
Train loss on 500 batch: 0.407227
Train loss on 550 batch: 0.448301
Train loss on 600 batch: 0.463597
Train loss on 650 batch: 0.408550
Train loss on 700 batch: 0.430271
Train loss on 750 batch: 0.669949
Train loss on 800 batch: 0.522568
Train loss on 850 batch: 0.419077
Train loss on 900 batch: 0.527561
Train loss on 950 batch: 0.467223
Train loss on 1000 batch: 0.580243
Train loss on 1050 batch: 0.723581
Train loss on 1100 batch: 0.426501
Train loss on 1150 batch: 0.601645
Train loss on 1200 batch: 0.597253
Train loss on 1250 batch: 0.526848
Train loss on 1300 batch: 0.517556
Train loss on 1350 batch: 0.472046
Train loss on 1400 batch: 0.449119
Train loss on 1450 batch: 0.554780
: Epoch: 4 | Training Loss: 0.522747 | Val. Loss: 0.736544 | Val. Kappa Score: 0.5304 | LR: 0.001000 | Estimated time: 398.21
Train loss on 50 batch: 0.644784
Train loss on 100 batch: 0.541092
Train loss on 150 batch: 0.459440
Train loss on 200 batch: 0.565595
Train loss on 250 batch: 0.421657
Train loss on 300 batch: 0.384662
Train loss on 350 batch: 0.509977
Train loss on 400 batch: 0.445158
Train loss on 450 batch: 0.496535
Train loss on 500 batch: 0.313436
Train loss on 550 batch: 0.644817
Train loss on 600 batch: 0.498939
Train loss on 650 batch: 0.723217
Train loss on 700 batch: 0.391652
Train loss on 750 batch: 0.561942
Train loss on 800 batch: 0.617390
Train loss on 850 batch: 0.453239
Train loss on 900 batch: 0.443358
Train loss on 950 batch: 0.582279
Train loss on 1000 batch: 0.484700
Train loss on 1050 batch: 0.559365
Train loss on 1100 batch: 0.532661
Train loss on 1150 batch: 0.414264
Train loss on 1200 batch: 0.538530
Train loss on 1250 batch: 0.414803
Train loss on 1300 batch: 0.655594
Train loss on 1350 batch: 0.523383
Train loss on 1400 batch: 0.456988
Train loss on 1450 batch: 0.521865
: Epoch: 5 | Training Loss: 0.510413 | Val. Loss: 0.744226 | Val. Kappa Score: 0.4904 | LR: 0.001000 | Estimated time: 399.21
Train loss on 50 batch: 0.503826
Train loss on 100 batch: 0.940623
Train loss on 150 batch: 0.497879
Train loss on 200 batch: 0.553780
Train loss on 250 batch: 0.405279
Train loss on 300 batch: 0.328117
Train loss on 350 batch: 0.566133
Train loss on 400 batch: 0.487530
Train loss on 450 batch: 0.403168
Train loss on 500 batch: 0.568813
Train loss on 550 batch: 0.592210
Train loss on 600 batch: 0.413935
Train loss on 650 batch: 0.440721
Train loss on 700 batch: 0.492493
Train loss on 750 batch: 0.654906
Train loss on 800 batch: 0.403479
Train loss on 850 batch: 0.414392
Train loss on 900 batch: 0.470550
Train loss on 950 batch: 0.284074
Train loss on 1000 batch: 0.512029
Train loss on 1050 batch: 0.473967
Train loss on 1100 batch: 0.480644
Train loss on 1150 batch: 0.498262
Train loss on 1200 batch: 0.411139
Train loss on 1250 batch: 0.415471
Train loss on 1300 batch: 0.388343
Train loss on 1350 batch: 0.452208
Train loss on 1400 batch: 0.432997
Train loss on 1450 batch: 0.245618
best-train-loss: 0.472298
best-valid-loss: 0.426623
best-kappa: 0.5123
: Epoch: 6 | Training Loss: 0.472298 | Val. Loss: 0.426623 | Val. Kappa Score: 0.5123 | LR: 0.001000 | Estimated time: 403.35
Train loss on 50 batch: 0.493490
Train loss on 100 batch: 0.564441
Train loss on 150 batch: 0.421666
Train loss on 200 batch: 0.411547
Train loss on 250 batch: 0.511457
Train loss on 300 batch: 0.476326
Train loss on 350 batch: 0.453551
Train loss on 400 batch: 0.413661
Train loss on 450 batch: 0.315489
Train loss on 500 batch: 0.337464
Train loss on 550 batch: 0.575251
Train loss on 600 batch: 0.570967
Train loss on 650 batch: 0.416173
Train loss on 700 batch: 0.262130
Train loss on 750 batch: 0.509068
Train loss on 800 batch: 0.741914
Train loss on 850 batch: 0.487338
Train loss on 900 batch: 0.636817
Train loss on 950 batch: 0.459663
Train loss on 1000 batch: 0.362698
Train loss on 1050 batch: 0.382756
Train loss on 1100 batch: 0.568468
Train loss on 1150 batch: 0.414022
Train loss on 1200 batch: 0.628559
Train loss on 1250 batch: 0.521289
Train loss on 1300 batch: 0.531315
Train loss on 1350 batch: 0.467364
Train loss on 1400 batch: 0.501971
Train loss on 1450 batch: 0.357124
: Epoch: 7 | Training Loss: 0.472391 | Val. Loss: 0.573806 | Val. Kappa Score: 0.5090 | LR: 0.001000 | Estimated time: 399.31
Train loss on 50 batch: 0.354686
Train loss on 100 batch: 0.644533
Train loss on 150 batch: 0.479381
Train loss on 200 batch: 0.421317
Train loss on 250 batch: 0.570431
Train loss on 300 batch: 0.358668
Train loss on 350 batch: 0.574421
Train loss on 400 batch: 0.445729
Train loss on 450 batch: 0.508576
Train loss on 500 batch: 0.671388
Train loss on 550 batch: 0.647592
Train loss on 600 batch: 0.751606
Train loss on 650 batch: 0.532626
Train loss on 700 batch: 0.391916
Train loss on 750 batch: 0.331119
Train loss on 800 batch: 0.527750
Train loss on 850 batch: 0.536307
Train loss on 900 batch: 0.369425
Train loss on 950 batch: 0.350354
Train loss on 1000 batch: 0.471484
Train loss on 1050 batch: 0.462638
Train loss on 1100 batch: 0.518538
Train loss on 1150 batch: 0.328924
Train loss on 1200 batch: 0.347141
Train loss on 1250 batch: 0.286242
Train loss on 1300 batch: 0.363269
Train loss on 1350 batch: 0.351582
Train loss on 1400 batch: 0.774308
Train loss on 1450 batch: 0.353233
best-train-loss: 0.475491
best-valid-loss: 0.411377
best-kappa: 0.5202
: Epoch: 8 | Training Loss: 0.475491 | Val. Loss: 0.411377 | Val. Kappa Score: 0.5202 | LR: 0.001000 | Estimated time: 398.27
Train loss on 50 batch: 0.599429
Train loss on 100 batch: 0.450314
Train loss on 150 batch: 0.627762
Train loss on 200 batch: 0.340536
Train loss on 250 batch: 0.337896
Train loss on 300 batch: 0.312727
Train loss on 350 batch: 0.539337
Train loss on 400 batch: 0.461406
Train loss on 450 batch: 0.465012
Train loss on 500 batch: 0.441360
Train loss on 550 batch: 0.428502
Train loss on 600 batch: 0.747408
Train loss on 650 batch: 0.460981
Train loss on 700 batch: 0.619308
Train loss on 750 batch: 0.470645
Train loss on 800 batch: 0.315523
Train loss on 850 batch: 0.373066
Train loss on 900 batch: 0.431556
Train loss on 950 batch: 0.323592
Train loss on 1000 batch: 0.429577
Train loss on 1050 batch: 0.409581
Train loss on 1100 batch: 0.471816
Train loss on 1150 batch: 0.402120
Train loss on 1200 batch: 0.753303
Train loss on 1250 batch: 0.371488
Train loss on 1300 batch: 0.423901
Train loss on 1350 batch: 0.455068
Train loss on 1400 batch: 0.409412
Train loss on 1450 batch: 0.316958
: Epoch: 9 | Training Loss: 0.460786 | Val. Loss: 0.551100 | Val. Kappa Score: 0.5262 | LR: 0.001000 | Estimated time: 397.89
Train loss on 50 batch: 0.429982
Train loss on 100 batch: 0.369162
Train loss on 150 batch: 0.333882
Train loss on 200 batch: 0.398887
Train loss on 250 batch: 0.439170
Train loss on 300 batch: 0.498175
Train loss on 350 batch: 0.505744
Train loss on 400 batch: 0.343514
Train loss on 450 batch: 0.347949
Train loss on 500 batch: 0.462147
Train loss on 550 batch: 0.455362
Train loss on 600 batch: 0.600326
Train loss on 650 batch: 0.402791
Train loss on 700 batch: 0.588285
Train loss on 750 batch: 0.415576
Train loss on 800 batch: 0.312999
Train loss on 850 batch: 0.360593
Train loss on 900 batch: 0.471679
Train loss on 950 batch: 0.289178
Train loss on 1000 batch: 0.378145
Train loss on 1050 batch: 0.423198
Train loss on 1100 batch: 0.375624
Train loss on 1150 batch: 0.415963
Train loss on 1200 batch: 0.571315
Train loss on 1250 batch: 0.555104
Train loss on 1300 batch: 0.456880
Train loss on 1350 batch: 0.418150
Train loss on 1400 batch: 0.417566
Train loss on 1450 batch: 0.435945
: Epoch: 10 | Training Loss: 0.430278 | Val. Loss: 0.494935 | Val. Kappa Score: 0.5356 | LR: 0.001000 | Estimated time: 399.08
Train loss on 50 batch: 0.560000
Train loss on 100 batch: 0.486335
Train loss on 150 batch: 0.454788
Train loss on 200 batch: 0.306202
Train loss on 250 batch: 0.353796
Train loss on 300 batch: 0.248235
Train loss on 350 batch: 0.363449
Train loss on 400 batch: 0.432151
Train loss on 450 batch: 0.484717
Train loss on 500 batch: 0.456863
Train loss on 550 batch: 0.372986
Train loss on 600 batch: 0.334890
Train loss on 650 batch: 0.413704
Train loss on 700 batch: 0.386629
Train loss on 750 batch: 0.392237
Train loss on 800 batch: 0.499553
Train loss on 850 batch: 0.560686
Train loss on 900 batch: 0.351927
Train loss on 950 batch: 0.545243
Train loss on 1000 batch: 0.350808
Train loss on 1050 batch: 0.438891
Train loss on 1100 batch: 0.349023
Train loss on 1150 batch: 0.285129
Train loss on 1200 batch: 0.564788
Train loss on 1250 batch: 0.431870
Train loss on 1300 batch: 0.361005
Train loss on 1350 batch: 0.367818
Train loss on 1400 batch: 0.320909
Train loss on 1450 batch: 0.440127
: Epoch: 11 | Training Loss: 0.416903 | Val. Loss: 0.422343 | Val. Kappa Score: 0.5420 | LR: 0.000500 | Estimated time: 398.59
Train loss on 50 batch: 0.306691
Train loss on 100 batch: 0.437354
Train loss on 150 batch: 0.302927
Train loss on 200 batch: 0.250043
Train loss on 250 batch: 0.397103
Train loss on 300 batch: 0.320158
Train loss on 350 batch: 0.516781
Train loss on 400 batch: 0.319191
Train loss on 450 batch: 0.373324
Train loss on 500 batch: 0.269637
Train loss on 550 batch: 0.315708
Train loss on 600 batch: 0.336928
Train loss on 650 batch: 0.395024
Train loss on 700 batch: 0.220099
Train loss on 750 batch: 0.287947
Train loss on 800 batch: 0.324355
Train loss on 850 batch: 0.479381
Train loss on 900 batch: 0.462992
Train loss on 950 batch: 0.411562
Train loss on 1000 batch: 0.336195
Train loss on 1050 batch: 0.299035
Train loss on 1100 batch: 0.294817
Train loss on 1150 batch: 0.503091
Train loss on 1200 batch: 0.292793
Train loss on 1250 batch: 0.281321
Train loss on 1300 batch: 0.423865
Train loss on 1350 batch: 0.559274
Train loss on 1400 batch: 0.226575
Train loss on 1450 batch: 0.308527
best-train-loss: 0.361194
best-valid-loss: 0.368051
best-kappa: 0.5493
: Epoch: 12 | Training Loss: 0.361194 | Val. Loss: 0.368051 | Val. Kappa Score: 0.5493 | LR: 0.000500 | Estimated time: 397.21
Train loss on 50 batch: 0.323911
Train loss on 100 batch: 0.391366
Train loss on 150 batch: 0.318951
Train loss on 200 batch: 0.296336
Train loss on 250 batch: 0.339948
Train loss on 300 batch: 0.364213
Train loss on 350 batch: 0.257641
Train loss on 400 batch: 0.382873
Train loss on 450 batch: 0.328714
Train loss on 500 batch: 0.501885
Train loss on 550 batch: 0.377235
Train loss on 600 batch: 0.299005
Train loss on 650 batch: 0.309521
Train loss on 700 batch: 0.479490
Train loss on 750 batch: 0.217025
Train loss on 800 batch: 0.370552
Train loss on 850 batch: 0.294407
Train loss on 900 batch: 0.473296
Train loss on 950 batch: 0.311389
Train loss on 1000 batch: 0.403624
Train loss on 1050 batch: 0.296036
Train loss on 1100 batch: 0.294329
Train loss on 1150 batch: 0.448086
Train loss on 1200 batch: 0.345283
Train loss on 1250 batch: 0.336516
Train loss on 1300 batch: 0.201325
Train loss on 1350 batch: 0.460476
Train loss on 1400 batch: 0.286155
Train loss on 1450 batch: 0.323958
: Epoch: 13 | Training Loss: 0.340738 | Val. Loss: 0.465388 | Val. Kappa Score: 0.5552 | LR: 0.000500 | Estimated time: 398.07
Train loss on 50 batch: 0.278624
Train loss on 100 batch: 0.334602
Train loss on 150 batch: 0.323234
Train loss on 200 batch: 0.329223
Train loss on 250 batch: 0.289504
Train loss on 300 batch: 0.332409
Train loss on 350 batch: 0.182750
Train loss on 400 batch: 0.347328
Train loss on 450 batch: 0.235615
Train loss on 500 batch: 0.485201
Train loss on 550 batch: 0.253480
Train loss on 600 batch: 0.154059
Train loss on 650 batch: 0.297138
Train loss on 700 batch: 0.343023
Train loss on 750 batch: 0.319106
Train loss on 800 batch: 0.305110
Train loss on 850 batch: 0.336880
Train loss on 900 batch: 0.271723
Train loss on 950 batch: 0.474138
Train loss on 1000 batch: 0.491820
Train loss on 1050 batch: 0.256188
Train loss on 1100 batch: 0.282180
Train loss on 1150 batch: 0.344835
Train loss on 1200 batch: 0.360036
Train loss on 1250 batch: 0.290410
Train loss on 1300 batch: 0.176653
Train loss on 1350 batch: 0.296649
Train loss on 1400 batch: 0.403460
Train loss on 1450 batch: 0.585295
: Epoch: 14 | Training Loss: 0.320293 | Val. Loss: 0.417421 | Val. Kappa Score: 0.5565 | LR: 0.000500 | Estimated time: 398.79
Train loss on 50 batch: 0.169364
Train loss on 100 batch: 0.417278
Train loss on 150 batch: 0.344169
Train loss on 200 batch: 0.518157
Train loss on 250 batch: 0.290792
Train loss on 300 batch: 0.200638
Train loss on 350 batch: 0.389937
Train loss on 400 batch: 0.240487
Train loss on 450 batch: 0.314904
Train loss on 500 batch: 0.276132
Train loss on 550 batch: 0.296297
Train loss on 600 batch: 0.338702
Train loss on 650 batch: 0.356395
Train loss on 700 batch: 0.342996
Train loss on 750 batch: 0.290492
Train loss on 800 batch: 0.239047
Train loss on 850 batch: 0.289037
Train loss on 900 batch: 0.393724
Train loss on 950 batch: 0.267184
Train loss on 1000 batch: 0.316438
Train loss on 1050 batch: 0.256600
Train loss on 1100 batch: 0.303197
Train loss on 1150 batch: 0.268582
Train loss on 1200 batch: 0.293475
Train loss on 1250 batch: 0.371948
Train loss on 1300 batch: 0.218833
Train loss on 1350 batch: 0.478501
Train loss on 1400 batch: 0.260215
Train loss on 1450 batch: 0.257922
: Epoch: 15 | Training Loss: 0.306299 | Val. Loss: 0.411630 | Val. Kappa Score: 0.5638 | LR: 0.000250 | Estimated time: 400.48
Train loss on 50 batch: 0.303501
Train loss on 100 batch: 0.235469
Train loss on 150 batch: 0.295717
Train loss on 200 batch: 0.398685
Train loss on 250 batch: 0.305887
Train loss on 300 batch: 0.241303
Train loss on 350 batch: 0.377963
Train loss on 400 batch: 0.246803
Train loss on 450 batch: 0.367402
Train loss on 500 batch: 0.237035
Train loss on 550 batch: 0.263864
Train loss on 600 batch: 0.261131
Train loss on 650 batch: 0.355317
Train loss on 700 batch: 0.235830
Train loss on 750 batch: 0.332007
Train loss on 800 batch: 0.216496
Train loss on 850 batch: 0.278739
Train loss on 900 batch: 0.255695
Train loss on 950 batch: 0.347769
Train loss on 1000 batch: 0.203470
Train loss on 1050 batch: 0.227557
Train loss on 1100 batch: 0.401999
Train loss on 1150 batch: 0.290519
Train loss on 1200 batch: 0.373821
Train loss on 1250 batch: 0.321295
Train loss on 1300 batch: 0.362138
Train loss on 1350 batch: 0.294007
Train loss on 1400 batch: 0.186995
Train loss on 1450 batch: 0.322057
: Epoch: 16 | Training Loss: 0.292042 | Val. Loss: 0.385132 | Val. Kappa Score: 0.5700 | LR: 0.000250 | Estimated time: 399.92
Train loss on 50 batch: 0.444850
Train loss on 100 batch: 0.286962
Train loss on 150 batch: 0.327378
Train loss on 200 batch: 0.230356
Train loss on 250 batch: 0.283576
Train loss on 300 batch: 0.276866
Train loss on 350 batch: 0.273496
Train loss on 400 batch: 0.375976
Train loss on 450 batch: 0.254250
Train loss on 500 batch: 0.329102
Train loss on 550 batch: 0.323398
Train loss on 600 batch: 0.291774
Train loss on 650 batch: 0.313220
Train loss on 700 batch: 0.273776
Train loss on 750 batch: 0.306581
Train loss on 800 batch: 0.171659
Train loss on 850 batch: 0.162035
Train loss on 900 batch: 0.142961
Train loss on 950 batch: 0.374441
Train loss on 1000 batch: 0.271204
Train loss on 1050 batch: 0.240259
Train loss on 1100 batch: 0.305705
Train loss on 1150 batch: 0.145461
Train loss on 1200 batch: 0.336713
Train loss on 1250 batch: 0.366849
Train loss on 1300 batch: 0.230015
Train loss on 1350 batch: 0.259211
Train loss on 1400 batch: 0.213030
Train loss on 1450 batch: 0.299107
: Epoch: 17 | Training Loss: 0.277715 | Val. Loss: 0.371250 | Val. Kappa Score: 0.5741 | LR: 0.000250 | Estimated time: 400.15
Train loss on 50 batch: 0.341224
Train loss on 100 batch: 0.226613
Train loss on 150 batch: 0.260888
Train loss on 200 batch: 0.366599
Train loss on 250 batch: 0.278252
Train loss on 300 batch: 0.244770
Train loss on 350 batch: 0.409002
Train loss on 400 batch: 0.198074
Train loss on 450 batch: 0.204815
Train loss on 500 batch: 0.297343
Train loss on 550 batch: 0.280665
Train loss on 600 batch: 0.273820
Train loss on 650 batch: 0.311000
Train loss on 700 batch: 0.171423
Train loss on 750 batch: 0.280513
Train loss on 800 batch: 0.170070
Train loss on 850 batch: 0.312916
Train loss on 900 batch: 0.268343
Train loss on 950 batch: 0.244506
Train loss on 1000 batch: 0.433038
Train loss on 1050 batch: 0.271203
Train loss on 1100 batch: 0.254584
Train loss on 1150 batch: 0.277589
Train loss on 1200 batch: 0.248702
Train loss on 1250 batch: 0.238440
Train loss on 1300 batch: 0.305270
Train loss on 1350 batch: 0.223353
Train loss on 1400 batch: 0.335359
Train loss on 1450 batch: 0.233268
best-train-loss: 0.272544
best-valid-loss: 0.359720
best-kappa: 0.5792
: Epoch: 18 | Training Loss: 0.272544 | Val. Loss: 0.359720 | Val. Kappa Score: 0.5792 | LR: 0.000250 | Estimated time: 398.86
Train loss on 50 batch: 0.248969
Train loss on 100 batch: 0.219466
Train loss on 150 batch: 0.301067
Train loss on 200 batch: 0.291130
Train loss on 250 batch: 0.236050
Train loss on 300 batch: 0.209855
Train loss on 350 batch: 0.165421
Train loss on 400 batch: 0.167829
Train loss on 450 batch: 0.224306
Train loss on 500 batch: 0.329951
Train loss on 550 batch: 0.370886
Train loss on 600 batch: 0.246990
Train loss on 650 batch: 0.232337
Train loss on 700 batch: 0.224501
Train loss on 750 batch: 0.222575
Train loss on 800 batch: 0.314347
Train loss on 850 batch: 0.287301
Train loss on 900 batch: 0.194745
Train loss on 950 batch: 0.153949
Train loss on 1000 batch: 0.322158
Train loss on 1050 batch: 0.321075
Train loss on 1100 batch: 0.363616
Train loss on 1150 batch: 0.307427
Train loss on 1200 batch: 0.411685
Train loss on 1250 batch: 0.357769
Train loss on 1300 batch: 0.255097
Train loss on 1350 batch: 0.268251
Train loss on 1400 batch: 0.320540
Train loss on 1450 batch: 0.290806
: Epoch: 19 | Training Loss: 0.271680 | Val. Loss: 0.432211 | Val. Kappa Score: 0.5839 | LR: 0.000250 | Estimated time: 400.19
Train loss on 50 batch: 0.259270
Train loss on 100 batch: 0.154907
Train loss on 150 batch: 0.302727
Train loss on 200 batch: 0.176774
Train loss on 250 batch: 0.323086
Train loss on 300 batch: 0.253763
Train loss on 350 batch: 0.328370
Train loss on 400 batch: 0.257765
Train loss on 450 batch: 0.251225
Train loss on 500 batch: 0.246508
Train loss on 550 batch: 0.228404
Train loss on 600 batch: 0.379935
Train loss on 650 batch: 0.208407
Train loss on 700 batch: 0.498574
Train loss on 750 batch: 0.381680
Train loss on 800 batch: 0.213861
Train loss on 850 batch: 0.379489
Train loss on 900 batch: 0.249645
Train loss on 950 batch: 0.186578
Train loss on 1000 batch: 0.151488
Train loss on 1050 batch: 0.155886
Train loss on 1100 batch: 0.238149
Train loss on 1150 batch: 0.177355
Train loss on 1200 batch: 0.359756
Train loss on 1250 batch: 0.222084
Train loss on 1300 batch: 0.274143
Train loss on 1350 batch: 0.145040
Train loss on 1400 batch: 0.273968
Train loss on 1450 batch: 0.233316
best-train-loss: 0.256124
best-valid-loss: 0.357202
best-kappa: 0.5878
: Epoch: 20 | Training Loss: 0.256124 | Val. Loss: 0.357202 | Val. Kappa Score: 0.5878 | LR: 0.000250 | Estimated time: 398.62
Train loss on 50 batch: 0.328538
Train loss on 100 batch: 0.190661
Train loss on 150 batch: 0.334743
Train loss on 200 batch: 0.259030
Train loss on 250 batch: 0.253224
Train loss on 300 batch: 0.235786
Train loss on 350 batch: 0.299450
Train loss on 400 batch: 0.264797
Train loss on 450 batch: 0.371398
Train loss on 500 batch: 0.225408
Train loss on 550 batch: 0.114880
Train loss on 600 batch: 0.247228
Train loss on 650 batch: 0.274357
Train loss on 700 batch: 0.310692
Train loss on 750 batch: 0.268287
Train loss on 800 batch: 0.261700
Train loss on 850 batch: 0.231924
Train loss on 900 batch: 0.195152
Train loss on 950 batch: 0.321196
Train loss on 1000 batch: 0.395691
Train loss on 1050 batch: 0.205259
Train loss on 1100 batch: 0.313961
Train loss on 1150 batch: 0.224429
Train loss on 1200 batch: 0.208776
Train loss on 1250 batch: 0.258975
Train loss on 1300 batch: 0.322666
Train loss on 1350 batch: 0.290554
Train loss on 1400 batch: 0.265954
Train loss on 1450 batch: 0.293254
best-train-loss: 0.265694
best-valid-loss: 0.351910
best-kappa: 0.5924
: Epoch: 21 | Training Loss: 0.265694 | Val. Loss: 0.351910 | Val. Kappa Score: 0.5924 | LR: 0.000250 | Estimated time: 400.21
Train loss on 50 batch: 0.254145
Train loss on 100 batch: 0.250248
Train loss on 150 batch: 0.392029
Train loss on 200 batch: 0.210402
Train loss on 250 batch: 0.299199
Train loss on 300 batch: 0.249352
Train loss on 350 batch: 0.308173
Train loss on 400 batch: 0.147988
Train loss on 450 batch: 0.272558
Train loss on 500 batch: 0.326623
Train loss on 550 batch: 0.160022
Train loss on 600 batch: 0.247847
Train loss on 650 batch: 0.254278
Train loss on 700 batch: 0.367730
Train loss on 750 batch: 0.214167
Train loss on 800 batch: 0.251553
Train loss on 850 batch: 0.301028
Train loss on 900 batch: 0.274625
Train loss on 950 batch: 0.271913
Train loss on 1000 batch: 0.299652
Train loss on 1050 batch: 0.215200
Train loss on 1100 batch: 0.299889
Train loss on 1150 batch: 0.387660
Train loss on 1200 batch: 0.236014
Train loss on 1250 batch: 0.199621
Train loss on 1300 batch: 0.251715
Train loss on 1350 batch: 0.299437
Train loss on 1400 batch: 0.224310
Train loss on 1450 batch: 0.256674
: Epoch: 22 | Training Loss: 0.262083 | Val. Loss: 0.359284 | Val. Kappa Score: 0.5950 | LR: 0.000250 | Estimated time: 398.55
Train loss on 50 batch: 0.113502
Train loss on 100 batch: 0.181282
Train loss on 150 batch: 0.206895
Train loss on 200 batch: 0.354372
Train loss on 250 batch: 0.259509
Train loss on 300 batch: 0.320502
Train loss on 350 batch: 0.231638
Train loss on 400 batch: 0.272851
Train loss on 450 batch: 0.263552
Train loss on 500 batch: 0.286652
Train loss on 550 batch: 0.280570
Train loss on 600 batch: 0.272596
Train loss on 650 batch: 0.290063
Train loss on 700 batch: 0.311495
Train loss on 750 batch: 0.169105
Train loss on 800 batch: 0.263851
Train loss on 850 batch: 0.213285
Train loss on 900 batch: 0.246755
Train loss on 950 batch: 0.274513
Train loss on 1000 batch: 0.285654
Train loss on 1050 batch: 0.210466
Train loss on 1100 batch: 0.447449
Train loss on 1150 batch: 0.256271
Train loss on 1200 batch: 0.192256
Train loss on 1250 batch: 0.215812
Train loss on 1300 batch: 0.267570
Train loss on 1350 batch: 0.265198
Train loss on 1400 batch: 0.363195
Train loss on 1450 batch: 0.161606
: Epoch: 23 | Training Loss: 0.253120 | Val. Loss: 0.387361 | Val. Kappa Score: 0.5985 | LR: 0.000250 | Estimated time: 400.35
Train loss on 50 batch: 0.325185
Train loss on 100 batch: 0.188784
Train loss on 150 batch: 0.309098
Train loss on 200 batch: 0.173327
Train loss on 250 batch: 0.279618
Train loss on 300 batch: 0.220747
Train loss on 350 batch: 0.267575
Train loss on 400 batch: 0.198091
Train loss on 450 batch: 0.350530
Train loss on 500 batch: 0.223089
Train loss on 550 batch: 0.280647
Train loss on 600 batch: 0.259658
Train loss on 650 batch: 0.211700
Train loss on 700 batch: 0.132648
Train loss on 750 batch: 0.226683
Train loss on 800 batch: 0.354320
Train loss on 850 batch: 0.163961
Train loss on 900 batch: 0.300718
Train loss on 950 batch: 0.392330
Train loss on 1000 batch: 0.281929
Train loss on 1050 batch: 0.197341
Train loss on 1100 batch: 0.236792
Train loss on 1150 batch: 0.172262
Train loss on 1200 batch: 0.352765
Train loss on 1250 batch: 0.210381
Train loss on 1300 batch: 0.259274
Train loss on 1350 batch: 0.356378
Train loss on 1400 batch: 0.294388
Train loss on 1450 batch: 0.170312
: Epoch: 24 | Training Loss: 0.255504 | Val. Loss: 0.358405 | Val. Kappa Score: 0.6005 | LR: 0.000125 | Estimated time: 398.78
Train loss on 50 batch: 0.181612
Train loss on 100 batch: 0.337361
Train loss on 150 batch: 0.334431
Train loss on 200 batch: 0.163456
Train loss on 250 batch: 0.128331
Train loss on 300 batch: 0.222047
Train loss on 350 batch: 0.217779
Train loss on 400 batch: 0.214770
Train loss on 450 batch: 0.261135
Train loss on 500 batch: 0.136687
Train loss on 550 batch: 0.197603
Train loss on 600 batch: 0.209146
Train loss on 650 batch: 0.197961
Train loss on 700 batch: 0.244293
Train loss on 750 batch: 0.227523
Train loss on 800 batch: 0.160028
Train loss on 850 batch: 0.279422
Train loss on 900 batch: 0.210346
Train loss on 950 batch: 0.206776
Train loss on 1000 batch: 0.256959
Train loss on 1050 batch: 0.267396
Train loss on 1100 batch: 0.328107
Train loss on 1150 batch: 0.178015
Train loss on 1200 batch: 0.248380
Train loss on 1250 batch: 0.247742
Train loss on 1300 batch: 0.306012
Train loss on 1350 batch: 0.188425
Train loss on 1400 batch: 0.267789
Train loss on 1450 batch: 0.143678
: Epoch: 25 | Training Loss: 0.230990 | Val. Loss: 0.361757 | Val. Kappa Score: 0.6044 | LR: 0.000125 | Estimated time: 398.43
Train loss on 50 batch: 0.288202
Train loss on 100 batch: 0.194906
Train loss on 150 batch: 0.204751
Train loss on 200 batch: 0.289204
Train loss on 250 batch: 0.280736
Train loss on 300 batch: 0.227138
Train loss on 350 batch: 0.160245
Train loss on 400 batch: 0.247428
Train loss on 450 batch: 0.137642
Train loss on 500 batch: 0.194100
Train loss on 550 batch: 0.276578
Train loss on 600 batch: 0.188921
Train loss on 650 batch: 0.144605
Train loss on 700 batch: 0.251085
Train loss on 750 batch: 0.224919
Train loss on 800 batch: 0.251788
Train loss on 850 batch: 0.299129
Train loss on 900 batch: 0.228423
Train loss on 950 batch: 0.211772
Train loss on 1000 batch: 0.353453
Train loss on 1050 batch: 0.164124
Train loss on 1100 batch: 0.251395
Train loss on 1150 batch: 0.177768
Train loss on 1200 batch: 0.409467
Train loss on 1250 batch: 0.187537
Train loss on 1300 batch: 0.233064
Train loss on 1350 batch: 0.240511
Train loss on 1400 batch: 0.186631
Train loss on 1450 batch: 0.271068
: Epoch: 26 | Training Loss: 0.236348 | Val. Loss: 0.366673 | Val. Kappa Score: 0.6073 | LR: 0.000125 | Estimated time: 399.46
Train loss on 50 batch: 0.199407
Train loss on 100 batch: 0.223895
Train loss on 150 batch: 0.157580
Train loss on 200 batch: 0.156971
Train loss on 250 batch: 0.231137
Train loss on 300 batch: 0.212270
Train loss on 350 batch: 0.423716
Train loss on 400 batch: 0.268318
Train loss on 450 batch: 0.229382
Train loss on 500 batch: 0.184169
Train loss on 550 batch: 0.238728
Train loss on 600 batch: 0.335597
Train loss on 650 batch: 0.260119
Train loss on 700 batch: 0.233902
Train loss on 750 batch: 0.160353
Train loss on 800 batch: 0.355015
Train loss on 850 batch: 0.263622
Train loss on 900 batch: 0.266552
Train loss on 950 batch: 0.178924
Train loss on 1000 batch: 0.250690
Train loss on 1050 batch: 0.196009
Train loss on 1100 batch: 0.208318
Train loss on 1150 batch: 0.166601
Train loss on 1200 batch: 0.183202
Train loss on 1250 batch: 0.150828
Train loss on 1300 batch: 0.201050
Train loss on 1350 batch: 0.176396
Train loss on 1400 batch: 0.183590
Train loss on 1450 batch: 0.247690
: Epoch: 27 | Training Loss: 0.220381 | Val. Loss: 0.467940 | Val. Kappa Score: 0.6097 | LR: 0.000063 | Estimated time: 398.48
Train loss on 50 batch: 0.239311
Train loss on 100 batch: 0.335813
Train loss on 150 batch: 0.234528
Train loss on 200 batch: 0.211176
Train loss on 250 batch: 0.224516
Train loss on 300 batch: 0.271314
Train loss on 350 batch: 0.188406
Train loss on 400 batch: 0.237044
Train loss on 450 batch: 0.171410
Train loss on 500 batch: 0.111989
Train loss on 550 batch: 0.267529
Train loss on 600 batch: 0.166105
Train loss on 650 batch: 0.159314
Train loss on 700 batch: 0.296820
Train loss on 750 batch: 0.304266
Train loss on 800 batch: 0.179485
Train loss on 850 batch: 0.177617
Train loss on 900 batch: 0.277568
Train loss on 950 batch: 0.365756
Train loss on 1000 batch: 0.312332
Train loss on 1050 batch: 0.155676
Train loss on 1100 batch: 0.102178
Train loss on 1150 batch: 0.160937
Train loss on 1200 batch: 0.162530
Train loss on 1250 batch: 0.286797
Train loss on 1300 batch: 0.268487
Train loss on 1350 batch: 0.205248
Train loss on 1400 batch: 0.183334
Train loss on 1450 batch: 0.176793
: Epoch: 28 | Training Loss: 0.218592 | Val. Loss: 0.374552 | Val. Kappa Score: 0.6118 | LR: 0.000063 | Estimated time: 397.78
Train loss on 50 batch: 0.318968
Train loss on 100 batch: 0.193894
Train loss on 150 batch: 0.165278
Train loss on 200 batch: 0.162758
Train loss on 250 batch: 0.174278
Train loss on 300 batch: 0.182566
Train loss on 350 batch: 0.133773
Train loss on 400 batch: 0.128091
Train loss on 450 batch: 0.148506
Train loss on 500 batch: 0.182495
Train loss on 550 batch: 0.231374
Train loss on 600 batch: 0.317671
Train loss on 650 batch: 0.266081
Train loss on 700 batch: 0.187649
Train loss on 750 batch: 0.234831
Train loss on 800 batch: 0.236614
Train loss on 850 batch: 0.253985
Train loss on 900 batch: 0.276258
Train loss on 950 batch: 0.306302
Train loss on 1000 batch: 0.169836
Train loss on 1050 batch: 0.159189
Train loss on 1100 batch: 0.158273
Train loss on 1150 batch: 0.253695
Train loss on 1200 batch: 0.279229
Train loss on 1250 batch: 0.240280
Train loss on 1300 batch: 0.234019
Train loss on 1350 batch: 0.252532
Train loss on 1400 batch: 0.228985
Train loss on 1450 batch: 0.189129
: Epoch: 29 | Training Loss: 0.216589 | Val. Loss: 0.412531 | Val. Kappa Score: 0.6137 | LR: 0.000063 | Estimated time: 397.79
Train loss on 50 batch: 0.248999
Train loss on 100 batch: 0.190707
Train loss on 150 batch: 0.186021
Train loss on 200 batch: 0.213806
Train loss on 250 batch: 0.219481
Train loss on 300 batch: 0.213043
Train loss on 350 batch: 0.217406
Train loss on 400 batch: 0.236975
Train loss on 450 batch: 0.261398
Train loss on 500 batch: 0.228676
Train loss on 550 batch: 0.149271
Train loss on 600 batch: 0.194398
Train loss on 650 batch: 0.180300
Train loss on 700 batch: 0.210171
Train loss on 750 batch: 0.199551
Train loss on 800 batch: 0.284875
Train loss on 850 batch: 0.168155
Train loss on 900 batch: 0.292541
Train loss on 950 batch: 0.271290
Train loss on 1000 batch: 0.262693
Train loss on 1050 batch: 0.241594
Train loss on 1100 batch: 0.131036
Train loss on 1150 batch: 0.180031
Train loss on 1200 batch: 0.196393
Train loss on 1250 batch: 0.235689
Train loss on 1300 batch: 0.361277
Train loss on 1350 batch: 0.151199
Train loss on 1400 batch: 0.126922
Train loss on 1450 batch: 0.135430
: Epoch: 30 | Training Loss: 0.215814 | Val. Loss: 0.396577 | Val. Kappa Score: 0.6146 | LR: 0.000031 | Estimated time: 399.26
Train loss on 50 batch: 0.167338
Train loss on 100 batch: 0.176420
Train loss on 150 batch: 0.174595
Train loss on 200 batch: 0.132490
Train loss on 250 batch: 0.266355
Train loss on 300 batch: 0.179748
Train loss on 350 batch: 0.203695
Train loss on 400 batch: 0.258900
Train loss on 450 batch: 0.199637
Train loss on 500 batch: 0.218868
Train loss on 550 batch: 0.242604
Train loss on 600 batch: 0.323034
Train loss on 650 batch: 0.204891
Train loss on 700 batch: 0.240330
Train loss on 750 batch: 0.193735
Train loss on 800 batch: 0.271235
Train loss on 850 batch: 0.192351
Train loss on 900 batch: 0.211930
Train loss on 950 batch: 0.266989
Train loss on 1000 batch: 0.215829
Train loss on 1050 batch: 0.266788
Train loss on 1100 batch: 0.186390
Train loss on 1150 batch: 0.180491
Train loss on 1200 batch: 0.136361
Train loss on 1250 batch: 0.209927
Train loss on 1300 batch: 0.210407
Train loss on 1350 batch: 0.269733
Train loss on 1400 batch: 0.277663
Train loss on 1450 batch: 0.199252
: Epoch: 31 | Training Loss: 0.218012 | Val. Loss: 0.456636 | Val. Kappa Score: 0.6164 | LR: 0.000031 | Estimated time: 397.45
time_estimated: 12406.76
n-epochs: 31
time_estimated: 12406.79
----------------------------------------

Experiment N: 118: 



EXPERIMENT WITH BATCH_SIZE: 2, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.08.21 10:41:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb982de0f0>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 150
batch-size: 2
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 118: 



EXPERIMENT WITH BATCH_SIZE: 1, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.08.21 10:42:52
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d107588>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 150
batch-size: 1
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.986368
Train loss on 100 batch: 1.492531
Train loss on 150 batch: 2.179050
Train loss on 200 batch: 2.232654
Train loss on 250 batch: 2.031897
Train loss on 300 batch: 1.669682
Train loss on 350 batch: 2.250385
Train loss on 400 batch: 1.939811
Train loss on 450 batch: 1.658516
Train loss on 500 batch: 1.713971
Train loss on 550 batch: 1.670457
Train loss on 600 batch: 2.232605
Train loss on 650 batch: 1.970615
Train loss on 700 batch: 1.218152
Train loss on 750 batch: 1.738965
Train loss on 800 batch: 2.051961
Train loss on 850 batch: 2.121003
Train loss on 900 batch: 1.890260
Train loss on 950 batch: 1.588560
Train loss on 1000 batch: 1.776982
Train loss on 1050 batch: 1.849595
Train loss on 1100 batch: 1.590289
Train loss on 1150 batch: 2.353702
Train loss on 1200 batch: 2.152961
Train loss on 1250 batch: 2.492648
Train loss on 1300 batch: 1.375626
Train loss on 1350 batch: 1.809667
Train loss on 1400 batch: 2.188781
Train loss on 1450 batch: 1.667614
Train loss on 1500 batch: 2.123113
Train loss on 1550 batch: 2.671761
Train loss on 1600 batch: 1.632697
Train loss on 1650 batch: 1.735912
Train loss on 1700 batch: 1.817245
Train loss on 1750 batch: 1.486623
Train loss on 1800 batch: 1.672495
Train loss on 1850 batch: 1.258216
Train loss on 1900 batch: 1.007551
Train loss on 1950 batch: 0.998019
Train loss on 2000 batch: 1.525364
Train loss on 2050 batch: 1.629959
Train loss on 2100 batch: 1.324864
Train loss on 2150 batch: 1.461952
Train loss on 2200 batch: 0.926118
Train loss on 2250 batch: 0.638242
Train loss on 2300 batch: 1.160952
Train loss on 2350 batch: 1.163952
Train loss on 2400 batch: 1.167800
Train loss on 2450 batch: 0.587209
Train loss on 2500 batch: 1.038767
Train loss on 2550 batch: 1.153327
Train loss on 2600 batch: 1.012474
Train loss on 2650 batch: 1.230632
Train loss on 2700 batch: 1.421482
Train loss on 2750 batch: 1.032811
Train loss on 2800 batch: 1.239515
Train loss on 2850 batch: 1.021564
Train loss on 2900 batch: 0.456603
best-train-loss: 1.585960
best-valid-loss: 16.108005
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.585960 | Val. Loss: 16.108005 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 815.55
Train loss on 50 batch: 1.141096
Train loss on 100 batch: 0.702972
Train loss on 150 batch: 1.225649
Train loss on 200 batch: 0.827511
Train loss on 250 batch: 0.995743
Train loss on 300 batch: 0.475805
Train loss on 350 batch: 0.633735
Train loss on 400 batch: 0.910555
Train loss on 450 batch: 1.406076
Train loss on 500 batch: 1.486416
Train loss on 550 batch: 1.258384
Train loss on 600 batch: 0.667781
Train loss on 650 batch: 1.303484
Train loss on 700 batch: 0.869330
Train loss on 750 batch: 1.092314
Train loss on 800 batch: 1.037320
Train loss on 850 batch: 0.907470
Train loss on 900 batch: 1.442968
Train loss on 950 batch: 1.048871
Train loss on 1000 batch: 1.294029
Train loss on 1050 batch: 0.912366
Train loss on 1100 batch: 0.644594
Train loss on 1150 batch: 0.964794
Train loss on 1200 batch: 0.798465
Train loss on 1250 batch: 0.828895
Train loss on 1300 batch: 0.573158
Train loss on 1350 batch: 1.599197
Train loss on 1400 batch: 1.219071
Train loss on 1450 batch: 0.910843
Train loss on 1500 batch: 0.874240
Train loss on 1550 batch: 0.918150
Train loss on 1600 batch: 0.801152
Train loss on 1650 batch: 0.865756
Train loss on 1700 batch: 1.304318
Train loss on 1750 batch: 1.330779
Train loss on 1800 batch: 1.249691
Train loss on 1850 batch: 0.514489
Train loss on 1900 batch: 0.909407
Train loss on 1950 batch: 0.491145
Train loss on 2000 batch: 0.567083
Train loss on 2050 batch: 0.868586
Train loss on 2100 batch: 0.826891
Train loss on 2150 batch: 1.259140
Train loss on 2200 batch: 0.761810
Train loss on 2250 batch: 0.798988
Train loss on 2300 batch: 0.606325
Train loss on 2350 batch: 0.750291
Train loss on 2400 batch: 0.859554
Train loss on 2450 batch: 0.738851
Train loss on 2500 batch: 0.997253
Train loss on 2550 batch: 0.776216
Train loss on 2600 batch: 1.016078
Train loss on 2650 batch: 1.042565
Train loss on 2700 batch: 0.906125
Train loss on 2750 batch: 1.423995
Train loss on 2800 batch: 0.851886
Train loss on 2850 batch: 0.903003
Train loss on 2900 batch: 0.967511
: Epoch: 2 | Training Loss: 0.959288 | Val. Loss: 707.756686 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 806.20
Train loss on 50 batch: 0.617669
Train loss on 100 batch: 0.661449
Train loss on 150 batch: 0.644045
Train loss on 200 batch: 0.782889
Train loss on 250 batch: 1.071795
Train loss on 300 batch: 0.582225
Train loss on 350 batch: 1.142245
Train loss on 400 batch: 0.975037
Train loss on 450 batch: 0.843952
Train loss on 500 batch: 1.197274
Train loss on 550 batch: 0.458830
Train loss on 600 batch: 0.931177
Train loss on 650 batch: 0.800299
Train loss on 700 batch: 0.796888
Train loss on 750 batch: 0.802244
Train loss on 800 batch: 1.178006
Train loss on 850 batch: 0.528254
Train loss on 900 batch: 0.691828
Train loss on 950 batch: 0.930375
Train loss on 1000 batch: 1.077430
Train loss on 1050 batch: 0.936798
Train loss on 1100 batch: 0.936416
Train loss on 1150 batch: 0.652006
Train loss on 1200 batch: 0.828837
Train loss on 1250 batch: 1.281533
Train loss on 1300 batch: 1.367597
Train loss on 1350 batch: 0.520079
Train loss on 1400 batch: 0.993515
Train loss on 1450 batch: 1.353205
Train loss on 1500 batch: 0.761595
Train loss on 1550 batch: 1.040455
Train loss on 1600 batch: 1.253143
Train loss on 1650 batch: 0.866653
Train loss on 1700 batch: 0.762539
Train loss on 1750 batch: 0.867609
Train loss on 1800 batch: 0.954375
Train loss on 1850 batch: 0.747358
Train loss on 1900 batch: 0.814203
Train loss on 1950 batch: 0.870362
Train loss on 2000 batch: 1.005089
Train loss on 2050 batch: 0.996605
Train loss on 2100 batch: 0.909927
Train loss on 2150 batch: 0.773833
Train loss on 2200 batch: 0.734777
Train loss on 2250 batch: 1.157263
Train loss on 2300 batch: 0.937853
Train loss on 2350 batch: 1.037106
Train loss on 2400 batch: 1.030739
Train loss on 2450 batch: 1.288969
Train loss on 2500 batch: 0.580062
Train loss on 2550 batch: 0.862481
Train loss on 2600 batch: 0.887320
Train loss on 2650 batch: 0.688268
Train loss on 2700 batch: 0.894573
Train loss on 2750 batch: 0.767861
Train loss on 2800 batch: 0.646760
Train loss on 2850 batch: 0.818177
Train loss on 2900 batch: 0.651283
best-train-loss: 0.883816
best-valid-loss: 5.826838
best-kappa: 0.0000
: Epoch: 3 | Training Loss: 0.883816 | Val. Loss: 5.826838 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 808.78
Train loss on 50 batch: 1.028636
Train loss on 100 batch: 1.264126
Train loss on 150 batch: 0.943598
Train loss on 200 batch: 1.110899
Train loss on 250 batch: 0.555004
Train loss on 300 batch: 0.808091
Train loss on 350 batch: 0.881739
Train loss on 400 batch: 0.961716
Train loss on 450 batch: 0.654438
Train loss on 500 batch: 1.069265
Train loss on 550 batch: 0.671888
Train loss on 600 batch: 0.790966
Train loss on 650 batch: 0.810365
Train loss on 700 batch: 0.840539
Train loss on 750 batch: 1.011371
Train loss on 800 batch: 0.857201
Train loss on 850 batch: 1.150009
Train loss on 900 batch: 0.807059
Train loss on 950 batch: 0.374197
Train loss on 1000 batch: 0.638833
Train loss on 1050 batch: 0.391899
Train loss on 1100 batch: 0.926145
Train loss on 1150 batch: 1.183272
Train loss on 1200 batch: 0.558329
Train loss on 1250 batch: 1.081656
Train loss on 1300 batch: 0.768092
Train loss on 1350 batch: 0.511951
Train loss on 1400 batch: 1.045943
Train loss on 1450 batch: 1.077926
Train loss on 1500 batch: 0.807798
Train loss on 1550 batch: 0.805291
Train loss on 1600 batch: 1.099446
Train loss on 1650 batch: 0.636482
Train loss on 1700 batch: 0.499716
Train loss on 1750 batch: 0.609837
Train loss on 1800 batch: 0.858494
Train loss on 1850 batch: 0.501200
Train loss on 1900 batch: 1.082335
Train loss on 1950 batch: 1.007198
Train loss on 2000 batch: 0.834330
Train loss on 2050 batch: 0.444386
Train loss on 2100 batch: 1.207145
Train loss on 2150 batch: 0.749277
Train loss on 2200 batch: 0.807851
Train loss on 2250 batch: 0.767049
Train loss on 2300 batch: 1.178039
Train loss on 2350 batch: 0.705280
Train loss on 2400 batch: 1.128276
Train loss on 2450 batch: 1.028434
Train loss on 2500 batch: 0.776244
Train loss on 2550 batch: 0.542452
Train loss on 2600 batch: 1.160167
Train loss on 2650 batch: 0.695322
Train loss on 2700 batch: 0.896107
Train loss on 2750 batch: 0.407349
Train loss on 2800 batch: 0.739490
Train loss on 2850 batch: 0.575895
Train loss on 2900 batch: 0.972811
: Epoch: 4 | Training Loss: 0.841044 | Val. Loss: 34.264282 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 806.88
Train loss on 50 batch: 0.721800
Train loss on 100 batch: 0.944883
Train loss on 150 batch: 0.762838
Train loss on 200 batch: 0.630927
Train loss on 250 batch: 1.277337
Train loss on 300 batch: 0.532770
Train loss on 350 batch: 0.667732
Train loss on 400 batch: 1.365014
Train loss on 450 batch: 1.175482
Train loss on 500 batch: 0.883292
Train loss on 550 batch: 0.643662
Train loss on 600 batch: 0.523251
Train loss on 650 batch: 0.490823
Train loss on 700 batch: 0.362407
Train loss on 750 batch: 0.562080
Train loss on 800 batch: 0.898030
Train loss on 850 batch: 0.696415
Train loss on 900 batch: 0.763888
Train loss on 950 batch: 0.595044
Train loss on 1000 batch: 0.486951
Train loss on 1050 batch: 1.977540
Train loss on 1100 batch: 0.626119
Train loss on 1150 batch: 0.676078
Train loss on 1200 batch: 0.694802
Train loss on 1250 batch: 0.871424
Train loss on 1300 batch: 1.072352
Train loss on 1350 batch: 0.698958
Train loss on 1400 batch: 0.627996
Train loss on 1450 batch: 0.685093
Train loss on 1500 batch: 0.779075
Train loss on 1550 batch: 0.848515
Train loss on 1600 batch: 0.768068
Train loss on 1650 batch: 0.762482
Train loss on 1700 batch: 0.436524
Train loss on 1750 batch: 0.340165
Train loss on 1800 batch: 0.801302
Train loss on 1850 batch: 0.511795
Train loss on 1900 batch: 0.922053
Train loss on 1950 batch: 0.559476
Train loss on 2000 batch: 0.669058
Train loss on 2050 batch: 1.157058
Train loss on 2100 batch: 1.017802
Train loss on 2150 batch: 1.223060
Train loss on 2200 batch: 0.841575
Train loss on 2250 batch: 0.654129
Train loss on 2300 batch: 0.864334
Train loss on 2350 batch: 0.744572
Train loss on 2400 batch: 1.266956
Train loss on 2450 batch: 1.129362
Train loss on 2500 batch: 0.859669
Train loss on 2550 batch: 1.368686
Train loss on 2600 batch: 0.827970
Train loss on 2650 batch: 0.600297
Train loss on 2700 batch: 0.721785
Train loss on 2750 batch: 0.837658
Train loss on 2800 batch: 0.705273
Train loss on 2850 batch: 0.885343
Train loss on 2900 batch: 0.501903
: Epoch: 5 | Training Loss: 0.803865 | Val. Loss: 11.253463 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 807.94
Train loss on 50 batch: 0.608988
Train loss on 100 batch: 1.063621
Train loss on 150 batch: 1.060824
Train loss on 200 batch: 0.805858
Train loss on 250 batch: 0.479839
Train loss on 300 batch: 1.158653
Train loss on 350 batch: 0.500081
Train loss on 400 batch: 0.731249
Train loss on 450 batch: 0.869304
Train loss on 500 batch: 0.437054
Train loss on 550 batch: 1.059732
Train loss on 600 batch: 0.622256
Train loss on 650 batch: 0.922837
Train loss on 700 batch: 0.689250
Train loss on 750 batch: 0.854675
Train loss on 800 batch: 0.968570
Train loss on 850 batch: 0.546915
Train loss on 900 batch: 0.775850
Train loss on 950 batch: 0.779808
Train loss on 1000 batch: 1.078376
Train loss on 1050 batch: 0.596118
Train loss on 1100 batch: 0.842937
Train loss on 1150 batch: 0.880932
Train loss on 1200 batch: 0.559614
Train loss on 1250 batch: 0.508235
Train loss on 1300 batch: 0.752019
Train loss on 1350 batch: 0.649942
Train loss on 1400 batch: 0.984010
Train loss on 1450 batch: 0.799413
Train loss on 1500 batch: 1.138484
Train loss on 1550 batch: 0.521659
Train loss on 1600 batch: 0.880361
Train loss on 1650 batch: 0.693787
Train loss on 1700 batch: 0.829750
Train loss on 1750 batch: 0.708091
Train loss on 1800 batch: 0.704422
Train loss on 1850 batch: 0.760620
Train loss on 1900 batch: 0.516540
Train loss on 1950 batch: 0.574416
Train loss on 2000 batch: 0.940561
Train loss on 2050 batch: 0.778148
Train loss on 2100 batch: 0.743410
Train loss on 2150 batch: 0.590503
Train loss on 2200 batch: 0.807621
Train loss on 2250 batch: 0.826879
Train loss on 2300 batch: 0.726058
Train loss on 2350 batch: 0.658484
Train loss on 2400 batch: 1.083076
Train loss on 2450 batch: 1.118074
Train loss on 2500 batch: 0.996764
Train loss on 2550 batch: 0.436581
Train loss on 2600 batch: 0.490454
Train loss on 2650 batch: 0.837732
Train loss on 2700 batch: 0.533909
Train loss on 2750 batch: 0.913530
Train loss on 2800 batch: 0.906046
Train loss on 2850 batch: 0.514778
Train loss on 2900 batch: 0.374528
best-train-loss: 0.759233
best-valid-loss: 5.423826
best-kappa: 0.0000
: Epoch: 6 | Training Loss: 0.759233 | Val. Loss: 5.423826 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 807.60
Train loss on 50 batch: 0.976599
Train loss on 100 batch: 0.941065
Train loss on 150 batch: 1.058884
Train loss on 200 batch: 1.128825
Train loss on 250 batch: 0.700112
Train loss on 300 batch: 0.651728
Train loss on 350 batch: 0.613258
Train loss on 400 batch: 0.653635
Train loss on 450 batch: 0.567999
Train loss on 500 batch: 0.857206
Train loss on 550 batch: 0.581465
Train loss on 600 batch: 0.552012
Train loss on 650 batch: 0.817491
Train loss on 700 batch: 0.851757
Train loss on 750 batch: 0.419330
Train loss on 800 batch: 0.655332
Train loss on 850 batch: 0.521804
Train loss on 900 batch: 0.719293
Train loss on 950 batch: 0.726199
Train loss on 1000 batch: 0.713991
Train loss on 1050 batch: 0.923573
Train loss on 1100 batch: 0.523549
Train loss on 1150 batch: 0.796730
Train loss on 1200 batch: 0.763417
Train loss on 1250 batch: 0.408705
Train loss on 1300 batch: 0.726965
Train loss on 1350 batch: 0.534265
Train loss on 1400 batch: 1.071275
Train loss on 1450 batch: 0.798821
Train loss on 1500 batch: 0.710674
Train loss on 1550 batch: 0.927510
Train loss on 1600 batch: 0.791890
Train loss on 1650 batch: 0.658920
Train loss on 1700 batch: 0.761045
Train loss on 1750 batch: 1.188175
Train loss on 1800 batch: 0.443432
Train loss on 1850 batch: 0.916372
Train loss on 1900 batch: 0.970254
Train loss on 1950 batch: 0.686462
Train loss on 2000 batch: 0.891639
Train loss on 2050 batch: 0.510924
Train loss on 2100 batch: 0.870107
Train loss on 2150 batch: 0.590491
Train loss on 2200 batch: 0.744065
Train loss on 2250 batch: 0.668333
Train loss on 2300 batch: 1.042961
Train loss on 2350 batch: 0.949513
Train loss on 2400 batch: 0.427556
Train loss on 2450 batch: 0.569403
Train loss on 2500 batch: 0.872768
Train loss on 2550 batch: 0.880448
Train loss on 2600 batch: 0.779261
Train loss on 2650 batch: 0.991042
Train loss on 2700 batch: 0.847425
Train loss on 2750 batch: 0.882082
Train loss on 2800 batch: 0.921046
Train loss on 2850 batch: 0.669354
Train loss on 2900 batch: 0.796114
best-train-loss: 0.767351
best-valid-loss: 4.013189
best-kappa: 0.0000
: Epoch: 7 | Training Loss: 0.767351 | Val. Loss: 4.013189 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 807.21
Train loss on 50 batch: 0.509867
Train loss on 100 batch: 0.708269
Train loss on 150 batch: 0.721750
Train loss on 200 batch: 0.672735
Train loss on 250 batch: 0.945755
Train loss on 300 batch: 0.849837
Train loss on 350 batch: 0.827241
Train loss on 400 batch: 0.518965
Train loss on 450 batch: 0.892467
Train loss on 500 batch: 0.760750
Train loss on 550 batch: 0.566472
Train loss on 600 batch: 0.645814
Train loss on 650 batch: 1.192587
Train loss on 700 batch: 0.892095
Train loss on 750 batch: 0.584651
Train loss on 800 batch: 1.071192
Train loss on 850 batch: 0.687421
Train loss on 900 batch: 0.992628
Train loss on 950 batch: 0.767836
Train loss on 1000 batch: 0.779167
Train loss on 1050 batch: 1.087690
Train loss on 1100 batch: 0.837356
Train loss on 1150 batch: 1.374560
Train loss on 1200 batch: 0.809984
Train loss on 1250 batch: 0.704878
Train loss on 1300 batch: 0.590529
Train loss on 1350 batch: 0.683498
Train loss on 1400 batch: 0.535283
Train loss on 1450 batch: 0.540598
Train loss on 1500 batch: 0.343651
Train loss on 1550 batch: 0.914069
Train loss on 1600 batch: 0.510053
Train loss on 1650 batch: 0.974824
Train loss on 1700 batch: 1.083468
Train loss on 1750 batch: 0.793932
Train loss on 1800 batch: 0.689890
Train loss on 1850 batch: 0.500151
Train loss on 1900 batch: 0.975102
Train loss on 1950 batch: 0.631670
Train loss on 2000 batch: 0.826083
Train loss on 2050 batch: 0.628869
Train loss on 2100 batch: 0.467765
Train loss on 2150 batch: 0.680110
Train loss on 2200 batch: 0.914740
Train loss on 2250 batch: 0.539271
Train loss on 2300 batch: 0.544128
Train loss on 2350 batch: 0.829787
Train loss on 2400 batch: 0.614512
Train loss on 2450 batch: 0.435997
Train loss on 2500 batch: 0.543217
Train loss on 2550 batch: 0.626405
Train loss on 2600 batch: 0.537032
Train loss on 2650 batch: 0.423216
Train loss on 2700 batch: 0.463655
Train loss on 2750 batch: 1.121865
Train loss on 2800 batch: 0.797228
Train loss on 2850 batch: 0.548355
Train loss on 2900 batch: 0.761268
: Epoch: 8 | Training Loss: 0.731726 | Val. Loss: 6.121562 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 808.48
Train loss on 50 batch: 1.124284
Train loss on 100 batch: 0.596999
Train loss on 150 batch: 0.414651
Train loss on 200 batch: 0.790701
Train loss on 250 batch: 0.668064
Train loss on 300 batch: 0.686532
Train loss on 350 batch: 0.932095
Train loss on 400 batch: 0.435611
Train loss on 450 batch: 0.647026
Train loss on 500 batch: 0.590932
Train loss on 550 batch: 0.632375
Train loss on 600 batch: 0.698519
Train loss on 650 batch: 1.264591
Train loss on 700 batch: 0.834691
Train loss on 750 batch: 0.497647
Train loss on 800 batch: 0.614078
Train loss on 850 batch: 0.646514
Train loss on 900 batch: 0.804208
Train loss on 950 batch: 1.012542
Train loss on 1000 batch: 0.361597
Train loss on 1050 batch: 0.898833
Train loss on 1100 batch: 0.788021
Train loss on 1150 batch: 0.832119
Train loss on 1200 batch: 0.643255
Train loss on 1250 batch: 0.922385
Train loss on 1300 batch: 0.808064
Train loss on 1350 batch: 1.102096
Train loss on 1400 batch: 0.813870
Train loss on 1450 batch: 0.766095
Train loss on 1500 batch: 0.467057
Train loss on 1550 batch: 0.669215
Train loss on 1600 batch: 0.426221
Train loss on 1650 batch: 0.320764
Train loss on 1700 batch: 0.442935
Train loss on 1750 batch: 0.616912
Train loss on 1800 batch: 0.513203
Train loss on 1850 batch: 0.565451
Train loss on 1900 batch: 0.542408
Train loss on 1950 batch: 0.822587
Train loss on 2000 batch: 0.686488
Train loss on 2050 batch: 1.008728
Train loss on 2100 batch: 0.873001
Train loss on 2150 batch: 0.656263
Train loss on 2200 batch: 0.417872
Train loss on 2250 batch: 0.718761
Train loss on 2300 batch: 0.625499
Train loss on 2350 batch: 0.896689
Train loss on 2400 batch: 0.911600
Train loss on 2450 batch: 0.901028
Train loss on 2500 batch: 0.456211
Train loss on 2550 batch: 0.712421
Train loss on 2600 batch: 0.727684
Train loss on 2650 batch: 0.757862
Train loss on 2700 batch: 0.536358
Train loss on 2750 batch: 0.587458
Train loss on 2800 batch: 0.835281
Train loss on 2850 batch: 0.533623
Train loss on 2900 batch: 0.645676
: Epoch: 9 | Training Loss: 0.700987 | Val. Loss: 5.782526 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 808.64
Train loss on 50 batch: 0.712353
Train loss on 100 batch: 0.492867
Train loss on 150 batch: 0.647549
Train loss on 200 batch: 0.913639
Train loss on 250 batch: 0.697530
Train loss on 300 batch: 0.596671
Train loss on 350 batch: 0.724599
Train loss on 400 batch: 0.586090
Train loss on 450 batch: 0.739188
Train loss on 500 batch: 0.833113
Train loss on 550 batch: 0.495078
Train loss on 600 batch: 0.884225
Train loss on 650 batch: 0.483514
Train loss on 700 batch: 0.802150
Train loss on 750 batch: 0.976281
Train loss on 800 batch: 0.405782
Train loss on 850 batch: 0.359011
Train loss on 900 batch: 0.574504
Train loss on 950 batch: 0.646764
Train loss on 1000 batch: 0.749377
Train loss on 1050 batch: 0.786939
Train loss on 1100 batch: 0.572873
Train loss on 1150 batch: 0.954733
Train loss on 1200 batch: 0.655223
Train loss on 1250 batch: 0.821711
Train loss on 1300 batch: 0.830962
Train loss on 1350 batch: 0.655666
Train loss on 1400 batch: 0.859235
Train loss on 1450 batch: 0.997626
Train loss on 1500 batch: 0.634370
Train loss on 1550 batch: 0.755236
Train loss on 1600 batch: 1.004760
Train loss on 1650 batch: 0.384788
Train loss on 1700 batch: 0.673536
Train loss on 1750 batch: 1.106958
Train loss on 1800 batch: 0.471762
Train loss on 1850 batch: 0.747364
Train loss on 1900 batch: 0.665481
Train loss on 1950 batch: 0.447555
Train loss on 2000 batch: 0.486738
Train loss on 2050 batch: 0.765445
Train loss on 2100 batch: 0.733611
Train loss on 2150 batch: 1.040926
Train loss on 2200 batch: 0.700738
Train loss on 2250 batch: 0.632183
Train loss on 2300 batch: 0.687588
Train loss on 2350 batch: 0.457898
Train loss on 2400 batch: 0.777692
Train loss on 2450 batch: 0.569402
Train loss on 2500 batch: 0.809173
Train loss on 2550 batch: 0.853691
Train loss on 2600 batch: 0.769398
Train loss on 2650 batch: 0.673967
Train loss on 2700 batch: 0.487932
Train loss on 2750 batch: 0.613525
Train loss on 2800 batch: 0.806076
Train loss on 2850 batch: 0.857548
Train loss on 2900 batch: 0.728833
: Epoch: 10 | Training Loss: 0.706813 | Val. Loss: 12.147219 | Val. Kappa Score: 0.0000 | LR: 0.000500 | Estimated time: 807.59
Train loss on 50 batch: 0.858949
Train loss on 100 batch: 0.599568
Train loss on 150 batch: 0.472481
Train loss on 200 batch: 0.611540
Train loss on 250 batch: 0.727442
Train loss on 300 batch: 0.577650
Train loss on 350 batch: 0.693076
Train loss on 400 batch: 0.496474
Train loss on 450 batch: 0.440547
Train loss on 500 batch: 0.556084
Train loss on 550 batch: 0.480610
Train loss on 600 batch: 0.395357
Train loss on 650 batch: 0.487831
Train loss on 700 batch: 0.686551
Train loss on 750 batch: 0.706180
Train loss on 800 batch: 0.450705
Train loss on 850 batch: 0.458384
Train loss on 900 batch: 0.934520
Train loss on 950 batch: 0.401978
Train loss on 1000 batch: 1.126434
Train loss on 1050 batch: 0.417182
Train loss on 1100 batch: 0.437746
Train loss on 1150 batch: 0.681726
Train loss on 1200 batch: 0.389418
Train loss on 1250 batch: 0.414548
Train loss on 1300 batch: 0.829203
Train loss on 1350 batch: 0.719075
Train loss on 1400 batch: 0.645997
Train loss on 1450 batch: 0.634355
Train loss on 1500 batch: 0.446451
Train loss on 1550 batch: 0.723663
Train loss on 1600 batch: 0.569672
Train loss on 1650 batch: 0.644723
Train loss on 1700 batch: 0.601618
Train loss on 1750 batch: 0.344295
Train loss on 1800 batch: 0.503215
Train loss on 1850 batch: 0.617612
Train loss on 1900 batch: 0.802461
Train loss on 1950 batch: 0.629205
Train loss on 2000 batch: 0.553535
Train loss on 2050 batch: 0.414703
Train loss on 2100 batch: 0.656429
Train loss on 2150 batch: 0.753442
Train loss on 2200 batch: 0.461941
Train loss on 2250 batch: 0.603547
Train loss on 2300 batch: 0.510346
Train loss on 2350 batch: 0.725061
Train loss on 2400 batch: 0.749691
Train loss on 2450 batch: 0.313269
Train loss on 2500 batch: 0.577334
Train loss on 2550 batch: 0.476181
Train loss on 2600 batch: 0.655279
Train loss on 2650 batch: 0.574295
Train loss on 2700 batch: 0.739909
Train loss on 2750 batch: 0.713285
Train loss on 2800 batch: 0.358267
Train loss on 2850 batch: 0.577574
Train loss on 2900 batch: 0.227777
: Epoch: 11 | Training Loss: 0.589995 | Val. Loss: 214.957006 | Val. Kappa Score: 0.0000 | LR: 0.000500 | Estimated time: 807.96
Train loss on 50 batch: 0.363939
Train loss on 100 batch: 0.486181
Train loss on 150 batch: 0.460693
Train loss on 200 batch: 0.624383
Train loss on 250 batch: 0.541835
Train loss on 300 batch: 0.341128
Train loss on 350 batch: 0.582305
Train loss on 400 batch: 0.691344
Train loss on 450 batch: 0.609273
Train loss on 500 batch: 0.739310
Train loss on 550 batch: 0.682996
Train loss on 600 batch: 0.359418
Train loss on 650 batch: 0.761808
Train loss on 700 batch: 0.694218
Train loss on 750 batch: 0.519668
Train loss on 800 batch: 0.529999
Train loss on 850 batch: 0.508365
Train loss on 900 batch: 0.606098
Train loss on 950 batch: 0.422766
Train loss on 1000 batch: 0.826677
Train loss on 1050 batch: 0.469655
Train loss on 1100 batch: 0.652100
Train loss on 1150 batch: 0.623808
Train loss on 1200 batch: 0.438173
Train loss on 1250 batch: 0.440089
Train loss on 1300 batch: 0.722311
Train loss on 1350 batch: 0.340433
Train loss on 1400 batch: 0.384166
Train loss on 1450 batch: 0.415977
Train loss on 1500 batch: 0.712876
Train loss on 1550 batch: 0.383680
Train loss on 1600 batch: 0.858783
Train loss on 1650 batch: 0.801646
Train loss on 1700 batch: 0.521116
Train loss on 1750 batch: 0.583484
Train loss on 1800 batch: 0.676909
Train loss on 1850 batch: 0.464586
Train loss on 1900 batch: 0.570615
Train loss on 1950 batch: 0.381478
Train loss on 2000 batch: 0.663390
Train loss on 2050 batch: 0.483847
Train loss on 2100 batch: 0.393669
Train loss on 2150 batch: 0.825879
Train loss on 2200 batch: 0.450854
Train loss on 2250 batch: 0.847647
Train loss on 2300 batch: 0.702231
Train loss on 2350 batch: 0.516304
Train loss on 2400 batch: 0.402399
Train loss on 2450 batch: 0.647859
Train loss on 2500 batch: 0.285035
Train loss on 2550 batch: 0.696463
Train loss on 2600 batch: 0.566147
Train loss on 2650 batch: 0.568693
Train loss on 2700 batch: 0.807550
Train loss on 2750 batch: 0.357338
Train loss on 2800 batch: 0.288464
Train loss on 2850 batch: 0.667397
Train loss on 2900 batch: 0.349311
: Epoch: 12 | Training Loss: 0.562957 | Val. Loss: 6.294110 | Val. Kappa Score: 0.0000 | LR: 0.000500 | Estimated time: 807.94
Train loss on 50 batch: 0.253776
Train loss on 100 batch: 0.681522
Train loss on 150 batch: 0.554549
Train loss on 200 batch: 0.557742
Train loss on 250 batch: 0.444057
Train loss on 300 batch: 0.560232
Train loss on 350 batch: 0.477500
Train loss on 400 batch: 0.515063
Train loss on 450 batch: 0.342566
Train loss on 500 batch: 0.489243
Train loss on 550 batch: 0.505881
Train loss on 600 batch: 0.556970
Train loss on 650 batch: 0.719031
Train loss on 700 batch: 0.321707
Train loss on 750 batch: 0.436554
Train loss on 800 batch: 0.530530
Train loss on 850 batch: 0.772665
Train loss on 900 batch: 0.217987
Train loss on 950 batch: 0.662267
Train loss on 1000 batch: 0.794336
Train loss on 1050 batch: 0.673940
Train loss on 1100 batch: 0.618054
Train loss on 1150 batch: 0.343339
Train loss on 1200 batch: 0.571587
Train loss on 1250 batch: 0.355519
Train loss on 1300 batch: 0.649826
Train loss on 1350 batch: 0.545291
Train loss on 1400 batch: 0.499011
Train loss on 1450 batch: 0.346034
Train loss on 1500 batch: 0.325010
Train loss on 1550 batch: 0.783872
Train loss on 1600 batch: 0.657549
Train loss on 1650 batch: 0.674021
Train loss on 1700 batch: 0.626320
Train loss on 1750 batch: 0.466987
Train loss on 1800 batch: 0.560337
Train loss on 1850 batch: 0.453818
Train loss on 1900 batch: 0.501847
Train loss on 1950 batch: 0.909435
Train loss on 2000 batch: 0.623830
Train loss on 2050 batch: 0.674172
Train loss on 2100 batch: 0.371171
Train loss on 2150 batch: 0.479983
Train loss on 2200 batch: 0.425036
Train loss on 2250 batch: 0.523954
Train loss on 2300 batch: 0.402428
Train loss on 2350 batch: 0.422050
Train loss on 2400 batch: 0.566725
Train loss on 2450 batch: 0.328795
Train loss on 2500 batch: 0.578717
Train loss on 2550 batch: 0.367883
Train loss on 2600 batch: 0.349990
Train loss on 2650 batch: 0.773823
Train loss on 2700 batch: 0.461381
Train loss on 2750 batch: 0.449232
Train loss on 2800 batch: 0.529923
Train loss on 2850 batch: 0.353325
Train loss on 2900 batch: 0.474557
: Epoch: 13 | Training Loss: 0.516451 | Val. Loss: 4.399885 | Val. Kappa Score: 0.0000 | LR: 0.000250 | Estimated time: 808.22
Train loss on 50 batch: 0.349678
Train loss on 100 batch: 0.464460
Train loss on 150 batch: 0.291044
Train loss on 200 batch: 0.480041
Train loss on 250 batch: 0.751540
Train loss on 300 batch: 0.609763
Train loss on 350 batch: 0.781241
Train loss on 400 batch: 0.308002
Train loss on 450 batch: 0.374819
Train loss on 500 batch: 0.394105
Train loss on 550 batch: 0.535954
Train loss on 600 batch: 0.453293
Train loss on 650 batch: 0.219109
Train loss on 700 batch: 0.267743
Train loss on 750 batch: 0.285170
Train loss on 800 batch: 0.903718
Train loss on 850 batch: 0.334656
Train loss on 900 batch: 0.512469
Train loss on 950 batch: 0.513901
Train loss on 1000 batch: 0.735425
Train loss on 1050 batch: 0.353208
Train loss on 1100 batch: 0.352429
Train loss on 1150 batch: 0.327047
Train loss on 1200 batch: 0.342067
Train loss on 1250 batch: 0.257315
Train loss on 1300 batch: 0.560292
Train loss on 1350 batch: 0.525794
Train loss on 1400 batch: 0.405015
Train loss on 1450 batch: 0.626053
Train loss on 1500 batch: 0.386666
Train loss on 1550 batch: 0.570293
Train loss on 1600 batch: 0.693145
Train loss on 1650 batch: 0.456598
Train loss on 1700 batch: 0.490042
Train loss on 1750 batch: 0.515047
Train loss on 1800 batch: 0.438409
Train loss on 1850 batch: 0.613308
Train loss on 1900 batch: 0.818334
Train loss on 1950 batch: 0.657988
Train loss on 2000 batch: 0.490610
Train loss on 2050 batch: 0.255493
Train loss on 2100 batch: 0.459631
Train loss on 2150 batch: 0.493115
Train loss on 2200 batch: 0.338438
Train loss on 2250 batch: 0.510361
Train loss on 2300 batch: 0.486859
Train loss on 2350 batch: 0.519454
Train loss on 2400 batch: 0.599102
Train loss on 2450 batch: 0.398412
Train loss on 2500 batch: 0.355547
Train loss on 2550 batch: 0.356182
Train loss on 2600 batch: 0.405934
Train loss on 2650 batch: 0.512720
Train loss on 2700 batch: 0.776201
Train loss on 2750 batch: 0.491013
Train loss on 2800 batch: 0.620317
Train loss on 2850 batch: 1.099026
Train loss on 2900 batch: 0.518207
: Epoch: 14 | Training Loss: 0.495023 | Val. Loss: 4.745323 | Val. Kappa Score: 0.0000 | LR: 0.000250 | Estimated time: 807.02
Train loss on 50 batch: 0.339457
Train loss on 100 batch: 0.285883
Train loss on 150 batch: 0.799420
Train loss on 200 batch: 0.488298
Train loss on 250 batch: 0.693639
Train loss on 300 batch: 0.499788
Train loss on 350 batch: 0.774992
Train loss on 400 batch: 0.481356
Train loss on 450 batch: 0.500939
Train loss on 500 batch: 0.376703
Train loss on 550 batch: 0.336697
Train loss on 600 batch: 0.328616
Train loss on 650 batch: 0.382332
Train loss on 700 batch: 0.737570
Train loss on 750 batch: 0.272633
Train loss on 800 batch: 0.564238
Train loss on 850 batch: 0.503768
Train loss on 900 batch: 0.398916
Train loss on 950 batch: 0.283631
Train loss on 1000 batch: 0.310203
Train loss on 1050 batch: 0.449503
Train loss on 1100 batch: 0.477537
Train loss on 1150 batch: 0.366445
Train loss on 1200 batch: 0.700332
Train loss on 1250 batch: 0.718744
Train loss on 1300 batch: 0.403821
Train loss on 1350 batch: 0.467914
Train loss on 1400 batch: 0.629920
Train loss on 1450 batch: 0.472672
Train loss on 1500 batch: 0.219633
Train loss on 1550 batch: 0.461704
Train loss on 1600 batch: 0.967062
Train loss on 1650 batch: 0.323626
Train loss on 1700 batch: 0.520794
Train loss on 1750 batch: 0.439637
Train loss on 1800 batch: 0.816577
Train loss on 1850 batch: 0.410833
Train loss on 1900 batch: 0.501076
Train loss on 1950 batch: 0.656137
Train loss on 2000 batch: 0.348647
Train loss on 2050 batch: 0.439076
Train loss on 2100 batch: 0.288038
Train loss on 2150 batch: 0.531509
Train loss on 2200 batch: 0.322329
Train loss on 2250 batch: 0.472481
Train loss on 2300 batch: 0.403999
Train loss on 2350 batch: 0.380423
Train loss on 2400 batch: 0.380963
Train loss on 2450 batch: 0.523320
Train loss on 2500 batch: 0.355652
Train loss on 2550 batch: 0.238571
Train loss on 2600 batch: 0.467114
Train loss on 2650 batch: 0.631740
Train loss on 2700 batch: 0.603617
Train loss on 2750 batch: 0.623203
Train loss on 2800 batch: 0.359725
Train loss on 2850 batch: 0.462366
Train loss on 2900 batch: 0.410168
: Epoch: 15 | Training Loss: 0.470520 | Val. Loss: 4.688244 | Val. Kappa Score: 0.0000 | LR: 0.000250 | Estimated time: 810.66
Train loss on 50 batch: 0.315425
Train loss on 100 batch: 0.549043
Train loss on 150 batch: 0.316444
Train loss on 200 batch: 0.590692
Train loss on 250 batch: 0.372479
Train loss on 300 batch: 0.305915
Train loss on 350 batch: 0.452568
Train loss on 400 batch: 0.874899
Train loss on 450 batch: 0.641762
Train loss on 500 batch: 0.446947
Train loss on 550 batch: 0.387114
Train loss on 600 batch: 0.548427
Train loss on 650 batch: 0.811913
Train loss on 700 batch: 0.351611
Train loss on 750 batch: 0.360550
Train loss on 800 batch: 0.378871
Train loss on 850 batch: 0.514988
Train loss on 900 batch: 0.664717
Train loss on 950 batch: 0.329862
Train loss on 1000 batch: 0.367083
Train loss on 1050 batch: 0.443307
Train loss on 1100 batch: 0.551452
Train loss on 1150 batch: 0.412869
Train loss on 1200 batch: 0.389600
Train loss on 1250 batch: 0.517166
Train loss on 1300 batch: 0.546985
Train loss on 1350 batch: 0.458729
Train loss on 1400 batch: 0.283783
Train loss on 1450 batch: 0.686809
Train loss on 1500 batch: 0.184073
Train loss on 1550 batch: 0.471450
Train loss on 1600 batch: 0.374915
Train loss on 1650 batch: 0.355468
Train loss on 1700 batch: 0.656998
Train loss on 1750 batch: 0.374154
Train loss on 1800 batch: 0.315392
Train loss on 1850 batch: 0.466202
Train loss on 1900 batch: 0.392888
Train loss on 1950 batch: 0.418944
Train loss on 2000 batch: 0.414292
Train loss on 2050 batch: 0.345967
Train loss on 2100 batch: 0.416795
Train loss on 2150 batch: 0.386113
Train loss on 2200 batch: 0.901896
Train loss on 2250 batch: 0.537785
Train loss on 2300 batch: 0.277319
Train loss on 2350 batch: 0.511052
Train loss on 2400 batch: 0.401445
Train loss on 2450 batch: 0.757487
Train loss on 2500 batch: 0.451040
Train loss on 2550 batch: 0.418233
Train loss on 2600 batch: 0.529452
Train loss on 2650 batch: 0.433563
Train loss on 2700 batch: 0.251141
Train loss on 2750 batch: 0.277485
Train loss on 2800 batch: 0.428106
Train loss on 2850 batch: 0.421081
Train loss on 2900 batch: 0.630652
: Epoch: 16 | Training Loss: 0.460089 | Val. Loss: 6.990996 | Val. Kappa Score: 0.0000 | LR: 0.000125 | Estimated time: 809.22
Train loss on 50 batch: 0.564922
Train loss on 100 batch: 0.444404
Train loss on 150 batch: 0.353398
Train loss on 200 batch: 0.518755
Train loss on 250 batch: 0.422922
Train loss on 300 batch: 0.738331
Train loss on 350 batch: 0.367072
Train loss on 400 batch: 0.303258
Train loss on 450 batch: 0.484627
Train loss on 500 batch: 0.369448
Train loss on 550 batch: 0.510114
Train loss on 600 batch: 0.432114
Train loss on 650 batch: 0.340612
Train loss on 700 batch: 0.439908
Train loss on 750 batch: 0.762639
Train loss on 800 batch: 0.526280
Train loss on 850 batch: 0.311020
Train loss on 900 batch: 0.308518
Train loss on 950 batch: 0.498585
Train loss on 1000 batch: 0.293146
Train loss on 1050 batch: 0.819296
Train loss on 1100 batch: 0.406027
Train loss on 1150 batch: 0.354649
Train loss on 1200 batch: 0.614275
Train loss on 1250 batch: 0.553242
----------------------------------------

Experiment N: 119: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.08.21 14:25:52
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95eef0b8>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 119: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.21 14:26:12
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1dac50>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.978677
Train loss on 100 batch: 0.603214
Train loss on 150 batch: 0.546513
best-train-loss: 0.639657
best-valid-loss: 0.413543
best-kappa: 0.8649
: Epoch: 1 | Training Loss: 0.639657 | Val. Loss: 0.413543 | Val. Kappa Score: 0.8649 | LR: 0.001000 | Estimated time: 509.55
Train loss on 50 batch: 0.435758
Train loss on 100 batch: 0.425664
Train loss on 150 batch: 0.337297
best-train-loss: 0.422469
best-valid-loss: 0.379814
best-kappa: 0.8658
: Epoch: 2 | Training Loss: 0.422469 | Val. Loss: 0.379814 | Val. Kappa Score: 0.8658 | LR: 0.001000 | Estimated time: 508.83
Train loss on 50 batch: 0.378988
Train loss on 100 batch: 0.419748
Train loss on 150 batch: 0.376297
best-train-loss: 0.402012
best-valid-loss: 0.361190
best-kappa: 0.8669
: Epoch: 3 | Training Loss: 0.402012 | Val. Loss: 0.361190 | Val. Kappa Score: 0.8669 | LR: 0.001000 | Estimated time: 508.17
Train loss on 50 batch: 0.377779
Train loss on 100 batch: 0.381733
Train loss on 150 batch: 0.327643
: Epoch: 4 | Training Loss: 0.388328 | Val. Loss: 1.027050 | Val. Kappa Score: 0.8445 | LR: 0.001000 | Estimated time: 507.57
Train loss on 50 batch: 0.415011
Train loss on 100 batch: 0.368150
Train loss on 150 batch: 0.292258
: Epoch: 5 | Training Loss: 0.360785 | Val. Loss: 0.404508 | Val. Kappa Score: 0.8461 | LR: 0.001000 | Estimated time: 508.58
Train loss on 50 batch: 0.351506
Train loss on 100 batch: 0.310332
Train loss on 150 batch: 0.327406
: Epoch: 6 | Training Loss: 0.327866 | Val. Loss: 0.385589 | Val. Kappa Score: 0.8483 | LR: 0.000500 | Estimated time: 508.11
Train loss on 50 batch: 0.330590
Train loss on 100 batch: 0.249422
Train loss on 150 batch: 0.230114
best-train-loss: 0.264148
best-valid-loss: 0.270293
best-kappa: 0.8557
: Epoch: 7 | Training Loss: 0.264148 | Val. Loss: 0.270293 | Val. Kappa Score: 0.8557 | LR: 0.000500 | Estimated time: 508.27
Train loss on 50 batch: 0.189604
Train loss on 100 batch: 0.257708
Train loss on 150 batch: 0.203640
best-train-loss: 0.230505
best-valid-loss: 0.264461
best-kappa: 0.8613
: Epoch: 8 | Training Loss: 0.230505 | Val. Loss: 0.264461 | Val. Kappa Score: 0.8613 | LR: 0.000500 | Estimated time: 508.79
Train loss on 50 batch: 0.206566
Train loss on 100 batch: 0.246995
Train loss on 150 batch: 0.227015
: Epoch: 9 | Training Loss: 0.224357 | Val. Loss: 0.266824 | Val. Kappa Score: 0.8653 | LR: 0.000500 | Estimated time: 508.37
Train loss on 50 batch: 0.172379
Train loss on 100 batch: 0.202790
Train loss on 150 batch: 0.205384
: Epoch: 10 | Training Loss: 0.237558 | Val. Loss: 0.275297 | Val. Kappa Score: 0.8685 | LR: 0.000500 | Estimated time: 507.88
Train loss on 50 batch: 0.220312
Train loss on 100 batch: 0.181236
Train loss on 150 batch: 0.200609
: Epoch: 11 | Training Loss: 0.229226 | Val. Loss: 0.272465 | Val. Kappa Score: 0.8700 | LR: 0.000250 | Estimated time: 509.05
Train loss on 50 batch: 0.156747
Train loss on 100 batch: 0.152226
Train loss on 150 batch: 0.167471
: Epoch: 12 | Training Loss: 0.169063 | Val. Loss: 0.276093 | Val. Kappa Score: 0.8713 | LR: 0.000250 | Estimated time: 508.38
Train loss on 50 batch: 0.136372
Train loss on 100 batch: 0.167968
Train loss on 150 batch: 0.121360
: Epoch: 13 | Training Loss: 0.148066 | Val. Loss: 0.274328 | Val. Kappa Score: 0.8730 | LR: 0.000250 | Estimated time: 508.65
Train loss on 50 batch: 0.134081
Train loss on 100 batch: 0.116526
Train loss on 150 batch: 0.154853
: Epoch: 14 | Training Loss: 0.149295 | Val. Loss: 0.283749 | Val. Kappa Score: 0.8742 | LR: 0.000125 | Estimated time: 508.38
Train loss on 50 batch: 0.155995
Train loss on 100 batch: 0.120297
Train loss on 150 batch: 0.125885
: Epoch: 15 | Training Loss: 0.131002 | Val. Loss: 0.273312 | Val. Kappa Score: 0.8756 | LR: 0.000125 | Estimated time: 511.37
Train loss on 50 batch: 0.112972
Train loss on 100 batch: 0.105668
Train loss on 150 batch: 0.107854
: Epoch: 16 | Training Loss: 0.109293 | Val. Loss: 0.273136 | Val. Kappa Score: 0.8770 | LR: 0.000125 | Estimated time: 521.48
Train loss on 50 batch: 0.127051
Train loss on 100 batch: 0.102840
Train loss on 150 batch: 0.109324
: Epoch: 17 | Training Loss: 0.116176 | Val. Loss: 0.272288 | Val. Kappa Score: 0.8782 | LR: 0.000063 | Estimated time: 512.91
Train loss on 50 batch: 0.090286
Train loss on 100 batch: 0.095626
Train loss on 150 batch: 0.102893
: Epoch: 18 | Training Loss: 0.097820 | Val. Loss: 0.277436 | Val. Kappa Score: 0.8792 | LR: 0.000063 | Estimated time: 512.38
time_estimated: 9177.46
n-epochs: 18
time_estimated: 9177.49
----------------------------------------

Experiment N: 120: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.21 19:06:49
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d102710>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 120: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.21 19:15:09
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d103828>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.967450
Train loss on 100 batch: 0.601356
Train loss on 150 batch: 0.542864
best-train-loss: 0.633246
best-valid-loss: 0.432871
best-kappa: 0.8435
: Epoch: 1 | Training Loss: 0.633246 | Val. Loss: 0.432871 | Val. Kappa Score: 0.8435 | LR: 0.001000 | Estimated time: 41.93
Train loss on 50 batch: 0.431175
Train loss on 100 batch: 0.411578
Train loss on 150 batch: 0.323419
best-train-loss: 0.407272
best-valid-loss: 0.331869
best-kappa: 0.8529
: Epoch: 2 | Training Loss: 0.407272 | Val. Loss: 0.331869 | Val. Kappa Score: 0.8529 | LR: 0.001000 | Estimated time: 40.30
Train loss on 50 batch: 0.395519
Train loss on 100 batch: 0.407162
Train loss on 150 batch: 0.373894
: Epoch: 3 | Training Loss: 0.399071 | Val. Loss: 0.380115 | Val. Kappa Score: 0.8578 | LR: 0.001000 | Estimated time: 41.35
Train loss on 50 batch: 0.391864
Train loss on 100 batch: 0.410080
Train loss on 150 batch: 0.331955
: Epoch: 4 | Training Loss: 0.419066 | Val. Loss: 0.637004 | Val. Kappa Score: 0.8518 | LR: 0.001000 | Estimated time: 42.47
Train loss on 50 batch: 0.426878
Train loss on 100 batch: 0.388958
Train loss on 150 batch: 0.325916
: Epoch: 5 | Training Loss: 0.379644 | Val. Loss: 0.339329 | Val. Kappa Score: 0.8566 | LR: 0.000500 | Estimated time: 43.15
Train loss on 50 batch: 0.305931
Train loss on 100 batch: 0.291181
Train loss on 150 batch: 0.228240
best-train-loss: 0.268675
best-valid-loss: 0.310415
best-kappa: 0.8599
: Epoch: 6 | Training Loss: 0.268675 | Val. Loss: 0.310415 | Val. Kappa Score: 0.8599 | LR: 0.000500 | Estimated time: 42.49
Train loss on 50 batch: 0.273201
Train loss on 100 batch: 0.241962
Train loss on 150 batch: 0.226515
best-train-loss: 0.254182
best-valid-loss: 0.281748
best-kappa: 0.8638
: Epoch: 7 | Training Loss: 0.254182 | Val. Loss: 0.281748 | Val. Kappa Score: 0.8638 | LR: 0.000500 | Estimated time: 43.14
Train loss on 50 batch: 0.202165
Train loss on 100 batch: 0.254717
Train loss on 150 batch: 0.215058
best-train-loss: 0.228930
best-valid-loss: 0.276959
best-kappa: 0.8684
: Epoch: 8 | Training Loss: 0.228930 | Val. Loss: 0.276959 | Val. Kappa Score: 0.8684 | LR: 0.000500 | Estimated time: 42.33
Train loss on 50 batch: 0.216786
Train loss on 100 batch: 0.244808
Train loss on 150 batch: 0.242591
: Epoch: 9 | Training Loss: 0.228324 | Val. Loss: 0.297076 | Val. Kappa Score: 0.8708 | LR: 0.000500 | Estimated time: 43.03
Train loss on 50 batch: 0.183679
Train loss on 100 batch: 0.191503
Train loss on 150 batch: 0.220443
best-train-loss: 0.249148
best-valid-loss: 0.272864
best-kappa: 0.8734
: Epoch: 10 | Training Loss: 0.249148 | Val. Loss: 0.272864 | Val. Kappa Score: 0.8734 | LR: 0.000500 | Estimated time: 43.68
Train loss on 50 batch: 0.243438
Train loss on 100 batch: 0.209034
Train loss on 150 batch: 0.186975
: Epoch: 11 | Training Loss: 0.225108 | Val. Loss: 0.343982 | Val. Kappa Score: 0.8720 | LR: 0.000500 | Estimated time: 43.38
Train loss on 50 batch: 0.190807
Train loss on 100 batch: 0.191119
Train loss on 150 batch: 0.210463
: Epoch: 12 | Training Loss: 0.211766 | Val. Loss: 0.318057 | Val. Kappa Score: 0.8721 | LR: 0.000500 | Estimated time: 43.55
Train loss on 50 batch: 0.176829
Train loss on 100 batch: 0.214798
Train loss on 150 batch: 0.191346
: Epoch: 13 | Training Loss: 0.207100 | Val. Loss: 0.312892 | Val. Kappa Score: 0.8724 | LR: 0.000250 | Estimated time: 43.27
Train loss on 50 batch: 0.170986
Train loss on 100 batch: 0.162684
Train loss on 150 batch: 0.190541
: Epoch: 14 | Training Loss: 0.180941 | Val. Loss: 0.277150 | Val. Kappa Score: 0.8740 | LR: 0.000250 | Estimated time: 42.70
Train loss on 50 batch: 0.192779
Train loss on 100 batch: 0.151869
Train loss on 150 batch: 0.168992
: Epoch: 15 | Training Loss: 0.170607 | Val. Loss: 0.275962 | Val. Kappa Score: 0.8754 | LR: 0.000250 | Estimated time: 43.31
Train loss on 50 batch: 0.136490
Train loss on 100 batch: 0.144814
Train loss on 150 batch: 0.159400
: Epoch: 16 | Training Loss: 0.151005 | Val. Loss: 0.297992 | Val. Kappa Score: 0.8758 | LR: 0.000125 | Estimated time: 42.74
Train loss on 50 batch: 0.151378
Train loss on 100 batch: 0.125837
Train loss on 150 batch: 0.126044
: Epoch: 17 | Training Loss: 0.133721 | Val. Loss: 0.281308 | Val. Kappa Score: 0.8766 | LR: 0.000125 | Estimated time: 43.60
Train loss on 50 batch: 0.110590
Train loss on 100 batch: 0.107935
Train loss on 150 batch: 0.138303
: Epoch: 18 | Training Loss: 0.120267 | Val. Loss: 0.301364 | Val. Kappa Score: 0.8770 | LR: 0.000125 | Estimated time: 43.08
Train loss on 50 batch: 0.096818
Train loss on 100 batch: 0.124024
Train loss on 150 batch: 0.126390
: Epoch: 19 | Training Loss: 0.118277 | Val. Loss: 0.281847 | Val. Kappa Score: 0.8776 | LR: 0.000063 | Estimated time: 43.55
Train loss on 50 batch: 0.102922
Train loss on 100 batch: 0.130515
Train loss on 150 batch: 0.098565
: Epoch: 20 | Training Loss: 0.114744 | Val. Loss: 0.281307 | Val. Kappa Score: 0.8788 | LR: 0.000063 | Estimated time: 42.95
time_estimated: 856.90
n-epochs: 20
time_estimated: 856.93
----------------------------------------

Experiment N: 121: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.21 19:35:31
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1017b8>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.987318
Train loss on 100 batch: 0.876141
Train loss on 150 batch: 0.823563
Train loss on 200 batch: 0.709979
Train loss on 250 batch: 0.758485
Train loss on 300 batch: 0.719196
Train loss on 350 batch: 0.735438
Train loss on 400 batch: 0.754788
Train loss on 450 batch: 0.749638
Train loss on 500 batch: 0.644147
Train loss on 550 batch: 0.623614
Train loss on 600 batch: 0.615233
Train loss on 650 batch: 0.730241
Train loss on 700 batch: 0.635121
Train loss on 750 batch: 0.593644
Train loss on 800 batch: 0.645803
Train loss on 850 batch: 0.703973
Train loss on 900 batch: 0.591491
Train loss on 950 batch: 0.538128
Train loss on 1000 batch: 0.627301
Train loss on 1050 batch: 0.578180
Train loss on 1100 batch: 0.596652
Train loss on 1150 batch: 0.635329
Train loss on 1200 batch: 0.633149
Train loss on 1250 batch: 0.535335
Train loss on 1300 batch: 0.626659
Train loss on 1350 batch: 0.543632
Train loss on 1400 batch: 0.588218
Train loss on 1450 batch: 0.711642
Train loss on 1500 batch: 0.585744
Train loss on 1550 batch: 0.573672
Train loss on 1600 batch: 0.615274
Train loss on 1650 batch: 0.665219
Train loss on 1700 batch: 0.608664
Train loss on 1750 batch: 0.572100
Train loss on 1800 batch: 0.557199
Train loss on 1850 batch: 0.612957
Train loss on 1900 batch: 0.666251
best-train-loss: 0.655974
best-valid-loss: 0.564750
best-kappa: 0.5598
: Epoch: 1 | Training Loss: 0.655974 | Val. Loss: 0.564750 | Val. Kappa Score: 0.5598 | LR: 0.001000 | Estimated time: 395.77
Train loss on 50 batch: 0.542509
Train loss on 100 batch: 0.574855
Train loss on 150 batch: 0.588162
Train loss on 200 batch: 0.548919
Train loss on 250 batch: 0.495497
Train loss on 300 batch: 0.565289
Train loss on 350 batch: 0.609187
Train loss on 400 batch: 0.575808
Train loss on 450 batch: 0.542734
Train loss on 500 batch: 0.564836
Train loss on 550 batch: 0.531640
Train loss on 600 batch: 0.536175
Train loss on 650 batch: 0.481548
Train loss on 700 batch: 0.581901
Train loss on 750 batch: 0.585861
Train loss on 800 batch: 0.548782
Train loss on 850 batch: 0.567726
Train loss on 900 batch: 0.608582
Train loss on 950 batch: 0.618148
Train loss on 1000 batch: 0.531949
Train loss on 1050 batch: 0.513757
Train loss on 1100 batch: 0.576605
Train loss on 1150 batch: 0.434556
Train loss on 1200 batch: 0.545902
Train loss on 1250 batch: 0.599743
Train loss on 1300 batch: 0.591127
Train loss on 1350 batch: 0.574575
Train loss on 1400 batch: 0.495059
Train loss on 1450 batch: 0.561549
Train loss on 1500 batch: 0.576518
Train loss on 1550 batch: 0.555654
Train loss on 1600 batch: 0.489370
Train loss on 1650 batch: 0.530320
Train loss on 1700 batch: 0.623194
Train loss on 1750 batch: 0.475220
Train loss on 1800 batch: 0.504552
Train loss on 1850 batch: 0.528399
Train loss on 1900 batch: 0.438374
best-train-loss: 0.545331
best-valid-loss: 0.437912
best-kappa: 0.6159
: Epoch: 2 | Training Loss: 0.545331 | Val. Loss: 0.437912 | Val. Kappa Score: 0.6159 | LR: 0.001000 | Estimated time: 374.71
Train loss on 50 batch: 0.577428
Train loss on 100 batch: 0.544121
Train loss on 150 batch: 0.491220
Train loss on 200 batch: 0.574904
Train loss on 250 batch: 0.540798
Train loss on 300 batch: 0.458708
Train loss on 350 batch: 0.476438
Train loss on 400 batch: 0.499756
Train loss on 450 batch: 0.486771
Train loss on 500 batch: 0.574694
Train loss on 550 batch: 0.484787
Train loss on 600 batch: 0.519312
Train loss on 650 batch: 0.570441
Train loss on 700 batch: 0.521321
Train loss on 750 batch: 0.493265
Train loss on 800 batch: 0.511438
Train loss on 850 batch: 0.539503
Train loss on 900 batch: 0.476765
Train loss on 950 batch: 0.476089
Train loss on 1000 batch: 0.452477
Train loss on 1050 batch: 0.455664
Train loss on 1100 batch: 0.510491
Train loss on 1150 batch: 0.495435
Train loss on 1200 batch: 0.563315
Train loss on 1250 batch: 0.469098
Train loss on 1300 batch: 0.459209
Train loss on 1350 batch: 0.538987
Train loss on 1400 batch: 0.451096
Train loss on 1450 batch: 0.474599
Train loss on 1500 batch: 0.514030
Train loss on 1550 batch: 0.480262
Train loss on 1600 batch: 0.484581
Train loss on 1650 batch: 0.413591
Train loss on 1700 batch: 0.431689
Train loss on 1750 batch: 0.427549
Train loss on 1800 batch: 0.533313
Train loss on 1850 batch: 0.505253
Train loss on 1900 batch: 0.486796
: Epoch: 3 | Training Loss: 0.499137 | Val. Loss: 0.678641 | Val. Kappa Score: 0.5936 | LR: 0.001000 | Estimated time: 374.82
Train loss on 50 batch: 0.564508
Train loss on 100 batch: 0.466124
Train loss on 150 batch: 0.558159
Train loss on 200 batch: 0.520169
Train loss on 250 batch: 0.484346
Train loss on 300 batch: 0.456665
Train loss on 350 batch: 0.557309
Train loss on 400 batch: 0.492523
Train loss on 450 batch: 0.427796
Train loss on 500 batch: 0.516591
Train loss on 550 batch: 0.520078
Train loss on 600 batch: 0.495300
Train loss on 650 batch: 0.450492
Train loss on 700 batch: 0.520027
Train loss on 750 batch: 0.453103
Train loss on 800 batch: 0.514985
Train loss on 850 batch: 0.458876
Train loss on 900 batch: 0.505262
Train loss on 950 batch: 0.466236
Train loss on 1000 batch: 0.422435
Train loss on 1050 batch: 0.517308
Train loss on 1100 batch: 0.496128
Train loss on 1150 batch: 0.476855
Train loss on 1200 batch: 0.470892
Train loss on 1250 batch: 0.441796
Train loss on 1300 batch: 0.480726
Train loss on 1350 batch: 0.399137
Train loss on 1400 batch: 0.450941
Train loss on 1450 batch: 0.437573
Train loss on 1500 batch: 0.434660
Train loss on 1550 batch: 0.487343
Train loss on 1600 batch: 0.537531
Train loss on 1650 batch: 0.504144
Train loss on 1700 batch: 0.566363
Train loss on 1750 batch: 0.477339
Train loss on 1800 batch: 0.434969
Train loss on 1850 batch: 0.443559
Train loss on 1900 batch: 0.546179
: Epoch: 4 | Training Loss: 0.484556 | Val. Loss: 0.531900 | Val. Kappa Score: 0.5931 | LR: 0.001000 | Estimated time: 375.40
Train loss on 50 batch: 0.424546
Train loss on 100 batch: 0.475153
Train loss on 150 batch: 0.438294
Train loss on 200 batch: 0.462782
Train loss on 250 batch: 0.445129
Train loss on 300 batch: 0.422086
Train loss on 350 batch: 0.511148
Train loss on 400 batch: 0.476239
Train loss on 450 batch: 0.467779
Train loss on 500 batch: 0.489153
Train loss on 550 batch: 0.516274
Train loss on 600 batch: 0.471960
Train loss on 650 batch: 0.403866
Train loss on 700 batch: 0.544620
Train loss on 750 batch: 0.498299
Train loss on 800 batch: 0.549298
Train loss on 850 batch: 0.504743
Train loss on 900 batch: 0.453569
Train loss on 950 batch: 0.443900
Train loss on 1000 batch: 0.429464
Train loss on 1050 batch: 0.514787
Train loss on 1100 batch: 0.480911
Train loss on 1150 batch: 0.491556
Train loss on 1200 batch: 0.409118
Train loss on 1250 batch: 0.455635
Train loss on 1300 batch: 0.500172
Train loss on 1350 batch: 0.435388
Train loss on 1400 batch: 0.425855
Train loss on 1450 batch: 0.407444
Train loss on 1500 batch: 0.442006
Train loss on 1550 batch: 0.397777
Train loss on 1600 batch: 0.419728
Train loss on 1650 batch: 0.473695
Train loss on 1700 batch: 0.533510
Train loss on 1750 batch: 0.472037
Train loss on 1800 batch: 0.407061
Train loss on 1850 batch: 0.441033
Train loss on 1900 batch: 0.426728
: Epoch: 5 | Training Loss: 0.463274 | Val. Loss: 0.448474 | Val. Kappa Score: 0.6096 | LR: 0.000500 | Estimated time: 375.39
Train loss on 50 batch: 0.477478
Train loss on 100 batch: 0.421651
Train loss on 150 batch: 0.394246
Train loss on 200 batch: 0.445727
Train loss on 250 batch: 0.362107
Train loss on 300 batch: 0.434078
Train loss on 350 batch: 0.399086
Train loss on 400 batch: 0.440890
Train loss on 450 batch: 0.476774
Train loss on 500 batch: 0.364331
Train loss on 550 batch: 0.434264
Train loss on 600 batch: 0.468708
Train loss on 650 batch: 0.440086
Train loss on 700 batch: 0.389789
Train loss on 750 batch: 0.384054
Train loss on 800 batch: 0.444372
Train loss on 850 batch: 0.365888
Train loss on 900 batch: 0.476387
Train loss on 950 batch: 0.440700
Train loss on 1000 batch: 0.389875
Train loss on 1050 batch: 0.424522
Train loss on 1100 batch: 0.383959
Train loss on 1150 batch: 0.408889
Train loss on 1200 batch: 0.360129
Train loss on 1250 batch: 0.443264
Train loss on 1300 batch: 0.386632
Train loss on 1350 batch: 0.402431
Train loss on 1400 batch: 0.422553
Train loss on 1450 batch: 0.412664
Train loss on 1500 batch: 0.444468
Train loss on 1550 batch: 0.436711
Train loss on 1600 batch: 0.429698
Train loss on 1650 batch: 0.362677
Train loss on 1700 batch: 0.347626
Train loss on 1750 batch: 0.395434
Train loss on 1800 batch: 0.345046
Train loss on 1850 batch: 0.361108
Train loss on 1900 batch: 0.400828
best-train-loss: 0.410395
best-valid-loss: 0.426675
best-kappa: 0.6233
: Epoch: 6 | Training Loss: 0.410395 | Val. Loss: 0.426675 | Val. Kappa Score: 0.6233 | LR: 0.000500 | Estimated time: 375.73
Train loss on 50 batch: 0.395128
Train loss on 100 batch: 0.440298
Train loss on 150 batch: 0.414723
Train loss on 200 batch: 0.357089
Train loss on 250 batch: 0.403956
Train loss on 300 batch: 0.449733
Train loss on 350 batch: 0.400109
Train loss on 400 batch: 0.465726
Train loss on 450 batch: 0.380077
Train loss on 500 batch: 0.331100
Train loss on 550 batch: 0.368873
Train loss on 600 batch: 0.501992
Train loss on 650 batch: 0.400492
Train loss on 700 batch: 0.397949
Train loss on 750 batch: 0.336437
Train loss on 800 batch: 0.349836
Train loss on 850 batch: 0.384053
Train loss on 900 batch: 0.382533
Train loss on 950 batch: 0.313750
Train loss on 1000 batch: 0.363550
Train loss on 1050 batch: 0.387413
Train loss on 1100 batch: 0.370903
Train loss on 1150 batch: 0.367421
Train loss on 1200 batch: 0.409150
Train loss on 1250 batch: 0.409002
Train loss on 1300 batch: 0.371634
Train loss on 1350 batch: 0.415964
Train loss on 1400 batch: 0.357863
Train loss on 1450 batch: 0.399885
Train loss on 1500 batch: 0.335186
Train loss on 1550 batch: 0.444846
Train loss on 1600 batch: 0.377747
Train loss on 1650 batch: 0.471033
Train loss on 1700 batch: 0.373613
Train loss on 1750 batch: 0.369512
Train loss on 1800 batch: 0.396985
Train loss on 1850 batch: 0.493933
Train loss on 1900 batch: 0.417455
best-train-loss: 0.393970
best-valid-loss: 0.411883
best-kappa: 0.6335
: Epoch: 7 | Training Loss: 0.393970 | Val. Loss: 0.411883 | Val. Kappa Score: 0.6335 | LR: 0.000500 | Estimated time: 374.77
Train loss on 50 batch: 0.355487
Train loss on 100 batch: 0.304987
Train loss on 150 batch: 0.431935
Train loss on 200 batch: 0.443153
Train loss on 250 batch: 0.346039
Train loss on 300 batch: 0.380341
Train loss on 350 batch: 0.338515
Train loss on 400 batch: 0.417940
Train loss on 450 batch: 0.307985
Train loss on 500 batch: 0.433863
Train loss on 550 batch: 0.393698
Train loss on 600 batch: 0.363730
Train loss on 650 batch: 0.413465
Train loss on 700 batch: 0.390526
Train loss on 750 batch: 0.375746
Train loss on 800 batch: 0.408228
Train loss on 850 batch: 0.364256
Train loss on 900 batch: 0.413241
Train loss on 950 batch: 0.362415
Train loss on 1000 batch: 0.357161
Train loss on 1050 batch: 0.395800
Train loss on 1100 batch: 0.362569
Train loss on 1150 batch: 0.439821
Train loss on 1200 batch: 0.404711
Train loss on 1250 batch: 0.368443
Train loss on 1300 batch: 0.393585
Train loss on 1350 batch: 0.397149
Train loss on 1400 batch: 0.376540
Train loss on 1450 batch: 0.331378
Train loss on 1500 batch: 0.404477
Train loss on 1550 batch: 0.381490
Train loss on 1600 batch: 0.401194
Train loss on 1650 batch: 0.434907
Train loss on 1700 batch: 0.370333
Train loss on 1750 batch: 0.387286
Train loss on 1800 batch: 0.372561
Train loss on 1850 batch: 0.388727
Train loss on 1900 batch: 0.324161
: Epoch: 8 | Training Loss: 0.383890 | Val. Loss: 0.453928 | Val. Kappa Score: 0.6431 | LR: 0.000500 | Estimated time: 375.03
Train loss on 50 batch: 0.366118
Train loss on 100 batch: 0.354003
Train loss on 150 batch: 0.373708
Train loss on 200 batch: 0.337740
Train loss on 250 batch: 0.319621
Train loss on 300 batch: 0.352591
Train loss on 350 batch: 0.331926
Train loss on 400 batch: 0.415356
Train loss on 450 batch: 0.360310
Train loss on 500 batch: 0.353534
Train loss on 550 batch: 0.400683
Train loss on 600 batch: 0.426166
Train loss on 650 batch: 0.400404
Train loss on 700 batch: 0.390488
Train loss on 750 batch: 0.321577
Train loss on 800 batch: 0.382077
Train loss on 850 batch: 0.431416
Train loss on 900 batch: 0.378916
Train loss on 950 batch: 0.314284
Train loss on 1000 batch: 0.334835
Train loss on 1050 batch: 0.391467
Train loss on 1100 batch: 0.422106
Train loss on 1150 batch: 0.385127
Train loss on 1200 batch: 0.421475
Train loss on 1250 batch: 0.305474
Train loss on 1300 batch: 0.347908
Train loss on 1350 batch: 0.382444
Train loss on 1400 batch: 0.371962
Train loss on 1450 batch: 0.432585
Train loss on 1500 batch: 0.368603
Train loss on 1550 batch: 0.380476
Train loss on 1600 batch: 0.405293
Train loss on 1650 batch: 0.432554
Train loss on 1700 batch: 0.406203
Train loss on 1750 batch: 0.347062
Train loss on 1800 batch: 0.348583
Train loss on 1850 batch: 0.339282
Train loss on 1900 batch: 0.342999
: Epoch: 9 | Training Loss: 0.373217 | Val. Loss: 0.552169 | Val. Kappa Score: 0.6499 | LR: 0.000500 | Estimated time: 375.22
Train loss on 50 batch: 0.373472
Train loss on 100 batch: 0.344918
Train loss on 150 batch: 0.327264
Train loss on 200 batch: 0.320818
Train loss on 250 batch: 0.346182
Train loss on 300 batch: 0.366197
Train loss on 350 batch: 0.378304
Train loss on 400 batch: 0.367060
Train loss on 450 batch: 0.362118
Train loss on 500 batch: 0.331860
Train loss on 550 batch: 0.341474
Train loss on 600 batch: 0.332821
Train loss on 650 batch: 0.351332
Train loss on 700 batch: 0.415977
Train loss on 750 batch: 0.394508
Train loss on 800 batch: 0.397996
Train loss on 850 batch: 0.307983
Train loss on 900 batch: 0.335285
Train loss on 950 batch: 0.309828
Train loss on 1000 batch: 0.363196
Train loss on 1050 batch: 0.447955
Train loss on 1100 batch: 0.364548
Train loss on 1150 batch: 0.405126
Train loss on 1200 batch: 0.374357
Train loss on 1250 batch: 0.377160
Train loss on 1300 batch: 0.413746
Train loss on 1350 batch: 0.386765
Train loss on 1400 batch: 0.462026
Train loss on 1450 batch: 0.363433
Train loss on 1500 batch: 0.403102
Train loss on 1550 batch: 0.420042
Train loss on 1600 batch: 0.377544
Train loss on 1650 batch: 0.401348
Train loss on 1700 batch: 0.346173
Train loss on 1750 batch: 0.353290
Train loss on 1800 batch: 0.368850
Train loss on 1850 batch: 0.319085
Train loss on 1900 batch: 0.364679
: Epoch: 10 | Training Loss: 0.368142 | Val. Loss: 0.493205 | Val. Kappa Score: 0.6546 | LR: 0.000250 | Estimated time: 374.53
Train loss on 50 batch: 0.363246
Train loss on 100 batch: 0.317316
Train loss on 150 batch: 0.299283
Train loss on 200 batch: 0.359704
Train loss on 250 batch: 0.319773
Train loss on 300 batch: 0.254544
Train loss on 350 batch: 0.409745
Train loss on 400 batch: 0.317432
Train loss on 450 batch: 0.365808
Train loss on 500 batch: 0.366386
Train loss on 550 batch: 0.297709
Train loss on 600 batch: 0.345774
Train loss on 650 batch: 0.310899
Train loss on 700 batch: 0.428648
Train loss on 750 batch: 0.395915
Train loss on 800 batch: 0.387472
Train loss on 850 batch: 0.428764
Train loss on 900 batch: 0.374053
Train loss on 950 batch: 0.293650
Train loss on 1000 batch: 0.306120
Train loss on 1050 batch: 0.396524
Train loss on 1100 batch: 0.289736
Train loss on 1150 batch: 0.346896
Train loss on 1200 batch: 0.334159
Train loss on 1250 batch: 0.373778
Train loss on 1300 batch: 0.305649
Train loss on 1350 batch: 0.326001
Train loss on 1400 batch: 0.367516
Train loss on 1450 batch: 0.352163
Train loss on 1500 batch: 0.318053
Train loss on 1550 batch: 0.329192
Train loss on 1600 batch: 0.317512
Train loss on 1650 batch: 0.323504
Train loss on 1700 batch: 0.345125
Train loss on 1750 batch: 0.339235
Train loss on 1800 batch: 0.389663
Train loss on 1850 batch: 0.287169
Train loss on 1900 batch: 0.352043
: Epoch: 11 | Training Loss: 0.341670 | Val. Loss: 0.449868 | Val. Kappa Score: 0.6629 | LR: 0.000250 | Estimated time: 375.26
Train loss on 50 batch: 0.383352
Train loss on 100 batch: 0.398659
Train loss on 150 batch: 0.359215
Train loss on 200 batch: 0.329914
Train loss on 250 batch: 0.329157
Train loss on 300 batch: 0.319873
Train loss on 350 batch: 0.278882
Train loss on 400 batch: 0.301980
Train loss on 450 batch: 0.259800
Train loss on 500 batch: 0.308569
Train loss on 550 batch: 0.378774
Train loss on 600 batch: 0.373658
Train loss on 650 batch: 0.299963
Train loss on 700 batch: 0.365411
Train loss on 750 batch: 0.342714
Train loss on 800 batch: 0.274406
Train loss on 850 batch: 0.287379
Train loss on 900 batch: 0.374306
Train loss on 950 batch: 0.311999
Train loss on 1000 batch: 0.350694
Train loss on 1050 batch: 0.360857
Train loss on 1100 batch: 0.310879
Train loss on 1150 batch: 0.340006
Train loss on 1200 batch: 0.344148
Train loss on 1250 batch: 0.321079
Train loss on 1300 batch: 0.336097
Train loss on 1350 batch: 0.327721
Train loss on 1400 batch: 0.331370
Train loss on 1450 batch: 0.375648
Train loss on 1500 batch: 0.342296
Train loss on 1550 batch: 0.324965
Train loss on 1600 batch: 0.352374
Train loss on 1650 batch: 0.312829
Train loss on 1700 batch: 0.300857
Train loss on 1750 batch: 0.326013
Train loss on 1800 batch: 0.317370
Train loss on 1850 batch: 0.360659
Train loss on 1900 batch: 0.350221
best-train-loss: 0.333820
best-valid-loss: 0.362635
best-kappa: 0.6690
: Epoch: 12 | Training Loss: 0.333820 | Val. Loss: 0.362635 | Val. Kappa Score: 0.6690 | LR: 0.000250 | Estimated time: 375.43
Train loss on 50 batch: 0.324760
Train loss on 100 batch: 0.373821
Train loss on 150 batch: 0.337869
Train loss on 200 batch: 0.347983
Train loss on 250 batch: 0.313105
Train loss on 300 batch: 0.374326
Train loss on 350 batch: 0.319717
Train loss on 400 batch: 0.322713
Train loss on 450 batch: 0.271418
Train loss on 500 batch: 0.317921
Train loss on 550 batch: 0.296121
Train loss on 600 batch: 0.334295
Train loss on 650 batch: 0.359136
Train loss on 700 batch: 0.351168
Train loss on 750 batch: 0.326993
Train loss on 800 batch: 0.365478
Train loss on 850 batch: 0.286447
Train loss on 900 batch: 0.392053
Train loss on 950 batch: 0.319358
Train loss on 1000 batch: 0.327039
Train loss on 1050 batch: 0.347490
Train loss on 1100 batch: 0.343309
Train loss on 1150 batch: 0.300239
Train loss on 1200 batch: 0.326501
Train loss on 1250 batch: 0.335575
Train loss on 1300 batch: 0.284757
Train loss on 1350 batch: 0.307165
Train loss on 1400 batch: 0.348482
Train loss on 1450 batch: 0.357991
Train loss on 1500 batch: 0.328725
Train loss on 1550 batch: 0.304306
Train loss on 1600 batch: 0.320773
Train loss on 1650 batch: 0.358129
Train loss on 1700 batch: 0.322102
Train loss on 1750 batch: 0.335048
Train loss on 1800 batch: 0.317875
Train loss on 1850 batch: 0.280614
Train loss on 1900 batch: 0.291198
: Epoch: 13 | Training Loss: 0.330590 | Val. Loss: 0.394470 | Val. Kappa Score: 0.6745 | LR: 0.000250 | Estimated time: 375.17
Train loss on 50 batch: 0.367902
Train loss on 100 batch: 0.352894
Train loss on 150 batch: 0.329897
Train loss on 200 batch: 0.290868
Train loss on 250 batch: 0.336686
Train loss on 300 batch: 0.357939
Train loss on 350 batch: 0.286256
Train loss on 400 batch: 0.338456
Train loss on 450 batch: 0.342682
Train loss on 500 batch: 0.315481
Train loss on 550 batch: 0.337046
Train loss on 600 batch: 0.283249
Train loss on 650 batch: 0.354392
Train loss on 700 batch: 0.330498
Train loss on 750 batch: 0.269548
Train loss on 800 batch: 0.335150
Train loss on 850 batch: 0.361611
Train loss on 900 batch: 0.349372
Train loss on 950 batch: 0.299386
Train loss on 1000 batch: 0.315212
Train loss on 1050 batch: 0.356266
Train loss on 1100 batch: 0.292450
Train loss on 1150 batch: 0.221483
Train loss on 1200 batch: 0.310863
Train loss on 1250 batch: 0.348962
Train loss on 1300 batch: 0.347299
Train loss on 1350 batch: 0.322899
Train loss on 1400 batch: 0.348891
Train loss on 1450 batch: 0.359480
Train loss on 1500 batch: 0.302680
Train loss on 1550 batch: 0.272036
Train loss on 1600 batch: 0.280314
Train loss on 1650 batch: 0.357806
Train loss on 1700 batch: 0.312405
Train loss on 1750 batch: 0.267235
Train loss on 1800 batch: 0.372584
Train loss on 1850 batch: 0.308234
Train loss on 1900 batch: 0.395149
: Epoch: 14 | Training Loss: 0.323377 | Val. Loss: 0.424436 | Val. Kappa Score: 0.6798 | LR: 0.000250 | Estimated time: 374.24
Train loss on 50 batch: 0.289412
Train loss on 100 batch: 0.311900
Train loss on 150 batch: 0.285201
Train loss on 200 batch: 0.377103
Train loss on 250 batch: 0.327205
Train loss on 300 batch: 0.292823
Train loss on 350 batch: 0.360738
Train loss on 400 batch: 0.307094
Train loss on 450 batch: 0.345953
Train loss on 500 batch: 0.309044
Train loss on 550 batch: 0.365128
Train loss on 600 batch: 0.311239
Train loss on 650 batch: 0.318958
Train loss on 700 batch: 0.295741
Train loss on 750 batch: 0.305964
Train loss on 800 batch: 0.339985
Train loss on 850 batch: 0.365205
Train loss on 900 batch: 0.341546
Train loss on 950 batch: 0.334218
Train loss on 1000 batch: 0.316259
Train loss on 1050 batch: 0.344872
Train loss on 1100 batch: 0.327515
Train loss on 1150 batch: 0.292410
Train loss on 1200 batch: 0.295856
Train loss on 1250 batch: 0.304220
Train loss on 1300 batch: 0.389065
Train loss on 1350 batch: 0.316891
Train loss on 1400 batch: 0.355272
Train loss on 1450 batch: 0.317554
Train loss on 1500 batch: 0.289832
Train loss on 1550 batch: 0.271375
Train loss on 1600 batch: 0.314208
Train loss on 1650 batch: 0.333379
Train loss on 1700 batch: 0.250912
Train loss on 1750 batch: 0.279845
Train loss on 1800 batch: 0.326967
Train loss on 1850 batch: 0.339439
Train loss on 1900 batch: 0.376480
best-train-loss: 0.320827
best-valid-loss: 0.358048
best-kappa: 0.6834
: Epoch: 15 | Training Loss: 0.320827 | Val. Loss: 0.358048 | Val. Kappa Score: 0.6834 | LR: 0.000250 | Estimated time: 374.19
Train loss on 50 batch: 0.301256
Train loss on 100 batch: 0.294914
Train loss on 150 batch: 0.397482
Train loss on 200 batch: 0.300648
Train loss on 250 batch: 0.305798
Train loss on 300 batch: 0.302877
Train loss on 350 batch: 0.292486
Train loss on 400 batch: 0.302008
Train loss on 450 batch: 0.275264
Train loss on 500 batch: 0.373284
Train loss on 550 batch: 0.307560
Train loss on 600 batch: 0.360772
Train loss on 650 batch: 0.334476
Train loss on 700 batch: 0.246251
Train loss on 750 batch: 0.299870
Train loss on 800 batch: 0.337929
Train loss on 850 batch: 0.331042
Train loss on 900 batch: 0.347880
Train loss on 950 batch: 0.330325
Train loss on 1000 batch: 0.314736
Train loss on 1050 batch: 0.352369
Train loss on 1100 batch: 0.320011
Train loss on 1150 batch: 0.327682
Train loss on 1200 batch: 0.272268
Train loss on 1250 batch: 0.282794
Train loss on 1300 batch: 0.282287
Train loss on 1350 batch: 0.287475
Train loss on 1400 batch: 0.302300
Train loss on 1450 batch: 0.264435
Train loss on 1500 batch: 0.336189
Train loss on 1550 batch: 0.338806
Train loss on 1600 batch: 0.299044
Train loss on 1650 batch: 0.293710
Train loss on 1700 batch: 0.402382
Train loss on 1750 batch: 0.330902
Train loss on 1800 batch: 0.318504
Train loss on 1850 batch: 0.332508
Train loss on 1900 batch: 0.304579
best-train-loss: 0.317813
best-valid-loss: 0.340910
best-kappa: 0.6859
: Epoch: 16 | Training Loss: 0.317813 | Val. Loss: 0.340910 | Val. Kappa Score: 0.6859 | LR: 0.000250 | Estimated time: 374.22
Train loss on 50 batch: 0.294782
Train loss on 100 batch: 0.298653
Train loss on 150 batch: 0.392448
Train loss on 200 batch: 0.320866
Train loss on 250 batch: 0.329399
Train loss on 300 batch: 0.311146
Train loss on 350 batch: 0.373378
Train loss on 400 batch: 0.349377
Train loss on 450 batch: 0.273680
Train loss on 500 batch: 0.292155
Train loss on 550 batch: 0.286093
Train loss on 600 batch: 0.281512
Train loss on 650 batch: 0.286883
Train loss on 700 batch: 0.372796
Train loss on 750 batch: 0.324650
Train loss on 800 batch: 0.307603
Train loss on 850 batch: 0.335240
Train loss on 900 batch: 0.332985
Train loss on 950 batch: 0.297934
Train loss on 1000 batch: 0.376706
Train loss on 1050 batch: 0.340256
Train loss on 1100 batch: 0.357887
Train loss on 1150 batch: 0.260289
Train loss on 1200 batch: 0.296047
Train loss on 1250 batch: 0.263397
Train loss on 1300 batch: 0.280930
Train loss on 1350 batch: 0.256493
Train loss on 1400 batch: 0.334277
Train loss on 1450 batch: 0.336887
Train loss on 1500 batch: 0.333893
Train loss on 1550 batch: 0.338312
Train loss on 1600 batch: 0.298869
Train loss on 1650 batch: 0.336696
Train loss on 1700 batch: 0.340560
Train loss on 1750 batch: 0.346019
Train loss on 1800 batch: 0.280108
Train loss on 1850 batch: 0.356689
Train loss on 1900 batch: 0.296185
: Epoch: 17 | Training Loss: 0.317335 | Val. Loss: 0.363287 | Val. Kappa Score: 0.6891 | LR: 0.000250 | Estimated time: 374.88
Train loss on 50 batch: 0.306186
Train loss on 100 batch: 0.260756
Train loss on 150 batch: 0.300903
Train loss on 200 batch: 0.298227
Train loss on 250 batch: 0.342978
Train loss on 300 batch: 0.286212
Train loss on 350 batch: 0.271643
Train loss on 400 batch: 0.293182
Train loss on 450 batch: 0.342439
Train loss on 500 batch: 0.318367
Train loss on 550 batch: 0.324354
Train loss on 600 batch: 0.279235
Train loss on 650 batch: 0.268572
Train loss on 700 batch: 0.281771
Train loss on 750 batch: 0.298793
Train loss on 800 batch: 0.322625
Train loss on 850 batch: 0.316536
Train loss on 900 batch: 0.335084
Train loss on 950 batch: 0.295680
Train loss on 1000 batch: 0.284129
Train loss on 1050 batch: 0.344120
Train loss on 1100 batch: 0.341323
Train loss on 1150 batch: 0.264247
Train loss on 1200 batch: 0.318781
Train loss on 1250 batch: 0.329769
Train loss on 1300 batch: 0.277250
Train loss on 1350 batch: 0.355612
Train loss on 1400 batch: 0.317836
Train loss on 1450 batch: 0.348667
Train loss on 1500 batch: 0.327447
Train loss on 1550 batch: 0.316987
Train loss on 1600 batch: 0.263119
Train loss on 1650 batch: 0.264949
Train loss on 1700 batch: 0.380786
Train loss on 1750 batch: 0.310513
Train loss on 1800 batch: 0.299403
Train loss on 1850 batch: 0.311305
Train loss on 1900 batch: 0.329557
: Epoch: 18 | Training Loss: 0.309460 | Val. Loss: 0.356447 | Val. Kappa Score: 0.6920 | LR: 0.000250 | Estimated time: 373.88
Train loss on 50 batch: 0.246677
Train loss on 100 batch: 0.278994
Train loss on 150 batch: 0.324105
Train loss on 200 batch: 0.297809
Train loss on 250 batch: 0.352550
Train loss on 300 batch: 0.339828
Train loss on 350 batch: 0.310050
Train loss on 400 batch: 0.286954
Train loss on 450 batch: 0.319742
Train loss on 500 batch: 0.298204
Train loss on 550 batch: 0.236805
Train loss on 600 batch: 0.351860
Train loss on 650 batch: 0.328353
Train loss on 700 batch: 0.269315
Train loss on 750 batch: 0.267719
Train loss on 800 batch: 0.278359
Train loss on 850 batch: 0.340115
Train loss on 900 batch: 0.316758
Train loss on 950 batch: 0.285387
Train loss on 1000 batch: 0.350778
Train loss on 1050 batch: 0.329100
Train loss on 1100 batch: 0.286675
Train loss on 1150 batch: 0.241095
Train loss on 1200 batch: 0.286285
Train loss on 1250 batch: 0.310943
Train loss on 1300 batch: 0.343770
Train loss on 1350 batch: 0.333593
Train loss on 1400 batch: 0.329532
Train loss on 1450 batch: 0.262710
Train loss on 1500 batch: 0.288563
Train loss on 1550 batch: 0.269016
Train loss on 1600 batch: 0.264340
Train loss on 1650 batch: 0.300635
Train loss on 1700 batch: 0.305632
Train loss on 1750 batch: 0.294319
Train loss on 1800 batch: 0.370441
Train loss on 1850 batch: 0.301201
Train loss on 1900 batch: 0.319541
: Epoch: 19 | Training Loss: 0.305039 | Val. Loss: 0.354682 | Val. Kappa Score: 0.6947 | LR: 0.000125 | Estimated time: 374.48
Train loss on 50 batch: 0.254460
Train loss on 100 batch: 0.369488
Train loss on 150 batch: 0.288371
Train loss on 200 batch: 0.293164
Train loss on 250 batch: 0.285959
Train loss on 300 batch: 0.283689
Train loss on 350 batch: 0.262041
Train loss on 400 batch: 0.305516
Train loss on 450 batch: 0.303120
Train loss on 500 batch: 0.275505
Train loss on 550 batch: 0.308240
Train loss on 600 batch: 0.281290
Train loss on 650 batch: 0.357455
Train loss on 700 batch: 0.267968
Train loss on 750 batch: 0.302732
Train loss on 800 batch: 0.273058
Train loss on 850 batch: 0.332613
Train loss on 900 batch: 0.287847
Train loss on 950 batch: 0.262482
Train loss on 1000 batch: 0.273973
Train loss on 1050 batch: 0.318011
Train loss on 1100 batch: 0.303191
Train loss on 1150 batch: 0.299795
Train loss on 1200 batch: 0.278208
Train loss on 1250 batch: 0.234518
Train loss on 1300 batch: 0.245801
Train loss on 1350 batch: 0.226517
Train loss on 1400 batch: 0.303694
Train loss on 1450 batch: 0.224237
Train loss on 1500 batch: 0.283500
Train loss on 1550 batch: 0.318918
Train loss on 1600 batch: 0.317595
Train loss on 1650 batch: 0.277376
Train loss on 1700 batch: 0.287814
Train loss on 1750 batch: 0.294710
Train loss on 1800 batch: 0.300165
Train loss on 1850 batch: 0.300257
Train loss on 1900 batch: 0.319775
: Epoch: 20 | Training Loss: 0.289408 | Val. Loss: 0.348235 | Val. Kappa Score: 0.6967 | LR: 0.000125 | Estimated time: 379.28
Train loss on 50 batch: 0.262592
Train loss on 100 batch: 0.268740
Train loss on 150 batch: 0.289552
Train loss on 200 batch: 0.328265
Train loss on 250 batch: 0.261693
Train loss on 300 batch: 0.286205
Train loss on 350 batch: 0.276385
Train loss on 400 batch: 0.323663
Train loss on 450 batch: 0.297443
Train loss on 500 batch: 0.267647
Train loss on 550 batch: 0.275371
Train loss on 600 batch: 0.354140
Train loss on 650 batch: 0.267042
Train loss on 700 batch: 0.276489
Train loss on 750 batch: 0.251359
Train loss on 800 batch: 0.279781
Train loss on 850 batch: 0.295408
Train loss on 900 batch: 0.339815
Train loss on 950 batch: 0.268994
Train loss on 1000 batch: 0.280854
Train loss on 1050 batch: 0.243275
Train loss on 1100 batch: 0.323168
Train loss on 1150 batch: 0.278977
Train loss on 1200 batch: 0.288233
Train loss on 1250 batch: 0.269748
Train loss on 1300 batch: 0.263283
Train loss on 1350 batch: 0.305657
Train loss on 1400 batch: 0.283667
Train loss on 1450 batch: 0.300536
Train loss on 1500 batch: 0.281117
Train loss on 1550 batch: 0.268052
Train loss on 1600 batch: 0.285009
Train loss on 1650 batch: 0.244360
Train loss on 1700 batch: 0.362407
Train loss on 1750 batch: 0.313844
Train loss on 1800 batch: 0.224755
Train loss on 1850 batch: 0.264969
Train loss on 1900 batch: 0.300040
best-train-loss: 0.286343
best-valid-loss: 0.329147
best-kappa: 0.6992
: Epoch: 21 | Training Loss: 0.286343 | Val. Loss: 0.329147 | Val. Kappa Score: 0.6992 | LR: 0.000125 | Estimated time: 381.10
Train loss on 50 batch: 0.251679
Train loss on 100 batch: 0.309405
Train loss on 150 batch: 0.324076
Train loss on 200 batch: 0.283786
Train loss on 250 batch: 0.264293
Train loss on 300 batch: 0.268350
Train loss on 350 batch: 0.266913
Train loss on 400 batch: 0.312552
Train loss on 450 batch: 0.315074
Train loss on 500 batch: 0.258444
Train loss on 550 batch: 0.259933
Train loss on 600 batch: 0.280763
Train loss on 650 batch: 0.293562
Train loss on 700 batch: 0.309837
Train loss on 750 batch: 0.285941
Train loss on 800 batch: 0.228640
Train loss on 850 batch: 0.280930
Train loss on 900 batch: 0.312254
Train loss on 950 batch: 0.226743
Train loss on 1000 batch: 0.300981
Train loss on 1050 batch: 0.292091
Train loss on 1100 batch: 0.252023
Train loss on 1150 batch: 0.324222
Train loss on 1200 batch: 0.322966
Train loss on 1250 batch: 0.240079
Train loss on 1300 batch: 0.268258
Train loss on 1350 batch: 0.285822
Train loss on 1400 batch: 0.283412
Train loss on 1450 batch: 0.306356
Train loss on 1500 batch: 0.333067
Train loss on 1550 batch: 0.276955
Train loss on 1600 batch: 0.269582
Train loss on 1650 batch: 0.253465
Train loss on 1700 batch: 0.280502
Train loss on 1750 batch: 0.252480
Train loss on 1800 batch: 0.296912
Train loss on 1850 batch: 0.296850
Train loss on 1900 batch: 0.303173
: Epoch: 22 | Training Loss: 0.284333 | Val. Loss: 0.335123 | Val. Kappa Score: 0.7021 | LR: 0.000125 | Estimated time: 375.02
Train loss on 50 batch: 0.227080
Train loss on 100 batch: 0.253292
Train loss on 150 batch: 0.243163
Train loss on 200 batch: 0.297820
Train loss on 250 batch: 0.288004
Train loss on 300 batch: 0.282983
Train loss on 350 batch: 0.278908
Train loss on 400 batch: 0.308322
Train loss on 450 batch: 0.305416
Train loss on 500 batch: 0.250799
Train loss on 550 batch: 0.293495
Train loss on 600 batch: 0.301514
Train loss on 650 batch: 0.274395
Train loss on 700 batch: 0.299075
Train loss on 750 batch: 0.253057
Train loss on 800 batch: 0.303225
Train loss on 850 batch: 0.317213
Train loss on 900 batch: 0.267479
Train loss on 950 batch: 0.275882
Train loss on 1000 batch: 0.271642
Train loss on 1050 batch: 0.281049
Train loss on 1100 batch: 0.301383
Train loss on 1150 batch: 0.348645
Train loss on 1200 batch: 0.258044
Train loss on 1250 batch: 0.330761
Train loss on 1300 batch: 0.270714
Train loss on 1350 batch: 0.284419
Train loss on 1400 batch: 0.277211
Train loss on 1450 batch: 0.253489
Train loss on 1500 batch: 0.232992
Train loss on 1550 batch: 0.312842
Train loss on 1600 batch: 0.241008
Train loss on 1650 batch: 0.286582
Train loss on 1700 batch: 0.280246
Train loss on 1750 batch: 0.245066
Train loss on 1800 batch: 0.299520
Train loss on 1850 batch: 0.260186
Train loss on 1900 batch: 0.268509
: Epoch: 23 | Training Loss: 0.279859 | Val. Loss: 0.339763 | Val. Kappa Score: 0.7037 | LR: 0.000125 | Estimated time: 374.40
Train loss on 50 batch: 0.256524
Train loss on 100 batch: 0.257404
Train loss on 150 batch: 0.276142
Train loss on 200 batch: 0.292347
Train loss on 250 batch: 0.226171
Train loss on 300 batch: 0.226691
Train loss on 350 batch: 0.314839
Train loss on 400 batch: 0.236394
Train loss on 450 batch: 0.267414
Train loss on 500 batch: 0.272866
Train loss on 550 batch: 0.255189
Train loss on 600 batch: 0.277341
Train loss on 650 batch: 0.277108
Train loss on 700 batch: 0.240698
Train loss on 750 batch: 0.272859
Train loss on 800 batch: 0.343635
Train loss on 850 batch: 0.278800
Train loss on 900 batch: 0.294644
Train loss on 950 batch: 0.277379
Train loss on 1000 batch: 0.255604
Train loss on 1050 batch: 0.287549
Train loss on 1100 batch: 0.296299
Train loss on 1150 batch: 0.323803
Train loss on 1200 batch: 0.291766
Train loss on 1250 batch: 0.286021
Train loss on 1300 batch: 0.312513
Train loss on 1350 batch: 0.268856
Train loss on 1400 batch: 0.279795
Train loss on 1450 batch: 0.273688
Train loss on 1500 batch: 0.310551
Train loss on 1550 batch: 0.296879
Train loss on 1600 batch: 0.337985
Train loss on 1650 batch: 0.268916
Train loss on 1700 batch: 0.338586
Train loss on 1750 batch: 0.287235
Train loss on 1800 batch: 0.326162
Train loss on 1850 batch: 0.245537
Train loss on 1900 batch: 0.268466
: Epoch: 24 | Training Loss: 0.281452 | Val. Loss: 0.344031 | Val. Kappa Score: 0.7054 | LR: 0.000063 | Estimated time: 374.48
Train loss on 50 batch: 0.278886
Train loss on 100 batch: 0.259757
Train loss on 150 batch: 0.273087
Train loss on 200 batch: 0.252750
Train loss on 250 batch: 0.278446
Train loss on 300 batch: 0.248315
Train loss on 350 batch: 0.261162
Train loss on 400 batch: 0.248314
Train loss on 450 batch: 0.233572
Train loss on 500 batch: 0.249724
Train loss on 550 batch: 0.279099
Train loss on 600 batch: 0.265761
Train loss on 650 batch: 0.308665
Train loss on 700 batch: 0.264724
Train loss on 750 batch: 0.243593
Train loss on 800 batch: 0.285694
Train loss on 850 batch: 0.258981
Train loss on 900 batch: 0.229568
Train loss on 950 batch: 0.270360
Train loss on 1000 batch: 0.284839
Train loss on 1050 batch: 0.307197
Train loss on 1100 batch: 0.255809
Train loss on 1150 batch: 0.259719
Train loss on 1200 batch: 0.237672
Train loss on 1250 batch: 0.278623
Train loss on 1300 batch: 0.258074
Train loss on 1350 batch: 0.294645
Train loss on 1400 batch: 0.298538
Train loss on 1450 batch: 0.281192
Train loss on 1500 batch: 0.289039
Train loss on 1550 batch: 0.256238
Train loss on 1600 batch: 0.258668
Train loss on 1650 batch: 0.263536
Train loss on 1700 batch: 0.320658
Train loss on 1750 batch: 0.238149
Train loss on 1800 batch: 0.280316
Train loss on 1850 batch: 0.277360
Train loss on 1900 batch: 0.279548
best-train-loss: 0.268595
best-valid-loss: 0.324008
best-kappa: 0.7074
: Epoch: 25 | Training Loss: 0.268595 | Val. Loss: 0.324008 | Val. Kappa Score: 0.7074 | LR: 0.000063 | Estimated time: 374.64
Train loss on 50 batch: 0.231638
Train loss on 100 batch: 0.258258
Train loss on 150 batch: 0.242073
Train loss on 200 batch: 0.265777
Train loss on 250 batch: 0.257463
Train loss on 300 batch: 0.271654
Train loss on 350 batch: 0.270941
Train loss on 400 batch: 0.261581
Train loss on 450 batch: 0.266317
Train loss on 500 batch: 0.291645
Train loss on 550 batch: 0.238207
Train loss on 600 batch: 0.244560
Train loss on 650 batch: 0.267113
Train loss on 700 batch: 0.262310
Train loss on 750 batch: 0.236644
Train loss on 800 batch: 0.255164
Train loss on 850 batch: 0.301847
Train loss on 900 batch: 0.263187
Train loss on 950 batch: 0.288255
Train loss on 1000 batch: 0.270055
Train loss on 1050 batch: 0.259059
Train loss on 1100 batch: 0.267477
Train loss on 1150 batch: 0.275679
Train loss on 1200 batch: 0.290678
Train loss on 1250 batch: 0.261660
Train loss on 1300 batch: 0.204320
Train loss on 1350 batch: 0.301059
Train loss on 1400 batch: 0.260010
Train loss on 1450 batch: 0.245249
Train loss on 1500 batch: 0.310574
Train loss on 1550 batch: 0.273257
Train loss on 1600 batch: 0.248719
Train loss on 1650 batch: 0.324772
Train loss on 1700 batch: 0.268143
Train loss on 1750 batch: 0.293020
Train loss on 1800 batch: 0.283227
Train loss on 1850 batch: 0.244777
Train loss on 1900 batch: 0.277863
best-train-loss: 0.266646
best-valid-loss: 0.315483
best-kappa: 0.7094
: Epoch: 26 | Training Loss: 0.266646 | Val. Loss: 0.315483 | Val. Kappa Score: 0.7094 | LR: 0.000063 | Estimated time: 374.83
Train loss on 50 batch: 0.257955
Train loss on 100 batch: 0.245419
Train loss on 150 batch: 0.311010
Train loss on 200 batch: 0.286835
Train loss on 250 batch: 0.250015
Train loss on 300 batch: 0.303755
Train loss on 350 batch: 0.263780
Train loss on 400 batch: 0.264767
Train loss on 450 batch: 0.261971
Train loss on 500 batch: 0.238425
Train loss on 550 batch: 0.303521
Train loss on 600 batch: 0.275636
Train loss on 650 batch: 0.297223
Train loss on 700 batch: 0.298429
Train loss on 750 batch: 0.281408
Train loss on 800 batch: 0.276776
Train loss on 850 batch: 0.290006
Train loss on 900 batch: 0.273414
Train loss on 950 batch: 0.261834
Train loss on 1000 batch: 0.239491
Train loss on 1050 batch: 0.290689
Train loss on 1100 batch: 0.250232
Train loss on 1150 batch: 0.273804
Train loss on 1200 batch: 0.253502
Train loss on 1250 batch: 0.336374
Train loss on 1300 batch: 0.280356
Train loss on 1350 batch: 0.213937
Train loss on 1400 batch: 0.228245
Train loss on 1450 batch: 0.276348
Train loss on 1500 batch: 0.253398
Train loss on 1550 batch: 0.234735
Train loss on 1600 batch: 0.223502
Train loss on 1650 batch: 0.236939
Train loss on 1700 batch: 0.266179
Train loss on 1750 batch: 0.227278
Train loss on 1800 batch: 0.249189
Train loss on 1850 batch: 0.269580
Train loss on 1900 batch: 0.225182
: Epoch: 27 | Training Loss: 0.264315 | Val. Loss: 0.319660 | Val. Kappa Score: 0.7112 | LR: 0.000063 | Estimated time: 374.63
Train loss on 50 batch: 0.276477
Train loss on 100 batch: 0.235734
Train loss on 150 batch: 0.253664
Train loss on 200 batch: 0.240064
Train loss on 250 batch: 0.267384
Train loss on 300 batch: 0.278601
Train loss on 350 batch: 0.300543
Train loss on 400 batch: 0.226348
Train loss on 450 batch: 0.267382
Train loss on 500 batch: 0.267770
Train loss on 550 batch: 0.256293
Train loss on 600 batch: 0.293826
Train loss on 650 batch: 0.250248
Train loss on 700 batch: 0.261944
Train loss on 750 batch: 0.254954
Train loss on 800 batch: 0.271009
Train loss on 850 batch: 0.292751
Train loss on 900 batch: 0.257434
Train loss on 950 batch: 0.304630
Train loss on 1000 batch: 0.274878
Train loss on 1050 batch: 0.250274
Train loss on 1100 batch: 0.243064
Train loss on 1150 batch: 0.232331
Train loss on 1200 batch: 0.266565
Train loss on 1250 batch: 0.256114
Train loss on 1300 batch: 0.226252
Train loss on 1350 batch: 0.258549
Train loss on 1400 batch: 0.265642
Train loss on 1450 batch: 0.306242
Train loss on 1500 batch: 0.247243
Train loss on 1550 batch: 0.256479
Train loss on 1600 batch: 0.328547
Train loss on 1650 batch: 0.244755
Train loss on 1700 batch: 0.276892
Train loss on 1750 batch: 0.274984
Train loss on 1800 batch: 0.231025
Train loss on 1850 batch: 0.269761
Train loss on 1900 batch: 0.219739
: Epoch: 28 | Training Loss: 0.262728 | Val. Loss: 0.330290 | Val. Kappa Score: 0.7132 | LR: 0.000063 | Estimated time: 374.81
Train loss on 50 batch: 0.247020
Train loss on 100 batch: 0.272176
Train loss on 150 batch: 0.272439
Train loss on 200 batch: 0.218634
Train loss on 250 batch: 0.272901
Train loss on 300 batch: 0.265571
Train loss on 350 batch: 0.265557
Train loss on 400 batch: 0.268565
Train loss on 450 batch: 0.298649
Train loss on 500 batch: 0.209169
Train loss on 550 batch: 0.191301
Train loss on 600 batch: 0.259393
Train loss on 650 batch: 0.236052
Train loss on 700 batch: 0.262297
Train loss on 750 batch: 0.255736
Train loss on 800 batch: 0.289889
Train loss on 850 batch: 0.301904
Train loss on 900 batch: 0.278578
Train loss on 950 batch: 0.283968
Train loss on 1000 batch: 0.245669
Train loss on 1050 batch: 0.234388
Train loss on 1100 batch: 0.285953
Train loss on 1150 batch: 0.254146
Train loss on 1200 batch: 0.313916
Train loss on 1250 batch: 0.277314
Train loss on 1300 batch: 0.290973
Train loss on 1350 batch: 0.276123
Train loss on 1400 batch: 0.267214
Train loss on 1450 batch: 0.282705
Train loss on 1500 batch: 0.248071
Train loss on 1550 batch: 0.227115
Train loss on 1600 batch: 0.261103
Train loss on 1650 batch: 0.250894
Train loss on 1700 batch: 0.235956
Train loss on 1750 batch: 0.272693
Train loss on 1800 batch: 0.257198
Train loss on 1850 batch: 0.229274
Train loss on 1900 batch: 0.242366
best-train-loss: 0.261123
best-valid-loss: 0.314917
best-kappa: 0.7151
: Epoch: 29 | Training Loss: 0.261123 | Val. Loss: 0.314917 | Val. Kappa Score: 0.7151 | LR: 0.000063 | Estimated time: 374.00
Train loss on 50 batch: 0.262999
Train loss on 100 batch: 0.232810
Train loss on 150 batch: 0.227977
Train loss on 200 batch: 0.239491
Train loss on 250 batch: 0.310152
Train loss on 300 batch: 0.280865
Train loss on 350 batch: 0.285513
Train loss on 400 batch: 0.299455
Train loss on 450 batch: 0.296557
Train loss on 500 batch: 0.268107
Train loss on 550 batch: 0.295592
Train loss on 600 batch: 0.271378
Train loss on 650 batch: 0.252839
Train loss on 700 batch: 0.247512
Train loss on 750 batch: 0.263974
Train loss on 800 batch: 0.217445
Train loss on 850 batch: 0.270453
Train loss on 900 batch: 0.244361
Train loss on 950 batch: 0.225008
Train loss on 1000 batch: 0.312581
Train loss on 1050 batch: 0.243827
Train loss on 1100 batch: 0.281794
Train loss on 1150 batch: 0.273569
Train loss on 1200 batch: 0.273769
Train loss on 1250 batch: 0.235234
Train loss on 1300 batch: 0.248576
Train loss on 1350 batch: 0.251159
Train loss on 1400 batch: 0.256053
Train loss on 1450 batch: 0.289829
Train loss on 1500 batch: 0.236280
Train loss on 1550 batch: 0.212614
Train loss on 1600 batch: 0.264625
Train loss on 1650 batch: 0.254037
Train loss on 1700 batch: 0.295262
Train loss on 1750 batch: 0.239868
Train loss on 1800 batch: 0.207662
Train loss on 1850 batch: 0.266940
Train loss on 1900 batch: 0.247805
best-train-loss: 0.259898
best-valid-loss: 0.308270
best-kappa: 0.7169
: Epoch: 30 | Training Loss: 0.259898 | Val. Loss: 0.308270 | Val. Kappa Score: 0.7169 | LR: 0.000063 | Estimated time: 374.60
Train loss on 50 batch: 0.326245
Train loss on 100 batch: 0.293627
Train loss on 150 batch: 0.267322
Train loss on 200 batch: 0.253092
Train loss on 250 batch: 0.218314
Train loss on 300 batch: 0.275933
Train loss on 350 batch: 0.282755
Train loss on 400 batch: 0.223916
Train loss on 450 batch: 0.249146
Train loss on 500 batch: 0.302328
Train loss on 550 batch: 0.218993
Train loss on 600 batch: 0.254094
Train loss on 650 batch: 0.259287
Train loss on 700 batch: 0.274770
Train loss on 750 batch: 0.243470
Train loss on 800 batch: 0.257894
Train loss on 850 batch: 0.243931
Train loss on 900 batch: 0.239346
Train loss on 950 batch: 0.230724
Train loss on 1000 batch: 0.278840
Train loss on 1050 batch: 0.253102
Train loss on 1100 batch: 0.311400
Train loss on 1150 batch: 0.223204
Train loss on 1200 batch: 0.280315
Train loss on 1250 batch: 0.215814
Train loss on 1300 batch: 0.272110
Train loss on 1350 batch: 0.283281
Train loss on 1400 batch: 0.323388
Train loss on 1450 batch: 0.244462
Train loss on 1500 batch: 0.291019
Train loss on 1550 batch: 0.284851
Train loss on 1600 batch: 0.263296
Train loss on 1650 batch: 0.236152
Train loss on 1700 batch: 0.242404
Train loss on 1750 batch: 0.246491
Train loss on 1800 batch: 0.209205
Train loss on 1850 batch: 0.240990
Train loss on 1900 batch: 0.266951
: Epoch: 31 | Training Loss: 0.260637 | Val. Loss: 0.342748 | Val. Kappa Score: 0.7183 | LR: 0.000063 | Estimated time: 374.40
Train loss on 50 batch: 0.243108
Train loss on 100 batch: 0.291342
Train loss on 150 batch: 0.266560
Train loss on 200 batch: 0.249848
Train loss on 250 batch: 0.258790
Train loss on 300 batch: 0.241557
Train loss on 350 batch: 0.251271
Train loss on 400 batch: 0.293375
Train loss on 450 batch: 0.238608
Train loss on 500 batch: 0.302922
Train loss on 550 batch: 0.244096
Train loss on 600 batch: 0.304939
Train loss on 650 batch: 0.297019
Train loss on 700 batch: 0.273915
Train loss on 750 batch: 0.228897
Train loss on 800 batch: 0.267615
Train loss on 850 batch: 0.275914
Train loss on 900 batch: 0.242752
Train loss on 950 batch: 0.274116
Train loss on 1000 batch: 0.267304
Train loss on 1050 batch: 0.293250
Train loss on 1100 batch: 0.257932
Train loss on 1150 batch: 0.245525
Train loss on 1200 batch: 0.211509
Train loss on 1250 batch: 0.287205
Train loss on 1300 batch: 0.225768
Train loss on 1350 batch: 0.269516
Train loss on 1400 batch: 0.279668
Train loss on 1450 batch: 0.241164
Train loss on 1500 batch: 0.227274
Train loss on 1550 batch: 0.279150
Train loss on 1600 batch: 0.248913
Train loss on 1650 batch: 0.274776
Train loss on 1700 batch: 0.258706
Train loss on 1750 batch: 0.264392
Train loss on 1800 batch: 0.239747
Train loss on 1850 batch: 0.244608
Train loss on 1900 batch: 0.237400
: Epoch: 32 | Training Loss: 0.259441 | Val. Loss: 0.312660 | Val. Kappa Score: 0.7194 | LR: 0.000063 | Estimated time: 374.89
Train loss on 50 batch: 0.230347
Train loss on 100 batch: 0.280971
Train loss on 150 batch: 0.250283
Train loss on 200 batch: 0.264374
Train loss on 250 batch: 0.282725
Train loss on 300 batch: 0.245938
Train loss on 350 batch: 0.265994
Train loss on 400 batch: 0.215705
Train loss on 450 batch: 0.236307
Train loss on 500 batch: 0.240194
Train loss on 550 batch: 0.228266
Train loss on 600 batch: 0.275131
Train loss on 650 batch: 0.280833
Train loss on 700 batch: 0.274699
Train loss on 750 batch: 0.241776
Train loss on 800 batch: 0.283684
Train loss on 850 batch: 0.292895
Train loss on 900 batch: 0.296538
Train loss on 950 batch: 0.236806
Train loss on 1000 batch: 0.242774
Train loss on 1050 batch: 0.232852
Train loss on 1100 batch: 0.246563
Train loss on 1150 batch: 0.270107
Train loss on 1200 batch: 0.209394
Train loss on 1250 batch: 0.235308
Train loss on 1300 batch: 0.247509
Train loss on 1350 batch: 0.256635
Train loss on 1400 batch: 0.260385
Train loss on 1450 batch: 0.318200
Train loss on 1500 batch: 0.336845
Train loss on 1550 batch: 0.265617
Train loss on 1600 batch: 0.252181
Train loss on 1650 batch: 0.275383
Train loss on 1700 batch: 0.215110
Train loss on 1750 batch: 0.260858
Train loss on 1800 batch: 0.237440
Train loss on 1850 batch: 0.251190
Train loss on 1900 batch: 0.256961
: Epoch: 33 | Training Loss: 0.257137 | Val. Loss: 0.309028 | Val. Kappa Score: 0.7207 | LR: 0.000031 | Estimated time: 375.43
Train loss on 50 batch: 0.243437
Train loss on 100 batch: 0.282532
Train loss on 150 batch: 0.280480
Train loss on 200 batch: 0.258188
Train loss on 250 batch: 0.211116
Train loss on 300 batch: 0.262107
Train loss on 350 batch: 0.219949
Train loss on 400 batch: 0.234892
Train loss on 450 batch: 0.201649
Train loss on 500 batch: 0.257050
Train loss on 550 batch: 0.258276
Train loss on 600 batch: 0.284661
Train loss on 650 batch: 0.280137
Train loss on 700 batch: 0.248172
Train loss on 750 batch: 0.243333
Train loss on 800 batch: 0.264298
Train loss on 850 batch: 0.248496
Train loss on 900 batch: 0.303085
Train loss on 950 batch: 0.271614
Train loss on 1000 batch: 0.314963
Train loss on 1050 batch: 0.264382
Train loss on 1100 batch: 0.285605
Train loss on 1150 batch: 0.244625
Train loss on 1200 batch: 0.269100
Train loss on 1250 batch: 0.279355
Train loss on 1300 batch: 0.227917
Train loss on 1350 batch: 0.245977
Train loss on 1400 batch: 0.258894
Train loss on 1450 batch: 0.253701
Train loss on 1500 batch: 0.218057
Train loss on 1550 batch: 0.262394
Train loss on 1600 batch: 0.221937
Train loss on 1650 batch: 0.195281
Train loss on 1700 batch: 0.225369
Train loss on 1750 batch: 0.242404
Train loss on 1800 batch: 0.261208
Train loss on 1850 batch: 0.195054
Train loss on 1900 batch: 0.250421
: Epoch: 34 | Training Loss: 0.251705 | Val. Loss: 0.319332 | Val. Kappa Score: 0.7218 | LR: 0.000031 | Estimated time: 375.39
Train loss on 50 batch: 0.186507
Train loss on 100 batch: 0.228532
Train loss on 150 batch: 0.207100
Train loss on 200 batch: 0.259800
Train loss on 250 batch: 0.209945
Train loss on 300 batch: 0.247373
Train loss on 350 batch: 0.223058
Train loss on 400 batch: 0.254751
Train loss on 450 batch: 0.238143
Train loss on 500 batch: 0.236021
Train loss on 550 batch: 0.251675
Train loss on 600 batch: 0.262163
Train loss on 650 batch: 0.268730
Train loss on 700 batch: 0.250649
Train loss on 750 batch: 0.272734
Train loss on 800 batch: 0.249786
Train loss on 850 batch: 0.277765
Train loss on 900 batch: 0.278738
Train loss on 950 batch: 0.287038
Train loss on 1000 batch: 0.266414
Train loss on 1050 batch: 0.256668
Train loss on 1100 batch: 0.243006
Train loss on 1150 batch: 0.266780
Train loss on 1200 batch: 0.307545
Train loss on 1250 batch: 0.283739
Train loss on 1300 batch: 0.253527
Train loss on 1350 batch: 0.265292
Train loss on 1400 batch: 0.227372
Train loss on 1450 batch: 0.244261
Train loss on 1500 batch: 0.234658
Train loss on 1550 batch: 0.228404
Train loss on 1600 batch: 0.271470
Train loss on 1650 batch: 0.237442
Train loss on 1700 batch: 0.238156
Train loss on 1750 batch: 0.307105
Train loss on 1800 batch: 0.305446
Train loss on 1850 batch: 0.250788
Train loss on 1900 batch: 0.223739
: Epoch: 35 | Training Loss: 0.252263 | Val. Loss: 0.314998 | Val. Kappa Score: 0.7229 | LR: 0.000031 | Estimated time: 395.07
Train loss on 50 batch: 0.278110
Train loss on 100 batch: 0.205319
Train loss on 150 batch: 0.277011
Train loss on 200 batch: 0.224774
Train loss on 250 batch: 0.277020
Train loss on 300 batch: 0.248371
Train loss on 350 batch: 0.247796
Train loss on 400 batch: 0.254234
Train loss on 450 batch: 0.204706
Train loss on 500 batch: 0.240511
Train loss on 550 batch: 0.243425
Train loss on 600 batch: 0.249881
Train loss on 650 batch: 0.238907
Train loss on 700 batch: 0.277301
Train loss on 750 batch: 0.229433
Train loss on 800 batch: 0.268767
Train loss on 850 batch: 0.259487
Train loss on 900 batch: 0.272614
Train loss on 950 batch: 0.231667
Train loss on 1000 batch: 0.282097
Train loss on 1050 batch: 0.244327
Train loss on 1100 batch: 0.255915
Train loss on 1150 batch: 0.244039
Train loss on 1200 batch: 0.248242
Train loss on 1250 batch: 0.235323
Train loss on 1300 batch: 0.254936
Train loss on 1350 batch: 0.220899
Train loss on 1400 batch: 0.244005
Train loss on 1450 batch: 0.264004
Train loss on 1500 batch: 0.263390
Train loss on 1550 batch: 0.258558
Train loss on 1600 batch: 0.293681
Train loss on 1650 batch: 0.230946
Train loss on 1700 batch: 0.243744
Train loss on 1750 batch: 0.224676
Train loss on 1800 batch: 0.244087
Train loss on 1850 batch: 0.226500
Train loss on 1900 batch: 0.245718
: Epoch: 36 | Training Loss: 0.249563 | Val. Loss: 0.314838 | Val. Kappa Score: 0.7238 | LR: 0.000016 | Estimated time: 387.06
Train loss on 50 batch: 0.252510
Train loss on 100 batch: 0.265412
Train loss on 150 batch: 0.257550
Train loss on 200 batch: 0.245067
Train loss on 250 batch: 0.297811
Train loss on 300 batch: 0.275541
Train loss on 350 batch: 0.299816
Train loss on 400 batch: 0.241833
Train loss on 450 batch: 0.259818
Train loss on 500 batch: 0.257704
Train loss on 550 batch: 0.230187
Train loss on 600 batch: 0.224631
Train loss on 650 batch: 0.268280
Train loss on 700 batch: 0.236048
Train loss on 750 batch: 0.255760
Train loss on 800 batch: 0.281661
Train loss on 850 batch: 0.207832
Train loss on 900 batch: 0.263245
Train loss on 950 batch: 0.262435
Train loss on 1000 batch: 0.205083
Train loss on 1050 batch: 0.252783
Train loss on 1100 batch: 0.242529
Train loss on 1150 batch: 0.223839
Train loss on 1200 batch: 0.247565
Train loss on 1250 batch: 0.285811
Train loss on 1300 batch: 0.203501
Train loss on 1350 batch: 0.215656
Train loss on 1400 batch: 0.249776
Train loss on 1450 batch: 0.278673
Train loss on 1500 batch: 0.222137
Train loss on 1550 batch: 0.195645
Train loss on 1600 batch: 0.257083
Train loss on 1650 batch: 0.279876
Train loss on 1700 batch: 0.236960
Train loss on 1750 batch: 0.258388
Train loss on 1800 batch: 0.224642
Train loss on 1850 batch: 0.271168
Train loss on 1900 batch: 0.206752
: Epoch: 37 | Training Loss: 0.247333 | Val. Loss: 0.314345 | Val. Kappa Score: 0.7249 | LR: 0.000016 | Estimated time: 387.25
Train loss on 50 batch: 0.263054
Train loss on 100 batch: 0.252105
Train loss on 150 batch: 0.185133
Train loss on 200 batch: 0.266645
Train loss on 250 batch: 0.226828
Train loss on 300 batch: 0.228128
Train loss on 350 batch: 0.256061
Train loss on 400 batch: 0.198732
Train loss on 450 batch: 0.259627
Train loss on 500 batch: 0.231336
Train loss on 550 batch: 0.277298
Train loss on 600 batch: 0.230450
Train loss on 650 batch: 0.249772
Train loss on 700 batch: 0.234948
Train loss on 750 batch: 0.290604
Train loss on 800 batch: 0.270326
Train loss on 850 batch: 0.202083
Train loss on 900 batch: 0.278856
Train loss on 950 batch: 0.264807
Train loss on 1000 batch: 0.259357
Train loss on 1050 batch: 0.226978
Train loss on 1100 batch: 0.283329
Train loss on 1150 batch: 0.207935
Train loss on 1200 batch: 0.247316
Train loss on 1250 batch: 0.202441
Train loss on 1300 batch: 0.264066
Train loss on 1350 batch: 0.253239
Train loss on 1400 batch: 0.211603
Train loss on 1450 batch: 0.200119
Train loss on 1500 batch: 0.233734
Train loss on 1550 batch: 0.266845
Train loss on 1600 batch: 0.279335
Train loss on 1650 batch: 0.299475
Train loss on 1700 batch: 0.225015
Train loss on 1750 batch: 0.249787
Train loss on 1800 batch: 0.239054
Train loss on 1850 batch: 0.253158
Train loss on 1900 batch: 0.220401
: Epoch: 38 | Training Loss: 0.243842 | Val. Loss: 0.316391 | Val. Kappa Score: 0.7255 | LR: 0.000016 | Estimated time: 381.72
Train loss on 50 batch: 0.241415
Train loss on 100 batch: 0.233103
Train loss on 150 batch: 0.241364
Train loss on 200 batch: 0.230683
Train loss on 250 batch: 0.242166
Train loss on 300 batch: 0.226378
Train loss on 350 batch: 0.259201
Train loss on 400 batch: 0.232070
Train loss on 450 batch: 0.240919
Train loss on 500 batch: 0.285057
Train loss on 550 batch: 0.239286
Train loss on 600 batch: 0.190547
Train loss on 650 batch: 0.242898
Train loss on 700 batch: 0.234442
Train loss on 750 batch: 0.238822
Train loss on 800 batch: 0.248858
Train loss on 850 batch: 0.252106
Train loss on 900 batch: 0.297384
Train loss on 950 batch: 0.273573
Train loss on 1000 batch: 0.265920
Train loss on 1050 batch: 0.264927
Train loss on 1100 batch: 0.258983
Train loss on 1150 batch: 0.259353
Train loss on 1200 batch: 0.228036
Train loss on 1250 batch: 0.224977
Train loss on 1300 batch: 0.270319
Train loss on 1350 batch: 0.240974
Train loss on 1400 batch: 0.276937
Train loss on 1450 batch: 0.259964
Train loss on 1500 batch: 0.236412
Train loss on 1550 batch: 0.250724
Train loss on 1600 batch: 0.244992
Train loss on 1650 batch: 0.247023
Train loss on 1700 batch: 0.258992
Train loss on 1750 batch: 0.251429
Train loss on 1800 batch: 0.283387
Train loss on 1850 batch: 0.225160
Train loss on 1900 batch: 0.239540
: Epoch: 39 | Training Loss: 0.247843 | Val. Loss: 0.315681 | Val. Kappa Score: 0.7265 | LR: 0.000008 | Estimated time: 385.10
Train loss on 50 batch: 0.248879
Train loss on 100 batch: 0.246075
Train loss on 150 batch: 0.231209
Train loss on 200 batch: 0.255194
Train loss on 250 batch: 0.243794
Train loss on 300 batch: 0.220739
Train loss on 350 batch: 0.240353
Train loss on 400 batch: 0.241580
Train loss on 450 batch: 0.272002
Train loss on 500 batch: 0.246676
Train loss on 550 batch: 0.226964
Train loss on 600 batch: 0.211539
Train loss on 650 batch: 0.259768
Train loss on 700 batch: 0.231495
Train loss on 750 batch: 0.220885
Train loss on 800 batch: 0.249386
Train loss on 850 batch: 0.304561
Train loss on 900 batch: 0.255504
Train loss on 950 batch: 0.247338
Train loss on 1000 batch: 0.238522
Train loss on 1050 batch: 0.234715
Train loss on 1100 batch: 0.242369
Train loss on 1150 batch: 0.248999
Train loss on 1200 batch: 0.248608
Train loss on 1250 batch: 0.248864
Train loss on 1300 batch: 0.258998
Train loss on 1350 batch: 0.220093
Train loss on 1400 batch: 0.227299
Train loss on 1450 batch: 0.264482
Train loss on 1500 batch: 0.265596
Train loss on 1550 batch: 0.234713
Train loss on 1600 batch: 0.234968
Train loss on 1650 batch: 0.282852
Train loss on 1700 batch: 0.276909
Train loss on 1750 batch: 0.281020
Train loss on 1800 batch: 0.241017
Train loss on 1850 batch: 0.258488
Train loss on 1900 batch: 0.265575
: Epoch: 40 | Training Loss: 0.247961 | Val. Loss: 0.316835 | Val. Kappa Score: 0.7274 | LR: 0.000008 | Estimated time: 389.35
time_estimated: 15102.26
n-epochs: 40
time_estimated: 15102.30
----------------------------------------

Experiment N: 122: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.23 00:37:38
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6d8>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 122: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.23 00:39:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d107748>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 122: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.23 00:39:42
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d710>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.018663
Train loss on 100 batch: 0.629479
Train loss on 150 batch: 0.600020
best-train-loss: 0.680015
best-valid-loss: 0.417356
best-kappa: 0.8422
: Epoch: 1 | Training Loss: 0.680015 | Val. Loss: 0.417356 | Val. Kappa Score: 0.8422 | LR: 0.001000 | Estimated time: 41.79
----------------------------------------

Experiment N: 123: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 00:41:53
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c518>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.109427
Train loss on 100 batch: 0.637837
Train loss on 150 batch: 0.571907
best-train-loss: 0.711697
best-valid-loss: 1.025648
best-kappa: 0.7814
: Epoch: 1 | Training Loss: 0.711697 | Val. Loss: 1.025648 | Val. Kappa Score: 0.7814 | LR: 0.001000 | Estimated time: 55.07
----------------------------------------

Experiment N: 124: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 00:43:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10f630>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 124: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 00:44:05
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e630>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 124: 



EXPERIMENT WITH BATCH_SIZE: 6, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 00:44:42
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6a0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 6
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 124: 



EXPERIMENT WITH BATCH_SIZE: 4, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 00:44:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6a0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 4
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.552395
Train loss on 100 batch: 1.252837
Train loss on 150 batch: 1.041309
Train loss on 200 batch: 0.776589
Train loss on 250 batch: 0.855295
Train loss on 300 batch: 0.916259
Train loss on 350 batch: 1.038709
Train loss on 400 batch: 1.022963
Train loss on 450 batch: 1.017051
Train loss on 500 batch: 0.798763
Train loss on 550 batch: 0.719057
Train loss on 600 batch: 0.694592
Train loss on 650 batch: 0.551803
Train loss on 700 batch: 0.694735
best-train-loss: 0.906710
best-valid-loss: 0.835998
best-kappa: 0.6547
: Epoch: 1 | Training Loss: 0.906710 | Val. Loss: 0.835998 | Val. Kappa Score: 0.6547 | LR: 0.001000 | Estimated time: 172.34
Train loss on 50 batch: 0.622082
----------------------------------------

Experiment N: 125: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.23 00:48:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6a0>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.018663
Train loss on 100 batch: 0.629479
Train loss on 150 batch: 0.600020
best-train-loss: 0.680015
best-valid-loss: 0.417356
best-kappa: 0.8422
: Epoch: 1 | Training Loss: 0.680015 | Val. Loss: 0.417356 | Val. Kappa Score: 0.8422 | LR: 0.001000 | Estimated time: 42.19
Train loss on 50 batch: 0.435190
Train loss on 100 batch: 0.419463
Train loss on 150 batch: 0.338240
: Epoch: 2 | Training Loss: 0.431625 | Val. Loss: 0.517669 | Val. Kappa Score: 0.8206 | LR: 0.001000 | Estimated time: 40.63
Train loss on 50 batch: 0.445602
Train loss on 100 batch: 0.432828
Train loss on 150 batch: 0.400201
: Epoch: 3 | Training Loss: 0.424394 | Val. Loss: 0.710438 | Val. Kappa Score: 0.8315 | LR: 0.001000 | Estimated time: 41.39
Train loss on 50 batch: 0.451986
Train loss on 100 batch: 0.410470
Train loss on 150 batch: 0.295371
: Epoch: 4 | Training Loss: 0.437508 | Val. Loss: 0.772063 | Val. Kappa Score: 0.8165 | LR: 0.000500 | Estimated time: 41.12
Train loss on 50 batch: 0.398270
Train loss on 100 batch: 0.365488
Train loss on 150 batch: 0.278607
best-train-loss: 0.353337
best-valid-loss: 0.310267
best-kappa: 0.8288
: Epoch: 5 | Training Loss: 0.353337 | Val. Loss: 0.310267 | Val. Kappa Score: 0.8288 | LR: 0.000500 | Estimated time: 41.62
Train loss on 50 batch: 0.286376
Train loss on 100 batch: 0.279985
Train loss on 150 batch: 0.275529
: Epoch: 6 | Training Loss: 0.277754 | Val. Loss: 0.439245 | Val. Kappa Score: 0.8300 | LR: 0.000500 | Estimated time: 41.56
Train loss on 50 batch: 0.297084
Train loss on 100 batch: 0.294266
Train loss on 150 batch: 0.245329
best-train-loss: 0.280176
best-valid-loss: 0.297409
best-kappa: 0.8376
: Epoch: 7 | Training Loss: 0.280176 | Val. Loss: 0.297409 | Val. Kappa Score: 0.8376 | LR: 0.000500 | Estimated time: 41.76
Train loss on 50 batch: 0.220975
Train loss on 100 batch: 0.257629
Train loss on 150 batch: 0.198243
: Epoch: 8 | Training Loss: 0.233096 | Val. Loss: 0.354296 | Val. Kappa Score: 0.8426 | LR: 0.000500 | Estimated time: 41.04
Train loss on 50 batch: 0.197855
Train loss on 100 batch: 0.261319
Train loss on 150 batch: 0.231883
: Epoch: 9 | Training Loss: 0.229097 | Val. Loss: 0.304996 | Val. Kappa Score: 0.8484 | LR: 0.000500 | Estimated time: 42.09
Train loss on 50 batch: 0.185752
Train loss on 100 batch: 0.201116
Train loss on 150 batch: 0.253782
best-train-loss: 0.260061
best-valid-loss: 0.293010
best-kappa: 0.8515
: Epoch: 10 | Training Loss: 0.260061 | Val. Loss: 0.293010 | Val. Kappa Score: 0.8515 | LR: 0.000500 | Estimated time: 42.04
Train loss on 50 batch: 0.218317
Train loss on 100 batch: 0.221296
Train loss on 150 batch: 0.214309
: Epoch: 11 | Training Loss: 0.230806 | Val. Loss: 0.337167 | Val. Kappa Score: 0.8531 | LR: 0.000500 | Estimated time: 41.66
Train loss on 50 batch: 0.196068
Train loss on 100 batch: 0.170316
Train loss on 150 batch: 0.223002
: Epoch: 12 | Training Loss: 0.201591 | Val. Loss: 0.339441 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 42.05
Train loss on 50 batch: 0.159466
Train loss on 100 batch: 0.228967
Train loss on 150 batch: 0.192252
: Epoch: 13 | Training Loss: 0.206729 | Val. Loss: 0.307180 | Val. Kappa Score: 0.8562 | LR: 0.000250 | Estimated time: 41.38
Train loss on 50 batch: 0.179041
Train loss on 100 batch: 0.147196
Train loss on 150 batch: 0.168589
: Epoch: 14 | Training Loss: 0.173321 | Val. Loss: 0.305342 | Val. Kappa Score: 0.8582 | LR: 0.000250 | Estimated time: 41.79
Train loss on 50 batch: 0.179660
Train loss on 100 batch: 0.142302
Train loss on 150 batch: 0.158295
best-train-loss: 0.163141
best-valid-loss: 0.284349
best-kappa: 0.8605
: Epoch: 15 | Training Loss: 0.163141 | Val. Loss: 0.284349 | Val. Kappa Score: 0.8605 | LR: 0.000250 | Estimated time: 41.74
Train loss on 50 batch: 0.126266
Train loss on 100 batch: 0.137154
Train loss on 150 batch: 0.134726
: Epoch: 16 | Training Loss: 0.136460 | Val. Loss: 0.308720 | Val. Kappa Score: 0.8619 | LR: 0.000250 | Estimated time: 41.56
Train loss on 50 batch: 0.142468
Train loss on 100 batch: 0.131399
Train loss on 150 batch: 0.118663
: Epoch: 17 | Training Loss: 0.132772 | Val. Loss: 0.285029 | Val. Kappa Score: 0.8636 | LR: 0.000250 | Estimated time: 41.38
Train loss on 50 batch: 0.117042
Train loss on 100 batch: 0.106669
Train loss on 150 batch: 0.117987
: Epoch: 18 | Training Loss: 0.116740 | Val. Loss: 0.304357 | Val. Kappa Score: 0.8653 | LR: 0.000125 | Estimated time: 41.19
Train loss on 50 batch: 0.097437
Train loss on 100 batch: 0.102918
Train loss on 150 batch: 0.103614
: Epoch: 19 | Training Loss: 0.106801 | Val. Loss: 0.304782 | Val. Kappa Score: 0.8663 | LR: 0.000125 | Estimated time: 42.00
Train loss on 50 batch: 0.103987
Train loss on 100 batch: 0.114098
Train loss on 150 batch: 0.103447
: Epoch: 20 | Training Loss: 0.105494 | Val. Loss: 0.301331 | Val. Kappa Score: 0.8673 | LR: 0.000125 | Estimated time: 40.95
Train loss on 50 batch: 0.106685
Train loss on 100 batch: 0.083490
Train loss on 150 batch: 0.082417
: Epoch: 21 | Training Loss: 0.111573 | Val. Loss: 0.287267 | Val. Kappa Score: 0.8689 | LR: 0.000063 | Estimated time: 41.08
Train loss on 50 batch: 0.088229
Train loss on 100 batch: 0.092702
Train loss on 150 batch: 0.088872
: Epoch: 22 | Training Loss: 0.089130 | Val. Loss: 0.299313 | Val. Kappa Score: 0.8701 | LR: 0.000063 | Estimated time: 41.42
Train loss on 50 batch: 0.079805
Train loss on 100 batch: 0.072604
Train loss on 150 batch: 0.070904
: Epoch: 23 | Training Loss: 0.080267 | Val. Loss: 0.303339 | Val. Kappa Score: 0.8710 | LR: 0.000063 | Estimated time: 41.99
Train loss on 50 batch: 0.070498
Train loss on 100 batch: 0.088205
Train loss on 150 batch: 0.073587
: Epoch: 24 | Training Loss: 0.128830 | Val. Loss: 0.293472 | Val. Kappa Score: 0.8717 | LR: 0.000031 | Estimated time: 41.66
Train loss on 50 batch: 0.076187
Train loss on 100 batch: 0.060033
Train loss on 150 batch: 0.074504
: Epoch: 25 | Training Loss: 0.068291 | Val. Loss: 0.288683 | Val. Kappa Score: 0.8728 | LR: 0.000031 | Estimated time: 41.29
time_estimated: 1039.60
n-epochs: 25
time_estimated: 1039.63
----------------------------------------

Experiment N: 126: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.23 01:07:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b710>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.959371
Train loss on 100 batch: 0.685194
Train loss on 150 batch: 0.649281
best-train-loss: 0.704468
best-valid-loss: 0.684445
best-kappa: 0.7816
: Epoch: 1 | Training Loss: 0.704468 | Val. Loss: 0.684445 | Val. Kappa Score: 0.7816 | LR: 0.001000 | Estimated time: 31.95
Train loss on 50 batch: 0.463746
Train loss on 100 batch: 0.451617
Train loss on 150 batch: 0.396176
best-train-loss: 0.450694
best-valid-loss: 0.526858
best-kappa: 0.8011
: Epoch: 2 | Training Loss: 0.450694 | Val. Loss: 0.526858 | Val. Kappa Score: 0.8011 | LR: 0.001000 | Estimated time: 31.38
Train loss on 50 batch: 0.422398
Train loss on 100 batch: 0.424293
Train loss on 150 batch: 0.417511
best-train-loss: 0.421615
best-valid-loss: 0.360338
best-kappa: 0.8232
: Epoch: 3 | Training Loss: 0.421615 | Val. Loss: 0.360338 | Val. Kappa Score: 0.8232 | LR: 0.001000 | Estimated time: 31.15
Train loss on 50 batch: 0.398345
Train loss on 100 batch: 0.447653
Train loss on 150 batch: 0.360199
best-train-loss: 0.438635
best-valid-loss: 0.322260
best-kappa: 0.8367
: Epoch: 4 | Training Loss: 0.438635 | Val. Loss: 0.322260 | Val. Kappa Score: 0.8367 | LR: 0.001000 | Estimated time: 31.42
Train loss on 50 batch: 0.445569
Train loss on 100 batch: 0.469515
Train loss on 150 batch: 0.344119
: Epoch: 5 | Training Loss: 0.413921 | Val. Loss: 0.328739 | Val. Kappa Score: 0.8439 | LR: 0.001000 | Estimated time: 31.07
Train loss on 50 batch: 0.364069
Train loss on 100 batch: 0.356694
Train loss on 150 batch: 0.338726
: Epoch: 6 | Training Loss: 0.339436 | Val. Loss: 0.411390 | Val. Kappa Score: 0.8414 | LR: 0.001000 | Estimated time: 30.81
Train loss on 50 batch: 0.339064
Train loss on 100 batch: 0.334897
Train loss on 150 batch: 0.313698
: Epoch: 7 | Training Loss: 0.323052 | Val. Loss: 0.334642 | Val. Kappa Score: 0.8455 | LR: 0.000500 | Estimated time: 31.58
Train loss on 50 batch: 0.277040
Train loss on 100 batch: 0.301547
Train loss on 150 batch: 0.212085
best-train-loss: 0.274309
best-valid-loss: 0.292897
best-kappa: 0.8510
: Epoch: 8 | Training Loss: 0.274309 | Val. Loss: 0.292897 | Val. Kappa Score: 0.8510 | LR: 0.000500 | Estimated time: 31.11
Train loss on 50 batch: 0.252565
Train loss on 100 batch: 0.307170
Train loss on 150 batch: 0.265413
: Epoch: 9 | Training Loss: 0.263586 | Val. Loss: 0.299188 | Val. Kappa Score: 0.8556 | LR: 0.000500 | Estimated time: 31.88
Train loss on 50 batch: 0.213128
Train loss on 100 batch: 0.222108
Train loss on 150 batch: 0.242895
best-train-loss: 0.285290
best-valid-loss: 0.286900
best-kappa: 0.8595
: Epoch: 10 | Training Loss: 0.285290 | Val. Loss: 0.286900 | Val. Kappa Score: 0.8595 | LR: 0.000500 | Estimated time: 32.52
Train loss on 50 batch: 0.251133
Train loss on 100 batch: 0.262627
Train loss on 150 batch: 0.214198
: Epoch: 11 | Training Loss: 0.251110 | Val. Loss: 0.303574 | Val. Kappa Score: 0.8611 | LR: 0.000500 | Estimated time: 31.68
Train loss on 50 batch: 0.196193
Train loss on 100 batch: 0.208798
Train loss on 150 batch: 0.252988
: Epoch: 12 | Training Loss: 0.234149 | Val. Loss: 0.330031 | Val. Kappa Score: 0.8621 | LR: 0.000500 | Estimated time: 32.40
Train loss on 50 batch: 0.213093
Train loss on 100 batch: 0.247114
Train loss on 150 batch: 0.217931
: Epoch: 13 | Training Loss: 0.232384 | Val. Loss: 0.292022 | Val. Kappa Score: 0.8637 | LR: 0.000250 | Estimated time: 31.36
Train loss on 50 batch: 0.194010
Train loss on 100 batch: 0.163583
Train loss on 150 batch: 0.192711
best-train-loss: 0.200474
best-valid-loss: 0.265410
best-kappa: 0.8660
: Epoch: 14 | Training Loss: 0.200474 | Val. Loss: 0.265410 | Val. Kappa Score: 0.8660 | LR: 0.000250 | Estimated time: 31.63
Train loss on 50 batch: 0.180130
Train loss on 100 batch: 0.169710
Train loss on 150 batch: 0.187880
: Epoch: 15 | Training Loss: 0.190936 | Val. Loss: 0.303611 | Val. Kappa Score: 0.8668 | LR: 0.000250 | Estimated time: 31.58
Train loss on 50 batch: 0.149887
Train loss on 100 batch: 0.152286
Train loss on 150 batch: 0.178345
: Epoch: 16 | Training Loss: 0.158490 | Val. Loss: 0.287549 | Val. Kappa Score: 0.8679 | LR: 0.000250 | Estimated time: 31.17
Train loss on 50 batch: 0.184344
Train loss on 100 batch: 0.164101
Train loss on 150 batch: 0.141822
: Epoch: 17 | Training Loss: 0.163968 | Val. Loss: 0.289974 | Val. Kappa Score: 0.8691 | LR: 0.000125 | Estimated time: 31.46
Train loss on 50 batch: 0.147110
Train loss on 100 batch: 0.129086
Train loss on 150 batch: 0.151134
: Epoch: 18 | Training Loss: 0.145285 | Val. Loss: 0.292802 | Val. Kappa Score: 0.8701 | LR: 0.000125 | Estimated time: 31.34
Train loss on 50 batch: 0.119972
Train loss on 100 batch: 0.139421
Train loss on 150 batch: 0.150000
: Epoch: 19 | Training Loss: 0.146787 | Val. Loss: 0.282591 | Val. Kappa Score: 0.8708 | LR: 0.000125 | Estimated time: 31.72
Train loss on 50 batch: 0.129181
Train loss on 100 batch: 0.141485
Train loss on 150 batch: 0.128097
: Epoch: 20 | Training Loss: 0.129811 | Val. Loss: 0.274792 | Val. Kappa Score: 0.8719 | LR: 0.000063 | Estimated time: 30.43
Train loss on 50 batch: 0.120676
Train loss on 100 batch: 0.103614
Train loss on 150 batch: 0.139918
: Epoch: 21 | Training Loss: 0.155623 | Val. Loss: 0.274993 | Val. Kappa Score: 0.8732 | LR: 0.000063 | Estimated time: 30.85
Train loss on 50 batch: 0.119143
Train loss on 100 batch: 0.129423
Train loss on 150 batch: 0.100256
: Epoch: 22 | Training Loss: 0.115084 | Val. Loss: 0.273597 | Val. Kappa Score: 0.8743 | LR: 0.000063 | Estimated time: 31.14
Train loss on 50 batch: 0.112959
Train loss on 100 batch: 0.103401
Train loss on 150 batch: 0.100015
: Epoch: 23 | Training Loss: 0.110863 | Val. Loss: 0.281487 | Val. Kappa Score: 0.8751 | LR: 0.000031 | Estimated time: 31.12
Train loss on 50 batch: 0.087911
Train loss on 100 batch: 0.120486
Train loss on 150 batch: 0.105259
: Epoch: 24 | Training Loss: 0.158779 | Val. Loss: 0.276798 | Val. Kappa Score: 0.8759 | LR: 0.000031 | Estimated time: 31.44
time_estimated: 755.21
n-epochs: 24
time_estimated: 755.25
----------------------------------------

Experiment N: 127: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.23 01:37:15
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e668>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.047726
Train loss on 100 batch: 0.861762
Train loss on 150 batch: 0.908798
Train loss on 200 batch: 0.724938
Train loss on 250 batch: 0.784731
Train loss on 300 batch: 0.700194
Train loss on 350 batch: 0.773599
Train loss on 400 batch: 0.843264
Train loss on 450 batch: 0.787864
Train loss on 500 batch: 0.699865
Train loss on 550 batch: 0.634741
Train loss on 600 batch: 0.653197
Train loss on 650 batch: 0.701999
Train loss on 700 batch: 0.726582
Train loss on 750 batch: 0.660299
Train loss on 800 batch: 0.650001
Train loss on 850 batch: 0.718878
Train loss on 900 batch: 0.610729
Train loss on 950 batch: 0.571588
Train loss on 1000 batch: 0.645641
Train loss on 1050 batch: 0.625715
Train loss on 1100 batch: 0.627550
Train loss on 1150 batch: 0.626544
Train loss on 1200 batch: 0.667138
Train loss on 1250 batch: 0.572312
Train loss on 1300 batch: 0.634422
Train loss on 1350 batch: 0.610271
Train loss on 1400 batch: 0.650294
Train loss on 1450 batch: 0.727835
Train loss on 1500 batch: 0.628376
Train loss on 1550 batch: 0.588455
Train loss on 1600 batch: 0.673023
Train loss on 1650 batch: 0.702200
Train loss on 1700 batch: 0.593616
Train loss on 1750 batch: 0.630270
Train loss on 1800 batch: 0.616182
Train loss on 1850 batch: 0.695501
Train loss on 1900 batch: 0.649840
best-train-loss: 0.689882
best-valid-loss: 0.640970
best-kappa: 0.4972
: Epoch: 1 | Training Loss: 0.689882 | Val. Loss: 0.640970 | Val. Kappa Score: 0.4972 | LR: 0.001000 | Estimated time: 256.50
Train loss on 50 batch: 0.575190
Train loss on 100 batch: 0.630082
Train loss on 150 batch: 0.626809
Train loss on 200 batch: 0.564692
Train loss on 250 batch: 0.537074
Train loss on 300 batch: 0.630778
Train loss on 350 batch: 0.653377
Train loss on 400 batch: 0.584282
Train loss on 450 batch: 0.536030
Train loss on 500 batch: 0.590060
Train loss on 550 batch: 0.587390
Train loss on 600 batch: 0.542982
Train loss on 650 batch: 0.480720
Train loss on 700 batch: 0.674884
Train loss on 750 batch: 0.613930
Train loss on 800 batch: 0.565738
Train loss on 850 batch: 0.553688
Train loss on 900 batch: 0.705481
Train loss on 950 batch: 0.679582
Train loss on 1000 batch: 0.545339
Train loss on 1050 batch: 0.543317
Train loss on 1100 batch: 0.580605
Train loss on 1150 batch: 0.492684
Train loss on 1200 batch: 0.537724
Train loss on 1250 batch: 0.581042
Train loss on 1300 batch: 0.608956
Train loss on 1350 batch: 0.596021
Train loss on 1400 batch: 0.508263
Train loss on 1450 batch: 0.656602
Train loss on 1500 batch: 0.636034
Train loss on 1550 batch: 0.615592
Train loss on 1600 batch: 0.532008
Train loss on 1650 batch: 0.578790
Train loss on 1700 batch: 0.669258
Train loss on 1750 batch: 0.516279
Train loss on 1800 batch: 0.547363
Train loss on 1850 batch: 0.550184
Train loss on 1900 batch: 0.464837
best-train-loss: 0.579347
best-valid-loss: 0.507361
best-kappa: 0.5471
: Epoch: 2 | Training Loss: 0.579347 | Val. Loss: 0.507361 | Val. Kappa Score: 0.5471 | LR: 0.001000 | Estimated time: 263.97
Train loss on 50 batch: 0.606554
Train loss on 100 batch: 0.584210
Train loss on 150 batch: 0.524754
Train loss on 200 batch: 0.586340
Train loss on 250 batch: 0.537771
Train loss on 300 batch: 0.515772
Train loss on 350 batch: 0.545196
Train loss on 400 batch: 0.540607
Train loss on 450 batch: 0.536477
Train loss on 500 batch: 0.621161
Train loss on 550 batch: 0.497080
Train loss on 600 batch: 0.607528
Train loss on 650 batch: 0.616990
Train loss on 700 batch: 0.570468
Train loss on 750 batch: 0.576463
Train loss on 800 batch: 0.562209
Train loss on 850 batch: 0.598680
Train loss on 900 batch: 0.545041
Train loss on 950 batch: 0.519335
Train loss on 1000 batch: 0.501169
Train loss on 1050 batch: 0.506204
Train loss on 1100 batch: 0.523746
Train loss on 1150 batch: 0.558154
Train loss on 1200 batch: 0.576793
Train loss on 1250 batch: 0.540755
Train loss on 1300 batch: 0.491731
Train loss on 1350 batch: 0.612567
Train loss on 1400 batch: 0.508633
Train loss on 1450 batch: 0.569126
Train loss on 1500 batch: 0.556125
Train loss on 1550 batch: 0.505365
Train loss on 1600 batch: 0.545295
Train loss on 1650 batch: 0.446964
Train loss on 1700 batch: 0.464009
Train loss on 1750 batch: 0.512751
Train loss on 1800 batch: 0.571707
Train loss on 1850 batch: 0.556578
Train loss on 1900 batch: 0.530916
: Epoch: 3 | Training Loss: 0.548417 | Val. Loss: 0.512675 | Val. Kappa Score: 0.5644 | LR: 0.001000 | Estimated time: 264.19
Train loss on 50 batch: 0.596301
Train loss on 100 batch: 0.501491
Train loss on 150 batch: 0.596492
Train loss on 200 batch: 0.527866
Train loss on 250 batch: 0.525230
Train loss on 300 batch: 0.498846
Train loss on 350 batch: 0.619873
Train loss on 400 batch: 0.539548
Train loss on 450 batch: 0.476745
Train loss on 500 batch: 0.586481
Train loss on 550 batch: 0.555425
Train loss on 600 batch: 0.473234
Train loss on 650 batch: 0.462275
Train loss on 700 batch: 0.550003
Train loss on 750 batch: 0.471116
Train loss on 800 batch: 0.575467
Train loss on 850 batch: 0.497039
Train loss on 900 batch: 0.535279
Train loss on 950 batch: 0.463231
Train loss on 1000 batch: 0.476706
Train loss on 1050 batch: 0.588612
Train loss on 1100 batch: 0.523802
Train loss on 1150 batch: 0.504613
Train loss on 1200 batch: 0.488605
Train loss on 1250 batch: 0.483762
Train loss on 1300 batch: 0.511527
Train loss on 1350 batch: 0.430270
Train loss on 1400 batch: 0.519559
Train loss on 1450 batch: 0.483078
Train loss on 1500 batch: 0.500930
Train loss on 1550 batch: 0.515501
Train loss on 1600 batch: 0.616315
Train loss on 1650 batch: 0.560831
Train loss on 1700 batch: 0.661956
Train loss on 1750 batch: 0.514882
Train loss on 1800 batch: 0.505806
Train loss on 1850 batch: 0.512925
Train loss on 1900 batch: 0.513708
best-train-loss: 0.524599
best-valid-loss: 0.496946
best-kappa: 0.5774
: Epoch: 4 | Training Loss: 0.524599 | Val. Loss: 0.496946 | Val. Kappa Score: 0.5774 | LR: 0.001000 | Estimated time: 263.03
Train loss on 50 batch: 0.491070
Train loss on 100 batch: 0.532189
Train loss on 150 batch: 0.467700
Train loss on 200 batch: 0.587008
Train loss on 250 batch: 0.508881
Train loss on 300 batch: 0.466981
Train loss on 350 batch: 0.599792
Train loss on 400 batch: 0.444731
Train loss on 450 batch: 0.523493
Train loss on 500 batch: 0.549186
Train loss on 550 batch: 0.545994
Train loss on 600 batch: 0.500337
Train loss on 650 batch: 0.453835
Train loss on 700 batch: 0.586517
Train loss on 750 batch: 0.505004
Train loss on 800 batch: 0.565166
Train loss on 850 batch: 0.568252
Train loss on 900 batch: 0.464989
Train loss on 950 batch: 0.477619
Train loss on 1000 batch: 0.501007
Train loss on 1050 batch: 0.545853
Train loss on 1100 batch: 0.438056
Train loss on 1150 batch: 0.540539
Train loss on 1200 batch: 0.470598
Train loss on 1250 batch: 0.538608
Train loss on 1300 batch: 0.564335
Train loss on 1350 batch: 0.486921
Train loss on 1400 batch: 0.489060
Train loss on 1450 batch: 0.413006
Train loss on 1500 batch: 0.497818
Train loss on 1550 batch: 0.447188
Train loss on 1600 batch: 0.461269
Train loss on 1650 batch: 0.535725
Train loss on 1700 batch: 0.542992
Train loss on 1750 batch: 0.521394
Train loss on 1800 batch: 0.483818
Train loss on 1850 batch: 0.465521
Train loss on 1900 batch: 0.481139
: Epoch: 5 | Training Loss: 0.507250 | Val. Loss: 0.597047 | Val. Kappa Score: 0.5826 | LR: 0.001000 | Estimated time: 259.42
Train loss on 50 batch: 0.558633
Train loss on 100 batch: 0.475187
Train loss on 150 batch: 0.445009
Train loss on 200 batch: 0.546462
Train loss on 250 batch: 0.448355
Train loss on 300 batch: 0.499446
Train loss on 350 batch: 0.475920
Train loss on 400 batch: 0.541571
Train loss on 450 batch: 0.593215
Train loss on 500 batch: 0.472604
Train loss on 550 batch: 0.471728
Train loss on 600 batch: 0.526031
Train loss on 650 batch: 0.514681
Train loss on 700 batch: 0.460423
Train loss on 750 batch: 0.457237
Train loss on 800 batch: 0.515700
Train loss on 850 batch: 0.465865
Train loss on 900 batch: 0.543047
Train loss on 950 batch: 0.566342
Train loss on 1000 batch: 0.483045
Train loss on 1050 batch: 0.518801
Train loss on 1100 batch: 0.487185
Train loss on 1150 batch: 0.510166
Train loss on 1200 batch: 0.412459
Train loss on 1250 batch: 0.520485
Train loss on 1300 batch: 0.516837
Train loss on 1350 batch: 0.486827
Train loss on 1400 batch: 0.522431
Train loss on 1450 batch: 0.572647
Train loss on 1500 batch: 0.501825
Train loss on 1550 batch: 0.535653
Train loss on 1600 batch: 0.527747
Train loss on 1650 batch: 0.453898
Train loss on 1700 batch: 0.435042
Train loss on 1750 batch: 0.520041
Train loss on 1800 batch: 0.450167
Train loss on 1850 batch: 0.469080
Train loss on 1900 batch: 0.556606
: Epoch: 6 | Training Loss: 0.501863 | Val. Loss: 0.524717 | Val. Kappa Score: 0.5862 | LR: 0.001000 | Estimated time: 261.42
Train loss on 50 batch: 0.486131
Train loss on 100 batch: 0.525914
Train loss on 150 batch: 0.477590
Train loss on 200 batch: 0.465625
Train loss on 250 batch: 0.487186
Train loss on 300 batch: 0.530872
Train loss on 350 batch: 0.476695
Train loss on 400 batch: 0.533842
Train loss on 450 batch: 0.505145
Train loss on 500 batch: 0.434435
Train loss on 550 batch: 0.470198
Train loss on 600 batch: 0.613564
Train loss on 650 batch: 0.498163
Train loss on 700 batch: 0.461691
Train loss on 750 batch: 0.421297
Train loss on 800 batch: 0.467477
Train loss on 850 batch: 0.453248
Train loss on 900 batch: 0.467504
Train loss on 950 batch: 0.418393
Train loss on 1000 batch: 0.430475
Train loss on 1050 batch: 0.488598
Train loss on 1100 batch: 0.478808
Train loss on 1150 batch: 0.473006
Train loss on 1200 batch: 0.528771
Train loss on 1250 batch: 0.509517
Train loss on 1300 batch: 0.469256
Train loss on 1350 batch: 0.485363
Train loss on 1400 batch: 0.459827
Train loss on 1450 batch: 0.465881
Train loss on 1500 batch: 0.443905
Train loss on 1550 batch: 0.511112
Train loss on 1600 batch: 0.426314
Train loss on 1650 batch: 0.477664
Train loss on 1700 batch: 0.457899
Train loss on 1750 batch: 0.471115
Train loss on 1800 batch: 0.505768
Train loss on 1850 batch: 0.575523
Train loss on 1900 batch: 0.508675
: Epoch: 7 | Training Loss: 0.481916 | Val. Loss: 0.613816 | Val. Kappa Score: 0.5744 | LR: 0.000500 | Estimated time: 255.36
Train loss on 50 batch: 0.443925
Train loss on 100 batch: 0.380189
Train loss on 150 batch: 0.501856
Train loss on 200 batch: 0.476876
Train loss on 250 batch: 0.366560
Train loss on 300 batch: 0.426033
Train loss on 350 batch: 0.407105
Train loss on 400 batch: 0.469381
Train loss on 450 batch: 0.375182
Train loss on 500 batch: 0.508640
Train loss on 550 batch: 0.462126
Train loss on 600 batch: 0.403481
Train loss on 650 batch: 0.432866
Train loss on 700 batch: 0.447203
Train loss on 750 batch: 0.439421
Train loss on 800 batch: 0.446837
Train loss on 850 batch: 0.425004
Train loss on 900 batch: 0.459632
Train loss on 950 batch: 0.407104
Train loss on 1000 batch: 0.379603
Train loss on 1050 batch: 0.415901
Train loss on 1100 batch: 0.426967
Train loss on 1150 batch: 0.437908
Train loss on 1200 batch: 0.467540
Train loss on 1250 batch: 0.423052
Train loss on 1300 batch: 0.388555
Train loss on 1350 batch: 0.424833
Train loss on 1400 batch: 0.420195
Train loss on 1450 batch: 0.365443
Train loss on 1500 batch: 0.462275
Train loss on 1550 batch: 0.459254
Train loss on 1600 batch: 0.429483
Train loss on 1650 batch: 0.468977
Train loss on 1700 batch: 0.443952
Train loss on 1750 batch: 0.432123
Train loss on 1800 batch: 0.387481
Train loss on 1850 batch: 0.432208
Train loss on 1900 batch: 0.346453
best-train-loss: 0.428838
best-valid-loss: 0.463035
best-kappa: 0.5840
: Epoch: 8 | Training Loss: 0.428838 | Val. Loss: 0.463035 | Val. Kappa Score: 0.5840 | LR: 0.000500 | Estimated time: 254.14
Train loss on 50 batch: 0.468181
Train loss on 100 batch: 0.374687
Train loss on 150 batch: 0.381239
Train loss on 200 batch: 0.396592
Train loss on 250 batch: 0.391449
Train loss on 300 batch: 0.427294
Train loss on 350 batch: 0.376198
Train loss on 400 batch: 0.450459
Train loss on 450 batch: 0.400282
Train loss on 500 batch: 0.412837
Train loss on 550 batch: 0.399318
Train loss on 600 batch: 0.429222
Train loss on 650 batch: 0.443638
Train loss on 700 batch: 0.454188
Train loss on 750 batch: 0.365830
Train loss on 800 batch: 0.415247
Train loss on 850 batch: 0.448657
Train loss on 900 batch: 0.418522
Train loss on 950 batch: 0.350240
Train loss on 1000 batch: 0.360607
Train loss on 1050 batch: 0.401182
Train loss on 1100 batch: 0.439481
Train loss on 1150 batch: 0.430198
Train loss on 1200 batch: 0.491965
Train loss on 1250 batch: 0.349795
Train loss on 1300 batch: 0.381927
Train loss on 1350 batch: 0.421204
Train loss on 1400 batch: 0.399681
Train loss on 1450 batch: 0.452844
Train loss on 1500 batch: 0.382851
Train loss on 1550 batch: 0.440372
Train loss on 1600 batch: 0.420026
Train loss on 1650 batch: 0.471790
Train loss on 1700 batch: 0.450969
Train loss on 1750 batch: 0.428163
Train loss on 1800 batch: 0.394993
Train loss on 1850 batch: 0.402817
Train loss on 1900 batch: 0.400101
: Epoch: 9 | Training Loss: 0.414224 | Val. Loss: 0.465590 | Val. Kappa Score: 0.5937 | LR: 0.000500 | Estimated time: 255.26
Train loss on 50 batch: 0.413137
Train loss on 100 batch: 0.373739
Train loss on 150 batch: 0.345043
Train loss on 200 batch: 0.370720
Train loss on 250 batch: 0.392445
Train loss on 300 batch: 0.426179
Train loss on 350 batch: 0.413528
Train loss on 400 batch: 0.388961
Train loss on 450 batch: 0.409704
Train loss on 500 batch: 0.414783
Train loss on 550 batch: 0.388553
Train loss on 600 batch: 0.351866
Train loss on 650 batch: 0.411627
Train loss on 700 batch: 0.445128
Train loss on 750 batch: 0.447487
Train loss on 800 batch: 0.467942
Train loss on 850 batch: 0.361093
Train loss on 900 batch: 0.404024
Train loss on 950 batch: 0.369834
Train loss on 1000 batch: 0.415448
Train loss on 1050 batch: 0.468862
Train loss on 1100 batch: 0.428395
Train loss on 1150 batch: 0.401770
Train loss on 1200 batch: 0.435062
Train loss on 1250 batch: 0.370536
Train loss on 1300 batch: 0.450721
Train loss on 1350 batch: 0.455074
Train loss on 1400 batch: 0.520686
Train loss on 1450 batch: 0.410800
Train loss on 1500 batch: 0.480028
Train loss on 1550 batch: 0.435933
Train loss on 1600 batch: 0.426206
Train loss on 1650 batch: 0.429501
Train loss on 1700 batch: 0.391324
Train loss on 1750 batch: 0.394522
Train loss on 1800 batch: 0.403264
Train loss on 1850 batch: 0.338555
Train loss on 1900 batch: 0.406230
best-train-loss: 0.410152
best-valid-loss: 0.441665
best-kappa: 0.6007
: Epoch: 10 | Training Loss: 0.410152 | Val. Loss: 0.441665 | Val. Kappa Score: 0.6007 | LR: 0.000500 | Estimated time: 257.04
Train loss on 50 batch: 0.411115
Train loss on 100 batch: 0.364740
Train loss on 150 batch: 0.350902
Train loss on 200 batch: 0.422093
Train loss on 250 batch: 0.411178
Train loss on 300 batch: 0.298038
Train loss on 350 batch: 0.418959
Train loss on 400 batch: 0.366125
Train loss on 450 batch: 0.428556
Train loss on 500 batch: 0.435528
Train loss on 550 batch: 0.371760
Train loss on 600 batch: 0.435559
Train loss on 650 batch: 0.347998
Train loss on 700 batch: 0.457352
Train loss on 750 batch: 0.451300
Train loss on 800 batch: 0.430873
Train loss on 850 batch: 0.514908
Train loss on 900 batch: 0.441026
Train loss on 950 batch: 0.377596
Train loss on 1000 batch: 0.380399
Train loss on 1050 batch: 0.468995
Train loss on 1100 batch: 0.385846
Train loss on 1150 batch: 0.412735
Train loss on 1200 batch: 0.399265
Train loss on 1250 batch: 0.429040
Train loss on 1300 batch: 0.342323
Train loss on 1350 batch: 0.373980
Train loss on 1400 batch: 0.399698
Train loss on 1450 batch: 0.383919
Train loss on 1500 batch: 0.382573
Train loss on 1550 batch: 0.360911
Train loss on 1600 batch: 0.383448
Train loss on 1650 batch: 0.351614
Train loss on 1700 batch: 0.396557
Train loss on 1750 batch: 0.422406
Train loss on 1800 batch: 0.434028
Train loss on 1850 batch: 0.360179
Train loss on 1900 batch: 0.454770
: Epoch: 11 | Training Loss: 0.401720 | Val. Loss: 0.451577 | Val. Kappa Score: 0.6072 | LR: 0.000500 | Estimated time: 253.98
Train loss on 50 batch: 0.436173
Train loss on 100 batch: 0.442410
Train loss on 150 batch: 0.430626
Train loss on 200 batch: 0.355718
Train loss on 250 batch: 0.408312
Train loss on 300 batch: 0.389077
Train loss on 350 batch: 0.340673
Train loss on 400 batch: 0.352974
Train loss on 450 batch: 0.307931
Train loss on 500 batch: 0.447250
Train loss on 550 batch: 0.431715
Train loss on 600 batch: 0.412409
Train loss on 650 batch: 0.387485
Train loss on 700 batch: 0.422088
Train loss on 750 batch: 0.410983
Train loss on 800 batch: 0.351754
Train loss on 850 batch: 0.350617
Train loss on 900 batch: 0.428789
Train loss on 950 batch: 0.341064
Train loss on 1000 batch: 0.412748
Train loss on 1050 batch: 0.397702
Train loss on 1100 batch: 0.378528
Train loss on 1150 batch: 0.382768
Train loss on 1200 batch: 0.396024
Train loss on 1250 batch: 0.368445
Train loss on 1300 batch: 0.395969
Train loss on 1350 batch: 0.380065
Train loss on 1400 batch: 0.379337
Train loss on 1450 batch: 0.393942
Train loss on 1500 batch: 0.374995
Train loss on 1550 batch: 0.380999
Train loss on 1600 batch: 0.410420
Train loss on 1650 batch: 0.389967
Train loss on 1700 batch: 0.406352
Train loss on 1750 batch: 0.355479
Train loss on 1800 batch: 0.399411
Train loss on 1850 batch: 0.399955
Train loss on 1900 batch: 0.418436
: Epoch: 12 | Training Loss: 0.392424 | Val. Loss: 0.450344 | Val. Kappa Score: 0.6106 | LR: 0.000500 | Estimated time: 253.91
Train loss on 50 batch: 0.378202
Train loss on 100 batch: 0.400939
Train loss on 150 batch: 0.356241
Train loss on 200 batch: 0.403878
Train loss on 250 batch: 0.349191
Train loss on 300 batch: 0.434698
Train loss on 350 batch: 0.381079
Train loss on 400 batch: 0.439128
Train loss on 450 batch: 0.367150
Train loss on 500 batch: 0.397087
Train loss on 550 batch: 0.373016
Train loss on 600 batch: 0.372559
Train loss on 650 batch: 0.368187
Train loss on 700 batch: 0.428800
Train loss on 750 batch: 0.431780
Train loss on 800 batch: 0.445697
Train loss on 850 batch: 0.369037
Train loss on 900 batch: 0.470694
Train loss on 950 batch: 0.392563
Train loss on 1000 batch: 0.391988
Train loss on 1050 batch: 0.431818
Train loss on 1100 batch: 0.406740
Train loss on 1150 batch: 0.385142
Train loss on 1200 batch: 0.368661
Train loss on 1250 batch: 0.398276
Train loss on 1300 batch: 0.378807
Train loss on 1350 batch: 0.365689
Train loss on 1400 batch: 0.451405
Train loss on 1450 batch: 0.382060
Train loss on 1500 batch: 0.396238
Train loss on 1550 batch: 0.401652
Train loss on 1600 batch: 0.425158
Train loss on 1650 batch: 0.401357
Train loss on 1700 batch: 0.373529
Train loss on 1750 batch: 0.389038
Train loss on 1800 batch: 0.434513
Train loss on 1850 batch: 0.381772
Train loss on 1900 batch: 0.378694
best-train-loss: 0.398049
best-valid-loss: 0.432411
best-kappa: 0.6178
: Epoch: 13 | Training Loss: 0.398049 | Val. Loss: 0.432411 | Val. Kappa Score: 0.6178 | LR: 0.000500 | Estimated time: 252.15
Train loss on 50 batch: 0.368909
Train loss on 100 batch: 0.414287
Train loss on 150 batch: 0.364037
Train loss on 200 batch: 0.360609
Train loss on 250 batch: 0.377410
Train loss on 300 batch: 0.434044
Train loss on 350 batch: 0.373496
Train loss on 400 batch: 0.376622
Train loss on 450 batch: 0.371266
Train loss on 500 batch: 0.389179
Train loss on 550 batch: 0.377062
Train loss on 600 batch: 0.346450
Train loss on 650 batch: 0.387419
Train loss on 700 batch: 0.405165
Train loss on 750 batch: 0.329940
Train loss on 800 batch: 0.380804
Train loss on 850 batch: 0.391905
Train loss on 900 batch: 0.398862
Train loss on 950 batch: 0.359156
Train loss on 1000 batch: 0.361024
Train loss on 1050 batch: 0.405763
Train loss on 1100 batch: 0.346940
Train loss on 1150 batch: 0.280089
Train loss on 1200 batch: 0.373607
Train loss on 1250 batch: 0.475319
Train loss on 1300 batch: 0.408601
Train loss on 1350 batch: 0.392631
Train loss on 1400 batch: 0.460500
Train loss on 1450 batch: 0.404986
Train loss on 1500 batch: 0.356288
Train loss on 1550 batch: 0.351594
Train loss on 1600 batch: 0.348710
Train loss on 1650 batch: 0.431012
Train loss on 1700 batch: 0.382919
Train loss on 1750 batch: 0.337748
Train loss on 1800 batch: 0.454939
Train loss on 1850 batch: 0.358329
Train loss on 1900 batch: 0.480344
: Epoch: 14 | Training Loss: 0.383477 | Val. Loss: 0.501809 | Val. Kappa Score: 0.6191 | LR: 0.000500 | Estimated time: 251.92
Train loss on 50 batch: 0.350846
Train loss on 100 batch: 0.349045
Train loss on 150 batch: 0.359695
Train loss on 200 batch: 0.455243
Train loss on 250 batch: 0.441143
Train loss on 300 batch: 0.380877
Train loss on 350 batch: 0.438145
Train loss on 400 batch: 0.343808
Train loss on 450 batch: 0.406814
Train loss on 500 batch: 0.348962
Train loss on 550 batch: 0.441990
Train loss on 600 batch: 0.372576
Train loss on 650 batch: 0.392986
Train loss on 700 batch: 0.353323
Train loss on 750 batch: 0.369942
Train loss on 800 batch: 0.381198
Train loss on 850 batch: 0.430405
Train loss on 900 batch: 0.430288
Train loss on 950 batch: 0.440938
Train loss on 1000 batch: 0.371982
Train loss on 1050 batch: 0.407491
Train loss on 1100 batch: 0.414535
Train loss on 1150 batch: 0.388883
Train loss on 1200 batch: 0.366139
Train loss on 1250 batch: 0.341426
Train loss on 1300 batch: 0.404241
Train loss on 1350 batch: 0.377924
Train loss on 1400 batch: 0.391876
Train loss on 1450 batch: 0.373914
Train loss on 1500 batch: 0.327158
Train loss on 1550 batch: 0.354646
Train loss on 1600 batch: 0.398043
Train loss on 1650 batch: 0.388225
Train loss on 1700 batch: 0.288040
Train loss on 1750 batch: 0.321033
Train loss on 1800 batch: 0.395199
Train loss on 1850 batch: 0.441000
Train loss on 1900 batch: 0.425104
best-train-loss: 0.383754
best-valid-loss: 0.403407
best-kappa: 0.6245
: Epoch: 15 | Training Loss: 0.383754 | Val. Loss: 0.403407 | Val. Kappa Score: 0.6245 | LR: 0.000500 | Estimated time: 253.71
Train loss on 50 batch: 0.305537
Train loss on 100 batch: 0.347866
Train loss on 150 batch: 0.442847
Train loss on 200 batch: 0.322067
Train loss on 250 batch: 0.373926
Train loss on 300 batch: 0.383399
Train loss on 350 batch: 0.344748
Train loss on 400 batch: 0.361382
Train loss on 450 batch: 0.323496
Train loss on 500 batch: 0.385979
Train loss on 550 batch: 0.365439
Train loss on 600 batch: 0.385099
Train loss on 650 batch: 0.412910
Train loss on 700 batch: 0.320389
Train loss on 750 batch: 0.424401
Train loss on 800 batch: 0.424853
Train loss on 850 batch: 0.398269
Train loss on 900 batch: 0.375970
Train loss on 950 batch: 0.408531
Train loss on 1000 batch: 0.376833
Train loss on 1050 batch: 0.383784
Train loss on 1100 batch: 0.372831
Train loss on 1150 batch: 0.366662
Train loss on 1200 batch: 0.368552
Train loss on 1250 batch: 0.299912
Train loss on 1300 batch: 0.350793
Train loss on 1350 batch: 0.347470
Train loss on 1400 batch: 0.357751
Train loss on 1450 batch: 0.325480
Train loss on 1500 batch: 0.366027
Train loss on 1550 batch: 0.414179
Train loss on 1600 batch: 0.371933
Train loss on 1650 batch: 0.399518
Train loss on 1700 batch: 0.466231
Train loss on 1750 batch: 0.359606
Train loss on 1800 batch: 0.389725
Train loss on 1850 batch: 0.374780
Train loss on 1900 batch: 0.346400
: Epoch: 16 | Training Loss: 0.373326 | Val. Loss: 0.435086 | Val. Kappa Score: 0.6247 | LR: 0.000500 | Estimated time: 251.94
Train loss on 50 batch: 0.371513
Train loss on 100 batch: 0.359013
Train loss on 150 batch: 0.424512
Train loss on 200 batch: 0.412657
Train loss on 250 batch: 0.384882
Train loss on 300 batch: 0.395705
Train loss on 350 batch: 0.406128
Train loss on 400 batch: 0.386090
Train loss on 450 batch: 0.355178
Train loss on 500 batch: 0.361025
Train loss on 550 batch: 0.342807
Train loss on 600 batch: 0.368554
Train loss on 650 batch: 0.364805
Train loss on 700 batch: 0.347584
Train loss on 750 batch: 0.391719
Train loss on 800 batch: 0.375250
Train loss on 850 batch: 0.434967
Train loss on 900 batch: 0.402746
Train loss on 950 batch: 0.376639
Train loss on 1000 batch: 0.391687
Train loss on 1050 batch: 0.378224
Train loss on 1100 batch: 0.382975
Train loss on 1150 batch: 0.314033
Train loss on 1200 batch: 0.388646
Train loss on 1250 batch: 0.353703
Train loss on 1300 batch: 0.360775
Train loss on 1350 batch: 0.309453
Train loss on 1400 batch: 0.406811
Train loss on 1450 batch: 0.425682
Train loss on 1500 batch: 0.366069
Train loss on 1550 batch: 0.404578
Train loss on 1600 batch: 0.353817
Train loss on 1650 batch: 0.384682
Train loss on 1700 batch: 0.380480
Train loss on 1750 batch: 0.396210
Train loss on 1800 batch: 0.349997
Train loss on 1850 batch: 0.359776
Train loss on 1900 batch: 0.332172
: Epoch: 17 | Training Loss: 0.374489 | Val. Loss: 0.413314 | Val. Kappa Score: 0.6288 | LR: 0.000500 | Estimated time: 252.16
Train loss on 50 batch: 0.365807
Train loss on 100 batch: 0.339110
Train loss on 150 batch: 0.363140
Train loss on 200 batch: 0.376010
Train loss on 250 batch: 0.405267
Train loss on 300 batch: 0.359756
Train loss on 350 batch: 0.341456
Train loss on 400 batch: 0.353300
Train loss on 450 batch: 0.436985
Train loss on 500 batch: 0.328591
Train loss on 550 batch: 0.398094
Train loss on 600 batch: 0.376446
Train loss on 650 batch: 0.313360
Train loss on 700 batch: 0.327693
Train loss on 750 batch: 0.342731
Train loss on 800 batch: 0.374536
Train loss on 850 batch: 0.341205
Train loss on 900 batch: 0.412576
Train loss on 950 batch: 0.385162
Train loss on 1000 batch: 0.349937
Train loss on 1050 batch: 0.434877
Train loss on 1100 batch: 0.403276
Train loss on 1150 batch: 0.341518
Train loss on 1200 batch: 0.404494
Train loss on 1250 batch: 0.359400
Train loss on 1300 batch: 0.349194
Train loss on 1350 batch: 0.378599
Train loss on 1400 batch: 0.399553
Train loss on 1450 batch: 0.424011
Train loss on 1500 batch: 0.359337
Train loss on 1550 batch: 0.360285
Train loss on 1600 batch: 0.318742
Train loss on 1650 batch: 0.311851
Train loss on 1700 batch: 0.416778
Train loss on 1750 batch: 0.336517
Train loss on 1800 batch: 0.348533
Train loss on 1850 batch: 0.342014
Train loss on 1900 batch: 0.398775
: Epoch: 18 | Training Loss: 0.369216 | Val. Loss: 0.426001 | Val. Kappa Score: 0.6318 | LR: 0.000250 | Estimated time: 253.13
Train loss on 50 batch: 0.305343
Train loss on 100 batch: 0.324830
Train loss on 150 batch: 0.383752
Train loss on 200 batch: 0.339659
Train loss on 250 batch: 0.395854
Train loss on 300 batch: 0.377411
Train loss on 350 batch: 0.336463
Train loss on 400 batch: 0.298743
Train loss on 450 batch: 0.383363
Train loss on 500 batch: 0.346282
Train loss on 550 batch: 0.274478
Train loss on 600 batch: 0.382205
Train loss on 650 batch: 0.371471
Train loss on 700 batch: 0.333358
Train loss on 750 batch: 0.329306
Train loss on 800 batch: 0.312484
Train loss on 850 batch: 0.397071
Train loss on 900 batch: 0.367279
Train loss on 950 batch: 0.333751
Train loss on 1000 batch: 0.348892
Train loss on 1050 batch: 0.363178
Train loss on 1100 batch: 0.320684
Train loss on 1150 batch: 0.257783
Train loss on 1200 batch: 0.292974
Train loss on 1250 batch: 0.361084
Train loss on 1300 batch: 0.347036
Train loss on 1350 batch: 0.383738
Train loss on 1400 batch: 0.349106
Train loss on 1450 batch: 0.297120
Train loss on 1500 batch: 0.318196
Train loss on 1550 batch: 0.330782
Train loss on 1600 batch: 0.334066
Train loss on 1650 batch: 0.321737
Train loss on 1700 batch: 0.311051
Train loss on 1750 batch: 0.294830
Train loss on 1800 batch: 0.413696
Train loss on 1850 batch: 0.314775
Train loss on 1900 batch: 0.375670
: Epoch: 19 | Training Loss: 0.340922 | Val. Loss: 0.420539 | Val. Kappa Score: 0.6354 | LR: 0.000250 | Estimated time: 253.34
Train loss on 50 batch: 0.284423
Train loss on 100 batch: 0.394772
Train loss on 150 batch: 0.272365
Train loss on 200 batch: 0.350983
Train loss on 250 batch: 0.340690
Train loss on 300 batch: 0.323520
Train loss on 350 batch: 0.306213
Train loss on 400 batch: 0.368042
Train loss on 450 batch: 0.337281
Train loss on 500 batch: 0.334829
Train loss on 550 batch: 0.351534
Train loss on 600 batch: 0.306966
Train loss on 650 batch: 0.376807
Train loss on 700 batch: 0.335258
Train loss on 750 batch: 0.364333
Train loss on 800 batch: 0.321064
Train loss on 850 batch: 0.386325
Train loss on 900 batch: 0.343081
Train loss on 950 batch: 0.315165
Train loss on 1000 batch: 0.308989
Train loss on 1050 batch: 0.403537
Train loss on 1100 batch: 0.320973
Train loss on 1150 batch: 0.336024
Train loss on 1200 batch: 0.342635
Train loss on 1250 batch: 0.270052
Train loss on 1300 batch: 0.295858
Train loss on 1350 batch: 0.279894
Train loss on 1400 batch: 0.342762
Train loss on 1450 batch: 0.292122
Train loss on 1500 batch: 0.314318
Train loss on 1550 batch: 0.345744
Train loss on 1600 batch: 0.343498
Train loss on 1650 batch: 0.321125
Train loss on 1700 batch: 0.338497
Train loss on 1750 batch: 0.332965
Train loss on 1800 batch: 0.353576
Train loss on 1850 batch: 0.362679
Train loss on 1900 batch: 0.378096
best-train-loss: 0.334558
best-valid-loss: 0.377411
best-kappa: 0.6388
: Epoch: 20 | Training Loss: 0.334558 | Val. Loss: 0.377411 | Val. Kappa Score: 0.6388 | LR: 0.000250 | Estimated time: 251.97
Train loss on 50 batch: 0.300335
Train loss on 100 batch: 0.325829
Train loss on 150 batch: 0.347358
Train loss on 200 batch: 0.356827
Train loss on 250 batch: 0.293801
Train loss on 300 batch: 0.343150
Train loss on 350 batch: 0.309726
Train loss on 400 batch: 0.341330
Train loss on 450 batch: 0.293502
Train loss on 500 batch: 0.309545
Train loss on 550 batch: 0.342983
Train loss on 600 batch: 0.374573
Train loss on 650 batch: 0.302505
Train loss on 700 batch: 0.324126
Train loss on 750 batch: 0.289845
Train loss on 800 batch: 0.318105
Train loss on 850 batch: 0.315014
Train loss on 900 batch: 0.438967
Train loss on 950 batch: 0.318010
Train loss on 1000 batch: 0.336230
Train loss on 1050 batch: 0.298040
Train loss on 1100 batch: 0.362510
Train loss on 1150 batch: 0.312354
Train loss on 1200 batch: 0.322192
Train loss on 1250 batch: 0.364098
Train loss on 1300 batch: 0.290980
Train loss on 1350 batch: 0.384356
Train loss on 1400 batch: 0.338827
Train loss on 1450 batch: 0.354935
Train loss on 1500 batch: 0.318857
Train loss on 1550 batch: 0.323640
Train loss on 1600 batch: 0.337219
Train loss on 1650 batch: 0.285932
Train loss on 1700 batch: 0.406826
Train loss on 1750 batch: 0.357741
Train loss on 1800 batch: 0.287505
Train loss on 1850 batch: 0.321775
Train loss on 1900 batch: 0.345205
: Epoch: 21 | Training Loss: 0.332574 | Val. Loss: 0.424702 | Val. Kappa Score: 0.6412 | LR: 0.000250 | Estimated time: 254.45
Train loss on 50 batch: 0.281755
Train loss on 100 batch: 0.332981
Train loss on 150 batch: 0.390988
Train loss on 200 batch: 0.314718
Train loss on 250 batch: 0.337266
Train loss on 300 batch: 0.329472
Train loss on 350 batch: 0.280631
Train loss on 400 batch: 0.320080
Train loss on 450 batch: 0.342428
Train loss on 500 batch: 0.325149
Train loss on 550 batch: 0.306451
Train loss on 600 batch: 0.301243
Train loss on 650 batch: 0.321898
Train loss on 700 batch: 0.354251
Train loss on 750 batch: 0.347575
Train loss on 800 batch: 0.303321
Train loss on 850 batch: 0.340444
Train loss on 900 batch: 0.337119
Train loss on 950 batch: 0.283810
Train loss on 1000 batch: 0.327306
Train loss on 1050 batch: 0.316768
Train loss on 1100 batch: 0.298968
Train loss on 1150 batch: 0.341942
Train loss on 1200 batch: 0.403501
Train loss on 1250 batch: 0.266551
Train loss on 1300 batch: 0.323036
Train loss on 1350 batch: 0.339775
Train loss on 1400 batch: 0.358495
Train loss on 1450 batch: 0.323772
Train loss on 1500 batch: 0.409247
Train loss on 1550 batch: 0.308482
Train loss on 1600 batch: 0.318879
Train loss on 1650 batch: 0.323825
Train loss on 1700 batch: 0.313276
Train loss on 1750 batch: 0.289549
Train loss on 1800 batch: 0.356046
Train loss on 1850 batch: 0.354493
Train loss on 1900 batch: 0.303575
: Epoch: 22 | Training Loss: 0.327848 | Val. Loss: 0.386334 | Val. Kappa Score: 0.6443 | LR: 0.000250 | Estimated time: 253.20
Train loss on 50 batch: 0.281723
Train loss on 100 batch: 0.286111
Train loss on 150 batch: 0.285239
Train loss on 200 batch: 0.317510
Train loss on 250 batch: 0.380935
Train loss on 300 batch: 0.332094
Train loss on 350 batch: 0.336618
Train loss on 400 batch: 0.341432
Train loss on 450 batch: 0.350651
Train loss on 500 batch: 0.284748
Train loss on 550 batch: 0.338956
Train loss on 600 batch: 0.369940
Train loss on 650 batch: 0.313070
Train loss on 700 batch: 0.338844
Train loss on 750 batch: 0.314507
Train loss on 800 batch: 0.324878
Train loss on 850 batch: 0.373018
Train loss on 900 batch: 0.291239
Train loss on 950 batch: 0.297057
Train loss on 1000 batch: 0.338952
Train loss on 1050 batch: 0.323150
Train loss on 1100 batch: 0.358152
Train loss on 1150 batch: 0.415622
Train loss on 1200 batch: 0.291767
Train loss on 1250 batch: 0.373479
Train loss on 1300 batch: 0.312158
Train loss on 1350 batch: 0.337928
Train loss on 1400 batch: 0.341154
Train loss on 1450 batch: 0.343475
Train loss on 1500 batch: 0.280072
Train loss on 1550 batch: 0.316642
Train loss on 1600 batch: 0.282211
Train loss on 1650 batch: 0.347421
Train loss on 1700 batch: 0.329267
Train loss on 1750 batch: 0.322718
Train loss on 1800 batch: 0.365892
Train loss on 1850 batch: 0.289334
Train loss on 1900 batch: 0.299938
best-train-loss: 0.327048
best-valid-loss: 0.377059
best-kappa: 0.6467
: Epoch: 23 | Training Loss: 0.327048 | Val. Loss: 0.377059 | Val. Kappa Score: 0.6467 | LR: 0.000250 | Estimated time: 254.59
Train loss on 50 batch: 0.314464
Train loss on 100 batch: 0.280200
Train loss on 150 batch: 0.276733
Train loss on 200 batch: 0.333628
Train loss on 250 batch: 0.239026
Train loss on 300 batch: 0.244548
Train loss on 350 batch: 0.378079
Train loss on 400 batch: 0.292625
Train loss on 450 batch: 0.318998
Train loss on 500 batch: 0.318656
Train loss on 550 batch: 0.293955
Train loss on 600 batch: 0.342747
Train loss on 650 batch: 0.334660
Train loss on 700 batch: 0.292454
Train loss on 750 batch: 0.297504
Train loss on 800 batch: 0.336625
Train loss on 850 batch: 0.300464
Train loss on 900 batch: 0.330941
Train loss on 950 batch: 0.323222
Train loss on 1000 batch: 0.292540
Train loss on 1050 batch: 0.339310
Train loss on 1100 batch: 0.300535
Train loss on 1150 batch: 0.320208
Train loss on 1200 batch: 0.351648
Train loss on 1250 batch: 0.352235
Train loss on 1300 batch: 0.327397
Train loss on 1350 batch: 0.334440
Train loss on 1400 batch: 0.294696
Train loss on 1450 batch: 0.338194
Train loss on 1500 batch: 0.372408
Train loss on 1550 batch: 0.341573
Train loss on 1600 batch: 0.380521
Train loss on 1650 batch: 0.301881
Train loss on 1700 batch: 0.381945
Train loss on 1750 batch: 0.295229
Train loss on 1800 batch: 0.348194
Train loss on 1850 batch: 0.285762
Train loss on 1900 batch: 0.310172
: Epoch: 24 | Training Loss: 0.318872 | Val. Loss: 0.384793 | Val. Kappa Score: 0.6488 | LR: 0.000250 | Estimated time: 253.40
Train loss on 50 batch: 0.325236
Train loss on 100 batch: 0.325570
Train loss on 150 batch: 0.306683
Train loss on 200 batch: 0.296969
Train loss on 250 batch: 0.330507
Train loss on 300 batch: 0.315071
Train loss on 350 batch: 0.317953
Train loss on 400 batch: 0.307150
Train loss on 450 batch: 0.303897
Train loss on 500 batch: 0.317935
Train loss on 550 batch: 0.320478
Train loss on 600 batch: 0.288108
Train loss on 650 batch: 0.368942
Train loss on 700 batch: 0.329859
Train loss on 750 batch: 0.268512
Train loss on 800 batch: 0.343895
Train loss on 850 batch: 0.299869
Train loss on 900 batch: 0.278090
Train loss on 950 batch: 0.339331
Train loss on 1000 batch: 0.315677
Train loss on 1050 batch: 0.376555
Train loss on 1100 batch: 0.338494
Train loss on 1150 batch: 0.277832
Train loss on 1200 batch: 0.265008
Train loss on 1250 batch: 0.317022
Train loss on 1300 batch: 0.279496
Train loss on 1350 batch: 0.307242
Train loss on 1400 batch: 0.336229
Train loss on 1450 batch: 0.287806
Train loss on 1500 batch: 0.332325
Train loss on 1550 batch: 0.289676
Train loss on 1600 batch: 0.355561
Train loss on 1650 batch: 0.301662
Train loss on 1700 batch: 0.397376
Train loss on 1750 batch: 0.305001
Train loss on 1800 batch: 0.338927
Train loss on 1850 batch: 0.345938
Train loss on 1900 batch: 0.331056
: Epoch: 25 | Training Loss: 0.317549 | Val. Loss: 0.386853 | Val. Kappa Score: 0.6512 | LR: 0.000250 | Estimated time: 255.07
Train loss on 50 batch: 0.302813
Train loss on 100 batch: 0.306729
Train loss on 150 batch: 0.287429
Train loss on 200 batch: 0.311891
Train loss on 250 batch: 0.333995
Train loss on 300 batch: 0.296088
Train loss on 350 batch: 0.290549
Train loss on 400 batch: 0.352342
Train loss on 450 batch: 0.291735
Train loss on 500 batch: 0.345821
Train loss on 550 batch: 0.295421
Train loss on 600 batch: 0.301521
Train loss on 650 batch: 0.311378
Train loss on 700 batch: 0.312601
Train loss on 750 batch: 0.298444
Train loss on 800 batch: 0.284683
Train loss on 850 batch: 0.331615
Train loss on 900 batch: 0.302294
Train loss on 950 batch: 0.330339
Train loss on 1000 batch: 0.317772
Train loss on 1050 batch: 0.301763
Train loss on 1100 batch: 0.311948
Train loss on 1150 batch: 0.354319
Train loss on 1200 batch: 0.354502
Train loss on 1250 batch: 0.311799
Train loss on 1300 batch: 0.251855
Train loss on 1350 batch: 0.342895
Train loss on 1400 batch: 0.336181
Train loss on 1450 batch: 0.306491
Train loss on 1500 batch: 0.347842
Train loss on 1550 batch: 0.286604
Train loss on 1600 batch: 0.299708
Train loss on 1650 batch: 0.340949
Train loss on 1700 batch: 0.314195
Train loss on 1750 batch: 0.323732
Train loss on 1800 batch: 0.346466
Train loss on 1850 batch: 0.327555
Train loss on 1900 batch: 0.327420
best-train-loss: 0.315774
best-valid-loss: 0.362127
best-kappa: 0.6538
: Epoch: 26 | Training Loss: 0.315774 | Val. Loss: 0.362127 | Val. Kappa Score: 0.6538 | LR: 0.000250 | Estimated time: 251.66
Train loss on 50 batch: 0.307206
Train loss on 100 batch: 0.278113
Train loss on 150 batch: 0.360224
Train loss on 200 batch: 0.341785
Train loss on 250 batch: 0.276798
Train loss on 300 batch: 0.325561
Train loss on 350 batch: 0.319626
Train loss on 400 batch: 0.303536
Train loss on 450 batch: 0.281533
Train loss on 500 batch: 0.297068
Train loss on 550 batch: 0.362506
Train loss on 600 batch: 0.328032
Train loss on 650 batch: 0.347469
Train loss on 700 batch: 0.342084
Train loss on 750 batch: 0.302557
Train loss on 800 batch: 0.326766
Train loss on 850 batch: 0.304347
Train loss on 900 batch: 0.324208
Train loss on 950 batch: 0.313928
Train loss on 1000 batch: 0.313708
Train loss on 1050 batch: 0.341542
Train loss on 1100 batch: 0.317302
Train loss on 1150 batch: 0.306758
Train loss on 1200 batch: 0.287424
Train loss on 1250 batch: 0.394348
Train loss on 1300 batch: 0.337946
Train loss on 1350 batch: 0.273369
Train loss on 1400 batch: 0.241359
Train loss on 1450 batch: 0.340924
Train loss on 1500 batch: 0.335224
Train loss on 1550 batch: 0.284294
Train loss on 1600 batch: 0.290762
Train loss on 1650 batch: 0.302172
Train loss on 1700 batch: 0.288132
Train loss on 1750 batch: 0.294424
Train loss on 1800 batch: 0.293342
Train loss on 1850 batch: 0.318074
Train loss on 1900 batch: 0.289684
: Epoch: 27 | Training Loss: 0.312203 | Val. Loss: 0.383072 | Val. Kappa Score: 0.6560 | LR: 0.000250 | Estimated time: 253.27
Train loss on 50 batch: 0.318691
Train loss on 100 batch: 0.291756
Train loss on 150 batch: 0.302760
Train loss on 200 batch: 0.259781
Train loss on 250 batch: 0.331778
Train loss on 300 batch: 0.354730
Train loss on 350 batch: 0.344386
Train loss on 400 batch: 0.271705
Train loss on 450 batch: 0.294760
Train loss on 500 batch: 0.312965
Train loss on 550 batch: 0.313343
Train loss on 600 batch: 0.324024
Train loss on 650 batch: 0.307629
Train loss on 700 batch: 0.308307
Train loss on 750 batch: 0.287753
Train loss on 800 batch: 0.317931
Train loss on 850 batch: 0.284003
Train loss on 900 batch: 0.285688
Train loss on 950 batch: 0.328358
Train loss on 1000 batch: 0.337172
Train loss on 1050 batch: 0.326642
Train loss on 1100 batch: 0.294250
Train loss on 1150 batch: 0.291069
Train loss on 1200 batch: 0.309749
Train loss on 1250 batch: 0.302560
Train loss on 1300 batch: 0.257012
Train loss on 1350 batch: 0.326974
Train loss on 1400 batch: 0.312308
Train loss on 1450 batch: 0.329247
Train loss on 1500 batch: 0.308255
Train loss on 1550 batch: 0.338461
Train loss on 1600 batch: 0.362789
Train loss on 1650 batch: 0.298571
Train loss on 1700 batch: 0.316161
Train loss on 1750 batch: 0.333546
Train loss on 1800 batch: 0.279033
Train loss on 1850 batch: 0.301030
Train loss on 1900 batch: 0.266423
: Epoch: 28 | Training Loss: 0.308581 | Val. Loss: 0.369448 | Val. Kappa Score: 0.6582 | LR: 0.000250 | Estimated time: 253.21
Train loss on 50 batch: 0.279519
Train loss on 100 batch: 0.334005
Train loss on 150 batch: 0.323771
Train loss on 200 batch: 0.272437
Train loss on 250 batch: 0.319567
Train loss on 300 batch: 0.307083
Train loss on 350 batch: 0.319668
Train loss on 400 batch: 0.301886
Train loss on 450 batch: 0.329548
Train loss on 500 batch: 0.250471
Train loss on 550 batch: 0.259674
Train loss on 600 batch: 0.310325
Train loss on 650 batch: 0.270525
Train loss on 700 batch: 0.334907
Train loss on 750 batch: 0.316078
Train loss on 800 batch: 0.362994
Train loss on 850 batch: 0.327511
Train loss on 900 batch: 0.329327
Train loss on 950 batch: 0.306891
Train loss on 1000 batch: 0.286849
Train loss on 1050 batch: 0.290167
Train loss on 1100 batch: 0.312857
Train loss on 1150 batch: 0.277734
Train loss on 1200 batch: 0.382415
Train loss on 1250 batch: 0.318968
Train loss on 1300 batch: 0.316961
Train loss on 1350 batch: 0.336018
Train loss on 1400 batch: 0.320343
Train loss on 1450 batch: 0.335177
Train loss on 1500 batch: 0.283088
Train loss on 1550 batch: 0.276295
Train loss on 1600 batch: 0.325317
Train loss on 1650 batch: 0.302110
Train loss on 1700 batch: 0.292625
Train loss on 1750 batch: 0.312311
Train loss on 1800 batch: 0.311279
Train loss on 1850 batch: 0.263576
Train loss on 1900 batch: 0.258413
: Epoch: 29 | Training Loss: 0.307429 | Val. Loss: 0.399705 | Val. Kappa Score: 0.6604 | LR: 0.000125 | Estimated time: 253.05
Train loss on 50 batch: 0.296935
Train loss on 100 batch: 0.267082
Train loss on 150 batch: 0.275094
Train loss on 200 batch: 0.291729
Train loss on 250 batch: 0.317266
Train loss on 300 batch: 0.313016
Train loss on 350 batch: 0.355545
Train loss on 400 batch: 0.312188
Train loss on 450 batch: 0.325891
Train loss on 500 batch: 0.291962
Train loss on 550 batch: 0.372466
Train loss on 600 batch: 0.297602
Train loss on 650 batch: 0.276950
Train loss on 700 batch: 0.273148
Train loss on 750 batch: 0.305411
Train loss on 800 batch: 0.268029
Train loss on 850 batch: 0.309403
Train loss on 900 batch: 0.275922
Train loss on 950 batch: 0.275075
Train loss on 1000 batch: 0.358982
Train loss on 1050 batch: 0.266674
Train loss on 1100 batch: 0.328134
Train loss on 1150 batch: 0.301177
Train loss on 1200 batch: 0.328892
Train loss on 1250 batch: 0.293625
Train loss on 1300 batch: 0.264910
Train loss on 1350 batch: 0.251714
Train loss on 1400 batch: 0.275084
Train loss on 1450 batch: 0.309562
Train loss on 1500 batch: 0.258470
Train loss on 1550 batch: 0.231761
Train loss on 1600 batch: 0.290154
Train loss on 1650 batch: 0.254815
Train loss on 1700 batch: 0.333203
Train loss on 1750 batch: 0.261888
Train loss on 1800 batch: 0.243967
Train loss on 1850 batch: 0.294822
Train loss on 1900 batch: 0.277999
best-train-loss: 0.292271
best-valid-loss: 0.358920
best-kappa: 0.6627
: Epoch: 30 | Training Loss: 0.292271 | Val. Loss: 0.358920 | Val. Kappa Score: 0.6627 | LR: 0.000125 | Estimated time: 252.98
Train loss on 50 batch: 0.336069
Train loss on 100 batch: 0.318149
Train loss on 150 batch: 0.290974
Train loss on 200 batch: 0.255403
Train loss on 250 batch: 0.248026
Train loss on 300 batch: 0.281598
Train loss on 350 batch: 0.309613
Train loss on 400 batch: 0.282766
Train loss on 450 batch: 0.281721
Train loss on 500 batch: 0.294538
Train loss on 550 batch: 0.279264
Train loss on 600 batch: 0.284740
Train loss on 650 batch: 0.271363
Train loss on 700 batch: 0.285056
Train loss on 750 batch: 0.314882
Train loss on 800 batch: 0.280133
Train loss on 850 batch: 0.282851
Train loss on 900 batch: 0.253005
Train loss on 950 batch: 0.292891
Train loss on 1000 batch: 0.301837
Train loss on 1050 batch: 0.282150
Train loss on 1100 batch: 0.345749
Train loss on 1150 batch: 0.220603
Train loss on 1200 batch: 0.325289
Train loss on 1250 batch: 0.226838
Train loss on 1300 batch: 0.323295
Train loss on 1350 batch: 0.314626
Train loss on 1400 batch: 0.355588
Train loss on 1450 batch: 0.258691
Train loss on 1500 batch: 0.300981
Train loss on 1550 batch: 0.309138
Train loss on 1600 batch: 0.280952
Train loss on 1650 batch: 0.263681
Train loss on 1700 batch: 0.253835
Train loss on 1750 batch: 0.284936
Train loss on 1800 batch: 0.291963
Train loss on 1850 batch: 0.287182
Train loss on 1900 batch: 0.314471
: Epoch: 31 | Training Loss: 0.290597 | Val. Loss: 0.362701 | Val. Kappa Score: 0.6646 | LR: 0.000125 | Estimated time: 253.50
Train loss on 50 batch: 0.282127
Train loss on 100 batch: 0.324778
Train loss on 150 batch: 0.306868
Train loss on 200 batch: 0.298597
Train loss on 250 batch: 0.314360
Train loss on 300 batch: 0.269005
Train loss on 350 batch: 0.259713
Train loss on 400 batch: 0.311052
Train loss on 450 batch: 0.265732
Train loss on 500 batch: 0.326397
Train loss on 550 batch: 0.280034
Train loss on 600 batch: 0.315112
Train loss on 650 batch: 0.319546
Train loss on 700 batch: 0.289900
Train loss on 750 batch: 0.255757
Train loss on 800 batch: 0.312093
Train loss on 850 batch: 0.294187
Train loss on 900 batch: 0.230833
Train loss on 950 batch: 0.319674
Train loss on 1000 batch: 0.285789
Train loss on 1050 batch: 0.321976
Train loss on 1100 batch: 0.289377
Train loss on 1150 batch: 0.263718
Train loss on 1200 batch: 0.220012
Train loss on 1250 batch: 0.309016
Train loss on 1300 batch: 0.254312
Train loss on 1350 batch: 0.306976
Train loss on 1400 batch: 0.321913
Train loss on 1450 batch: 0.279457
Train loss on 1500 batch: 0.243005
Train loss on 1550 batch: 0.307158
Train loss on 1600 batch: 0.257647
Train loss on 1650 batch: 0.284977
Train loss on 1700 batch: 0.284577
Train loss on 1750 batch: 0.276138
Train loss on 1800 batch: 0.268686
Train loss on 1850 batch: 0.266783
Train loss on 1900 batch: 0.241479
best-train-loss: 0.284154
best-valid-loss: 0.352344
best-kappa: 0.6660
: Epoch: 32 | Training Loss: 0.284154 | Val. Loss: 0.352344 | Val. Kappa Score: 0.6660 | LR: 0.000125 | Estimated time: 253.14
Train loss on 50 batch: 0.238851
Train loss on 100 batch: 0.302461
Train loss on 150 batch: 0.269697
Train loss on 200 batch: 0.286506
Train loss on 250 batch: 0.326251
Train loss on 300 batch: 0.273345
Train loss on 350 batch: 0.277733
Train loss on 400 batch: 0.260413
Train loss on 450 batch: 0.274498
Train loss on 500 batch: 0.231938
Train loss on 550 batch: 0.253219
Train loss on 600 batch: 0.295369
Train loss on 650 batch: 0.294980
Train loss on 700 batch: 0.300306
Train loss on 750 batch: 0.272768
Train loss on 800 batch: 0.310417
Train loss on 850 batch: 0.326420
Train loss on 900 batch: 0.313614
Train loss on 950 batch: 0.263156
Train loss on 1000 batch: 0.263872
Train loss on 1050 batch: 0.261042
Train loss on 1100 batch: 0.261860
Train loss on 1150 batch: 0.271866
Train loss on 1200 batch: 0.225786
Train loss on 1250 batch: 0.277717
Train loss on 1300 batch: 0.282322
Train loss on 1350 batch: 0.282220
Train loss on 1400 batch: 0.299564
Train loss on 1450 batch: 0.350052
Train loss on 1500 batch: 0.327484
Train loss on 1550 batch: 0.307856
Train loss on 1600 batch: 0.290861
Train loss on 1650 batch: 0.294211
Train loss on 1700 batch: 0.257246
Train loss on 1750 batch: 0.287827
Train loss on 1800 batch: 0.265318
Train loss on 1850 batch: 0.280692
Train loss on 1900 batch: 0.256719
: Epoch: 33 | Training Loss: 0.281409 | Val. Loss: 0.358993 | Val. Kappa Score: 0.6674 | LR: 0.000125 | Estimated time: 252.33
Train loss on 50 batch: 0.224196
Train loss on 100 batch: 0.291340
Train loss on 150 batch: 0.309085
Train loss on 200 batch: 0.294162
Train loss on 250 batch: 0.254997
Train loss on 300 batch: 0.266016
Train loss on 350 batch: 0.262612
Train loss on 400 batch: 0.293372
Train loss on 450 batch: 0.278993
Train loss on 500 batch: 0.287024
Train loss on 550 batch: 0.295634
Train loss on 600 batch: 0.291148
Train loss on 650 batch: 0.316766
Train loss on 700 batch: 0.277502
Train loss on 750 batch: 0.308906
Train loss on 800 batch: 0.309757
Train loss on 850 batch: 0.272669
Train loss on 900 batch: 0.327043
Train loss on 950 batch: 0.272954
Train loss on 1000 batch: 0.345952
Train loss on 1050 batch: 0.255316
Train loss on 1100 batch: 0.377866
Train loss on 1150 batch: 0.269189
Train loss on 1200 batch: 0.302804
Train loss on 1250 batch: 0.308955
Train loss on 1300 batch: 0.252569
Train loss on 1350 batch: 0.292520
Train loss on 1400 batch: 0.301604
Train loss on 1450 batch: 0.252069
Train loss on 1500 batch: 0.248963
Train loss on 1550 batch: 0.281345
Train loss on 1600 batch: 0.236926
Train loss on 1650 batch: 0.252852
Train loss on 1700 batch: 0.275905
Train loss on 1750 batch: 0.267084
Train loss on 1800 batch: 0.283075
Train loss on 1850 batch: 0.223587
Train loss on 1900 batch: 0.252979
: Epoch: 34 | Training Loss: 0.282475 | Val. Loss: 0.354943 | Val. Kappa Score: 0.6693 | LR: 0.000125 | Estimated time: 252.81
Train loss on 50 batch: 0.216706
Train loss on 100 batch: 0.281336
Train loss on 150 batch: 0.243181
Train loss on 200 batch: 0.303355
Train loss on 250 batch: 0.229273
Train loss on 300 batch: 0.273544
Train loss on 350 batch: 0.280020
Train loss on 400 batch: 0.275803
Train loss on 450 batch: 0.277975
Train loss on 500 batch: 0.256166
Train loss on 550 batch: 0.281168
Train loss on 600 batch: 0.300784
Train loss on 650 batch: 0.290206
Train loss on 700 batch: 0.282688
Train loss on 750 batch: 0.297492
Train loss on 800 batch: 0.271183
Train loss on 850 batch: 0.283518
Train loss on 900 batch: 0.311334
Train loss on 950 batch: 0.274770
Train loss on 1000 batch: 0.285231
Train loss on 1050 batch: 0.288148
Train loss on 1100 batch: 0.274779
Train loss on 1150 batch: 0.290327
Train loss on 1200 batch: 0.322519
Train loss on 1250 batch: 0.296215
Train loss on 1300 batch: 0.261642
Train loss on 1350 batch: 0.296278
Train loss on 1400 batch: 0.258520
Train loss on 1450 batch: 0.273271
Train loss on 1500 batch: 0.270255
Train loss on 1550 batch: 0.261282
Train loss on 1600 batch: 0.289475
Train loss on 1650 batch: 0.275840
Train loss on 1700 batch: 0.273678
Train loss on 1750 batch: 0.346684
Train loss on 1800 batch: 0.305717
Train loss on 1850 batch: 0.298527
Train loss on 1900 batch: 0.255785
: Epoch: 35 | Training Loss: 0.280264 | Val. Loss: 0.360458 | Val. Kappa Score: 0.6705 | LR: 0.000063 | Estimated time: 254.36
Train loss on 50 batch: 0.274470
Train loss on 100 batch: 0.229121
Train loss on 150 batch: 0.289402
Train loss on 200 batch: 0.216756
Train loss on 250 batch: 0.306521
Train loss on 300 batch: 0.250594
Train loss on 350 batch: 0.275780
Train loss on 400 batch: 0.251862
Train loss on 450 batch: 0.240267
Train loss on 500 batch: 0.267785
Train loss on 550 batch: 0.263832
Train loss on 600 batch: 0.282406
Train loss on 650 batch: 0.272066
Train loss on 700 batch: 0.316161
Train loss on 750 batch: 0.261031
Train loss on 800 batch: 0.298407
Train loss on 850 batch: 0.279121
Train loss on 900 batch: 0.274952
Train loss on 950 batch: 0.287163
Train loss on 1000 batch: 0.322707
Train loss on 1050 batch: 0.263663
Train loss on 1100 batch: 0.276693
Train loss on 1150 batch: 0.244709
Train loss on 1200 batch: 0.268830
Train loss on 1250 batch: 0.274687
Train loss on 1300 batch: 0.259015
Train loss on 1350 batch: 0.226743
Train loss on 1400 batch: 0.243546
Train loss on 1450 batch: 0.280389
Train loss on 1500 batch: 0.282783
Train loss on 1550 batch: 0.292046
Train loss on 1600 batch: 0.299384
Train loss on 1650 batch: 0.262162
Train loss on 1700 batch: 0.291117
Train loss on 1750 batch: 0.272231
Train loss on 1800 batch: 0.264975
Train loss on 1850 batch: 0.267271
Train loss on 1900 batch: 0.251520
: Epoch: 36 | Training Loss: 0.270797 | Val. Loss: 0.360770 | Val. Kappa Score: 0.6717 | LR: 0.000063 | Estimated time: 251.68
Train loss on 50 batch: 0.248718
Train loss on 100 batch: 0.287325
Train loss on 150 batch: 0.270389
Train loss on 200 batch: 0.260730
Train loss on 250 batch: 0.330574
Train loss on 300 batch: 0.264674
Train loss on 350 batch: 0.308402
Train loss on 400 batch: 0.267017
Train loss on 450 batch: 0.240529
Train loss on 500 batch: 0.269810
Train loss on 550 batch: 0.244771
Train loss on 600 batch: 0.247749
Train loss on 650 batch: 0.245488
Train loss on 700 batch: 0.282469
Train loss on 750 batch: 0.260959
Train loss on 800 batch: 0.314735
Train loss on 850 batch: 0.236705
Train loss on 900 batch: 0.275049
Train loss on 950 batch: 0.309562
Train loss on 1000 batch: 0.250782
Train loss on 1050 batch: 0.247367
Train loss on 1100 batch: 0.273218
Train loss on 1150 batch: 0.258301
Train loss on 1200 batch: 0.291405
Train loss on 1250 batch: 0.268098
Train loss on 1300 batch: 0.233889
Train loss on 1350 batch: 0.269978
Train loss on 1400 batch: 0.275627
Train loss on 1450 batch: 0.314400
Train loss on 1500 batch: 0.246989
Train loss on 1550 batch: 0.243184
Train loss on 1600 batch: 0.292026
Train loss on 1650 batch: 0.295476
Train loss on 1700 batch: 0.268728
Train loss on 1750 batch: 0.318878
Train loss on 1800 batch: 0.248467
Train loss on 1850 batch: 0.302869
Train loss on 1900 batch: 0.236739
: Epoch: 37 | Training Loss: 0.270944 | Val. Loss: 0.355354 | Val. Kappa Score: 0.6731 | LR: 0.000063 | Estimated time: 252.66
Train loss on 50 batch: 0.272100
Train loss on 100 batch: 0.264770
Train loss on 150 batch: 0.219725
Train loss on 200 batch: 0.296573
Train loss on 250 batch: 0.230355
Train loss on 300 batch: 0.266166
Train loss on 350 batch: 0.252046
Train loss on 400 batch: 0.255134
Train loss on 450 batch: 0.292319
Train loss on 500 batch: 0.315704
Train loss on 550 batch: 0.298744
Train loss on 600 batch: 0.229222
Train loss on 650 batch: 0.260618
Train loss on 700 batch: 0.291998
Train loss on 750 batch: 0.303860
Train loss on 800 batch: 0.273026
Train loss on 850 batch: 0.229747
Train loss on 900 batch: 0.277102
Train loss on 950 batch: 0.279904
Train loss on 1000 batch: 0.279828
Train loss on 1050 batch: 0.249450
Train loss on 1100 batch: 0.285125
Train loss on 1150 batch: 0.217935
Train loss on 1200 batch: 0.267488
Train loss on 1250 batch: 0.261283
Train loss on 1300 batch: 0.268381
Train loss on 1350 batch: 0.294407
Train loss on 1400 batch: 0.265806
Train loss on 1450 batch: 0.231486
Train loss on 1500 batch: 0.253402
Train loss on 1550 batch: 0.309439
Train loss on 1600 batch: 0.300428
Train loss on 1650 batch: 0.279500
Train loss on 1700 batch: 0.260282
Train loss on 1750 batch: 0.257205
Train loss on 1800 batch: 0.269799
Train loss on 1850 batch: 0.261592
Train loss on 1900 batch: 0.224533
best-train-loss: 0.266456
best-valid-loss: 0.350073
best-kappa: 0.6740
: Epoch: 38 | Training Loss: 0.266456 | Val. Loss: 0.350073 | Val. Kappa Score: 0.6740 | LR: 0.000063 | Estimated time: 253.21
Train loss on 50 batch: 0.264752
Train loss on 100 batch: 0.248889
Train loss on 150 batch: 0.246222
Train loss on 200 batch: 0.257419
Train loss on 250 batch: 0.233243
Train loss on 300 batch: 0.260910
Train loss on 350 batch: 0.283372
Train loss on 400 batch: 0.251770
Train loss on 450 batch: 0.242513
Train loss on 500 batch: 0.299424
Train loss on 550 batch: 0.248304
Train loss on 600 batch: 0.250841
Train loss on 650 batch: 0.263145
Train loss on 700 batch: 0.241260
Train loss on 750 batch: 0.240798
Train loss on 800 batch: 0.257528
Train loss on 850 batch: 0.261244
Train loss on 900 batch: 0.311740
Train loss on 950 batch: 0.304731
Train loss on 1000 batch: 0.298867
Train loss on 1050 batch: 0.285698
Train loss on 1100 batch: 0.289294
Train loss on 1150 batch: 0.297563
Train loss on 1200 batch: 0.245916
Train loss on 1250 batch: 0.228206
Train loss on 1300 batch: 0.290410
Train loss on 1350 batch: 0.325383
Train loss on 1400 batch: 0.259001
Train loss on 1450 batch: 0.295638
Train loss on 1500 batch: 0.263416
Train loss on 1550 batch: 0.252979
Train loss on 1600 batch: 0.255864
Train loss on 1650 batch: 0.275531
Train loss on 1700 batch: 0.265648
Train loss on 1750 batch: 0.288219
Train loss on 1800 batch: 0.300260
Train loss on 1850 batch: 0.260112
Train loss on 1900 batch: 0.262508
best-train-loss: 0.268542
best-valid-loss: 0.347943
best-kappa: 0.6754
: Epoch: 39 | Training Loss: 0.268542 | Val. Loss: 0.347943 | Val. Kappa Score: 0.6754 | LR: 0.000063 | Estimated time: 254.71
Train loss on 50 batch: 0.264372
Train loss on 100 batch: 0.237451
Train loss on 150 batch: 0.250437
Train loss on 200 batch: 0.278100
Train loss on 250 batch: 0.269221
Train loss on 300 batch: 0.259190
Train loss on 350 batch: 0.241846
Train loss on 400 batch: 0.268389
Train loss on 450 batch: 0.311336
Train loss on 500 batch: 0.251618
Train loss on 550 batch: 0.258284
Train loss on 600 batch: 0.239404
Train loss on 650 batch: 0.271424
Train loss on 700 batch: 0.270385
Train loss on 750 batch: 0.239756
Train loss on 800 batch: 0.281763
Train loss on 850 batch: 0.310917
Train loss on 900 batch: 0.265043
Train loss on 950 batch: 0.283802
Train loss on 1000 batch: 0.247055
Train loss on 1050 batch: 0.265167
Train loss on 1100 batch: 0.273696
Train loss on 1150 batch: 0.267384
Train loss on 1200 batch: 0.255307
Train loss on 1250 batch: 0.282965
Train loss on 1300 batch: 0.282937
Train loss on 1350 batch: 0.241032
Train loss on 1400 batch: 0.239707
Train loss on 1450 batch: 0.283899
Train loss on 1500 batch: 0.271999
Train loss on 1550 batch: 0.241502
Train loss on 1600 batch: 0.256032
Train loss on 1650 batch: 0.289604
Train loss on 1700 batch: 0.290953
Train loss on 1750 batch: 0.299308
Train loss on 1800 batch: 0.261181
Train loss on 1850 batch: 0.243031
Train loss on 1900 batch: 0.313044
: Epoch: 40 | Training Loss: 0.267354 | Val. Loss: 0.351221 | Val. Kappa Score: 0.6766 | LR: 0.000063 | Estimated time: 252.89
Train loss on 50 batch: 0.324474
Train loss on 100 batch: 0.226610
Train loss on 150 batch: 0.259395
Train loss on 200 batch: 0.256235
Train loss on 250 batch: 0.260632
Train loss on 300 batch: 0.243407
Train loss on 350 batch: 0.269680
Train loss on 400 batch: 0.252441
Train loss on 450 batch: 0.235473
Train loss on 500 batch: 0.289052
Train loss on 550 batch: 0.312736
Train loss on 600 batch: 0.273604
Train loss on 650 batch: 0.244601
Train loss on 700 batch: 0.262093
Train loss on 750 batch: 0.255802
Train loss on 800 batch: 0.272911
Train loss on 850 batch: 0.307360
Train loss on 900 batch: 0.236586
Train loss on 950 batch: 0.224104
Train loss on 1000 batch: 0.233950
Train loss on 1050 batch: 0.269000
Train loss on 1100 batch: 0.278385
Train loss on 1150 batch: 0.274832
Train loss on 1200 batch: 0.246300
Train loss on 1250 batch: 0.276189
Train loss on 1300 batch: 0.251214
Train loss on 1350 batch: 0.218688
Train loss on 1400 batch: 0.287285
Train loss on 1450 batch: 0.222409
Train loss on 1500 batch: 0.237988
Train loss on 1550 batch: 0.296363
Train loss on 1600 batch: 0.288203
Train loss on 1650 batch: 0.248340
Train loss on 1700 batch: 0.269615
Train loss on 1750 batch: 0.238178
Train loss on 1800 batch: 0.322773
Train loss on 1850 batch: 0.263989
Train loss on 1900 batch: 0.267877
: Epoch: 41 | Training Loss: 0.264163 | Val. Loss: 0.352767 | Val. Kappa Score: 0.6780 | LR: 0.000063 | Estimated time: 253.50
Train loss on 50 batch: 0.250876
Train loss on 100 batch: 0.233860
Train loss on 150 batch: 0.238551
Train loss on 200 batch: 0.272390
Train loss on 250 batch: 0.280151
Train loss on 300 batch: 0.234509
Train loss on 350 batch: 0.260982
Train loss on 400 batch: 0.301896
Train loss on 450 batch: 0.304697
Train loss on 500 batch: 0.270593
Train loss on 550 batch: 0.284135
Train loss on 600 batch: 0.244970
Train loss on 650 batch: 0.271565
Train loss on 700 batch: 0.260509
Train loss on 750 batch: 0.241231
Train loss on 800 batch: 0.275463
Train loss on 850 batch: 0.263543
Train loss on 900 batch: 0.230603
Train loss on 950 batch: 0.289274
Train loss on 1000 batch: 0.283546
Train loss on 1050 batch: 0.252225
Train loss on 1100 batch: 0.285286
Train loss on 1150 batch: 0.249126
Train loss on 1200 batch: 0.258189
Train loss on 1250 batch: 0.258578
Train loss on 1300 batch: 0.292066
Train loss on 1350 batch: 0.249357
Train loss on 1400 batch: 0.295747
Train loss on 1450 batch: 0.241721
Train loss on 1500 batch: 0.257431
Train loss on 1550 batch: 0.238309
Train loss on 1600 batch: 0.264688
Train loss on 1650 batch: 0.246416
Train loss on 1700 batch: 0.244707
Train loss on 1750 batch: 0.266330
Train loss on 1800 batch: 0.236207
Train loss on 1850 batch: 0.259775
Train loss on 1900 batch: 0.247451
: Epoch: 42 | Training Loss: 0.262425 | Val. Loss: 0.352436 | Val. Kappa Score: 0.6792 | LR: 0.000031 | Estimated time: 253.99
Train loss on 50 batch: 0.274123
Train loss on 100 batch: 0.258324
Train loss on 150 batch: 0.266574
Train loss on 200 batch: 0.261077
Train loss on 250 batch: 0.271027
Train loss on 300 batch: 0.252231
Train loss on 350 batch: 0.293431
Train loss on 400 batch: 0.233069
Train loss on 450 batch: 0.279984
Train loss on 500 batch: 0.269490
Train loss on 550 batch: 0.266976
Train loss on 600 batch: 0.278965
Train loss on 650 batch: 0.231556
Train loss on 700 batch: 0.239923
Train loss on 750 batch: 0.249546
Train loss on 800 batch: 0.252544
Train loss on 850 batch: 0.258892
Train loss on 900 batch: 0.243725
Train loss on 950 batch: 0.257500
Train loss on 1000 batch: 0.302902
Train loss on 1050 batch: 0.283705
Train loss on 1100 batch: 0.264810
Train loss on 1150 batch: 0.296659
Train loss on 1200 batch: 0.287138
Train loss on 1250 batch: 0.240890
Train loss on 1300 batch: 0.267189
Train loss on 1350 batch: 0.250030
Train loss on 1400 batch: 0.213664
Train loss on 1450 batch: 0.257828
Train loss on 1500 batch: 0.255251
Train loss on 1550 batch: 0.235872
Train loss on 1600 batch: 0.243679
Train loss on 1650 batch: 0.244467
Train loss on 1700 batch: 0.258470
Train loss on 1750 batch: 0.228260
Train loss on 1800 batch: 0.262413
Train loss on 1850 batch: 0.231106
Train loss on 1900 batch: 0.260541
: Epoch: 43 | Training Loss: 0.258309 | Val. Loss: 0.352974 | Val. Kappa Score: 0.6802 | LR: 0.000031 | Estimated time: 253.47
Train loss on 50 batch: 0.214350
Train loss on 100 batch: 0.276260
Train loss on 150 batch: 0.225999
Train loss on 200 batch: 0.233086
Train loss on 250 batch: 0.230508
Train loss on 300 batch: 0.264965
Train loss on 350 batch: 0.223089
Train loss on 400 batch: 0.254901
Train loss on 450 batch: 0.250929
Train loss on 500 batch: 0.269346
Train loss on 550 batch: 0.263622
Train loss on 600 batch: 0.255625
Train loss on 650 batch: 0.273375
Train loss on 700 batch: 0.233094
Train loss on 750 batch: 0.258775
Train loss on 800 batch: 0.307158
Train loss on 850 batch: 0.250435
Train loss on 900 batch: 0.261121
Train loss on 950 batch: 0.244513
Train loss on 1000 batch: 0.259942
Train loss on 1050 batch: 0.222718
Train loss on 1100 batch: 0.272060
Train loss on 1150 batch: 0.304558
Train loss on 1200 batch: 0.266102
Train loss on 1250 batch: 0.278314
Train loss on 1300 batch: 0.252052
Train loss on 1350 batch: 0.241218
Train loss on 1400 batch: 0.226840
Train loss on 1450 batch: 0.271556
Train loss on 1500 batch: 0.250254
Train loss on 1550 batch: 0.262643
Train loss on 1600 batch: 0.289112
Train loss on 1650 batch: 0.249830
Train loss on 1700 batch: 0.251566
Train loss on 1750 batch: 0.313619
Train loss on 1800 batch: 0.241652
Train loss on 1850 batch: 0.266219
Train loss on 1900 batch: 0.255718
: Epoch: 44 | Training Loss: 0.256972 | Val. Loss: 0.351491 | Val. Kappa Score: 0.6811 | LR: 0.000031 | Estimated time: 253.15
Train loss on 50 batch: 0.295430
Train loss on 100 batch: 0.244284
Train loss on 150 batch: 0.249022
Train loss on 200 batch: 0.228111
Train loss on 250 batch: 0.266566
Train loss on 300 batch: 0.280529
Train loss on 350 batch: 0.271962
Train loss on 400 batch: 0.237439
Train loss on 450 batch: 0.265043
Train loss on 500 batch: 0.265196
Train loss on 550 batch: 0.279674
Train loss on 600 batch: 0.226875
Train loss on 650 batch: 0.268129
Train loss on 700 batch: 0.231338
Train loss on 750 batch: 0.248197
Train loss on 800 batch: 0.261101
Train loss on 850 batch: 0.245069
Train loss on 900 batch: 0.272436
Train loss on 950 batch: 0.223232
Train loss on 1000 batch: 0.247133
Train loss on 1050 batch: 0.249086
Train loss on 1100 batch: 0.227054
Train loss on 1150 batch: 0.238616
Train loss on 1200 batch: 0.298382
Train loss on 1250 batch: 0.293280
Train loss on 1300 batch: 0.248622
Train loss on 1350 batch: 0.266301
Train loss on 1400 batch: 0.277393
Train loss on 1450 batch: 0.246742
Train loss on 1500 batch: 0.255653
Train loss on 1550 batch: 0.221602
Train loss on 1600 batch: 0.200658
Train loss on 1650 batch: 0.281413
Train loss on 1700 batch: 0.240078
Train loss on 1750 batch: 0.252754
Train loss on 1800 batch: 0.281957
Train loss on 1850 batch: 0.268964
Train loss on 1900 batch: 0.209296
: Epoch: 45 | Training Loss: 0.254484 | Val. Loss: 0.354484 | Val. Kappa Score: 0.6821 | LR: 0.000016 | Estimated time: 254.03
Train loss on 50 batch: 0.258487
Train loss on 100 batch: 0.278498
Train loss on 150 batch: 0.291445
Train loss on 200 batch: 0.286901
Train loss on 250 batch: 0.273064
Train loss on 300 batch: 0.248656
Train loss on 350 batch: 0.273734
Train loss on 400 batch: 0.240700
Train loss on 450 batch: 0.256152
Train loss on 500 batch: 0.260167
Train loss on 550 batch: 0.237836
Train loss on 600 batch: 0.258857
Train loss on 650 batch: 0.249976
Train loss on 700 batch: 0.237406
Train loss on 750 batch: 0.229965
Train loss on 800 batch: 0.275433
Train loss on 850 batch: 0.275326
Train loss on 900 batch: 0.291530
Train loss on 950 batch: 0.280124
Train loss on 1000 batch: 0.201966
Train loss on 1050 batch: 0.256966
Train loss on 1100 batch: 0.255456
Train loss on 1150 batch: 0.214276
Train loss on 1200 batch: 0.249339
Train loss on 1250 batch: 0.226823
Train loss on 1300 batch: 0.249862
Train loss on 1350 batch: 0.266262
Train loss on 1400 batch: 0.236027
Train loss on 1450 batch: 0.219212
Train loss on 1500 batch: 0.279720
Train loss on 1550 batch: 0.257216
Train loss on 1600 batch: 0.275768
Train loss on 1650 batch: 0.227419
Train loss on 1700 batch: 0.269350
Train loss on 1750 batch: 0.247068
Train loss on 1800 batch: 0.280649
Train loss on 1850 batch: 0.287877
Train loss on 1900 batch: 0.247532
: Epoch: 46 | Training Loss: 0.257001 | Val. Loss: 0.350746 | Val. Kappa Score: 0.6832 | LR: 0.000016 | Estimated time: 253.93
Train loss on 50 batch: 0.229877
Train loss on 100 batch: 0.246015
Train loss on 150 batch: 0.227482
Train loss on 200 batch: 0.264577
Train loss on 250 batch: 0.277731
Train loss on 300 batch: 0.281155
Train loss on 350 batch: 0.250921
Train loss on 400 batch: 0.259538
Train loss on 450 batch: 0.279401
Train loss on 500 batch: 0.236677
Train loss on 550 batch: 0.259803
Train loss on 600 batch: 0.233064
Train loss on 650 batch: 0.260029
Train loss on 700 batch: 0.273039
Train loss on 750 batch: 0.247599
Train loss on 800 batch: 0.278119
Train loss on 850 batch: 0.258148
Train loss on 900 batch: 0.245064
Train loss on 950 batch: 0.235836
Train loss on 1000 batch: 0.291887
Train loss on 1050 batch: 0.245715
Train loss on 1100 batch: 0.312959
Train loss on 1150 batch: 0.228682
Train loss on 1200 batch: 0.223879
Train loss on 1250 batch: 0.240481
Train loss on 1300 batch: 0.263804
Train loss on 1350 batch: 0.272319
Train loss on 1400 batch: 0.251955
Train loss on 1450 batch: 0.278332
Train loss on 1500 batch: 0.277075
Train loss on 1550 batch: 0.220337
Train loss on 1600 batch: 0.222676
Train loss on 1650 batch: 0.228664
Train loss on 1700 batch: 0.235721
Train loss on 1750 batch: 0.227470
Train loss on 1800 batch: 0.262997
Train loss on 1850 batch: 0.220681
Train loss on 1900 batch: 0.280372
: Epoch: 47 | Training Loss: 0.253339 | Val. Loss: 0.349921 | Val. Kappa Score: 0.6843 | LR: 0.000016 | Estimated time: 252.63
Train loss on 50 batch: 0.240699
Train loss on 100 batch: 0.243263
Train loss on 150 batch: 0.268172
Train loss on 200 batch: 0.244930
Train loss on 250 batch: 0.271507
Train loss on 300 batch: 0.260698
Train loss on 350 batch: 0.219858
Train loss on 400 batch: 0.274985
Train loss on 450 batch: 0.293142
Train loss on 500 batch: 0.274880
Train loss on 550 batch: 0.271612
Train loss on 600 batch: 0.270073
Train loss on 650 batch: 0.223932
Train loss on 700 batch: 0.256765
Train loss on 750 batch: 0.209520
Train loss on 800 batch: 0.258026
Train loss on 850 batch: 0.226624
Train loss on 900 batch: 0.272348
Train loss on 950 batch: 0.221315
Train loss on 1000 batch: 0.294622
Train loss on 1050 batch: 0.237298
Train loss on 1100 batch: 0.228121
Train loss on 1150 batch: 0.248657
Train loss on 1200 batch: 0.253897
Train loss on 1250 batch: 0.242319
Train loss on 1300 batch: 0.265792
Train loss on 1350 batch: 0.269348
Train loss on 1400 batch: 0.296461
Train loss on 1450 batch: 0.259981
Train loss on 1500 batch: 0.279817
Train loss on 1550 batch: 0.247716
Train loss on 1600 batch: 0.251648
Train loss on 1650 batch: 0.253336
Train loss on 1700 batch: 0.211894
Train loss on 1750 batch: 0.256559
Train loss on 1800 batch: 0.232777
Train loss on 1850 batch: 0.230442
Train loss on 1900 batch: 0.268652
: Epoch: 48 | Training Loss: 0.253219 | Val. Loss: 0.350890 | Val. Kappa Score: 0.6850 | LR: 0.000008 | Estimated time: 254.52
Train loss on 50 batch: 0.249513
Train loss on 100 batch: 0.234416
Train loss on 150 batch: 0.238776
Train loss on 200 batch: 0.289228
Train loss on 250 batch: 0.233497
Train loss on 300 batch: 0.241388
Train loss on 350 batch: 0.249553
Train loss on 400 batch: 0.243067
Train loss on 450 batch: 0.258142
Train loss on 500 batch: 0.276135
Train loss on 550 batch: 0.277906
Train loss on 600 batch: 0.223437
Train loss on 650 batch: 0.307767
Train loss on 700 batch: 0.242357
Train loss on 750 batch: 0.249797
Train loss on 800 batch: 0.214676
Train loss on 850 batch: 0.261532
Train loss on 900 batch: 0.274881
Train loss on 950 batch: 0.272714
Train loss on 1000 batch: 0.247769
Train loss on 1050 batch: 0.219277
Train loss on 1100 batch: 0.209201
Train loss on 1150 batch: 0.235689
Train loss on 1200 batch: 0.254586
Train loss on 1250 batch: 0.219241
Train loss on 1300 batch: 0.232801
Train loss on 1350 batch: 0.278144
Train loss on 1400 batch: 0.225545
Train loss on 1450 batch: 0.246695
Train loss on 1500 batch: 0.268480
Train loss on 1550 batch: 0.249423
Train loss on 1600 batch: 0.230839
Train loss on 1650 batch: 0.267441
Train loss on 1700 batch: 0.243587
Train loss on 1750 batch: 0.198186
Train loss on 1800 batch: 0.262237
Train loss on 1850 batch: 0.276694
Train loss on 1900 batch: 0.242918
: Epoch: 49 | Training Loss: 0.248285 | Val. Loss: 0.352065 | Val. Kappa Score: 0.6859 | LR: 0.000008 | Estimated time: 253.76
time_estimated: 12469.77
n-epochs: 49
time_estimated: 12469.81
----------------------------------------

Experiment N: 128: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.08.23 09:29:07
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6a0>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.996745
Train loss on 100 batch: 0.847929
Train loss on 150 batch: 0.830248
Train loss on 200 batch: 0.726776
Train loss on 250 batch: 0.726261
Train loss on 300 batch: 0.700504
Train loss on 350 batch: 0.748179
Train loss on 400 batch: 0.818570
Train loss on 450 batch: 0.766360
Train loss on 500 batch: 0.660593
Train loss on 550 batch: 0.606299
Train loss on 600 batch: 0.622333
Train loss on 650 batch: 0.725790
Train loss on 700 batch: 0.705745
Train loss on 750 batch: 0.623161
Train loss on 800 batch: 0.662908
Train loss on 850 batch: 0.684854
Train loss on 900 batch: 0.601927
Train loss on 950 batch: 0.553498
Train loss on 1000 batch: 0.599315
Train loss on 1050 batch: 0.600247
Train loss on 1100 batch: 0.606368
Train loss on 1150 batch: 0.615541
Train loss on 1200 batch: 0.650948
Train loss on 1250 batch: 0.577532
Train loss on 1300 batch: 0.597036
Train loss on 1350 batch: 0.581471
Train loss on 1400 batch: 0.603187
Train loss on 1450 batch: 0.705363
Train loss on 1500 batch: 0.621546
Train loss on 1550 batch: 0.602192
Train loss on 1600 batch: 0.643336
Train loss on 1650 batch: 0.634026
Train loss on 1700 batch: 0.605537
Train loss on 1750 batch: 0.612656
Train loss on 1800 batch: 0.554748
Train loss on 1850 batch: 0.636951
Train loss on 1900 batch: 0.630674
best-train-loss: 0.663922
best-valid-loss: 0.557730
best-kappa: 0.5480
: Epoch: 1 | Training Loss: 0.663922 | Val. Loss: 0.557730 | Val. Kappa Score: 0.5480 | LR: 0.001000 | Estimated time: 377.48
Train loss on 50 batch: 0.519566
Train loss on 100 batch: 0.633101
Train loss on 150 batch: 0.584331
Train loss on 200 batch: 0.600017
Train loss on 250 batch: 0.545400
Train loss on 300 batch: 0.555368
Train loss on 350 batch: 0.638486
Train loss on 400 batch: 0.585221
Train loss on 450 batch: 0.522109
Train loss on 500 batch: 0.580798
Train loss on 550 batch: 0.555207
Train loss on 600 batch: 0.531325
Train loss on 650 batch: 0.516827
Train loss on 700 batch: 0.593868
Train loss on 750 batch: 0.603476
Train loss on 800 batch: 0.556276
Train loss on 850 batch: 0.545296
Train loss on 900 batch: 0.676194
Train loss on 950 batch: 0.606147
Train loss on 1000 batch: 0.546406
Train loss on 1050 batch: 0.520149
Train loss on 1100 batch: 0.580941
Train loss on 1150 batch: 0.455115
Train loss on 1200 batch: 0.555877
Train loss on 1250 batch: 0.597121
Train loss on 1300 batch: 0.584932
Train loss on 1350 batch: 0.585805
Train loss on 1400 batch: 0.510974
Train loss on 1450 batch: 0.577283
Train loss on 1500 batch: 0.565086
Train loss on 1550 batch: 0.553386
Train loss on 1600 batch: 0.466102
Train loss on 1650 batch: 0.558330
Train loss on 1700 batch: 0.618707
Train loss on 1750 batch: 0.513602
Train loss on 1800 batch: 0.527873
Train loss on 1850 batch: 0.502903
Train loss on 1900 batch: 0.435772
: Epoch: 2 | Training Loss: 0.556994 | Val. Loss: 0.559274 | Val. Kappa Score: 0.5483 | LR: 0.001000 | Estimated time: 402.14
Train loss on 50 batch: 0.586998
Train loss on 100 batch: 0.562904
Train loss on 150 batch: 0.502752
Train loss on 200 batch: 0.561405
Train loss on 250 batch: 0.480324
Train loss on 300 batch: 0.507341
Train loss on 350 batch: 0.514031
Train loss on 400 batch: 0.480524
Train loss on 450 batch: 0.468450
Train loss on 500 batch: 0.527148
Train loss on 550 batch: 0.487575
Train loss on 600 batch: 0.531150
Train loss on 650 batch: 0.577897
Train loss on 700 batch: 0.564825
Train loss on 750 batch: 0.511051
Train loss on 800 batch: 0.539946
Train loss on 850 batch: 0.550984
Train loss on 900 batch: 0.517363
Train loss on 950 batch: 0.482791
Train loss on 1000 batch: 0.472774
Train loss on 1050 batch: 0.467452
Train loss on 1100 batch: 0.522172
Train loss on 1150 batch: 0.504823
Train loss on 1200 batch: 0.537270
Train loss on 1250 batch: 0.500695
Train loss on 1300 batch: 0.460510
Train loss on 1350 batch: 0.547511
Train loss on 1400 batch: 0.471244
Train loss on 1450 batch: 0.519740
Train loss on 1500 batch: 0.508102
Train loss on 1550 batch: 0.460442
Train loss on 1600 batch: 0.483103
Train loss on 1650 batch: 0.440942
Train loss on 1700 batch: 0.442076
Train loss on 1750 batch: 0.435573
Train loss on 1800 batch: 0.526570
Train loss on 1850 batch: 0.486125
Train loss on 1900 batch: 0.476262
best-train-loss: 0.506543
best-valid-loss: 0.467036
best-kappa: 0.5895
: Epoch: 3 | Training Loss: 0.506543 | Val. Loss: 0.467036 | Val. Kappa Score: 0.5895 | LR: 0.001000 | Estimated time: 371.77
Train loss on 50 batch: 0.571463
Train loss on 100 batch: 0.448222
Train loss on 150 batch: 0.539916
Train loss on 200 batch: 0.507906
Train loss on 250 batch: 0.462599
Train loss on 300 batch: 0.436271
Train loss on 350 batch: 0.594017
Train loss on 400 batch: 0.485683
Train loss on 450 batch: 0.453979
Train loss on 500 batch: 0.558106
Train loss on 550 batch: 0.531185
Train loss on 600 batch: 0.441854
Train loss on 650 batch: 0.465403
Train loss on 700 batch: 0.544782
Train loss on 750 batch: 0.453945
Train loss on 800 batch: 0.535572
Train loss on 850 batch: 0.500886
Train loss on 900 batch: 0.531351
Train loss on 950 batch: 0.475420
Train loss on 1000 batch: 0.434229
Train loss on 1050 batch: 0.508317
Train loss on 1100 batch: 0.509215
Train loss on 1150 batch: 0.501778
Train loss on 1200 batch: 0.437639
Train loss on 1250 batch: 0.483212
Train loss on 1300 batch: 0.473809
Train loss on 1350 batch: 0.423719
Train loss on 1400 batch: 0.471619
Train loss on 1450 batch: 0.473217
Train loss on 1500 batch: 0.459228
Train loss on 1550 batch: 0.480990
Train loss on 1600 batch: 0.561540
Train loss on 1650 batch: 0.503203
Train loss on 1700 batch: 0.551917
Train loss on 1750 batch: 0.484650
Train loss on 1800 batch: 0.458942
Train loss on 1850 batch: 0.438348
Train loss on 1900 batch: 0.517855
best-train-loss: 0.492152
best-valid-loss: 0.454184
best-kappa: 0.6084
: Epoch: 4 | Training Loss: 0.492152 | Val. Loss: 0.454184 | Val. Kappa Score: 0.6084 | LR: 0.001000 | Estimated time: 371.82
Train loss on 50 batch: 0.456301
Train loss on 100 batch: 0.516283
Train loss on 150 batch: 0.463276
Train loss on 200 batch: 0.507122
Train loss on 250 batch: 0.515728
Train loss on 300 batch: 0.456401
Train loss on 350 batch: 0.516349
Train loss on 400 batch: 0.496814
Train loss on 450 batch: 0.500508
Train loss on 500 batch: 0.515786
Train loss on 550 batch: 0.504975
Train loss on 600 batch: 0.457537
Train loss on 650 batch: 0.420337
Train loss on 700 batch: 0.531658
Train loss on 750 batch: 0.472728
Train loss on 800 batch: 0.511278
Train loss on 850 batch: 0.530923
Train loss on 900 batch: 0.461959
Train loss on 950 batch: 0.475873
Train loss on 1000 batch: 0.438220
Train loss on 1050 batch: 0.498716
Train loss on 1100 batch: 0.453271
Train loss on 1150 batch: 0.525984
Train loss on 1200 batch: 0.476326
Train loss on 1250 batch: 0.471899
Train loss on 1300 batch: 0.497999
Train loss on 1350 batch: 0.461474
Train loss on 1400 batch: 0.466438
Train loss on 1450 batch: 0.394552
Train loss on 1500 batch: 0.459361
Train loss on 1550 batch: 0.428713
Train loss on 1600 batch: 0.404194
Train loss on 1650 batch: 0.431605
Train loss on 1700 batch: 0.481842
Train loss on 1750 batch: 0.491800
Train loss on 1800 batch: 0.468654
Train loss on 1850 batch: 0.452211
Train loss on 1900 batch: 0.413629
: Epoch: 5 | Training Loss: 0.474035 | Val. Loss: 0.492307 | Val. Kappa Score: 0.6228 | LR: 0.001000 | Estimated time: 371.83
Train loss on 50 batch: 0.505608
Train loss on 100 batch: 0.440450
Train loss on 150 batch: 0.423743
Train loss on 200 batch: 0.468081
Train loss on 250 batch: 0.426353
Train loss on 300 batch: 0.484280
Train loss on 350 batch: 0.447083
Train loss on 400 batch: 0.488014
Train loss on 450 batch: 0.472110
Train loss on 500 batch: 0.443624
Train loss on 550 batch: 0.448504
Train loss on 600 batch: 0.503779
Train loss on 650 batch: 0.489027
Train loss on 700 batch: 0.443269
Train loss on 750 batch: 0.434680
Train loss on 800 batch: 0.481668
Train loss on 850 batch: 0.411126
Train loss on 900 batch: 0.510848
Train loss on 950 batch: 0.537712
Train loss on 1000 batch: 0.423414
Train loss on 1050 batch: 0.485124
Train loss on 1100 batch: 0.440021
Train loss on 1150 batch: 0.438760
Train loss on 1200 batch: 0.421598
Train loss on 1250 batch: 0.490581
Train loss on 1300 batch: 0.451256
Train loss on 1350 batch: 0.409973
Train loss on 1400 batch: 0.438798
Train loss on 1450 batch: 0.472401
Train loss on 1500 batch: 0.472912
Train loss on 1550 batch: 0.502268
Train loss on 1600 batch: 0.479765
Train loss on 1650 batch: 0.454589
Train loss on 1700 batch: 0.359287
Train loss on 1750 batch: 0.487360
Train loss on 1800 batch: 0.387721
Train loss on 1850 batch: 0.431010
Train loss on 1900 batch: 0.470496
best-train-loss: 0.456641
best-valid-loss: 0.444479
best-kappa: 0.6291
: Epoch: 6 | Training Loss: 0.456641 | Val. Loss: 0.444479 | Val. Kappa Score: 0.6291 | LR: 0.001000 | Estimated time: 371.25
Train loss on 50 batch: 0.468456
Train loss on 100 batch: 0.463009
Train loss on 150 batch: 0.510311
Train loss on 200 batch: 0.439040
Train loss on 250 batch: 0.476591
Train loss on 300 batch: 0.519670
Train loss on 350 batch: 0.427244
Train loss on 400 batch: 0.491539
Train loss on 450 batch: 0.387296
Train loss on 500 batch: 0.375729
Train loss on 550 batch: 0.434823
Train loss on 600 batch: 0.495935
Train loss on 650 batch: 0.419881
Train loss on 700 batch: 0.456288
Train loss on 750 batch: 0.360270
Train loss on 800 batch: 0.405717
Train loss on 850 batch: 0.412005
Train loss on 900 batch: 0.449717
Train loss on 950 batch: 0.419135
Train loss on 1000 batch: 0.414945
Train loss on 1050 batch: 0.450057
Train loss on 1100 batch: 0.430185
Train loss on 1150 batch: 0.427681
Train loss on 1200 batch: 0.459723
Train loss on 1250 batch: 0.461546
Train loss on 1300 batch: 0.395446
Train loss on 1350 batch: 0.455577
Train loss on 1400 batch: 0.430761
Train loss on 1450 batch: 0.433669
Train loss on 1500 batch: 0.401818
Train loss on 1550 batch: 0.491332
Train loss on 1600 batch: 0.410668
Train loss on 1650 batch: 0.455332
Train loss on 1700 batch: 0.468763
Train loss on 1750 batch: 0.434035
Train loss on 1800 batch: 0.452078
Train loss on 1850 batch: 0.553743
Train loss on 1900 batch: 0.452090
best-train-loss: 0.442952
best-valid-loss: 0.414821
best-kappa: 0.6368
: Epoch: 7 | Training Loss: 0.442952 | Val. Loss: 0.414821 | Val. Kappa Score: 0.6368 | LR: 0.001000 | Estimated time: 373.27
Train loss on 50 batch: 0.375362
Train loss on 100 batch: 0.357917
Train loss on 150 batch: 0.517349
Train loss on 200 batch: 0.524640
Train loss on 250 batch: 0.392895
Train loss on 300 batch: 0.445040
Train loss on 350 batch: 0.410943
Train loss on 400 batch: 0.480918
Train loss on 450 batch: 0.379451
Train loss on 500 batch: 0.504042
Train loss on 550 batch: 0.445214
Train loss on 600 batch: 0.408561
Train loss on 650 batch: 0.428378
Train loss on 700 batch: 0.443937
Train loss on 750 batch: 0.442686
Train loss on 800 batch: 0.462679
Train loss on 850 batch: 0.474818
Train loss on 900 batch: 0.456517
Train loss on 950 batch: 0.412633
Train loss on 1000 batch: 0.417192
Train loss on 1050 batch: 0.446315
Train loss on 1100 batch: 0.445412
Train loss on 1150 batch: 0.440600
Train loss on 1200 batch: 0.492225
Train loss on 1250 batch: 0.414063
Train loss on 1300 batch: 0.463287
Train loss on 1350 batch: 0.470990
Train loss on 1400 batch: 0.402231
Train loss on 1450 batch: 0.400872
Train loss on 1500 batch: 0.429953
Train loss on 1550 batch: 0.426722
Train loss on 1600 batch: 0.471686
Train loss on 1650 batch: 0.493170
Train loss on 1700 batch: 0.406817
Train loss on 1750 batch: 0.443507
Train loss on 1800 batch: 0.418050
Train loss on 1850 batch: 0.457992
Train loss on 1900 batch: 0.351580
: Epoch: 8 | Training Loss: 0.439752 | Val. Loss: 0.603835 | Val. Kappa Score: 0.6324 | LR: 0.001000 | Estimated time: 372.19
Train loss on 50 batch: 0.460937
Train loss on 100 batch: 0.389748
Train loss on 150 batch: 0.414320
Train loss on 200 batch: 0.441388
Train loss on 250 batch: 0.394228
Train loss on 300 batch: 0.425399
Train loss on 350 batch: 0.395719
Train loss on 400 batch: 0.474010
Train loss on 450 batch: 0.395237
Train loss on 500 batch: 0.394069
Train loss on 550 batch: 0.469942
Train loss on 600 batch: 0.456142
Train loss on 650 batch: 0.434433
Train loss on 700 batch: 0.445922
Train loss on 750 batch: 0.342281
Train loss on 800 batch: 0.435374
Train loss on 850 batch: 0.468405
Train loss on 900 batch: 0.442892
Train loss on 950 batch: 0.390510
Train loss on 1000 batch: 0.398457
Train loss on 1050 batch: 0.461083
Train loss on 1100 batch: 0.487615
Train loss on 1150 batch: 0.440078
Train loss on 1200 batch: 0.482813
Train loss on 1250 batch: 0.348436
Train loss on 1300 batch: 0.383894
Train loss on 1350 batch: 0.440296
Train loss on 1400 batch: 0.413962
Train loss on 1450 batch: 0.464197
Train loss on 1500 batch: 0.404462
Train loss on 1550 batch: 0.461324
Train loss on 1600 batch: 0.455899
Train loss on 1650 batch: 0.490435
Train loss on 1700 batch: 0.496790
Train loss on 1750 batch: 0.440946
Train loss on 1800 batch: 0.399395
Train loss on 1850 batch: 0.393652
Train loss on 1900 batch: 0.400610
: Epoch: 9 | Training Loss: 0.430051 | Val. Loss: 0.443617 | Val. Kappa Score: 0.6367 | LR: 0.001000 | Estimated time: 371.90
Train loss on 50 batch: 0.440964
Train loss on 100 batch: 0.416144
Train loss on 150 batch: 0.391401
Train loss on 200 batch: 0.377268
Train loss on 250 batch: 0.403082
Train loss on 300 batch: 0.430383
Train loss on 350 batch: 0.423852
Train loss on 400 batch: 0.443863
Train loss on 450 batch: 0.404422
Train loss on 500 batch: 0.399675
Train loss on 550 batch: 0.404714
Train loss on 600 batch: 0.409205
Train loss on 650 batch: 0.383966
Train loss on 700 batch: 0.471684
Train loss on 750 batch: 0.446515
Train loss on 800 batch: 0.401698
Train loss on 850 batch: 0.346296
Train loss on 900 batch: 0.438036
Train loss on 950 batch: 0.357411
Train loss on 1000 batch: 0.380550
Train loss on 1050 batch: 0.456910
Train loss on 1100 batch: 0.383835
Train loss on 1150 batch: 0.446924
Train loss on 1200 batch: 0.481961
Train loss on 1250 batch: 0.419251
Train loss on 1300 batch: 0.480713
Train loss on 1350 batch: 0.425114
Train loss on 1400 batch: 0.492624
Train loss on 1450 batch: 0.430838
Train loss on 1500 batch: 0.446366
Train loss on 1550 batch: 0.465418
Train loss on 1600 batch: 0.409456
Train loss on 1650 batch: 0.454468
Train loss on 1700 batch: 0.360652
Train loss on 1750 batch: 0.438808
Train loss on 1800 batch: 0.428073
Train loss on 1850 batch: 0.354514
Train loss on 1900 batch: 0.455196
: Epoch: 10 | Training Loss: 0.420442 | Val. Loss: 0.514610 | Val. Kappa Score: 0.6351 | LR: 0.000500 | Estimated time: 371.71
Train loss on 50 batch: 0.411375
Train loss on 100 batch: 0.364070
Train loss on 150 batch: 0.340597
Train loss on 200 batch: 0.425945
Train loss on 250 batch: 0.363195
Train loss on 300 batch: 0.296321
Train loss on 350 batch: 0.452687
Train loss on 400 batch: 0.354125
Train loss on 450 batch: 0.425177
Train loss on 500 batch: 0.440305
Train loss on 550 batch: 0.334699
Train loss on 600 batch: 0.422320
Train loss on 650 batch: 0.328744
Train loss on 700 batch: 0.440392
Train loss on 750 batch: 0.437548
Train loss on 800 batch: 0.421537
Train loss on 850 batch: 0.449332
Train loss on 900 batch: 0.442478
Train loss on 950 batch: 0.359507
Train loss on 1000 batch: 0.322766
Train loss on 1050 batch: 0.437679
Train loss on 1100 batch: 0.367534
Train loss on 1150 batch: 0.384065
Train loss on 1200 batch: 0.364497
Train loss on 1250 batch: 0.405972
Train loss on 1300 batch: 0.343617
Train loss on 1350 batch: 0.347502
Train loss on 1400 batch: 0.364176
Train loss on 1450 batch: 0.367739
Train loss on 1500 batch: 0.355833
Train loss on 1550 batch: 0.342402
Train loss on 1600 batch: 0.351183
Train loss on 1650 batch: 0.340655
Train loss on 1700 batch: 0.383679
Train loss on 1750 batch: 0.380740
Train loss on 1800 batch: 0.401522
Train loss on 1850 batch: 0.337791
Train loss on 1900 batch: 0.401994
best-train-loss: 0.381513
best-valid-loss: 0.411737
best-kappa: 0.6430
: Epoch: 11 | Training Loss: 0.381513 | Val. Loss: 0.411737 | Val. Kappa Score: 0.6430 | LR: 0.000500 | Estimated time: 372.29
Train loss on 50 batch: 0.407447
Train loss on 100 batch: 0.455242
Train loss on 150 batch: 0.421176
Train loss on 200 batch: 0.362420
Train loss on 250 batch: 0.369872
Train loss on 300 batch: 0.353416
Train loss on 350 batch: 0.303544
Train loss on 400 batch: 0.330359
Train loss on 450 batch: 0.327256
Train loss on 500 batch: 0.350464
Train loss on 550 batch: 0.413526
Train loss on 600 batch: 0.420095
Train loss on 650 batch: 0.354653
Train loss on 700 batch: 0.412939
Train loss on 750 batch: 0.370031
Train loss on 800 batch: 0.318157
Train loss on 850 batch: 0.333040
Train loss on 900 batch: 0.388289
Train loss on 950 batch: 0.339483
Train loss on 1000 batch: 0.370502
Train loss on 1050 batch: 0.375657
Train loss on 1100 batch: 0.353976
Train loss on 1150 batch: 0.383174
Train loss on 1200 batch: 0.377906
Train loss on 1250 batch: 0.365022
Train loss on 1300 batch: 0.383339
Train loss on 1350 batch: 0.379480
Train loss on 1400 batch: 0.374955
Train loss on 1450 batch: 0.373715
Train loss on 1500 batch: 0.359214
Train loss on 1550 batch: 0.365430
Train loss on 1600 batch: 0.408255
Train loss on 1650 batch: 0.365220
Train loss on 1700 batch: 0.356857
Train loss on 1750 batch: 0.335363
Train loss on 1800 batch: 0.351400
Train loss on 1850 batch: 0.354380
Train loss on 1900 batch: 0.385842
best-train-loss: 0.370670
best-valid-loss: 0.359729
best-kappa: 0.6497
: Epoch: 12 | Training Loss: 0.370670 | Val. Loss: 0.359729 | Val. Kappa Score: 0.6497 | LR: 0.000500 | Estimated time: 371.14
Train loss on 50 batch: 0.379716
Train loss on 100 batch: 0.377054
Train loss on 150 batch: 0.340645
Train loss on 200 batch: 0.365313
Train loss on 250 batch: 0.345977
Train loss on 300 batch: 0.402130
Train loss on 350 batch: 0.358023
Train loss on 400 batch: 0.409369
Train loss on 450 batch: 0.319624
Train loss on 500 batch: 0.386119
Train loss on 550 batch: 0.338496
Train loss on 600 batch: 0.350851
Train loss on 650 batch: 0.347365
Train loss on 700 batch: 0.391431
Train loss on 750 batch: 0.385308
Train loss on 800 batch: 0.391646
Train loss on 850 batch: 0.316021
Train loss on 900 batch: 0.426766
Train loss on 950 batch: 0.365798
Train loss on 1000 batch: 0.368452
Train loss on 1050 batch: 0.407281
Train loss on 1100 batch: 0.376025
Train loss on 1150 batch: 0.331861
Train loss on 1200 batch: 0.356632
Train loss on 1250 batch: 0.381680
Train loss on 1300 batch: 0.372281
Train loss on 1350 batch: 0.342501
Train loss on 1400 batch: 0.408919
Train loss on 1450 batch: 0.395640
Train loss on 1500 batch: 0.355969
Train loss on 1550 batch: 0.341436
Train loss on 1600 batch: 0.349869
Train loss on 1650 batch: 0.397633
Train loss on 1700 batch: 0.343052
Train loss on 1750 batch: 0.366810
Train loss on 1800 batch: 0.401729
Train loss on 1850 batch: 0.340596
Train loss on 1900 batch: 0.322361
: Epoch: 13 | Training Loss: 0.368643 | Val. Loss: 0.399761 | Val. Kappa Score: 0.6557 | LR: 0.000500 | Estimated time: 371.65
Train loss on 50 batch: 0.363640
Train loss on 100 batch: 0.380223
Train loss on 150 batch: 0.353136
Train loss on 200 batch: 0.359167
Train loss on 250 batch: 0.384584
Train loss on 300 batch: 0.397135
Train loss on 350 batch: 0.339926
Train loss on 400 batch: 0.395287
Train loss on 450 batch: 0.368597
Train loss on 500 batch: 0.332174
Train loss on 550 batch: 0.358045
Train loss on 600 batch: 0.341301
Train loss on 650 batch: 0.389323
Train loss on 700 batch: 0.351243
Train loss on 750 batch: 0.328124
Train loss on 800 batch: 0.362094
Train loss on 850 batch: 0.381235
Train loss on 900 batch: 0.388515
Train loss on 950 batch: 0.371799
Train loss on 1000 batch: 0.329331
Train loss on 1050 batch: 0.389367
Train loss on 1100 batch: 0.333476
Train loss on 1150 batch: 0.246234
Train loss on 1200 batch: 0.330907
Train loss on 1250 batch: 0.407302
Train loss on 1300 batch: 0.381030
Train loss on 1350 batch: 0.347169
Train loss on 1400 batch: 0.412477
Train loss on 1450 batch: 0.389855
Train loss on 1500 batch: 0.344350
Train loss on 1550 batch: 0.312957
Train loss on 1600 batch: 0.312022
Train loss on 1650 batch: 0.412972
Train loss on 1700 batch: 0.348674
Train loss on 1750 batch: 0.291581
Train loss on 1800 batch: 0.405581
Train loss on 1850 batch: 0.318726
Train loss on 1900 batch: 0.428350
: Epoch: 14 | Training Loss: 0.358511 | Val. Loss: 0.412414 | Val. Kappa Score: 0.6601 | LR: 0.000500 | Estimated time: 372.46
Train loss on 50 batch: 0.302559
Train loss on 100 batch: 0.341837
Train loss on 150 batch: 0.315361
Train loss on 200 batch: 0.428563
Train loss on 250 batch: 0.359552
Train loss on 300 batch: 0.338028
Train loss on 350 batch: 0.413905
Train loss on 400 batch: 0.320832
Train loss on 450 batch: 0.351169
Train loss on 500 batch: 0.355320
Train loss on 550 batch: 0.399854
Train loss on 600 batch: 0.360792
Train loss on 650 batch: 0.372295
Train loss on 700 batch: 0.344235
Train loss on 750 batch: 0.341018
Train loss on 800 batch: 0.346338
Train loss on 850 batch: 0.435406
Train loss on 900 batch: 0.399851
Train loss on 950 batch: 0.416500
Train loss on 1000 batch: 0.348212
Train loss on 1050 batch: 0.351791
Train loss on 1100 batch: 0.367232
Train loss on 1150 batch: 0.362122
Train loss on 1200 batch: 0.336598
Train loss on 1250 batch: 0.312991
Train loss on 1300 batch: 0.415163
Train loss on 1350 batch: 0.346106
Train loss on 1400 batch: 0.365218
Train loss on 1450 batch: 0.335135
Train loss on 1500 batch: 0.312659
Train loss on 1550 batch: 0.291998
Train loss on 1600 batch: 0.376602
Train loss on 1650 batch: 0.348394
Train loss on 1700 batch: 0.280177
Train loss on 1750 batch: 0.294416
Train loss on 1800 batch: 0.372995
Train loss on 1850 batch: 0.374065
Train loss on 1900 batch: 0.414763
: Epoch: 15 | Training Loss: 0.355432 | Val. Loss: 0.395061 | Val. Kappa Score: 0.6637 | LR: 0.000250 | Estimated time: 371.13
Train loss on 50 batch: 0.294349
Train loss on 100 batch: 0.320074
Train loss on 150 batch: 0.392007
Train loss on 200 batch: 0.293489
Train loss on 250 batch: 0.346281
Train loss on 300 batch: 0.329714
Train loss on 350 batch: 0.310511
Train loss on 400 batch: 0.297798
Train loss on 450 batch: 0.290209
Train loss on 500 batch: 0.362214
Train loss on 550 batch: 0.323966
Train loss on 600 batch: 0.354394
Train loss on 650 batch: 0.363346
Train loss on 700 batch: 0.260707
Train loss on 750 batch: 0.336496
Train loss on 800 batch: 0.364566
Train loss on 850 batch: 0.354771
Train loss on 900 batch: 0.349825
Train loss on 950 batch: 0.363310
Train loss on 1000 batch: 0.329832
Train loss on 1050 batch: 0.355850
Train loss on 1100 batch: 0.311521
Train loss on 1150 batch: 0.336571
Train loss on 1200 batch: 0.316526
Train loss on 1250 batch: 0.294557
Train loss on 1300 batch: 0.317114
Train loss on 1350 batch: 0.302230
Train loss on 1400 batch: 0.330208
Train loss on 1450 batch: 0.298087
Train loss on 1500 batch: 0.347903
Train loss on 1550 batch: 0.356805
Train loss on 1600 batch: 0.309259
Train loss on 1650 batch: 0.313924
Train loss on 1700 batch: 0.402362
Train loss on 1750 batch: 0.332038
Train loss on 1800 batch: 0.340144
Train loss on 1850 batch: 0.351341
Train loss on 1900 batch: 0.304059
best-train-loss: 0.331542
best-valid-loss: 0.347299
best-kappa: 0.6678
: Epoch: 16 | Training Loss: 0.331542 | Val. Loss: 0.347299 | Val. Kappa Score: 0.6678 | LR: 0.000250 | Estimated time: 370.66
Train loss on 50 batch: 0.289371
Train loss on 100 batch: 0.309955
Train loss on 150 batch: 0.360943
Train loss on 200 batch: 0.332816
Train loss on 250 batch: 0.319227
Train loss on 300 batch: 0.344570
Train loss on 350 batch: 0.391932
Train loss on 400 batch: 0.346536
Train loss on 450 batch: 0.287784
Train loss on 500 batch: 0.284986
Train loss on 550 batch: 0.300273
Train loss on 600 batch: 0.318842
Train loss on 650 batch: 0.287700
Train loss on 700 batch: 0.327243
Train loss on 750 batch: 0.328686
Train loss on 800 batch: 0.307178
Train loss on 850 batch: 0.353903
Train loss on 900 batch: 0.354849
Train loss on 950 batch: 0.319096
Train loss on 1000 batch: 0.371479
Train loss on 1050 batch: 0.339382
Train loss on 1100 batch: 0.349821
Train loss on 1150 batch: 0.319730
Train loss on 1200 batch: 0.303556
Train loss on 1250 batch: 0.282169
Train loss on 1300 batch: 0.290307
Train loss on 1350 batch: 0.261052
Train loss on 1400 batch: 0.332588
Train loss on 1450 batch: 0.391575
Train loss on 1500 batch: 0.315267
Train loss on 1550 batch: 0.361452
Train loss on 1600 batch: 0.304555
Train loss on 1650 batch: 0.333256
Train loss on 1700 batch: 0.371718
Train loss on 1750 batch: 0.346222
Train loss on 1800 batch: 0.317078
Train loss on 1850 batch: 0.340835
Train loss on 1900 batch: 0.308500
: Epoch: 17 | Training Loss: 0.325195 | Val. Loss: 0.353034 | Val. Kappa Score: 0.6723 | LR: 0.000250 | Estimated time: 371.87
Train loss on 50 batch: 0.304423
Train loss on 100 batch: 0.290125
Train loss on 150 batch: 0.318110
Train loss on 200 batch: 0.344849
Train loss on 250 batch: 0.362333
Train loss on 300 batch: 0.321237
Train loss on 350 batch: 0.279706
Train loss on 400 batch: 0.292136
Train loss on 450 batch: 0.363340
Train loss on 500 batch: 0.305066
Train loss on 550 batch: 0.328373
Train loss on 600 batch: 0.328006
Train loss on 650 batch: 0.264045
Train loss on 700 batch: 0.287758
Train loss on 750 batch: 0.299533
Train loss on 800 batch: 0.324321
Train loss on 850 batch: 0.289518
Train loss on 900 batch: 0.334126
Train loss on 950 batch: 0.314082
Train loss on 1000 batch: 0.312985
Train loss on 1050 batch: 0.373849
Train loss on 1100 batch: 0.327883
Train loss on 1150 batch: 0.286708
Train loss on 1200 batch: 0.363219
Train loss on 1250 batch: 0.291541
Train loss on 1300 batch: 0.315939
Train loss on 1350 batch: 0.336333
Train loss on 1400 batch: 0.341516
Train loss on 1450 batch: 0.370125
Train loss on 1500 batch: 0.313898
Train loss on 1550 batch: 0.302229
Train loss on 1600 batch: 0.288847
Train loss on 1650 batch: 0.269211
Train loss on 1700 batch: 0.360437
Train loss on 1750 batch: 0.285596
Train loss on 1800 batch: 0.299231
Train loss on 1850 batch: 0.313865
Train loss on 1900 batch: 0.327815
: Epoch: 18 | Training Loss: 0.317338 | Val. Loss: 0.356279 | Val. Kappa Score: 0.6758 | LR: 0.000250 | Estimated time: 372.23
Train loss on 50 batch: 0.262174
Train loss on 100 batch: 0.312879
Train loss on 150 batch: 0.368108
Train loss on 200 batch: 0.333882
Train loss on 250 batch: 0.386902
Train loss on 300 batch: 0.343222
Train loss on 350 batch: 0.300258
Train loss on 400 batch: 0.307194
Train loss on 450 batch: 0.329868
Train loss on 500 batch: 0.320976
Train loss on 550 batch: 0.233269
Train loss on 600 batch: 0.328227
Train loss on 650 batch: 0.363800
Train loss on 700 batch: 0.289145
Train loss on 750 batch: 0.301256
Train loss on 800 batch: 0.298258
Train loss on 850 batch: 0.321926
Train loss on 900 batch: 0.329587
Train loss on 950 batch: 0.307451
Train loss on 1000 batch: 0.314536
Train loss on 1050 batch: 0.336369
Train loss on 1100 batch: 0.298068
Train loss on 1150 batch: 0.244143
Train loss on 1200 batch: 0.286739
Train loss on 1250 batch: 0.329746
Train loss on 1300 batch: 0.345040
Train loss on 1350 batch: 0.338284
Train loss on 1400 batch: 0.318969
Train loss on 1450 batch: 0.281257
Train loss on 1500 batch: 0.283389
Train loss on 1550 batch: 0.288991
Train loss on 1600 batch: 0.305772
Train loss on 1650 batch: 0.297637
Train loss on 1700 batch: 0.267821
Train loss on 1750 batch: 0.304879
Train loss on 1800 batch: 0.372502
Train loss on 1850 batch: 0.297959
Train loss on 1900 batch: 0.342165
: Epoch: 19 | Training Loss: 0.314426 | Val. Loss: 0.349414 | Val. Kappa Score: 0.6793 | LR: 0.000125 | Estimated time: 371.61
Train loss on 50 batch: 0.257457
Train loss on 100 batch: 0.369230
Train loss on 150 batch: 0.317150
Train loss on 200 batch: 0.301045
Train loss on 250 batch: 0.299347
Train loss on 300 batch: 0.285280
Train loss on 350 batch: 0.263155
Train loss on 400 batch: 0.319369
Train loss on 450 batch: 0.325274
Train loss on 500 batch: 0.310067
Train loss on 550 batch: 0.304674
Train loss on 600 batch: 0.275752
Train loss on 650 batch: 0.357123
Train loss on 700 batch: 0.321899
Train loss on 750 batch: 0.317701
Train loss on 800 batch: 0.297925
Train loss on 850 batch: 0.335766
Train loss on 900 batch: 0.269749
Train loss on 950 batch: 0.281779
Train loss on 1000 batch: 0.290840
Train loss on 1050 batch: 0.316829
Train loss on 1100 batch: 0.290990
Train loss on 1150 batch: 0.304736
Train loss on 1200 batch: 0.327941
Train loss on 1250 batch: 0.260601
Train loss on 1300 batch: 0.265580
Train loss on 1350 batch: 0.239794
Train loss on 1400 batch: 0.312032
Train loss on 1450 batch: 0.254650
Train loss on 1500 batch: 0.308402
Train loss on 1550 batch: 0.334481
Train loss on 1600 batch: 0.309800
Train loss on 1650 batch: 0.268572
Train loss on 1700 batch: 0.297335
Train loss on 1750 batch: 0.318076
Train loss on 1800 batch: 0.312031
Train loss on 1850 batch: 0.323756
Train loss on 1900 batch: 0.346154
best-train-loss: 0.301529
best-valid-loss: 0.346082
best-kappa: 0.6819
: Epoch: 20 | Training Loss: 0.301529 | Val. Loss: 0.346082 | Val. Kappa Score: 0.6819 | LR: 0.000125 | Estimated time: 371.74
Train loss on 50 batch: 0.279783
Train loss on 100 batch: 0.284671
Train loss on 150 batch: 0.298541
Train loss on 200 batch: 0.353621
Train loss on 250 batch: 0.264888
Train loss on 300 batch: 0.297376
Train loss on 350 batch: 0.304877
Train loss on 400 batch: 0.353028
Train loss on 450 batch: 0.297445
Train loss on 500 batch: 0.257517
Train loss on 550 batch: 0.293978
Train loss on 600 batch: 0.367292
Train loss on 650 batch: 0.276143
Train loss on 700 batch: 0.289821
Train loss on 750 batch: 0.282119
Train loss on 800 batch: 0.285678
Train loss on 850 batch: 0.281514
Train loss on 900 batch: 0.351807
Train loss on 950 batch: 0.267939
Train loss on 1000 batch: 0.287368
Train loss on 1050 batch: 0.259053
Train loss on 1100 batch: 0.315961
Train loss on 1150 batch: 0.296324
Train loss on 1200 batch: 0.309159
Train loss on 1250 batch: 0.302493
Train loss on 1300 batch: 0.259587
Train loss on 1350 batch: 0.317565
Train loss on 1400 batch: 0.281343
Train loss on 1450 batch: 0.310221
Train loss on 1500 batch: 0.290406
Train loss on 1550 batch: 0.274849
Train loss on 1600 batch: 0.335119
Train loss on 1650 batch: 0.282045
Train loss on 1700 batch: 0.380277
Train loss on 1750 batch: 0.319789
Train loss on 1800 batch: 0.255769
Train loss on 1850 batch: 0.277536
Train loss on 1900 batch: 0.328176
best-train-loss: 0.300803
best-valid-loss: 0.333775
best-kappa: 0.6850
: Epoch: 21 | Training Loss: 0.300803 | Val. Loss: 0.333775 | Val. Kappa Score: 0.6850 | LR: 0.000125 | Estimated time: 371.91
Train loss on 50 batch: 0.261445
Train loss on 100 batch: 0.311066
Train loss on 150 batch: 0.334488
Train loss on 200 batch: 0.271755
Train loss on 250 batch: 0.266232
Train loss on 300 batch: 0.276178
Train loss on 350 batch: 0.244412
Train loss on 400 batch: 0.328420
Train loss on 450 batch: 0.301386
Train loss on 500 batch: 0.282114
Train loss on 550 batch: 0.260172
Train loss on 600 batch: 0.288481
Train loss on 650 batch: 0.319463
Train loss on 700 batch: 0.340164
Train loss on 750 batch: 0.312253
Train loss on 800 batch: 0.275236
Train loss on 850 batch: 0.305299
Train loss on 900 batch: 0.294183
Train loss on 950 batch: 0.260555
Train loss on 1000 batch: 0.305068
Train loss on 1050 batch: 0.293850
Train loss on 1100 batch: 0.260478
Train loss on 1150 batch: 0.330236
Train loss on 1200 batch: 0.375321
Train loss on 1250 batch: 0.242028
Train loss on 1300 batch: 0.292480
Train loss on 1350 batch: 0.302650
Train loss on 1400 batch: 0.306024
Train loss on 1450 batch: 0.330540
Train loss on 1500 batch: 0.352993
Train loss on 1550 batch: 0.332932
Train loss on 1600 batch: 0.289034
Train loss on 1650 batch: 0.278686
Train loss on 1700 batch: 0.277485
Train loss on 1750 batch: 0.260756
Train loss on 1800 batch: 0.290705
Train loss on 1850 batch: 0.316416
Train loss on 1900 batch: 0.276022
best-train-loss: 0.295741
best-valid-loss: 0.332079
best-kappa: 0.6881
: Epoch: 22 | Training Loss: 0.295741 | Val. Loss: 0.332079 | Val. Kappa Score: 0.6881 | LR: 0.000125 | Estimated time: 371.53
Train loss on 50 batch: 0.235119
Train loss on 100 batch: 0.285539
Train loss on 150 batch: 0.275854
Train loss on 200 batch: 0.279560
Train loss on 250 batch: 0.309299
Train loss on 300 batch: 0.278478
Train loss on 350 batch: 0.307860
Train loss on 400 batch: 0.315499
Train loss on 450 batch: 0.305568
Train loss on 500 batch: 0.256970
Train loss on 550 batch: 0.284072
Train loss on 600 batch: 0.305443
Train loss on 650 batch: 0.287918
Train loss on 700 batch: 0.313183
Train loss on 750 batch: 0.251507
Train loss on 800 batch: 0.309634
Train loss on 850 batch: 0.318835
Train loss on 900 batch: 0.266489
Train loss on 950 batch: 0.284937
Train loss on 1000 batch: 0.289941
Train loss on 1050 batch: 0.291058
Train loss on 1100 batch: 0.317446
Train loss on 1150 batch: 0.377480
Train loss on 1200 batch: 0.261757
Train loss on 1250 batch: 0.350880
Train loss on 1300 batch: 0.293216
Train loss on 1350 batch: 0.321962
Train loss on 1400 batch: 0.300141
Train loss on 1450 batch: 0.257290
Train loss on 1500 batch: 0.256623
Train loss on 1550 batch: 0.327951
Train loss on 1600 batch: 0.244965
Train loss on 1650 batch: 0.312281
Train loss on 1700 batch: 0.274385
Train loss on 1750 batch: 0.265931
Train loss on 1800 batch: 0.326105
Train loss on 1850 batch: 0.245185
Train loss on 1900 batch: 0.284321
best-train-loss: 0.292556
best-valid-loss: 0.331870
best-kappa: 0.6900
: Epoch: 23 | Training Loss: 0.292556 | Val. Loss: 0.331870 | Val. Kappa Score: 0.6900 | LR: 0.000125 | Estimated time: 371.78
Train loss on 50 batch: 0.270570
Train loss on 100 batch: 0.287319
Train loss on 150 batch: 0.281983
Train loss on 200 batch: 0.297871
Train loss on 250 batch: 0.235454
Train loss on 300 batch: 0.238761
Train loss on 350 batch: 0.343710
Train loss on 400 batch: 0.257543
Train loss on 450 batch: 0.287496
Train loss on 500 batch: 0.298861
Train loss on 550 batch: 0.260634
Train loss on 600 batch: 0.301458
Train loss on 650 batch: 0.302038
Train loss on 700 batch: 0.253855
Train loss on 750 batch: 0.270898
Train loss on 800 batch: 0.323427
Train loss on 850 batch: 0.295217
Train loss on 900 batch: 0.301614
Train loss on 950 batch: 0.272206
Train loss on 1000 batch: 0.258074
Train loss on 1050 batch: 0.303629
Train loss on 1100 batch: 0.298066
Train loss on 1150 batch: 0.293490
Train loss on 1200 batch: 0.292553
Train loss on 1250 batch: 0.291018
Train loss on 1300 batch: 0.318297
Train loss on 1350 batch: 0.281694
Train loss on 1400 batch: 0.269123
Train loss on 1450 batch: 0.286215
Train loss on 1500 batch: 0.309118
Train loss on 1550 batch: 0.311301
Train loss on 1600 batch: 0.340418
Train loss on 1650 batch: 0.280264
Train loss on 1700 batch: 0.337635
Train loss on 1750 batch: 0.288643
Train loss on 1800 batch: 0.329052
Train loss on 1850 batch: 0.254481
Train loss on 1900 batch: 0.291268
: Epoch: 24 | Training Loss: 0.289474 | Val. Loss: 0.346829 | Val. Kappa Score: 0.6925 | LR: 0.000125 | Estimated time: 372.02
Train loss on 50 batch: 0.309282
Train loss on 100 batch: 0.306699
Train loss on 150 batch: 0.287891
Train loss on 200 batch: 0.261324
Train loss on 250 batch: 0.282123
Train loss on 300 batch: 0.297713
Train loss on 350 batch: 0.267046
Train loss on 400 batch: 0.275940
Train loss on 450 batch: 0.263226
Train loss on 500 batch: 0.270637
Train loss on 550 batch: 0.289445
Train loss on 600 batch: 0.280894
Train loss on 650 batch: 0.344706
Train loss on 700 batch: 0.305400
Train loss on 750 batch: 0.247739
Train loss on 800 batch: 0.288413
Train loss on 850 batch: 0.267639
Train loss on 900 batch: 0.265809
Train loss on 950 batch: 0.264749
Train loss on 1000 batch: 0.313856
Train loss on 1050 batch: 0.335035
Train loss on 1100 batch: 0.284797
Train loss on 1150 batch: 0.267943
Train loss on 1200 batch: 0.251822
Train loss on 1250 batch: 0.306390
Train loss on 1300 batch: 0.265521
Train loss on 1350 batch: 0.311241
Train loss on 1400 batch: 0.299286
Train loss on 1450 batch: 0.299548
Train loss on 1500 batch: 0.295465
Train loss on 1550 batch: 0.272726
Train loss on 1600 batch: 0.311963
Train loss on 1650 batch: 0.281121
Train loss on 1700 batch: 0.336155
Train loss on 1750 batch: 0.251812
Train loss on 1800 batch: 0.314845
Train loss on 1850 batch: 0.291419
Train loss on 1900 batch: 0.310453
best-train-loss: 0.288409
best-valid-loss: 0.326320
best-kappa: 0.6945
: Epoch: 25 | Training Loss: 0.288409 | Val. Loss: 0.326320 | Val. Kappa Score: 0.6945 | LR: 0.000125 | Estimated time: 371.92
Train loss on 50 batch: 0.236505
Train loss on 100 batch: 0.269670
Train loss on 150 batch: 0.236540
Train loss on 200 batch: 0.280282
Train loss on 250 batch: 0.298456
Train loss on 300 batch: 0.277392
Train loss on 350 batch: 0.297445
Train loss on 400 batch: 0.307202
Train loss on 450 batch: 0.257467
Train loss on 500 batch: 0.319976
Train loss on 550 batch: 0.259744
Train loss on 600 batch: 0.282710
Train loss on 650 batch: 0.286238
Train loss on 700 batch: 0.281128
Train loss on 750 batch: 0.239490
Train loss on 800 batch: 0.284850
Train loss on 850 batch: 0.319100
Train loss on 900 batch: 0.300551
Train loss on 950 batch: 0.291424
Train loss on 1000 batch: 0.272143
Train loss on 1050 batch: 0.287102
Train loss on 1100 batch: 0.310857
Train loss on 1150 batch: 0.278005
Train loss on 1200 batch: 0.307537
Train loss on 1250 batch: 0.280148
Train loss on 1300 batch: 0.229712
Train loss on 1350 batch: 0.312728
Train loss on 1400 batch: 0.290024
Train loss on 1450 batch: 0.292281
Train loss on 1500 batch: 0.309421
Train loss on 1550 batch: 0.290613
Train loss on 1600 batch: 0.273135
Train loss on 1650 batch: 0.339458
Train loss on 1700 batch: 0.287616
Train loss on 1750 batch: 0.313674
Train loss on 1800 batch: 0.313247
Train loss on 1850 batch: 0.280212
Train loss on 1900 batch: 0.301270
best-train-loss: 0.285981
best-valid-loss: 0.322053
best-kappa: 0.6970
: Epoch: 26 | Training Loss: 0.285981 | Val. Loss: 0.322053 | Val. Kappa Score: 0.6970 | LR: 0.000125 | Estimated time: 371.31
Train loss on 50 batch: 0.291518
Train loss on 100 batch: 0.295024
Train loss on 150 batch: 0.322478
Train loss on 200 batch: 0.296323
Train loss on 250 batch: 0.274483
Train loss on 300 batch: 0.303643
Train loss on 350 batch: 0.273899
Train loss on 400 batch: 0.276934
Train loss on 450 batch: 0.259369
Train loss on 500 batch: 0.261332
Train loss on 550 batch: 0.311682
Train loss on 600 batch: 0.302474
Train loss on 650 batch: 0.323870
Train loss on 700 batch: 0.327170
Train loss on 750 batch: 0.288377
Train loss on 800 batch: 0.313661
Train loss on 850 batch: 0.296539
Train loss on 900 batch: 0.309650
Train loss on 950 batch: 0.300965
Train loss on 1000 batch: 0.302944
Train loss on 1050 batch: 0.311229
Train loss on 1100 batch: 0.265162
Train loss on 1150 batch: 0.310649
Train loss on 1200 batch: 0.290513
Train loss on 1250 batch: 0.378283
Train loss on 1300 batch: 0.319262
Train loss on 1350 batch: 0.237563
Train loss on 1400 batch: 0.263827
Train loss on 1450 batch: 0.293229
Train loss on 1500 batch: 0.294322
Train loss on 1550 batch: 0.232588
Train loss on 1600 batch: 0.254659
Train loss on 1650 batch: 0.244207
Train loss on 1700 batch: 0.259178
Train loss on 1750 batch: 0.277509
Train loss on 1800 batch: 0.274643
Train loss on 1850 batch: 0.289676
Train loss on 1900 batch: 0.251604
best-train-loss: 0.287885
best-valid-loss: 0.320176
best-kappa: 0.6989
: Epoch: 27 | Training Loss: 0.287885 | Val. Loss: 0.320176 | Val. Kappa Score: 0.6989 | LR: 0.000125 | Estimated time: 371.50
Train loss on 50 batch: 0.286811
Train loss on 100 batch: 0.277789
Train loss on 150 batch: 0.282813
Train loss on 200 batch: 0.252203
Train loss on 250 batch: 0.293665
Train loss on 300 batch: 0.278613
Train loss on 350 batch: 0.321513
Train loss on 400 batch: 0.259435
Train loss on 450 batch: 0.242621
Train loss on 500 batch: 0.298802
Train loss on 550 batch: 0.273246
Train loss on 600 batch: 0.293427
Train loss on 650 batch: 0.252431
Train loss on 700 batch: 0.267779
Train loss on 750 batch: 0.271699
Train loss on 800 batch: 0.286107
Train loss on 850 batch: 0.309518
Train loss on 900 batch: 0.255736
Train loss on 950 batch: 0.322273
Train loss on 1000 batch: 0.295157
Train loss on 1050 batch: 0.288070
Train loss on 1100 batch: 0.256230
Train loss on 1150 batch: 0.251968
Train loss on 1200 batch: 0.284697
Train loss on 1250 batch: 0.268136
Train loss on 1300 batch: 0.234948
Train loss on 1350 batch: 0.292477
Train loss on 1400 batch: 0.308002
Train loss on 1450 batch: 0.302071
Train loss on 1500 batch: 0.263663
Train loss on 1550 batch: 0.291651
Train loss on 1600 batch: 0.351668
Train loss on 1650 batch: 0.282459
Train loss on 1700 batch: 0.296261
Train loss on 1750 batch: 0.324884
Train loss on 1800 batch: 0.271957
Train loss on 1850 batch: 0.281761
Train loss on 1900 batch: 0.223546
: Epoch: 28 | Training Loss: 0.281671 | Val. Loss: 0.329533 | Val. Kappa Score: 0.7009 | LR: 0.000125 | Estimated time: 371.72
Train loss on 50 batch: 0.273499
Train loss on 100 batch: 0.311773
Train loss on 150 batch: 0.328246
Train loss on 200 batch: 0.269854
Train loss on 250 batch: 0.287247
Train loss on 300 batch: 0.277983
Train loss on 350 batch: 0.281934
Train loss on 400 batch: 0.278753
Train loss on 450 batch: 0.313588
Train loss on 500 batch: 0.229720
Train loss on 550 batch: 0.237937
Train loss on 600 batch: 0.277583
Train loss on 650 batch: 0.251079
Train loss on 700 batch: 0.277957
Train loss on 750 batch: 0.285371
Train loss on 800 batch: 0.321017
Train loss on 850 batch: 0.317133
Train loss on 900 batch: 0.304467
Train loss on 950 batch: 0.292532
Train loss on 1000 batch: 0.252169
Train loss on 1050 batch: 0.257165
Train loss on 1100 batch: 0.261656
Train loss on 1150 batch: 0.266874
Train loss on 1200 batch: 0.346805
Train loss on 1250 batch: 0.279398
Train loss on 1300 batch: 0.309922
Train loss on 1350 batch: 0.297252
Train loss on 1400 batch: 0.274919
Train loss on 1450 batch: 0.285433
Train loss on 1500 batch: 0.264716
Train loss on 1550 batch: 0.265250
Train loss on 1600 batch: 0.297274
Train loss on 1650 batch: 0.270330
Train loss on 1700 batch: 0.271278
Train loss on 1750 batch: 0.295656
Train loss on 1800 batch: 0.266663
Train loss on 1850 batch: 0.272326
Train loss on 1900 batch: 0.254963
: Epoch: 29 | Training Loss: 0.281715 | Val. Loss: 0.323117 | Val. Kappa Score: 0.7029 | LR: 0.000125 | Estimated time: 371.49
Train loss on 50 batch: 0.282519
Train loss on 100 batch: 0.249014
Train loss on 150 batch: 0.243032
Train loss on 200 batch: 0.269020
Train loss on 250 batch: 0.300333
Train loss on 300 batch: 0.291609
Train loss on 350 batch: 0.306990
Train loss on 400 batch: 0.316111
Train loss on 450 batch: 0.291755
Train loss on 500 batch: 0.300497
Train loss on 550 batch: 0.336939
Train loss on 600 batch: 0.294940
Train loss on 650 batch: 0.288861
Train loss on 700 batch: 0.270318
Train loss on 750 batch: 0.278858
Train loss on 800 batch: 0.251262
Train loss on 850 batch: 0.295277
Train loss on 900 batch: 0.267875
Train loss on 950 batch: 0.241660
Train loss on 1000 batch: 0.319739
Train loss on 1050 batch: 0.271633
Train loss on 1100 batch: 0.327285
Train loss on 1150 batch: 0.294473
Train loss on 1200 batch: 0.310118
Train loss on 1250 batch: 0.258612
Train loss on 1300 batch: 0.260292
Train loss on 1350 batch: 0.254971
Train loss on 1400 batch: 0.272687
Train loss on 1450 batch: 0.298931
Train loss on 1500 batch: 0.260827
Train loss on 1550 batch: 0.217975
Train loss on 1600 batch: 0.275119
Train loss on 1650 batch: 0.277720
Train loss on 1700 batch: 0.303580
Train loss on 1750 batch: 0.239194
Train loss on 1800 batch: 0.233118
Train loss on 1850 batch: 0.276069
Train loss on 1900 batch: 0.277814
: Epoch: 30 | Training Loss: 0.279227 | Val. Loss: 0.327666 | Val. Kappa Score: 0.7045 | LR: 0.000063 | Estimated time: 372.41
Train loss on 50 batch: 0.331137
Train loss on 100 batch: 0.298992
Train loss on 150 batch: 0.277076
Train loss on 200 batch: 0.285268
Train loss on 250 batch: 0.220730
Train loss on 300 batch: 0.294341
Train loss on 350 batch: 0.291749
Train loss on 400 batch: 0.250815
Train loss on 450 batch: 0.249677
Train loss on 500 batch: 0.283749
Train loss on 550 batch: 0.253637
Train loss on 600 batch: 0.269119
Train loss on 650 batch: 0.269938
Train loss on 700 batch: 0.286606
Train loss on 750 batch: 0.267362
Train loss on 800 batch: 0.271591
Train loss on 850 batch: 0.254279
Train loss on 900 batch: 0.256402
Train loss on 950 batch: 0.259670
Train loss on 1000 batch: 0.296587
Train loss on 1050 batch: 0.273560
Train loss on 1100 batch: 0.315618
Train loss on 1150 batch: 0.213258
Train loss on 1200 batch: 0.288412
Train loss on 1250 batch: 0.237900
Train loss on 1300 batch: 0.300633
Train loss on 1350 batch: 0.294851
Train loss on 1400 batch: 0.327323
Train loss on 1450 batch: 0.235423
Train loss on 1500 batch: 0.316953
Train loss on 1550 batch: 0.288422
Train loss on 1600 batch: 0.257196
Train loss on 1650 batch: 0.262253
Train loss on 1700 batch: 0.238697
Train loss on 1750 batch: 0.261553
Train loss on 1800 batch: 0.241392
Train loss on 1850 batch: 0.269963
Train loss on 1900 batch: 0.262058
: Epoch: 31 | Training Loss: 0.273361 | Val. Loss: 0.320288 | Val. Kappa Score: 0.7060 | LR: 0.000063 | Estimated time: 371.55
Train loss on 50 batch: 0.268705
Train loss on 100 batch: 0.330569
Train loss on 150 batch: 0.282918
Train loss on 200 batch: 0.260464
Train loss on 250 batch: 0.283354
Train loss on 300 batch: 0.233232
Train loss on 350 batch: 0.277554
Train loss on 400 batch: 0.297628
Train loss on 450 batch: 0.240436
Train loss on 500 batch: 0.324262
Train loss on 550 batch: 0.264935
Train loss on 600 batch: 0.291559
Train loss on 650 batch: 0.324079
Train loss on 700 batch: 0.251280
Train loss on 750 batch: 0.248990
Train loss on 800 batch: 0.279843
Train loss on 850 batch: 0.294163
Train loss on 900 batch: 0.232495
Train loss on 950 batch: 0.291164
Train loss on 1000 batch: 0.301957
Train loss on 1050 batch: 0.322421
Train loss on 1100 batch: 0.269183
Train loss on 1150 batch: 0.276048
Train loss on 1200 batch: 0.214929
Train loss on 1250 batch: 0.312406
Train loss on 1300 batch: 0.250223
Train loss on 1350 batch: 0.295026
Train loss on 1400 batch: 0.308532
Train loss on 1450 batch: 0.266770
Train loss on 1500 batch: 0.228408
Train loss on 1550 batch: 0.277963
Train loss on 1600 batch: 0.275425
Train loss on 1650 batch: 0.278747
Train loss on 1700 batch: 0.272805
Train loss on 1750 batch: 0.256206
Train loss on 1800 batch: 0.239978
Train loss on 1850 batch: 0.250237
Train loss on 1900 batch: 0.230495
: Epoch: 32 | Training Loss: 0.272311 | Val. Loss: 0.321697 | Val. Kappa Score: 0.7070 | LR: 0.000063 | Estimated time: 370.99
Train loss on 50 batch: 0.238214
Train loss on 100 batch: 0.290891
Train loss on 150 batch: 0.258024
Train loss on 200 batch: 0.303956
Train loss on 250 batch: 0.274971
Train loss on 300 batch: 0.263505
Train loss on 350 batch: 0.287281
Train loss on 400 batch: 0.231388
Train loss on 450 batch: 0.255953
Train loss on 500 batch: 0.227431
Train loss on 550 batch: 0.235466
Train loss on 600 batch: 0.306531
Train loss on 650 batch: 0.288362
Train loss on 700 batch: 0.303562
Train loss on 750 batch: 0.267929
Train loss on 800 batch: 0.285050
Train loss on 850 batch: 0.325518
Train loss on 900 batch: 0.316285
Train loss on 950 batch: 0.237545
Train loss on 1000 batch: 0.232273
Train loss on 1050 batch: 0.240792
Train loss on 1100 batch: 0.269359
Train loss on 1150 batch: 0.276272
Train loss on 1200 batch: 0.204902
Train loss on 1250 batch: 0.264784
Train loss on 1300 batch: 0.275053
Train loss on 1350 batch: 0.251124
Train loss on 1400 batch: 0.267145
Train loss on 1450 batch: 0.349763
Train loss on 1500 batch: 0.330880
Train loss on 1550 batch: 0.273136
Train loss on 1600 batch: 0.255317
Train loss on 1650 batch: 0.279424
Train loss on 1700 batch: 0.227984
Train loss on 1750 batch: 0.284335
Train loss on 1800 batch: 0.290586
Train loss on 1850 batch: 0.260208
Train loss on 1900 batch: 0.269276
best-train-loss: 0.270266
best-valid-loss: 0.318433
best-kappa: 0.7081
: Epoch: 33 | Training Loss: 0.270266 | Val. Loss: 0.318433 | Val. Kappa Score: 0.7081 | LR: 0.000063 | Estimated time: 371.34
Train loss on 50 batch: 0.243218
Train loss on 100 batch: 0.295601
Train loss on 150 batch: 0.291942
Train loss on 200 batch: 0.257729
Train loss on 250 batch: 0.232027
Train loss on 300 batch: 0.264252
Train loss on 350 batch: 0.236755
Train loss on 400 batch: 0.260748
Train loss on 450 batch: 0.241592
Train loss on 500 batch: 0.242036
Train loss on 550 batch: 0.284820
Train loss on 600 batch: 0.294393
Train loss on 650 batch: 0.297869
Train loss on 700 batch: 0.258868
Train loss on 750 batch: 0.275033
Train loss on 800 batch: 0.297379
Train loss on 850 batch: 0.254996
Train loss on 900 batch: 0.295242
Train loss on 950 batch: 0.291511
Train loss on 1000 batch: 0.314453
Train loss on 1050 batch: 0.300651
Train loss on 1100 batch: 0.338769
Train loss on 1150 batch: 0.252069
Train loss on 1200 batch: 0.298103
Train loss on 1250 batch: 0.306844
Train loss on 1300 batch: 0.232363
Train loss on 1350 batch: 0.257593
Train loss on 1400 batch: 0.268721
Train loss on 1450 batch: 0.251659
Train loss on 1500 batch: 0.248276
Train loss on 1550 batch: 0.290644
Train loss on 1600 batch: 0.236298
Train loss on 1650 batch: 0.251119
Train loss on 1700 batch: 0.241203
Train loss on 1750 batch: 0.243328
Train loss on 1800 batch: 0.262139
Train loss on 1850 batch: 0.210774
Train loss on 1900 batch: 0.246596
: Epoch: 34 | Training Loss: 0.267817 | Val. Loss: 0.319820 | Val. Kappa Score: 0.7092 | LR: 0.000063 | Estimated time: 372.44
Train loss on 50 batch: 0.203521
Train loss on 100 batch: 0.243074
Train loss on 150 batch: 0.224424
Train loss on 200 batch: 0.276323
Train loss on 250 batch: 0.221658
Train loss on 300 batch: 0.271894
Train loss on 350 batch: 0.239632
Train loss on 400 batch: 0.259038
Train loss on 450 batch: 0.259149
Train loss on 500 batch: 0.251825
Train loss on 550 batch: 0.246217
Train loss on 600 batch: 0.280510
Train loss on 650 batch: 0.294427
Train loss on 700 batch: 0.263568
Train loss on 750 batch: 0.312269
Train loss on 800 batch: 0.273649
Train loss on 850 batch: 0.281650
Train loss on 900 batch: 0.291139
Train loss on 950 batch: 0.295246
Train loss on 1000 batch: 0.270434
Train loss on 1050 batch: 0.294775
Train loss on 1100 batch: 0.267434
Train loss on 1150 batch: 0.277797
Train loss on 1200 batch: 0.315616
Train loss on 1250 batch: 0.302575
Train loss on 1300 batch: 0.257562
Train loss on 1350 batch: 0.264427
Train loss on 1400 batch: 0.232689
Train loss on 1450 batch: 0.254188
Train loss on 1500 batch: 0.248014
Train loss on 1550 batch: 0.254156
Train loss on 1600 batch: 0.270067
Train loss on 1650 batch: 0.250757
Train loss on 1700 batch: 0.267471
Train loss on 1750 batch: 0.328462
Train loss on 1800 batch: 0.324489
Train loss on 1850 batch: 0.292766
Train loss on 1900 batch: 0.247747
best-train-loss: 0.267252
best-valid-loss: 0.317233
best-kappa: 0.7106
: Epoch: 35 | Training Loss: 0.267252 | Val. Loss: 0.317233 | Val. Kappa Score: 0.7106 | LR: 0.000063 | Estimated time: 372.34
Train loss on 50 batch: 0.284435
Train loss on 100 batch: 0.217311
Train loss on 150 batch: 0.306022
Train loss on 200 batch: 0.223502
Train loss on 250 batch: 0.282126
Train loss on 300 batch: 0.239912
Train loss on 350 batch: 0.254338
Train loss on 400 batch: 0.271165
Train loss on 450 batch: 0.209837
Train loss on 500 batch: 0.268920
Train loss on 550 batch: 0.262820
Train loss on 600 batch: 0.275953
Train loss on 650 batch: 0.266791
Train loss on 700 batch: 0.323049
Train loss on 750 batch: 0.266760
Train loss on 800 batch: 0.271400
Train loss on 850 batch: 0.260090
Train loss on 900 batch: 0.267301
Train loss on 950 batch: 0.254853
Train loss on 1000 batch: 0.329557
Train loss on 1050 batch: 0.250295
Train loss on 1100 batch: 0.270265
Train loss on 1150 batch: 0.272852
Train loss on 1200 batch: 0.255619
Train loss on 1250 batch: 0.255913
Train loss on 1300 batch: 0.257650
Train loss on 1350 batch: 0.208737
Train loss on 1400 batch: 0.276903
Train loss on 1450 batch: 0.266652
Train loss on 1500 batch: 0.293681
Train loss on 1550 batch: 0.248818
Train loss on 1600 batch: 0.320999
Train loss on 1650 batch: 0.217220
Train loss on 1700 batch: 0.276708
Train loss on 1750 batch: 0.255758
Train loss on 1800 batch: 0.277410
Train loss on 1850 batch: 0.286517
Train loss on 1900 batch: 0.247359
: Epoch: 36 | Training Loss: 0.265684 | Val. Loss: 0.321070 | Val. Kappa Score: 0.7116 | LR: 0.000063 | Estimated time: 371.81
Train loss on 50 batch: 0.254072
Train loss on 100 batch: 0.275885
Train loss on 150 batch: 0.277243
Train loss on 200 batch: 0.245965
Train loss on 250 batch: 0.327367
Train loss on 300 batch: 0.278307
Train loss on 350 batch: 0.282029
Train loss on 400 batch: 0.269223
Train loss on 450 batch: 0.259589
Train loss on 500 batch: 0.268070
Train loss on 550 batch: 0.266655
Train loss on 600 batch: 0.238339
Train loss on 650 batch: 0.298399
Train loss on 700 batch: 0.256573
Train loss on 750 batch: 0.260938
Train loss on 800 batch: 0.316477
Train loss on 850 batch: 0.214445
Train loss on 900 batch: 0.268055
Train loss on 950 batch: 0.301875
Train loss on 1000 batch: 0.237165
Train loss on 1050 batch: 0.272443
Train loss on 1100 batch: 0.244243
Train loss on 1150 batch: 0.241075
Train loss on 1200 batch: 0.241051
Train loss on 1250 batch: 0.302283
Train loss on 1300 batch: 0.216087
Train loss on 1350 batch: 0.233553
Train loss on 1400 batch: 0.274448
Train loss on 1450 batch: 0.297691
Train loss on 1500 batch: 0.271028
Train loss on 1550 batch: 0.224827
Train loss on 1600 batch: 0.296077
Train loss on 1650 batch: 0.310426
Train loss on 1700 batch: 0.269504
Train loss on 1750 batch: 0.304419
Train loss on 1800 batch: 0.239281
Train loss on 1850 batch: 0.285655
Train loss on 1900 batch: 0.225028
: Epoch: 37 | Training Loss: 0.265907 | Val. Loss: 0.321184 | Val. Kappa Score: 0.7128 | LR: 0.000063 | Estimated time: 372.06
Train loss on 50 batch: 0.271460
Train loss on 100 batch: 0.260573
Train loss on 150 batch: 0.198835
Train loss on 200 batch: 0.281193
Train loss on 250 batch: 0.234977
Train loss on 300 batch: 0.265567
Train loss on 350 batch: 0.264084
Train loss on 400 batch: 0.233555
Train loss on 450 batch: 0.294244
Train loss on 500 batch: 0.253647
Train loss on 550 batch: 0.300300
Train loss on 600 batch: 0.246671
Train loss on 650 batch: 0.263350
Train loss on 700 batch: 0.254508
Train loss on 750 batch: 0.301221
Train loss on 800 batch: 0.284863
Train loss on 850 batch: 0.222636
Train loss on 900 batch: 0.299359
Train loss on 950 batch: 0.273323
Train loss on 1000 batch: 0.285000
Train loss on 1050 batch: 0.252794
Train loss on 1100 batch: 0.287594
Train loss on 1150 batch: 0.196811
Train loss on 1200 batch: 0.247055
Train loss on 1250 batch: 0.255401
Train loss on 1300 batch: 0.282799
Train loss on 1350 batch: 0.265104
Train loss on 1400 batch: 0.263290
Train loss on 1450 batch: 0.237438
Train loss on 1500 batch: 0.261846
Train loss on 1550 batch: 0.290188
Train loss on 1600 batch: 0.287062
Train loss on 1650 batch: 0.287297
Train loss on 1700 batch: 0.243873
Train loss on 1750 batch: 0.271506
Train loss on 1800 batch: 0.258508
Train loss on 1850 batch: 0.265608
Train loss on 1900 batch: 0.228335
: Epoch: 38 | Training Loss: 0.262418 | Val. Loss: 0.320336 | Val. Kappa Score: 0.7135 | LR: 0.000031 | Estimated time: 371.62
Train loss on 50 batch: 0.265444
Train loss on 100 batch: 0.221595
Train loss on 150 batch: 0.244472
Train loss on 200 batch: 0.244160
Train loss on 250 batch: 0.253632
Train loss on 300 batch: 0.244120
Train loss on 350 batch: 0.283403
Train loss on 400 batch: 0.246017
Train loss on 450 batch: 0.261666
Train loss on 500 batch: 0.314482
Train loss on 550 batch: 0.259893
Train loss on 600 batch: 0.205958
Train loss on 650 batch: 0.277798
Train loss on 700 batch: 0.248410
Train loss on 750 batch: 0.238363
Train loss on 800 batch: 0.242335
Train loss on 850 batch: 0.245111
Train loss on 900 batch: 0.315233
Train loss on 950 batch: 0.299946
Train loss on 1000 batch: 0.284528
Train loss on 1050 batch: 0.279460
Train loss on 1100 batch: 0.300822
Train loss on 1150 batch: 0.283874
Train loss on 1200 batch: 0.239274
Train loss on 1250 batch: 0.231568
Train loss on 1300 batch: 0.287525
Train loss on 1350 batch: 0.269989
Train loss on 1400 batch: 0.263080
Train loss on 1450 batch: 0.264420
Train loss on 1500 batch: 0.267715
Train loss on 1550 batch: 0.265625
Train loss on 1600 batch: 0.245894
Train loss on 1650 batch: 0.275732
Train loss on 1700 batch: 0.247545
Train loss on 1750 batch: 0.291325
Train loss on 1800 batch: 0.295687
Train loss on 1850 batch: 0.268032
Train loss on 1900 batch: 0.249575
best-train-loss: 0.263561
best-valid-loss: 0.316773
best-kappa: 0.7146
: Epoch: 39 | Training Loss: 0.263561 | Val. Loss: 0.316773 | Val. Kappa Score: 0.7146 | LR: 0.000031 | Estimated time: 371.66
Train loss on 50 batch: 0.257780
Train loss on 100 batch: 0.243902
Train loss on 150 batch: 0.223465
Train loss on 200 batch: 0.259058
Train loss on 250 batch: 0.251058
Train loss on 300 batch: 0.261321
Train loss on 350 batch: 0.255561
Train loss on 400 batch: 0.250794
Train loss on 450 batch: 0.270947
Train loss on 500 batch: 0.256848
Train loss on 550 batch: 0.224934
Train loss on 600 batch: 0.229341
Train loss on 650 batch: 0.281734
Train loss on 700 batch: 0.240765
Train loss on 750 batch: 0.219422
Train loss on 800 batch: 0.263319
Train loss on 850 batch: 0.292556
Train loss on 900 batch: 0.258125
Train loss on 950 batch: 0.283312
Train loss on 1000 batch: 0.233285
Train loss on 1050 batch: 0.267168
Train loss on 1100 batch: 0.268021
Train loss on 1150 batch: 0.259726
Train loss on 1200 batch: 0.223682
Train loss on 1250 batch: 0.269800
Train loss on 1300 batch: 0.280548
Train loss on 1350 batch: 0.237498
Train loss on 1400 batch: 0.236049
Train loss on 1450 batch: 0.307161
Train loss on 1500 batch: 0.272901
Train loss on 1550 batch: 0.237653
Train loss on 1600 batch: 0.253662
Train loss on 1650 batch: 0.288793
Train loss on 1700 batch: 0.280267
Train loss on 1750 batch: 0.298961
Train loss on 1800 batch: 0.240840
Train loss on 1850 batch: 0.253844
Train loss on 1900 batch: 0.260219
: Epoch: 40 | Training Loss: 0.257451 | Val. Loss: 0.318567 | Val. Kappa Score: 0.7156 | LR: 0.000031 | Estimated time: 371.78
Train loss on 50 batch: 0.319761
Train loss on 100 batch: 0.228002
Train loss on 150 batch: 0.262767
Train loss on 200 batch: 0.228104
Train loss on 250 batch: 0.261338
Train loss on 300 batch: 0.236482
Train loss on 350 batch: 0.248761
Train loss on 400 batch: 0.225922
Train loss on 450 batch: 0.255044
Train loss on 500 batch: 0.295786
Train loss on 550 batch: 0.283898
Train loss on 600 batch: 0.280903
Train loss on 650 batch: 0.243096
Train loss on 700 batch: 0.258221
Train loss on 750 batch: 0.241091
Train loss on 800 batch: 0.246986
Train loss on 850 batch: 0.273990
Train loss on 900 batch: 0.255183
Train loss on 950 batch: 0.222734
Train loss on 1000 batch: 0.216746
Train loss on 1050 batch: 0.248833
Train loss on 1100 batch: 0.308542
Train loss on 1150 batch: 0.278706
Train loss on 1200 batch: 0.205574
Train loss on 1250 batch: 0.242332
Train loss on 1300 batch: 0.243775
Train loss on 1350 batch: 0.234093
Train loss on 1400 batch: 0.294427
Train loss on 1450 batch: 0.211952
Train loss on 1500 batch: 0.260679
Train loss on 1550 batch: 0.290660
Train loss on 1600 batch: 0.277367
Train loss on 1650 batch: 0.217617
Train loss on 1700 batch: 0.253121
Train loss on 1750 batch: 0.239826
Train loss on 1800 batch: 0.309715
Train loss on 1850 batch: 0.240893
Train loss on 1900 batch: 0.275600
: Epoch: 41 | Training Loss: 0.257225 | Val. Loss: 0.317382 | Val. Kappa Score: 0.7165 | LR: 0.000031 | Estimated time: 371.50
Train loss on 50 batch: 0.246848
Train loss on 100 batch: 0.234423
Train loss on 150 batch: 0.270467
Train loss on 200 batch: 0.276184
Train loss on 250 batch: 0.262675
Train loss on 300 batch: 0.212144
Train loss on 350 batch: 0.226699
Train loss on 400 batch: 0.305336
Train loss on 450 batch: 0.275957
Train loss on 500 batch: 0.236148
Train loss on 550 batch: 0.292809
Train loss on 600 batch: 0.240391
Train loss on 650 batch: 0.285735
Train loss on 700 batch: 0.229915
Train loss on 750 batch: 0.234741
Train loss on 800 batch: 0.265126
Train loss on 850 batch: 0.278545
Train loss on 900 batch: 0.212651
Train loss on 950 batch: 0.286911
Train loss on 1000 batch: 0.295652
Train loss on 1050 batch: 0.231339
Train loss on 1100 batch: 0.241152
Train loss on 1150 batch: 0.258498
Train loss on 1200 batch: 0.289235
Train loss on 1250 batch: 0.262984
Train loss on 1300 batch: 0.315142
Train loss on 1350 batch: 0.258455
Train loss on 1400 batch: 0.276714
Train loss on 1450 batch: 0.254591
Train loss on 1500 batch: 0.262762
Train loss on 1550 batch: 0.257851
Train loss on 1600 batch: 0.269917
Train loss on 1650 batch: 0.219652
Train loss on 1700 batch: 0.247207
Train loss on 1750 batch: 0.240550
Train loss on 1800 batch: 0.269933
Train loss on 1850 batch: 0.213387
Train loss on 1900 batch: 0.245326
best-train-loss: 0.257692
best-valid-loss: 0.315205
best-kappa: 0.7175
: Epoch: 42 | Training Loss: 0.257692 | Val. Loss: 0.315205 | Val. Kappa Score: 0.7175 | LR: 0.000031 | Estimated time: 371.76
Train loss on 50 batch: 0.282425
Train loss on 100 batch: 0.234870
Train loss on 150 batch: 0.259891
Train loss on 200 batch: 0.240301
Train loss on 250 batch: 0.234162
Train loss on 300 batch: 0.281003
Train loss on 350 batch: 0.306279
Train loss on 400 batch: 0.252616
Train loss on 450 batch: 0.274762
Train loss on 500 batch: 0.262754
Train loss on 550 batch: 0.267473
Train loss on 600 batch: 0.278313
Train loss on 650 batch: 0.222571
Train loss on 700 batch: 0.241683
Train loss on 750 batch: 0.261281
Train loss on 800 batch: 0.252064
Train loss on 850 batch: 0.286377
Train loss on 900 batch: 0.241468
Train loss on 950 batch: 0.257872
Train loss on 1000 batch: 0.289293
Train loss on 1050 batch: 0.274666
Train loss on 1100 batch: 0.277331
Train loss on 1150 batch: 0.296519
Train loss on 1200 batch: 0.273752
Train loss on 1250 batch: 0.255506
Train loss on 1300 batch: 0.268577
Train loss on 1350 batch: 0.272946
Train loss on 1400 batch: 0.205102
Train loss on 1450 batch: 0.264713
Train loss on 1500 batch: 0.268014
Train loss on 1550 batch: 0.251471
Train loss on 1600 batch: 0.213361
Train loss on 1650 batch: 0.258782
Train loss on 1700 batch: 0.244806
Train loss on 1750 batch: 0.240256
Train loss on 1800 batch: 0.249144
Train loss on 1850 batch: 0.234592
Train loss on 1900 batch: 0.274158
best-train-loss: 0.258018
best-valid-loss: 0.315005
best-kappa: 0.7183
: Epoch: 43 | Training Loss: 0.258018 | Val. Loss: 0.315005 | Val. Kappa Score: 0.7183 | LR: 0.000031 | Estimated time: 371.85
Train loss on 50 batch: 0.223395
Train loss on 100 batch: 0.268788
Train loss on 150 batch: 0.223986
Train loss on 200 batch: 0.220317
Train loss on 250 batch: 0.231709
Train loss on 300 batch: 0.265993
Train loss on 350 batch: 0.231846
Train loss on 400 batch: 0.250917
Train loss on 450 batch: 0.273106
Train loss on 500 batch: 0.260625
Train loss on 550 batch: 0.274435
Train loss on 600 batch: 0.234775
Train loss on 650 batch: 0.261141
Train loss on 700 batch: 0.207238
Train loss on 750 batch: 0.237722
Train loss on 800 batch: 0.288019
Train loss on 850 batch: 0.269607
Train loss on 900 batch: 0.251348
Train loss on 950 batch: 0.239104
Train loss on 1000 batch: 0.222600
Train loss on 1050 batch: 0.231842
Train loss on 1100 batch: 0.276786
Train loss on 1150 batch: 0.280918
Train loss on 1200 batch: 0.245208
Train loss on 1250 batch: 0.275295
Train loss on 1300 batch: 0.273196
Train loss on 1350 batch: 0.247793
Train loss on 1400 batch: 0.231061
Train loss on 1450 batch: 0.261688
Train loss on 1500 batch: 0.253320
Train loss on 1550 batch: 0.259107
Train loss on 1600 batch: 0.296060
Train loss on 1650 batch: 0.267237
Train loss on 1700 batch: 0.258967
Train loss on 1750 batch: 0.327970
Train loss on 1800 batch: 0.265090
Train loss on 1850 batch: 0.299016
Train loss on 1900 batch: 0.239332
best-train-loss: 0.255100
best-valid-loss: 0.314609
best-kappa: 0.7192
: Epoch: 44 | Training Loss: 0.255100 | Val. Loss: 0.314609 | Val. Kappa Score: 0.7192 | LR: 0.000031 | Estimated time: 371.69
Train loss on 50 batch: 0.305669
Train loss on 100 batch: 0.242355
Train loss on 150 batch: 0.219995
Train loss on 200 batch: 0.254580
Train loss on 250 batch: 0.281154
Train loss on 300 batch: 0.280396
Train loss on 350 batch: 0.259791
Train loss on 400 batch: 0.235853
Train loss on 450 batch: 0.244244
Train loss on 500 batch: 0.281367
Train loss on 550 batch: 0.276752
Train loss on 600 batch: 0.232462
Train loss on 650 batch: 0.263501
Train loss on 700 batch: 0.236138
Train loss on 750 batch: 0.255522
Train loss on 800 batch: 0.267154
Train loss on 850 batch: 0.229539
Train loss on 900 batch: 0.267161
Train loss on 950 batch: 0.242554
Train loss on 1000 batch: 0.271692
Train loss on 1050 batch: 0.247159
Train loss on 1100 batch: 0.233928
Train loss on 1150 batch: 0.250334
Train loss on 1200 batch: 0.294977
Train loss on 1250 batch: 0.280647
Train loss on 1300 batch: 0.268149
Train loss on 1350 batch: 0.265743
Train loss on 1400 batch: 0.271540
Train loss on 1450 batch: 0.235975
Train loss on 1500 batch: 0.242665
Train loss on 1550 batch: 0.220786
Train loss on 1600 batch: 0.205359
Train loss on 1650 batch: 0.276749
Train loss on 1700 batch: 0.244396
Train loss on 1750 batch: 0.278576
Train loss on 1800 batch: 0.285430
Train loss on 1850 batch: 0.247123
Train loss on 1900 batch: 0.217260
: Epoch: 45 | Training Loss: 0.256175 | Val. Loss: 0.320202 | Val. Kappa Score: 0.7199 | LR: 0.000031 | Estimated time: 372.12
Train loss on 50 batch: 0.245994
Train loss on 100 batch: 0.293850
Train loss on 150 batch: 0.277206
Train loss on 200 batch: 0.257270
Train loss on 250 batch: 0.303015
Train loss on 300 batch: 0.208242
Train loss on 350 batch: 0.231630
Train loss on 400 batch: 0.250843
Train loss on 450 batch: 0.268305
Train loss on 500 batch: 0.257183
Train loss on 550 batch: 0.246465
Train loss on 600 batch: 0.260819
Train loss on 650 batch: 0.251531
Train loss on 700 batch: 0.214994
Train loss on 750 batch: 0.231233
Train loss on 800 batch: 0.282812
Train loss on 850 batch: 0.288587
Train loss on 900 batch: 0.302859
Train loss on 950 batch: 0.293015
Train loss on 1000 batch: 0.202470
Train loss on 1050 batch: 0.240329
Train loss on 1100 batch: 0.235230
Train loss on 1150 batch: 0.207083
Train loss on 1200 batch: 0.243380
Train loss on 1250 batch: 0.200660
Train loss on 1300 batch: 0.220549
Train loss on 1350 batch: 0.272325
Train loss on 1400 batch: 0.250607
Train loss on 1450 batch: 0.226175
Train loss on 1500 batch: 0.252260
Train loss on 1550 batch: 0.248359
Train loss on 1600 batch: 0.292097
Train loss on 1650 batch: 0.253452
Train loss on 1700 batch: 0.289702
Train loss on 1750 batch: 0.253420
Train loss on 1800 batch: 0.266047
Train loss on 1850 batch: 0.275217
Train loss on 1900 batch: 0.262000
: Epoch: 46 | Training Loss: 0.253973 | Val. Loss: 0.316007 | Val. Kappa Score: 0.7208 | LR: 0.000031 | Estimated time: 370.58
Train loss on 50 batch: 0.229629
Train loss on 100 batch: 0.228595
Train loss on 150 batch: 0.266256
Train loss on 200 batch: 0.281452
Train loss on 250 batch: 0.262341
Train loss on 300 batch: 0.241040
Train loss on 350 batch: 0.256282
Train loss on 400 batch: 0.260879
Train loss on 450 batch: 0.245944
Train loss on 500 batch: 0.228212
Train loss on 550 batch: 0.250307
Train loss on 600 batch: 0.249306
Train loss on 650 batch: 0.268883
Train loss on 700 batch: 0.270828
Train loss on 750 batch: 0.269579
Train loss on 800 batch: 0.269202
Train loss on 850 batch: 0.284070
Train loss on 900 batch: 0.250203
Train loss on 950 batch: 0.235760
Train loss on 1000 batch: 0.282664
Train loss on 1050 batch: 0.235089
Train loss on 1100 batch: 0.304984
Train loss on 1150 batch: 0.243020
Train loss on 1200 batch: 0.243477
Train loss on 1250 batch: 0.228973
Train loss on 1300 batch: 0.297020
Train loss on 1350 batch: 0.271277
Train loss on 1400 batch: 0.273728
Train loss on 1450 batch: 0.266169
Train loss on 1500 batch: 0.250855
Train loss on 1550 batch: 0.231518
Train loss on 1600 batch: 0.231630
Train loss on 1650 batch: 0.228850
Train loss on 1700 batch: 0.224838
Train loss on 1750 batch: 0.246594
Train loss on 1800 batch: 0.265375
Train loss on 1850 batch: 0.242386
Train loss on 1900 batch: 0.273949
: Epoch: 47 | Training Loss: 0.254410 | Val. Loss: 0.315408 | Val. Kappa Score: 0.7217 | LR: 0.000016 | Estimated time: 371.69
Train loss on 50 batch: 0.253806
Train loss on 100 batch: 0.264507
Train loss on 150 batch: 0.259935
Train loss on 200 batch: 0.256535
Train loss on 250 batch: 0.270001
Train loss on 300 batch: 0.248247
Train loss on 350 batch: 0.224285
Train loss on 400 batch: 0.270534
Train loss on 450 batch: 0.246511
Train loss on 500 batch: 0.261652
Train loss on 550 batch: 0.248528
Train loss on 600 batch: 0.265854
Train loss on 650 batch: 0.252373
Train loss on 700 batch: 0.273562
Train loss on 750 batch: 0.232238
Train loss on 800 batch: 0.271180
Train loss on 850 batch: 0.244802
Train loss on 900 batch: 0.263823
Train loss on 950 batch: 0.228831
Train loss on 1000 batch: 0.299223
Train loss on 1050 batch: 0.263011
Train loss on 1100 batch: 0.242969
Train loss on 1150 batch: 0.250689
Train loss on 1200 batch: 0.233561
Train loss on 1250 batch: 0.244210
Train loss on 1300 batch: 0.273499
Train loss on 1350 batch: 0.263659
Train loss on 1400 batch: 0.255629
Train loss on 1450 batch: 0.244649
Train loss on 1500 batch: 0.265726
Train loss on 1550 batch: 0.271003
Train loss on 1600 batch: 0.264056
Train loss on 1650 batch: 0.240016
Train loss on 1700 batch: 0.204748
Train loss on 1750 batch: 0.263100
Train loss on 1800 batch: 0.243951
Train loss on 1850 batch: 0.214848
Train loss on 1900 batch: 0.244047
best-train-loss: 0.252810
best-valid-loss: 0.314528
best-kappa: 0.7221
: Epoch: 48 | Training Loss: 0.252810 | Val. Loss: 0.314528 | Val. Kappa Score: 0.7221 | LR: 0.000016 | Estimated time: 371.58
Train loss on 50 batch: 0.236408
Train loss on 100 batch: 0.252157
Train loss on 150 batch: 0.227002
Train loss on 200 batch: 0.287707
Train loss on 250 batch: 0.234632
Train loss on 300 batch: 0.244880
Train loss on 350 batch: 0.262190
Train loss on 400 batch: 0.258652
Train loss on 450 batch: 0.266328
Train loss on 500 batch: 0.284207
Train loss on 550 batch: 0.274466
Train loss on 600 batch: 0.240470
Train loss on 650 batch: 0.271624
Train loss on 700 batch: 0.252198
Train loss on 750 batch: 0.284472
Train loss on 800 batch: 0.236426
Train loss on 850 batch: 0.253423
Train loss on 900 batch: 0.289577
Train loss on 950 batch: 0.245485
Train loss on 1000 batch: 0.248578
Train loss on 1050 batch: 0.224877
Train loss on 1100 batch: 0.213655
Train loss on 1150 batch: 0.243990
Train loss on 1200 batch: 0.274346
Train loss on 1250 batch: 0.216572
Train loss on 1300 batch: 0.252901
Train loss on 1350 batch: 0.270944
Train loss on 1400 batch: 0.240544
Train loss on 1450 batch: 0.232696
Train loss on 1500 batch: 0.266884
Train loss on 1550 batch: 0.245995
Train loss on 1600 batch: 0.223190
Train loss on 1650 batch: 0.276110
Train loss on 1700 batch: 0.253478
Train loss on 1750 batch: 0.213683
Train loss on 1800 batch: 0.253558
Train loss on 1850 batch: 0.271421
Train loss on 1900 batch: 0.267587
: Epoch: 49 | Training Loss: 0.252277 | Val. Loss: 0.316903 | Val. Kappa Score: 0.7229 | LR: 0.000016 | Estimated time: 371.05
Train loss on 50 batch: 0.272805
Train loss on 100 batch: 0.243493
Train loss on 150 batch: 0.248594
Train loss on 200 batch: 0.248527
Train loss on 250 batch: 0.238339
Train loss on 300 batch: 0.262051
Train loss on 350 batch: 0.257097
Train loss on 400 batch: 0.283328
Train loss on 450 batch: 0.282183
Train loss on 500 batch: 0.237200
Train loss on 550 batch: 0.230057
Train loss on 600 batch: 0.245457
Train loss on 650 batch: 0.280820
Train loss on 700 batch: 0.240924
Train loss on 750 batch: 0.255131
Train loss on 800 batch: 0.222953
Train loss on 850 batch: 0.273185
Train loss on 900 batch: 0.267100
Train loss on 950 batch: 0.258829
Train loss on 1000 batch: 0.247441
Train loss on 1050 batch: 0.291813
Train loss on 1100 batch: 0.251466
Train loss on 1150 batch: 0.231196
Train loss on 1200 batch: 0.207126
Train loss on 1250 batch: 0.253470
Train loss on 1300 batch: 0.260557
Train loss on 1350 batch: 0.289462
Train loss on 1400 batch: 0.231933
Train loss on 1450 batch: 0.250015
Train loss on 1500 batch: 0.254609
Train loss on 1550 batch: 0.247410
Train loss on 1600 batch: 0.191651
Train loss on 1650 batch: 0.275100
Train loss on 1700 batch: 0.208674
Train loss on 1750 batch: 0.274701
Train loss on 1800 batch: 0.214632
Train loss on 1850 batch: 0.280795
Train loss on 1900 batch: 0.236597
: Epoch: 50 | Training Loss: 0.251122 | Val. Loss: 0.317421 | Val. Kappa Score: 0.7235 | LR: 0.000016 | Estimated time: 372.79
Train loss on 50 batch: 0.294374
Train loss on 100 batch: 0.259448
Train loss on 150 batch: 0.284954
Train loss on 200 batch: 0.268568
Train loss on 250 batch: 0.300041
Train loss on 300 batch: 0.277729
Train loss on 350 batch: 0.223891
Train loss on 400 batch: 0.270604
Train loss on 450 batch: 0.262013
Train loss on 500 batch: 0.242480
Train loss on 550 batch: 0.238629
Train loss on 600 batch: 0.220552
Train loss on 650 batch: 0.237211
Train loss on 700 batch: 0.265958
Train loss on 750 batch: 0.261612
Train loss on 800 batch: 0.237391
Train loss on 850 batch: 0.211669
Train loss on 900 batch: 0.207965
Train loss on 950 batch: 0.266571
Train loss on 1000 batch: 0.213968
Train loss on 1050 batch: 0.241411
Train loss on 1100 batch: 0.221918
Train loss on 1150 batch: 0.219337
Train loss on 1200 batch: 0.201408
Train loss on 1250 batch: 0.240316
Train loss on 1300 batch: 0.298843
Train loss on 1350 batch: 0.240605
Train loss on 1400 batch: 0.260129
Train loss on 1450 batch: 0.288667
Train loss on 1500 batch: 0.243698
Train loss on 1550 batch: 0.305844
Train loss on 1600 batch: 0.255739
Train loss on 1650 batch: 0.244313
Train loss on 1700 batch: 0.240059
Train loss on 1750 batch: 0.277774
Train loss on 1800 batch: 0.254480
Train loss on 1850 batch: 0.262132
Train loss on 1900 batch: 0.223405
: Epoch: 51 | Training Loss: 0.251012 | Val. Loss: 0.319350 | Val. Kappa Score: 0.7240 | LR: 0.000008 | Estimated time: 371.91
Train loss on 50 batch: 0.262679
Train loss on 100 batch: 0.250482
Train loss on 150 batch: 0.314457
Train loss on 200 batch: 0.218863
Train loss on 250 batch: 0.248073
Train loss on 300 batch: 0.210998
Train loss on 350 batch: 0.265804
Train loss on 400 batch: 0.285333
Train loss on 450 batch: 0.238278
Train loss on 500 batch: 0.239261
Train loss on 550 batch: 0.264754
Train loss on 600 batch: 0.294637
Train loss on 650 batch: 0.248367
Train loss on 700 batch: 0.247678
Train loss on 750 batch: 0.227442
Train loss on 800 batch: 0.220535
Train loss on 850 batch: 0.248502
Train loss on 900 batch: 0.267260
Train loss on 950 batch: 0.244367
Train loss on 1000 batch: 0.253993
Train loss on 1050 batch: 0.214446
Train loss on 1100 batch: 0.296430
Train loss on 1150 batch: 0.220268
Train loss on 1200 batch: 0.248939
Train loss on 1250 batch: 0.213672
Train loss on 1300 batch: 0.217755
Train loss on 1350 batch: 0.250544
Train loss on 1400 batch: 0.251979
Train loss on 1450 batch: 0.316405
Train loss on 1500 batch: 0.233543
Train loss on 1550 batch: 0.261530
Train loss on 1600 batch: 0.245339
Train loss on 1650 batch: 0.235265
Train loss on 1700 batch: 0.230973
Train loss on 1750 batch: 0.217696
Train loss on 1800 batch: 0.338262
Train loss on 1850 batch: 0.237250
Train loss on 1900 batch: 0.275658
: Epoch: 52 | Training Loss: 0.250976 | Val. Loss: 0.317140 | Val. Kappa Score: 0.7247 | LR: 0.000008 | Estimated time: 371.61
Train loss on 50 batch: 0.245561
Train loss on 100 batch: 0.246934
Train loss on 150 batch: 0.222212
Train loss on 200 batch: 0.225113
Train loss on 250 batch: 0.230367
Train loss on 300 batch: 0.244299
Train loss on 350 batch: 0.260382
Train loss on 400 batch: 0.237185
Train loss on 450 batch: 0.223288
Train loss on 500 batch: 0.268083
Train loss on 550 batch: 0.237322
Train loss on 600 batch: 0.277594
Train loss on 650 batch: 0.312335
Train loss on 700 batch: 0.251097
Train loss on 750 batch: 0.217598
Train loss on 800 batch: 0.273085
Train loss on 850 batch: 0.246811
Train loss on 900 batch: 0.228444
Train loss on 950 batch: 0.235011
Train loss on 1000 batch: 0.257231
Train loss on 1050 batch: 0.238811
Train loss on 1100 batch: 0.269860
Train loss on 1150 batch: 0.251472
Train loss on 1200 batch: 0.231846
Train loss on 1250 batch: 0.232956
Train loss on 1300 batch: 0.262426
Train loss on 1350 batch: 0.271104
Train loss on 1400 batch: 0.225065
Train loss on 1450 batch: 0.226806
Train loss on 1500 batch: 0.260890
Train loss on 1550 batch: 0.240764
Train loss on 1600 batch: 0.225412
Train loss on 1650 batch: 0.247752
Train loss on 1700 batch: 0.244079
Train loss on 1750 batch: 0.297520
Train loss on 1800 batch: 0.234563
Train loss on 1850 batch: 0.233886
Train loss on 1900 batch: 0.258234
: Epoch: 53 | Training Loss: 0.246498 | Val. Loss: 0.316353 | Val. Kappa Score: 0.7254 | LR: 0.000008 | Estimated time: 371.17
Train loss on 50 batch: 0.232833
Train loss on 100 batch: 0.238859
Train loss on 150 batch: 0.265153
Train loss on 200 batch: 0.241850
Train loss on 250 batch: 0.250774
Train loss on 300 batch: 0.278838
Train loss on 350 batch: 0.244931
Train loss on 400 batch: 0.271093
Train loss on 450 batch: 0.257738
Train loss on 500 batch: 0.257095
Train loss on 550 batch: 0.248934
Train loss on 600 batch: 0.236857
Train loss on 650 batch: 0.242837
Train loss on 700 batch: 0.295654
Train loss on 750 batch: 0.256594
Train loss on 800 batch: 0.235281
Train loss on 850 batch: 0.268633
Train loss on 900 batch: 0.218980
Train loss on 950 batch: 0.228463
Train loss on 1000 batch: 0.227057
Train loss on 1050 batch: 0.279290
Train loss on 1100 batch: 0.302737
Train loss on 1150 batch: 0.252772
Train loss on 1200 batch: 0.284663
Train loss on 1250 batch: 0.235002
Train loss on 1300 batch: 0.258484
Train loss on 1350 batch: 0.223088
Train loss on 1400 batch: 0.225328
Train loss on 1450 batch: 0.239950
Train loss on 1500 batch: 0.239241
Train loss on 1550 batch: 0.241217
Train loss on 1600 batch: 0.201812
Train loss on 1650 batch: 0.267497
Train loss on 1700 batch: 0.231352
Train loss on 1750 batch: 0.248031
Train loss on 1800 batch: 0.262307
Train loss on 1850 batch: 0.236160
Train loss on 1900 batch: 0.267424
: Epoch: 54 | Training Loss: 0.249060 | Val. Loss: 0.318292 | Val. Kappa Score: 0.7262 | LR: 0.000004 | Estimated time: 371.96
Train loss on 50 batch: 0.266506
Train loss on 100 batch: 0.232610
Train loss on 150 batch: 0.226556
Train loss on 200 batch: 0.221813
Train loss on 250 batch: 0.273561
Train loss on 300 batch: 0.273604
Train loss on 350 batch: 0.260630
Train loss on 400 batch: 0.253680
Train loss on 450 batch: 0.254803
Train loss on 500 batch: 0.229936
Train loss on 550 batch: 0.250237
Train loss on 600 batch: 0.252752
Train loss on 650 batch: 0.307208
Train loss on 700 batch: 0.245758
Train loss on 750 batch: 0.250079
Train loss on 800 batch: 0.244447
Train loss on 850 batch: 0.280920
Train loss on 900 batch: 0.243792
Train loss on 950 batch: 0.233741
Train loss on 1000 batch: 0.234171
Train loss on 1050 batch: 0.262322
Train loss on 1100 batch: 0.206178
Train loss on 1150 batch: 0.240063
Train loss on 1200 batch: 0.245676
Train loss on 1250 batch: 0.258705
Train loss on 1300 batch: 0.293449
Train loss on 1350 batch: 0.284319
Train loss on 1400 batch: 0.217004
Train loss on 1450 batch: 0.254684
Train loss on 1500 batch: 0.234469
Train loss on 1550 batch: 0.234926
Train loss on 1600 batch: 0.256197
Train loss on 1650 batch: 0.225338
Train loss on 1700 batch: 0.268965
Train loss on 1750 batch: 0.222414
Train loss on 1800 batch: 0.252152
Train loss on 1850 batch: 0.247693
Train loss on 1900 batch: 0.263525
: Epoch: 55 | Training Loss: 0.250346 | Val. Loss: 0.317109 | Val. Kappa Score: 0.7266 | LR: 0.000004 | Estimated time: 371.38
Train loss on 50 batch: 0.247912
Train loss on 100 batch: 0.245220
Train loss on 150 batch: 0.266169
Train loss on 200 batch: 0.257646
Train loss on 250 batch: 0.246241
Train loss on 300 batch: 0.272541
Train loss on 350 batch: 0.253944
Train loss on 400 batch: 0.208825
Train loss on 450 batch: 0.225335
Train loss on 500 batch: 0.315453
Train loss on 550 batch: 0.237289
Train loss on 600 batch: 0.226091
Train loss on 650 batch: 0.207054
Train loss on 700 batch: 0.312758
Train loss on 750 batch: 0.225447
Train loss on 800 batch: 0.270277
Train loss on 850 batch: 0.243412
Train loss on 900 batch: 0.273188
Train loss on 950 batch: 0.200003
Train loss on 1000 batch: 0.222429
Train loss on 1050 batch: 0.250962
Train loss on 1100 batch: 0.264084
Train loss on 1150 batch: 0.239982
Train loss on 1200 batch: 0.305107
Train loss on 1250 batch: 0.245513
Train loss on 1300 batch: 0.267184
Train loss on 1350 batch: 0.279665
Train loss on 1400 batch: 0.263196
Train loss on 1450 batch: 0.236228
Train loss on 1500 batch: 0.243131
Train loss on 1550 batch: 0.222155
Train loss on 1600 batch: 0.252405
Train loss on 1650 batch: 0.245772
Train loss on 1700 batch: 0.279376
Train loss on 1750 batch: 0.243146
Train loss on 1800 batch: 0.244812
Train loss on 1850 batch: 0.244050
Train loss on 1900 batch: 0.218535
: Epoch: 56 | Training Loss: 0.249715 | Val. Loss: 0.316207 | Val. Kappa Score: 0.7271 | LR: 0.000004 | Estimated time: 371.09
Train loss on 50 batch: 0.265301
Train loss on 100 batch: 0.225408
Train loss on 150 batch: 0.231496
Train loss on 200 batch: 0.213577
Train loss on 250 batch: 0.231229
Train loss on 300 batch: 0.302786
Train loss on 350 batch: 0.231709
Train loss on 400 batch: 0.229792
Train loss on 450 batch: 0.198858
Train loss on 500 batch: 0.284957
Train loss on 550 batch: 0.238299
Train loss on 600 batch: 0.225442
Train loss on 650 batch: 0.297594
Train loss on 700 batch: 0.225611
Train loss on 750 batch: 0.284828
Train loss on 800 batch: 0.199642
Train loss on 850 batch: 0.291611
Train loss on 900 batch: 0.282771
Train loss on 950 batch: 0.223627
Train loss on 1000 batch: 0.270142
Train loss on 1050 batch: 0.282277
Train loss on 1100 batch: 0.262917
Train loss on 1150 batch: 0.208760
Train loss on 1200 batch: 0.250697
Train loss on 1250 batch: 0.272977
Train loss on 1300 batch: 0.281161
Train loss on 1350 batch: 0.257987
Train loss on 1400 batch: 0.267799
Train loss on 1450 batch: 0.188850
Train loss on 1500 batch: 0.263859
Train loss on 1550 batch: 0.243838
Train loss on 1600 batch: 0.244221
Train loss on 1650 batch: 0.286995
Train loss on 1700 batch: 0.211372
Train loss on 1750 batch: 0.238793
Train loss on 1800 batch: 0.236392
Train loss on 1850 batch: 0.236217
Train loss on 1900 batch: 0.256539
: Epoch: 57 | Training Loss: 0.247289 | Val. Loss: 0.316462 | Val. Kappa Score: 0.7275 | LR: 0.000002 | Estimated time: 371.67
Train loss on 50 batch: 0.252269
Train loss on 100 batch: 0.271894
Train loss on 150 batch: 0.248621
Train loss on 200 batch: 0.243961
Train loss on 250 batch: 0.230510
Train loss on 300 batch: 0.266060
Train loss on 350 batch: 0.222810
Train loss on 400 batch: 0.250167
Train loss on 450 batch: 0.272988
Train loss on 500 batch: 0.277274
Train loss on 550 batch: 0.237316
Train loss on 600 batch: 0.266148
Train loss on 650 batch: 0.284648
Train loss on 700 batch: 0.238943
Train loss on 750 batch: 0.191854
Train loss on 800 batch: 0.260602
Train loss on 850 batch: 0.273432
Train loss on 900 batch: 0.246954
Train loss on 950 batch: 0.285795
Train loss on 1000 batch: 0.235181
Train loss on 1050 batch: 0.241778
Train loss on 1100 batch: 0.278280
Train loss on 1150 batch: 0.280322
Train loss on 1200 batch: 0.254676
Train loss on 1250 batch: 0.244053
Train loss on 1300 batch: 0.228619
Train loss on 1350 batch: 0.198908
Train loss on 1400 batch: 0.228236
Train loss on 1450 batch: 0.228099
Train loss on 1500 batch: 0.266852
Train loss on 1550 batch: 0.221586
Train loss on 1600 batch: 0.262233
Train loss on 1650 batch: 0.261355
Train loss on 1700 batch: 0.259966
Train loss on 1750 batch: 0.262762
Train loss on 1800 batch: 0.214052
Train loss on 1850 batch: 0.272223
Train loss on 1900 batch: 0.245993
: Epoch: 58 | Training Loss: 0.250757 | Val. Loss: 0.316845 | Val. Kappa Score: 0.7278 | LR: 0.000002 | Estimated time: 370.97
time_estimated: 21598.48
n-epochs: 58
time_estimated: 21598.51
----------------------------------------

Experiment N: 129: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 16:28:43
data-type: new_old_mixed
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6d8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.068041
Train loss on 100 batch: 0.896444
Train loss on 150 batch: 0.837390
Train loss on 200 batch: 0.762959
Train loss on 250 batch: 0.827271
----------------------------------------

Experiment N: 129: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 16:30:13
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e630>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.109427
Train loss on 100 batch: 0.637837
Train loss on 150 batch: 0.571907
best-train-loss: 0.711697
best-valid-loss: 1.025648
best-kappa: 0.7814
: Epoch: 1 | Training Loss: 0.711697 | Val. Loss: 1.025648 | Val. Kappa Score: 0.7814 | LR: 0.001000 | Estimated time: 55.80
Train loss on 50 batch: 0.475355
Train loss on 100 batch: 0.534754
Train loss on 150 batch: 0.400768
best-train-loss: 0.489006
best-valid-loss: 0.387888
best-kappa: 0.8189
: Epoch: 2 | Training Loss: 0.489006 | Val. Loss: 0.387888 | Val. Kappa Score: 0.8189 | LR: 0.001000 | Estimated time: 54.38
Train loss on 50 batch: 0.439476
Train loss on 100 batch: 0.434376
Train loss on 150 batch: 0.395283
: Epoch: 3 | Training Loss: 0.425974 | Val. Loss: 0.416098 | Val. Kappa Score: 0.8325 | LR: 0.001000 | Estimated time: 54.83
Train loss on 50 batch: 0.455264
Train loss on 100 batch: 0.409563
Train loss on 150 batch: 0.405613
: Epoch: 4 | Training Loss: 0.479799 | Val. Loss: 0.426013 | Val. Kappa Score: 0.8360 | LR: 0.001000 | Estimated time: 54.86
Train loss on 50 batch: 0.499810
Train loss on 100 batch: 0.482787
Train loss on 150 batch: 0.346250
best-train-loss: 0.427472
best-valid-loss: 0.318568
best-kappa: 0.8418
: Epoch: 5 | Training Loss: 0.427472 | Val. Loss: 0.318568 | Val. Kappa Score: 0.8418 | LR: 0.001000 | Estimated time: 54.81
Train loss on 50 batch: 0.383008
Train loss on 100 batch: 0.369626
Train loss on 150 batch: 0.340190
: Epoch: 6 | Training Loss: 0.352672 | Val. Loss: 0.577359 | Val. Kappa Score: 0.8300 | LR: 0.001000 | Estimated time: 55.01
Train loss on 50 batch: 0.393008
Train loss on 100 batch: 0.389966
Train loss on 150 batch: 0.347413
: Epoch: 7 | Training Loss: 0.366570 | Val. Loss: 0.341170 | Val. Kappa Score: 0.8352 | LR: 0.001000 | Estimated time: 55.04
Train loss on 50 batch: 0.295585
Train loss on 100 batch: 0.344775
Train loss on 150 batch: 0.264755
: Epoch: 8 | Training Loss: 0.325711 | Val. Loss: 0.430884 | Val. Kappa Score: 0.8357 | LR: 0.000500 | Estimated time: 54.98
Train loss on 50 batch: 0.291830
Train loss on 100 batch: 0.326540
Train loss on 150 batch: 0.260609
best-train-loss: 0.278689
best-valid-loss: 0.306591
best-kappa: 0.8414
: Epoch: 9 | Training Loss: 0.278689 | Val. Loss: 0.306591 | Val. Kappa Score: 0.8414 | LR: 0.000500 | Estimated time: 55.12
Train loss on 50 batch: 0.232228
Train loss on 100 batch: 0.242454
Train loss on 150 batch: 0.264949
best-train-loss: 0.301505
best-valid-loss: 0.306359
best-kappa: 0.8453
: Epoch: 10 | Training Loss: 0.301505 | Val. Loss: 0.306359 | Val. Kappa Score: 0.8453 | LR: 0.000500 | Estimated time: 55.31
Train loss on 50 batch: 0.218005
Train loss on 100 batch: 0.226804
Train loss on 150 batch: 0.235982
: Epoch: 11 | Training Loss: 0.247460 | Val. Loss: 0.308544 | Val. Kappa Score: 0.8491 | LR: 0.000500 | Estimated time: 54.59
Train loss on 50 batch: 0.213966
Train loss on 100 batch: 0.211748
Train loss on 150 batch: 0.235717
: Epoch: 12 | Training Loss: 0.232499 | Val. Loss: 0.339092 | Val. Kappa Score: 0.8513 | LR: 0.000500 | Estimated time: 54.87
Train loss on 50 batch: 0.194052
Train loss on 100 batch: 0.251477
Train loss on 150 batch: 0.213095
best-train-loss: 0.228086
best-valid-loss: 0.304085
best-kappa: 0.8545
: Epoch: 13 | Training Loss: 0.228086 | Val. Loss: 0.304085 | Val. Kappa Score: 0.8545 | LR: 0.000500 | Estimated time: 55.21
Train loss on 50 batch: 0.193017
Train loss on 100 batch: 0.207042
Train loss on 150 batch: 0.264359
: Epoch: 14 | Training Loss: 0.238596 | Val. Loss: 0.328972 | Val. Kappa Score: 0.8562 | LR: 0.000500 | Estimated time: 54.52
Train loss on 50 batch: 0.258992
Train loss on 100 batch: 0.225486
Train loss on 150 batch: 0.215560
: Epoch: 15 | Training Loss: 0.236458 | Val. Loss: 0.353123 | Val. Kappa Score: 0.8569 | LR: 0.000500 | Estimated time: 55.29
Train loss on 50 batch: 0.204385
Train loss on 100 batch: 0.195898
Train loss on 150 batch: 0.224900
best-train-loss: 0.206595
best-valid-loss: 0.291451
best-kappa: 0.8579
: Epoch: 16 | Training Loss: 0.206595 | Val. Loss: 0.291451 | Val. Kappa Score: 0.8579 | LR: 0.000500 | Estimated time: 54.30
Train loss on 50 batch: 0.227868
Train loss on 100 batch: 0.209997
Train loss on 150 batch: 0.195332
: Epoch: 17 | Training Loss: 0.201942 | Val. Loss: 0.308596 | Val. Kappa Score: 0.8594 | LR: 0.000500 | Estimated time: 54.70
Train loss on 50 batch: 0.201639
Train loss on 100 batch: 0.190325
Train loss on 150 batch: 0.201669
: Epoch: 18 | Training Loss: 0.209497 | Val. Loss: 0.318506 | Val. Kappa Score: 0.8607 | LR: 0.000500 | Estimated time: 54.14
Train loss on 50 batch: 0.162186
Train loss on 100 batch: 0.206974
Train loss on 150 batch: 0.216858
: Epoch: 19 | Training Loss: 0.198732 | Val. Loss: 0.317405 | Val. Kappa Score: 0.8620 | LR: 0.000250 | Estimated time: 54.94
Train loss on 50 batch: 0.144008
Train loss on 100 batch: 0.172531
Train loss on 150 batch: 0.139965
: Epoch: 20 | Training Loss: 0.150669 | Val. Loss: 0.312569 | Val. Kappa Score: 0.8635 | LR: 0.000250 | Estimated time: 54.79
Train loss on 50 batch: 0.146667
Train loss on 100 batch: 0.124646
Train loss on 150 batch: 0.156032
: Epoch: 21 | Training Loss: 0.171821 | Val. Loss: 0.303161 | Val. Kappa Score: 0.8643 | LR: 0.000250 | Estimated time: 53.96
Train loss on 50 batch: 0.130719
Train loss on 100 batch: 0.137845
Train loss on 150 batch: 0.151459
: Epoch: 22 | Training Loss: 0.140543 | Val. Loss: 0.326017 | Val. Kappa Score: 0.8655 | LR: 0.000125 | Estimated time: 54.50
Train loss on 50 batch: 0.128677
Train loss on 100 batch: 0.115273
Train loss on 150 batch: 0.107467
: Epoch: 23 | Training Loss: 0.118218 | Val. Loss: 0.313694 | Val. Kappa Score: 0.8663 | LR: 0.000125 | Estimated time: 54.52
Train loss on 50 batch: 0.108163
Train loss on 100 batch: 0.106991
Train loss on 150 batch: 0.106627
: Epoch: 24 | Training Loss: 0.171412 | Val. Loss: 0.323036 | Val. Kappa Score: 0.8668 | LR: 0.000125 | Estimated time: 55.33
Train loss on 50 batch: 0.120171
Train loss on 100 batch: 0.105422
Train loss on 150 batch: 0.114084
: Epoch: 25 | Training Loss: 0.122087 | Val. Loss: 0.324791 | Val. Kappa Score: 0.8677 | LR: 0.000063 | Estimated time: 54.32
Train loss on 50 batch: 0.109219
Train loss on 100 batch: 0.088833
Train loss on 150 batch: 0.115731
: Epoch: 26 | Training Loss: 0.106255 | Val. Loss: 0.316839 | Val. Kappa Score: 0.8684 | LR: 0.000063 | Estimated time: 54.83
time_estimated: 1426.39
n-epochs: 26
time_estimated: 1426.43
----------------------------------------

Experiment N: 130: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 18:33:16
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10e668>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
----------------------------------------

Experiment N: 130: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 18:36:04
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d110668>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.092805
Train loss on 100 batch: 0.681459
Train loss on 150 batch: 0.704152
best-train-loss: 0.761507
best-valid-loss: 0.497932
best-kappa: 0.8149
: Epoch: 1 | Training Loss: 0.761507 | Val. Loss: 0.497932 | Val. Kappa Score: 0.8149 | LR: 0.001000 | Estimated time: 187.85
Train loss on 50 batch: 0.522908
Train loss on 100 batch: 0.593315
Train loss on 150 batch: 0.558638
: Epoch: 2 | Training Loss: 0.575162 | Val. Loss: 0.891281 | Val. Kappa Score: 0.7110 | LR: 0.001000 | Estimated time: 187.66
Train loss on 50 batch: 0.555882
Train loss on 100 batch: 0.565785
Train loss on 150 batch: 0.511465
: Epoch: 3 | Training Loss: 0.536177 | Val. Loss: 0.579483 | Val. Kappa Score: 0.7408 | LR: 0.001000 | Estimated time: 186.75
Train loss on 50 batch: 0.549514
Train loss on 100 batch: 0.530849
Train loss on 150 batch: 0.518819
best-train-loss: 0.563883
best-valid-loss: 0.353151
best-kappa: 0.7729
: Epoch: 4 | Training Loss: 0.563883 | Val. Loss: 0.353151 | Val. Kappa Score: 0.7729 | LR: 0.001000 | Estimated time: 189.13
Train loss on 50 batch: 0.592595
Train loss on 100 batch: 0.629716
Train loss on 150 batch: 0.441520
: Epoch: 5 | Training Loss: 0.549701 | Val. Loss: 0.877246 | Val. Kappa Score: 0.7405 | LR: 0.001000 | Estimated time: 191.99
----------------------------------------

Experiment N: 131: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.23 18:52:31
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d110588>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.092805
Train loss on 100 batch: 0.681459
Train loss on 150 batch: 0.704152
best-train-loss: 0.761507
best-valid-loss: 0.612277
best-kappa: 0.7901
: Epoch: 1 | Training Loss: 0.761507 | Val. Loss: 0.612277 | Val. Kappa Score: 0.7901 | LR: 0.001000 | Estimated time: 187.99
Train loss on 50 batch: 0.522908
Train loss on 100 batch: 0.593315
Train loss on 150 batch: 0.558638
: Epoch: 2 | Training Loss: 0.575162 | Val. Loss: 0.668039 | Val. Kappa Score: 0.7696 | LR: 0.001000 | Estimated time: 187.88
Train loss on 50 batch: 0.555882
Train loss on 100 batch: 0.565785
Train loss on 150 batch: 0.511465
best-train-loss: 0.536177
best-valid-loss: 0.440210
best-kappa: 0.7945
: Epoch: 3 | Training Loss: 0.536177 | Val. Loss: 0.440210 | Val. Kappa Score: 0.7945 | LR: 0.001000 | Estimated time: 188.05
Train loss on 50 batch: 0.549514
Train loss on 100 batch: 0.530849
Train loss on 150 batch: 0.518819
: Epoch: 4 | Training Loss: 0.563883 | Val. Loss: 0.760943 | Val. Kappa Score: 0.7939 | LR: 0.001000 | Estimated time: 186.73
Train loss on 50 batch: 0.592595
Train loss on 100 batch: 0.629716
Train loss on 150 batch: 0.441520
: Epoch: 5 | Training Loss: 0.549701 | Val. Loss: 0.491968 | Val. Kappa Score: 0.7977 | LR: 0.001000 | Estimated time: 189.09
Train loss on 50 batch: 0.524748
Train loss on 100 batch: 0.511130
Train loss on 150 batch: 0.496077
: Epoch: 6 | Training Loss: 0.495997 | Val. Loss: 0.663897 | Val. Kappa Score: 0.7944 | LR: 0.000500 | Estimated time: 186.57
Train loss on 50 batch: 0.458225
Train loss on 100 batch: 0.369230
Train loss on 150 batch: 0.387029
best-train-loss: 0.407213
best-valid-loss: 0.391477
best-kappa: 0.8026
: Epoch: 7 | Training Loss: 0.407213 | Val. Loss: 0.391477 | Val. Kappa Score: 0.8026 | LR: 0.000500 | Estimated time: 187.52
Train loss on 50 batch: 0.330486
Train loss on 100 batch: 0.380770
Train loss on 150 batch: 0.331067
: Epoch: 8 | Training Loss: 0.355059 | Val. Loss: 0.466702 | Val. Kappa Score: 0.8103 | LR: 0.000500 | Estimated time: 187.17
Train loss on 50 batch: 0.369371
Train loss on 100 batch: 0.377913
Train loss on 150 batch: 0.395513
best-train-loss: 0.372913
best-valid-loss: 0.389898
best-kappa: 0.8162
: Epoch: 9 | Training Loss: 0.372913 | Val. Loss: 0.389898 | Val. Kappa Score: 0.8162 | LR: 0.000500 | Estimated time: 188.03
Train loss on 50 batch: 0.316637
Train loss on 100 batch: 0.382377
Train loss on 150 batch: 0.390106
: Epoch: 10 | Training Loss: 0.410748 | Val. Loss: 0.571392 | Val. Kappa Score: 0.8193 | LR: 0.000500 | Estimated time: 187.81
Train loss on 50 batch: 0.339266
Train loss on 100 batch: 0.435511
Train loss on 150 batch: 0.384124
: Epoch: 11 | Training Loss: 0.400763 | Val. Loss: 0.396056 | Val. Kappa Score: 0.8224 | LR: 0.000500 | Estimated time: 187.62
Train loss on 50 batch: 0.345064
Train loss on 100 batch: 0.362062
Train loss on 150 batch: 0.361235
: Epoch: 12 | Training Loss: 0.366000 | Val. Loss: 0.390131 | Val. Kappa Score: 0.8264 | LR: 0.000250 | Estimated time: 186.92
Train loss on 50 batch: 0.309718
Train loss on 100 batch: 0.328955
Train loss on 150 batch: 0.286131
best-train-loss: 0.311762
best-valid-loss: 0.354983
best-kappa: 0.8300
: Epoch: 13 | Training Loss: 0.311762 | Val. Loss: 0.354983 | Val. Kappa Score: 0.8300 | LR: 0.000250 | Estimated time: 187.84
Train loss on 50 batch: 0.304726
Train loss on 100 batch: 0.288189
Train loss on 150 batch: 0.320063
best-train-loss: 0.305985
best-valid-loss: 0.310820
best-kappa: 0.8333
: Epoch: 14 | Training Loss: 0.305985 | Val. Loss: 0.310820 | Val. Kappa Score: 0.8333 | LR: 0.000250 | Estimated time: 186.95
Train loss on 50 batch: 0.315128
Train loss on 100 batch: 0.302439
Train loss on 150 batch: 0.267708
: Epoch: 15 | Training Loss: 0.291119 | Val. Loss: 0.318724 | Val. Kappa Score: 0.8369 | LR: 0.000250 | Estimated time: 187.29
Train loss on 50 batch: 0.300015
Train loss on 100 batch: 0.289268
Train loss on 150 batch: 0.254545
: Epoch: 16 | Training Loss: 0.294354 | Val. Loss: 0.320127 | Val. Kappa Score: 0.8396 | LR: 0.000250 | Estimated time: 187.84
Train loss on 50 batch: 0.318506
Train loss on 100 batch: 0.291081
Train loss on 150 batch: 0.266320
: Epoch: 17 | Training Loss: 0.294029 | Val. Loss: 0.349547 | Val. Kappa Score: 0.8417 | LR: 0.000125 | Estimated time: 187.51
Train loss on 50 batch: 0.296583
Train loss on 100 batch: 0.245554
Train loss on 150 batch: 0.273074
: Epoch: 18 | Training Loss: 0.269706 | Val. Loss: 0.336624 | Val. Kappa Score: 0.8433 | LR: 0.000125 | Estimated time: 187.22
Train loss on 50 batch: 0.227999
Train loss on 100 batch: 0.272114
Train loss on 150 batch: 0.279184
: Epoch: 19 | Training Loss: 0.273975 | Val. Loss: 0.369682 | Val. Kappa Score: 0.8444 | LR: 0.000125 | Estimated time: 187.29
Train loss on 50 batch: 0.289670
Train loss on 100 batch: 0.282974
Train loss on 150 batch: 0.216295
best-train-loss: 0.268614
best-valid-loss: 0.293101
best-kappa: 0.8467
: Epoch: 20 | Training Loss: 0.268614 | Val. Loss: 0.293101 | Val. Kappa Score: 0.8467 | LR: 0.000125 | Estimated time: 187.98
Train loss on 50 batch: 0.224809
Train loss on 100 batch: 0.252852
Train loss on 150 batch: 0.281135
: Epoch: 21 | Training Loss: 0.291476 | Val. Loss: 0.369056 | Val. Kappa Score: 0.8476 | LR: 0.000125 | Estimated time: 186.83
Train loss on 50 batch: 0.265216
Train loss on 100 batch: 0.254413
Train loss on 150 batch: 0.294489
: Epoch: 22 | Training Loss: 0.270465 | Val. Loss: 0.354400 | Val. Kappa Score: 0.8487 | LR: 0.000125 | Estimated time: 187.63
Train loss on 50 batch: 0.275741
Train loss on 100 batch: 0.233772
Train loss on 150 batch: 0.242197
: Epoch: 23 | Training Loss: 0.249431 | Val. Loss: 0.389310 | Val. Kappa Score: 0.8491 | LR: 0.000063 | Estimated time: 186.77
Train loss on 50 batch: 0.229897
Train loss on 100 batch: 0.238131
Train loss on 150 batch: 0.226828
: Epoch: 24 | Training Loss: 0.291124 | Val. Loss: 0.343156 | Val. Kappa Score: 0.8501 | LR: 0.000063 | Estimated time: 187.53
Train loss on 50 batch: 0.208690
Train loss on 100 batch: 0.243424
Train loss on 150 batch: 0.316141
: Epoch: 25 | Training Loss: 0.269989 | Val. Loss: 0.362122 | Val. Kappa Score: 0.8508 | LR: 0.000063 | Estimated time: 187.37
Train loss on 50 batch: 0.234207
Train loss on 100 batch: 0.227867
Train loss on 150 batch: 0.214326
: Epoch: 26 | Training Loss: 0.244552 | Val. Loss: 0.352855 | Val. Kappa Score: 0.8507 | LR: 0.000031 | Estimated time: 187.25
Train loss on 50 batch: 0.268365
Train loss on 100 batch: 0.268366
Train loss on 150 batch: 0.221738
: Epoch: 27 | Training Loss: 0.244095 | Val. Loss: 0.297116 | Val. Kappa Score: 0.8522 | LR: 0.000031 | Estimated time: 187.82
Train loss on 50 batch: 0.229370
Train loss on 100 batch: 0.225598
Train loss on 150 batch: 0.203838
: Epoch: 28 | Training Loss: 0.217137 | Val. Loss: 0.328070 | Val. Kappa Score: 0.8529 | LR: 0.000031 | Estimated time: 189.23
Train loss on 50 batch: 0.186628
Train loss on 100 batch: 0.274485
Train loss on 150 batch: 0.226754
: Epoch: 29 | Training Loss: 0.229746 | Val. Loss: 0.326641 | Val. Kappa Score: 0.8537 | LR: 0.000016 | Estimated time: 186.64
Train loss on 50 batch: 0.206078
Train loss on 100 batch: 0.237200
Train loss on 150 batch: 0.226533
: Epoch: 30 | Training Loss: 0.229106 | Val. Loss: 0.325270 | Val. Kappa Score: 0.8548 | LR: 0.000016 | Estimated time: 187.10
time_estimated: 5627.11
n-epochs: 30
time_estimated: 5627.15
----------------------------------------

Experiment N: 132: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.23 20:43:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1dab38>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.147042
Train loss on 100 batch: 0.829839
Train loss on 150 batch: 0.707080
best-train-loss: 0.820729
best-valid-loss: 0.647210
best-kappa: 0.7750
: Epoch: 1 | Training Loss: 0.820729 | Val. Loss: 0.647210 | Val. Kappa Score: 0.7750 | LR: 0.001000 | Estimated time: 168.95
Train loss on 50 batch: 0.582992
Train loss on 100 batch: 0.543533
Train loss on 150 batch: 0.483865
best-train-loss: 0.573110
best-valid-loss: 0.643051
best-kappa: 0.7814
: Epoch: 2 | Training Loss: 0.573110 | Val. Loss: 0.643051 | Val. Kappa Score: 0.7814 | LR: 0.001000 | Estimated time: 169.10
Train loss on 50 batch: 0.555613
Train loss on 100 batch: 0.543193
Train loss on 150 batch: 0.542868
best-train-loss: 0.531231
best-valid-loss: 0.485861
best-kappa: 0.7964
: Epoch: 3 | Training Loss: 0.531231 | Val. Loss: 0.485861 | Val. Kappa Score: 0.7964 | LR: 0.001000 | Estimated time: 169.03
Train loss on 50 batch: 0.493826
Train loss on 100 batch: 0.558810
Train loss on 150 batch: 0.452736
: Epoch: 4 | Training Loss: 0.566922 | Val. Loss: 0.487221 | Val. Kappa Score: 0.8003 | LR: 0.001000 | Estimated time: 169.52
Train loss on 50 batch: 0.554472
Train loss on 100 batch: 0.545797
Train loss on 150 batch: 0.411805
: Epoch: 5 | Training Loss: 0.517627 | Val. Loss: 0.533312 | Val. Kappa Score: 0.8018 | LR: 0.001000 | Estimated time: 170.61
Train loss on 50 batch: 0.502858
Train loss on 100 batch: 0.518764
Train loss on 150 batch: 0.452195
best-train-loss: 0.471544
best-valid-loss: 0.416232
best-kappa: 0.8068
: Epoch: 6 | Training Loss: 0.471544 | Val. Loss: 0.416232 | Val. Kappa Score: 0.8068 | LR: 0.001000 | Estimated time: 169.29
Train loss on 50 batch: 0.461979
Train loss on 100 batch: 0.425473
Train loss on 150 batch: 0.414056
: Epoch: 7 | Training Loss: 0.455019 | Val. Loss: 0.470250 | Val. Kappa Score: 0.8099 | LR: 0.001000 | Estimated time: 169.32
Train loss on 50 batch: 0.410594
Train loss on 100 batch: 0.474858
Train loss on 150 batch: 0.346532
best-train-loss: 0.414940
best-valid-loss: 0.373555
best-kappa: 0.8162
: Epoch: 8 | Training Loss: 0.414940 | Val. Loss: 0.373555 | Val. Kappa Score: 0.8162 | LR: 0.001000 | Estimated time: 169.14
Train loss on 50 batch: 0.397972
Train loss on 100 batch: 0.427409
Train loss on 150 batch: 0.477447
: Epoch: 9 | Training Loss: 0.432752 | Val. Loss: 0.703912 | Val. Kappa Score: 0.8087 | LR: 0.001000 | Estimated time: 170.56
Train loss on 50 batch: 0.455231
Train loss on 100 batch: 0.516952
Train loss on 150 batch: 0.415791
: Epoch: 10 | Training Loss: 0.502104 | Val. Loss: 0.466606 | Val. Kappa Score: 0.8114 | LR: 0.001000 | Estimated time: 169.41
Train loss on 50 batch: 0.459785
Train loss on 100 batch: 0.439307
Train loss on 150 batch: 0.391001
: Epoch: 11 | Training Loss: 0.428040 | Val. Loss: 0.613143 | Val. Kappa Score: 0.8126 | LR: 0.000500 | Estimated time: 169.03
Train loss on 50 batch: 0.410817
Train loss on 100 batch: 0.345608
Train loss on 150 batch: 0.369410
best-train-loss: 0.397006
best-valid-loss: 0.371263
best-kappa: 0.8157
: Epoch: 12 | Training Loss: 0.397006 | Val. Loss: 0.371263 | Val. Kappa Score: 0.8157 | LR: 0.000500 | Estimated time: 169.29
Train loss on 50 batch: 0.328326
Train loss on 100 batch: 0.352996
Train loss on 150 batch: 0.388377
: Epoch: 13 | Training Loss: 0.352553 | Val. Loss: 0.412012 | Val. Kappa Score: 0.8189 | LR: 0.000500 | Estimated time: 170.23
Train loss on 50 batch: 0.339519
Train loss on 100 batch: 0.309785
Train loss on 150 batch: 0.381950
: Epoch: 14 | Training Loss: 0.361624 | Val. Loss: 0.391040 | Val. Kappa Score: 0.8215 | LR: 0.000500 | Estimated time: 169.61
Train loss on 50 batch: 0.324905
Train loss on 100 batch: 0.350051
Train loss on 150 batch: 0.334513
best-train-loss: 0.363908
best-valid-loss: 0.368296
best-kappa: 0.8228
: Epoch: 15 | Training Loss: 0.363908 | Val. Loss: 0.368296 | Val. Kappa Score: 0.8228 | LR: 0.000500 | Estimated time: 169.15
Train loss on 50 batch: 0.321704
Train loss on 100 batch: 0.335298
Train loss on 150 batch: 0.344179
: Epoch: 16 | Training Loss: 0.334827 | Val. Loss: 0.392771 | Val. Kappa Score: 0.8246 | LR: 0.000500 | Estimated time: 169.25
Train loss on 50 batch: 0.387121
Train loss on 100 batch: 0.321720
Train loss on 150 batch: 0.319078
: Epoch: 17 | Training Loss: 0.360441 | Val. Loss: 0.410308 | Val. Kappa Score: 0.8265 | LR: 0.000500 | Estimated time: 169.52
Train loss on 50 batch: 0.351083
Train loss on 100 batch: 0.287032
Train loss on 150 batch: 0.330291
best-train-loss: 0.322426
best-valid-loss: 0.342283
best-kappa: 0.8289
: Epoch: 18 | Training Loss: 0.322426 | Val. Loss: 0.342283 | Val. Kappa Score: 0.8289 | LR: 0.000500 | Estimated time: 169.06
Train loss on 50 batch: 0.283785
Train loss on 100 batch: 0.332560
Train loss on 150 batch: 0.332685
: Epoch: 19 | Training Loss: 0.333372 | Val. Loss: 0.360657 | Val. Kappa Score: 0.8304 | LR: 0.000500 | Estimated time: 170.00
Train loss on 50 batch: 0.320136
Train loss on 100 batch: 0.350327
Train loss on 150 batch: 0.331389
: Epoch: 20 | Training Loss: 0.329260 | Val. Loss: 0.489505 | Val. Kappa Score: 0.8313 | LR: 0.000500 | Estimated time: 169.19
Train loss on 50 batch: 0.300378
Train loss on 100 batch: 0.299466
Train loss on 150 batch: 0.338987
: Epoch: 21 | Training Loss: 0.362170 | Val. Loss: 0.386998 | Val. Kappa Score: 0.8323 | LR: 0.000250 | Estimated time: 169.48
Train loss on 50 batch: 0.275806
Train loss on 100 batch: 0.299975
Train loss on 150 batch: 0.315864
best-train-loss: 0.288196
best-valid-loss: 0.340733
best-kappa: 0.8345
: Epoch: 22 | Training Loss: 0.288196 | Val. Loss: 0.340733 | Val. Kappa Score: 0.8345 | LR: 0.000250 | Estimated time: 170.56
Train loss on 50 batch: 0.272225
Train loss on 100 batch: 0.269099
Train loss on 150 batch: 0.276609
: Epoch: 23 | Training Loss: 0.282313 | Val. Loss: 0.394755 | Val. Kappa Score: 0.8357 | LR: 0.000250 | Estimated time: 169.20
Train loss on 50 batch: 0.314195
Train loss on 100 batch: 0.280328
Train loss on 150 batch: 0.286856
: Epoch: 24 | Training Loss: 0.358495 | Val. Loss: 0.390613 | Val. Kappa Score: 0.8365 | LR: 0.000250 | Estimated time: 169.25
Train loss on 50 batch: 0.308692
Train loss on 100 batch: 0.280456
Train loss on 150 batch: 0.315909
: Epoch: 25 | Training Loss: 0.304216 | Val. Loss: 0.343330 | Val. Kappa Score: 0.8380 | LR: 0.000125 | Estimated time: 170.01
Train loss on 50 batch: 0.295039
Train loss on 100 batch: 0.243944
Train loss on 150 batch: 0.265881
best-train-loss: 0.289049
best-valid-loss: 0.333426
best-kappa: 0.8393
: Epoch: 26 | Training Loss: 0.289049 | Val. Loss: 0.333426 | Val. Kappa Score: 0.8393 | LR: 0.000125 | Estimated time: 169.20
Train loss on 50 batch: 0.267188
Train loss on 100 batch: 0.258832
Train loss on 150 batch: 0.272889
: Epoch: 27 | Training Loss: 0.257782 | Val. Loss: 0.377102 | Val. Kappa Score: 0.8400 | LR: 0.000125 | Estimated time: 169.55
Train loss on 50 batch: 0.278920
Train loss on 100 batch: 0.237889
Train loss on 150 batch: 0.260566
: Epoch: 28 | Training Loss: 0.260035 | Val. Loss: 0.353648 | Val. Kappa Score: 0.8407 | LR: 0.000125 | Estimated time: 169.57
Train loss on 50 batch: 0.203990
Train loss on 100 batch: 0.253003
Train loss on 150 batch: 0.249882
best-train-loss: 0.244594
best-valid-loss: 0.313217
best-kappa: 0.8417
: Epoch: 29 | Training Loss: 0.244594 | Val. Loss: 0.313217 | Val. Kappa Score: 0.8417 | LR: 0.000125 | Estimated time: 168.57
Train loss on 50 batch: 0.238979
Train loss on 100 batch: 0.270969
Train loss on 150 batch: 0.252258
best-train-loss: 0.254927
best-valid-loss: 0.302655
best-kappa: 0.8432
: Epoch: 30 | Training Loss: 0.254927 | Val. Loss: 0.302655 | Val. Kappa Score: 0.8432 | LR: 0.000125 | Estimated time: 169.12
Train loss on 50 batch: 0.239282
Train loss on 100 batch: 0.247646
Train loss on 150 batch: 0.233399
: Epoch: 31 | Training Loss: 0.276740 | Val. Loss: 0.355311 | Val. Kappa Score: 0.8437 | LR: 0.000125 | Estimated time: 168.96
Train loss on 50 batch: 0.264739
Train loss on 100 batch: 0.274563
Train loss on 150 batch: 0.233844
: Epoch: 32 | Training Loss: 0.272001 | Val. Loss: 0.359672 | Val. Kappa Score: 0.8441 | LR: 0.000125 | Estimated time: 169.17
Train loss on 50 batch: 0.221365
Train loss on 100 batch: 0.256176
Train loss on 150 batch: 0.241269
: Epoch: 33 | Training Loss: 0.246741 | Val. Loss: 0.324324 | Val. Kappa Score: 0.8452 | LR: 0.000063 | Estimated time: 168.64
Train loss on 50 batch: 0.246288
Train loss on 100 batch: 0.235549
Train loss on 150 batch: 0.266745
: Epoch: 34 | Training Loss: 0.246971 | Val. Loss: 0.340097 | Val. Kappa Score: 0.8457 | LR: 0.000063 | Estimated time: 169.63
Train loss on 50 batch: 0.225628
Train loss on 100 batch: 0.233908
Train loss on 150 batch: 0.226751
: Epoch: 35 | Training Loss: 0.230697 | Val. Loss: 0.324942 | Val. Kappa Score: 0.8469 | LR: 0.000063 | Estimated time: 168.19
Train loss on 50 batch: 0.174122
Train loss on 100 batch: 0.238025
Train loss on 150 batch: 0.203843
: Epoch: 36 | Training Loss: 0.218583 | Val. Loss: 0.324650 | Val. Kappa Score: 0.8477 | LR: 0.000031 | Estimated time: 169.26
Train loss on 50 batch: 0.224405
Train loss on 100 batch: 0.233123
Train loss on 150 batch: 0.206553
: Epoch: 37 | Training Loss: 0.230034 | Val. Loss: 0.315202 | Val. Kappa Score: 0.8483 | LR: 0.000031 | Estimated time: 169.01
Train loss on 50 batch: 0.214195
Train loss on 100 batch: 0.199543
Train loss on 150 batch: 0.221850
: Epoch: 38 | Training Loss: 0.264107 | Val. Loss: 0.356513 | Val. Kappa Score: 0.8489 | LR: 0.000031 | Estimated time: 168.92
Train loss on 50 batch: 0.227192
Train loss on 100 batch: 0.217864
Train loss on 150 batch: 0.214695
: Epoch: 39 | Training Loss: 0.227176 | Val. Loss: 0.370455 | Val. Kappa Score: 0.8489 | LR: 0.000016 | Estimated time: 169.01
Train loss on 50 batch: 0.217181
Train loss on 100 batch: 0.194502
Train loss on 150 batch: 0.208882
: Epoch: 40 | Training Loss: 0.202145 | Val. Loss: 0.347192 | Val. Kappa Score: 0.8491 | LR: 0.000016 | Estimated time: 170.12
time_estimated: 6776.49
n-epochs: 40
time_estimated: 6776.53
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:19:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109828>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:22:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1097b8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:22:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b710>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:25:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d710>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:26:32
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b940>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:27:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a7b8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:28:01
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a780>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:28:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c748>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 133: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.24 14:29:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9600b860>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.580325
Train loss on 100 batch: 0.527332
best-train-loss: 0.513032
best-valid-loss: 0.377008
best-kappa: 0.8633
: Epoch: 1 | Training Loss: 0.513032 | Val. Loss: 0.377008 | Val. Kappa Score: 0.8633 | LR: 0.001000 | Estimated time: 19.16
Train loss on 50 batch: 0.423735
Train loss on 100 batch: 0.419418
best-train-loss: 0.403279
best-valid-loss: 0.329490
best-kappa: 0.8674
: Epoch: 2 | Training Loss: 0.403279 | Val. Loss: 0.329490 | Val. Kappa Score: 0.8674 | LR: 0.001000 | Estimated time: 19.02
Train loss on 50 batch: 0.399657
Train loss on 100 batch: 0.404762
best-train-loss: 0.376110
best-valid-loss: 0.309303
best-kappa: 0.8664
: Epoch: 3 | Training Loss: 0.376110 | Val. Loss: 0.309303 | Val. Kappa Score: 0.8664 | LR: 0.001000 | Estimated time: 18.76
Train loss on 50 batch: 0.310330
Train loss on 100 batch: 0.384921
: Epoch: 4 | Training Loss: 0.343876 | Val. Loss: 0.311066 | Val. Kappa Score: 0.8682 | LR: 0.001000 | Estimated time: 18.90
Train loss on 50 batch: 0.311429
Train loss on 100 batch: 0.358847
best-train-loss: 0.342024
best-valid-loss: 0.299001
best-kappa: 0.8695
: Epoch: 5 | Training Loss: 0.342024 | Val. Loss: 0.299001 | Val. Kappa Score: 0.8695 | LR: 0.001000 | Estimated time: 18.94
Train loss on 50 batch: 0.297528
Train loss on 100 batch: 0.321731
: Epoch: 6 | Training Loss: 0.328306 | Val. Loss: 0.327398 | Val. Kappa Score: 0.8703 | LR: 0.001000 | Estimated time: 18.92
Train loss on 50 batch: 0.272408
Train loss on 100 batch: 0.342922
: Epoch: 7 | Training Loss: 0.309920 | Val. Loss: 0.350262 | Val. Kappa Score: 0.8714 | LR: 0.001000 | Estimated time: 18.97
Train loss on 50 batch: 0.366166
Train loss on 100 batch: 0.283880
best-train-loss: 0.322594
best-valid-loss: 0.296387
best-kappa: 0.8738
: Epoch: 8 | Training Loss: 0.322594 | Val. Loss: 0.296387 | Val. Kappa Score: 0.8738 | LR: 0.001000 | Estimated time: 19.17
Train loss on 50 batch: 0.258603
Train loss on 100 batch: 0.330208
: Epoch: 9 | Training Loss: 0.292506 | Val. Loss: 0.329403 | Val. Kappa Score: 0.8734 | LR: 0.001000 | Estimated time: 18.87
Train loss on 50 batch: 0.291815
Train loss on 100 batch: 0.333065
best-train-loss: 0.299047
best-valid-loss: 0.285149
best-kappa: 0.8745
: Epoch: 10 | Training Loss: 0.299047 | Val. Loss: 0.285149 | Val. Kappa Score: 0.8745 | LR: 0.001000 | Estimated time: 19.03
Train loss on 50 batch: 0.285690
Train loss on 100 batch: 0.265473
: Epoch: 11 | Training Loss: 0.279832 | Val. Loss: 0.358978 | Val. Kappa Score: 0.8745 | LR: 0.001000 | Estimated time: 18.75
Train loss on 50 batch: 0.291805
Train loss on 100 batch: 0.260998
: Epoch: 12 | Training Loss: 0.281477 | Val. Loss: 0.332148 | Val. Kappa Score: 0.8740 | LR: 0.001000 | Estimated time: 18.84
Train loss on 50 batch: 0.237908
Train loss on 100 batch: 0.272437
best-train-loss: 0.268183
best-valid-loss: 0.267802
best-kappa: 0.8754
: Epoch: 13 | Training Loss: 0.268183 | Val. Loss: 0.267802 | Val. Kappa Score: 0.8754 | LR: 0.001000 | Estimated time: 18.84
Train loss on 50 batch: 0.265808
Train loss on 100 batch: 0.289013
best-train-loss: 0.266638
best-valid-loss: 0.267634
best-kappa: 0.8772
: Epoch: 14 | Training Loss: 0.266638 | Val. Loss: 0.267634 | Val. Kappa Score: 0.8772 | LR: 0.001000 | Estimated time: 18.87
Train loss on 50 batch: 0.276281
Train loss on 100 batch: 0.275683
: Epoch: 15 | Training Loss: 0.265914 | Val. Loss: 0.284242 | Val. Kappa Score: 0.8784 | LR: 0.001000 | Estimated time: 18.89
Train loss on 50 batch: 0.299543
Train loss on 100 batch: 0.300824
: Epoch: 16 | Training Loss: 0.282081 | Val. Loss: 0.286783 | Val. Kappa Score: 0.8791 | LR: 0.001000 | Estimated time: 19.07
Train loss on 50 batch: 0.232302
Train loss on 100 batch: 0.263945
best-train-loss: 0.261665
best-valid-loss: 0.254659
best-kappa: 0.8803
: Epoch: 17 | Training Loss: 0.261665 | Val. Loss: 0.254659 | Val. Kappa Score: 0.8803 | LR: 0.001000 | Estimated time: 18.86
Train loss on 50 batch: 0.224345
Train loss on 100 batch: 0.258786
: Epoch: 18 | Training Loss: 0.268353 | Val. Loss: 0.296999 | Val. Kappa Score: 0.8800 | LR: 0.001000 | Estimated time: 19.25
Train loss on 50 batch: 0.308494
Train loss on 100 batch: 0.266767
: Epoch: 19 | Training Loss: 0.282573 | Val. Loss: 0.316010 | Val. Kappa Score: 0.8805 | LR: 0.001000 | Estimated time: 18.89
Train loss on 50 batch: 0.244109
Train loss on 100 batch: 0.255161
: Epoch: 20 | Training Loss: 0.255828 | Val. Loss: 0.323588 | Val. Kappa Score: 0.8800 | LR: 0.000500 | Estimated time: 19.08
Train loss on 50 batch: 0.244711
Train loss on 100 batch: 0.214495
: Epoch: 21 | Training Loss: 0.232695 | Val. Loss: 0.264891 | Val. Kappa Score: 0.8807 | LR: 0.000500 | Estimated time: 18.88
Train loss on 50 batch: 0.215809
Train loss on 100 batch: 0.255738
best-train-loss: 0.232230
best-valid-loss: 0.254105
best-kappa: 0.8812
: Epoch: 22 | Training Loss: 0.232230 | Val. Loss: 0.254105 | Val. Kappa Score: 0.8812 | LR: 0.000500 | Estimated time: 18.92
Train loss on 50 batch: 0.205274
Train loss on 100 batch: 0.232164
: Epoch: 23 | Training Loss: 0.227476 | Val. Loss: 0.257137 | Val. Kappa Score: 0.8819 | LR: 0.000500 | Estimated time: 18.71
Train loss on 50 batch: 0.236295
Train loss on 100 batch: 0.215561
: Epoch: 24 | Training Loss: 0.241199 | Val. Loss: 0.273337 | Val. Kappa Score: 0.8828 | LR: 0.000500 | Estimated time: 18.73
Train loss on 50 batch: 0.222928
Train loss on 100 batch: 0.240075
best-train-loss: 0.238749
best-valid-loss: 0.251090
best-kappa: 0.8835
: Epoch: 25 | Training Loss: 0.238749 | Val. Loss: 0.251090 | Val. Kappa Score: 0.8835 | LR: 0.000500 | Estimated time: 18.96
Train loss on 50 batch: 0.209688
Train loss on 100 batch: 0.221095
: Epoch: 26 | Training Loss: 0.226197 | Val. Loss: 0.252053 | Val. Kappa Score: 0.8845 | LR: 0.000500 | Estimated time: 18.91
Train loss on 50 batch: 0.238409
Train loss on 100 batch: 0.230481
: Epoch: 27 | Training Loss: 0.228729 | Val. Loss: 0.254821 | Val. Kappa Score: 0.8851 | LR: 0.000500 | Estimated time: 18.95
Train loss on 50 batch: 0.191093
Train loss on 100 batch: 0.212987
: Epoch: 28 | Training Loss: 0.215130 | Val. Loss: 0.258300 | Val. Kappa Score: 0.8860 | LR: 0.000250 | Estimated time: 19.08
Train loss on 50 batch: 0.208563
Train loss on 100 batch: 0.221294
best-train-loss: 0.212790
best-valid-loss: 0.248546
best-kappa: 0.8867
: Epoch: 29 | Training Loss: 0.212790 | Val. Loss: 0.248546 | Val. Kappa Score: 0.8867 | LR: 0.000250 | Estimated time: 18.87
Train loss on 50 batch: 0.225067
Train loss on 100 batch: 0.196753
: Epoch: 30 | Training Loss: 0.214746 | Val. Loss: 0.257764 | Val. Kappa Score: 0.8867 | LR: 0.000250 | Estimated time: 19.24
Train loss on 50 batch: 0.204742
Train loss on 100 batch: 0.247077
best-train-loss: 0.209214
best-valid-loss: 0.242287
best-kappa: 0.8871
: Epoch: 31 | Training Loss: 0.209214 | Val. Loss: 0.242287 | Val. Kappa Score: 0.8871 | LR: 0.000250 | Estimated time: 18.99
Train loss on 50 batch: 0.195609
Train loss on 100 batch: 0.220510
: Epoch: 32 | Training Loss: 0.206073 | Val. Loss: 0.244100 | Val. Kappa Score: 0.8875 | LR: 0.000250 | Estimated time: 18.77
Train loss on 50 batch: 0.200079
Train loss on 100 batch: 0.205007
best-train-loss: 0.207753
best-valid-loss: 0.239033
best-kappa: 0.8884
: Epoch: 33 | Training Loss: 0.207753 | Val. Loss: 0.239033 | Val. Kappa Score: 0.8884 | LR: 0.000250 | Estimated time: 18.86
Train loss on 50 batch: 0.209101
Train loss on 100 batch: 0.203875
: Epoch: 34 | Training Loss: 0.199590 | Val. Loss: 0.246883 | Val. Kappa Score: 0.8887 | LR: 0.000250 | Estimated time: 18.82
Train loss on 50 batch: 0.190492
Train loss on 100 batch: 0.208576
: Epoch: 35 | Training Loss: 0.192813 | Val. Loss: 0.270180 | Val. Kappa Score: 0.8890 | LR: 0.000250 | Estimated time: 18.86
Train loss on 50 batch: 0.195295
Train loss on 100 batch: 0.202192
: Epoch: 36 | Training Loss: 0.193171 | Val. Loss: 0.257344 | Val. Kappa Score: 0.8894 | LR: 0.000125 | Estimated time: 18.80
Train loss on 50 batch: 0.179667
Train loss on 100 batch: 0.195572
: Epoch: 37 | Training Loss: 0.198601 | Val. Loss: 0.241206 | Val. Kappa Score: 0.8896 | LR: 0.000125 | Estimated time: 18.70
Train loss on 50 batch: 0.211697
Train loss on 100 batch: 0.188915
: Epoch: 38 | Training Loss: 0.197703 | Val. Loss: 0.246371 | Val. Kappa Score: 0.8901 | LR: 0.000125 | Estimated time: 19.18
Train loss on 50 batch: 0.196619
Train loss on 100 batch: 0.204456
: Epoch: 39 | Training Loss: 0.193304 | Val. Loss: 0.242511 | Val. Kappa Score: 0.8905 | LR: 0.000063 | Estimated time: 18.78
Train loss on 50 batch: 0.198479
Train loss on 100 batch: 0.187939
: Epoch: 40 | Training Loss: 0.194728 | Val. Loss: 0.244189 | Val. Kappa Score: 0.8908 | LR: 0.000063 | Estimated time: 18.95
Train loss on 50 batch: 0.190598
Train loss on 100 batch: 0.185258
: Epoch: 41 | Training Loss: 0.193359 | Val. Loss: 0.241595 | Val. Kappa Score: 0.8911 | LR: 0.000063 | Estimated time: 19.01
Train loss on 50 batch: 0.183285
Train loss on 100 batch: 0.176251
: Epoch: 42 | Training Loss: 0.189642 | Val. Loss: 0.241581 | Val. Kappa Score: 0.8915 | LR: 0.000031 | Estimated time: 19.04
Train loss on 50 batch: 0.179030
Train loss on 100 batch: 0.199058
: Epoch: 43 | Training Loss: 0.183712 | Val. Loss: 0.256582 | Val. Kappa Score: 0.8916 | LR: 0.000031 | Estimated time: 19.04
time_estimated: 816.09
n-epochs: 43
time_estimated: 816.13
----------------------------------------

Experiment N: 134: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.24 23:19:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95fa4be0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.500396
Train loss on 100 batch: 0.439631
best-train-loss: 0.434047
best-valid-loss: 0.347726
best-kappa: 0.8696
: Epoch: 1 | Training Loss: 0.434047 | Val. Loss: 0.347726 | Val. Kappa Score: 0.8696 | LR: 0.001000 | Estimated time: 40.46
Train loss on 50 batch: 0.353453
Train loss on 100 batch: 0.353932
best-train-loss: 0.339018
best-valid-loss: 0.301457
best-kappa: 0.8804
: Epoch: 2 | Training Loss: 0.339018 | Val. Loss: 0.301457 | Val. Kappa Score: 0.8804 | LR: 0.001000 | Estimated time: 40.04
Train loss on 50 batch: 0.320187
Train loss on 100 batch: 0.356599
: Epoch: 3 | Training Loss: 0.323128 | Val. Loss: 0.391790 | Val. Kappa Score: 0.8714 | LR: 0.001000 | Estimated time: 40.19
Train loss on 50 batch: 0.263818
Train loss on 100 batch: 0.319240
: Epoch: 4 | Training Loss: 0.287661 | Val. Loss: 0.320099 | Val. Kappa Score: 0.8705 | LR: 0.001000 | Estimated time: 40.24
Train loss on 50 batch: 0.269658
Train loss on 100 batch: 0.333243
: Epoch: 5 | Training Loss: 0.300136 | Val. Loss: 0.579402 | Val. Kappa Score: 0.8419 | LR: 0.000500 | Estimated time: 40.10
Train loss on 50 batch: 0.260255
Train loss on 100 batch: 0.284174
best-train-loss: 0.275973
best-valid-loss: 0.258558
best-kappa: 0.8494
: Epoch: 6 | Training Loss: 0.275973 | Val. Loss: 0.258558 | Val. Kappa Score: 0.8494 | LR: 0.000500 | Estimated time: 40.13
Train loss on 50 batch: 0.250660
Train loss on 100 batch: 0.289614
: Epoch: 7 | Training Loss: 0.261541 | Val. Loss: 0.267910 | Val. Kappa Score: 0.8550 | LR: 0.000500 | Estimated time: 40.22
Train loss on 50 batch: 0.284167
Train loss on 100 batch: 0.235955
: Epoch: 8 | Training Loss: 0.264118 | Val. Loss: 0.266076 | Val. Kappa Score: 0.8602 | LR: 0.000500 | Estimated time: 40.14
Train loss on 50 batch: 0.238957
Train loss on 100 batch: 0.275281
: Epoch: 9 | Training Loss: 0.256649 | Val. Loss: 0.271230 | Val. Kappa Score: 0.8631 | LR: 0.000250 | Estimated time: 40.18
Train loss on 50 batch: 0.244505
Train loss on 100 batch: 0.257726
: Epoch: 10 | Training Loss: 0.248527 | Val. Loss: 0.271895 | Val. Kappa Score: 0.8666 | LR: 0.000250 | Estimated time: 40.13
Train loss on 50 batch: 0.255657
Train loss on 100 batch: 0.206772
: Epoch: 11 | Training Loss: 0.240972 | Val. Loss: 0.262508 | Val. Kappa Score: 0.8679 | LR: 0.000250 | Estimated time: 40.12
Train loss on 50 batch: 0.244549
Train loss on 100 batch: 0.215948
: Epoch: 12 | Training Loss: 0.237218 | Val. Loss: 0.285092 | Val. Kappa Score: 0.8703 | LR: 0.000125 | Estimated time: 40.18
Train loss on 50 batch: 0.216788
Train loss on 100 batch: 0.239660
: Epoch: 13 | Training Loss: 0.231242 | Val. Loss: 0.271146 | Val. Kappa Score: 0.8710 | LR: 0.000125 | Estimated time: 40.20
Train loss on 50 batch: 0.232114
Train loss on 100 batch: 0.261596
best-train-loss: 0.234832
best-valid-loss: 0.258115
best-kappa: 0.8723
: Epoch: 14 | Training Loss: 0.234832 | Val. Loss: 0.258115 | Val. Kappa Score: 0.8723 | LR: 0.000125 | Estimated time: 40.25
Train loss on 50 batch: 0.235921
Train loss on 100 batch: 0.245399
: Epoch: 15 | Training Loss: 0.230991 | Val. Loss: 0.280962 | Val. Kappa Score: 0.8741 | LR: 0.000125 | Estimated time: 40.23
Train loss on 50 batch: 0.248142
Train loss on 100 batch: 0.240724
: Epoch: 16 | Training Loss: 0.231818 | Val. Loss: 0.262562 | Val. Kappa Score: 0.8754 | LR: 0.000125 | Estimated time: 40.44
Train loss on 50 batch: 0.224269
Train loss on 100 batch: 0.248534
: Epoch: 17 | Training Loss: 0.238635 | Val. Loss: 0.260039 | Val. Kappa Score: 0.8762 | LR: 0.000063 | Estimated time: 40.28
Train loss on 50 batch: 0.218587
Train loss on 100 batch: 0.230945
best-train-loss: 0.242867
best-valid-loss: 0.255046
best-kappa: 0.8765
: Epoch: 18 | Training Loss: 0.242867 | Val. Loss: 0.255046 | Val. Kappa Score: 0.8765 | LR: 0.000063 | Estimated time: 40.15
Train loss on 50 batch: 0.235509
Train loss on 100 batch: 0.232857
best-train-loss: 0.232130
best-valid-loss: 0.254874
best-kappa: 0.8770
: Epoch: 19 | Training Loss: 0.232130 | Val. Loss: 0.254874 | Val. Kappa Score: 0.8770 | LR: 0.000063 | Estimated time: 40.21
Train loss on 50 batch: 0.208961
Train loss on 100 batch: 0.233938
: Epoch: 20 | Training Loss: 0.232900 | Val. Loss: 0.254937 | Val. Kappa Score: 0.8776 | LR: 0.000063 | Estimated time: 40.18
Train loss on 50 batch: 0.223928
Train loss on 100 batch: 0.214187
: Epoch: 21 | Training Loss: 0.227368 | Val. Loss: 0.255854 | Val. Kappa Score: 0.8784 | LR: 0.000063 | Estimated time: 40.06
Train loss on 50 batch: 0.201071
Train loss on 100 batch: 0.240940
best-train-loss: 0.221429
best-valid-loss: 0.250586
best-kappa: 0.8792
: Epoch: 22 | Training Loss: 0.221429 | Val. Loss: 0.250586 | Val. Kappa Score: 0.8792 | LR: 0.000063 | Estimated time: 40.24
Train loss on 50 batch: 0.202113
Train loss on 100 batch: 0.232820
: Epoch: 23 | Training Loss: 0.225575 | Val. Loss: 0.252138 | Val. Kappa Score: 0.8801 | LR: 0.000063 | Estimated time: 40.13
Train loss on 50 batch: 0.233717
Train loss on 100 batch: 0.200352
: Epoch: 24 | Training Loss: 0.231063 | Val. Loss: 0.251797 | Val. Kappa Score: 0.8806 | LR: 0.000063 | Estimated time: 40.07
Train loss on 50 batch: 0.224429
Train loss on 100 batch: 0.239071
best-train-loss: 0.225246
best-valid-loss: 0.246841
best-kappa: 0.8813
: Epoch: 25 | Training Loss: 0.225246 | Val. Loss: 0.246841 | Val. Kappa Score: 0.8813 | LR: 0.000063 | Estimated time: 40.11
Train loss on 50 batch: 0.192868
Train loss on 100 batch: 0.232127
: Epoch: 26 | Training Loss: 0.227572 | Val. Loss: 0.259376 | Val. Kappa Score: 0.8821 | LR: 0.000063 | Estimated time: 40.13
Train loss on 50 batch: 0.221131
Train loss on 100 batch: 0.211873
: Epoch: 27 | Training Loss: 0.223459 | Val. Loss: 0.252195 | Val. Kappa Score: 0.8826 | LR: 0.000063 | Estimated time: 40.19
Train loss on 50 batch: 0.193319
Train loss on 100 batch: 0.222237
: Epoch: 28 | Training Loss: 0.224767 | Val. Loss: 0.256938 | Val. Kappa Score: 0.8832 | LR: 0.000031 | Estimated time: 40.11
Train loss on 50 batch: 0.217389
Train loss on 100 batch: 0.231617
: Epoch: 29 | Training Loss: 0.219289 | Val. Loss: 0.248977 | Val. Kappa Score: 0.8840 | LR: 0.000031 | Estimated time: 40.17
Train loss on 50 batch: 0.234388
Train loss on 100 batch: 0.230761
: Epoch: 30 | Training Loss: 0.227267 | Val. Loss: 0.249245 | Val. Kappa Score: 0.8845 | LR: 0.000031 | Estimated time: 40.15
Train loss on 50 batch: 0.239864
Train loss on 100 batch: 0.259135
: Epoch: 31 | Training Loss: 0.228822 | Val. Loss: 0.248779 | Val. Kappa Score: 0.8853 | LR: 0.000016 | Estimated time: 40.12
Train loss on 50 batch: 0.216902
Train loss on 100 batch: 0.240271
: Epoch: 32 | Training Loss: 0.226060 | Val. Loss: 0.250538 | Val. Kappa Score: 0.8856 | LR: 0.000016 | Estimated time: 40.14
Train loss on 50 batch: 0.221500
Train loss on 100 batch: 0.216521
: Epoch: 33 | Training Loss: 0.222194 | Val. Loss: 0.253256 | Val. Kappa Score: 0.8860 | LR: 0.000016 | Estimated time: 40.18
Train loss on 50 batch: 0.210203
Train loss on 100 batch: 0.233831
: Epoch: 34 | Training Loss: 0.213620 | Val. Loss: 0.248748 | Val. Kappa Score: 0.8865 | LR: 0.000008 | Estimated time: 40.04
Train loss on 50 batch: 0.220933
Train loss on 100 batch: 0.235862
: Epoch: 35 | Training Loss: 0.224667 | Val. Loss: 0.249031 | Val. Kappa Score: 0.8868 | LR: 0.000008 | Estimated time: 40.14
time_estimated: 1408.00
n-epochs: 35
time_estimated: 1408.04
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 00:47:07
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d108780>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 00:48:06
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d710>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 00:48:45
data-type: new
loss-func: BCEWithLogitsLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10d668>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 00:49:30
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6d8>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 01:03:34
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1087f0>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 01:03:45
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c710>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 135: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.25 01:07:43
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c6a0>
early-stopping-patience: 10
parameters-amount: 28351029
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.933159
Train loss on 100 batch: 0.756898
best-train-loss: 0.782977
best-valid-loss: 0.962478
best-kappa: 0.1173
: Epoch: 1 | Training Loss: 0.782977 | Val. Loss: 0.962478 | Val. Kappa Score: 0.1173 | LR: 0.001000 | Estimated time: 40.35
Train loss on 50 batch: 0.609506
Train loss on 100 batch: 0.630749
best-train-loss: 0.615531
best-valid-loss: 0.634700
best-kappa: 0.2009
: Epoch: 2 | Training Loss: 0.615531 | Val. Loss: 0.634700 | Val. Kappa Score: 0.2009 | LR: 0.001000 | Estimated time: 39.76
Train loss on 50 batch: 0.601364
Train loss on 100 batch: 0.546815
: Epoch: 3 | Training Loss: 0.573974 | Val. Loss: 0.638439 | Val. Kappa Score: 0.2530 | LR: 0.001000 | Estimated time: 39.86
Train loss on 50 batch: 0.524882
Train loss on 100 batch: 0.585952
best-train-loss: 0.554722
best-valid-loss: 0.614468
best-kappa: 0.3103
: Epoch: 4 | Training Loss: 0.554722 | Val. Loss: 0.614468 | Val. Kappa Score: 0.3103 | LR: 0.001000 | Estimated time: 39.85
Train loss on 50 batch: 0.510029
Train loss on 100 batch: 0.547164
: Epoch: 5 | Training Loss: 0.538838 | Val. Loss: 0.626246 | Val. Kappa Score: 0.3492 | LR: 0.001000 | Estimated time: 39.87
Train loss on 50 batch: 0.462701
Train loss on 100 batch: 0.515731
: Epoch: 6 | Training Loss: 0.513714 | Val. Loss: 0.904362 | Val. Kappa Score: 0.3283 | LR: 0.001000 | Estimated time: 39.85
Train loss on 50 batch: 0.477997
Train loss on 100 batch: 0.489977
best-train-loss: 0.476087
best-valid-loss: 0.586977
best-kappa: 0.3307
: Epoch: 7 | Training Loss: 0.476087 | Val. Loss: 0.586977 | Val. Kappa Score: 0.3307 | LR: 0.001000 | Estimated time: 39.91
Train loss on 50 batch: 0.539152
Train loss on 100 batch: 0.425155
: Epoch: 8 | Training Loss: 0.476119 | Val. Loss: 0.744831 | Val. Kappa Score: 0.3271 | LR: 0.001000 | Estimated time: 39.89
Train loss on 50 batch: 0.416840
Train loss on 100 batch: 0.443422
best-train-loss: 0.446408
best-valid-loss: 0.515704
best-kappa: 0.3287
: Epoch: 9 | Training Loss: 0.446408 | Val. Loss: 0.515704 | Val. Kappa Score: 0.3287 | LR: 0.001000 | Estimated time: 39.85
Train loss on 50 batch: 0.405222
Train loss on 100 batch: 0.453533
: Epoch: 10 | Training Loss: 0.436678 | Val. Loss: 0.559104 | Val. Kappa Score: 0.3300 | LR: 0.001000 | Estimated time: 39.89
Train loss on 50 batch: 0.453976
Train loss on 100 batch: 0.427503
best-train-loss: 0.431082
best-valid-loss: 0.453444
best-kappa: 0.3285
: Epoch: 11 | Training Loss: 0.431082 | Val. Loss: 0.453444 | Val. Kappa Score: 0.3285 | LR: 0.001000 | Estimated time: 39.95
Train loss on 50 batch: 0.394922
Train loss on 100 batch: 0.403266
: Epoch: 12 | Training Loss: 0.403947 | Val. Loss: 0.500450 | Val. Kappa Score: 0.3342 | LR: 0.001000 | Estimated time: 39.91
Train loss on 50 batch: 0.351590
Train loss on 100 batch: 0.436190
: Epoch: 13 | Training Loss: 0.405716 | Val. Loss: 0.528946 | Val. Kappa Score: 0.3377 | LR: 0.001000 | Estimated time: 39.88
Train loss on 50 batch: 0.325891
Train loss on 100 batch: 0.401856
: Epoch: 14 | Training Loss: 0.378159 | Val. Loss: 0.561322 | Val. Kappa Score: 0.3428 | LR: 0.000500 | Estimated time: 39.91
Train loss on 50 batch: 0.331864
Train loss on 100 batch: 0.342462
: Epoch: 15 | Training Loss: 0.329616 | Val. Loss: 0.527400 | Val. Kappa Score: 0.3399 | LR: 0.000500 | Estimated time: 39.86
Train loss on 50 batch: 0.330314
Train loss on 100 batch: 0.314235
best-train-loss: 0.304179
best-valid-loss: 0.428101
best-kappa: 0.3404
: Epoch: 16 | Training Loss: 0.304179 | Val. Loss: 0.428101 | Val. Kappa Score: 0.3404 | LR: 0.000500 | Estimated time: 39.94
Train loss on 50 batch: 0.244283
Train loss on 100 batch: 0.275046
: Epoch: 17 | Training Loss: 0.267635 | Val. Loss: 0.510811 | Val. Kappa Score: 0.3402 | LR: 0.000500 | Estimated time: 39.89
Train loss on 50 batch: 0.200838
Train loss on 100 batch: 0.268428
: Epoch: 18 | Training Loss: 0.258020 | Val. Loss: 0.554707 | Val. Kappa Score: 0.3412 | LR: 0.000500 | Estimated time: 40.12
Train loss on 50 batch: 0.266153
Train loss on 100 batch: 0.285836
: Epoch: 19 | Training Loss: 0.267238 | Val. Loss: 0.540960 | Val. Kappa Score: 0.3407 | LR: 0.000250 | Estimated time: 39.99
Train loss on 50 batch: 0.203617
Train loss on 100 batch: 0.186844
: Epoch: 20 | Training Loss: 0.188087 | Val. Loss: 0.588612 | Val. Kappa Score: 0.3391 | LR: 0.000250 | Estimated time: 39.95
Train loss on 50 batch: 0.160497
Train loss on 100 batch: 0.143960
: Epoch: 21 | Training Loss: 0.158374 | Val. Loss: 0.598565 | Val. Kappa Score: 0.3372 | LR: 0.000250 | Estimated time: 40.02
Train loss on 50 batch: 0.146908
Train loss on 100 batch: 0.188748
: Epoch: 22 | Training Loss: 0.163607 | Val. Loss: 0.563020 | Val. Kappa Score: 0.3374 | LR: 0.000125 | Estimated time: 40.11
Train loss on 50 batch: 0.113964
Train loss on 100 batch: 0.111067
: Epoch: 23 | Training Loss: 0.115300 | Val. Loss: 0.622383 | Val. Kappa Score: 0.3369 | LR: 0.000125 | Estimated time: 40.13
Train loss on 50 batch: 0.110535
Train loss on 100 batch: 0.145070
: Epoch: 24 | Training Loss: 0.126417 | Val. Loss: 0.623018 | Val. Kappa Score: 0.3352 | LR: 0.000125 | Estimated time: 40.10
Train loss on 50 batch: 0.084926
Train loss on 100 batch: 0.132261
: Epoch: 25 | Training Loss: 0.098354 | Val. Loss: 0.654810 | Val. Kappa Score: 0.3338 | LR: 0.000063 | Estimated time: 40.66
Train loss on 50 batch: 0.072428
Train loss on 100 batch: 0.085438
: Epoch: 26 | Training Loss: 0.087435 | Val. Loss: 0.658573 | Val. Kappa Score: 0.3320 | LR: 0.000063 | Estimated time: 40.50
time_estimated: 1041.56
n-epochs: 26
time_estimated: 1041.59
----------------------------------------

Experiment N: 136: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 08:43:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96007a20>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 136: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 08:44:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96005ac8>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 136: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 08:44:46
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96007a20>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 136: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 08:45:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96004a90>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.894012
----------------------------------------

Experiment N: 136: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 08:46:13
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96004ac8>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.528009
Train loss on 100 batch: 0.413818
Train loss on 150 batch: 0.363512
best-train-loss: 0.395533
best-valid-loss: 0.274085
best-kappa: 0.8917
: Epoch: 1 | Training Loss: 0.395533 | Val. Loss: 0.274085 | Val. Kappa Score: 0.8917 | LR: 0.001000 | Estimated time: 54.04
Train loss on 50 batch: 0.332884
Train loss on 100 batch: 0.309397
Train loss on 150 batch: 0.374881
: Epoch: 2 | Training Loss: 0.323582 | Val. Loss: 0.298164 | Val. Kappa Score: 0.8924 | LR: 0.001000 | Estimated time: 53.31
Train loss on 50 batch: 0.324594
Train loss on 100 batch: 0.339262
Train loss on 150 batch: 0.308227
: Epoch: 3 | Training Loss: 0.314700 | Val. Loss: 0.372287 | Val. Kappa Score: 0.8849 | LR: 0.001000 | Estimated time: 53.07
Train loss on 50 batch: 0.278463
Train loss on 100 batch: 0.306467
Train loss on 150 batch: 0.329280
best-train-loss: 0.291520
best-valid-loss: 0.248546
best-kappa: 0.8861
: Epoch: 4 | Training Loss: 0.291520 | Val. Loss: 0.248546 | Val. Kappa Score: 0.8861 | LR: 0.001000 | Estimated time: 53.36
Train loss on 50 batch: 0.273808
Train loss on 100 batch: 0.329346
Train loss on 150 batch: 0.266131
: Epoch: 5 | Training Loss: 0.296410 | Val. Loss: 0.269069 | Val. Kappa Score: 0.8834 | LR: 0.001000 | Estimated time: 53.33
Train loss on 50 batch: 0.238300
Train loss on 100 batch: 0.251984
Train loss on 150 batch: 0.299020
: Epoch: 6 | Training Loss: 0.262585 | Val. Loss: 0.275614 | Val. Kappa Score: 0.8821 | LR: 0.001000 | Estimated time: 53.81
Train loss on 50 batch: 0.226653
Train loss on 100 batch: 0.285907
Train loss on 150 batch: 0.242326
: Epoch: 7 | Training Loss: 0.262893 | Val. Loss: 0.275963 | Val. Kappa Score: 0.8847 | LR: 0.000500 | Estimated time: 53.30
Train loss on 50 batch: 0.263081
Train loss on 100 batch: 0.222062
Train loss on 150 batch: 0.204313
best-train-loss: 0.233775
best-valid-loss: 0.244712
best-kappa: 0.8868
: Epoch: 8 | Training Loss: 0.233775 | Val. Loss: 0.244712 | Val. Kappa Score: 0.8868 | LR: 0.000500 | Estimated time: 53.69
Train loss on 50 batch: 0.186219
Train loss on 100 batch: 0.263059
Train loss on 150 batch: 0.233905
: Epoch: 9 | Training Loss: 0.242271 | Val. Loss: 0.265927 | Val. Kappa Score: 0.8861 | LR: 0.000500 | Estimated time: 53.46
Train loss on 50 batch: 0.227571
Train loss on 100 batch: 0.247416
Train loss on 150 batch: 0.234703
: Epoch: 10 | Training Loss: 0.235679 | Val. Loss: 0.296877 | Val. Kappa Score: 0.8860 | LR: 0.000500 | Estimated time: 53.52
Train loss on 50 batch: 0.258356
Train loss on 100 batch: 0.194598
Train loss on 150 batch: 0.248786
best-train-loss: 0.226862
best-valid-loss: 0.222365
best-kappa: 0.8874
: Epoch: 11 | Training Loss: 0.226862 | Val. Loss: 0.222365 | Val. Kappa Score: 0.8874 | LR: 0.000500 | Estimated time: 53.29
Train loss on 50 batch: 0.214068
Train loss on 100 batch: 0.215745
Train loss on 150 batch: 0.208385
best-train-loss: 0.216825
best-valid-loss: 0.218084
best-kappa: 0.8872
: Epoch: 12 | Training Loss: 0.216825 | Val. Loss: 0.218084 | Val. Kappa Score: 0.8872 | LR: 0.000500 | Estimated time: 53.37
Train loss on 50 batch: 0.203702
Train loss on 100 batch: 0.223882
Train loss on 150 batch: 0.209585
: Epoch: 13 | Training Loss: 0.213678 | Val. Loss: 0.230022 | Val. Kappa Score: 0.8865 | LR: 0.000500 | Estimated time: 52.79
Train loss on 50 batch: 0.222022
Train loss on 100 batch: 0.235075
Train loss on 150 batch: 0.163755
: Epoch: 14 | Training Loss: 0.211857 | Val. Loss: 0.245294 | Val. Kappa Score: 0.8877 | LR: 0.000500 | Estimated time: 53.14
Train loss on 50 batch: 0.201810
Train loss on 100 batch: 0.230975
Train loss on 150 batch: 0.230735
: Epoch: 15 | Training Loss: 0.211920 | Val. Loss: 0.247649 | Val. Kappa Score: 0.8883 | LR: 0.000250 | Estimated time: 53.15
Train loss on 50 batch: 0.223585
Train loss on 100 batch: 0.221871
Train loss on 150 batch: 0.172052
best-train-loss: 0.203113
best-valid-loss: 0.215811
best-kappa: 0.8888
: Epoch: 16 | Training Loss: 0.203113 | Val. Loss: 0.215811 | Val. Kappa Score: 0.8888 | LR: 0.000250 | Estimated time: 53.28
Train loss on 50 batch: 0.178570
Train loss on 100 batch: 0.198938
Train loss on 150 batch: 0.210543
: Epoch: 17 | Training Loss: 0.197466 | Val. Loss: 0.216797 | Val. Kappa Score: 0.8886 | LR: 0.000250 | Estimated time: 52.76
Train loss on 50 batch: 0.152232
Train loss on 100 batch: 0.195065
Train loss on 150 batch: 0.214293
: Epoch: 18 | Training Loss: 0.194776 | Val. Loss: 0.220244 | Val. Kappa Score: 0.8876 | LR: 0.000250 | Estimated time: 53.49
Train loss on 50 batch: 0.186935
Train loss on 100 batch: 0.224212
Train loss on 150 batch: 0.172512
: Epoch: 19 | Training Loss: 0.191247 | Val. Loss: 0.221650 | Val. Kappa Score: 0.8884 | LR: 0.000125 | Estimated time: 53.75
Train loss on 50 batch: 0.163752
Train loss on 100 batch: 0.167720
Train loss on 150 batch: 0.211049
: Epoch: 20 | Training Loss: 0.198967 | Val. Loss: 0.218475 | Val. Kappa Score: 0.8886 | LR: 0.000125 | Estimated time: 53.47
Train loss on 50 batch: 0.174476
Train loss on 100 batch: 0.185401
Train loss on 150 batch: 0.165814
: Epoch: 21 | Training Loss: 0.177062 | Val. Loss: 0.220504 | Val. Kappa Score: 0.8893 | LR: 0.000125 | Estimated time: 53.49
Train loss on 50 batch: 0.146144
Train loss on 100 batch: 0.198860
Train loss on 150 batch: 0.177440
: Epoch: 22 | Training Loss: 0.175392 | Val. Loss: 0.223467 | Val. Kappa Score: 0.8896 | LR: 0.000063 | Estimated time: 53.68
Train loss on 50 batch: 0.156166
Train loss on 100 batch: 0.178614
Train loss on 150 batch: 0.189158
: Epoch: 23 | Training Loss: 0.181033 | Val. Loss: 0.222319 | Val. Kappa Score: 0.8904 | LR: 0.000063 | Estimated time: 53.19
Train loss on 50 batch: 0.170230
Train loss on 100 batch: 0.163163
Train loss on 150 batch: 0.165503
: Epoch: 24 | Training Loss: 0.181353 | Val. Loss: 0.221948 | Val. Kappa Score: 0.8915 | LR: 0.000063 | Estimated time: 53.08
Train loss on 50 batch: 0.183820
Train loss on 100 batch: 0.176376
Train loss on 150 batch: 0.180595
: Epoch: 25 | Training Loss: 0.177638 | Val. Loss: 0.220640 | Val. Kappa Score: 0.8919 | LR: 0.000031 | Estimated time: 53.59
Train loss on 50 batch: 0.137829
Train loss on 100 batch: 0.175751
Train loss on 150 batch: 0.215992
: Epoch: 26 | Training Loss: 0.174593 | Val. Loss: 0.224297 | Val. Kappa Score: 0.8926 | LR: 0.000031 | Estimated time: 54.33
time_estimated: 1389.84
n-epochs: 26
time_estimated: 1389.88
----------------------------------------

Experiment N: 137: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 09:44:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb960079e8>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.626825
Train loss on 100 batch: 0.506572
Train loss on 150 batch: 0.450875
best-train-loss: 0.488108
best-valid-loss: 0.315277
best-kappa: 0.8697
: Epoch: 1 | Training Loss: 0.488108 | Val. Loss: 0.315277 | Val. Kappa Score: 0.8697 | LR: 0.000100 | Estimated time: 53.99
Train loss on 50 batch: 0.441756
Train loss on 100 batch: 0.359707
Train loss on 150 batch: 0.476146
best-train-loss: 0.403620
best-valid-loss: 0.291441
best-kappa: 0.8753
: Epoch: 2 | Training Loss: 0.403620 | Val. Loss: 0.291441 | Val. Kappa Score: 0.8753 | LR: 0.000100 | Estimated time: 53.46
Train loss on 50 batch: 0.402212
Train loss on 100 batch: 0.395673
Train loss on 150 batch: 0.366735
best-train-loss: 0.384622
best-valid-loss: 0.288742
best-kappa: 0.8728
: Epoch: 3 | Training Loss: 0.384622 | Val. Loss: 0.288742 | Val. Kappa Score: 0.8728 | LR: 0.000100 | Estimated time: 53.77
Train loss on 50 batch: 0.308552
Train loss on 100 batch: 0.385993
Train loss on 150 batch: 0.391763
best-train-loss: 0.352315
best-valid-loss: 0.282300
best-kappa: 0.8767
: Epoch: 4 | Training Loss: 0.352315 | Val. Loss: 0.282300 | Val. Kappa Score: 0.8767 | LR: 0.000100 | Estimated time: 54.53
Train loss on 50 batch: 0.339156
Train loss on 100 batch: 0.419045
Train loss on 150 batch: 0.344028
best-train-loss: 0.360557
best-valid-loss: 0.276649
best-kappa: 0.8766
: Epoch: 5 | Training Loss: 0.360557 | Val. Loss: 0.276649 | Val. Kappa Score: 0.8766 | LR: 0.000100 | Estimated time: 55.22
Train loss on 50 batch: 0.282557
Train loss on 100 batch: 0.312477
Train loss on 150 batch: 0.362685
best-train-loss: 0.325903
best-valid-loss: 0.269668
best-kappa: 0.8796
: Epoch: 6 | Training Loss: 0.325903 | Val. Loss: 0.269668 | Val. Kappa Score: 0.8796 | LR: 0.000100 | Estimated time: 54.17
Train loss on 50 batch: 0.304618
Train loss on 100 batch: 0.319233
Train loss on 150 batch: 0.323804
best-train-loss: 0.329716
best-valid-loss: 0.261310
best-kappa: 0.8806
: Epoch: 7 | Training Loss: 0.329716 | Val. Loss: 0.261310 | Val. Kappa Score: 0.8806 | LR: 0.000100 | Estimated time: 53.32
Train loss on 50 batch: 0.326347
Train loss on 100 batch: 0.302195
Train loss on 150 batch: 0.275026
: Epoch: 8 | Training Loss: 0.301352 | Val. Loss: 0.261326 | Val. Kappa Score: 0.8822 | LR: 0.000100 | Estimated time: 55.30
Train loss on 50 batch: 0.257826
Train loss on 100 batch: 0.371982
Train loss on 150 batch: 0.320622
best-train-loss: 0.323606
best-valid-loss: 0.257744
best-kappa: 0.8819
: Epoch: 9 | Training Loss: 0.323606 | Val. Loss: 0.257744 | Val. Kappa Score: 0.8819 | LR: 0.000100 | Estimated time: 55.54
Train loss on 50 batch: 0.264532
Train loss on 100 batch: 0.313717
Train loss on 150 batch: 0.309650
: Epoch: 10 | Training Loss: 0.296750 | Val. Loss: 0.259018 | Val. Kappa Score: 0.8822 | LR: 0.000100 | Estimated time: 53.32
Train loss on 50 batch: 0.312271
Train loss on 100 batch: 0.250817
Train loss on 150 batch: 0.381084
: Epoch: 11 | Training Loss: 0.300533 | Val. Loss: 0.258474 | Val. Kappa Score: 0.8830 | LR: 0.000100 | Estimated time: 53.13
Train loss on 50 batch: 0.289790
Train loss on 100 batch: 0.289067
Train loss on 150 batch: 0.279895
best-train-loss: 0.297522
best-valid-loss: 0.248826
best-kappa: 0.8830
: Epoch: 12 | Training Loss: 0.297522 | Val. Loss: 0.248826 | Val. Kappa Score: 0.8830 | LR: 0.000100 | Estimated time: 54.77
Train loss on 50 batch: 0.260165
Train loss on 100 batch: 0.297559
Train loss on 150 batch: 0.290007
: Epoch: 13 | Training Loss: 0.286005 | Val. Loss: 0.255181 | Val. Kappa Score: 0.8828 | LR: 0.000100 | Estimated time: 52.60
Train loss on 50 batch: 0.298759
Train loss on 100 batch: 0.339695
Train loss on 150 batch: 0.222572
: Epoch: 14 | Training Loss: 0.290500 | Val. Loss: 0.255713 | Val. Kappa Score: 0.8833 | LR: 0.000100 | Estimated time: 53.25
Train loss on 50 batch: 0.290230
Train loss on 100 batch: 0.294687
Train loss on 150 batch: 0.308008
: Epoch: 15 | Training Loss: 0.287067 | Val. Loss: 0.250424 | Val. Kappa Score: 0.8831 | LR: 0.000050 | Estimated time: 52.75
Train loss on 50 batch: 0.319621
Train loss on 100 batch: 0.282491
Train loss on 150 batch: 0.276085
best-train-loss: 0.286883
best-valid-loss: 0.246301
best-kappa: 0.8834
: Epoch: 16 | Training Loss: 0.286883 | Val. Loss: 0.246301 | Val. Kappa Score: 0.8834 | LR: 0.000050 | Estimated time: 53.18
Train loss on 50 batch: 0.278150
Train loss on 100 batch: 0.266702
Train loss on 150 batch: 0.289056
: Epoch: 17 | Training Loss: 0.278338 | Val. Loss: 0.247743 | Val. Kappa Score: 0.8836 | LR: 0.000050 | Estimated time: 52.62
Train loss on 50 batch: 0.235376
Train loss on 100 batch: 0.276071
Train loss on 150 batch: 0.277962
best-train-loss: 0.267404
best-valid-loss: 0.246286
best-kappa: 0.8830
: Epoch: 18 | Training Loss: 0.267404 | Val. Loss: 0.246286 | Val. Kappa Score: 0.8830 | LR: 0.000050 | Estimated time: 53.15
Train loss on 50 batch: 0.269882
Train loss on 100 batch: 0.296314
Train loss on 150 batch: 0.237118
best-train-loss: 0.265772
best-valid-loss: 0.243584
best-kappa: 0.8839
: Epoch: 19 | Training Loss: 0.265772 | Val. Loss: 0.243584 | Val. Kappa Score: 0.8839 | LR: 0.000050 | Estimated time: 53.41
Train loss on 50 batch: 0.242178
Train loss on 100 batch: 0.248011
Train loss on 150 batch: 0.284348
: Epoch: 20 | Training Loss: 0.289772 | Val. Loss: 0.246049 | Val. Kappa Score: 0.8836 | LR: 0.000050 | Estimated time: 52.98
Train loss on 50 batch: 0.264118
Train loss on 100 batch: 0.279565
Train loss on 150 batch: 0.249960
best-train-loss: 0.262676
best-valid-loss: 0.240873
best-kappa: 0.8840
: Epoch: 21 | Training Loss: 0.262676 | Val. Loss: 0.240873 | Val. Kappa Score: 0.8840 | LR: 0.000050 | Estimated time: 53.06
Train loss on 50 batch: 0.233906
Train loss on 100 batch: 0.295366
Train loss on 150 batch: 0.248394
: Epoch: 22 | Training Loss: 0.256345 | Val. Loss: 0.240990 | Val. Kappa Score: 0.8841 | LR: 0.000050 | Estimated time: 53.58
Train loss on 50 batch: 0.231317
Train loss on 100 batch: 0.266781
Train loss on 150 batch: 0.249756
best-train-loss: 0.257963
best-valid-loss: 0.238768
best-kappa: 0.8844
: Epoch: 23 | Training Loss: 0.257963 | Val. Loss: 0.238768 | Val. Kappa Score: 0.8844 | LR: 0.000050 | Estimated time: 53.73
Train loss on 50 batch: 0.262133
Train loss on 100 batch: 0.260790
Train loss on 150 batch: 0.243709
----------------------------------------

Experiment N: 138: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 10:46:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96004a90>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 138: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 10:47:14
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96005ac8>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 138: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 10:47:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96007a20>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.586657
Train loss on 100 batch: 0.474112
Train loss on 150 batch: 0.378472
best-train-loss: 0.436976
best-valid-loss: 0.293379
best-kappa: 0.8744
: Epoch: 1 | Training Loss: 0.436976 | Val. Loss: 0.293379 | Val. Kappa Score: 0.8744 | LR: 0.001000 | Estimated time: 64.30
Train loss on 50 batch: 0.336965
Train loss on 100 batch: 0.303436
Train loss on 150 batch: 0.391950
best-train-loss: 0.334936
best-valid-loss: 0.282504
best-kappa: 0.8824
: Epoch: 2 | Training Loss: 0.334936 | Val. Loss: 0.282504 | Val. Kappa Score: 0.8824 | LR: 0.001000 | Estimated time: 64.54
Train loss on 50 batch: 0.329914
Train loss on 100 batch: 0.349388
Train loss on 150 batch: 0.322434
: Epoch: 3 | Training Loss: 0.324254 | Val. Loss: 0.301472 | Val. Kappa Score: 0.8857 | LR: 0.001000 | Estimated time: 63.99
Train loss on 50 batch: 0.281784
Train loss on 100 batch: 0.329235
Train loss on 150 batch: 0.333666
best-train-loss: 0.301715
best-valid-loss: 0.247573
best-kappa: 0.8894
: Epoch: 4 | Training Loss: 0.301715 | Val. Loss: 0.247573 | Val. Kappa Score: 0.8894 | LR: 0.001000 | Estimated time: 64.17
Train loss on 50 batch: 0.272158
Train loss on 100 batch: 0.339813
Train loss on 150 batch: 0.279338
: Epoch: 5 | Training Loss: 0.309255 | Val. Loss: 0.252028 | Val. Kappa Score: 0.8896 | LR: 0.001000 | Estimated time: 64.50
Train loss on 50 batch: 0.253307
Train loss on 100 batch: 0.251528
Train loss on 150 batch: 0.306893
: Epoch: 6 | Training Loss: 0.269989 | Val. Loss: 0.258379 | Val. Kappa Score: 0.8875 | LR: 0.001000 | Estimated time: 64.63
Train loss on 50 batch: 0.242881
Train loss on 100 batch: 0.282571
Train loss on 150 batch: 0.256082
: Epoch: 7 | Training Loss: 0.272050 | Val. Loss: 0.266011 | Val. Kappa Score: 0.8860 | LR: 0.000500 | Estimated time: 63.94
Train loss on 50 batch: 0.273326
Train loss on 100 batch: 0.225162
Train loss on 150 batch: 0.211879
best-train-loss: 0.242120
best-valid-loss: 0.242363
best-kappa: 0.8882
: Epoch: 8 | Training Loss: 0.242120 | Val. Loss: 0.242363 | Val. Kappa Score: 0.8882 | LR: 0.000500 | Estimated time: 63.60
Train loss on 50 batch: 0.199884
Train loss on 100 batch: 0.277098
Train loss on 150 batch: 0.240218
: Epoch: 9 | Training Loss: 0.247823 | Val. Loss: 0.256750 | Val. Kappa Score: 0.8878 | LR: 0.000500 | Estimated time: 63.18
Train loss on 50 batch: 0.226134
Train loss on 100 batch: 0.260102
Train loss on 150 batch: 0.256048
: Epoch: 10 | Training Loss: 0.245686 | Val. Loss: 0.244465 | Val. Kappa Score: 0.8876 | LR: 0.000500 | Estimated time: 63.27
Train loss on 50 batch: 0.258836
Train loss on 100 batch: 0.203895
Train loss on 150 batch: 0.276240
best-train-loss: 0.237250
best-valid-loss: 0.230245
best-kappa: 0.8891
: Epoch: 11 | Training Loss: 0.237250 | Val. Loss: 0.230245 | Val. Kappa Score: 0.8891 | LR: 0.000500 | Estimated time: 62.91
Train loss on 50 batch: 0.213084
Train loss on 100 batch: 0.218051
Train loss on 150 batch: 0.209960
: Epoch: 12 | Training Loss: 0.219687 | Val. Loss: 0.256957 | Val. Kappa Score: 0.8880 | LR: 0.000500 | Estimated time: 62.74
Train loss on 50 batch: 0.209004
Train loss on 100 batch: 0.234860
Train loss on 150 batch: 0.219105
: Epoch: 13 | Training Loss: 0.222800 | Val. Loss: 0.230301 | Val. Kappa Score: 0.8877 | LR: 0.000500 | Estimated time: 62.81
Train loss on 50 batch: 0.228448
Train loss on 100 batch: 0.238626
Train loss on 150 batch: 0.181823
: Epoch: 14 | Training Loss: 0.220811 | Val. Loss: 0.250869 | Val. Kappa Score: 0.8878 | LR: 0.000250 | Estimated time: 63.45
Train loss on 50 batch: 0.204422
Train loss on 100 batch: 0.227851
Train loss on 150 batch: 0.236955
----------------------------------------

Experiment N: 139: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 11:03:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96005a58>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.923920
Train loss on 100 batch: 0.635055
Train loss on 150 batch: 0.487605
best-train-loss: 0.604316
best-valid-loss: 0.607737
best-kappa: 0.7596
: Epoch: 1 | Training Loss: 0.604316 | Val. Loss: 0.607737 | Val. Kappa Score: 0.7596 | LR: 0.001000 | Estimated time: 64.39
Train loss on 50 batch: 0.367847
Train loss on 100 batch: 0.366645
Train loss on 150 batch: 0.548585
best-train-loss: 0.417225
best-valid-loss: 0.341683
best-kappa: 0.8072
: Epoch: 2 | Training Loss: 0.417225 | Val. Loss: 0.341683 | Val. Kappa Score: 0.8072 | LR: 0.001000 | Estimated time: 62.61
Train loss on 50 batch: 0.303818
Train loss on 100 batch: 0.417611
Train loss on 150 batch: 0.372633
: Epoch: 3 | Training Loss: 0.347532 | Val. Loss: 0.394223 | Val. Kappa Score: 0.8315 | LR: 0.001000 | Estimated time: 62.93
Train loss on 50 batch: 0.255898
Train loss on 100 batch: 0.297778
Train loss on 150 batch: 0.346989
: Epoch: 4 | Training Loss: 0.297268 | Val. Loss: 0.383820 | Val. Kappa Score: 0.8391 | LR: 0.001000 | Estimated time: 63.70
Train loss on 50 batch: 0.285830
Train loss on 100 batch: 0.338690
Train loss on 150 batch: 0.283438
best-train-loss: 0.309610
best-valid-loss: 0.305551
best-kappa: 0.8474
: Epoch: 5 | Training Loss: 0.309610 | Val. Loss: 0.305551 | Val. Kappa Score: 0.8474 | LR: 0.001000 | Estimated time: 62.95
Train loss on 50 batch: 0.263091
Train loss on 100 batch: 0.218916
Train loss on 150 batch: 0.280052
: Epoch: 6 | Training Loss: 0.268675 | Val. Loss: 0.308809 | Val. Kappa Score: 0.8525 | LR: 0.001000 | Estimated time: 63.38
Train loss on 50 batch: 0.219206
Train loss on 100 batch: 0.259518
Train loss on 150 batch: 0.232043
: Epoch: 7 | Training Loss: 0.237639 | Val. Loss: 0.328375 | Val. Kappa Score: 0.8573 | LR: 0.001000 | Estimated time: 62.67
Train loss on 50 batch: 0.240567
Train loss on 100 batch: 0.244298
Train loss on 150 batch: 0.209238
: Epoch: 8 | Training Loss: 0.236588 | Val. Loss: 0.371251 | Val. Kappa Score: 0.8587 | LR: 0.000500 | Estimated time: 63.70
Train loss on 50 batch: 0.140995
Train loss on 100 batch: 0.166007
Train loss on 150 batch: 0.158443
best-train-loss: 0.158999
best-valid-loss: 0.249041
best-kappa: 0.8644
: Epoch: 9 | Training Loss: 0.158999 | Val. Loss: 0.249041 | Val. Kappa Score: 0.8644 | LR: 0.000500 | Estimated time: 63.33
Train loss on 50 batch: 0.116441
Train loss on 100 batch: 0.132590
Train loss on 150 batch: 0.149452
: Epoch: 10 | Training Loss: 0.135192 | Val. Loss: 0.298692 | Val. Kappa Score: 0.8674 | LR: 0.000500 | Estimated time: 63.35
Train loss on 50 batch: 0.131567
Train loss on 100 batch: 0.118431
Train loss on 150 batch: 0.139167
best-train-loss: 0.126027
best-valid-loss: 0.244770
best-kappa: 0.8708
: Epoch: 11 | Training Loss: 0.126027 | Val. Loss: 0.244770 | Val. Kappa Score: 0.8708 | LR: 0.000500 | Estimated time: 62.66
Train loss on 50 batch: 0.120942
Train loss on 100 batch: 0.125513
Train loss on 150 batch: 0.095647
: Epoch: 12 | Training Loss: 0.115087 | Val. Loss: 0.308707 | Val. Kappa Score: 0.8716 | LR: 0.000500 | Estimated time: 63.19
Train loss on 50 batch: 0.090536
Train loss on 100 batch: 0.104780
Train loss on 150 batch: 0.095126
best-train-loss: 0.095946
best-valid-loss: 0.223319
best-kappa: 0.8735
: Epoch: 13 | Training Loss: 0.095946 | Val. Loss: 0.223319 | Val. Kappa Score: 0.8735 | LR: 0.000500 | Estimated time: 62.98
Train loss on 50 batch: 0.090151
Train loss on 100 batch: 0.089850
Train loss on 150 batch: 0.082852
: Epoch: 14 | Training Loss: 0.092349 | Val. Loss: 0.267022 | Val. Kappa Score: 0.8749 | LR: 0.000500 | Estimated time: 64.01
Train loss on 50 batch: 0.072334
Train loss on 100 batch: 0.089212
Train loss on 150 batch: 0.094806
best-train-loss: 0.086483
best-valid-loss: 0.212292
best-kappa: 0.8773
: Epoch: 15 | Training Loss: 0.086483 | Val. Loss: 0.212292 | Val. Kappa Score: 0.8773 | LR: 0.000500 | Estimated time: 64.06
Train loss on 50 batch: 0.077233
Train loss on 100 batch: 0.093389
Train loss on 150 batch: 0.067956
best-train-loss: 0.081314
best-valid-loss: 0.207733
best-kappa: 0.8786
: Epoch: 16 | Training Loss: 0.081314 | Val. Loss: 0.207733 | Val. Kappa Score: 0.8786 | LR: 0.000500 | Estimated time: 64.73
Train loss on 50 batch: 0.077542
Train loss on 100 batch: 0.068898
Train loss on 150 batch: 0.065383
: Epoch: 17 | Training Loss: 0.073257 | Val. Loss: 0.220489 | Val. Kappa Score: 0.8795 | LR: 0.000500 | Estimated time: 62.63
Train loss on 50 batch: 0.078219
Train loss on 100 batch: 0.064994
Train loss on 150 batch: 0.085425
: Epoch: 18 | Training Loss: 0.081901 | Val. Loss: 0.256395 | Val. Kappa Score: 0.8795 | LR: 0.000500 | Estimated time: 64.47
Train loss on 50 batch: 0.067870
Train loss on 100 batch: 0.069751
Train loss on 150 batch: 0.071006
: Epoch: 19 | Training Loss: 0.071234 | Val. Loss: 0.227517 | Val. Kappa Score: 0.8809 | LR: 0.000250 | Estimated time: 66.53
Train loss on 50 batch: 0.056719
Train loss on 100 batch: 0.044233
Train loss on 150 batch: 0.055422
best-train-loss: 0.055154
best-valid-loss: 0.205557
best-kappa: 0.8821
: Epoch: 20 | Training Loss: 0.055154 | Val. Loss: 0.205557 | Val. Kappa Score: 0.8821 | LR: 0.000250 | Estimated time: 65.12
Train loss on 50 batch: 0.049642
Train loss on 100 batch: 0.043721
Train loss on 150 batch: 0.054997
: Epoch: 21 | Training Loss: 0.051039 | Val. Loss: 0.207354 | Val. Kappa Score: 0.8836 | LR: 0.000250 | Estimated time: 64.39
Train loss on 50 batch: 0.039834
Train loss on 100 batch: 0.038759
Train loss on 150 batch: 0.043470
: Epoch: 22 | Training Loss: 0.040169 | Val. Loss: 0.210627 | Val. Kappa Score: 0.8848 | LR: 0.000250 | Estimated time: 63.57
Train loss on 50 batch: 0.043941
Train loss on 100 batch: 0.040096
Train loss on 150 batch: 0.041828
best-train-loss: 0.042960
best-valid-loss: 0.194195
best-kappa: 0.8859
: Epoch: 23 | Training Loss: 0.042960 | Val. Loss: 0.194195 | Val. Kappa Score: 0.8859 | LR: 0.000250 | Estimated time: 62.99
Train loss on 50 batch: 0.038117
Train loss on 100 batch: 0.037208
Train loss on 150 batch: 0.039663
: Epoch: 24 | Training Loss: 0.038693 | Val. Loss: 0.199477 | Val. Kappa Score: 0.8870 | LR: 0.000250 | Estimated time: 63.34
Train loss on 50 batch: 0.028825
Train loss on 100 batch: 0.030602
Train loss on 150 batch: 0.041682
: Epoch: 25 | Training Loss: 0.036115 | Val. Loss: 0.197576 | Val. Kappa Score: 0.8882 | LR: 0.000250 | Estimated time: 63.62
Train loss on 50 batch: 0.042325
Train loss on 100 batch: 0.038597
Train loss on 150 batch: 0.038174
: Epoch: 26 | Training Loss: 0.039139 | Val. Loss: 0.197648 | Val. Kappa Score: 0.8897 | LR: 0.000125 | Estimated time: 63.43
Train loss on 50 batch: 0.026138
Train loss on 100 batch: 0.032371
Train loss on 150 batch: 0.032615
: Epoch: 27 | Training Loss: 0.030429 | Val. Loss: 0.199287 | Val. Kappa Score: 0.8906 | LR: 0.000125 | Estimated time: 63.05
Train loss on 50 batch: 0.032886
Train loss on 100 batch: 0.022103
Train loss on 150 batch: 0.024562
: Epoch: 28 | Training Loss: 0.026878 | Val. Loss: 0.208734 | Val. Kappa Score: 0.8917 | LR: 0.000125 | Estimated time: 63.15
Train loss on 50 batch: 0.030232
Train loss on 100 batch: 0.018860
Train loss on 150 batch: 0.030082
best-train-loss: 0.027764
best-valid-loss: 0.194170
best-kappa: 0.8925
: Epoch: 29 | Training Loss: 0.027764 | Val. Loss: 0.194170 | Val. Kappa Score: 0.8925 | LR: 0.000125 | Estimated time: 63.13
Train loss on 50 batch: 0.030908
Train loss on 100 batch: 0.024687
Train loss on 150 batch: 0.028137
: Epoch: 30 | Training Loss: 0.025820 | Val. Loss: 0.194216 | Val. Kappa Score: 0.8931 | LR: 0.000125 | Estimated time: 63.68
Train loss on 50 batch: 0.024038
Train loss on 100 batch: 0.026834
Train loss on 150 batch: 0.027344
best-train-loss: 0.027366
best-valid-loss: 0.183756
best-kappa: 0.8937
: Epoch: 31 | Training Loss: 0.027366 | Val. Loss: 0.183756 | Val. Kappa Score: 0.8937 | LR: 0.000125 | Estimated time: 63.84
Train loss on 50 batch: 0.029655
Train loss on 100 batch: 0.020307
Train loss on 150 batch: 0.020513
: Epoch: 32 | Training Loss: 0.027653 | Val. Loss: 0.189296 | Val. Kappa Score: 0.8945 | LR: 0.000125 | Estimated time: 64.29
Train loss on 50 batch: 0.022800
Train loss on 100 batch: 0.025370
Train loss on 150 batch: 0.026726
: Epoch: 33 | Training Loss: 0.024527 | Val. Loss: 0.183800 | Val. Kappa Score: 0.8953 | LR: 0.000125 | Estimated time: 64.90
Train loss on 50 batch: 0.021476
Train loss on 100 batch: 0.025409
Train loss on 150 batch: 0.021187
: Epoch: 34 | Training Loss: 0.022206 | Val. Loss: 0.184772 | Val. Kappa Score: 0.8960 | LR: 0.000063 | Estimated time: 65.16
Train loss on 50 batch: 0.026013
Train loss on 100 batch: 0.018199
Train loss on 150 batch: 0.018349
: Epoch: 35 | Training Loss: 0.020412 | Val. Loss: 0.191887 | Val. Kappa Score: 0.8962 | LR: 0.000063 | Estimated time: 65.16
Train loss on 50 batch: 0.018733
Train loss on 100 batch: 0.020951
Train loss on 150 batch: 0.021057
: Epoch: 36 | Training Loss: 0.019399 | Val. Loss: 0.186366 | Val. Kappa Score: 0.8964 | LR: 0.000063 | Estimated time: 63.70
Train loss on 50 batch: 0.017584
Train loss on 100 batch: 0.017169
Train loss on 150 batch: 0.021813
: Epoch: 37 | Training Loss: 0.020352 | Val. Loss: 0.187323 | Val. Kappa Score: 0.8966 | LR: 0.000031 | Estimated time: 64.67
Train loss on 50 batch: 0.019736
Train loss on 100 batch: 0.016524
Train loss on 150 batch: 0.017643
: Epoch: 38 | Training Loss: 0.017321 | Val. Loss: 0.185832 | Val. Kappa Score: 0.8970 | LR: 0.000031 | Estimated time: 64.63
Train loss on 50 batch: 0.018649
Train loss on 100 batch: 0.018378
Train loss on 150 batch: 0.016269
: Epoch: 39 | Training Loss: 0.018154 | Val. Loss: 0.193323 | Val. Kappa Score: 0.8973 | LR: 0.000031 | Estimated time: 64.13
Train loss on 50 batch: 0.023155
Train loss on 100 batch: 0.016767
Train loss on 150 batch: 0.013787
: Epoch: 40 | Training Loss: 0.017563 | Val. Loss: 0.190826 | Val. Kappa Score: 0.8973 | LR: 0.000016 | Estimated time: 64.00
Train loss on 50 batch: 0.014280
Train loss on 100 batch: 0.018806
Train loss on 150 batch: 0.020718
: Epoch: 41 | Training Loss: 0.018206 | Val. Loss: 0.193225 | Val. Kappa Score: 0.8976 | LR: 0.000016 | Estimated time: 64.54
time_estimated: 2618.73
n-epochs: 41
time_estimated: 2618.77
----------------------------------------

Experiment N: 140: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 11:48:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d939898>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.932331
Train loss on 100 batch: 0.640693
Train loss on 150 batch: 0.523714
best-train-loss: 0.620065
best-valid-loss: 0.322257
best-kappa: 0.8906
: Epoch: 1 | Training Loss: 0.620065 | Val. Loss: 0.322257 | Val. Kappa Score: 0.8906 | LR: 0.001000 | Estimated time: 64.45
Train loss on 50 batch: 0.402728
Train loss on 100 batch: 0.390741
Train loss on 150 batch: 0.529615
best-train-loss: 0.431411
best-valid-loss: 0.311601
best-kappa: 0.8851
: Epoch: 2 | Training Loss: 0.431411 | Val. Loss: 0.311601 | Val. Kappa Score: 0.8851 | LR: 0.001000 | Estimated time: 63.19
Train loss on 50 batch: 0.333923
Train loss on 100 batch: 0.412466
Train loss on 150 batch: 0.411101
: Epoch: 3 | Training Loss: 0.374611 | Val. Loss: 0.337701 | Val. Kappa Score: 0.8853 | LR: 0.001000 | Estimated time: 63.29
Train loss on 50 batch: 0.285263
Train loss on 100 batch: 0.312468
Train loss on 150 batch: 0.372141
: Epoch: 4 | Training Loss: 0.318501 | Val. Loss: 0.610783 | Val. Kappa Score: 0.8761 | LR: 0.001000 | Estimated time: 64.67
Train loss on 50 batch: 0.270527
Train loss on 100 batch: 0.358415
Train loss on 150 batch: 0.323065
: Epoch: 5 | Training Loss: 0.324670 | Val. Loss: 0.326320 | Val. Kappa Score: 0.8759 | LR: 0.000500 | Estimated time: 63.90
Train loss on 50 batch: 0.259766
Train loss on 100 batch: 0.214235
Train loss on 150 batch: 0.259655
best-train-loss: 0.246766
best-valid-loss: 0.261358
best-kappa: 0.8795
: Epoch: 6 | Training Loss: 0.246766 | Val. Loss: 0.261358 | Val. Kappa Score: 0.8795 | LR: 0.000500 | Estimated time: 65.76
Train loss on 50 batch: 0.169587
Train loss on 100 batch: 0.224819
Train loss on 150 batch: 0.192508
best-train-loss: 0.200273
best-valid-loss: 0.248151
best-kappa: 0.8812
: Epoch: 7 | Training Loss: 0.200273 | Val. Loss: 0.248151 | Val. Kappa Score: 0.8812 | LR: 0.000500 | Estimated time: 65.81
Train loss on 50 batch: 0.176676
Train loss on 100 batch: 0.204862
Train loss on 150 batch: 0.163894
: Epoch: 8 | Training Loss: 0.184865 | Val. Loss: 0.359957 | Val. Kappa Score: 0.8780 | LR: 0.000500 | Estimated time: 69.03
Train loss on 50 batch: 0.136223
Train loss on 100 batch: 0.182770
Train loss on 150 batch: 0.145358
: Epoch: 9 | Training Loss: 0.161050 | Val. Loss: 0.271221 | Val. Kappa Score: 0.8790 | LR: 0.000500 | Estimated time: 66.62
Train loss on 50 batch: 0.128139
Train loss on 100 batch: 0.131431
Train loss on 150 batch: 0.190871
: Epoch: 10 | Training Loss: 0.152017 | Val. Loss: 0.249338 | Val. Kappa Score: 0.8793 | LR: 0.000250 | Estimated time: 64.53
Train loss on 50 batch: 0.139983
Train loss on 100 batch: 0.094910
Train loss on 150 batch: 0.117567
best-train-loss: 0.112708
best-valid-loss: 0.234658
best-kappa: 0.8818
: Epoch: 11 | Training Loss: 0.112708 | Val. Loss: 0.234658 | Val. Kappa Score: 0.8818 | LR: 0.000250 | Estimated time: 62.82
Train loss on 50 batch: 0.084044
Train loss on 100 batch: 0.101187
Train loss on 150 batch: 0.083513
: Epoch: 12 | Training Loss: 0.090674 | Val. Loss: 0.237191 | Val. Kappa Score: 0.8826 | LR: 0.000250 | Estimated time: 65.39
Train loss on 50 batch: 0.080754
Train loss on 100 batch: 0.077764
Train loss on 150 batch: 0.078321
best-train-loss: 0.081830
best-valid-loss: 0.218921
best-kappa: 0.8836
: Epoch: 13 | Training Loss: 0.081830 | Val. Loss: 0.218921 | Val. Kappa Score: 0.8836 | LR: 0.000250 | Estimated time: 63.64
Train loss on 50 batch: 0.072054
Train loss on 100 batch: 0.083819
Train loss on 150 batch: 0.073027
best-train-loss: 0.078076
best-valid-loss: 0.218393
best-kappa: 0.8855
: Epoch: 14 | Training Loss: 0.078076 | Val. Loss: 0.218393 | Val. Kappa Score: 0.8855 | LR: 0.000250 | Estimated time: 64.40
Train loss on 50 batch: 0.064702
Train loss on 100 batch: 0.091849
Train loss on 150 batch: 0.090763
: Epoch: 15 | Training Loss: 0.081302 | Val. Loss: 0.245124 | Val. Kappa Score: 0.8863 | LR: 0.000250 | Estimated time: 63.68
Train loss on 50 batch: 0.066167
Train loss on 100 batch: 0.076307
Train loss on 150 batch: 0.054459
: Epoch: 16 | Training Loss: 0.068718 | Val. Loss: 0.224574 | Val. Kappa Score: 0.8867 | LR: 0.000250 | Estimated time: 64.22
Train loss on 50 batch: 0.070294
Train loss on 100 batch: 0.061681
Train loss on 150 batch: 0.061957
: Epoch: 17 | Training Loss: 0.066360 | Val. Loss: 0.238332 | Val. Kappa Score: 0.8870 | LR: 0.000125 | Estimated time: 63.63
Train loss on 50 batch: 0.053667
Train loss on 100 batch: 0.055993
Train loss on 150 batch: 0.049832
: Epoch: 18 | Training Loss: 0.054265 | Val. Loss: 0.227815 | Val. Kappa Score: 0.8874 | LR: 0.000125 | Estimated time: 64.09
Train loss on 50 batch: 0.050699
Train loss on 100 batch: 0.056011
Train loss on 150 batch: 0.043984
: Epoch: 19 | Training Loss: 0.052361 | Val. Loss: 0.221066 | Val. Kappa Score: 0.8882 | LR: 0.000125 | Estimated time: 63.62
Train loss on 50 batch: 0.048549
Train loss on 100 batch: 0.039850
Train loss on 150 batch: 0.046367
best-train-loss: 0.044465
best-valid-loss: 0.207913
best-kappa: 0.8886
: Epoch: 20 | Training Loss: 0.044465 | Val. Loss: 0.207913 | Val. Kappa Score: 0.8886 | LR: 0.000125 | Estimated time: 63.35
Train loss on 50 batch: 0.039553
Train loss on 100 batch: 0.041957
Train loss on 150 batch: 0.055351
: Epoch: 21 | Training Loss: 0.048139 | Val. Loss: 0.219634 | Val. Kappa Score: 0.8900 | LR: 0.000125 | Estimated time: 63.83
Train loss on 50 batch: 0.035761
Train loss on 100 batch: 0.045024
Train loss on 150 batch: 0.037053
: Epoch: 22 | Training Loss: 0.040887 | Val. Loss: 0.209714 | Val. Kappa Score: 0.8904 | LR: 0.000125 | Estimated time: 64.18
Train loss on 50 batch: 0.041564
Train loss on 100 batch: 0.040877
Train loss on 150 batch: 0.047960
: Epoch: 23 | Training Loss: 0.044271 | Val. Loss: 0.221432 | Val. Kappa Score: 0.8911 | LR: 0.000063 | Estimated time: 63.48
Train loss on 50 batch: 0.031304
Train loss on 100 batch: 0.035488
Train loss on 150 batch: 0.034229
: Epoch: 24 | Training Loss: 0.034883 | Val. Loss: 0.215928 | Val. Kappa Score: 0.8914 | LR: 0.000063 | Estimated time: 63.40
Train loss on 50 batch: 0.033279
Train loss on 100 batch: 0.033044
Train loss on 150 batch: 0.036914
: Epoch: 25 | Training Loss: 0.033746 | Val. Loss: 0.212823 | Val. Kappa Score: 0.8917 | LR: 0.000063 | Estimated time: 64.86
Train loss on 50 batch: 0.031951
Train loss on 100 batch: 0.030157
Train loss on 150 batch: 0.035842
: Epoch: 26 | Training Loss: 0.032525 | Val. Loss: 0.221648 | Val. Kappa Score: 0.8926 | LR: 0.000031 | Estimated time: 64.47
Train loss on 50 batch: 0.029740
Train loss on 100 batch: 0.035055
Train loss on 150 batch: 0.035866
: Epoch: 27 | Training Loss: 0.032592 | Val. Loss: 0.223498 | Val. Kappa Score: 0.8931 | LR: 0.000031 | Estimated time: 63.20
Train loss on 50 batch: 0.034098
Train loss on 100 batch: 0.025480
Train loss on 150 batch: 0.034851
: Epoch: 28 | Training Loss: 0.031979 | Val. Loss: 0.217349 | Val. Kappa Score: 0.8936 | LR: 0.000031 | Estimated time: 63.36
Train loss on 50 batch: 0.031786
Train loss on 100 batch: 0.029963
Train loss on 150 batch: 0.034767
: Epoch: 29 | Training Loss: 0.031415 | Val. Loss: 0.212591 | Val. Kappa Score: 0.8941 | LR: 0.000016 | Estimated time: 64.04
Train loss on 50 batch: 0.032078
Train loss on 100 batch: 0.031242
Train loss on 150 batch: 0.034493
: Epoch: 30 | Training Loss: 0.029864 | Val. Loss: 0.216179 | Val. Kappa Score: 0.8946 | LR: 0.000016 | Estimated time: 64.47
time_estimated: 1930.82
n-epochs: 30
time_estimated: 1930.85
----------------------------------------

Experiment N: 141: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.25 18:27:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a908>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.403056
Train loss on 100 batch: 0.370573
Train loss on 150 batch: 0.317152
best-train-loss: 0.342453
best-valid-loss: 0.380269
best-kappa: 0.8340
: Epoch: 1 | Training Loss: 0.342453 | Val. Loss: 0.380269 | Val. Kappa Score: 0.8340 | LR: 0.001000 | Estimated time: 63.81
Train loss on 50 batch: 0.318992
Train loss on 100 batch: 0.246415
Train loss on 150 batch: 0.339725
best-train-loss: 0.292840
best-valid-loss: 0.229201
best-kappa: 0.8683
: Epoch: 2 | Training Loss: 0.292840 | Val. Loss: 0.229201 | Val. Kappa Score: 0.8683 | LR: 0.001000 | Estimated time: 63.22
Train loss on 50 batch: 0.277129
Train loss on 100 batch: 0.306344
Train loss on 150 batch: 0.278949
: Epoch: 3 | Training Loss: 0.280041 | Val. Loss: 0.337361 | Val. Kappa Score: 0.8748 | LR: 0.001000 | Estimated time: 63.24
Train loss on 50 batch: 0.245246
Train loss on 100 batch: 0.296167
Train loss on 150 batch: 0.284759
best-train-loss: 0.263583
best-valid-loss: 0.211868
best-kappa: 0.8841
: Epoch: 4 | Training Loss: 0.263583 | Val. Loss: 0.211868 | Val. Kappa Score: 0.8841 | LR: 0.001000 | Estimated time: 63.10
Train loss on 50 batch: 0.236281
Train loss on 100 batch: 0.280310
Train loss on 150 batch: 0.237249
: Epoch: 5 | Training Loss: 0.263098 | Val. Loss: 0.327426 | Val. Kappa Score: 0.8833 | LR: 0.001000 | Estimated time: 63.42
Train loss on 50 batch: 0.229561
Train loss on 100 batch: 0.221923
Train loss on 150 batch: 0.264705
: Epoch: 6 | Training Loss: 0.247925 | Val. Loss: 0.739552 | Val. Kappa Score: 0.8586 | LR: 0.001000 | Estimated time: 63.80
Train loss on 50 batch: 0.218953
Train loss on 100 batch: 0.251918
Train loss on 150 batch: 0.230666
: Epoch: 7 | Training Loss: 0.235103 | Val. Loss: 0.317753 | Val. Kappa Score: 0.8613 | LR: 0.000500 | Estimated time: 63.45
Train loss on 50 batch: 0.247023
Train loss on 100 batch: 0.228226
Train loss on 150 batch: 0.194382
: Epoch: 8 | Training Loss: 0.225406 | Val. Loss: 0.250070 | Val. Kappa Score: 0.8665 | LR: 0.000500 | Estimated time: 63.51
Train loss on 50 batch: 0.184236
Train loss on 100 batch: 0.239655
Train loss on 150 batch: 0.200175
: Epoch: 9 | Training Loss: 0.216794 | Val. Loss: 0.308382 | Val. Kappa Score: 0.8680 | LR: 0.000500 | Estimated time: 63.06
Train loss on 50 batch: 0.209529
Train loss on 100 batch: 0.254634
Train loss on 150 batch: 0.227519
best-train-loss: 0.220514
best-valid-loss: 0.209989
best-kappa: 0.8719
: Epoch: 10 | Training Loss: 0.220514 | Val. Loss: 0.209989 | Val. Kappa Score: 0.8719 | LR: 0.000500 | Estimated time: 63.09
Train loss on 50 batch: 0.234620
Train loss on 100 batch: 0.178512
Train loss on 150 batch: 0.244864
: Epoch: 11 | Training Loss: 0.204049 | Val. Loss: 0.264310 | Val. Kappa Score: 0.8744 | LR: 0.000500 | Estimated time: 62.37
Train loss on 50 batch: 0.198774
Train loss on 100 batch: 0.188560
Train loss on 150 batch: 0.183336
: Epoch: 12 | Training Loss: 0.197242 | Val. Loss: 0.221675 | Val. Kappa Score: 0.8763 | LR: 0.000500 | Estimated time: 62.69
Train loss on 50 batch: 0.180190
Train loss on 100 batch: 0.188420
Train loss on 150 batch: 0.215089
: Epoch: 13 | Training Loss: 0.199799 | Val. Loss: 0.215835 | Val. Kappa Score: 0.8783 | LR: 0.000250 | Estimated time: 62.47
Train loss on 50 batch: 0.182844
Train loss on 100 batch: 0.207577
Train loss on 150 batch: 0.147573
: Epoch: 14 | Training Loss: 0.188881 | Val. Loss: 0.218322 | Val. Kappa Score: 0.8802 | LR: 0.000250 | Estimated time: 62.66
Train loss on 50 batch: 0.164054
Train loss on 100 batch: 0.216595
Train loss on 150 batch: 0.203450
: Epoch: 15 | Training Loss: 0.190354 | Val. Loss: 0.214203 | Val. Kappa Score: 0.8820 | LR: 0.000250 | Estimated time: 62.65
Train loss on 50 batch: 0.209312
Train loss on 100 batch: 0.190435
Train loss on 150 batch: 0.177263
: Epoch: 16 | Training Loss: 0.181189 | Val. Loss: 0.213899 | Val. Kappa Score: 0.8835 | LR: 0.000125 | Estimated time: 63.83
Train loss on 50 batch: 0.143993
Train loss on 100 batch: 0.170277
Train loss on 150 batch: 0.182097
: Epoch: 17 | Training Loss: 0.169508 | Val. Loss: 0.222517 | Val. Kappa Score: 0.8839 | LR: 0.000125 | Estimated time: 63.60
Train loss on 50 batch: 0.148611
Train loss on 100 batch: 0.179957
Train loss on 150 batch: 0.194892
best-train-loss: 0.174856
best-valid-loss: 0.209631
best-kappa: 0.8844
: Epoch: 18 | Training Loss: 0.174856 | Val. Loss: 0.209631 | Val. Kappa Score: 0.8844 | LR: 0.000125 | Estimated time: 63.05
Train loss on 50 batch: 0.154942
Train loss on 100 batch: 0.196012
Train loss on 150 batch: 0.160606
: Epoch: 19 | Training Loss: 0.169038 | Val. Loss: 0.211948 | Val. Kappa Score: 0.8856 | LR: 0.000125 | Estimated time: 63.30
Train loss on 50 batch: 0.138103
Train loss on 100 batch: 0.167423
Train loss on 150 batch: 0.182233
: Epoch: 20 | Training Loss: 0.195931 | Val. Loss: 0.220676 | Val. Kappa Score: 0.8864 | LR: 0.000125 | Estimated time: 63.52
Train loss on 50 batch: 0.159117
Train loss on 100 batch: 0.183051
Train loss on 150 batch: 0.143426
: Epoch: 21 | Training Loss: 0.160755 | Val. Loss: 0.237185 | Val. Kappa Score: 0.8871 | LR: 0.000063 | Estimated time: 63.63
Train loss on 50 batch: 0.109685
Train loss on 100 batch: 0.197620
Train loss on 150 batch: 0.179048
: Epoch: 22 | Training Loss: 0.161163 | Val. Loss: 0.215405 | Val. Kappa Score: 0.8880 | LR: 0.000063 | Estimated time: 62.74
Train loss on 50 batch: 0.151578
Train loss on 100 batch: 0.155420
Train loss on 150 batch: 0.159512
: Epoch: 23 | Training Loss: 0.170831 | Val. Loss: 0.215717 | Val. Kappa Score: 0.8885 | LR: 0.000063 | Estimated time: 63.38
Train loss on 50 batch: 0.162857
Train loss on 100 batch: 0.156669
Train loss on 150 batch: 0.164793
: Epoch: 24 | Training Loss: 0.170072 | Val. Loss: 0.213076 | Val. Kappa Score: 0.8895 | LR: 0.000031 | Estimated time: 62.33
Train loss on 50 batch: 0.150600
Train loss on 100 batch: 0.164070
Train loss on 150 batch: 0.156792
: Epoch: 25 | Training Loss: 0.154548 | Val. Loss: 0.211548 | Val. Kappa Score: 0.8895 | LR: 0.000031 | Estimated time: 63.15
Train loss on 50 batch: 0.115878
Train loss on 100 batch: 0.173901
Train loss on 150 batch: 0.206918
: Epoch: 26 | Training Loss: 0.161665 | Val. Loss: 0.214190 | Val. Kappa Score: 0.8902 | LR: 0.000031 | Estimated time: 63.36
Train loss on 50 batch: 0.161550
Train loss on 100 batch: 0.166356
Train loss on 150 batch: 0.164833
: Epoch: 27 | Training Loss: 0.196247 | Val. Loss: 0.212490 | Val. Kappa Score: 0.8912 | LR: 0.000016 | Estimated time: 63.02
Train loss on 50 batch: 0.162915
Train loss on 100 batch: 0.142169
Train loss on 150 batch: 0.173203
: Epoch: 28 | Training Loss: 0.168417 | Val. Loss: 0.214340 | Val. Kappa Score: 0.8917 | LR: 0.000016 | Estimated time: 62.66
time_estimated: 1769.33
n-epochs: 28
time_estimated: 1769.37
----------------------------------------

Experiment N: 142: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.26 00:45:22
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109860>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.801881
Train loss on 100 batch: 0.647181
----------------------------------------

Experiment N: 142: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.26 00:46:17
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109630>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.664139
Train loss on 100 batch: 1.050660
Train loss on 150 batch: 0.853514
Train loss on 200 batch: 0.792256
Train loss on 250 batch: 0.745564
best-train-loss: 0.994072
best-valid-loss: 0.666810
best-kappa: 0.7911
: Epoch: 1 | Training Loss: 0.994072 | Val. Loss: 0.666810 | Val. Kappa Score: 0.7911 | LR: 0.001000 | Estimated time: 80.96
Train loss on 50 batch: 0.696306
Train loss on 100 batch: 0.571227
Train loss on 150 batch: 0.710348
Train loss on 200 batch: 0.659950
Train loss on 250 batch: 0.576166
: Epoch: 2 | Training Loss: 0.635187 | Val. Loss: 0.772289 | Val. Kappa Score: 0.7898 | LR: 0.001000 | Estimated time: 80.49
Train loss on 50 batch: 0.614183
Train loss on 100 batch: 0.532646
Train loss on 150 batch: 0.637145
Train loss on 200 batch: 0.644060
Train loss on 250 batch: 0.558306
best-train-loss: 0.586527
best-valid-loss: 0.518745
best-kappa: 0.7966
: Epoch: 3 | Training Loss: 0.586527 | Val. Loss: 0.518745 | Val. Kappa Score: 0.7966 | LR: 0.001000 | Estimated time: 80.39
Train loss on 50 batch: 0.536509
Train loss on 100 batch: 0.513049
Train loss on 150 batch: 0.538220
Train loss on 200 batch: 0.649409
Train loss on 250 batch: 0.491088
: Epoch: 4 | Training Loss: 0.526817 | Val. Loss: 0.570782 | Val. Kappa Score: 0.8029 | LR: 0.001000 | Estimated time: 80.16
Train loss on 50 batch: 0.473878
Train loss on 100 batch: 0.506948
Train loss on 150 batch: 0.487842
Train loss on 200 batch: 0.408345
Train loss on 250 batch: 0.477818
best-train-loss: 0.473776
best-valid-loss: 0.480172
best-kappa: 0.8071
: Epoch: 5 | Training Loss: 0.473776 | Val. Loss: 0.480172 | Val. Kappa Score: 0.8071 | LR: 0.001000 | Estimated time: 80.33
Train loss on 50 batch: 0.392196
Train loss on 100 batch: 0.451847
Train loss on 150 batch: 0.523878
Train loss on 200 batch: 0.453456
Train loss on 250 batch: 0.463220
best-train-loss: 0.470606
best-valid-loss: 0.464069
best-kappa: 0.8095
: Epoch: 6 | Training Loss: 0.470606 | Val. Loss: 0.464069 | Val. Kappa Score: 0.8095 | LR: 0.001000 | Estimated time: 79.34
Train loss on 50 batch: 0.403696
Train loss on 100 batch: 0.425507
Train loss on 150 batch: 0.430736
Train loss on 200 batch: 0.493651
Train loss on 250 batch: 0.535815
best-train-loss: 0.465596
best-valid-loss: 0.406882
best-kappa: 0.8166
: Epoch: 7 | Training Loss: 0.465596 | Val. Loss: 0.406882 | Val. Kappa Score: 0.8166 | LR: 0.001000 | Estimated time: 78.93
Train loss on 50 batch: 0.375870
Train loss on 100 batch: 0.375708
Train loss on 150 batch: 0.308340
Train loss on 200 batch: 0.426086
Train loss on 250 batch: 0.449874
: Epoch: 8 | Training Loss: 0.396592 | Val. Loss: 0.407509 | Val. Kappa Score: 0.8218 | LR: 0.001000 | Estimated time: 78.93
Train loss on 50 batch: 0.374291
Train loss on 100 batch: 0.398824
Train loss on 150 batch: 0.450695
Train loss on 200 batch: 0.450022
Train loss on 250 batch: 0.396062
: Epoch: 9 | Training Loss: 0.422973 | Val. Loss: 0.519880 | Val. Kappa Score: 0.8234 | LR: 0.001000 | Estimated time: 78.96
Train loss on 50 batch: 0.314236
Train loss on 100 batch: 0.431350
Train loss on 150 batch: 0.331941
Train loss on 200 batch: 0.483635
Train loss on 250 batch: 0.417600
: Epoch: 10 | Training Loss: 0.404309 | Val. Loss: 0.475450 | Val. Kappa Score: 0.8245 | LR: 0.000500 | Estimated time: 78.87
Train loss on 50 batch: 0.303549
Train loss on 100 batch: 0.325637
Train loss on 150 batch: 0.269594
Train loss on 200 batch: 0.292937
Train loss on 250 batch: 0.282198
best-train-loss: 0.292008
best-valid-loss: 0.360730
best-kappa: 0.8286
: Epoch: 11 | Training Loss: 0.292008 | Val. Loss: 0.360730 | Val. Kappa Score: 0.8286 | LR: 0.000500 | Estimated time: 79.44
Train loss on 50 batch: 0.217975
Train loss on 100 batch: 0.220706
Train loss on 150 batch: 0.258227
Train loss on 200 batch: 0.254309
Train loss on 250 batch: 0.233741
: Epoch: 12 | Training Loss: 0.238461 | Val. Loss: 0.362907 | Val. Kappa Score: 0.8320 | LR: 0.000500 | Estimated time: 79.28
Train loss on 50 batch: 0.215332
Train loss on 100 batch: 0.202812
Train loss on 150 batch: 0.244469
Train loss on 200 batch: 0.201765
Train loss on 250 batch: 0.254818
: Epoch: 13 | Training Loss: 0.222344 | Val. Loss: 0.384031 | Val. Kappa Score: 0.8346 | LR: 0.000500 | Estimated time: 78.55
Train loss on 50 batch: 0.183317
Train loss on 100 batch: 0.212838
Train loss on 150 batch: 0.197337
Train loss on 200 batch: 0.205321
Train loss on 250 batch: 0.208448
: Epoch: 14 | Training Loss: 0.203429 | Val. Loss: 0.419030 | Val. Kappa Score: 0.8359 | LR: 0.000250 | Estimated time: 79.30
Train loss on 50 batch: 0.169717
Train loss on 100 batch: 0.154310
Train loss on 150 batch: 0.175950
Train loss on 200 batch: 0.144920
Train loss on 250 batch: 0.194577
: Epoch: 15 | Training Loss: 0.168663 | Val. Loss: 0.373141 | Val. Kappa Score: 0.8370 | LR: 0.000250 | Estimated time: 78.72
Train loss on 50 batch: 0.114323
Train loss on 100 batch: 0.125788
Train loss on 150 batch: 0.153582
Train loss on 200 batch: 0.147362
Train loss on 250 batch: 0.145874
best-train-loss: 0.142031
best-valid-loss: 0.346868
best-kappa: 0.8401
: Epoch: 16 | Training Loss: 0.142031 | Val. Loss: 0.346868 | Val. Kappa Score: 0.8401 | LR: 0.000250 | Estimated time: 79.62
Train loss on 50 batch: 0.133419
Train loss on 100 batch: 0.140420
Train loss on 150 batch: 0.126391
Train loss on 200 batch: 0.129939
Train loss on 250 batch: 0.109726
best-train-loss: 0.129025
best-valid-loss: 0.343766
best-kappa: 0.8428
: Epoch: 17 | Training Loss: 0.129025 | Val. Loss: 0.343766 | Val. Kappa Score: 0.8428 | LR: 0.000250 | Estimated time: 78.55
Train loss on 50 batch: 0.100290
Train loss on 100 batch: 0.118745
Train loss on 150 batch: 0.111142
Train loss on 200 batch: 0.101967
Train loss on 250 batch: 0.139077
: Epoch: 18 | Training Loss: 0.140107 | Val. Loss: 0.344477 | Val. Kappa Score: 0.8451 | LR: 0.000250 | Estimated time: 78.57
Train loss on 50 batch: 0.127495
Train loss on 100 batch: 0.103752
Train loss on 150 batch: 0.117621
Train loss on 200 batch: 0.129681
Train loss on 250 batch: 0.133125
best-train-loss: 0.122141
best-valid-loss: 0.335362
best-kappa: 0.8466
: Epoch: 19 | Training Loss: 0.122141 | Val. Loss: 0.335362 | Val. Kappa Score: 0.8466 | LR: 0.000250 | Estimated time: 78.91
Train loss on 50 batch: 0.104906
Train loss on 100 batch: 0.095142
Train loss on 150 batch: 0.117627
Train loss on 200 batch: 0.111070
Train loss on 250 batch: 0.107253
: Epoch: 20 | Training Loss: 0.106410 | Val. Loss: 0.339109 | Val. Kappa Score: 0.8486 | LR: 0.000250 | Estimated time: 79.00
Train loss on 50 batch: 0.092653
Train loss on 100 batch: 0.088861
Train loss on 150 batch: 0.091439
Train loss on 200 batch: 0.112706
Train loss on 250 batch: 0.108423
: Epoch: 21 | Training Loss: 0.100636 | Val. Loss: 0.358064 | Val. Kappa Score: 0.8499 | LR: 0.000250 | Estimated time: 78.24
Train loss on 50 batch: 0.080177
Train loss on 100 batch: 0.111307
Train loss on 150 batch: 0.114908
Train loss on 200 batch: 0.091491
Train loss on 250 batch: 0.101386
: Epoch: 22 | Training Loss: 0.096773 | Val. Loss: 0.349805 | Val. Kappa Score: 0.8507 | LR: 0.000125 | Estimated time: 79.14
Train loss on 50 batch: 0.099707
Train loss on 100 batch: 0.098049
Train loss on 150 batch: 0.076879
Train loss on 200 batch: 0.077888
Train loss on 250 batch: 0.085494
: Epoch: 23 | Training Loss: 0.092249 | Val. Loss: 0.353652 | Val. Kappa Score: 0.8518 | LR: 0.000125 | Estimated time: 79.78
Train loss on 50 batch: 0.073611
Train loss on 100 batch: 0.067994
Train loss on 150 batch: 0.077953
Train loss on 200 batch: 0.076238
Train loss on 250 batch: 0.071263
best-train-loss: 0.074033
best-valid-loss: 0.323204
best-kappa: 0.8533
: Epoch: 24 | Training Loss: 0.074033 | Val. Loss: 0.323204 | Val. Kappa Score: 0.8533 | LR: 0.000125 | Estimated time: 78.75
Train loss on 50 batch: 0.065958
Train loss on 100 batch: 0.058724
Train loss on 150 batch: 0.088175
Train loss on 200 batch: 0.079291
Train loss on 250 batch: 0.070741
best-train-loss: 0.070620
best-valid-loss: 0.318565
best-kappa: 0.8548
: Epoch: 25 | Training Loss: 0.070620 | Val. Loss: 0.318565 | Val. Kappa Score: 0.8548 | LR: 0.000125 | Estimated time: 79.31
Train loss on 50 batch: 0.056019
Train loss on 100 batch: 0.069159
Train loss on 150 batch: 0.066892
Train loss on 200 batch: 0.064499
Train loss on 250 batch: 0.080871
: Epoch: 26 | Training Loss: 0.069909 | Val. Loss: 0.325774 | Val. Kappa Score: 0.8562 | LR: 0.000125 | Estimated time: 78.70
Train loss on 50 batch: 0.053516
Train loss on 100 batch: 0.074687
Train loss on 150 batch: 0.072126
Train loss on 200 batch: 0.059688
Train loss on 250 batch: 0.060682
: Epoch: 27 | Training Loss: 0.063689 | Val. Loss: 0.332405 | Val. Kappa Score: 0.8572 | LR: 0.000125 | Estimated time: 79.06
Train loss on 50 batch: 0.060047
Train loss on 100 batch: 0.060480
Train loss on 150 batch: 0.066117
Train loss on 200 batch: 0.064438
Train loss on 250 batch: 0.072119
: Epoch: 28 | Training Loss: 0.066247 | Val. Loss: 0.340212 | Val. Kappa Score: 0.8577 | LR: 0.000063 | Estimated time: 80.02
Train loss on 50 batch: 0.064189
Train loss on 100 batch: 0.067239
Train loss on 150 batch: 0.056849
Train loss on 200 batch: 0.057453
Train loss on 250 batch: 0.048484
: Epoch: 29 | Training Loss: 0.061133 | Val. Loss: 0.322393 | Val. Kappa Score: 0.8589 | LR: 0.000063 | Estimated time: 78.59
Train loss on 50 batch: 0.059671
Train loss on 100 batch: 0.056297
Train loss on 150 batch: 0.044586
Train loss on 200 batch: 0.045741
Train loss on 250 batch: 0.058902
best-train-loss: 0.051843
best-valid-loss: 0.313890
best-kappa: 0.8599
: Epoch: 30 | Training Loss: 0.051843 | Val. Loss: 0.313890 | Val. Kappa Score: 0.8599 | LR: 0.000063 | Estimated time: 79.15
Train loss on 50 batch: 0.049232
Train loss on 100 batch: 0.061772
Train loss on 150 batch: 0.047947
Train loss on 200 batch: 0.050662
Train loss on 250 batch: 0.056059
: Epoch: 31 | Training Loss: 0.054848 | Val. Loss: 0.318484 | Val. Kappa Score: 0.8608 | LR: 0.000063 | Estimated time: 78.90
Train loss on 50 batch: 0.053176
Train loss on 100 batch: 0.052292
Train loss on 150 batch: 0.048078
Train loss on 200 batch: 0.051858
Train loss on 250 batch: 0.050639
: Epoch: 32 | Training Loss: 0.052444 | Val. Loss: 0.314833 | Val. Kappa Score: 0.8619 | LR: 0.000063 | Estimated time: 78.90
Train loss on 50 batch: 0.047607
Train loss on 100 batch: 0.047281
Train loss on 150 batch: 0.048373
Train loss on 200 batch: 0.058099
Train loss on 250 batch: 0.056773
: Epoch: 33 | Training Loss: 0.054775 | Val. Loss: 0.325224 | Val. Kappa Score: 0.8625 | LR: 0.000031 | Estimated time: 79.16
Train loss on 50 batch: 0.044565
Train loss on 100 batch: 0.038993
Train loss on 150 batch: 0.053574
Train loss on 200 batch: 0.046642
Train loss on 250 batch: 0.047367
: Epoch: 34 | Training Loss: 0.048224 | Val. Loss: 0.315631 | Val. Kappa Score: 0.8633 | LR: 0.000031 | Estimated time: 79.08
Train loss on 50 batch: 0.045634
Train loss on 100 batch: 0.038737
Train loss on 150 batch: 0.045942
Train loss on 200 batch: 0.047458
Train loss on 250 batch: 0.042134
best-train-loss: 0.046739
best-valid-loss: 0.313247
best-kappa: 0.8638
: Epoch: 35 | Training Loss: 0.046739 | Val. Loss: 0.313247 | Val. Kappa Score: 0.8638 | LR: 0.000031 | Estimated time: 78.94
Train loss on 50 batch: 0.040661
Train loss on 100 batch: 0.059109
Train loss on 150 batch: 0.042541
Train loss on 200 batch: 0.049084
Train loss on 250 batch: 0.049876
: Epoch: 36 | Training Loss: 0.048353 | Val. Loss: 0.315968 | Val. Kappa Score: 0.8644 | LR: 0.000031 | Estimated time: 79.26
Train loss on 50 batch: 0.052800
Train loss on 100 batch: 0.046752
Train loss on 150 batch: 0.044382
Train loss on 200 batch: 0.047707
Train loss on 250 batch: 0.038773
: Epoch: 37 | Training Loss: 0.045491 | Val. Loss: 0.314543 | Val. Kappa Score: 0.8653 | LR: 0.000031 | Estimated time: 79.26
Train loss on 50 batch: 0.046264
Train loss on 100 batch: 0.043273
Train loss on 150 batch: 0.038353
Train loss on 200 batch: 0.040085
Train loss on 250 batch: 0.043564
: Epoch: 38 | Training Loss: 0.042261 | Val. Loss: 0.314399 | Val. Kappa Score: 0.8660 | LR: 0.000016 | Estimated time: 79.61
Train loss on 50 batch: 0.038672
Train loss on 100 batch: 0.042122
Train loss on 150 batch: 0.041954
Train loss on 200 batch: 0.038266
Train loss on 250 batch: 0.039430
: Epoch: 39 | Training Loss: 0.040063 | Val. Loss: 0.316018 | Val. Kappa Score: 0.8666 | LR: 0.000016 | Estimated time: 78.96
Train loss on 50 batch: 0.036326
Train loss on 100 batch: 0.048712
Train loss on 150 batch: 0.039690
Train loss on 200 batch: 0.043388
Train loss on 250 batch: 0.043484
: Epoch: 40 | Training Loss: 0.045464 | Val. Loss: 0.314000 | Val. Kappa Score: 0.8672 | LR: 0.000016 | Estimated time: 78.87
Train loss on 50 batch: 0.044127
Train loss on 100 batch: 0.036136
Train loss on 150 batch: 0.041501
Train loss on 200 batch: 0.043828
Train loss on 250 batch: 0.045055
: Epoch: 41 | Training Loss: 0.041731 | Val. Loss: 0.313873 | Val. Kappa Score: 0.8679 | LR: 0.000008 | Estimated time: 78.40
Train loss on 50 batch: 0.039405
Train loss on 100 batch: 0.039946
Train loss on 150 batch: 0.046904
Train loss on 200 batch: 0.042644
Train loss on 250 batch: 0.049385
: Epoch: 42 | Training Loss: 0.043348 | Val. Loss: 0.314625 | Val. Kappa Score: 0.8683 | LR: 0.000008 | Estimated time: 79.36
Train loss on 50 batch: 0.041939
Train loss on 100 batch: 0.034980
Train loss on 150 batch: 0.038296
Train loss on 200 batch: 0.040576
Train loss on 250 batch: 0.044997
: Epoch: 43 | Training Loss: 0.040849 | Val. Loss: 0.314661 | Val. Kappa Score: 0.8689 | LR: 0.000008 | Estimated time: 79.85
Train loss on 50 batch: 0.034298
Train loss on 100 batch: 0.038977
Train loss on 150 batch: 0.051650
Train loss on 200 batch: 0.035570
Train loss on 250 batch: 0.037517
: Epoch: 44 | Training Loss: 0.039340 | Val. Loss: 0.316221 | Val. Kappa Score: 0.8694 | LR: 0.000004 | Estimated time: 79.35
Train loss on 50 batch: 0.034228
Train loss on 100 batch: 0.037451
Train loss on 150 batch: 0.038202
Train loss on 200 batch: 0.036234
Train loss on 250 batch: 0.043496
: Epoch: 45 | Training Loss: 0.038885 | Val. Loss: 0.314085 | Val. Kappa Score: 0.8697 | LR: 0.000004 | Estimated time: 78.95
time_estimated: 3567.00
n-epochs: 45
time_estimated: 3567.04
----------------------------------------

Experiment N: 143: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 09:35:13
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a8d0>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.861864
Train loss on 100 batch: 0.679028
Train loss on 150 batch: 0.716681
Train loss on 200 batch: 0.643073
----------------------------------------

Experiment N: 143: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 09:36:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b908>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.402123
Train loss on 100 batch: 0.418829
best-train-loss: 0.379118
best-valid-loss: 0.349589
best-kappa: 0.8742
: Epoch: 1 | Training Loss: 0.379118 | Val. Loss: 0.349589 | Val. Kappa Score: 0.8742 | LR: 0.001000 | Estimated time: 47.93
Train loss on 50 batch: 0.300661
Train loss on 100 batch: 0.314186
best-train-loss: 0.303353
best-valid-loss: 0.260176
best-kappa: 0.8867
: Epoch: 2 | Training Loss: 0.303353 | Val. Loss: 0.260176 | Val. Kappa Score: 0.8867 | LR: 0.001000 | Estimated time: 48.17
Train loss on 50 batch: 0.336958
Train loss on 100 batch: 0.297811
: Epoch: 3 | Training Loss: 0.294503 | Val. Loss: 0.292947 | Val. Kappa Score: 0.8883 | LR: 0.001000 | Estimated time: 48.12
Train loss on 50 batch: 0.251754
Train loss on 100 batch: 0.306176
best-train-loss: 0.273637
best-valid-loss: 0.246785
best-kappa: 0.8919
: Epoch: 4 | Training Loss: 0.273637 | Val. Loss: 0.246785 | Val. Kappa Score: 0.8919 | LR: 0.001000 | Estimated time: 48.08
Train loss on 50 batch: 0.246811
Train loss on 100 batch: 0.284816
: Epoch: 5 | Training Loss: 0.266250 | Val. Loss: 0.290698 | Val. Kappa Score: 0.8909 | LR: 0.001000 | Estimated time: 48.81
Train loss on 50 batch: 0.243875
Train loss on 100 batch: 0.267792
: Epoch: 6 | Training Loss: 0.268477 | Val. Loss: 0.247250 | Val. Kappa Score: 0.8923 | LR: 0.001000 | Estimated time: 48.43
Train loss on 50 batch: 0.228080
Train loss on 100 batch: 0.291090
: Epoch: 7 | Training Loss: 0.248842 | Val. Loss: 0.297935 | Val. Kappa Score: 0.8930 | LR: 0.000500 | Estimated time: 47.58
Train loss on 50 batch: 0.264223
Train loss on 100 batch: 0.204016
best-train-loss: 0.242611
best-valid-loss: 0.231704
best-kappa: 0.8950
: Epoch: 8 | Training Loss: 0.242611 | Val. Loss: 0.231704 | Val. Kappa Score: 0.8950 | LR: 0.000500 | Estimated time: 47.87
Train loss on 50 batch: 0.206436
Train loss on 100 batch: 0.268417
: Epoch: 9 | Training Loss: 0.232936 | Val. Loss: 0.251986 | Val. Kappa Score: 0.8956 | LR: 0.000500 | Estimated time: 47.60
Train loss on 50 batch: 0.207333
Train loss on 100 batch: 0.228885
: Epoch: 10 | Training Loss: 0.218788 | Val. Loss: 0.232948 | Val. Kappa Score: 0.8964 | LR: 0.000500 | Estimated time: 48.46
Train loss on 50 batch: 0.233809
Train loss on 100 batch: 0.201150
best-train-loss: 0.221632
best-valid-loss: 0.223739
best-kappa: 0.8971
: Epoch: 11 | Training Loss: 0.221632 | Val. Loss: 0.223739 | Val. Kappa Score: 0.8971 | LR: 0.000500 | Estimated time: 47.16
Train loss on 50 batch: 0.200602
Train loss on 100 batch: 0.201646
: Epoch: 12 | Training Loss: 0.206767 | Val. Loss: 0.228119 | Val. Kappa Score: 0.8977 | LR: 0.000500 | Estimated time: 47.65
Train loss on 50 batch: 0.201950
Train loss on 100 batch: 0.208036
: Epoch: 13 | Training Loss: 0.208076 | Val. Loss: 0.244278 | Val. Kappa Score: 0.8981 | LR: 0.000500 | Estimated time: 47.93
Train loss on 50 batch: 0.206815
Train loss on 100 batch: 0.213566
best-train-loss: 0.206864
best-valid-loss: 0.222118
best-kappa: 0.8984
: Epoch: 14 | Training Loss: 0.206864 | Val. Loss: 0.222118 | Val. Kappa Score: 0.8984 | LR: 0.000500 | Estimated time: 47.31
Train loss on 50 batch: 0.206767
Train loss on 100 batch: 0.209761
: Epoch: 15 | Training Loss: 0.202149 | Val. Loss: 0.227463 | Val. Kappa Score: 0.8986 | LR: 0.000500 | Estimated time: 48.22
Train loss on 50 batch: 0.210093
Train loss on 100 batch: 0.209542
: Epoch: 16 | Training Loss: 0.202058 | Val. Loss: 0.227934 | Val. Kappa Score: 0.8990 | LR: 0.000500 | Estimated time: 48.25
Train loss on 50 batch: 0.151607
Train loss on 100 batch: 0.205399
best-train-loss: 0.193782
best-valid-loss: 0.215692
best-kappa: 0.8990
: Epoch: 17 | Training Loss: 0.193782 | Val. Loss: 0.215692 | Val. Kappa Score: 0.8990 | LR: 0.000500 | Estimated time: 47.35
Train loss on 50 batch: 0.166199
Train loss on 100 batch: 0.198255
: Epoch: 18 | Training Loss: 0.195262 | Val. Loss: 0.216202 | Val. Kappa Score: 0.8988 | LR: 0.000500 | Estimated time: 47.07
Train loss on 50 batch: 0.190727
Train loss on 100 batch: 0.210671
: Epoch: 19 | Training Loss: 0.190330 | Val. Loss: 0.522998 | Val. Kappa Score: 0.8967 | LR: 0.000500 | Estimated time: 47.84
Train loss on 50 batch: 0.158642
Train loss on 100 batch: 0.198726
: Epoch: 20 | Training Loss: 0.184380 | Val. Loss: 0.255392 | Val. Kappa Score: 0.8967 | LR: 0.000250 | Estimated time: 47.99
Train loss on 50 batch: 0.169639
Train loss on 100 batch: 0.171703
: Epoch: 21 | Training Loss: 0.176083 | Val. Loss: 0.223354 | Val. Kappa Score: 0.8969 | LR: 0.000250 | Estimated time: 48.05
Train loss on 50 batch: 0.150991
Train loss on 100 batch: 0.188114
: Epoch: 22 | Training Loss: 0.170092 | Val. Loss: 0.224491 | Val. Kappa Score: 0.8971 | LR: 0.000250 | Estimated time: 48.51
Train loss on 50 batch: 0.162835
Train loss on 100 batch: 0.167988
: Epoch: 23 | Training Loss: 0.166420 | Val. Loss: 0.246406 | Val. Kappa Score: 0.8974 | LR: 0.000125 | Estimated time: 48.87
Train loss on 50 batch: 0.149303
Train loss on 100 batch: 0.162407
: Epoch: 24 | Training Loss: 0.164549 | Val. Loss: 0.217191 | Val. Kappa Score: 0.8977 | LR: 0.000125 | Estimated time: 47.56
Train loss on 50 batch: 0.152293
Train loss on 100 batch: 0.173813
: Epoch: 25 | Training Loss: 0.160988 | Val. Loss: 0.218478 | Val. Kappa Score: 0.8980 | LR: 0.000125 | Estimated time: 47.68
Train loss on 50 batch: 0.128246
Train loss on 100 batch: 0.150354
: Epoch: 26 | Training Loss: 0.154698 | Val. Loss: 0.236960 | Val. Kappa Score: 0.8981 | LR: 0.000063 | Estimated time: 47.96
Train loss on 50 batch: 0.157184
Train loss on 100 batch: 0.147623
: Epoch: 27 | Training Loss: 0.153282 | Val. Loss: 0.220769 | Val. Kappa Score: 0.8985 | LR: 0.000063 | Estimated time: 48.75
time_estimated: 1296.48
n-epochs: 27
time_estimated: 1296.52
----------------------------------------

Experiment N: 144: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.26 16:25:48
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb999d1240>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 144: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.26 16:26:49
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d109828>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.052578
Train loss on 100 batch: 0.645019
best-train-loss: 0.741796
best-valid-loss: 0.533389
best-kappa: 0.8020
: Epoch: 1 | Training Loss: 0.741796 | Val. Loss: 0.533389 | Val. Kappa Score: 0.8020 | LR: 0.001000 | Estimated time: 41.05
Train loss on 50 batch: 0.450226
Train loss on 100 batch: 0.513858
best-train-loss: 0.459590
best-valid-loss: 0.437302
best-kappa: 0.8113
: Epoch: 2 | Training Loss: 0.459590 | Val. Loss: 0.437302 | Val. Kappa Score: 0.8113 | LR: 0.001000 | Estimated time: 40.59
Train loss on 50 batch: 0.422572
Train loss on 100 batch: 0.409664
: Epoch: 3 | Training Loss: 0.412245 | Val. Loss: 0.564107 | Val. Kappa Score: 0.8058 | LR: 0.001000 | Estimated time: 40.50
----------------------------------------

Experiment N: 145: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.26 19:59:00
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d108828>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.030066
Train loss on 100 batch: 0.586828
----------------------------------------

Experiment N: 145: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.26 20:01:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d108828>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.539868
Train loss on 100 batch: 0.413725
Train loss on 150 batch: 0.400659
best-train-loss: 0.421680
best-valid-loss: 0.349797
best-kappa: 0.8647
: Epoch: 1 | Training Loss: 0.421680 | Val. Loss: 0.349797 | Val. Kappa Score: 0.8647 | LR: 0.001000 | Estimated time: 50.18
Train loss on 50 batch: 0.307783
Train loss on 100 batch: 0.342633
Train loss on 150 batch: 0.274075
: Epoch: 2 | Training Loss: 0.350835 | Val. Loss: 0.382103 | Val. Kappa Score: 0.8631 | LR: 0.001000 | Estimated time: 49.57
Train loss on 50 batch: 0.305704
Train loss on 100 batch: 0.312046
Train loss on 150 batch: 0.325146
: Epoch: 3 | Training Loss: 0.302234 | Val. Loss: 0.356387 | Val. Kappa Score: 0.8652 | LR: 0.001000 | Estimated time: 49.63
Train loss on 50 batch: 0.300961
Train loss on 100 batch: 0.296762
Train loss on 150 batch: 0.272600
best-train-loss: 0.385474
best-valid-loss: 0.329859
best-kappa: 0.8671
: Epoch: 4 | Training Loss: 0.385474 | Val. Loss: 0.329859 | Val. Kappa Score: 0.8671 | LR: 0.001000 | Estimated time: 49.62
Train loss on 50 batch: 0.352340
Train loss on 100 batch: 0.321757
Train loss on 150 batch: 0.247829
: Epoch: 5 | Training Loss: 0.301134 | Val. Loss: 0.331470 | Val. Kappa Score: 0.8697 | LR: 0.001000 | Estimated time: 50.03
Train loss on 50 batch: 0.289938
Train loss on 100 batch: 0.290313
Train loss on 150 batch: 0.276566
: Epoch: 6 | Training Loss: 0.273887 | Val. Loss: 0.353869 | Val. Kappa Score: 0.8670 | LR: 0.001000 | Estimated time: 50.01
Train loss on 50 batch: 0.280042
Train loss on 100 batch: 0.251667
Train loss on 150 batch: 0.257538
: Epoch: 7 | Training Loss: 0.261754 | Val. Loss: 0.368958 | Val. Kappa Score: 0.8663 | LR: 0.000500 | Estimated time: 49.92
Train loss on 50 batch: 0.243170
Train loss on 100 batch: 0.277274
Train loss on 150 batch: 0.208297
: Epoch: 8 | Training Loss: 0.275581 | Val. Loss: 0.332712 | Val. Kappa Score: 0.8674 | LR: 0.000500 | Estimated time: 49.89
Train loss on 50 batch: 0.231485
Train loss on 100 batch: 0.278473
Train loss on 150 batch: 0.257465
best-train-loss: 0.252675
best-valid-loss: 0.324489
best-kappa: 0.8695
: Epoch: 9 | Training Loss: 0.252675 | Val. Loss: 0.324489 | Val. Kappa Score: 0.8695 | LR: 0.000500 | Estimated time: 49.94
Train loss on 50 batch: 0.214749
Train loss on 100 batch: 0.251830
Train loss on 150 batch: 0.250581
: Epoch: 10 | Training Loss: 0.332332 | Val. Loss: 0.336089 | Val. Kappa Score: 0.8701 | LR: 0.000500 | Estimated time: 49.99
Train loss on 50 batch: 0.272928
Train loss on 100 batch: 0.273489
Train loss on 150 batch: 0.247046
: Epoch: 11 | Training Loss: 0.267822 | Val. Loss: 0.327642 | Val. Kappa Score: 0.8716 | LR: 0.000500 | Estimated time: 50.03
Train loss on 50 batch: 0.208094
Train loss on 100 batch: 0.233889
Train loss on 150 batch: 0.258970
best-train-loss: 0.232907
best-valid-loss: 0.319618
best-kappa: 0.8718
: Epoch: 12 | Training Loss: 0.232907 | Val. Loss: 0.319618 | Val. Kappa Score: 0.8718 | LR: 0.000500 | Estimated time: 50.00
Train loss on 50 batch: 0.217587
Train loss on 100 batch: 0.251890
Train loss on 150 batch: 0.229385
best-train-loss: 0.248071
best-valid-loss: 0.313781
best-kappa: 0.8722
: Epoch: 13 | Training Loss: 0.248071 | Val. Loss: 0.313781 | Val. Kappa Score: 0.8722 | LR: 0.000500 | Estimated time: 50.03
Train loss on 50 batch: 0.244511
Train loss on 100 batch: 0.213468
Train loss on 150 batch: 0.265510
best-train-loss: 0.240789
best-valid-loss: 0.302958
best-kappa: 0.8732
: Epoch: 14 | Training Loss: 0.240789 | Val. Loss: 0.302958 | Val. Kappa Score: 0.8732 | LR: 0.000500 | Estimated time: 49.96
Train loss on 50 batch: 0.249667
Train loss on 100 batch: 0.234316
Train loss on 150 batch: 0.223068
: Epoch: 15 | Training Loss: 0.251030 | Val. Loss: 0.348745 | Val. Kappa Score: 0.8734 | LR: 0.000500 | Estimated time: 50.03
Train loss on 50 batch: 0.228265
Train loss on 100 batch: 0.230855
Train loss on 150 batch: 0.223776
: Epoch: 16 | Training Loss: 0.228909 | Val. Loss: 0.364097 | Val. Kappa Score: 0.8726 | LR: 0.000500 | Estimated time: 50.09
Train loss on 50 batch: 0.261622
Train loss on 100 batch: 0.237135
Train loss on 150 batch: 0.196029
: Epoch: 17 | Training Loss: 0.228041 | Val. Loss: 0.327597 | Val. Kappa Score: 0.8728 | LR: 0.000250 | Estimated time: 50.01
Train loss on 50 batch: 0.220246
Train loss on 100 batch: 0.190297
Train loss on 150 batch: 0.237806
: Epoch: 18 | Training Loss: 0.221589 | Val. Loss: 0.305204 | Val. Kappa Score: 0.8732 | LR: 0.000250 | Estimated time: 49.87
Train loss on 50 batch: 0.178049
Train loss on 100 batch: 0.237924
Train loss on 150 batch: 0.226354
: Epoch: 19 | Training Loss: 0.224371 | Val. Loss: 0.333850 | Val. Kappa Score: 0.8735 | LR: 0.000250 | Estimated time: 49.94
Train loss on 50 batch: 0.193192
Train loss on 100 batch: 0.254966
Train loss on 150 batch: 0.201675
: Epoch: 20 | Training Loss: 0.211433 | Val. Loss: 0.308903 | Val. Kappa Score: 0.8744 | LR: 0.000125 | Estimated time: 49.97
Train loss on 50 batch: 0.212607
Train loss on 100 batch: 0.195352
Train loss on 150 batch: 0.213691
: Epoch: 21 | Training Loss: 0.263843 | Val. Loss: 0.317704 | Val. Kappa Score: 0.8754 | LR: 0.000125 | Estimated time: 49.85
Train loss on 50 batch: 0.189475
Train loss on 100 batch: 0.225432
Train loss on 150 batch: 0.223070
: Epoch: 22 | Training Loss: 0.203787 | Val. Loss: 0.317354 | Val. Kappa Score: 0.8763 | LR: 0.000125 | Estimated time: 49.96
Train loss on 50 batch: 0.217706
Train loss on 100 batch: 0.198467
Train loss on 150 batch: 0.206727
: Epoch: 23 | Training Loss: 0.219415 | Val. Loss: 0.312154 | Val. Kappa Score: 0.8766 | LR: 0.000063 | Estimated time: 49.79
Train loss on 50 batch: 0.212278
Train loss on 100 batch: 0.194112
Train loss on 150 batch: 0.197019
: Epoch: 24 | Training Loss: 0.254825 | Val. Loss: 0.308612 | Val. Kappa Score: 0.8767 | LR: 0.000063 | Estimated time: 49.87
time_estimated: 1199.59
n-epochs: 24
time_estimated: 1199.63
----------------------------------------

Experiment N: 146: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 20:35:30
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a828>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 146: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 20:36:15
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d108860>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 146: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 20:39:03
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a898>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.662784
----------------------------------------

Experiment N: 146: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 20:39:24
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b908>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.662784
Train loss on 100 batch: 0.492555
Train loss on 150 batch: 0.466036
best-train-loss: 0.511064
best-valid-loss: 0.390926
best-kappa: 0.8524
: Epoch: 1 | Training Loss: 0.511064 | Val. Loss: 0.390926 | Val. Kappa Score: 0.8524 | LR: 0.001000 | Estimated time: 24.14
Train loss on 50 batch: 0.385029
Train loss on 100 batch: 0.370497
Train loss on 150 batch: 0.335502
best-train-loss: 0.399625
best-valid-loss: 0.328121
best-kappa: 0.8544
: Epoch: 2 | Training Loss: 0.399625 | Val. Loss: 0.328121 | Val. Kappa Score: 0.8544 | LR: 0.001000 | Estimated time: 23.41
Train loss on 50 batch: 0.383298
Train loss on 100 batch: 0.360851
Train loss on 150 batch: 0.375761
best-train-loss: 0.354864
best-valid-loss: 0.325029
best-kappa: 0.8607
: Epoch: 3 | Training Loss: 0.354864 | Val. Loss: 0.325029 | Val. Kappa Score: 0.8607 | LR: 0.001000 | Estimated time: 24.10
Train loss on 50 batch: 0.383482
Train loss on 100 batch: 0.356445
Train loss on 150 batch: 0.343712
best-train-loss: 0.434367
best-valid-loss: 0.324847
best-kappa: 0.8631
: Epoch: 4 | Training Loss: 0.434367 | Val. Loss: 0.324847 | Val. Kappa Score: 0.8631 | LR: 0.001000 | Estimated time: 23.44
Train loss on 50 batch: 0.399888
Train loss on 100 batch: 0.358633
Train loss on 150 batch: 0.285531
best-train-loss: 0.342780
best-valid-loss: 0.310591
best-kappa: 0.8639
: Epoch: 5 | Training Loss: 0.342780 | Val. Loss: 0.310591 | Val. Kappa Score: 0.8639 | LR: 0.001000 | Estimated time: 23.91
Train loss on 50 batch: 0.326192
Train loss on 100 batch: 0.333706
Train loss on 150 batch: 0.314296
: Epoch: 6 | Training Loss: 0.308241 | Val. Loss: 0.311312 | Val. Kappa Score: 0.8645 | LR: 0.001000 | Estimated time: 23.73
Train loss on 50 batch: 0.349022
Train loss on 100 batch: 0.287629
Train loss on 150 batch: 0.288860
: Epoch: 7 | Training Loss: 0.306017 | Val. Loss: 0.325285 | Val. Kappa Score: 0.8661 | LR: 0.001000 | Estimated time: 23.73
Train loss on 50 batch: 0.281379
Train loss on 100 batch: 0.320226
Train loss on 150 batch: 0.255892
best-train-loss: 0.308222
best-valid-loss: 0.305200
best-kappa: 0.8681
: Epoch: 8 | Training Loss: 0.308222 | Val. Loss: 0.305200 | Val. Kappa Score: 0.8681 | LR: 0.001000 | Estimated time: 23.67
Train loss on 50 batch: 0.273897
Train loss on 100 batch: 0.332226
Train loss on 150 batch: 0.286964
: Epoch: 9 | Training Loss: 0.297195 | Val. Loss: 0.326569 | Val. Kappa Score: 0.8699 | LR: 0.001000 | Estimated time: 23.77
Train loss on 50 batch: 0.262221
Train loss on 100 batch: 0.304561
Train loss on 150 batch: 0.293195
: Epoch: 10 | Training Loss: 0.356665 | Val. Loss: 0.317062 | Val. Kappa Score: 0.8712 | LR: 0.001000 | Estimated time: 23.83
Train loss on 50 batch: 0.320405
Train loss on 100 batch: 0.274772
Train loss on 150 batch: 0.278835
: Epoch: 11 | Training Loss: 0.295431 | Val. Loss: 0.337918 | Val. Kappa Score: 0.8712 | LR: 0.000500 | Estimated time: 23.48
Train loss on 50 batch: 0.262655
Train loss on 100 batch: 0.253748
Train loss on 150 batch: 0.287025
best-train-loss: 0.267324
best-valid-loss: 0.285042
best-kappa: 0.8729
: Epoch: 12 | Training Loss: 0.267324 | Val. Loss: 0.285042 | Val. Kappa Score: 0.8729 | LR: 0.000500 | Estimated time: 24.36
Train loss on 50 batch: 0.251349
Train loss on 100 batch: 0.266269
Train loss on 150 batch: 0.250577
: Epoch: 13 | Training Loss: 0.259018 | Val. Loss: 0.326499 | Val. Kappa Score: 0.8729 | LR: 0.000500 | Estimated time: 24.13
Train loss on 50 batch: 0.243279
Train loss on 100 batch: 0.245487
Train loss on 150 batch: 0.260579
: Epoch: 14 | Training Loss: 0.258444 | Val. Loss: 0.289681 | Val. Kappa Score: 0.8747 | LR: 0.000500 | Estimated time: 23.95
Train loss on 50 batch: 0.286028
Train loss on 100 batch: 0.248467
Train loss on 150 batch: 0.246881
: Epoch: 15 | Training Loss: 0.263654 | Val. Loss: 0.300636 | Val. Kappa Score: 0.8750 | LR: 0.000250 | Estimated time: 23.92
Train loss on 50 batch: 0.235214
Train loss on 100 batch: 0.218740
Train loss on 150 batch: 0.240663
best-train-loss: 0.234502
best-valid-loss: 0.282047
best-kappa: 0.8761
: Epoch: 16 | Training Loss: 0.234502 | Val. Loss: 0.282047 | Val. Kappa Score: 0.8761 | LR: 0.000250 | Estimated time: 23.96
Train loss on 50 batch: 0.278189
Train loss on 100 batch: 0.251130
Train loss on 150 batch: 0.198385
: Epoch: 17 | Training Loss: 0.243397 | Val. Loss: 0.284836 | Val. Kappa Score: 0.8771 | LR: 0.000250 | Estimated time: 23.47
Train loss on 50 batch: 0.241518
Train loss on 100 batch: 0.232365
Train loss on 150 batch: 0.229603
: Epoch: 18 | Training Loss: 0.235640 | Val. Loss: 0.290431 | Val. Kappa Score: 0.8775 | LR: 0.000250 | Estimated time: 23.53
Train loss on 50 batch: 0.198772
Train loss on 100 batch: 0.235122
Train loss on 150 batch: 0.237732
: Epoch: 19 | Training Loss: 0.242304 | Val. Loss: 0.287232 | Val. Kappa Score: 0.8780 | LR: 0.000125 | Estimated time: 23.31
Train loss on 50 batch: 0.232044
Train loss on 100 batch: 0.251513
Train loss on 150 batch: 0.202560
: Epoch: 20 | Training Loss: 0.222941 | Val. Loss: 0.283689 | Val. Kappa Score: 0.8789 | LR: 0.000125 | Estimated time: 23.45
Train loss on 50 batch: 0.217825
Train loss on 100 batch: 0.230311
Train loss on 150 batch: 0.230113
best-train-loss: 0.258339
best-valid-loss: 0.277425
best-kappa: 0.8797
: Epoch: 21 | Training Loss: 0.258339 | Val. Loss: 0.277425 | Val. Kappa Score: 0.8797 | LR: 0.000125 | Estimated time: 23.59
Train loss on 50 batch: 0.199775
Train loss on 100 batch: 0.247460
Train loss on 150 batch: 0.244749
best-train-loss: 0.225806
best-valid-loss: 0.277376
best-kappa: 0.8804
: Epoch: 22 | Training Loss: 0.225806 | Val. Loss: 0.277376 | Val. Kappa Score: 0.8804 | LR: 0.000125 | Estimated time: 23.55
Train loss on 50 batch: 0.238653
Train loss on 100 batch: 0.216927
Train loss on 150 batch: 0.238402
: Epoch: 23 | Training Loss: 0.240923 | Val. Loss: 0.286225 | Val. Kappa Score: 0.8810 | LR: 0.000125 | Estimated time: 23.63
Train loss on 50 batch: 0.225559
Train loss on 100 batch: 0.252340
Train loss on 150 batch: 0.218672
: Epoch: 24 | Training Loss: 0.272832 | Val. Loss: 0.281307 | Val. Kappa Score: 0.8814 | LR: 0.000125 | Estimated time: 23.29
Train loss on 50 batch: 0.223163
Train loss on 100 batch: 0.205886
Train loss on 150 batch: 0.220371
: Epoch: 25 | Training Loss: 0.224382 | Val. Loss: 0.278117 | Val. Kappa Score: 0.8820 | LR: 0.000063 | Estimated time: 23.49
Train loss on 50 batch: 0.222993
Train loss on 100 batch: 0.207791
Train loss on 150 batch: 0.252945
best-train-loss: 0.239414
best-valid-loss: 0.275354
best-kappa: 0.8825
: Epoch: 26 | Training Loss: 0.239414 | Val. Loss: 0.275354 | Val. Kappa Score: 0.8825 | LR: 0.000063 | Estimated time: 23.53
Train loss on 50 batch: 0.222970
Train loss on 100 batch: 0.251240
Train loss on 150 batch: 0.204795
: Epoch: 27 | Training Loss: 0.218676 | Val. Loss: 0.275917 | Val. Kappa Score: 0.8830 | LR: 0.000063 | Estimated time: 23.75
Train loss on 50 batch: 0.224514
Train loss on 100 batch: 0.218550
Train loss on 150 batch: 0.198106
best-train-loss: 0.221085
best-valid-loss: 0.273989
best-kappa: 0.8833
: Epoch: 28 | Training Loss: 0.221085 | Val. Loss: 0.273989 | Val. Kappa Score: 0.8833 | LR: 0.000063 | Estimated time: 23.66
Train loss on 50 batch: 0.181809
Train loss on 100 batch: 0.239215
Train loss on 150 batch: 0.234967
: Epoch: 29 | Training Loss: 0.217846 | Val. Loss: 0.278265 | Val. Kappa Score: 0.8837 | LR: 0.000063 | Estimated time: 25.58
Train loss on 50 batch: 0.212022
Train loss on 100 batch: 0.222129
Train loss on 150 batch: 0.212896
: Epoch: 30 | Training Loss: 0.221111 | Val. Loss: 0.275036 | Val. Kappa Score: 0.8842 | LR: 0.000063 | Estimated time: 26.03
Train loss on 50 batch: 0.195148
Train loss on 100 batch: 0.228172
Train loss on 150 batch: 0.212064
: Epoch: 31 | Training Loss: 0.231587 | Val. Loss: 0.274085 | Val. Kappa Score: 0.8846 | LR: 0.000031 | Estimated time: 26.59
Train loss on 50 batch: 0.216649
Train loss on 100 batch: 0.252228
Train loss on 150 batch: 0.208208
best-train-loss: 0.224145
best-valid-loss: 0.272059
best-kappa: 0.8848
: Epoch: 32 | Training Loss: 0.224145 | Val. Loss: 0.272059 | Val. Kappa Score: 0.8848 | LR: 0.000031 | Estimated time: 26.08
Train loss on 50 batch: 0.201806
Train loss on 100 batch: 0.211030
Train loss on 150 batch: 0.192735
: Epoch: 33 | Training Loss: 0.206577 | Val. Loss: 0.275010 | Val. Kappa Score: 0.8851 | LR: 0.000031 | Estimated time: 26.06
Train loss on 50 batch: 0.212412
Train loss on 100 batch: 0.227605
Train loss on 150 batch: 0.243955
: Epoch: 34 | Training Loss: 0.220357 | Val. Loss: 0.273850 | Val. Kappa Score: 0.8853 | LR: 0.000031 | Estimated time: 26.14
Train loss on 50 batch: 0.194744
Train loss on 100 batch: 0.219556
Train loss on 150 batch: 0.220622
: Epoch: 35 | Training Loss: 0.222170 | Val. Loss: 0.273712 | Val. Kappa Score: 0.8856 | LR: 0.000016 | Estimated time: 24.80
Train loss on 50 batch: 0.202700
Train loss on 100 batch: 0.225358
Train loss on 150 batch: 0.190203
: Epoch: 36 | Training Loss: 0.218365 | Val. Loss: 0.275150 | Val. Kappa Score: 0.8858 | LR: 0.000016 | Estimated time: 23.66
Train loss on 50 batch: 0.221454
Train loss on 100 batch: 0.214792
Train loss on 150 batch: 0.213096
best-train-loss: 0.220449
best-valid-loss: 0.271994
best-kappa: 0.8858
: Epoch: 37 | Training Loss: 0.220449 | Val. Loss: 0.271994 | Val. Kappa Score: 0.8858 | LR: 0.000016 | Estimated time: 23.38
Train loss on 50 batch: 0.210990
Train loss on 100 batch: 0.190318
Train loss on 150 batch: 0.223126
: Epoch: 38 | Training Loss: 0.270044 | Val. Loss: 0.273518 | Val. Kappa Score: 0.8861 | LR: 0.000016 | Estimated time: 23.31
Train loss on 50 batch: 0.233514
Train loss on 100 batch: 0.203468
Train loss on 150 batch: 0.214987
: Epoch: 39 | Training Loss: 0.215803 | Val. Loss: 0.273938 | Val. Kappa Score: 0.8860 | LR: 0.000016 | Estimated time: 23.18
Train loss on 50 batch: 0.201985
Train loss on 100 batch: 0.186733
Train loss on 150 batch: 0.247549
: Epoch: 40 | Training Loss: 0.214457 | Val. Loss: 0.274011 | Val. Kappa Score: 0.8862 | LR: 0.000008 | Estimated time: 23.32
Train loss on 50 batch: 0.185823
Train loss on 100 batch: 0.212260
Train loss on 150 batch: 0.217998
: Epoch: 41 | Training Loss: 0.205350 | Val. Loss: 0.273980 | Val. Kappa Score: 0.8864 | LR: 0.000008 | Estimated time: 23.55
Train loss on 50 batch: 0.234372
Train loss on 100 batch: 0.192788
Train loss on 150 batch: 0.195890
: Epoch: 42 | Training Loss: 0.213634 | Val. Loss: 0.273475 | Val. Kappa Score: 0.8865 | LR: 0.000008 | Estimated time: 23.52
Train loss on 50 batch: 0.202778
Train loss on 100 batch: 0.218383
Train loss on 150 batch: 0.213253
: Epoch: 43 | Training Loss: 0.223053 | Val. Loss: 0.272781 | Val. Kappa Score: 0.8870 | LR: 0.000004 | Estimated time: 23.49
Train loss on 50 batch: 0.205879
Train loss on 100 batch: 0.234927
Train loss on 150 batch: 0.211346
: Epoch: 44 | Training Loss: 0.205912 | Val. Loss: 0.273408 | Val. Kappa Score: 0.8871 | LR: 0.000004 | Estimated time: 23.28
Train loss on 50 batch: 0.209409
Train loss on 100 batch: 0.181863
Train loss on 150 batch: 0.231779
: Epoch: 45 | Training Loss: 0.208689 | Val. Loss: 0.274024 | Val. Kappa Score: 0.8875 | LR: 0.000004 | Estimated time: 23.32
Train loss on 50 batch: 0.213725
Train loss on 100 batch: 0.209102
Train loss on 150 batch: 0.194392
: Epoch: 46 | Training Loss: 0.212659 | Val. Loss: 0.273113 | Val. Kappa Score: 0.8876 | LR: 0.000002 | Estimated time: 23.26
Train loss on 50 batch: 0.219761
Train loss on 100 batch: 0.207578
Train loss on 150 batch: 0.186253
: Epoch: 47 | Training Loss: 0.227485 | Val. Loss: 0.273153 | Val. Kappa Score: 0.8877 | LR: 0.000002 | Estimated time: 23.46
time_estimated: 1128.13
n-epochs: 47
time_estimated: 1128.17
----------------------------------------

Experiment N: 147: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.26 21:37:01
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10b898>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.846906
Train loss on 100 batch: 0.593845
Train loss on 150 batch: 0.445412
best-train-loss: 0.582678
best-valid-loss: 0.439854
best-kappa: 0.8352
: Epoch: 1 | Training Loss: 0.582678 | Val. Loss: 0.439854 | Val. Kappa Score: 0.8352 | LR: 0.001000 | Estimated time: 59.49
Train loss on 50 batch: 0.461329
----------------------------------------

Experiment N: 148: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 21:41:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1095c0>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.453141
Train loss on 100 batch: 0.383491
Train loss on 150 batch: 0.359114
best-train-loss: 0.372444
best-valid-loss: 0.348374
best-kappa: 0.8624
: Epoch: 1 | Training Loss: 0.372444 | Val. Loss: 0.348374 | Val. Kappa Score: 0.8624 | LR: 0.001000 | Estimated time: 60.39
Train loss on 50 batch: 0.311963
Train loss on 100 batch: 0.294524
Train loss on 150 batch: 0.277526
best-train-loss: 0.333238
best-valid-loss: 0.347716
best-kappa: 0.8629
: Epoch: 2 | Training Loss: 0.333238 | Val. Loss: 0.347716 | Val. Kappa Score: 0.8629 | LR: 0.001000 | Estimated time: 59.42
Train loss on 50 batch: 0.356554
Train loss on 100 batch: 0.326878
Train loss on 150 batch: 0.305250
best-train-loss: 0.314174
best-valid-loss: 0.345766
best-kappa: 0.8668
: Epoch: 3 | Training Loss: 0.314174 | Val. Loss: 0.345766 | Val. Kappa Score: 0.8668 | LR: 0.001000 | Estimated time: 60.45
Train loss on 50 batch: 0.282480
Train loss on 100 batch: 0.320149
Train loss on 150 batch: 0.291013
best-train-loss: 0.397437
best-valid-loss: 0.340234
best-kappa: 0.8688
: Epoch: 4 | Training Loss: 0.397437 | Val. Loss: 0.340234 | Val. Kappa Score: 0.8688 | LR: 0.001000 | Estimated time: 59.50
Train loss on 50 batch: 0.318146
Train loss on 100 batch: 0.312803
Train loss on 150 batch: 0.292706
: Epoch: 5 | Training Loss: 0.303716 | Val. Loss: 0.355743 | Val. Kappa Score: 0.8671 | LR: 0.001000 | Estimated time: 62.73
Train loss on 50 batch: 0.287162
Train loss on 100 batch: 0.309891
Train loss on 150 batch: 0.263373
: Epoch: 6 | Training Loss: 0.276044 | Val. Loss: 0.514023 | Val. Kappa Score: 0.8609 | LR: 0.001000 | Estimated time: 60.72
Train loss on 50 batch: 0.285120
Train loss on 100 batch: 0.248543
Train loss on 150 batch: 0.286851
best-train-loss: 0.271179
best-valid-loss: 0.314098
best-kappa: 0.8637
: Epoch: 7 | Training Loss: 0.271179 | Val. Loss: 0.314098 | Val. Kappa Score: 0.8637 | LR: 0.001000 | Estimated time: 59.37
Train loss on 50 batch: 0.244739
Train loss on 100 batch: 0.304830
Train loss on 150 batch: 0.217237
: Epoch: 8 | Training Loss: 0.288003 | Val. Loss: 0.354219 | Val. Kappa Score: 0.8664 | LR: 0.001000 | Estimated time: 60.67
Train loss on 50 batch: 0.256763
Train loss on 100 batch: 0.300175
Train loss on 150 batch: 0.258249
: Epoch: 9 | Training Loss: 0.271502 | Val. Loss: 0.448654 | Val. Kappa Score: 0.8633 | LR: 0.001000 | Estimated time: 60.03
Train loss on 50 batch: 0.251470
Train loss on 100 batch: 0.277890
Train loss on 150 batch: 0.281288
: Epoch: 10 | Training Loss: 0.358430 | Val. Loss: 0.338532 | Val. Kappa Score: 0.8638 | LR: 0.000500 | Estimated time: 59.99
Train loss on 50 batch: 0.263957
Train loss on 100 batch: 0.253303
Train loss on 150 batch: 0.258565
best-train-loss: 0.261125
best-valid-loss: 0.299578
best-kappa: 0.8650
: Epoch: 11 | Training Loss: 0.261125 | Val. Loss: 0.299578 | Val. Kappa Score: 0.8650 | LR: 0.000500 | Estimated time: 59.74
Train loss on 50 batch: 0.225016
Train loss on 100 batch: 0.223922
Train loss on 150 batch: 0.254047
: Epoch: 12 | Training Loss: 0.232031 | Val. Loss: 0.305375 | Val. Kappa Score: 0.8658 | LR: 0.000500 | Estimated time: 58.86
Train loss on 50 batch: 0.221529
Train loss on 100 batch: 0.258763
Train loss on 150 batch: 0.236430
: Epoch: 13 | Training Loss: 0.262500 | Val. Loss: 0.326608 | Val. Kappa Score: 0.8668 | LR: 0.000500 | Estimated time: 58.86
Train loss on 50 batch: 0.224777
Train loss on 100 batch: 0.225793
Train loss on 150 batch: 0.263224
: Epoch: 14 | Training Loss: 0.235704 | Val. Loss: 0.301954 | Val. Kappa Score: 0.8673 | LR: 0.000250 | Estimated time: 58.20
Train loss on 50 batch: 0.267205
Train loss on 100 batch: 0.208077
Train loss on 150 batch: 0.214578
best-train-loss: 0.252602
best-valid-loss: 0.292584
best-kappa: 0.8684
: Epoch: 15 | Training Loss: 0.252602 | Val. Loss: 0.292584 | Val. Kappa Score: 0.8684 | LR: 0.000250 | Estimated time: 58.85
Train loss on 50 batch: 0.219175
Train loss on 100 batch: 0.198738
Train loss on 150 batch: 0.219465
: Epoch: 16 | Training Loss: 0.220144 | Val. Loss: 0.297829 | Val. Kappa Score: 0.8694 | LR: 0.000250 | Estimated time: 58.60
Train loss on 50 batch: 0.254251
Train loss on 100 batch: 0.202526
Train loss on 150 batch: 0.200115
best-train-loss: 0.216619
best-valid-loss: 0.287640
best-kappa: 0.8703
: Epoch: 17 | Training Loss: 0.216619 | Val. Loss: 0.287640 | Val. Kappa Score: 0.8703 | LR: 0.000250 | Estimated time: 59.35
Train loss on 50 batch: 0.232235
Train loss on 100 batch: 0.195652
Train loss on 150 batch: 0.236845
: Epoch: 18 | Training Loss: 0.224910 | Val. Loss: 0.290994 | Val. Kappa Score: 0.8712 | LR: 0.000250 | Estimated time: 58.43
Train loss on 50 batch: 0.167456
Train loss on 100 batch: 0.226718
Train loss on 150 batch: 0.227738
: Epoch: 19 | Training Loss: 0.216613 | Val. Loss: 0.300253 | Val. Kappa Score: 0.8716 | LR: 0.000250 | Estimated time: 59.55
Train loss on 50 batch: 0.219545
Train loss on 100 batch: 0.243718
Train loss on 150 batch: 0.217518
: Epoch: 20 | Training Loss: 0.217713 | Val. Loss: 0.313215 | Val. Kappa Score: 0.8722 | LR: 0.000125 | Estimated time: 59.14
Train loss on 50 batch: 0.210683
Train loss on 100 batch: 0.204208
Train loss on 150 batch: 0.223516
best-train-loss: 0.268515
best-valid-loss: 0.281620
best-kappa: 0.8727
: Epoch: 21 | Training Loss: 0.268515 | Val. Loss: 0.281620 | Val. Kappa Score: 0.8727 | LR: 0.000125 | Estimated time: 59.35
Train loss on 50 batch: 0.193502
Train loss on 100 batch: 0.210814
Train loss on 150 batch: 0.224493
: Epoch: 22 | Training Loss: 0.204906 | Val. Loss: 0.284445 | Val. Kappa Score: 0.8731 | LR: 0.000125 | Estimated time: 62.97
Train loss on 50 batch: 0.210469
Train loss on 100 batch: 0.225182
Train loss on 150 batch: 0.208225
: Epoch: 23 | Training Loss: 0.231616 | Val. Loss: 0.288594 | Val. Kappa Score: 0.8736 | LR: 0.000125 | Estimated time: 61.88
Train loss on 50 batch: 0.214983
Train loss on 100 batch: 0.205215
Train loss on 150 batch: 0.196567
: Epoch: 24 | Training Loss: 0.292832 | Val. Loss: 0.291616 | Val. Kappa Score: 0.8735 | LR: 0.000063 | Estimated time: 60.15
Train loss on 50 batch: 0.200817
Train loss on 100 batch: 0.201123
Train loss on 150 batch: 0.220810
: Epoch: 25 | Training Loss: 0.210145 | Val. Loss: 0.287186 | Val. Kappa Score: 0.8737 | LR: 0.000063 | Estimated time: 57.87
Train loss on 50 batch: 0.222575
Train loss on 100 batch: 0.192423
Train loss on 150 batch: 0.228996
: Epoch: 26 | Training Loss: 0.264499 | Val. Loss: 0.288414 | Val. Kappa Score: 0.8740 | LR: 0.000063 | Estimated time: 58.33
Train loss on 50 batch: 0.215414
Train loss on 100 batch: 0.235915
Train loss on 150 batch: 0.198426
: Epoch: 27 | Training Loss: 0.225248 | Val. Loss: 0.284781 | Val. Kappa Score: 0.8743 | LR: 0.000031 | Estimated time: 58.69
Train loss on 50 batch: 0.240180
Train loss on 100 batch: 0.195054
Train loss on 150 batch: 0.180568
: Epoch: 28 | Training Loss: 0.226916 | Val. Loss: 0.285770 | Val. Kappa Score: 0.8743 | LR: 0.000031 | Estimated time: 58.75
Train loss on 50 batch: 0.154489
Train loss on 100 batch: 0.225073
Train loss on 150 batch: 0.216117
: Epoch: 29 | Training Loss: 0.226509 | Val. Loss: 0.285942 | Val. Kappa Score: 0.8743 | LR: 0.000031 | Estimated time: 58.53
Train loss on 50 batch: 0.184788
Train loss on 100 batch: 0.209939
Train loss on 150 batch: 0.212571
: Epoch: 30 | Training Loss: 0.225095 | Val. Loss: 0.286937 | Val. Kappa Score: 0.8743 | LR: 0.000016 | Estimated time: 59.21
Train loss on 50 batch: 0.172646
Train loss on 100 batch: 0.212808
Train loss on 150 batch: 0.195526
: Epoch: 31 | Training Loss: 0.205325 | Val. Loss: 0.286244 | Val. Kappa Score: 0.8746 | LR: 0.000016 | Estimated time: 58.54
time_estimated: 1848.69
n-epochs: 31
time_estimated: 1848.73
----------------------------------------

Experiment N: 149: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 22:24:35
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10c8d0>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.446264
Train loss on 100 batch: 0.371264
Train loss on 150 batch: 0.347422
best-train-loss: 0.370895
best-valid-loss: 0.327566
best-kappa: 0.8592
: Epoch: 1 | Training Loss: 0.370895 | Val. Loss: 0.327566 | Val. Kappa Score: 0.8592 | LR: 0.001000 | Estimated time: 58.81
Train loss on 50 batch: 0.302814
Train loss on 100 batch: 0.267275
Train loss on 150 batch: 0.264224
: Epoch: 2 | Training Loss: 0.320681 | Val. Loss: 0.344145 | Val. Kappa Score: 0.8626 | LR: 0.001000 | Estimated time: 60.75
Train loss on 50 batch: 0.302443
Train loss on 100 batch: 0.292789
Train loss on 150 batch: 0.282654
: Epoch: 3 | Training Loss: 0.283083 | Val. Loss: 0.384425 | Val. Kappa Score: 0.8660 | LR: 0.001000 | Estimated time: 61.74
Train loss on 50 batch: 0.273727
Train loss on 100 batch: 0.290104
Train loss on 150 batch: 0.255737
: Epoch: 4 | Training Loss: 0.359856 | Val. Loss: 0.350842 | Val. Kappa Score: 0.8679 | LR: 0.000500 | Estimated time: 61.90
Train loss on 50 batch: 0.264468
Train loss on 100 batch: 0.264678
Train loss on 150 batch: 0.219326
best-train-loss: 0.250770
best-valid-loss: 0.305596
best-kappa: 0.8702
: Epoch: 5 | Training Loss: 0.250770 | Val. Loss: 0.305596 | Val. Kappa Score: 0.8702 | LR: 0.000500 | Estimated time: 62.15
Train loss on 50 batch: 0.259509
Train loss on 100 batch: 0.256247
Train loss on 150 batch: 0.240059
: Epoch: 6 | Training Loss: 0.243376 | Val. Loss: 0.317495 | Val. Kappa Score: 0.8708 | LR: 0.000500 | Estimated time: 61.52
Train loss on 50 batch: 0.248913
Train loss on 100 batch: 0.218754
Train loss on 150 batch: 0.249223
best-train-loss: 0.238811
best-valid-loss: 0.303114
best-kappa: 0.8724
: Epoch: 7 | Training Loss: 0.238811 | Val. Loss: 0.303114 | Val. Kappa Score: 0.8724 | LR: 0.000500 | Estimated time: 61.29
Train loss on 50 batch: 0.216127
Train loss on 100 batch: 0.271000
Train loss on 150 batch: 0.184637
: Epoch: 8 | Training Loss: 0.250795 | Val. Loss: 0.344539 | Val. Kappa Score: 0.8743 | LR: 0.000500 | Estimated time: 60.82
Train loss on 50 batch: 0.238804
Train loss on 100 batch: 0.253169
Train loss on 150 batch: 0.233364
: Epoch: 9 | Training Loss: 0.242567 | Val. Loss: 0.337994 | Val. Kappa Score: 0.8753 | LR: 0.000500 | Estimated time: 62.07
Train loss on 50 batch: 0.216744
Train loss on 100 batch: 0.226049
Train loss on 150 batch: 0.231858
best-train-loss: 0.309363
best-valid-loss: 0.300367
best-kappa: 0.8759
: Epoch: 10 | Training Loss: 0.309363 | Val. Loss: 0.300367 | Val. Kappa Score: 0.8759 | LR: 0.000500 | Estimated time: 61.38
Train loss on 50 batch: 0.222084
Train loss on 100 batch: 0.221827
Train loss on 150 batch: 0.227514
best-train-loss: 0.225977
best-valid-loss: 0.291178
best-kappa: 0.8760
: Epoch: 11 | Training Loss: 0.225977 | Val. Loss: 0.291178 | Val. Kappa Score: 0.8760 | LR: 0.000500 | Estimated time: 61.24
Train loss on 50 batch: 0.190675
Train loss on 100 batch: 0.208327
Train loss on 150 batch: 0.236290
: Epoch: 12 | Training Loss: 0.210161 | Val. Loss: 0.299977 | Val. Kappa Score: 0.8753 | LR: 0.000500 | Estimated time: 59.83
Train loss on 50 batch: 0.200497
Train loss on 100 batch: 0.209263
Train loss on 150 batch: 0.189546
: Epoch: 13 | Training Loss: 0.219097 | Val. Loss: 0.316626 | Val. Kappa Score: 0.8761 | LR: 0.000500 | Estimated time: 59.44
Train loss on 50 batch: 0.196076
Train loss on 100 batch: 0.199816
Train loss on 150 batch: 0.228662
: Epoch: 14 | Training Loss: 0.207623 | Val. Loss: 0.295320 | Val. Kappa Score: 0.8762 | LR: 0.000250 | Estimated time: 57.58
Train loss on 50 batch: 0.216588
Train loss on 100 batch: 0.176652
Train loss on 150 batch: 0.191097
best-train-loss: 0.214635
best-valid-loss: 0.284670
best-kappa: 0.8767
: Epoch: 15 | Training Loss: 0.214635 | Val. Loss: 0.284670 | Val. Kappa Score: 0.8767 | LR: 0.000250 | Estimated time: 58.80
Train loss on 50 batch: 0.179437
Train loss on 100 batch: 0.169616
Train loss on 150 batch: 0.192800
: Epoch: 16 | Training Loss: 0.187278 | Val. Loss: 0.289199 | Val. Kappa Score: 0.8768 | LR: 0.000250 | Estimated time: 58.39
Train loss on 50 batch: 0.212881
Train loss on 100 batch: 0.185477
Train loss on 150 batch: 0.153258
: Epoch: 17 | Training Loss: 0.185319 | Val. Loss: 0.293558 | Val. Kappa Score: 0.8773 | LR: 0.000250 | Estimated time: 58.27
Train loss on 50 batch: 0.194135
Train loss on 100 batch: 0.168400
Train loss on 150 batch: 0.196089
: Epoch: 18 | Training Loss: 0.193104 | Val. Loss: 0.287232 | Val. Kappa Score: 0.8776 | LR: 0.000125 | Estimated time: 58.53
Train loss on 50 batch: 0.160942
Train loss on 100 batch: 0.190336
Train loss on 150 batch: 0.185540
: Epoch: 19 | Training Loss: 0.181442 | Val. Loss: 0.287321 | Val. Kappa Score: 0.8778 | LR: 0.000125 | Estimated time: 58.52
Train loss on 50 batch: 0.165774
Train loss on 100 batch: 0.198162
Train loss on 150 batch: 0.189723
: Epoch: 20 | Training Loss: 0.181804 | Val. Loss: 0.288254 | Val. Kappa Score: 0.8782 | LR: 0.000125 | Estimated time: 58.12
Train loss on 50 batch: 0.185791
Train loss on 100 batch: 0.163547
Train loss on 150 batch: 0.201012
best-train-loss: 0.225654
best-valid-loss: 0.281067
best-kappa: 0.8784
: Epoch: 21 | Training Loss: 0.225654 | Val. Loss: 0.281067 | Val. Kappa Score: 0.8784 | LR: 0.000125 | Estimated time: 58.52
Train loss on 50 batch: 0.154266
Train loss on 100 batch: 0.190338
Train loss on 150 batch: 0.187683
: Epoch: 22 | Training Loss: 0.173549 | Val. Loss: 0.287236 | Val. Kappa Score: 0.8786 | LR: 0.000125 | Estimated time: 58.94
Train loss on 50 batch: 0.183828
Train loss on 100 batch: 0.177436
Train loss on 150 batch: 0.172402
: Epoch: 23 | Training Loss: 0.195527 | Val. Loss: 0.295932 | Val. Kappa Score: 0.8788 | LR: 0.000125 | Estimated time: 58.01
Train loss on 50 batch: 0.174805
Train loss on 100 batch: 0.168228
Train loss on 150 batch: 0.145127
: Epoch: 24 | Training Loss: 0.241803 | Val. Loss: 0.292377 | Val. Kappa Score: 0.8788 | LR: 0.000063 | Estimated time: 57.65
Train loss on 50 batch: 0.159433
Train loss on 100 batch: 0.166539
Train loss on 150 batch: 0.172566
: Epoch: 25 | Training Loss: 0.170157 | Val. Loss: 0.287055 | Val. Kappa Score: 0.8789 | LR: 0.000063 | Estimated time: 57.75
Train loss on 50 batch: 0.185952
Train loss on 100 batch: 0.154785
Train loss on 150 batch: 0.202969
: Epoch: 26 | Training Loss: 0.223579 | Val. Loss: 0.288301 | Val. Kappa Score: 0.8790 | LR: 0.000063 | Estimated time: 58.15
Train loss on 50 batch: 0.164699
Train loss on 100 batch: 0.201838
Train loss on 150 batch: 0.157471
: Epoch: 27 | Training Loss: 0.187070 | Val. Loss: 0.287279 | Val. Kappa Score: 0.8792 | LR: 0.000031 | Estimated time: 57.57
Train loss on 50 batch: 0.171066
Train loss on 100 batch: 0.161327
Train loss on 150 batch: 0.159599
: Epoch: 28 | Training Loss: 0.187706 | Val. Loss: 0.288170 | Val. Kappa Score: 0.8788 | LR: 0.000031 | Estimated time: 57.66
Train loss on 50 batch: 0.135062
Train loss on 100 batch: 0.185499
Train loss on 150 batch: 0.178513
: Epoch: 29 | Training Loss: 0.177274 | Val. Loss: 0.287886 | Val. Kappa Score: 0.8789 | LR: 0.000031 | Estimated time: 58.63
Train loss on 50 batch: 0.163226
Train loss on 100 batch: 0.187238
Train loss on 150 batch: 0.181907
: Epoch: 30 | Training Loss: 0.191210 | Val. Loss: 0.288209 | Val. Kappa Score: 0.8789 | LR: 0.000016 | Estimated time: 59.81
Train loss on 50 batch: 0.141799
Train loss on 100 batch: 0.169335
Train loss on 150 batch: 0.155088
: Epoch: 31 | Training Loss: 0.159245 | Val. Loss: 0.287170 | Val. Kappa Score: 0.8789 | LR: 0.000016 | Estimated time: 59.73
time_estimated: 1845.08
n-epochs: 31
time_estimated: 1845.12
----------------------------------------

Experiment N: 150: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.26 23:07:19
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1088d0>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.086846
Train loss on 100 batch: 0.614605
Train loss on 150 batch: 0.573091
best-train-loss: 0.684176
best-valid-loss: 0.507715
best-kappa: 0.8225
: Epoch: 1 | Training Loss: 0.684176 | Val. Loss: 0.507715 | Val. Kappa Score: 0.8225 | LR: 0.001000 | Estimated time: 57.62
Train loss on 50 batch: 0.478476
Train loss on 100 batch: 0.466839
Train loss on 150 batch: 0.423530
: Epoch: 2 | Training Loss: 0.470971 | Val. Loss: 0.608888 | Val. Kappa Score: 0.8014 | LR: 0.001000 | Estimated time: 58.95
Train loss on 50 batch: 0.410307
Train loss on 100 batch: 0.510325
Train loss on 150 batch: 0.410177
best-train-loss: 0.446539
best-valid-loss: 0.347403
best-kappa: 0.8270
: Epoch: 3 | Training Loss: 0.446539 | Val. Loss: 0.347403 | Val. Kappa Score: 0.8270 | LR: 0.001000 | Estimated time: 58.69
Train loss on 50 batch: 0.349580
Train loss on 100 batch: 0.350002
Train loss on 150 batch: 0.360123
: Epoch: 4 | Training Loss: 0.418518 | Val. Loss: 0.444147 | Val. Kappa Score: 0.8292 | LR: 0.001000 | Estimated time: 58.33
Train loss on 50 batch: 0.456856
Train loss on 100 batch: 0.458693
Train loss on 150 batch: 0.322332
: Epoch: 5 | Training Loss: 0.416552 | Val. Loss: 0.514985 | Val. Kappa Score: 0.8297 | LR: 0.001000 | Estimated time: 59.79
Train loss on 50 batch: 0.373952
Train loss on 100 batch: 0.338305
Train loss on 150 batch: 0.307398
: Epoch: 6 | Training Loss: 0.322597 | Val. Loss: 0.413657 | Val. Kappa Score: 0.8341 | LR: 0.000500 | Estimated time: 58.97
Train loss on 50 batch: 0.308668
Train loss on 100 batch: 0.244772
Train loss on 150 batch: 0.232078
best-train-loss: 0.270382
best-valid-loss: 0.327863
best-kappa: 0.8395
: Epoch: 7 | Training Loss: 0.270382 | Val. Loss: 0.327863 | Val. Kappa Score: 0.8395 | LR: 0.000500 | Estimated time: 58.94
Train loss on 50 batch: 0.212103
Train loss on 100 batch: 0.263182
Train loss on 150 batch: 0.229945
best-train-loss: 0.234400
best-valid-loss: 0.281096
best-kappa: 0.8451
: Epoch: 8 | Training Loss: 0.234400 | Val. Loss: 0.281096 | Val. Kappa Score: 0.8451 | LR: 0.000500 | Estimated time: 58.42
Train loss on 50 batch: 0.239129
Train loss on 100 batch: 0.271951
Train loss on 150 batch: 0.264424
: Epoch: 9 | Training Loss: 0.249799 | Val. Loss: 0.299332 | Val. Kappa Score: 0.8505 | LR: 0.000500 | Estimated time: 58.89
Train loss on 50 batch: 0.204119
Train loss on 100 batch: 0.225836
Train loss on 150 batch: 0.224725
: Epoch: 10 | Training Loss: 0.267391 | Val. Loss: 0.290615 | Val. Kappa Score: 0.8539 | LR: 0.000500 | Estimated time: 58.61
Train loss on 50 batch: 0.207993
Train loss on 100 batch: 0.222985
Train loss on 150 batch: 0.221495
: Epoch: 11 | Training Loss: 0.237324 | Val. Loss: 0.322073 | Val. Kappa Score: 0.8553 | LR: 0.000250 | Estimated time: 58.68
Train loss on 50 batch: 0.177460
Train loss on 100 batch: 0.186182
Train loss on 150 batch: 0.214674
: Epoch: 12 | Training Loss: 0.198583 | Val. Loss: 0.300935 | Val. Kappa Score: 0.8574 | LR: 0.000250 | Estimated time: 57.97
Train loss on 50 batch: 0.174629
Train loss on 100 batch: 0.193499
Train loss on 150 batch: 0.172384
: Epoch: 13 | Training Loss: 0.181230 | Val. Loss: 0.301126 | Val. Kappa Score: 0.8608 | LR: 0.000250 | Estimated time: 58.82
Train loss on 50 batch: 0.166331
Train loss on 100 batch: 0.161885
Train loss on 150 batch: 0.191335
: Epoch: 14 | Training Loss: 0.184008 | Val. Loss: 0.294708 | Val. Kappa Score: 0.8623 | LR: 0.000125 | Estimated time: 57.41
Train loss on 50 batch: 0.177667
Train loss on 100 batch: 0.164417
Train loss on 150 batch: 0.150460
: Epoch: 15 | Training Loss: 0.164209 | Val. Loss: 0.301547 | Val. Kappa Score: 0.8639 | LR: 0.000125 | Estimated time: 57.99
Train loss on 50 batch: 0.141095
Train loss on 100 batch: 0.139318
Train loss on 150 batch: 0.131984
: Epoch: 16 | Training Loss: 0.143424 | Val. Loss: 0.316602 | Val. Kappa Score: 0.8645 | LR: 0.000125 | Estimated time: 58.34
Train loss on 50 batch: 0.146322
Train loss on 100 batch: 0.150524
Train loss on 150 batch: 0.113535
: Epoch: 17 | Training Loss: 0.142439 | Val. Loss: 0.313390 | Val. Kappa Score: 0.8658 | LR: 0.000063 | Estimated time: 60.18
Train loss on 50 batch: 0.127391
Train loss on 100 batch: 0.106813
Train loss on 150 batch: 0.150635
: Epoch: 18 | Training Loss: 0.131400 | Val. Loss: 0.311081 | Val. Kappa Score: 0.8667 | LR: 0.000063 | Estimated time: 59.07
time_estimated: 1056.54
n-epochs: 18
time_estimated: 1056.58
----------------------------------------

Experiment N: 151: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.26 23:28:08
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e9bfd0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.178320
Train loss on 100 batch: 0.609917
Train loss on 150 batch: 0.585880
best-train-loss: 0.718961
best-valid-loss: 0.396040
best-kappa: 0.8451
: Epoch: 1 | Training Loss: 0.718961 | Val. Loss: 0.396040 | Val. Kappa Score: 0.8451 | LR: 0.001000 | Estimated time: 73.32
Train loss on 50 batch: 0.465333
Train loss on 100 batch: 0.485573
Train loss on 150 batch: 0.397037
: Epoch: 2 | Training Loss: 0.446597 | Val. Loss: 0.903992 | Val. Kappa Score: 0.7437 | LR: 0.001000 | Estimated time: 69.38
Train loss on 50 batch: 0.416157
Train loss on 100 batch: 0.419039
Train loss on 150 batch: 0.390302
best-train-loss: 0.405058
best-valid-loss: 0.340783
best-kappa: 0.7866
: Epoch: 3 | Training Loss: 0.405058 | Val. Loss: 0.340783 | Val. Kappa Score: 0.7866 | LR: 0.001000 | Estimated time: 70.30
Train loss on 50 batch: 0.384380
Train loss on 100 batch: 0.414974
Train loss on 150 batch: 0.337407
best-train-loss: 0.436399
best-valid-loss: 0.330894
best-kappa: 0.8085
: Epoch: 4 | Training Loss: 0.436399 | Val. Loss: 0.330894 | Val. Kappa Score: 0.8085 | LR: 0.001000 | Estimated time: 69.76
Train loss on 50 batch: 0.548276
Train loss on 100 batch: 0.490689
Train loss on 150 batch: 0.338239
: Epoch: 5 | Training Loss: 0.446643 | Val. Loss: 0.459057 | Val. Kappa Score: 0.8201 | LR: 0.001000 | Estimated time: 70.56
Train loss on 50 batch: 0.388082
Train loss on 100 batch: 0.375315
Train loss on 150 batch: 0.329537
: Epoch: 6 | Training Loss: 0.348598 | Val. Loss: 1.340412 | Val. Kappa Score: 0.7453 | LR: 0.001000 | Estimated time: 69.61
Train loss on 50 batch: 0.373546
Train loss on 100 batch: 0.309783
Train loss on 150 batch: 0.320803
: Epoch: 7 | Training Loss: 0.340882 | Val. Loss: 0.346259 | Val. Kappa Score: 0.7623 | LR: 0.000500 | Estimated time: 69.90
Train loss on 50 batch: 0.247517
Train loss on 100 batch: 0.270410
Train loss on 150 batch: 0.216861
best-train-loss: 0.261030
best-valid-loss: 0.279523
best-kappa: 0.7789
: Epoch: 8 | Training Loss: 0.261030 | Val. Loss: 0.279523 | Val. Kappa Score: 0.7789 | LR: 0.000500 | Estimated time: 69.82
Train loss on 50 batch: 0.227708
Train loss on 100 batch: 0.255444
Train loss on 150 batch: 0.241867
: Epoch: 9 | Training Loss: 0.235527 | Val. Loss: 0.295746 | Val. Kappa Score: 0.7924 | LR: 0.000500 | Estimated time: 70.53
Train loss on 50 batch: 0.207491
Train loss on 100 batch: 0.238328
Train loss on 150 batch: 0.226551
: Epoch: 10 | Training Loss: 0.284794 | Val. Loss: 0.297092 | Val. Kappa Score: 0.8012 | LR: 0.000500 | Estimated time: 70.37
Train loss on 50 batch: 0.234443
Train loss on 100 batch: 0.237021
Train loss on 150 batch: 0.228305
: Epoch: 11 | Training Loss: 0.239867 | Val. Loss: 0.308063 | Val. Kappa Score: 0.8075 | LR: 0.000250 | Estimated time: 70.56
Train loss on 50 batch: 0.186148
Train loss on 100 batch: 0.189397
Train loss on 150 batch: 0.196015
: Epoch: 12 | Training Loss: 0.201129 | Val. Loss: 0.294626 | Val. Kappa Score: 0.8142 | LR: 0.000250 | Estimated time: 70.94
Train loss on 50 batch: 0.157592
Train loss on 100 batch: 0.220162
Train loss on 150 batch: 0.164401
: Epoch: 13 | Training Loss: 0.190597 | Val. Loss: 0.306960 | Val. Kappa Score: 0.8201 | LR: 0.000250 | Estimated time: 70.08
Train loss on 50 batch: 0.162545
Train loss on 100 batch: 0.162384
Train loss on 150 batch: 0.199566
best-train-loss: 0.184656
best-valid-loss: 0.270358
best-kappa: 0.8253
: Epoch: 14 | Training Loss: 0.184656 | Val. Loss: 0.270358 | Val. Kappa Score: 0.8253 | LR: 0.000250 | Estimated time: 69.17
Train loss on 50 batch: 0.172784
Train loss on 100 batch: 0.170730
Train loss on 150 batch: 0.179039
: Epoch: 15 | Training Loss: 0.177612 | Val. Loss: 0.301514 | Val. Kappa Score: 0.8294 | LR: 0.000250 | Estimated time: 69.84
Train loss on 50 batch: 0.163749
Train loss on 100 batch: 0.158744
Train loss on 150 batch: 0.186941
: Epoch: 16 | Training Loss: 0.173191 | Val. Loss: 0.303244 | Val. Kappa Score: 0.8321 | LR: 0.000250 | Estimated time: 70.27
Train loss on 50 batch: 0.164039
Train loss on 100 batch: 0.169738
Train loss on 150 batch: 0.147270
: Epoch: 17 | Training Loss: 0.156196 | Val. Loss: 0.287929 | Val. Kappa Score: 0.8363 | LR: 0.000125 | Estimated time: 69.90
Train loss on 50 batch: 0.137031
Train loss on 100 batch: 0.118348
Train loss on 150 batch: 0.134329
: Epoch: 18 | Training Loss: 0.135411 | Val. Loss: 0.295200 | Val. Kappa Score: 0.8394 | LR: 0.000125 | Estimated time: 69.60
Train loss on 50 batch: 0.106659
Train loss on 100 batch: 0.151379
Train loss on 150 batch: 0.128497
: Epoch: 19 | Training Loss: 0.137176 | Val. Loss: 0.304810 | Val. Kappa Score: 0.8418 | LR: 0.000125 | Estimated time: 70.20
Train loss on 50 batch: 0.109567
Train loss on 100 batch: 0.137428
Train loss on 150 batch: 0.125538
: Epoch: 20 | Training Loss: 0.120811 | Val. Loss: 0.306603 | Val. Kappa Score: 0.8444 | LR: 0.000063 | Estimated time: 70.40
Train loss on 50 batch: 0.121065
Train loss on 100 batch: 0.107328
Train loss on 150 batch: 0.116411
: Epoch: 21 | Training Loss: 0.144466 | Val. Loss: 0.307910 | Val. Kappa Score: 0.8466 | LR: 0.000063 | Estimated time: 70.15
Train loss on 50 batch: 0.098418
Train loss on 100 batch: 0.123442
Train loss on 150 batch: 0.115537
: Epoch: 22 | Training Loss: 0.113371 | Val. Loss: 0.319739 | Val. Kappa Score: 0.8486 | LR: 0.000063 | Estimated time: 72.74
Train loss on 50 batch: 0.100230
Train loss on 100 batch: 0.106944
Train loss on 150 batch: 0.102136
: Epoch: 23 | Training Loss: 0.108055 | Val. Loss: 0.309433 | Val. Kappa Score: 0.8505 | LR: 0.000031 | Estimated time: 73.40
Train loss on 50 batch: 0.101486
Train loss on 100 batch: 0.108648
Train loss on 150 batch: 0.097316
: Epoch: 24 | Training Loss: 0.165088 | Val. Loss: 0.306820 | Val. Kappa Score: 0.8521 | LR: 0.000031 | Estimated time: 74.57
time_estimated: 1696.79
n-epochs: 24
time_estimated: 1696.83
----------------------------------------

Experiment N: 152: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.27 08:22:58
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d10a8d0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.760603
Train loss on 100 batch: 0.531376
Train loss on 150 batch: 0.507831
best-train-loss: 0.553565
best-valid-loss: 0.571381
best-kappa: 0.6225
: Epoch: 1 | Training Loss: 0.553565 | Val. Loss: 0.571381 | Val. Kappa Score: 0.6225 | LR: 0.001000 | Estimated time: 70.06
Train loss on 50 batch: 0.376502
Train loss on 100 batch: 0.404125
Train loss on 150 batch: 0.342772
best-train-loss: 0.405364
best-valid-loss: 0.544765
best-kappa: 0.6774
: Epoch: 2 | Training Loss: 0.405364 | Val. Loss: 0.544765 | Val. Kappa Score: 0.6774 | LR: 0.001000 | Estimated time: 69.32
Train loss on 50 batch: 0.396242
Train loss on 100 batch: 0.369082
Train loss on 150 batch: 0.341976
best-train-loss: 0.359619
best-valid-loss: 0.344213
best-kappa: 0.7386
: Epoch: 3 | Training Loss: 0.359619 | Val. Loss: 0.344213 | Val. Kappa Score: 0.7386 | LR: 0.001000 | Estimated time: 69.51
Train loss on 50 batch: 0.364895
Train loss on 100 batch: 0.346443
Train loss on 150 batch: 0.297532
: Epoch: 4 | Training Loss: 0.424426 | Val. Loss: 0.369422 | Val. Kappa Score: 0.7711 | LR: 0.001000 | Estimated time: 69.19
Train loss on 50 batch: 0.355074
Train loss on 100 batch: 0.386230
Train loss on 150 batch: 0.275273
: Epoch: 5 | Training Loss: 0.333670 | Val. Loss: 0.349293 | Val. Kappa Score: 0.7893 | LR: 0.001000 | Estimated time: 69.60
Train loss on 50 batch: 0.316030
Train loss on 100 batch: 0.319334
Train loss on 150 batch: 0.292852
: Epoch: 6 | Training Loss: 0.297602 | Val. Loss: 0.422831 | Val. Kappa Score: 0.7962 | LR: 0.000500 | Estimated time: 69.38
Train loss on 50 batch: 0.305494
Train loss on 100 batch: 0.264324
Train loss on 150 batch: 0.287912
: Epoch: 7 | Training Loss: 0.289676 | Val. Loss: 0.372145 | Val. Kappa Score: 0.8047 | LR: 0.000500 | Estimated time: 69.46
Train loss on 50 batch: 0.243788
Train loss on 100 batch: 0.296685
Train loss on 150 batch: 0.245149
best-train-loss: 0.284979
best-valid-loss: 0.314664
best-kappa: 0.8130
: Epoch: 8 | Training Loss: 0.284979 | Val. Loss: 0.314664 | Val. Kappa Score: 0.8130 | LR: 0.000500 | Estimated time: 69.48
Train loss on 50 batch: 0.276449
Train loss on 100 batch: 0.302717
Train loss on 150 batch: 0.274725
: Epoch: 9 | Training Loss: 0.272953 | Val. Loss: 0.382696 | Val. Kappa Score: 0.8182 | LR: 0.000500 | Estimated time: 69.90
Train loss on 50 batch: 0.251184
Train loss on 100 batch: 0.273882
Train loss on 150 batch: 0.297865
: Epoch: 10 | Training Loss: 0.352858 | Val. Loss: 0.338657 | Val. Kappa Score: 0.8226 | LR: 0.000500 | Estimated time: 70.15
Train loss on 50 batch: 0.291944
Train loss on 100 batch: 0.275409
Train loss on 150 batch: 0.276900
: Epoch: 11 | Training Loss: 0.286888 | Val. Loss: 0.331221 | Val. Kappa Score: 0.8270 | LR: 0.000250 | Estimated time: 70.02
Train loss on 50 batch: 0.236988
Train loss on 100 batch: 0.242102
Train loss on 150 batch: 0.267312
: Epoch: 12 | Training Loss: 0.252057 | Val. Loss: 0.336030 | Val. Kappa Score: 0.8299 | LR: 0.000250 | Estimated time: 69.59
Train loss on 50 batch: 0.238865
Train loss on 100 batch: 0.285891
Train loss on 150 batch: 0.253761
best-train-loss: 0.269450
best-valid-loss: 0.312769
best-kappa: 0.8345
: Epoch: 13 | Training Loss: 0.269450 | Val. Loss: 0.312769 | Val. Kappa Score: 0.8345 | LR: 0.000250 | Estimated time: 69.56
Train loss on 50 batch: 0.239998
Train loss on 100 batch: 0.241805
Train loss on 150 batch: 0.289663
best-train-loss: 0.254201
best-valid-loss: 0.312065
best-kappa: 0.8375
: Epoch: 14 | Training Loss: 0.254201 | Val. Loss: 0.312065 | Val. Kappa Score: 0.8375 | LR: 0.000250 | Estimated time: 69.14
Train loss on 50 batch: 0.268923
Train loss on 100 batch: 0.239514
Train loss on 150 batch: 0.246683
: Epoch: 15 | Training Loss: 0.265692 | Val. Loss: 0.321313 | Val. Kappa Score: 0.8408 | LR: 0.000250 | Estimated time: 69.73
Train loss on 50 batch: 0.258229
Train loss on 100 batch: 0.217069
Train loss on 150 batch: 0.240745
: Epoch: 16 | Training Loss: 0.241179 | Val. Loss: 0.312435 | Val. Kappa Score: 0.8433 | LR: 0.000250 | Estimated time: 70.31
Train loss on 50 batch: 0.277723
Train loss on 100 batch: 0.259100
Train loss on 150 batch: 0.211406
best-train-loss: 0.245618
best-valid-loss: 0.306073
best-kappa: 0.8461
: Epoch: 17 | Training Loss: 0.245618 | Val. Loss: 0.306073 | Val. Kappa Score: 0.8461 | LR: 0.000250 | Estimated time: 69.42
Train loss on 50 batch: 0.249929
Train loss on 100 batch: 0.206837
Train loss on 150 batch: 0.244398
best-train-loss: 0.239884
best-valid-loss: 0.305632
best-kappa: 0.8483
: Epoch: 18 | Training Loss: 0.239884 | Val. Loss: 0.305632 | Val. Kappa Score: 0.8483 | LR: 0.000250 | Estimated time: 69.13
Train loss on 50 batch: 0.200931
Train loss on 100 batch: 0.246571
Train loss on 150 batch: 0.269486
best-train-loss: 0.245682
best-valid-loss: 0.300220
best-kappa: 0.8497
: Epoch: 19 | Training Loss: 0.245682 | Val. Loss: 0.300220 | Val. Kappa Score: 0.8497 | LR: 0.000250 | Estimated time: 69.85
Train loss on 50 batch: 0.244352
Train loss on 100 batch: 0.268668
Train loss on 150 batch: 0.225498
: Epoch: 20 | Training Loss: 0.235301 | Val. Loss: 0.320302 | Val. Kappa Score: 0.8510 | LR: 0.000250 | Estimated time: 69.39
Train loss on 50 batch: 0.233388
Train loss on 100 batch: 0.229709
Train loss on 150 batch: 0.251957
best-train-loss: 0.285340
best-valid-loss: 0.298189
best-kappa: 0.8529
: Epoch: 21 | Training Loss: 0.285340 | Val. Loss: 0.298189 | Val. Kappa Score: 0.8529 | LR: 0.000250 | Estimated time: 69.72
Train loss on 50 batch: 0.222581
Train loss on 100 batch: 0.229375
Train loss on 150 batch: 0.246028
: Epoch: 22 | Training Loss: 0.228159 | Val. Loss: 0.314803 | Val. Kappa Score: 0.8541 | LR: 0.000250 | Estimated time: 69.29
Train loss on 50 batch: 0.225336
Train loss on 100 batch: 0.232907
Train loss on 150 batch: 0.236586
: Epoch: 23 | Training Loss: 0.241620 | Val. Loss: 0.359000 | Val. Kappa Score: 0.8545 | LR: 0.000250 | Estimated time: 68.92
Train loss on 50 batch: 0.235931
Train loss on 100 batch: 0.225869
Train loss on 150 batch: 0.227453
: Epoch: 24 | Training Loss: 0.277662 | Val. Loss: 0.313206 | Val. Kappa Score: 0.8553 | LR: 0.000125 | Estimated time: 69.91
Train loss on 50 batch: 0.235805
Train loss on 100 batch: 0.213205
Train loss on 150 batch: 0.257290
best-train-loss: 0.232201
best-valid-loss: 0.288253
best-kappa: 0.8568
: Epoch: 25 | Training Loss: 0.232201 | Val. Loss: 0.288253 | Val. Kappa Score: 0.8568 | LR: 0.000125 | Estimated time: 69.28
Train loss on 50 batch: 0.214673
Train loss on 100 batch: 0.178713
Train loss on 150 batch: 0.244040
: Epoch: 26 | Training Loss: 0.257102 | Val. Loss: 0.291788 | Val. Kappa Score: 0.8577 | LR: 0.000125 | Estimated time: 70.02
Train loss on 50 batch: 0.230771
Train loss on 100 batch: 0.250623
Train loss on 150 batch: 0.203391
: Epoch: 27 | Training Loss: 0.236600 | Val. Loss: 0.301017 | Val. Kappa Score: 0.8589 | LR: 0.000125 | Estimated time: 69.56
Train loss on 50 batch: 0.228699
Train loss on 100 batch: 0.229255
Train loss on 150 batch: 0.201275
: Epoch: 28 | Training Loss: 0.234234 | Val. Loss: 0.288771 | Val. Kappa Score: 0.8601 | LR: 0.000063 | Estimated time: 70.14
Train loss on 50 batch: 0.182830
Train loss on 100 batch: 0.223467
Train loss on 150 batch: 0.218352
: Epoch: 29 | Training Loss: 0.223640 | Val. Loss: 0.290063 | Val. Kappa Score: 0.8608 | LR: 0.000063 | Estimated time: 69.52
Train loss on 50 batch: 0.202802
Train loss on 100 batch: 0.232212
Train loss on 150 batch: 0.219783
: Epoch: 30 | Training Loss: 0.226166 | Val. Loss: 0.290075 | Val. Kappa Score: 0.8618 | LR: 0.000063 | Estimated time: 71.11
Train loss on 50 batch: 0.189368
Train loss on 100 batch: 0.233215
Train loss on 150 batch: 0.200310
best-train-loss: 0.222939
best-valid-loss: 0.284045
best-kappa: 0.8629
: Epoch: 31 | Training Loss: 0.222939 | Val. Loss: 0.284045 | Val. Kappa Score: 0.8629 | LR: 0.000063 | Estimated time: 70.90
Train loss on 50 batch: 0.229685
Train loss on 100 batch: 0.236659
Train loss on 150 batch: 0.197404
: Epoch: 32 | Training Loss: 0.216389 | Val. Loss: 0.289026 | Val. Kappa Score: 0.8636 | LR: 0.000063 | Estimated time: 69.61
Train loss on 50 batch: 0.229844
Train loss on 100 batch: 0.199942
Train loss on 150 batch: 0.176633
: Epoch: 33 | Training Loss: 0.208611 | Val. Loss: 0.291526 | Val. Kappa Score: 0.8645 | LR: 0.000063 | Estimated time: 69.37
Train loss on 50 batch: 0.191396
Train loss on 100 batch: 0.225189
Train loss on 150 batch: 0.212884
: Epoch: 34 | Training Loss: 0.208173 | Val. Loss: 0.287540 | Val. Kappa Score: 0.8652 | LR: 0.000031 | Estimated time: 69.10
Train loss on 50 batch: 0.206247
Train loss on 100 batch: 0.221676
Train loss on 150 batch: 0.193117
: Epoch: 35 | Training Loss: 0.223403 | Val. Loss: 0.284660 | Val. Kappa Score: 0.8659 | LR: 0.000031 | Estimated time: 68.98
Train loss on 50 batch: 0.201681
Train loss on 100 batch: 0.217059
Train loss on 150 batch: 0.200481
: Epoch: 36 | Training Loss: 0.221877 | Val. Loss: 0.286254 | Val. Kappa Score: 0.8666 | LR: 0.000031 | Estimated time: 69.05
Train loss on 50 batch: 0.217645
Train loss on 100 batch: 0.191307
Train loss on 150 batch: 0.198076
: Epoch: 37 | Training Loss: 0.215812 | Val. Loss: 0.285602 | Val. Kappa Score: 0.8671 | LR: 0.000016 | Estimated time: 68.73
Train loss on 50 batch: 0.182383
Train loss on 100 batch: 0.201336
Train loss on 150 batch: 0.222146
: Epoch: 38 | Training Loss: 0.282968 | Val. Loss: 0.285261 | Val. Kappa Score: 0.8679 | LR: 0.000016 | Estimated time: 69.96
Train loss on 50 batch: 0.223419
Train loss on 100 batch: 0.205673
Train loss on 150 batch: 0.213915
: Epoch: 39 | Training Loss: 0.222294 | Val. Loss: 0.286662 | Val. Kappa Score: 0.8683 | LR: 0.000016 | Estimated time: 69.81
Train loss on 50 batch: 0.211266
Train loss on 100 batch: 0.197323
Train loss on 150 batch: 0.211713
: Epoch: 40 | Training Loss: 0.215756 | Val. Loss: 0.286517 | Val. Kappa Score: 0.8688 | LR: 0.000008 | Estimated time: 69.89
Train loss on 50 batch: 0.178140
Train loss on 100 batch: 0.218224
Train loss on 150 batch: 0.207657
: Epoch: 41 | Training Loss: 0.203180 | Val. Loss: 0.287393 | Val. Kappa Score: 0.8694 | LR: 0.000008 | Estimated time: 68.48
time_estimated: 2856.32
n-epochs: 41
time_estimated: 2856.36
----------------------------------------

Experiment N: 153: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.27 14:12:27
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95e9bfd0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.681870
Train loss on 100 batch: 0.459595
Train loss on 150 batch: 0.451437
best-train-loss: 0.491034
best-valid-loss: 0.432518
best-kappa: 0.8364
: Epoch: 1 | Training Loss: 0.491034 | Val. Loss: 0.432518 | Val. Kappa Score: 0.8364 | LR: 0.001000 | Estimated time: 72.20
Train loss on 50 batch: 0.359504
Train loss on 100 batch: 0.365768
Train loss on 150 batch: 0.317649
: Epoch: 2 | Training Loss: 0.373673 | Val. Loss: 0.587128 | Val. Kappa Score: 0.7563 | LR: 0.001000 | Estimated time: 69.80
Train loss on 50 batch: 0.354533
Train loss on 100 batch: 0.353521
Train loss on 150 batch: 0.325232
: Epoch: 3 | Training Loss: 0.334844 | Val. Loss: 0.552297 | Val. Kappa Score: 0.7796 | LR: 0.001000 | Estimated time: 69.75
Train loss on 50 batch: 0.319235
Train loss on 100 batch: 0.314786
Train loss on 150 batch: 0.315049
best-train-loss: 0.394458
best-valid-loss: 0.384167
best-kappa: 0.7959
: Epoch: 4 | Training Loss: 0.394458 | Val. Loss: 0.384167 | Val. Kappa Score: 0.7959 | LR: 0.001000 | Estimated time: 69.18
Train loss on 50 batch: 0.349705
Train loss on 100 batch: 0.353338
Train loss on 150 batch: 0.260748
: Epoch: 5 | Training Loss: 0.318345 | Val. Loss: 0.388535 | Val. Kappa Score: 0.8093 | LR: 0.001000 | Estimated time: 69.25
Train loss on 50 batch: 0.308898
Train loss on 100 batch: 0.323156
Train loss on 150 batch: 0.293011
best-train-loss: 0.293673
best-valid-loss: 0.336816
best-kappa: 0.8180
: Epoch: 6 | Training Loss: 0.293673 | Val. Loss: 0.336816 | Val. Kappa Score: 0.8180 | LR: 0.001000 | Estimated time: 69.48
Train loss on 50 batch: 0.320317
Train loss on 100 batch: 0.271319
Train loss on 150 batch: 0.274186
best-train-loss: 0.287870
best-valid-loss: 0.305896
best-kappa: 0.8274
: Epoch: 7 | Training Loss: 0.287870 | Val. Loss: 0.305896 | Val. Kappa Score: 0.8274 | LR: 0.001000 | Estimated time: 69.85
Train loss on 50 batch: 0.249052
Train loss on 100 batch: 0.295714
Train loss on 150 batch: 0.246696
: Epoch: 8 | Training Loss: 0.287988 | Val. Loss: 0.311434 | Val. Kappa Score: 0.8339 | LR: 0.001000 | Estimated time: 68.95
Train loss on 50 batch: 0.267438
Train loss on 100 batch: 0.307244
Train loss on 150 batch: 0.288730
: Epoch: 9 | Training Loss: 0.281420 | Val. Loss: 0.306313 | Val. Kappa Score: 0.8395 | LR: 0.001000 | Estimated time: 69.71
Train loss on 50 batch: 0.254379
Train loss on 100 batch: 0.297289
Train loss on 150 batch: 0.270749
: Epoch: 10 | Training Loss: 0.352280 | Val. Loss: 0.371400 | Val. Kappa Score: 0.8406 | LR: 0.000500 | Estimated time: 70.20
Train loss on 50 batch: 0.276368
Train loss on 100 batch: 0.269697
Train loss on 150 batch: 0.246406
: Epoch: 11 | Training Loss: 0.261892 | Val. Loss: 0.337927 | Val. Kappa Score: 0.8432 | LR: 0.000500 | Estimated time: 69.83
Train loss on 50 batch: 0.234028
Train loss on 100 batch: 0.233625
Train loss on 150 batch: 0.272179
: Epoch: 12 | Training Loss: 0.250056 | Val. Loss: 0.309186 | Val. Kappa Score: 0.8459 | LR: 0.000500 | Estimated time: 69.18
Train loss on 50 batch: 0.237370
Train loss on 100 batch: 0.263269
Train loss on 150 batch: 0.236733
best-train-loss: 0.258413
best-valid-loss: 0.295343
best-kappa: 0.8494
: Epoch: 13 | Training Loss: 0.258413 | Val. Loss: 0.295343 | Val. Kappa Score: 0.8494 | LR: 0.000500 | Estimated time: 69.61
Train loss on 50 batch: 0.232659
Train loss on 100 batch: 0.227157
Train loss on 150 batch: 0.285879
: Epoch: 14 | Training Loss: 0.246074 | Val. Loss: 0.321785 | Val. Kappa Score: 0.8518 | LR: 0.000500 | Estimated time: 69.26
Train loss on 50 batch: 0.264554
Train loss on 100 batch: 0.226709
Train loss on 150 batch: 0.235520
: Epoch: 15 | Training Loss: 0.253722 | Val. Loss: 0.295579 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 69.00
Train loss on 50 batch: 0.257071
Train loss on 100 batch: 0.218039
Train loss on 150 batch: 0.242713
best-train-loss: 0.239874
best-valid-loss: 0.291662
best-kappa: 0.8552
: Epoch: 16 | Training Loss: 0.239874 | Val. Loss: 0.291662 | Val. Kappa Score: 0.8552 | LR: 0.000500 | Estimated time: 69.62
Train loss on 50 batch: 0.265939
Train loss on 100 batch: 0.246057
Train loss on 150 batch: 0.196056
: Epoch: 17 | Training Loss: 0.237173 | Val. Loss: 0.308855 | Val. Kappa Score: 0.8571 | LR: 0.000500 | Estimated time: 69.48
Train loss on 50 batch: 0.261200
Train loss on 100 batch: 0.193378
Train loss on 150 batch: 0.235684
: Epoch: 18 | Training Loss: 0.230962 | Val. Loss: 0.306607 | Val. Kappa Score: 0.8583 | LR: 0.000500 | Estimated time: 69.58
Train loss on 50 batch: 0.212334
Train loss on 100 batch: 0.227389
Train loss on 150 batch: 0.253843
: Epoch: 19 | Training Loss: 0.237878 | Val. Loss: 0.302914 | Val. Kappa Score: 0.8595 | LR: 0.000250 | Estimated time: 69.93
Train loss on 50 batch: 0.228135
Train loss on 100 batch: 0.257118
Train loss on 150 batch: 0.210834
best-train-loss: 0.226601
best-valid-loss: 0.289784
best-kappa: 0.8608
: Epoch: 20 | Training Loss: 0.226601 | Val. Loss: 0.289784 | Val. Kappa Score: 0.8608 | LR: 0.000250 | Estimated time: 69.19
Train loss on 50 batch: 0.203163
Train loss on 100 batch: 0.208552
Train loss on 150 batch: 0.229786
: Epoch: 21 | Training Loss: 0.266484 | Val. Loss: 0.315941 | Val. Kappa Score: 0.8620 | LR: 0.000250 | Estimated time: 68.43
Train loss on 50 batch: 0.217331
Train loss on 100 batch: 0.218148
Train loss on 150 batch: 0.249993
: Epoch: 22 | Training Loss: 0.222266 | Val. Loss: 0.319774 | Val. Kappa Score: 0.8627 | LR: 0.000250 | Estimated time: 70.02
Train loss on 50 batch: 0.225041
Train loss on 100 batch: 0.216289
Train loss on 150 batch: 0.207801
: Epoch: 23 | Training Loss: 0.232094 | Val. Loss: 0.298760 | Val. Kappa Score: 0.8633 | LR: 0.000125 | Estimated time: 68.78
Train loss on 50 batch: 0.221372
Train loss on 100 batch: 0.211295
Train loss on 150 batch: 0.190994
best-train-loss: 0.292783
best-valid-loss: 0.287592
best-kappa: 0.8633
: Epoch: 24 | Training Loss: 0.292783 | Val. Loss: 0.287592 | Val. Kappa Score: 0.8633 | LR: 0.000125 | Estimated time: 70.13
Train loss on 50 batch: 0.209603
Train loss on 100 batch: 0.204352
Train loss on 150 batch: 0.245978
: Epoch: 25 | Training Loss: 0.217870 | Val. Loss: 0.295698 | Val. Kappa Score: 0.8640 | LR: 0.000125 | Estimated time: 69.47
Train loss on 50 batch: 0.215520
Train loss on 100 batch: 0.171133
Train loss on 150 batch: 0.235880
: Epoch: 26 | Training Loss: 0.260900 | Val. Loss: 0.290253 | Val. Kappa Score: 0.8646 | LR: 0.000125 | Estimated time: 69.36
Train loss on 50 batch: 0.222764
Train loss on 100 batch: 0.224507
Train loss on 150 batch: 0.195430
: Epoch: 27 | Training Loss: 0.232308 | Val. Loss: 0.298180 | Val. Kappa Score: 0.8653 | LR: 0.000063 | Estimated time: 69.69
Train loss on 50 batch: 0.223953
Train loss on 100 batch: 0.212331
Train loss on 150 batch: 0.204255
: Epoch: 28 | Training Loss: 0.235402 | Val. Loss: 0.289320 | Val. Kappa Score: 0.8654 | LR: 0.000063 | Estimated time: 68.95
Train loss on 50 batch: 0.165129
Train loss on 100 batch: 0.218466
Train loss on 150 batch: 0.207571
best-train-loss: 0.214735
best-valid-loss: 0.285579
best-kappa: 0.8659
: Epoch: 29 | Training Loss: 0.214735 | Val. Loss: 0.285579 | Val. Kappa Score: 0.8659 | LR: 0.000063 | Estimated time: 69.83
Train loss on 50 batch: 0.198456
Train loss on 100 batch: 0.214137
Train loss on 150 batch: 0.213908
: Epoch: 30 | Training Loss: 0.222577 | Val. Loss: 0.287219 | Val. Kappa Score: 0.8664 | LR: 0.000063 | Estimated time: 69.56
Train loss on 50 batch: 0.181557
Train loss on 100 batch: 0.215632
Train loss on 150 batch: 0.193263
: Epoch: 31 | Training Loss: 0.207131 | Val. Loss: 0.291241 | Val. Kappa Score: 0.8671 | LR: 0.000063 | Estimated time: 69.83
Train loss on 50 batch: 0.200751
Train loss on 100 batch: 0.225807
Train loss on 150 batch: 0.193679
best-train-loss: 0.204932
best-valid-loss: 0.282931
best-kappa: 0.8673
: Epoch: 32 | Training Loss: 0.204932 | Val. Loss: 0.282931 | Val. Kappa Score: 0.8673 | LR: 0.000063 | Estimated time: 69.61
Train loss on 50 batch: 0.204531
Train loss on 100 batch: 0.195805
Train loss on 150 batch: 0.170600
: Epoch: 33 | Training Loss: 0.198641 | Val. Loss: 0.288599 | Val. Kappa Score: 0.8680 | LR: 0.000063 | Estimated time: 69.14
Train loss on 50 batch: 0.181672
Train loss on 100 batch: 0.206851
Train loss on 150 batch: 0.228042
best-train-loss: 0.201316
best-valid-loss: 0.281650
best-kappa: 0.8681
: Epoch: 34 | Training Loss: 0.201316 | Val. Loss: 0.281650 | Val. Kappa Score: 0.8681 | LR: 0.000063 | Estimated time: 69.50
Train loss on 50 batch: 0.197095
Train loss on 100 batch: 0.215478
Train loss on 150 batch: 0.167459
: Epoch: 35 | Training Loss: 0.214353 | Val. Loss: 0.286342 | Val. Kappa Score: 0.8682 | LR: 0.000063 | Estimated time: 69.14
Train loss on 50 batch: 0.167701
Train loss on 100 batch: 0.210638
Train loss on 150 batch: 0.186051
: Epoch: 36 | Training Loss: 0.205733 | Val. Loss: 0.292724 | Val. Kappa Score: 0.8684 | LR: 0.000063 | Estimated time: 68.17
Train loss on 50 batch: 0.204005
Train loss on 100 batch: 0.195934
Train loss on 150 batch: 0.205426
: Epoch: 37 | Training Loss: 0.217868 | Val. Loss: 0.285159 | Val. Kappa Score: 0.8685 | LR: 0.000031 | Estimated time: 69.53
Train loss on 50 batch: 0.180854
Train loss on 100 batch: 0.187015
Train loss on 150 batch: 0.228284
: Epoch: 38 | Training Loss: 0.282302 | Val. Loss: 0.287375 | Val. Kappa Score: 0.8690 | LR: 0.000031 | Estimated time: 69.23
Train loss on 50 batch: 0.199669
Train loss on 100 batch: 0.183767
Train loss on 150 batch: 0.193718
: Epoch: 39 | Training Loss: 0.213302 | Val. Loss: 0.287263 | Val. Kappa Score: 0.8694 | LR: 0.000031 | Estimated time: 70.19
Train loss on 50 batch: 0.199888
Train loss on 100 batch: 0.185009
Train loss on 150 batch: 0.215333
: Epoch: 40 | Training Loss: 0.209499 | Val. Loss: 0.286743 | Val. Kappa Score: 0.8696 | LR: 0.000016 | Estimated time: 69.05
Train loss on 50 batch: 0.179889
Train loss on 100 batch: 0.232684
Train loss on 150 batch: 0.208042
: Epoch: 41 | Training Loss: 0.205403 | Val. Loss: 0.285602 | Val. Kappa Score: 0.8700 | LR: 0.000016 | Estimated time: 69.42
Train loss on 50 batch: 0.220714
Train loss on 100 batch: 0.180639
Train loss on 150 batch: 0.188543
: Epoch: 42 | Training Loss: 0.199730 | Val. Loss: 0.283841 | Val. Kappa Score: 0.8704 | LR: 0.000016 | Estimated time: 69.99
Train loss on 50 batch: 0.200346
Train loss on 100 batch: 0.195262
Train loss on 150 batch: 0.181038
: Epoch: 43 | Training Loss: 0.197581 | Val. Loss: 0.282068 | Val. Kappa Score: 0.8708 | LR: 0.000008 | Estimated time: 69.87
Train loss on 50 batch: 0.184655
Train loss on 100 batch: 0.197044
Train loss on 150 batch: 0.203978
: Epoch: 44 | Training Loss: 0.188974 | Val. Loss: 0.283232 | Val. Kappa Score: 0.8710 | LR: 0.000008 | Estimated time: 69.89
time_estimated: 3062.59
n-epochs: 44
time_estimated: 3062.63
----------------------------------------

Experiment N: 154: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.28 00:34:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f9ff28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 150
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.975354
Train loss on 100 batch: 0.698855
Train loss on 150 batch: 0.588200
best-train-loss: 0.694022
best-valid-loss: 0.887949
best-kappa: 0.5390
: Epoch: 1 | Training Loss: 0.694022 | Val. Loss: 0.887949 | Val. Kappa Score: 0.5390 | LR: 0.001000 | Estimated time: 66.46
Train loss on 50 batch: 0.558810
Train loss on 100 batch: 0.534682
Train loss on 150 batch: 0.479695
: Epoch: 2 | Training Loss: 0.551398 | Val. Loss: 1.426638 | Val. Kappa Score: 0.5011 | LR: 0.001000 | Estimated time: 66.03
Train loss on 50 batch: 0.591747
Train loss on 100 batch: 0.554670
Train loss on 150 batch: 0.535913
best-train-loss: 0.551004
best-valid-loss: 0.726519
best-kappa: 0.5565
: Epoch: 3 | Training Loss: 0.551004 | Val. Loss: 0.726519 | Val. Kappa Score: 0.5565 | LR: 0.001000 | Estimated time: 66.37
Train loss on 50 batch: 0.511107
Train loss on 100 batch: 0.572090
Train loss on 150 batch: 0.514834
best-train-loss: 0.584680
best-valid-loss: 0.679138
best-kappa: 0.6004
: Epoch: 4 | Training Loss: 0.584680 | Val. Loss: 0.679138 | Val. Kappa Score: 0.6004 | LR: 0.001000 | Estimated time: 66.25
Train loss on 50 batch: 0.482757
Train loss on 100 batch: 0.562628
Train loss on 150 batch: 0.500528
best-train-loss: 0.516677
best-valid-loss: 0.650392
best-kappa: 0.6319
: Epoch: 5 | Training Loss: 0.516677 | Val. Loss: 0.650392 | Val. Kappa Score: 0.6319 | LR: 0.001000 | Estimated time: 66.69
Train loss on 50 batch: 0.474176
Train loss on 100 batch: 0.462224
Train loss on 150 batch: 0.468501
best-train-loss: 0.473749
best-valid-loss: 0.407089
best-kappa: 0.6641
: Epoch: 6 | Training Loss: 0.473749 | Val. Loss: 0.407089 | Val. Kappa Score: 0.6641 | LR: 0.001000 | Estimated time: 65.43
Train loss on 50 batch: 0.508539
Train loss on 100 batch: 0.462126
Train loss on 150 batch: 0.493609
: Epoch: 7 | Training Loss: 0.489012 | Val. Loss: 0.446734 | Val. Kappa Score: 0.6880 | LR: 0.001000 | Estimated time: 65.91
Train loss on 50 batch: 0.384381
Train loss on 100 batch: 0.485672
Train loss on 150 batch: 0.416141
: Epoch: 8 | Training Loss: 0.439346 | Val. Loss: 0.446176 | Val. Kappa Score: 0.7051 | LR: 0.001000 | Estimated time: 65.23
Train loss on 50 batch: 0.471375
Train loss on 100 batch: 0.490978
Train loss on 150 batch: 0.445066
best-train-loss: 0.457757
best-valid-loss: 0.367270
best-kappa: 0.7223
: Epoch: 9 | Training Loss: 0.457757 | Val. Loss: 0.367270 | Val. Kappa Score: 0.7223 | LR: 0.001000 | Estimated time: 66.27
Train loss on 50 batch: 0.392860
Train loss on 100 batch: 0.482224
Train loss on 150 batch: 0.444450
: Epoch: 10 | Training Loss: 0.495881 | Val. Loss: 0.381811 | Val. Kappa Score: 0.7339 | LR: 0.001000 | Estimated time: 66.36
Train loss on 50 batch: 0.477120
Train loss on 100 batch: 0.440898
Train loss on 150 batch: 0.461491
: Epoch: 11 | Training Loss: 0.462258 | Val. Loss: 0.416854 | Val. Kappa Score: 0.7443 | LR: 0.001000 | Estimated time: 66.24
Train loss on 50 batch: 0.446753
Train loss on 100 batch: 0.420104
Train loss on 150 batch: 0.475187
: Epoch: 12 | Training Loss: 0.449161 | Val. Loss: 0.369035 | Val. Kappa Score: 0.7546 | LR: 0.000500 | Estimated time: 66.38
Train loss on 50 batch: 0.377447
Train loss on 100 batch: 0.426677
Train loss on 150 batch: 0.448743
: Epoch: 13 | Training Loss: 0.417988 | Val. Loss: 0.378083 | Val. Kappa Score: 0.7633 | LR: 0.000500 | Estimated time: 65.28
Train loss on 50 batch: 0.374086
Train loss on 100 batch: 0.383629
Train loss on 150 batch: 0.469039
: Epoch: 14 | Training Loss: 0.427870 | Val. Loss: 0.449126 | Val. Kappa Score: 0.7674 | LR: 0.000500 | Estimated time: 65.39
Train loss on 50 batch: 0.440176
Train loss on 100 batch: 0.382398
Train loss on 150 batch: 0.342869
best-train-loss: 0.396070
best-valid-loss: 0.363927
best-kappa: 0.7737
: Epoch: 15 | Training Loss: 0.396070 | Val. Loss: 0.363927 | Val. Kappa Score: 0.7737 | LR: 0.000500 | Estimated time: 65.23
Train loss on 50 batch: 0.436661
Train loss on 100 batch: 0.383599
Train loss on 150 batch: 0.340687
: Epoch: 16 | Training Loss: 0.391360 | Val. Loss: 0.437277 | Val. Kappa Score: 0.7772 | LR: 0.000500 | Estimated time: 64.44
Train loss on 50 batch: 0.486006
Train loss on 100 batch: 0.409410
Train loss on 150 batch: 0.355601
: Epoch: 17 | Training Loss: 0.420851 | Val. Loss: 0.388756 | Val. Kappa Score: 0.7817 | LR: 0.000500 | Estimated time: 64.85
Train loss on 50 batch: 0.396482
Train loss on 100 batch: 0.335867
Train loss on 150 batch: 0.390703
best-train-loss: 0.376350
best-valid-loss: 0.346307
best-kappa: 0.7866
: Epoch: 18 | Training Loss: 0.376350 | Val. Loss: 0.346307 | Val. Kappa Score: 0.7866 | LR: 0.000500 | Estimated time: 65.42
Train loss on 50 batch: 0.361882
Train loss on 100 batch: 0.460769
Train loss on 150 batch: 0.468025
: Epoch: 19 | Training Loss: 0.444161 | Val. Loss: 0.359221 | Val. Kappa Score: 0.7903 | LR: 0.000500 | Estimated time: 64.99
Train loss on 50 batch: 0.407448
Train loss on 100 batch: 0.416446
Train loss on 150 batch: 0.398927
: Epoch: 20 | Training Loss: 0.409274 | Val. Loss: 0.412704 | Val. Kappa Score: 0.7926 | LR: 0.000500 | Estimated time: 65.00
Train loss on 50 batch: 0.395891
Train loss on 100 batch: 0.394990
Train loss on 150 batch: 0.428137
: Epoch: 21 | Training Loss: 0.427537 | Val. Loss: 0.357579 | Val. Kappa Score: 0.7967 | LR: 0.000250 | Estimated time: 64.99
Train loss on 50 batch: 0.391788
Train loss on 100 batch: 0.396352
Train loss on 150 batch: 0.443025
: Epoch: 22 | Training Loss: 0.400778 | Val. Loss: 0.352008 | Val. Kappa Score: 0.8001 | LR: 0.000250 | Estimated time: 65.42
Train loss on 50 batch: 0.388122
Train loss on 100 batch: 0.383445
Train loss on 150 batch: 0.387685
: Epoch: 23 | Training Loss: 0.390603 | Val. Loss: 0.373767 | Val. Kappa Score: 0.8027 | LR: 0.000250 | Estimated time: 64.82
Train loss on 50 batch: 0.432402
Train loss on 100 batch: 0.410793
Train loss on 150 batch: 0.347103
best-train-loss: 0.439048
best-valid-loss: 0.339575
best-kappa: 0.8047
: Epoch: 24 | Training Loss: 0.439048 | Val. Loss: 0.339575 | Val. Kappa Score: 0.8047 | LR: 0.000250 | Estimated time: 64.78
Train loss on 50 batch: 0.400016
Train loss on 100 batch: 0.343549
Train loss on 150 batch: 0.468996
best-train-loss: 0.390615
best-valid-loss: 0.336189
best-kappa: 0.8075
: Epoch: 25 | Training Loss: 0.390615 | Val. Loss: 0.336189 | Val. Kappa Score: 0.8075 | LR: 0.000250 | Estimated time: 65.26
Train loss on 50 batch: 0.415161
Train loss on 100 batch: 0.337345
Train loss on 150 batch: 0.466205
: Epoch: 26 | Training Loss: 0.410402 | Val. Loss: 0.344423 | Val. Kappa Score: 0.8095 | LR: 0.000250 | Estimated time: 64.96
Train loss on 50 batch: 0.390962
Train loss on 100 batch: 0.461077
Train loss on 150 batch: 0.390497
best-train-loss: 0.417685
best-valid-loss: 0.321462
best-kappa: 0.8122
: Epoch: 27 | Training Loss: 0.417685 | Val. Loss: 0.321462 | Val. Kappa Score: 0.8122 | LR: 0.000250 | Estimated time: 65.29
Train loss on 50 batch: 0.489850
Train loss on 100 batch: 0.421776
Train loss on 150 batch: 0.360725
: Epoch: 28 | Training Loss: 0.409198 | Val. Loss: 0.358202 | Val. Kappa Score: 0.8140 | LR: 0.000250 | Estimated time: 65.59
Train loss on 50 batch: 0.340981
Train loss on 100 batch: 0.402415
Train loss on 150 batch: 0.375562
: Epoch: 29 | Training Loss: 0.374294 | Val. Loss: 0.336202 | Val. Kappa Score: 0.8159 | LR: 0.000250 | Estimated time: 65.74
Train loss on 50 batch: 0.396886
Train loss on 100 batch: 0.415219
Train loss on 150 batch: 0.413348
: Epoch: 30 | Training Loss: 0.401012 | Val. Loss: 0.362639 | Val. Kappa Score: 0.8168 | LR: 0.000125 | Estimated time: 64.63
Train loss on 50 batch: 0.341554
Train loss on 100 batch: 0.366604
Train loss on 150 batch: 0.374674
best-train-loss: 0.384680
best-valid-loss: 0.319321
best-kappa: 0.8187
: Epoch: 31 | Training Loss: 0.384680 | Val. Loss: 0.319321 | Val. Kappa Score: 0.8187 | LR: 0.000125 | Estimated time: 65.59
Train loss on 50 batch: 0.337263
Train loss on 100 batch: 0.435005
Train loss on 150 batch: 0.333392
: Epoch: 32 | Training Loss: 0.379496 | Val. Loss: 0.325040 | Val. Kappa Score: 0.8207 | LR: 0.000125 | Estimated time: 65.34
Train loss on 50 batch: 0.388785
Train loss on 100 batch: 0.398181
Train loss on 150 batch: 0.348661
: Epoch: 33 | Training Loss: 0.378048 | Val. Loss: 0.323310 | Val. Kappa Score: 0.8226 | LR: 0.000125 | Estimated time: 65.19
Train loss on 50 batch: 0.291187
Train loss on 100 batch: 0.409729
Train loss on 150 batch: 0.354142
: Epoch: 34 | Training Loss: 0.356601 | Val. Loss: 0.332359 | Val. Kappa Score: 0.8239 | LR: 0.000063 | Estimated time: 65.28
Train loss on 50 batch: 0.373068
Train loss on 100 batch: 0.366138
Train loss on 150 batch: 0.379790
best-train-loss: 0.378338
best-valid-loss: 0.319035
best-kappa: 0.8251
: Epoch: 35 | Training Loss: 0.378338 | Val. Loss: 0.319035 | Val. Kappa Score: 0.8251 | LR: 0.000063 | Estimated time: 64.30
Train loss on 50 batch: 0.331458
Train loss on 100 batch: 0.387674
Train loss on 150 batch: 0.360274
best-train-loss: 0.383862
best-valid-loss: 0.318594
best-kappa: 0.8266
: Epoch: 36 | Training Loss: 0.383862 | Val. Loss: 0.318594 | Val. Kappa Score: 0.8266 | LR: 0.000063 | Estimated time: 64.80
Train loss on 50 batch: 0.387518
Train loss on 100 batch: 0.353207
Train loss on 150 batch: 0.382131
: Epoch: 37 | Training Loss: 0.385768 | Val. Loss: 0.319325 | Val. Kappa Score: 0.8277 | LR: 0.000063 | Estimated time: 65.36
Train loss on 50 batch: 0.304202
Train loss on 100 batch: 0.353676
Train loss on 150 batch: 0.310598
best-train-loss: 0.411243
best-valid-loss: 0.316225
best-kappa: 0.8291
: Epoch: 38 | Training Loss: 0.411243 | Val. Loss: 0.316225 | Val. Kappa Score: 0.8291 | LR: 0.000063 | Estimated time: 65.37
Train loss on 50 batch: 0.409146
Train loss on 100 batch: 0.365228
Train loss on 150 batch: 0.381468
: Epoch: 39 | Training Loss: 0.386085 | Val. Loss: 0.318440 | Val. Kappa Score: 0.8300 | LR: 0.000063 | Estimated time: 65.26
Train loss on 50 batch: 0.354198
Train loss on 100 batch: 0.359721
Train loss on 150 batch: 0.346815
best-train-loss: 0.362316
best-valid-loss: 0.315216
best-kappa: 0.8312
: Epoch: 40 | Training Loss: 0.362316 | Val. Loss: 0.315216 | Val. Kappa Score: 0.8312 | LR: 0.000063 | Estimated time: 65.37
Train loss on 50 batch: 0.343198
Train loss on 100 batch: 0.387626
Train loss on 150 batch: 0.385781
: Epoch: 41 | Training Loss: 0.369328 | Val. Loss: 0.320567 | Val. Kappa Score: 0.8324 | LR: 0.000063 | Estimated time: 65.84
Train loss on 50 batch: 0.403968
Train loss on 100 batch: 0.326714
Train loss on 150 batch: 0.377589
: Epoch: 42 | Training Loss: 0.369682 | Val. Loss: 0.316634 | Val. Kappa Score: 0.8337 | LR: 0.000063 | Estimated time: 65.62
Train loss on 50 batch: 0.332258
Train loss on 100 batch: 0.399234
Train loss on 150 batch: 0.339991
: Epoch: 43 | Training Loss: 0.362454 | Val. Loss: 0.316358 | Val. Kappa Score: 0.8351 | LR: 0.000031 | Estimated time: 65.43
Train loss on 50 batch: 0.338459
Train loss on 100 batch: 0.363159
Train loss on 150 batch: 0.381302
: Epoch: 44 | Training Loss: 0.359018 | Val. Loss: 0.316927 | Val. Kappa Score: 0.8360 | LR: 0.000031 | Estimated time: 65.16
Train loss on 50 batch: 0.337706
Train loss on 100 batch: 0.362014
Train loss on 150 batch: 0.408647
: Epoch: 45 | Training Loss: 0.377479 | Val. Loss: 0.318508 | Val. Kappa Score: 0.8371 | LR: 0.000031 | Estimated time: 65.27
Train loss on 50 batch: 0.383156
Train loss on 100 batch: 0.365375
Train loss on 150 batch: 0.363622
: Epoch: 46 | Training Loss: 0.376009 | Val. Loss: 0.316315 | Val. Kappa Score: 0.8380 | LR: 0.000016 | Estimated time: 64.80
Train loss on 50 batch: 0.400185
Train loss on 100 batch: 0.350213
Train loss on 150 batch: 0.348997
: Epoch: 47 | Training Loss: 0.378726 | Val. Loss: 0.315558 | Val. Kappa Score: 0.8389 | LR: 0.000016 | Estimated time: 65.51
Train loss on 50 batch: 0.375771
Train loss on 100 batch: 0.413200
Train loss on 150 batch: 0.343069
: Epoch: 48 | Training Loss: 0.372027 | Val. Loss: 0.316279 | Val. Kappa Score: 0.8396 | LR: 0.000016 | Estimated time: 65.65
Train loss on 50 batch: 0.344087
Train loss on 100 batch: 0.406121
Train loss on 150 batch: 0.358425
: Epoch: 49 | Training Loss: 0.371181 | Val. Loss: 0.316238 | Val. Kappa Score: 0.8405 | LR: 0.000008 | Estimated time: 64.51
Train loss on 50 batch: 0.300136
Train loss on 100 batch: 0.401463
Train loss on 150 batch: 0.404788
: Epoch: 50 | Training Loss: 0.366367 | Val. Loss: 0.315964 | Val. Kappa Score: 0.8415 | LR: 0.000008 | Estimated time: 64.98
time_estimated: 3274.12
n-epochs: 50
time_estimated: 3274.16
----------------------------------------

Experiment N: 155: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.28 09:08:03
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f9ff98>
early-stopping-patience: 20
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.961421
Train loss on 100 batch: 0.663211
Train loss on 150 batch: 0.581122
best-train-loss: 0.689518
best-valid-loss: 0.721459
best-kappa: 0.6505
: Epoch: 1 | Training Loss: 0.689518 | Val. Loss: 0.721459 | Val. Kappa Score: 0.6505 | LR: 0.001000 | Estimated time: 69.45
Train loss on 50 batch: 0.482499
Train loss on 100 batch: 0.517882
Train loss on 150 batch: 0.440774
: Epoch: 2 | Training Loss: 0.511331 | Val. Loss: 0.764552 | Val. Kappa Score: 0.6523 | LR: 0.001000 | Estimated time: 68.78
Train loss on 50 batch: 0.564298
Train loss on 100 batch: 0.544483
Train loss on 150 batch: 0.514246
best-train-loss: 0.534098
best-valid-loss: 0.460183
best-kappa: 0.7080
: Epoch: 3 | Training Loss: 0.534098 | Val. Loss: 0.460183 | Val. Kappa Score: 0.7080 | LR: 0.001000 | Estimated time: 69.31
Train loss on 50 batch: 0.527377
Train loss on 100 batch: 0.540982
Train loss on 150 batch: 0.538167
: Epoch: 4 | Training Loss: 0.595303 | Val. Loss: 0.562374 | Val. Kappa Score: 0.7332 | LR: 0.001000 | Estimated time: 68.92
Train loss on 50 batch: 0.459827
Train loss on 100 batch: 0.509064
Train loss on 150 batch: 0.484638
: Epoch: 5 | Training Loss: 0.490376 | Val. Loss: 0.494859 | Val. Kappa Score: 0.7503 | LR: 0.001000 | Estimated time: 69.08
Train loss on 50 batch: 0.474082
Train loss on 100 batch: 0.447036
Train loss on 150 batch: 0.462533
best-train-loss: 0.468568
best-valid-loss: 0.436393
best-kappa: 0.7658
: Epoch: 6 | Training Loss: 0.468568 | Val. Loss: 0.436393 | Val. Kappa Score: 0.7658 | LR: 0.001000 | Estimated time: 69.11
Train loss on 50 batch: 0.522760
Train loss on 100 batch: 0.446245
Train loss on 150 batch: 0.467349
: Epoch: 7 | Training Loss: 0.482596 | Val. Loss: 0.438618 | Val. Kappa Score: 0.7768 | LR: 0.001000 | Estimated time: 69.28
Train loss on 50 batch: 0.400365
Train loss on 100 batch: 0.477877
Train loss on 150 batch: 0.411511
best-train-loss: 0.431755
best-valid-loss: 0.420418
best-kappa: 0.7853
: Epoch: 8 | Training Loss: 0.431755 | Val. Loss: 0.420418 | Val. Kappa Score: 0.7853 | LR: 0.001000 | Estimated time: 69.10
Train loss on 50 batch: 0.464490
Train loss on 100 batch: 0.494195
Train loss on 150 batch: 0.456157
best-train-loss: 0.459715
best-valid-loss: 0.377413
best-kappa: 0.7932
: Epoch: 9 | Training Loss: 0.459715 | Val. Loss: 0.377413 | Val. Kappa Score: 0.7932 | LR: 0.001000 | Estimated time: 69.21
Train loss on 50 batch: 0.407984
Train loss on 100 batch: 0.480095
Train loss on 150 batch: 0.422716
: Epoch: 10 | Training Loss: 0.490661 | Val. Loss: 0.409766 | Val. Kappa Score: 0.8001 | LR: 0.001000 | Estimated time: 69.58
Train loss on 50 batch: 0.496695
Train loss on 100 batch: 0.452242
Train loss on 150 batch: 0.467284
best-train-loss: 0.478350
best-valid-loss: 0.367481
best-kappa: 0.8056
: Epoch: 11 | Training Loss: 0.478350 | Val. Loss: 0.367481 | Val. Kappa Score: 0.8056 | LR: 0.001000 | Estimated time: 69.07
Train loss on 50 batch: 0.414003
Train loss on 100 batch: 0.423337
Train loss on 150 batch: 0.451782
: Epoch: 12 | Training Loss: 0.440998 | Val. Loss: 0.392860 | Val. Kappa Score: 0.8097 | LR: 0.001000 | Estimated time: 69.32
Train loss on 50 batch: 0.400686
Train loss on 100 batch: 0.440338
Train loss on 150 batch: 0.461025
: Epoch: 13 | Training Loss: 0.427913 | Val. Loss: 0.401341 | Val. Kappa Score: 0.8139 | LR: 0.001000 | Estimated time: 68.89
Train loss on 50 batch: 0.356021
Train loss on 100 batch: 0.388576
Train loss on 150 batch: 0.483817
best-train-loss: 0.429264
best-valid-loss: 0.352079
best-kappa: 0.8173
: Epoch: 14 | Training Loss: 0.429264 | Val. Loss: 0.352079 | Val. Kappa Score: 0.8173 | LR: 0.001000 | Estimated time: 68.42
Train loss on 50 batch: 0.456552
Train loss on 100 batch: 0.395992
Train loss on 150 batch: 0.358606
: Epoch: 15 | Training Loss: 0.408396 | Val. Loss: 0.465026 | Val. Kappa Score: 0.8178 | LR: 0.001000 | Estimated time: 68.25
Train loss on 50 batch: 0.426984
Train loss on 100 batch: 0.385438
Train loss on 150 batch: 0.363850
: Epoch: 16 | Training Loss: 0.396483 | Val. Loss: 0.502269 | Val. Kappa Score: 0.8185 | LR: 0.001000 | Estimated time: 68.89
Train loss on 50 batch: 0.468766
Train loss on 100 batch: 0.429623
Train loss on 150 batch: 0.370974
: Epoch: 17 | Training Loss: 0.425571 | Val. Loss: 0.418932 | Val. Kappa Score: 0.8198 | LR: 0.000500 | Estimated time: 69.27
Train loss on 50 batch: 0.383626
Train loss on 100 batch: 0.314453
Train loss on 150 batch: 0.363855
best-train-loss: 0.358746
best-valid-loss: 0.339753
best-kappa: 0.8226
: Epoch: 18 | Training Loss: 0.358746 | Val. Loss: 0.339753 | Val. Kappa Score: 0.8226 | LR: 0.000500 | Estimated time: 68.21
Train loss on 50 batch: 0.330735
Train loss on 100 batch: 0.394969
Train loss on 150 batch: 0.402128
: Epoch: 19 | Training Loss: 0.388621 | Val. Loss: 0.399267 | Val. Kappa Score: 0.8240 | LR: 0.000500 | Estimated time: 69.68
Train loss on 50 batch: 0.358557
Train loss on 100 batch: 0.365602
Train loss on 150 batch: 0.333251
: Epoch: 20 | Training Loss: 0.352128 | Val. Loss: 0.366754 | Val. Kappa Score: 0.8259 | LR: 0.000500 | Estimated time: 69.76
Train loss on 50 batch: 0.347068
Train loss on 100 batch: 0.350531
Train loss on 150 batch: 0.376530
: Epoch: 21 | Training Loss: 0.374972 | Val. Loss: 0.347236 | Val. Kappa Score: 0.8283 | LR: 0.000250 | Estimated time: 68.48
Train loss on 50 batch: 0.329377
Train loss on 100 batch: 0.346646
Train loss on 150 batch: 0.378829
: Epoch: 22 | Training Loss: 0.346505 | Val. Loss: 0.379731 | Val. Kappa Score: 0.8299 | LR: 0.000250 | Estimated time: 68.76
Train loss on 50 batch: 0.321171
Train loss on 100 batch: 0.336455
Train loss on 150 batch: 0.315466
: Epoch: 23 | Training Loss: 0.322426 | Val. Loss: 0.370937 | Val. Kappa Score: 0.8309 | LR: 0.000250 | Estimated time: 69.37
Train loss on 50 batch: 0.336973
Train loss on 100 batch: 0.359945
Train loss on 150 batch: 0.297451
: Epoch: 24 | Training Loss: 0.364419 | Val. Loss: 0.382556 | Val. Kappa Score: 0.8310 | LR: 0.000125 | Estimated time: 69.50
Train loss on 50 batch: 0.311551
Train loss on 100 batch: 0.304330
Train loss on 150 batch: 0.385295
: Epoch: 25 | Training Loss: 0.327450 | Val. Loss: 0.346329 | Val. Kappa Score: 0.8325 | LR: 0.000125 | Estimated time: 68.55
Train loss on 50 batch: 0.322707
Train loss on 100 batch: 0.279094
Train loss on 150 batch: 0.354546
best-train-loss: 0.336479
best-valid-loss: 0.339383
best-kappa: 0.8340
: Epoch: 26 | Training Loss: 0.336479 | Val. Loss: 0.339383 | Val. Kappa Score: 0.8340 | LR: 0.000125 | Estimated time: 68.80
Train loss on 50 batch: 0.347579
Train loss on 100 batch: 0.366372
Train loss on 150 batch: 0.317217
best-train-loss: 0.341415
best-valid-loss: 0.328563
best-kappa: 0.8358
: Epoch: 27 | Training Loss: 0.341415 | Val. Loss: 0.328563 | Val. Kappa Score: 0.8358 | LR: 0.000125 | Estimated time: 69.52
Train loss on 50 batch: 0.381435
Train loss on 100 batch: 0.338037
Train loss on 150 batch: 0.307133
best-train-loss: 0.331366
best-valid-loss: 0.324546
best-kappa: 0.8367
: Epoch: 28 | Training Loss: 0.331366 | Val. Loss: 0.324546 | Val. Kappa Score: 0.8367 | LR: 0.000125 | Estimated time: 68.96
Train loss on 50 batch: 0.267897
Train loss on 100 batch: 0.335612
Train loss on 150 batch: 0.328939
: Epoch: 29 | Training Loss: 0.308845 | Val. Loss: 0.333575 | Val. Kappa Score: 0.8380 | LR: 0.000125 | Estimated time: 68.79
Train loss on 50 batch: 0.308164
Train loss on 100 batch: 0.333263
Train loss on 150 batch: 0.326230
: Epoch: 30 | Training Loss: 0.313947 | Val. Loss: 0.345769 | Val. Kappa Score: 0.8389 | LR: 0.000125 | Estimated time: 68.98
Train loss on 50 batch: 0.277175
Train loss on 100 batch: 0.283300
Train loss on 150 batch: 0.287635
: Epoch: 31 | Training Loss: 0.315106 | Val. Loss: 0.324769 | Val. Kappa Score: 0.8397 | LR: 0.000063 | Estimated time: 69.89
Train loss on 50 batch: 0.288304
Train loss on 100 batch: 0.350059
Train loss on 150 batch: 0.276603
: Epoch: 32 | Training Loss: 0.307862 | Val. Loss: 0.343029 | Val. Kappa Score: 0.8404 | LR: 0.000063 | Estimated time: 68.78
Train loss on 50 batch: 0.311975
Train loss on 100 batch: 0.322507
Train loss on 150 batch: 0.260682
: Epoch: 33 | Training Loss: 0.303036 | Val. Loss: 0.343720 | Val. Kappa Score: 0.8412 | LR: 0.000063 | Estimated time: 68.75
Train loss on 50 batch: 0.271013
Train loss on 100 batch: 0.321471
Train loss on 150 batch: 0.283496
: Epoch: 34 | Training Loss: 0.299987 | Val. Loss: 0.337122 | Val. Kappa Score: 0.8420 | LR: 0.000031 | Estimated time: 68.77
Train loss on 50 batch: 0.296882
Train loss on 100 batch: 0.286946
Train loss on 150 batch: 0.291474
: Epoch: 35 | Training Loss: 0.296219 | Val. Loss: 0.333440 | Val. Kappa Score: 0.8427 | LR: 0.000031 | Estimated time: 68.71
Train loss on 50 batch: 0.258673
Train loss on 100 batch: 0.315774
Train loss on 150 batch: 0.287381
: Epoch: 36 | Training Loss: 0.301634 | Val. Loss: 0.334628 | Val. Kappa Score: 0.8434 | LR: 0.000031 | Estimated time: 68.28
Train loss on 50 batch: 0.306641
Train loss on 100 batch: 0.261374
Train loss on 150 batch: 0.277977
: Epoch: 37 | Training Loss: 0.289582 | Val. Loss: 0.331777 | Val. Kappa Score: 0.8440 | LR: 0.000016 | Estimated time: 68.57
Train loss on 50 batch: 0.268579
Train loss on 100 batch: 0.277877
Train loss on 150 batch: 0.271690
: Epoch: 38 | Training Loss: 0.330117 | Val. Loss: 0.331766 | Val. Kappa Score: 0.8446 | LR: 0.000016 | Estimated time: 68.87
Train loss on 50 batch: 0.311608
Train loss on 100 batch: 0.278065
Train loss on 150 batch: 0.321570
: Epoch: 39 | Training Loss: 0.304905 | Val. Loss: 0.337309 | Val. Kappa Score: 0.8450 | LR: 0.000016 | Estimated time: 69.25
Train loss on 50 batch: 0.271859
Train loss on 100 batch: 0.276657
Train loss on 150 batch: 0.274649
: Epoch: 40 | Training Loss: 0.282883 | Val. Loss: 0.331190 | Val. Kappa Score: 0.8457 | LR: 0.000008 | Estimated time: 69.94
Train loss on 50 batch: 0.260762
Train loss on 100 batch: 0.318291
Train loss on 150 batch: 0.290338
: Epoch: 41 | Training Loss: 0.299662 | Val. Loss: 0.332825 | Val. Kappa Score: 0.8464 | LR: 0.000008 | Estimated time: 68.72
Train loss on 50 batch: 0.326031
Train loss on 100 batch: 0.244726
Train loss on 150 batch: 0.289896
: Epoch: 42 | Training Loss: 0.295949 | Val. Loss: 0.331944 | Val. Kappa Score: 0.8469 | LR: 0.000008 | Estimated time: 70.00
Train loss on 50 batch: 0.276762
Train loss on 100 batch: 0.296025
Train loss on 150 batch: 0.269256
: Epoch: 43 | Training Loss: 0.300581 | Val. Loss: 0.330788 | Val. Kappa Score: 0.8477 | LR: 0.000004 | Estimated time: 69.27
Train loss on 50 batch: 0.273545
Train loss on 100 batch: 0.293839
Train loss on 150 batch: 0.316663
: Epoch: 44 | Training Loss: 0.282435 | Val. Loss: 0.332813 | Val. Kappa Score: 0.8480 | LR: 0.000004 | Estimated time: 68.91
Train loss on 50 batch: 0.286187
Train loss on 100 batch: 0.287095
Train loss on 150 batch: 0.325393
: Epoch: 45 | Training Loss: 0.301913 | Val. Loss: 0.335235 | Val. Kappa Score: 0.8486 | LR: 0.000004 | Estimated time: 69.27
Train loss on 50 batch: 0.306804
Train loss on 100 batch: 0.284698
Train loss on 150 batch: 0.279588
: Epoch: 46 | Training Loss: 0.298757 | Val. Loss: 0.334877 | Val. Kappa Score: 0.8490 | LR: 0.000002 | Estimated time: 69.75
Train loss on 50 batch: 0.286641
Train loss on 100 batch: 0.278582
Train loss on 150 batch: 0.275479
: Epoch: 47 | Training Loss: 0.295024 | Val. Loss: 0.333732 | Val. Kappa Score: 0.8496 | LR: 0.000002 | Estimated time: 69.23
Train loss on 50 batch: 0.269529
Train loss on 100 batch: 0.322459
Train loss on 150 batch: 0.289171
: Epoch: 48 | Training Loss: 0.308023 | Val. Loss: 0.333972 | Val. Kappa Score: 0.8499 | LR: 0.000002 | Estimated time: 69.74
time_estimated: 3319.18
n-epochs: 48
time_estimated: 3319.23
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:39:01
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f41518>
early-stopping-patience: 20
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:39:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f414e0>
early-stopping-patience: 20
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:43:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5ce528d0>
early-stopping-patience: 20
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:46:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5ce56748>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:47:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5ce56710>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:48:32
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5ce56780>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:49:19
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5cdd87b8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:50:57
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5cdd9710>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 00:59:46
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a324940>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:09:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb3af96ef0>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:10:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb3af97eb8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:11:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb3af95f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 1, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:12:44
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d0faa58>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 1
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:13:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e1a90>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:16:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e1b00>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:17:07
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e0b38>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:17:51
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5dcc0dd8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:32:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e2a90>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 1, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:32:57
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e0b00>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 1
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:36:06
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e2ac8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:38:52
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e3ac8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:42:18
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e0b00>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:43:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e5908>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:44:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2e5908>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:47:27
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2eb908>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:48:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5a2ea908>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 01:57:22
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5508e9b0>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:00:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5508e860>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:01:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:03:24
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5508e860>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:45:28
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f98>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:46:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb55090860>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:51:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702fd0>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:51:56
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5508b7f0>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:52:12
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5511b198>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:52:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb99c1eef0>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:54:22
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb4d06d978>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 02:56:22
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51703f98>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:07:24
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5508c9e8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:08:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f98>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:11:06
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54fa9d30>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:11:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb550907b8>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:13:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:14:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f98>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:17:04
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:17:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 03:21:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 20
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 156: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.29 20:31:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96026358>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.852529
Train loss on 100 batch: 0.671577
Train loss on 150 batch: 0.594211
best-train-loss: 0.668964
best-valid-loss: 0.569616
best-kappa: 0.8028
: Epoch: 1 | Training Loss: 0.668964 | Val. Loss: 0.569616 | Val. Kappa Score: 0.8028 | LR: 0.001000 | Estimated time: 57.19
Train loss on 50 batch: 0.548843
Train loss on 100 batch: 0.545988
Train loss on 150 batch: 0.482897
best-train-loss: 0.560832
best-valid-loss: 0.488546
best-kappa: 0.8052
: Epoch: 2 | Training Loss: 0.560832 | Val. Loss: 0.488546 | Val. Kappa Score: 0.8052 | LR: 0.001000 | Estimated time: 57.47
Train loss on 50 batch: 0.543222
Train loss on 100 batch: 0.533688
Train loss on 150 batch: 0.524614
: Epoch: 3 | Training Loss: 0.523369 | Val. Loss: 0.618991 | Val. Kappa Score: 0.7893 | LR: 0.001000 | Estimated time: 57.17
Train loss on 50 batch: 0.525282
Train loss on 100 batch: 0.551392
Train loss on 150 batch: 0.507067
: Epoch: 4 | Training Loss: 0.593244 | Val. Loss: 0.480832 | Val. Kappa Score: 0.7944 | LR: 0.001000 | Estimated time: 58.24
Train loss on 50 batch: 0.477882
Train loss on 100 batch: 0.566641
Train loss on 150 batch: 0.449735
: Epoch: 5 | Training Loss: 0.488726 | Val. Loss: 0.552569 | Val. Kappa Score: 0.7953 | LR: 0.000500 | Estimated time: 59.34
Train loss on 50 batch: 0.435271
Train loss on 100 batch: 0.445087
Train loss on 150 batch: 0.408756
: Epoch: 6 | Training Loss: 0.431984 | Val. Loss: 0.505246 | Val. Kappa Score: 0.7979 | LR: 0.000500 | Estimated time: 58.22
Train loss on 50 batch: 0.455540
Train loss on 100 batch: 0.412392
Train loss on 150 batch: 0.411669
: Epoch: 7 | Training Loss: 0.435685 | Val. Loss: 0.411739 | Val. Kappa Score: 0.8051 | LR: 0.000500 | Estimated time: 58.22
Train loss on 50 batch: 0.352313
Train loss on 100 batch: 0.453716
Train loss on 150 batch: 0.412687
best-train-loss: 0.415350
best-valid-loss: 0.376326
best-kappa: 0.8111
: Epoch: 8 | Training Loss: 0.415350 | Val. Loss: 0.376326 | Val. Kappa Score: 0.8111 | LR: 0.000500 | Estimated time: 58.34
Train loss on 50 batch: 0.451858
Train loss on 100 batch: 0.443138
Train loss on 150 batch: 0.418256
best-train-loss: 0.424922
best-valid-loss: 0.404846
best-kappa: 0.8156
: Epoch: 9 | Training Loss: 0.424922 | Val. Loss: 0.404846 | Val. Kappa Score: 0.8156 | LR: 0.000500 | Estimated time: 57.34
Train loss on 50 batch: 0.355507
Train loss on 100 batch: 0.423092
Train loss on 150 batch: 0.385509
best-train-loss: 0.470089
best-valid-loss: 0.396548
best-kappa: 0.8180
: Epoch: 10 | Training Loss: 0.470089 | Val. Loss: 0.396548 | Val. Kappa Score: 0.8180 | LR: 0.000500 | Estimated time: 58.36
Train loss on 50 batch: 0.437266
Train loss on 100 batch: 0.400691
Train loss on 150 batch: 0.388363
best-train-loss: 0.402759
best-valid-loss: 0.388917
best-kappa: 0.8202
: Epoch: 11 | Training Loss: 0.402759 | Val. Loss: 0.388917 | Val. Kappa Score: 0.8202 | LR: 0.000500 | Estimated time: 59.23
Train loss on 50 batch: 0.383292
Train loss on 100 batch: 0.374839
Train loss on 150 batch: 0.423338
best-train-loss: 0.393012
best-valid-loss: 0.344575
best-kappa: 0.8242
: Epoch: 12 | Training Loss: 0.393012 | Val. Loss: 0.344575 | Val. Kappa Score: 0.8242 | LR: 0.000500 | Estimated time: 57.60
Train loss on 50 batch: 0.332122
Train loss on 100 batch: 0.385220
Train loss on 150 batch: 0.422238
best-train-loss: 0.382451
best-valid-loss: 0.388670
best-kappa: 0.8272
: Epoch: 13 | Training Loss: 0.382451 | Val. Loss: 0.388670 | Val. Kappa Score: 0.8272 | LR: 0.000500 | Estimated time: 59.02
Train loss on 50 batch: 0.352434
Train loss on 100 batch: 0.327047
Train loss on 150 batch: 0.424340
best-train-loss: 0.378267
best-valid-loss: 0.371851
best-kappa: 0.8291
: Epoch: 14 | Training Loss: 0.378267 | Val. Loss: 0.371851 | Val. Kappa Score: 0.8291 | LR: 0.000500 | Estimated time: 57.33
Train loss on 50 batch: 0.416324
Train loss on 100 batch: 0.336526
Train loss on 150 batch: 0.334876
best-train-loss: 0.376187
best-valid-loss: 0.384017
best-kappa: 0.8305
: Epoch: 15 | Training Loss: 0.376187 | Val. Loss: 0.384017 | Val. Kappa Score: 0.8305 | LR: 0.000500 | Estimated time: 57.58
Train loss on 50 batch: 0.379477
Train loss on 100 batch: 0.302928
Train loss on 150 batch: 0.339412
best-train-loss: 0.348310
best-valid-loss: 0.380819
best-kappa: 0.8321
: Epoch: 16 | Training Loss: 0.348310 | Val. Loss: 0.380819 | Val. Kappa Score: 0.8321 | LR: 0.000500 | Estimated time: 58.26
Train loss on 50 batch: 0.402344
Train loss on 100 batch: 0.374893
Train loss on 150 batch: 0.267022
: Epoch: 17 | Training Loss: 0.358709 | Val. Loss: 0.526271 | Val. Kappa Score: 0.8310 | LR: 0.000500 | Estimated time: 57.44
Train loss on 50 batch: 0.375802
Train loss on 100 batch: 0.308860
Train loss on 150 batch: 0.364262
: Epoch: 18 | Training Loss: 0.349900 | Val. Loss: 0.421116 | Val. Kappa Score: 0.8317 | LR: 0.000500 | Estimated time: 58.27
Train loss on 50 batch: 0.315297
Train loss on 100 batch: 0.382581
Train loss on 150 batch: 0.401154
best-train-loss: 0.365525
best-valid-loss: 0.424626
best-kappa: 0.8327
: Epoch: 19 | Training Loss: 0.365525 | Val. Loss: 0.424626 | Val. Kappa Score: 0.8327 | LR: 0.000500 | Estimated time: 57.71
Train loss on 50 batch: 0.371410
Train loss on 100 batch: 0.362209
Train loss on 150 batch: 0.285736
best-train-loss: 0.327749
best-valid-loss: 0.388354
best-kappa: 0.8338
: Epoch: 20 | Training Loss: 0.327749 | Val. Loss: 0.388354 | Val. Kappa Score: 0.8338 | LR: 0.000500 | Estimated time: 57.49
Train loss on 50 batch: 0.346940
Train loss on 100 batch: 0.332987
Train loss on 150 batch: 0.347297
best-train-loss: 0.374227
best-valid-loss: 0.400844
best-kappa: 0.8347
: Epoch: 21 | Training Loss: 0.374227 | Val. Loss: 0.400844 | Val. Kappa Score: 0.8347 | LR: 0.000500 | Estimated time: 57.05
Train loss on 50 batch: 0.339336
Train loss on 100 batch: 0.343094
Train loss on 150 batch: 0.383840
best-train-loss: 0.348798
best-valid-loss: 0.399247
best-kappa: 0.8358
: Epoch: 22 | Training Loss: 0.348798 | Val. Loss: 0.399247 | Val. Kappa Score: 0.8358 | LR: 0.000500 | Estimated time: 57.22
Train loss on 50 batch: 0.348043
Train loss on 100 batch: 0.333066
Train loss on 150 batch: 0.355140
: Epoch: 23 | Training Loss: 0.354470 | Val. Loss: 0.551814 | Val. Kappa Score: 0.8341 | LR: 0.000500 | Estimated time: 57.83
Train loss on 50 batch: 0.339265
Train loss on 100 batch: 0.348629
Train loss on 150 batch: 0.345274
: Epoch: 24 | Training Loss: 0.421248 | Val. Loss: 0.375618 | Val. Kappa Score: 0.8348 | LR: 0.000500 | Estimated time: 57.22
Train loss on 50 batch: 0.341104
Train loss on 100 batch: 0.317982
Train loss on 150 batch: 0.396281
best-train-loss: 0.339104
best-valid-loss: 0.369476
best-kappa: 0.8361
: Epoch: 25 | Training Loss: 0.339104 | Val. Loss: 0.369476 | Val. Kappa Score: 0.8361 | LR: 0.000500 | Estimated time: 57.59
Train loss on 50 batch: 0.333501
Train loss on 100 batch: 0.308511
Train loss on 150 batch: 0.386397
best-train-loss: 0.383346
best-valid-loss: 0.398779
best-kappa: 0.8365
: Epoch: 26 | Training Loss: 0.383346 | Val. Loss: 0.398779 | Val. Kappa Score: 0.8365 | LR: 0.000500 | Estimated time: 57.90
Train loss on 50 batch: 0.359998
Train loss on 100 batch: 0.385450
Train loss on 150 batch: 0.321230
best-train-loss: 0.359850
best-valid-loss: 0.374950
best-kappa: 0.8376
: Epoch: 27 | Training Loss: 0.359850 | Val. Loss: 0.374950 | Val. Kappa Score: 0.8376 | LR: 0.000500 | Estimated time: 58.19
Train loss on 50 batch: 0.357786
Train loss on 100 batch: 0.354804
Train loss on 150 batch: 0.326302
best-train-loss: 0.354712
best-valid-loss: 0.379925
best-kappa: 0.8381
: Epoch: 28 | Training Loss: 0.354712 | Val. Loss: 0.379925 | Val. Kappa Score: 0.8381 | LR: 0.000500 | Estimated time: 58.02
Train loss on 50 batch: 0.301873
Train loss on 100 batch: 0.369845
Train loss on 150 batch: 0.354784
best-train-loss: 0.347000
best-valid-loss: 0.361621
best-kappa: 0.8390
: Epoch: 29 | Training Loss: 0.347000 | Val. Loss: 0.361621 | Val. Kappa Score: 0.8390 | LR: 0.000500 | Estimated time: 57.81
Train loss on 50 batch: 0.354274
Train loss on 100 batch: 0.347260
Train loss on 150 batch: 0.343110
best-train-loss: 0.351199
best-valid-loss: 0.361523
best-kappa: 0.8397
: Epoch: 30 | Training Loss: 0.351199 | Val. Loss: 0.361523 | Val. Kappa Score: 0.8397 | LR: 0.000500 | Estimated time: 57.70
Train loss on 50 batch: 0.289971
Train loss on 100 batch: 0.335614
Train loss on 150 batch: 0.317784
best-train-loss: 0.327803
best-valid-loss: 0.388533
best-kappa: 0.8407
: Epoch: 31 | Training Loss: 0.327803 | Val. Loss: 0.388533 | Val. Kappa Score: 0.8407 | LR: 0.000500 | Estimated time: 58.23
Train loss on 50 batch: 0.314905
Train loss on 100 batch: 0.373613
Train loss on 150 batch: 0.292707
: Epoch: 32 | Training Loss: 0.315239 | Val. Loss: 0.419748 | Val. Kappa Score: 0.8407 | LR: 0.000500 | Estimated time: 57.48
Train loss on 50 batch: 0.327167
Train loss on 100 batch: 0.338107
Train loss on 150 batch: 0.299907
best-train-loss: 0.327559
best-valid-loss: 0.421291
best-kappa: 0.8409
: Epoch: 33 | Training Loss: 0.327559 | Val. Loss: 0.421291 | Val. Kappa Score: 0.8409 | LR: 0.000500 | Estimated time: 57.83
Train loss on 50 batch: 0.300016
Train loss on 100 batch: 0.334185
Train loss on 150 batch: 0.347201
best-train-loss: 0.323265
best-valid-loss: 0.404342
best-kappa: 0.8412
: Epoch: 34 | Training Loss: 0.323265 | Val. Loss: 0.404342 | Val. Kappa Score: 0.8412 | LR: 0.000500 | Estimated time: 57.34
Train loss on 50 batch: 0.318989
Train loss on 100 batch: 0.317266
Train loss on 150 batch: 0.312300
: Epoch: 35 | Training Loss: 0.332441 | Val. Loss: 0.391586 | Val. Kappa Score: 0.8411 | LR: 0.000500 | Estimated time: 56.55
Train loss on 50 batch: 0.304921
Train loss on 100 batch: 0.370279
Train loss on 150 batch: 0.328028
: Epoch: 36 | Training Loss: 0.353106 | Val. Loss: 0.418541 | Val. Kappa Score: 0.8409 | LR: 0.000500 | Estimated time: 57.45
Train loss on 50 batch: 0.367004
Train loss on 100 batch: 0.298917
Train loss on 150 batch: 0.323537
: Epoch: 37 | Training Loss: 0.330750 | Val. Loss: 0.520878 | Val. Kappa Score: 0.8398 | LR: 0.000250 | Estimated time: 57.24
Train loss on 50 batch: 0.292264
Train loss on 100 batch: 0.285736
Train loss on 150 batch: 0.277197
: Epoch: 38 | Training Loss: 0.382848 | Val. Loss: 0.344284 | Val. Kappa Score: 0.8405 | LR: 0.000250 | Estimated time: 57.25
Train loss on 50 batch: 0.324773
Train loss on 100 batch: 0.293767
Train loss on 150 batch: 0.296487
: Epoch: 39 | Training Loss: 0.315915 | Val. Loss: 0.329684 | Val. Kappa Score: 0.8410 | LR: 0.000250 | Estimated time: 58.43
Train loss on 50 batch: 0.307062
Train loss on 100 batch: 0.280863
Train loss on 150 batch: 0.315407
best-train-loss: 0.318840
best-valid-loss: 0.353928
best-kappa: 0.8416
: Epoch: 40 | Training Loss: 0.318840 | Val. Loss: 0.353928 | Val. Kappa Score: 0.8416 | LR: 0.000250 | Estimated time: 58.64
Train loss on 50 batch: 0.262644
Train loss on 100 batch: 0.307278
Train loss on 150 batch: 0.305512
best-train-loss: 0.295357
best-valid-loss: 0.348185
best-kappa: 0.8421
: Epoch: 41 | Training Loss: 0.295357 | Val. Loss: 0.348185 | Val. Kappa Score: 0.8421 | LR: 0.000250 | Estimated time: 57.37
Train loss on 50 batch: 0.307468
Train loss on 100 batch: 0.261604
Train loss on 150 batch: 0.315740
best-train-loss: 0.292131
best-valid-loss: 0.349977
best-kappa: 0.8428
: Epoch: 42 | Training Loss: 0.292131 | Val. Loss: 0.349977 | Val. Kappa Score: 0.8428 | LR: 0.000250 | Estimated time: 57.81
Train loss on 50 batch: 0.305828
Train loss on 100 batch: 0.314456
Train loss on 150 batch: 0.297131
best-train-loss: 0.310031
best-valid-loss: 0.334606
best-kappa: 0.8434
: Epoch: 43 | Training Loss: 0.310031 | Val. Loss: 0.334606 | Val. Kappa Score: 0.8434 | LR: 0.000250 | Estimated time: 57.39
Train loss on 50 batch: 0.275599
Train loss on 100 batch: 0.316131
Train loss on 150 batch: 0.339269
best-train-loss: 0.291516
best-valid-loss: 0.349853
best-kappa: 0.8441
: Epoch: 44 | Training Loss: 0.291516 | Val. Loss: 0.349853 | Val. Kappa Score: 0.8441 | LR: 0.000250 | Estimated time: 59.07
Train loss on 50 batch: 0.293291
Train loss on 100 batch: 0.259290
Train loss on 150 batch: 0.320848
best-train-loss: 0.293788
best-valid-loss: 0.352238
best-kappa: 0.8448
: Epoch: 45 | Training Loss: 0.293788 | Val. Loss: 0.352238 | Val. Kappa Score: 0.8448 | LR: 0.000250 | Estimated time: 57.19
Train loss on 50 batch: 0.290563
Train loss on 100 batch: 0.307956
Train loss on 150 batch: 0.288115
best-train-loss: 0.303862
best-valid-loss: 0.336660
best-kappa: 0.8454
: Epoch: 46 | Training Loss: 0.303862 | Val. Loss: 0.336660 | Val. Kappa Score: 0.8454 | LR: 0.000250 | Estimated time: 58.02
Train loss on 50 batch: 0.328364
Train loss on 100 batch: 0.285342
Train loss on 150 batch: 0.254241
best-train-loss: 0.301788
best-valid-loss: 0.352319
best-kappa: 0.8458
: Epoch: 47 | Training Loss: 0.301788 | Val. Loss: 0.352319 | Val. Kappa Score: 0.8458 | LR: 0.000250 | Estimated time: 57.56
Train loss on 50 batch: 0.263908
Train loss on 100 batch: 0.344965
Train loss on 150 batch: 0.281161
best-train-loss: 0.293352
best-valid-loss: 0.365630
best-kappa: 0.8461
: Epoch: 48 | Training Loss: 0.293352 | Val. Loss: 0.365630 | Val. Kappa Score: 0.8461 | LR: 0.000250 | Estimated time: 58.66
Train loss on 50 batch: 0.267095
Train loss on 100 batch: 0.296414
Train loss on 150 batch: 0.275452
best-train-loss: 0.298562
best-valid-loss: 0.377470
best-kappa: 0.8466
: Epoch: 49 | Training Loss: 0.298562 | Val. Loss: 0.377470 | Val. Kappa Score: 0.8466 | LR: 0.000250 | Estimated time: 57.57
Train loss on 50 batch: 0.276653
Train loss on 100 batch: 0.293741
Train loss on 150 batch: 0.311374
best-train-loss: 0.292096
best-valid-loss: 0.383758
best-kappa: 0.8470
: Epoch: 50 | Training Loss: 0.292096 | Val. Loss: 0.383758 | Val. Kappa Score: 0.8470 | LR: 0.000250 | Estimated time: 57.94
Train loss on 50 batch: 0.270995
Train loss on 100 batch: 0.342989
Train loss on 150 batch: 0.268504
best-train-loss: 0.295598
best-valid-loss: 0.337774
best-kappa: 0.8475
: Epoch: 51 | Training Loss: 0.295598 | Val. Loss: 0.337774 | Val. Kappa Score: 0.8475 | LR: 0.000250 | Estimated time: 58.39
Train loss on 50 batch: 0.298050
Train loss on 100 batch: 0.285130
Train loss on 150 batch: 0.296377
best-train-loss: 0.293623
best-valid-loss: 0.342695
best-kappa: 0.8479
: Epoch: 52 | Training Loss: 0.293623 | Val. Loss: 0.342695 | Val. Kappa Score: 0.8479 | LR: 0.000250 | Estimated time: 57.07
Train loss on 50 batch: 0.342204
Train loss on 100 batch: 0.255702
Train loss on 150 batch: 0.264690
best-train-loss: 0.300591
best-valid-loss: 0.331690
best-kappa: 0.8486
: Epoch: 53 | Training Loss: 0.300591 | Val. Loss: 0.331690 | Val. Kappa Score: 0.8486 | LR: 0.000250 | Estimated time: 58.75
Train loss on 50 batch: 0.297823
Train loss on 100 batch: 0.266576
Train loss on 150 batch: 0.282225
best-train-loss: 0.329921
best-valid-loss: 0.351143
best-kappa: 0.8489
: Epoch: 54 | Training Loss: 0.329921 | Val. Loss: 0.351143 | Val. Kappa Score: 0.8489 | LR: 0.000250 | Estimated time: 58.32
Train loss on 50 batch: 0.320268
Train loss on 100 batch: 0.289899
Train loss on 150 batch: 0.327413
best-train-loss: 0.300325
best-valid-loss: 0.351709
best-kappa: 0.8493
: Epoch: 55 | Training Loss: 0.300325 | Val. Loss: 0.351709 | Val. Kappa Score: 0.8493 | LR: 0.000250 | Estimated time: 58.17
Train loss on 50 batch: 0.257229
Train loss on 100 batch: 0.255065
Train loss on 150 batch: 0.306418
best-train-loss: 0.312080
best-valid-loss: 0.356892
best-kappa: 0.8495
: Epoch: 56 | Training Loss: 0.312080 | Val. Loss: 0.356892 | Val. Kappa Score: 0.8495 | LR: 0.000250 | Estimated time: 58.38
Train loss on 50 batch: 0.258044
Train loss on 100 batch: 0.310586
Train loss on 150 batch: 0.283627
best-train-loss: 0.282574
best-valid-loss: 0.344577
best-kappa: 0.8499
: Epoch: 57 | Training Loss: 0.282574 | Val. Loss: 0.344577 | Val. Kappa Score: 0.8499 | LR: 0.000250 | Estimated time: 57.83
Train loss on 50 batch: 0.326497
Train loss on 100 batch: 0.272082
Train loss on 150 batch: 0.272874
best-train-loss: 0.299821
best-valid-loss: 0.352182
best-kappa: 0.8499
: Epoch: 58 | Training Loss: 0.299821 | Val. Loss: 0.352182 | Val. Kappa Score: 0.8499 | LR: 0.000250 | Estimated time: 58.00
Train loss on 50 batch: 0.316903
Train loss on 100 batch: 0.273814
Train loss on 150 batch: 0.258501
best-train-loss: 0.291557
best-valid-loss: 0.358907
best-kappa: 0.8500
: Epoch: 59 | Training Loss: 0.291557 | Val. Loss: 0.358907 | Val. Kappa Score: 0.8500 | LR: 0.000250 | Estimated time: 57.89
Train loss on 50 batch: 0.282591
Train loss on 100 batch: 0.298469
Train loss on 150 batch: 0.296211
best-train-loss: 0.384730
best-valid-loss: 0.335068
best-kappa: 0.8503
: Epoch: 60 | Training Loss: 0.384730 | Val. Loss: 0.335068 | Val. Kappa Score: 0.8503 | LR: 0.000250 | Estimated time: 58.05
Train loss on 50 batch: 0.294715
Train loss on 100 batch: 0.265917
Train loss on 150 batch: 0.281713
best-train-loss: 0.279841
best-valid-loss: 0.348996
best-kappa: 0.8507
: Epoch: 61 | Training Loss: 0.279841 | Val. Loss: 0.348996 | Val. Kappa Score: 0.8507 | LR: 0.000250 | Estimated time: 57.35
Train loss on 50 batch: 0.265237
Train loss on 100 batch: 0.252783
Train loss on 150 batch: 0.348440
best-train-loss: 0.365014
best-valid-loss: 0.340905
best-kappa: 0.8510
: Epoch: 62 | Training Loss: 0.365014 | Val. Loss: 0.340905 | Val. Kappa Score: 0.8510 | LR: 0.000250 | Estimated time: 57.48
Train loss on 50 batch: 0.266860
Train loss on 100 batch: 0.276985
Train loss on 150 batch: 0.284230
best-train-loss: 0.302441
best-valid-loss: 0.330570
best-kappa: 0.8512
: Epoch: 63 | Training Loss: 0.302441 | Val. Loss: 0.330570 | Val. Kappa Score: 0.8512 | LR: 0.000250 | Estimated time: 58.54
Train loss on 50 batch: 0.312499
Train loss on 100 batch: 0.302554
Train loss on 150 batch: 0.241911
best-train-loss: 0.285488
best-valid-loss: 0.345426
best-kappa: 0.8515
: Epoch: 64 | Training Loss: 0.285488 | Val. Loss: 0.345426 | Val. Kappa Score: 0.8515 | LR: 0.000250 | Estimated time: 58.01
Train loss on 50 batch: 0.282358
Train loss on 100 batch: 0.288987
Train loss on 150 batch: 0.313640
best-train-loss: 0.298472
best-valid-loss: 0.332232
best-kappa: 0.8518
: Epoch: 65 | Training Loss: 0.298472 | Val. Loss: 0.332232 | Val. Kappa Score: 0.8518 | LR: 0.000250 | Estimated time: 58.24
Train loss on 50 batch: 0.267610
Train loss on 100 batch: 0.277538
Train loss on 150 batch: 0.324775
best-train-loss: 0.370475
best-valid-loss: 0.330106
best-kappa: 0.8520
: Epoch: 66 | Training Loss: 0.370475 | Val. Loss: 0.330106 | Val. Kappa Score: 0.8520 | LR: 0.000250 | Estimated time: 58.26
Train loss on 50 batch: 0.264569
Train loss on 100 batch: 0.278197
Train loss on 150 batch: 0.293605
best-train-loss: 0.294391
best-valid-loss: 0.333294
best-kappa: 0.8523
: Epoch: 67 | Training Loss: 0.294391 | Val. Loss: 0.333294 | Val. Kappa Score: 0.8523 | LR: 0.000250 | Estimated time: 57.61
Train loss on 50 batch: 0.281595
Train loss on 100 batch: 0.258201
Train loss on 150 batch: 0.282311
: Epoch: 68 | Training Loss: 0.281506 | Val. Loss: 0.374173 | Val. Kappa Score: 0.8523 | LR: 0.000250 | Estimated time: 57.64
Train loss on 50 batch: 0.266673
Train loss on 100 batch: 0.297627
Train loss on 150 batch: 0.263555
best-train-loss: 0.291494
best-valid-loss: 0.326240
best-kappa: 0.8527
: Epoch: 69 | Training Loss: 0.291494 | Val. Loss: 0.326240 | Val. Kappa Score: 0.8527 | LR: 0.000250 | Estimated time: 57.44
Train loss on 50 batch: 0.273147
Train loss on 100 batch: 0.284859
Train loss on 150 batch: 0.281691
best-train-loss: 0.272323
best-valid-loss: 0.377660
best-kappa: 0.8528
: Epoch: 70 | Training Loss: 0.272323 | Val. Loss: 0.377660 | Val. Kappa Score: 0.8528 | LR: 0.000250 | Estimated time: 58.07
Train loss on 50 batch: 0.278933
Train loss on 100 batch: 0.245722
Train loss on 150 batch: 0.319403
best-train-loss: 0.270666
best-valid-loss: 0.347986
best-kappa: 0.8530
: Epoch: 71 | Training Loss: 0.270666 | Val. Loss: 0.347986 | Val. Kappa Score: 0.8530 | LR: 0.000250 | Estimated time: 57.73
Train loss on 50 batch: 0.239094
Train loss on 100 batch: 0.292168
Train loss on 150 batch: 0.269752
best-train-loss: 0.288186
best-valid-loss: 0.334632
best-kappa: 0.8533
: Epoch: 72 | Training Loss: 0.288186 | Val. Loss: 0.334632 | Val. Kappa Score: 0.8533 | LR: 0.000250 | Estimated time: 58.06
Train loss on 50 batch: 0.263267
Train loss on 100 batch: 0.283518
Train loss on 150 batch: 0.282585
best-train-loss: 0.361129
best-valid-loss: 0.325455
best-kappa: 0.8535
: Epoch: 73 | Training Loss: 0.361129 | Val. Loss: 0.325455 | Val. Kappa Score: 0.8535 | LR: 0.000250 | Estimated time: 57.98
Train loss on 50 batch: 0.275845
Train loss on 100 batch: 0.283617
Train loss on 150 batch: 0.265933
best-train-loss: 0.281777
best-valid-loss: 0.351130
best-kappa: 0.8537
: Epoch: 74 | Training Loss: 0.281777 | Val. Loss: 0.351130 | Val. Kappa Score: 0.8537 | LR: 0.000250 | Estimated time: 58.38
Train loss on 50 batch: 0.251625
Train loss on 100 batch: 0.265780
Train loss on 150 batch: 0.279470
best-train-loss: 0.277202
best-valid-loss: 0.350094
best-kappa: 0.8539
: Epoch: 75 | Training Loss: 0.277202 | Val. Loss: 0.350094 | Val. Kappa Score: 0.8539 | LR: 0.000250 | Estimated time: 58.30
Train loss on 50 batch: 0.237877
Train loss on 100 batch: 0.282283
Train loss on 150 batch: 0.290762
best-train-loss: 0.275818
best-valid-loss: 0.332415
best-kappa: 0.8542
: Epoch: 76 | Training Loss: 0.275818 | Val. Loss: 0.332415 | Val. Kappa Score: 0.8542 | LR: 0.000250 | Estimated time: 57.54
Train loss on 50 batch: 0.286365
Train loss on 100 batch: 0.276824
Train loss on 150 batch: 0.309048
best-train-loss: 0.285967
best-valid-loss: 0.321629
best-kappa: 0.8544
: Epoch: 77 | Training Loss: 0.285967 | Val. Loss: 0.321629 | Val. Kappa Score: 0.8544 | LR: 0.000250 | Estimated time: 57.34
Train loss on 50 batch: 0.300999
Train loss on 100 batch: 0.247470
Train loss on 150 batch: 0.283945
best-train-loss: 0.273812
best-valid-loss: 0.324973
best-kappa: 0.8547
: Epoch: 78 | Training Loss: 0.273812 | Val. Loss: 0.324973 | Val. Kappa Score: 0.8547 | LR: 0.000250 | Estimated time: 57.43
Train loss on 50 batch: 0.273598
Train loss on 100 batch: 0.251105
Train loss on 150 batch: 0.271366
best-train-loss: 0.273966
best-valid-loss: 0.333196
best-kappa: 0.8549
: Epoch: 79 | Training Loss: 0.273966 | Val. Loss: 0.333196 | Val. Kappa Score: 0.8549 | LR: 0.000250 | Estimated time: 57.60
Train loss on 50 batch: 0.291663
Train loss on 100 batch: 0.245190
Train loss on 150 batch: 0.279173
best-train-loss: 0.297880
best-valid-loss: 0.344385
best-kappa: 0.8551
: Epoch: 80 | Training Loss: 0.297880 | Val. Loss: 0.344385 | Val. Kappa Score: 0.8551 | LR: 0.000250 | Estimated time: 57.13
Train loss on 50 batch: 0.259816
Train loss on 100 batch: 0.289632
Train loss on 150 batch: 0.282666
best-train-loss: 0.271632
best-valid-loss: 0.339816
best-kappa: 0.8554
: Epoch: 81 | Training Loss: 0.271632 | Val. Loss: 0.339816 | Val. Kappa Score: 0.8554 | LR: 0.000250 | Estimated time: 58.09
Train loss on 50 batch: 0.275554
Train loss on 100 batch: 0.283965
Train loss on 150 batch: 0.212585
best-train-loss: 0.267975
best-valid-loss: 0.345405
best-kappa: 0.8556
: Epoch: 82 | Training Loss: 0.267975 | Val. Loss: 0.345405 | Val. Kappa Score: 0.8556 | LR: 0.000250 | Estimated time: 58.64
Train loss on 50 batch: 0.245732
Train loss on 100 batch: 0.290860
Train loss on 150 batch: 0.267067
best-train-loss: 0.275238
best-valid-loss: 0.356547
best-kappa: 0.8557
: Epoch: 83 | Training Loss: 0.275238 | Val. Loss: 0.356547 | Val. Kappa Score: 0.8557 | LR: 0.000250 | Estimated time: 57.95
Train loss on 50 batch: 0.258525
Train loss on 100 batch: 0.271142
Train loss on 150 batch: 0.287772
best-train-loss: 0.270643
best-valid-loss: 0.329924
best-kappa: 0.8559
: Epoch: 84 | Training Loss: 0.270643 | Val. Loss: 0.329924 | Val. Kappa Score: 0.8559 | LR: 0.000250 | Estimated time: 56.82
Train loss on 50 batch: 0.299689
Train loss on 100 batch: 0.289220
Train loss on 150 batch: 0.261099
best-train-loss: 0.286565
best-valid-loss: 0.332034
best-kappa: 0.8561
: Epoch: 85 | Training Loss: 0.286565 | Val. Loss: 0.332034 | Val. Kappa Score: 0.8561 | LR: 0.000250 | Estimated time: 58.23
Train loss on 50 batch: 0.282403
Train loss on 100 batch: 0.263168
Train loss on 150 batch: 0.288834
best-train-loss: 0.364214
best-valid-loss: 0.347510
best-kappa: 0.8564
: Epoch: 86 | Training Loss: 0.364214 | Val. Loss: 0.347510 | Val. Kappa Score: 0.8564 | LR: 0.000250 | Estimated time: 58.13
Train loss on 50 batch: 0.277308
Train loss on 100 batch: 0.268441
Train loss on 150 batch: 0.220775
best-train-loss: 0.278264
best-valid-loss: 0.333881
best-kappa: 0.8566
: Epoch: 87 | Training Loss: 0.278264 | Val. Loss: 0.333881 | Val. Kappa Score: 0.8566 | LR: 0.000250 | Estimated time: 58.48
Train loss on 50 batch: 0.270256
Train loss on 100 batch: 0.269377
Train loss on 150 batch: 0.280318
best-train-loss: 0.299448
best-valid-loss: 0.329871
best-kappa: 0.8567
: Epoch: 88 | Training Loss: 0.299448 | Val. Loss: 0.329871 | Val. Kappa Score: 0.8567 | LR: 0.000250 | Estimated time: 57.73
Train loss on 50 batch: 0.265914
Train loss on 100 batch: 0.284015
Train loss on 150 batch: 0.313230
: Epoch: 89 | Training Loss: 0.276390 | Val. Loss: 0.397639 | Val. Kappa Score: 0.8566 | LR: 0.000250 | Estimated time: 58.16
Train loss on 50 batch: 0.352828
Train loss on 100 batch: 0.248365
Train loss on 150 batch: 0.282318
best-train-loss: 0.285037
best-valid-loss: 0.344026
best-kappa: 0.8568
: Epoch: 90 | Training Loss: 0.285037 | Val. Loss: 0.344026 | Val. Kappa Score: 0.8568 | LR: 0.000250 | Estimated time: 57.80
Train loss on 50 batch: 0.285748
Train loss on 100 batch: 0.279094
Train loss on 150 batch: 0.256642
best-train-loss: 0.273119
best-valid-loss: 0.363329
best-kappa: 0.8569
: Epoch: 91 | Training Loss: 0.273119 | Val. Loss: 0.363329 | Val. Kappa Score: 0.8569 | LR: 0.000250 | Estimated time: 57.90
Train loss on 50 batch: 0.263113
Train loss on 100 batch: 0.244915
Train loss on 150 batch: 0.305347
best-train-loss: 0.278686
best-valid-loss: 0.348230
best-kappa: 0.8571
: Epoch: 92 | Training Loss: 0.278686 | Val. Loss: 0.348230 | Val. Kappa Score: 0.8571 | LR: 0.000250 | Estimated time: 57.85
Train loss on 50 batch: 0.255056
Train loss on 100 batch: 0.243502
Train loss on 150 batch: 0.262613
best-train-loss: 0.271017
best-valid-loss: 0.355720
best-kappa: 0.8572
: Epoch: 93 | Training Loss: 0.271017 | Val. Loss: 0.355720 | Val. Kappa Score: 0.8572 | LR: 0.000250 | Estimated time: 59.26
Train loss on 50 batch: 0.336049
Train loss on 100 batch: 0.238697
Train loss on 150 batch: 0.257450
best-train-loss: 0.335400
best-valid-loss: 0.369297
best-kappa: 0.8574
: Epoch: 94 | Training Loss: 0.335400 | Val. Loss: 0.369297 | Val. Kappa Score: 0.8574 | LR: 0.000250 | Estimated time: 57.29
Train loss on 50 batch: 0.264579
Train loss on 100 batch: 0.260008
Train loss on 150 batch: 0.282743
: Epoch: 95 | Training Loss: 0.273703 | Val. Loss: 0.365784 | Val. Kappa Score: 0.8573 | LR: 0.000250 | Estimated time: 58.09
Train loss on 50 batch: 0.267077
Train loss on 100 batch: 0.262583
Train loss on 150 batch: 0.273545
best-train-loss: 0.266397
best-valid-loss: 0.324785
best-kappa: 0.8575
: Epoch: 96 | Training Loss: 0.266397 | Val. Loss: 0.324785 | Val. Kappa Score: 0.8575 | LR: 0.000250 | Estimated time: 57.98
Train loss on 50 batch: 0.228767
Train loss on 100 batch: 0.254581
Train loss on 150 batch: 0.272964
best-train-loss: 0.260919
best-valid-loss: 0.336624
best-kappa: 0.8576
: Epoch: 97 | Training Loss: 0.260919 | Val. Loss: 0.336624 | Val. Kappa Score: 0.8576 | LR: 0.000250 | Estimated time: 58.12
Train loss on 50 batch: 0.256759
Train loss on 100 batch: 0.259323
Train loss on 150 batch: 0.286910
best-train-loss: 0.273744
best-valid-loss: 0.337351
best-kappa: 0.8578
: Epoch: 98 | Training Loss: 0.273744 | Val. Loss: 0.337351 | Val. Kappa Score: 0.8578 | LR: 0.000250 | Estimated time: 57.75
Train loss on 50 batch: 0.261674
Train loss on 100 batch: 0.254642
Train loss on 150 batch: 0.250451
best-train-loss: 0.282576
best-valid-loss: 0.341373
best-kappa: 0.8579
: Epoch: 99 | Training Loss: 0.282576 | Val. Loss: 0.341373 | Val. Kappa Score: 0.8579 | LR: 0.000250 | Estimated time: 57.59
Train loss on 50 batch: 0.221247
Train loss on 100 batch: 0.291741
Train loss on 150 batch: 0.259217
best-train-loss: 0.349961
best-valid-loss: 0.347859
best-kappa: 0.8580
: Epoch: 100 | Training Loss: 0.349961 | Val. Loss: 0.347859 | Val. Kappa Score: 0.8580 | LR: 0.000250 | Estimated time: 58.46
Train loss on 50 batch: 0.283399
Train loss on 100 batch: 0.227692
Train loss on 150 batch: 0.256135
best-train-loss: 0.274152
best-valid-loss: 0.333538
best-kappa: 0.8581
: Epoch: 101 | Training Loss: 0.274152 | Val. Loss: 0.333538 | Val. Kappa Score: 0.8581 | LR: 0.000250 | Estimated time: 57.23
Train loss on 50 batch: 0.258120
Train loss on 100 batch: 0.226784
Train loss on 150 batch: 0.281072
best-train-loss: 0.277415
best-valid-loss: 0.332567
best-kappa: 0.8582
: Epoch: 102 | Training Loss: 0.277415 | Val. Loss: 0.332567 | Val. Kappa Score: 0.8582 | LR: 0.000250 | Estimated time: 58.26
Train loss on 50 batch: 0.314180
Train loss on 100 batch: 0.260643
Train loss on 150 batch: 0.280203
: Epoch: 103 | Training Loss: 0.279682 | Val. Loss: 0.347326 | Val. Kappa Score: 0.8582 | LR: 0.000250 | Estimated time: 57.83
Train loss on 50 batch: 0.267360
Train loss on 100 batch: 0.254608
Train loss on 150 batch: 0.245410
best-train-loss: 0.267898
best-valid-loss: 0.355252
best-kappa: 0.8583
: Epoch: 104 | Training Loss: 0.267898 | Val. Loss: 0.355252 | Val. Kappa Score: 0.8583 | LR: 0.000250 | Estimated time: 58.87
Train loss on 50 batch: 0.246706
Train loss on 100 batch: 0.306264
Train loss on 150 batch: 0.245380
best-train-loss: 0.271817
best-valid-loss: 0.323688
best-kappa: 0.8585
: Epoch: 105 | Training Loss: 0.271817 | Val. Loss: 0.323688 | Val. Kappa Score: 0.8585 | LR: 0.000250 | Estimated time: 57.83
Train loss on 50 batch: 0.251388
Train loss on 100 batch: 0.261408
Train loss on 150 batch: 0.258267
best-train-loss: 0.265030
best-valid-loss: 0.326819
best-kappa: 0.8586
: Epoch: 106 | Training Loss: 0.265030 | Val. Loss: 0.326819 | Val. Kappa Score: 0.8586 | LR: 0.000250 | Estimated time: 57.48
Train loss on 50 batch: 0.257121
Train loss on 100 batch: 0.263799
Train loss on 150 batch: 0.258704
best-train-loss: 0.267482
best-valid-loss: 0.328612
best-kappa: 0.8587
: Epoch: 107 | Training Loss: 0.267482 | Val. Loss: 0.328612 | Val. Kappa Score: 0.8587 | LR: 0.000250 | Estimated time: 57.76
Train loss on 50 batch: 0.259761
Train loss on 100 batch: 0.287279
Train loss on 150 batch: 0.279852
best-train-loss: 0.272254
best-valid-loss: 0.328625
best-kappa: 0.8589
: Epoch: 108 | Training Loss: 0.272254 | Val. Loss: 0.328625 | Val. Kappa Score: 0.8589 | LR: 0.000250 | Estimated time: 58.13
Train loss on 50 batch: 0.238442
Train loss on 100 batch: 0.238276
Train loss on 150 batch: 0.297588
best-train-loss: 0.255737
best-valid-loss: 0.342362
best-kappa: 0.8590
: Epoch: 109 | Training Loss: 0.255737 | Val. Loss: 0.342362 | Val. Kappa Score: 0.8590 | LR: 0.000250 | Estimated time: 57.85
Train loss on 50 batch: 0.274767
Train loss on 100 batch: 0.250582
Train loss on 150 batch: 0.274847
best-train-loss: 0.264655
best-valid-loss: 0.345048
best-kappa: 0.8591
: Epoch: 110 | Training Loss: 0.264655 | Val. Loss: 0.345048 | Val. Kappa Score: 0.8591 | LR: 0.000250 | Estimated time: 58.15
Train loss on 50 batch: 0.284238
Train loss on 100 batch: 0.223962
Train loss on 150 batch: 0.266999
best-train-loss: 0.260920
best-valid-loss: 0.328680
best-kappa: 0.8593
: Epoch: 111 | Training Loss: 0.260920 | Val. Loss: 0.328680 | Val. Kappa Score: 0.8593 | LR: 0.000250 | Estimated time: 57.54
Train loss on 50 batch: 0.272499
Train loss on 100 batch: 0.281064
Train loss on 150 batch: 0.254594
: Epoch: 112 | Training Loss: 0.365016 | Val. Loss: 0.381151 | Val. Kappa Score: 0.8592 | LR: 0.000250 | Estimated time: 57.64
Train loss on 50 batch: 0.262317
Train loss on 100 batch: 0.257511
Train loss on 150 batch: 0.285887
: Epoch: 113 | Training Loss: 0.269104 | Val. Loss: 0.341547 | Val. Kappa Score: 0.8592 | LR: 0.000250 | Estimated time: 57.56
Train loss on 50 batch: 0.364567
Train loss on 100 batch: 0.285439
Train loss on 150 batch: 0.252188
best-train-loss: 0.281346
best-valid-loss: 0.324857
best-kappa: 0.8593
: Epoch: 114 | Training Loss: 0.281346 | Val. Loss: 0.324857 | Val. Kappa Score: 0.8593 | LR: 0.000250 | Estimated time: 57.03
Train loss on 50 batch: 0.281559
Train loss on 100 batch: 0.218175
Train loss on 150 batch: 0.257848
best-train-loss: 0.306765
best-valid-loss: 0.323352
best-kappa: 0.8593
: Epoch: 115 | Training Loss: 0.306765 | Val. Loss: 0.323352 | Val. Kappa Score: 0.8593 | LR: 0.000250 | Estimated time: 57.37
Train loss on 50 batch: 0.279092
Train loss on 100 batch: 0.274931
Train loss on 150 batch: 0.226004
best-train-loss: 0.252276
best-valid-loss: 0.338625
best-kappa: 0.8594
: Epoch: 116 | Training Loss: 0.252276 | Val. Loss: 0.338625 | Val. Kappa Score: 0.8594 | LR: 0.000250 | Estimated time: 57.84
Train loss on 50 batch: 0.270799
Train loss on 100 batch: 0.245776
Train loss on 150 batch: 0.240527
best-train-loss: 0.257578
best-valid-loss: 0.348061
best-kappa: 0.8595
: Epoch: 117 | Training Loss: 0.257578 | Val. Loss: 0.348061 | Val. Kappa Score: 0.8595 | LR: 0.000250 | Estimated time: 57.92
Train loss on 50 batch: 0.257135
Train loss on 100 batch: 0.262354
Train loss on 150 batch: 0.245005
best-train-loss: 0.347644
best-valid-loss: 0.367334
best-kappa: 0.8596
: Epoch: 118 | Training Loss: 0.347644 | Val. Loss: 0.367334 | Val. Kappa Score: 0.8596 | LR: 0.000250 | Estimated time: 57.57
Train loss on 50 batch: 0.274059
Train loss on 100 batch: 0.259392
Train loss on 150 batch: 0.264107
best-train-loss: 0.267324
best-valid-loss: 0.334842
best-kappa: 0.8596
: Epoch: 119 | Training Loss: 0.267324 | Val. Loss: 0.334842 | Val. Kappa Score: 0.8596 | LR: 0.000250 | Estimated time: 57.87
Train loss on 50 batch: 0.237099
Train loss on 100 batch: 0.256559
Train loss on 150 batch: 0.295705
best-train-loss: 0.269651
best-valid-loss: 0.325068
best-kappa: 0.8597
: Epoch: 120 | Training Loss: 0.269651 | Val. Loss: 0.325068 | Val. Kappa Score: 0.8597 | LR: 0.000250 | Estimated time: 57.62
Train loss on 50 batch: 0.247366
Train loss on 100 batch: 0.260704
Train loss on 150 batch: 0.266805
best-train-loss: 0.261367
best-valid-loss: 0.326660
best-kappa: 0.8600
: Epoch: 121 | Training Loss: 0.261367 | Val. Loss: 0.326660 | Val. Kappa Score: 0.8600 | LR: 0.000250 | Estimated time: 57.10
Train loss on 50 batch: 0.282084
Train loss on 100 batch: 0.265669
Train loss on 150 batch: 0.266983
best-train-loss: 0.275310
best-valid-loss: 0.357225
best-kappa: 0.8600
: Epoch: 122 | Training Loss: 0.275310 | Val. Loss: 0.357225 | Val. Kappa Score: 0.8600 | LR: 0.000250 | Estimated time: 57.95
Train loss on 50 batch: 0.257933
Train loss on 100 batch: 0.249963
Train loss on 150 batch: 0.270539
best-train-loss: 0.263327
best-valid-loss: 0.354174
best-kappa: 0.8601
: Epoch: 123 | Training Loss: 0.263327 | Val. Loss: 0.354174 | Val. Kappa Score: 0.8601 | LR: 0.000250 | Estimated time: 59.05
Train loss on 50 batch: 0.262659
Train loss on 100 batch: 0.252585
Train loss on 150 batch: 0.264270
best-train-loss: 0.263074
best-valid-loss: 0.366675
best-kappa: 0.8602
: Epoch: 124 | Training Loss: 0.263074 | Val. Loss: 0.366675 | Val. Kappa Score: 0.8602 | LR: 0.000250 | Estimated time: 58.73
Train loss on 50 batch: 0.263067
Train loss on 100 batch: 0.215384
Train loss on 150 batch: 0.255110
: Epoch: 125 | Training Loss: 0.259953 | Val. Loss: 0.364362 | Val. Kappa Score: 0.8602 | LR: 0.000250 | Estimated time: 57.18
Train loss on 50 batch: 0.283938
Train loss on 100 batch: 0.254413
Train loss on 150 batch: 0.241185
best-train-loss: 0.253861
best-valid-loss: 0.344171
best-kappa: 0.8602
: Epoch: 126 | Training Loss: 0.253861 | Val. Loss: 0.344171 | Val. Kappa Score: 0.8602 | LR: 0.000250 | Estimated time: 57.66
Train loss on 50 batch: 0.230949
Train loss on 100 batch: 0.265793
Train loss on 150 batch: 0.231612
best-train-loss: 0.251990
best-valid-loss: 0.325162
best-kappa: 0.8602
: Epoch: 127 | Training Loss: 0.251990 | Val. Loss: 0.325162 | Val. Kappa Score: 0.8602 | LR: 0.000250 | Estimated time: 57.55
Train loss on 50 batch: 0.263624
Train loss on 100 batch: 0.257919
Train loss on 150 batch: 0.302788
best-train-loss: 0.305779
best-valid-loss: 0.317475
best-kappa: 0.8604
: Epoch: 128 | Training Loss: 0.305779 | Val. Loss: 0.317475 | Val. Kappa Score: 0.8604 | LR: 0.000250 | Estimated time: 59.22
Train loss on 50 batch: 0.251429
Train loss on 100 batch: 0.249943
Train loss on 150 batch: 0.273220
best-train-loss: 0.259861
best-valid-loss: 0.356023
best-kappa: 0.8604
: Epoch: 129 | Training Loss: 0.259861 | Val. Loss: 0.356023 | Val. Kappa Score: 0.8604 | LR: 0.000250 | Estimated time: 58.65
Train loss on 50 batch: 0.249050
Train loss on 100 batch: 0.262562
Train loss on 150 batch: 0.267164
: Epoch: 130 | Training Loss: 0.243677 | Val. Loss: 0.377388 | Val. Kappa Score: 0.8604 | LR: 0.000250 | Estimated time: 58.66
Train loss on 50 batch: 0.268427
Train loss on 100 batch: 0.209980
Train loss on 150 batch: 0.266218
best-train-loss: 0.252864
best-valid-loss: 0.330606
best-kappa: 0.8604
: Epoch: 131 | Training Loss: 0.252864 | Val. Loss: 0.330606 | Val. Kappa Score: 0.8604 | LR: 0.000250 | Estimated time: 58.75
Train loss on 50 batch: 0.257244
Train loss on 100 batch: 0.245655
Train loss on 150 batch: 0.250238
: Epoch: 132 | Training Loss: 0.245840 | Val. Loss: 0.379735 | Val. Kappa Score: 0.8604 | LR: 0.000125 | Estimated time: 59.64
Train loss on 50 batch: 0.238231
Train loss on 100 batch: 0.251454
Train loss on 150 batch: 0.238586
: Epoch: 133 | Training Loss: 0.255632 | Val. Loss: 0.334881 | Val. Kappa Score: 0.8604 | LR: 0.000125 | Estimated time: 59.26
Train loss on 50 batch: 0.203733
Train loss on 100 batch: 0.287810
Train loss on 150 batch: 0.225546
best-train-loss: 0.227990
best-valid-loss: 0.340870
best-kappa: 0.8605
: Epoch: 134 | Training Loss: 0.227990 | Val. Loss: 0.340870 | Val. Kappa Score: 0.8605 | LR: 0.000125 | Estimated time: 58.69
Train loss on 50 batch: 0.225278
Train loss on 100 batch: 0.243744
Train loss on 150 batch: 0.245299
best-train-loss: 0.330589
best-valid-loss: 0.335839
best-kappa: 0.8606
: Epoch: 135 | Training Loss: 0.330589 | Val. Loss: 0.335839 | Val. Kappa Score: 0.8606 | LR: 0.000125 | Estimated time: 58.96
Train loss on 50 batch: 0.274318
Train loss on 100 batch: 0.237770
Train loss on 150 batch: 0.243153
best-train-loss: 0.241867
best-valid-loss: 0.343606
best-kappa: 0.8607
: Epoch: 136 | Training Loss: 0.241867 | Val. Loss: 0.343606 | Val. Kappa Score: 0.8607 | LR: 0.000125 | Estimated time: 58.02
Train loss on 50 batch: 0.226956
Train loss on 100 batch: 0.233020
Train loss on 150 batch: 0.240642
best-train-loss: 0.325093
best-valid-loss: 0.323694
best-kappa: 0.8608
: Epoch: 137 | Training Loss: 0.325093 | Val. Loss: 0.323694 | Val. Kappa Score: 0.8608 | LR: 0.000125 | Estimated time: 57.84
Train loss on 50 batch: 0.238118
Train loss on 100 batch: 0.232340
Train loss on 150 batch: 0.227748
best-train-loss: 0.231563
best-valid-loss: 0.332364
best-kappa: 0.8608
: Epoch: 138 | Training Loss: 0.231563 | Val. Loss: 0.332364 | Val. Kappa Score: 0.8608 | LR: 0.000125 | Estimated time: 57.73
Train loss on 50 batch: 0.243008
Train loss on 100 batch: 0.223907
Train loss on 150 batch: 0.245059
best-train-loss: 0.239998
best-valid-loss: 0.332644
best-kappa: 0.8609
: Epoch: 139 | Training Loss: 0.239998 | Val. Loss: 0.332644 | Val. Kappa Score: 0.8609 | LR: 0.000125 | Estimated time: 57.28
Train loss on 50 batch: 0.250914
Train loss on 100 batch: 0.232628
Train loss on 150 batch: 0.198989
: Epoch: 140 | Training Loss: 0.250737 | Val. Loss: 0.326911 | Val. Kappa Score: 0.8608 | LR: 0.000125 | Estimated time: 58.19
Train loss on 50 batch: 0.218708
Train loss on 100 batch: 0.224010
Train loss on 150 batch: 0.253128
: Epoch: 141 | Training Loss: 0.246650 | Val. Loss: 0.336640 | Val. Kappa Score: 0.8609 | LR: 0.000125 | Estimated time: 58.00
Train loss on 50 batch: 0.237925
Train loss on 100 batch: 0.263349
Train loss on 150 batch: 0.228034
: Epoch: 142 | Training Loss: 0.239274 | Val. Loss: 0.338136 | Val. Kappa Score: 0.8609 | LR: 0.000063 | Estimated time: 57.36
Train loss on 50 batch: 0.232997
Train loss on 100 batch: 0.241054
Train loss on 150 batch: 0.224910
: Epoch: 143 | Training Loss: 0.229928 | Val. Loss: 0.334266 | Val. Kappa Score: 0.8609 | LR: 0.000063 | Estimated time: 58.35
Train loss on 50 batch: 0.206109
Train loss on 100 batch: 0.241842
Train loss on 150 batch: 0.302877
best-train-loss: 0.240921
best-valid-loss: 0.324558
best-kappa: 0.8611
: Epoch: 144 | Training Loss: 0.240921 | Val. Loss: 0.324558 | Val. Kappa Score: 0.8611 | LR: 0.000063 | Estimated time: 57.89
Train loss on 50 batch: 0.232653
Train loss on 100 batch: 0.248687
Train loss on 150 batch: 0.208207
best-train-loss: 0.227942
best-valid-loss: 0.328086
best-kappa: 0.8612
: Epoch: 145 | Training Loss: 0.227942 | Val. Loss: 0.328086 | Val. Kappa Score: 0.8612 | LR: 0.000063 | Estimated time: 58.13
Train loss on 50 batch: 0.246167
Train loss on 100 batch: 0.243698
Train loss on 150 batch: 0.247988
best-train-loss: 0.247123
best-valid-loss: 0.339858
best-kappa: 0.8612
: Epoch: 146 | Training Loss: 0.247123 | Val. Loss: 0.339858 | Val. Kappa Score: 0.8612 | LR: 0.000063 | Estimated time: 58.59
Train loss on 50 batch: 0.219484
Train loss on 100 batch: 0.229883
Train loss on 150 batch: 0.223107
best-train-loss: 0.236188
best-valid-loss: 0.334146
best-kappa: 0.8613
: Epoch: 147 | Training Loss: 0.236188 | Val. Loss: 0.334146 | Val. Kappa Score: 0.8613 | LR: 0.000063 | Estimated time: 58.39
Train loss on 50 batch: 0.213260
Train loss on 100 batch: 0.245066
Train loss on 150 batch: 0.262012
best-train-loss: 0.239211
best-valid-loss: 0.328757
best-kappa: 0.8614
: Epoch: 148 | Training Loss: 0.239211 | Val. Loss: 0.328757 | Val. Kappa Score: 0.8614 | LR: 0.000063 | Estimated time: 58.83
Train loss on 50 batch: 0.240171
Train loss on 100 batch: 0.229502
Train loss on 150 batch: 0.209512
best-train-loss: 0.263250
best-valid-loss: 0.331422
best-kappa: 0.8615
: Epoch: 149 | Training Loss: 0.263250 | Val. Loss: 0.331422 | Val. Kappa Score: 0.8615 | LR: 0.000063 | Estimated time: 57.24
Train loss on 50 batch: 0.256504
Train loss on 100 batch: 0.201771
Train loss on 150 batch: 0.224401
: Epoch: 150 | Training Loss: 0.246759 | Val. Loss: 0.328759 | Val. Kappa Score: 0.8615 | LR: 0.000063 | Estimated time: 58.35
Train loss on 50 batch: 0.221778
Train loss on 100 batch: 0.220913
Train loss on 150 batch: 0.260807
best-train-loss: 0.249099
best-valid-loss: 0.334583
best-kappa: 0.8616
: Epoch: 151 | Training Loss: 0.249099 | Val. Loss: 0.334583 | Val. Kappa Score: 0.8616 | LR: 0.000063 | Estimated time: 57.85
Train loss on 50 batch: 0.227520
Train loss on 100 batch: 0.237591
Train loss on 150 batch: 0.216238
best-train-loss: 0.243229
best-valid-loss: 0.326437
best-kappa: 0.8617
: Epoch: 152 | Training Loss: 0.243229 | Val. Loss: 0.326437 | Val. Kappa Score: 0.8617 | LR: 0.000063 | Estimated time: 57.84
Train loss on 50 batch: 0.213970
Train loss on 100 batch: 0.202657
Train loss on 150 batch: 0.262499
best-train-loss: 0.230133
best-valid-loss: 0.331359
best-kappa: 0.8617
: Epoch: 153 | Training Loss: 0.230133 | Val. Loss: 0.331359 | Val. Kappa Score: 0.8617 | LR: 0.000063 | Estimated time: 58.55
Train loss on 50 batch: 0.226197
Train loss on 100 batch: 0.212106
Train loss on 150 batch: 0.235306
best-train-loss: 0.306692
best-valid-loss: 0.332047
best-kappa: 0.8617
: Epoch: 154 | Training Loss: 0.306692 | Val. Loss: 0.332047 | Val. Kappa Score: 0.8617 | LR: 0.000063 | Estimated time: 58.03
Train loss on 50 batch: 0.211158
Train loss on 100 batch: 0.235251
Train loss on 150 batch: 0.264991
best-train-loss: 0.234193
best-valid-loss: 0.335089
best-kappa: 0.8618
: Epoch: 155 | Training Loss: 0.234193 | Val. Loss: 0.335089 | Val. Kappa Score: 0.8618 | LR: 0.000063 | Estimated time: 58.36
Train loss on 50 batch: 0.200297
Train loss on 100 batch: 0.245638
Train loss on 150 batch: 0.238999
best-train-loss: 0.315240
best-valid-loss: 0.327137
best-kappa: 0.8619
: Epoch: 156 | Training Loss: 0.315240 | Val. Loss: 0.327137 | Val. Kappa Score: 0.8619 | LR: 0.000063 | Estimated time: 58.33
Train loss on 50 batch: 0.225278
Train loss on 100 batch: 0.216320
Train loss on 150 batch: 0.224541
best-train-loss: 0.237271
best-valid-loss: 0.329450
best-kappa: 0.8620
: Epoch: 157 | Training Loss: 0.237271 | Val. Loss: 0.329450 | Val. Kappa Score: 0.8620 | LR: 0.000063 | Estimated time: 57.86
Train loss on 50 batch: 0.236996
Train loss on 100 batch: 0.253250
Train loss on 150 batch: 0.213718
best-train-loss: 0.243544
best-valid-loss: 0.331746
best-kappa: 0.8621
: Epoch: 158 | Training Loss: 0.243544 | Val. Loss: 0.331746 | Val. Kappa Score: 0.8621 | LR: 0.000063 | Estimated time: 58.09
Train loss on 50 batch: 0.228205
Train loss on 100 batch: 0.213418
Train loss on 150 batch: 0.252472
best-train-loss: 0.225945
best-valid-loss: 0.338302
best-kappa: 0.8621
: Epoch: 159 | Training Loss: 0.225945 | Val. Loss: 0.338302 | Val. Kappa Score: 0.8621 | LR: 0.000063 | Estimated time: 57.68
Train loss on 50 batch: 0.233839
Train loss on 100 batch: 0.201429
Train loss on 150 batch: 0.252298
best-train-loss: 0.226148
best-valid-loss: 0.329149
best-kappa: 0.8622
: Epoch: 160 | Training Loss: 0.226148 | Val. Loss: 0.329149 | Val. Kappa Score: 0.8622 | LR: 0.000063 | Estimated time: 58.33
Train loss on 50 batch: 0.220008
Train loss on 100 batch: 0.265633
Train loss on 150 batch: 0.231625
: Epoch: 161 | Training Loss: 0.246089 | Val. Loss: 0.327606 | Val. Kappa Score: 0.8622 | LR: 0.000063 | Estimated time: 57.65
Train loss on 50 batch: 0.206458
Train loss on 100 batch: 0.195447
Train loss on 150 batch: 0.260629
best-train-loss: 0.226305
best-valid-loss: 0.329682
best-kappa: 0.8623
: Epoch: 162 | Training Loss: 0.226305 | Val. Loss: 0.329682 | Val. Kappa Score: 0.8623 | LR: 0.000063 | Estimated time: 57.85
Train loss on 50 batch: 0.237136
Train loss on 100 batch: 0.222463
Train loss on 150 batch: 0.227340
best-train-loss: 0.230843
best-valid-loss: 0.335281
best-kappa: 0.8623
: Epoch: 163 | Training Loss: 0.230843 | Val. Loss: 0.335281 | Val. Kappa Score: 0.8623 | LR: 0.000063 | Estimated time: 57.14
Train loss on 50 batch: 0.243361
Train loss on 100 batch: 0.224025
Train loss on 150 batch: 0.202085
best-train-loss: 0.233537
best-valid-loss: 0.322215
best-kappa: 0.8624
: Epoch: 164 | Training Loss: 0.233537 | Val. Loss: 0.322215 | Val. Kappa Score: 0.8624 | LR: 0.000063 | Estimated time: 58.05
Train loss on 50 batch: 0.222266
Train loss on 100 batch: 0.239289
Train loss on 150 batch: 0.226432
best-train-loss: 0.232805
best-valid-loss: 0.327676
best-kappa: 0.8626
: Epoch: 165 | Training Loss: 0.232805 | Val. Loss: 0.327676 | Val. Kappa Score: 0.8626 | LR: 0.000063 | Estimated time: 58.26
Train loss on 50 batch: 0.247225
Train loss on 100 batch: 0.219741
Train loss on 150 batch: 0.236190
best-train-loss: 0.240011
best-valid-loss: 0.329661
best-kappa: 0.8626
: Epoch: 166 | Training Loss: 0.240011 | Val. Loss: 0.329661 | Val. Kappa Score: 0.8626 | LR: 0.000063 | Estimated time: 57.59
Train loss on 50 batch: 0.238002
Train loss on 100 batch: 0.219770
Train loss on 150 batch: 0.240384
best-train-loss: 0.237143
best-valid-loss: 0.332005
best-kappa: 0.8627
: Epoch: 167 | Training Loss: 0.237143 | Val. Loss: 0.332005 | Val. Kappa Score: 0.8627 | LR: 0.000063 | Estimated time: 58.33
Train loss on 50 batch: 0.222634
Train loss on 100 batch: 0.260444
Train loss on 150 batch: 0.239348
best-train-loss: 0.317172
best-valid-loss: 0.344362
best-kappa: 0.8628
: Epoch: 168 | Training Loss: 0.317172 | Val. Loss: 0.344362 | Val. Kappa Score: 0.8628 | LR: 0.000063 | Estimated time: 57.31
Train loss on 50 batch: 0.239774
Train loss on 100 batch: 0.204265
Train loss on 150 batch: 0.222471
best-train-loss: 0.241814
best-valid-loss: 0.332083
best-kappa: 0.8628
: Epoch: 169 | Training Loss: 0.241814 | Val. Loss: 0.332083 | Val. Kappa Score: 0.8628 | LR: 0.000063 | Estimated time: 57.73
Train loss on 50 batch: 0.229395
Train loss on 100 batch: 0.250604
Train loss on 150 batch: 0.246844
best-train-loss: 0.233782
best-valid-loss: 0.333162
best-kappa: 0.8629
: Epoch: 170 | Training Loss: 0.233782 | Val. Loss: 0.333162 | Val. Kappa Score: 0.8629 | LR: 0.000063 | Estimated time: 57.13
Train loss on 50 batch: 0.234788
Train loss on 100 batch: 0.229961
Train loss on 150 batch: 0.221588
: Epoch: 171 | Training Loss: 0.226012 | Val. Loss: 0.328897 | Val. Kappa Score: 0.8629 | LR: 0.000063 | Estimated time: 57.49
Train loss on 50 batch: 0.261377
Train loss on 100 batch: 0.211351
Train loss on 150 batch: 0.220242
: Epoch: 172 | Training Loss: 0.236846 | Val. Loss: 0.326785 | Val. Kappa Score: 0.8629 | LR: 0.000063 | Estimated time: 59.29
Train loss on 50 batch: 0.270477
Train loss on 100 batch: 0.216653
Train loss on 150 batch: 0.233453
best-train-loss: 0.308024
best-valid-loss: 0.327227
best-kappa: 0.8630
: Epoch: 173 | Training Loss: 0.308024 | Val. Loss: 0.327227 | Val. Kappa Score: 0.8630 | LR: 0.000063 | Estimated time: 57.72
Train loss on 50 batch: 0.222841
Train loss on 100 batch: 0.205098
Train loss on 150 batch: 0.256160
best-train-loss: 0.230786
best-valid-loss: 0.322566
best-kappa: 0.8630
: Epoch: 174 | Training Loss: 0.230786 | Val. Loss: 0.322566 | Val. Kappa Score: 0.8630 | LR: 0.000063 | Estimated time: 58.01
Train loss on 50 batch: 0.214387
Train loss on 100 batch: 0.223459
Train loss on 150 batch: 0.239181
best-train-loss: 0.232941
best-valid-loss: 0.326533
best-kappa: 0.8630
: Epoch: 175 | Training Loss: 0.232941 | Val. Loss: 0.326533 | Val. Kappa Score: 0.8630 | LR: 0.000063 | Estimated time: 59.17
Train loss on 50 batch: 0.255600
Train loss on 100 batch: 0.215492
Train loss on 150 batch: 0.211899
best-train-loss: 0.235218
best-valid-loss: 0.337255
best-kappa: 0.8631
: Epoch: 176 | Training Loss: 0.235218 | Val. Loss: 0.337255 | Val. Kappa Score: 0.8631 | LR: 0.000063 | Estimated time: 60.35
Train loss on 50 batch: 0.200170
Train loss on 100 batch: 0.233612
Train loss on 150 batch: 0.203078
best-train-loss: 0.240316
best-valid-loss: 0.325344
best-kappa: 0.8631
: Epoch: 177 | Training Loss: 0.240316 | Val. Loss: 0.325344 | Val. Kappa Score: 0.8631 | LR: 0.000063 | Estimated time: 58.55
Train loss on 50 batch: 0.199978
Train loss on 100 batch: 0.257971
Train loss on 150 batch: 0.211952
best-train-loss: 0.223613
best-valid-loss: 0.320494
best-kappa: 0.8631
: Epoch: 178 | Training Loss: 0.223613 | Val. Loss: 0.320494 | Val. Kappa Score: 0.8631 | LR: 0.000063 | Estimated time: 59.39
Train loss on 50 batch: 0.204599
Train loss on 100 batch: 0.252208
Train loss on 150 batch: 0.232408
best-train-loss: 0.235562
best-valid-loss: 0.331953
best-kappa: 0.8632
: Epoch: 179 | Training Loss: 0.235562 | Val. Loss: 0.331953 | Val. Kappa Score: 0.8632 | LR: 0.000063 | Estimated time: 59.37
Train loss on 50 batch: 0.243214
Train loss on 100 batch: 0.235126
Train loss on 150 batch: 0.210481
best-train-loss: 0.232754
best-valid-loss: 0.323404
best-kappa: 0.8632
: Epoch: 180 | Training Loss: 0.232754 | Val. Loss: 0.323404 | Val. Kappa Score: 0.8632 | LR: 0.000063 | Estimated time: 59.01
Train loss on 50 batch: 0.225408
Train loss on 100 batch: 0.227732
Train loss on 150 batch: 0.229712
best-train-loss: 0.225438
best-valid-loss: 0.332913
best-kappa: 0.8633
: Epoch: 181 | Training Loss: 0.225438 | Val. Loss: 0.332913 | Val. Kappa Score: 0.8633 | LR: 0.000063 | Estimated time: 57.71
----------------------------------------

Experiment N: 157: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.29 23:30:58
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96026320>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 157: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.08.29 23:31:14
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51764be0>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 157: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 23:36:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f414e0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 157: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 23:37:12
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f3f588>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.068099
Train loss on 100 batch: 0.655748
Train loss on 150 batch: 0.650533
best-train-loss: 0.706035
best-valid-loss: 1.207197
best-kappa: 0.7812
: Epoch: 1 | Training Loss: 0.706035 | Val. Loss: 1.207197 | Val. Kappa Score: 0.7812 | LR: 0.001000 | Estimated time: 74.56
Train loss on 50 batch: 0.452733
Train loss on 100 batch: 0.501432
Train loss on 150 batch: 0.452438
best-train-loss: 0.485425
best-valid-loss: 0.412135
best-kappa: 0.8133
: Epoch: 2 | Training Loss: 0.485425 | Val. Loss: 0.412135 | Val. Kappa Score: 0.8133 | LR: 0.001000 | Estimated time: 73.78
Train loss on 50 batch: 0.484098
----------------------------------------

Experiment N: 158: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.29 23:40:19
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f424e0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.068099
Train loss on 100 batch: 0.655748
Train loss on 150 batch: 0.650533
best-train-loss: 0.706035
best-valid-loss: 1.207197
best-kappa: 0.7812
: Epoch: 1 | Training Loss: 0.706035 | Val. Loss: 1.207197 | Val. Kappa Score: 0.7812 | LR: 0.001000 | Estimated time: 74.30
Train loss on 50 batch: 0.452733
Train loss on 100 batch: 0.501432
Train loss on 150 batch: 0.452438
best-train-loss: 0.485425
best-valid-loss: 0.412135
best-kappa: 0.8133
: Epoch: 2 | Training Loss: 0.485425 | Val. Loss: 0.412135 | Val. Kappa Score: 0.8133 | LR: 0.001000 | Estimated time: 73.16
Train loss on 50 batch: 0.484098
Train loss on 100 batch: 0.424582
Train loss on 150 batch: 0.443468
best-train-loss: 0.438640
best-valid-loss: 0.388574
best-kappa: 0.8268
: Epoch: 3 | Training Loss: 0.438640 | Val. Loss: 0.388574 | Val. Kappa Score: 0.8268 | LR: 0.001000 | Estimated time: 71.39
Train loss on 50 batch: 0.514322
Train loss on 100 batch: 0.333417
Train loss on 150 batch: 0.303562
: Epoch: 4 | Training Loss: 0.380419 | Val. Loss: 0.529187 | Val. Kappa Score: 0.8188 | LR: 0.001000 | Estimated time: 70.11
Train loss on 50 batch: 0.376969
Train loss on 100 batch: 0.355620
Train loss on 150 batch: 0.343603
: Epoch: 5 | Training Loss: 0.366293 | Val. Loss: 0.678570 | Val. Kappa Score: 0.7558 | LR: 0.001000 | Estimated time: 71.55
Train loss on 50 batch: 0.357986
Train loss on 100 batch: 0.344660
Train loss on 150 batch: 0.355369
: Epoch: 6 | Training Loss: 0.366242 | Val. Loss: 0.389217 | Val. Kappa Score: 0.7701 | LR: 0.000500 | Estimated time: 71.63
Train loss on 50 batch: 0.338957
Train loss on 100 batch: 0.255443
Train loss on 150 batch: 0.280333
best-train-loss: 0.301358
best-valid-loss: 0.338374
best-kappa: 0.7842
: Epoch: 7 | Training Loss: 0.301358 | Val. Loss: 0.338374 | Val. Kappa Score: 0.7842 | LR: 0.000500 | Estimated time: 75.87
Train loss on 50 batch: 0.228199
Train loss on 100 batch: 0.280799
Train loss on 150 batch: 0.248069
best-train-loss: 0.244069
best-valid-loss: 0.309465
best-kappa: 0.7959
: Epoch: 8 | Training Loss: 0.244069 | Val. Loss: 0.309465 | Val. Kappa Score: 0.7959 | LR: 0.000500 | Estimated time: 71.64
Train loss on 50 batch: 0.227304
Train loss on 100 batch: 0.240147
Train loss on 150 batch: 0.196150
: Epoch: 9 | Training Loss: 0.230123 | Val. Loss: 0.325984 | Val. Kappa Score: 0.8056 | LR: 0.000500 | Estimated time: 68.90
Train loss on 50 batch: 0.206397
Train loss on 100 batch: 0.227922
Train loss on 150 batch: 0.216540
best-train-loss: 0.220783
best-valid-loss: 0.308764
best-kappa: 0.8135
: Epoch: 10 | Training Loss: 0.220783 | Val. Loss: 0.308764 | Val. Kappa Score: 0.8135 | LR: 0.000500 | Estimated time: 69.58
Train loss on 50 batch: 0.226865
Train loss on 100 batch: 0.214684
Train loss on 150 batch: 0.245497
: Epoch: 11 | Training Loss: 0.235338 | Val. Loss: 0.358245 | Val. Kappa Score: 0.8180 | LR: 0.000500 | Estimated time: 74.14
Train loss on 50 batch: 0.223407
Train loss on 100 batch: 0.202577
Train loss on 150 batch: 0.192876
: Epoch: 12 | Training Loss: 0.204779 | Val. Loss: 0.330299 | Val. Kappa Score: 0.8226 | LR: 0.000500 | Estimated time: 71.87
Train loss on 50 batch: 0.203150
Train loss on 100 batch: 0.216784
Train loss on 150 batch: 0.218981
: Epoch: 13 | Training Loss: 0.204038 | Val. Loss: 0.310554 | Val. Kappa Score: 0.8275 | LR: 0.000250 | Estimated time: 73.22
Train loss on 50 batch: 0.164381
Train loss on 100 batch: 0.180758
Train loss on 150 batch: 0.182029
best-train-loss: 0.178281
best-valid-loss: 0.266098
best-kappa: 0.8320
: Epoch: 14 | Training Loss: 0.178281 | Val. Loss: 0.266098 | Val. Kappa Score: 0.8320 | LR: 0.000250 | Estimated time: 73.35
Train loss on 50 batch: 0.179513
Train loss on 100 batch: 0.151806
Train loss on 150 batch: 0.164144
: Epoch: 15 | Training Loss: 0.163001 | Val. Loss: 0.266331 | Val. Kappa Score: 0.8360 | LR: 0.000250 | Estimated time: 71.59
Train loss on 50 batch: 0.140049
Train loss on 100 batch: 0.139929
Train loss on 150 batch: 0.177480
: Epoch: 16 | Training Loss: 0.169331 | Val. Loss: 0.296195 | Val. Kappa Score: 0.8393 | LR: 0.000250 | Estimated time: 69.00
Train loss on 50 batch: 0.149416
Train loss on 100 batch: 0.124113
Train loss on 150 batch: 0.163972
: Epoch: 17 | Training Loss: 0.154524 | Val. Loss: 0.290155 | Val. Kappa Score: 0.8430 | LR: 0.000125 | Estimated time: 71.63
Train loss on 50 batch: 0.134215
Train loss on 100 batch: 0.106010
Train loss on 150 batch: 0.141328
: Epoch: 18 | Training Loss: 0.125852 | Val. Loss: 0.275657 | Val. Kappa Score: 0.8461 | LR: 0.000125 | Estimated time: 72.27
Train loss on 50 batch: 0.108612
Train loss on 100 batch: 0.111642
Train loss on 150 batch: 0.118227
: Epoch: 19 | Training Loss: 0.115860 | Val. Loss: 0.288809 | Val. Kappa Score: 0.8480 | LR: 0.000125 | Estimated time: 72.52
Train loss on 50 batch: 0.100703
Train loss on 100 batch: 0.108303
Train loss on 150 batch: 0.119522
: Epoch: 20 | Training Loss: 0.108743 | Val. Loss: 0.285285 | Val. Kappa Score: 0.8502 | LR: 0.000063 | Estimated time: 72.01
Train loss on 50 batch: 0.086366
Train loss on 100 batch: 0.096166
Train loss on 150 batch: 0.099590
: Epoch: 21 | Training Loss: 0.104817 | Val. Loss: 0.279555 | Val. Kappa Score: 0.8522 | LR: 0.000063 | Estimated time: 70.27
Train loss on 50 batch: 0.095037
Train loss on 100 batch: 0.088866
Train loss on 150 batch: 0.085982
: Epoch: 22 | Training Loss: 0.094105 | Val. Loss: 0.288022 | Val. Kappa Score: 0.8538 | LR: 0.000063 | Estimated time: 69.74
Train loss on 50 batch: 0.077394
Train loss on 100 batch: 0.088190
Train loss on 150 batch: 0.099546
: Epoch: 23 | Training Loss: 0.092554 | Val. Loss: 0.292513 | Val. Kappa Score: 0.8551 | LR: 0.000031 | Estimated time: 69.60
Train loss on 50 batch: 0.077319
Train loss on 100 batch: 0.082204
Train loss on 150 batch: 0.089422
: Epoch: 24 | Training Loss: 0.093985 | Val. Loss: 0.280739 | Val. Kappa Score: 0.8567 | LR: 0.000031 | Estimated time: 69.28
time_estimated: 1720.36
n-epochs: 24
time_estimated: 1720.42
----------------------------------------

Experiment N: 159: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.08.30 08:16:56
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb96026278>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.660119
Train loss on 100 batch: 0.549684
Train loss on 150 batch: 0.494282
best-train-loss: 0.551253
best-valid-loss: 0.557491
best-kappa: 0.7862
: Epoch: 1 | Training Loss: 0.551253 | Val. Loss: 0.557491 | Val. Kappa Score: 0.7862 | LR: 0.001000 | Estimated time: 56.15
Train loss on 50 batch: 0.463487
Train loss on 100 batch: 0.464903
Train loss on 150 batch: 0.401290
: Epoch: 2 | Training Loss: 0.486215 | Val. Loss: 0.684169 | Val. Kappa Score: 0.7557 | LR: 0.001000 | Estimated time: 57.84
Train loss on 50 batch: 0.517190
Train loss on 100 batch: 0.447374
Train loss on 150 batch: 0.492520
best-train-loss: 0.472071
best-valid-loss: 0.455969
best-kappa: 0.7764
: Epoch: 3 | Training Loss: 0.472071 | Val. Loss: 0.455969 | Val. Kappa Score: 0.7764 | LR: 0.001000 | Estimated time: 57.29
Train loss on 50 batch: 0.423503
Train loss on 100 batch: 0.451616
Train loss on 150 batch: 0.407990
best-train-loss: 0.534670
best-valid-loss: 0.448005
best-kappa: 0.7903
: Epoch: 4 | Training Loss: 0.534670 | Val. Loss: 0.448005 | Val. Kappa Score: 0.7903 | LR: 0.001000 | Estimated time: 57.27
Train loss on 50 batch: 0.419824
Train loss on 100 batch: 0.493086
Train loss on 150 batch: 0.380384
: Epoch: 5 | Training Loss: 0.416968 | Val. Loss: 0.544054 | Val. Kappa Score: 0.7884 | LR: 0.001000 | Estimated time: 58.20
Train loss on 50 batch: 0.379182
Train loss on 100 batch: 0.375675
Train loss on 150 batch: 0.382986
best-train-loss: 0.369929
best-valid-loss: 0.446854
best-kappa: 0.7940
: Epoch: 6 | Training Loss: 0.369929 | Val. Loss: 0.446854 | Val. Kappa Score: 0.7940 | LR: 0.001000 | Estimated time: 57.67
Train loss on 50 batch: 0.416028
Train loss on 100 batch: 0.365910
Train loss on 150 batch: 0.389658
best-train-loss: 0.395237
best-valid-loss: 0.439947
best-kappa: 0.8023
: Epoch: 7 | Training Loss: 0.395237 | Val. Loss: 0.439947 | Val. Kappa Score: 0.8023 | LR: 0.001000 | Estimated time: 57.75
Train loss on 50 batch: 0.311768
Train loss on 100 batch: 0.410966
Train loss on 150 batch: 0.354106
best-train-loss: 0.378137
best-valid-loss: 0.408229
best-kappa: 0.8066
: Epoch: 8 | Training Loss: 0.378137 | Val. Loss: 0.408229 | Val. Kappa Score: 0.8066 | LR: 0.001000 | Estimated time: 56.87
Train loss on 50 batch: 0.394451
Train loss on 100 batch: 0.418102
Train loss on 150 batch: 0.387331
best-train-loss: 0.387570
best-valid-loss: 0.391523
best-kappa: 0.8122
: Epoch: 9 | Training Loss: 0.387570 | Val. Loss: 0.391523 | Val. Kappa Score: 0.8122 | LR: 0.001000 | Estimated time: 57.58
Train loss on 50 batch: 0.336352
Train loss on 100 batch: 0.382711
Train loss on 150 batch: 0.329226
best-train-loss: 0.453756
best-valid-loss: 0.381310
best-kappa: 0.8159
: Epoch: 10 | Training Loss: 0.453756 | Val. Loss: 0.381310 | Val. Kappa Score: 0.8159 | LR: 0.001000 | Estimated time: 57.35
Train loss on 50 batch: 0.368168
Train loss on 100 batch: 0.350747
Train loss on 150 batch: 0.389197
best-train-loss: 0.372025
best-valid-loss: 0.368784
best-kappa: 0.8199
: Epoch: 11 | Training Loss: 0.372025 | Val. Loss: 0.368784 | Val. Kappa Score: 0.8199 | LR: 0.001000 | Estimated time: 56.95
Train loss on 50 batch: 0.315197
Train loss on 100 batch: 0.346526
Train loss on 150 batch: 0.372719
: Epoch: 12 | Training Loss: 0.349718 | Val. Loss: 0.374800 | Val. Kappa Score: 0.8215 | LR: 0.001000 | Estimated time: 56.80
Train loss on 50 batch: 0.324509
Train loss on 100 batch: 0.369760
Train loss on 150 batch: 0.343373
: Epoch: 13 | Training Loss: 0.351229 | Val. Loss: 0.421054 | Val. Kappa Score: 0.8251 | LR: 0.001000 | Estimated time: 57.91
Train loss on 50 batch: 0.329356
Train loss on 100 batch: 0.331137
Train loss on 150 batch: 0.362076
best-train-loss: 0.346518
best-valid-loss: 0.322152
best-kappa: 0.8290
: Epoch: 14 | Training Loss: 0.346518 | Val. Loss: 0.322152 | Val. Kappa Score: 0.8290 | LR: 0.001000 | Estimated time: 57.92
Train loss on 50 batch: 0.356392
Train loss on 100 batch: 0.339673
Train loss on 150 batch: 0.325344
: Epoch: 15 | Training Loss: 0.370660 | Val. Loss: 0.436137 | Val. Kappa Score: 0.8302 | LR: 0.001000 | Estimated time: 56.88
Train loss on 50 batch: 0.383687
Train loss on 100 batch: 0.300231
Train loss on 150 batch: 0.322129
: Epoch: 16 | Training Loss: 0.345335 | Val. Loss: 0.388814 | Val. Kappa Score: 0.8315 | LR: 0.001000 | Estimated time: 57.33
Train loss on 50 batch: 0.398610
Train loss on 100 batch: 0.344850
Train loss on 150 batch: 0.284903
: Epoch: 17 | Training Loss: 0.341202 | Val. Loss: 0.338900 | Val. Kappa Score: 0.8336 | LR: 0.000500 | Estimated time: 57.28
Train loss on 50 batch: 0.334474
Train loss on 100 batch: 0.273387
Train loss on 150 batch: 0.301628
: Epoch: 18 | Training Loss: 0.307954 | Val. Loss: 0.326618 | Val. Kappa Score: 0.8354 | LR: 0.000500 | Estimated time: 56.57
Train loss on 50 batch: 0.286054
Train loss on 100 batch: 0.321440
Train loss on 150 batch: 0.345079
: Epoch: 19 | Training Loss: 0.322011 | Val. Loss: 0.347159 | Val. Kappa Score: 0.8372 | LR: 0.000500 | Estimated time: 57.62
Train loss on 50 batch: 0.338050
Train loss on 100 batch: 0.307020
Train loss on 150 batch: 0.265475
: Epoch: 20 | Training Loss: 0.292698 | Val. Loss: 0.326616 | Val. Kappa Score: 0.8391 | LR: 0.000250 | Estimated time: 57.05
Train loss on 50 batch: 0.303020
Train loss on 100 batch: 0.260440
Train loss on 150 batch: 0.311518
: Epoch: 21 | Training Loss: 0.339249 | Val. Loss: 0.324778 | Val. Kappa Score: 0.8409 | LR: 0.000250 | Estimated time: 56.68
Train loss on 50 batch: 0.291866
Train loss on 100 batch: 0.285225
Train loss on 150 batch: 0.311469
: Epoch: 22 | Training Loss: 0.294376 | Val. Loss: 0.327006 | Val. Kappa Score: 0.8423 | LR: 0.000250 | Estimated time: 57.43
Train loss on 50 batch: 0.282562
Train loss on 100 batch: 0.296419
Train loss on 150 batch: 0.282814
: Epoch: 23 | Training Loss: 0.310194 | Val. Loss: 0.338166 | Val. Kappa Score: 0.8440 | LR: 0.000125 | Estimated time: 57.53
Train loss on 50 batch: 0.305981
Train loss on 100 batch: 0.304288
Train loss on 150 batch: 0.261851
best-train-loss: 0.376866
best-valid-loss: 0.321751
best-kappa: 0.8453
: Epoch: 24 | Training Loss: 0.376866 | Val. Loss: 0.321751 | Val. Kappa Score: 0.8453 | LR: 0.000125 | Estimated time: 57.75
Train loss on 50 batch: 0.276350
Train loss on 100 batch: 0.266674
Train loss on 150 batch: 0.313152
: Epoch: 25 | Training Loss: 0.284456 | Val. Loss: 0.330211 | Val. Kappa Score: 0.8462 | LR: 0.000125 | Estimated time: 56.81
Train loss on 50 batch: 0.281893
Train loss on 100 batch: 0.227794
Train loss on 150 batch: 0.300828
: Epoch: 26 | Training Loss: 0.325605 | Val. Loss: 0.324578 | Val. Kappa Score: 0.8470 | LR: 0.000125 | Estimated time: 57.11
Train loss on 50 batch: 0.281955
Train loss on 100 batch: 0.314681
Train loss on 150 batch: 0.278367
best-train-loss: 0.312067
best-valid-loss: 0.320604
best-kappa: 0.8481
: Epoch: 27 | Training Loss: 0.312067 | Val. Loss: 0.320604 | Val. Kappa Score: 0.8481 | LR: 0.000125 | Estimated time: 57.65
Train loss on 50 batch: 0.295170
Train loss on 100 batch: 0.288352
Train loss on 150 batch: 0.253895
: Epoch: 28 | Training Loss: 0.295145 | Val. Loss: 0.321219 | Val. Kappa Score: 0.8485 | LR: 0.000125 | Estimated time: 57.28
Train loss on 50 batch: 0.249198
Train loss on 100 batch: 0.298242
Train loss on 150 batch: 0.288127
best-train-loss: 0.299663
best-valid-loss: 0.314548
best-kappa: 0.8495
: Epoch: 29 | Training Loss: 0.299663 | Val. Loss: 0.314548 | Val. Kappa Score: 0.8495 | LR: 0.000125 | Estimated time: 56.90
Train loss on 50 batch: 0.274084
Train loss on 100 batch: 0.258476
Train loss on 150 batch: 0.293029
: Epoch: 30 | Training Loss: 0.284255 | Val. Loss: 0.319208 | Val. Kappa Score: 0.8504 | LR: 0.000125 | Estimated time: 57.04
Train loss on 50 batch: 0.250189
Train loss on 100 batch: 0.289348
Train loss on 150 batch: 0.280874
best-train-loss: 0.283695
best-valid-loss: 0.309899
best-kappa: 0.8512
: Epoch: 31 | Training Loss: 0.283695 | Val. Loss: 0.309899 | Val. Kappa Score: 0.8512 | LR: 0.000125 | Estimated time: 58.47
Train loss on 50 batch: 0.261010
Train loss on 100 batch: 0.322416
Train loss on 150 batch: 0.252453
: Epoch: 32 | Training Loss: 0.274947 | Val. Loss: 0.325306 | Val. Kappa Score: 0.8522 | LR: 0.000125 | Estimated time: 57.17
Train loss on 50 batch: 0.281054
Train loss on 100 batch: 0.272534
Train loss on 150 batch: 0.257815
: Epoch: 33 | Training Loss: 0.280908 | Val. Loss: 0.319030 | Val. Kappa Score: 0.8531 | LR: 0.000125 | Estimated time: 57.51
Train loss on 50 batch: 0.260360
Train loss on 100 batch: 0.284487
Train loss on 150 batch: 0.295417
: Epoch: 34 | Training Loss: 0.272041 | Val. Loss: 0.316898 | Val. Kappa Score: 0.8536 | LR: 0.000063 | Estimated time: 57.03
Train loss on 50 batch: 0.270084
Train loss on 100 batch: 0.295063
Train loss on 150 batch: 0.278898
: Epoch: 35 | Training Loss: 0.297100 | Val. Loss: 0.315141 | Val. Kappa Score: 0.8540 | LR: 0.000063 | Estimated time: 57.19
Train loss on 50 batch: 0.231428
Train loss on 100 batch: 0.280095
Train loss on 150 batch: 0.254683
best-train-loss: 0.271152
best-valid-loss: 0.307440
best-kappa: 0.8546
: Epoch: 36 | Training Loss: 0.271152 | Val. Loss: 0.307440 | Val. Kappa Score: 0.8546 | LR: 0.000063 | Estimated time: 56.81
Train loss on 50 batch: 0.276381
Train loss on 100 batch: 0.266016
Train loss on 150 batch: 0.266903
: Epoch: 37 | Training Loss: 0.290188 | Val. Loss: 0.308565 | Val. Kappa Score: 0.8549 | LR: 0.000063 | Estimated time: 56.70
Train loss on 50 batch: 0.251804
Train loss on 100 batch: 0.257966
Train loss on 150 batch: 0.277462
best-train-loss: 0.358956
best-valid-loss: 0.306781
best-kappa: 0.8556
: Epoch: 38 | Training Loss: 0.358956 | Val. Loss: 0.306781 | Val. Kappa Score: 0.8556 | LR: 0.000063 | Estimated time: 56.97
Train loss on 50 batch: 0.288485
Train loss on 100 batch: 0.242556
Train loss on 150 batch: 0.275759
: Epoch: 39 | Training Loss: 0.293103 | Val. Loss: 0.306881 | Val. Kappa Score: 0.8559 | LR: 0.000063 | Estimated time: 57.76
Train loss on 50 batch: 0.275348
Train loss on 100 batch: 0.259615
Train loss on 150 batch: 0.287378
: Epoch: 40 | Training Loss: 0.282965 | Val. Loss: 0.306914 | Val. Kappa Score: 0.8564 | LR: 0.000063 | Estimated time: 58.03
Train loss on 50 batch: 0.257191
Train loss on 100 batch: 0.285505
Train loss on 150 batch: 0.271707
: Epoch: 41 | Training Loss: 0.267968 | Val. Loss: 0.311245 | Val. Kappa Score: 0.8572 | LR: 0.000031 | Estimated time: 57.29
Train loss on 50 batch: 0.294432
Train loss on 100 batch: 0.240519
Train loss on 150 batch: 0.272600
: Epoch: 42 | Training Loss: 0.267910 | Val. Loss: 0.306834 | Val. Kappa Score: 0.8577 | LR: 0.000031 | Estimated time: 57.17
Train loss on 50 batch: 0.249718
Train loss on 100 batch: 0.270939
Train loss on 150 batch: 0.239702
best-train-loss: 0.267099
best-valid-loss: 0.303687
best-kappa: 0.8584
: Epoch: 43 | Training Loss: 0.267099 | Val. Loss: 0.303687 | Val. Kappa Score: 0.8584 | LR: 0.000031 | Estimated time: 56.21
Train loss on 50 batch: 0.253391
Train loss on 100 batch: 0.255109
Train loss on 150 batch: 0.296204
: Epoch: 44 | Training Loss: 0.259282 | Val. Loss: 0.307379 | Val. Kappa Score: 0.8588 | LR: 0.000031 | Estimated time: 56.98
Train loss on 50 batch: 0.274885
Train loss on 100 batch: 0.238912
Train loss on 150 batch: 0.286338
: Epoch: 45 | Training Loss: 0.261457 | Val. Loss: 0.305890 | Val. Kappa Score: 0.8595 | LR: 0.000031 | Estimated time: 57.01
Train loss on 50 batch: 0.276450
Train loss on 100 batch: 0.263494
Train loss on 150 batch: 0.269864
: Epoch: 46 | Training Loss: 0.284250 | Val. Loss: 0.306583 | Val. Kappa Score: 0.8599 | LR: 0.000016 | Estimated time: 57.24
Train loss on 50 batch: 0.291903
Train loss on 100 batch: 0.239227
Train loss on 150 batch: 0.250624
: Epoch: 47 | Training Loss: 0.272224 | Val. Loss: 0.307010 | Val. Kappa Score: 0.8604 | LR: 0.000016 | Estimated time: 56.95
Train loss on 50 batch: 0.251071
Train loss on 100 batch: 0.275568
Train loss on 150 batch: 0.255264
: Epoch: 48 | Training Loss: 0.267881 | Val. Loss: 0.306189 | Val. Kappa Score: 0.8607 | LR: 0.000016 | Estimated time: 57.36
Train loss on 50 batch: 0.238912
Train loss on 100 batch: 0.288343
Train loss on 150 batch: 0.243653
: Epoch: 49 | Training Loss: 0.276952 | Val. Loss: 0.306166 | Val. Kappa Score: 0.8611 | LR: 0.000008 | Estimated time: 57.24
Train loss on 50 batch: 0.244847
Train loss on 100 batch: 0.261478
Train loss on 150 batch: 0.288669
: Epoch: 50 | Training Loss: 0.257487 | Val. Loss: 0.304698 | Val. Kappa Score: 0.8616 | LR: 0.000008 | Estimated time: 57.92
Train loss on 50 batch: 0.254704
Train loss on 100 batch: 0.317077
Train loss on 150 batch: 0.249453
: Epoch: 51 | Training Loss: 0.277462 | Val. Loss: 0.308043 | Val. Kappa Score: 0.8621 | LR: 0.000008 | Estimated time: 56.85
Train loss on 50 batch: 0.270808
Train loss on 100 batch: 0.258960
Train loss on 150 batch: 0.283923
: Epoch: 52 | Training Loss: 0.270749 | Val. Loss: 0.308923 | Val. Kappa Score: 0.8623 | LR: 0.000004 | Estimated time: 57.39
Train loss on 50 batch: 0.308777
Train loss on 100 batch: 0.236128
Train loss on 150 batch: 0.263577
: Epoch: 53 | Training Loss: 0.291103 | Val. Loss: 0.307501 | Val. Kappa Score: 0.8628 | LR: 0.000004 | Estimated time: 56.95
time_estimated: 3037.82
n-epochs: 53
time_estimated: 3037.87
----------------------------------------

Experiment N: 160: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.30 22:32:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f3e5c0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.508491
Train loss on 100 batch: 0.360112
Train loss on 150 batch: 0.388027
best-train-loss: 0.397615
best-valid-loss: 0.387942
best-kappa: 0.8638
: Epoch: 1 | Training Loss: 0.397615 | Val. Loss: 0.387942 | Val. Kappa Score: 0.8638 | LR: 0.001000 | Estimated time: 70.47
Train loss on 50 batch: 0.310000
Train loss on 100 batch: 0.344806
Train loss on 150 batch: 0.280530
best-train-loss: 0.341408
best-valid-loss: 0.339125
best-kappa: 0.8666
: Epoch: 2 | Training Loss: 0.341408 | Val. Loss: 0.339125 | Val. Kappa Score: 0.8666 | LR: 0.001000 | Estimated time: 70.04
Train loss on 50 batch: 0.330134
Train loss on 100 batch: 0.301625
Train loss on 150 batch: 0.312627
best-train-loss: 0.302103
best-valid-loss: 0.333899
best-kappa: 0.8680
: Epoch: 3 | Training Loss: 0.302103 | Val. Loss: 0.333899 | Val. Kappa Score: 0.8680 | LR: 0.001000 | Estimated time: 69.91
Train loss on 50 batch: 0.340022
Train loss on 100 batch: 0.325260
Train loss on 150 batch: 0.290864
: Epoch: 4 | Training Loss: 0.384624 | Val. Loss: 0.396011 | Val. Kappa Score: 0.8650 | LR: 0.001000 | Estimated time: 69.65
Train loss on 50 batch: 0.348556
Train loss on 100 batch: 0.362903
Train loss on 150 batch: 0.267094
: Epoch: 5 | Training Loss: 0.326268 | Val. Loss: 0.357249 | Val. Kappa Score: 0.8650 | LR: 0.001000 | Estimated time: 69.64
Train loss on 50 batch: 0.306911
Train loss on 100 batch: 0.321481
Train loss on 150 batch: 0.263875
: Epoch: 6 | Training Loss: 0.280486 | Val. Loss: 0.454233 | Val. Kappa Score: 0.8578 | LR: 0.000500 | Estimated time: 69.92
Train loss on 50 batch: 0.280239
Train loss on 100 batch: 0.253872
Train loss on 150 batch: 0.248866
best-train-loss: 0.260508
best-valid-loss: 0.315693
best-kappa: 0.8608
: Epoch: 7 | Training Loss: 0.260508 | Val. Loss: 0.315693 | Val. Kappa Score: 0.8608 | LR: 0.000500 | Estimated time: 70.05
Train loss on 50 batch: 0.223714
Train loss on 100 batch: 0.285031
Train loss on 150 batch: 0.220636
: Epoch: 8 | Training Loss: 0.264610 | Val. Loss: 0.341267 | Val. Kappa Score: 0.8628 | LR: 0.000500 | Estimated time: 69.77
Train loss on 50 batch: 0.247196
Train loss on 100 batch: 0.287688
Train loss on 150 batch: 0.237368
best-train-loss: 0.263291
best-valid-loss: 0.298566
best-kappa: 0.8650
: Epoch: 9 | Training Loss: 0.263291 | Val. Loss: 0.298566 | Val. Kappa Score: 0.8650 | LR: 0.000500 | Estimated time: 70.39
Train loss on 50 batch: 0.229288
Train loss on 100 batch: 0.249875
Train loss on 150 batch: 0.258114
: Epoch: 10 | Training Loss: 0.308603 | Val. Loss: 0.330820 | Val. Kappa Score: 0.8650 | LR: 0.000500 | Estimated time: 69.60
Train loss on 50 batch: 0.257432
Train loss on 100 batch: 0.273438
Train loss on 150 batch: 0.250509
: Epoch: 11 | Training Loss: 0.266271 | Val. Loss: 0.327352 | Val. Kappa Score: 0.8665 | LR: 0.000500 | Estimated time: 71.17
Train loss on 50 batch: 0.217768
Train loss on 100 batch: 0.225660
Train loss on 150 batch: 0.242959
: Epoch: 12 | Training Loss: 0.231582 | Val. Loss: 0.363535 | Val. Kappa Score: 0.8668 | LR: 0.000250 | Estimated time: 71.12
Train loss on 50 batch: 0.231914
Train loss on 100 batch: 0.251116
Train loss on 150 batch: 0.198611
best-train-loss: 0.229699
best-valid-loss: 0.288540
best-kappa: 0.8687
: Epoch: 13 | Training Loss: 0.229699 | Val. Loss: 0.288540 | Val. Kappa Score: 0.8687 | LR: 0.000250 | Estimated time: 70.82
Train loss on 50 batch: 0.207323
Train loss on 100 batch: 0.201212
Train loss on 150 batch: 0.230298
best-train-loss: 0.215580
best-valid-loss: 0.279381
best-kappa: 0.8694
: Epoch: 14 | Training Loss: 0.215580 | Val. Loss: 0.279381 | Val. Kappa Score: 0.8694 | LR: 0.000250 | Estimated time: 70.96
Train loss on 50 batch: 0.228864
Train loss on 100 batch: 0.221763
Train loss on 150 batch: 0.216313
: Epoch: 15 | Training Loss: 0.218925 | Val. Loss: 0.354032 | Val. Kappa Score: 0.8703 | LR: 0.000250 | Estimated time: 70.38
Train loss on 50 batch: 0.217454
Train loss on 100 batch: 0.191326
Train loss on 150 batch: 0.213354
: Epoch: 16 | Training Loss: 0.210900 | Val. Loss: 0.324624 | Val. Kappa Score: 0.8708 | LR: 0.000250 | Estimated time: 70.63
Train loss on 50 batch: 0.233697
Train loss on 100 batch: 0.220094
Train loss on 150 batch: 0.173124
: Epoch: 17 | Training Loss: 0.205174 | Val. Loss: 0.288832 | Val. Kappa Score: 0.8715 | LR: 0.000125 | Estimated time: 70.42
Train loss on 50 batch: 0.200934
Train loss on 100 batch: 0.163692
Train loss on 150 batch: 0.221533
: Epoch: 18 | Training Loss: 0.200233 | Val. Loss: 0.281443 | Val. Kappa Score: 0.8724 | LR: 0.000125 | Estimated time: 70.55
Train loss on 50 batch: 0.189494
Train loss on 100 batch: 0.178057
Train loss on 150 batch: 0.196480
: Epoch: 19 | Training Loss: 0.206602 | Val. Loss: 0.280833 | Val. Kappa Score: 0.8736 | LR: 0.000125 | Estimated time: 71.60
Train loss on 50 batch: 0.188943
Train loss on 100 batch: 0.226451
Train loss on 150 batch: 0.173890
: Epoch: 20 | Training Loss: 0.191468 | Val. Loss: 0.285745 | Val. Kappa Score: 0.8741 | LR: 0.000063 | Estimated time: 70.88
Train loss on 50 batch: 0.200311
Train loss on 100 batch: 0.199155
Train loss on 150 batch: 0.194710
: Epoch: 21 | Training Loss: 0.223462 | Val. Loss: 0.283764 | Val. Kappa Score: 0.8749 | LR: 0.000063 | Estimated time: 69.92
Train loss on 50 batch: 0.193036
Train loss on 100 batch: 0.201361
Train loss on 150 batch: 0.208509
: Epoch: 22 | Training Loss: 0.197399 | Val. Loss: 0.283658 | Val. Kappa Score: 0.8758 | LR: 0.000063 | Estimated time: 70.58
Train loss on 50 batch: 0.207167
Train loss on 100 batch: 0.194444
Train loss on 150 batch: 0.187188
: Epoch: 23 | Training Loss: 0.197952 | Val. Loss: 0.280109 | Val. Kappa Score: 0.8762 | LR: 0.000031 | Estimated time: 70.27
Train loss on 50 batch: 0.187065
Train loss on 100 batch: 0.193348
Train loss on 150 batch: 0.181167
: Epoch: 24 | Training Loss: 0.253751 | Val. Loss: 0.279552 | Val. Kappa Score: 0.8768 | LR: 0.000031 | Estimated time: 70.52
time_estimated: 1690.98
n-epochs: 24
time_estimated: 1691.04
----------------------------------------

Experiment N: 161: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.31 05:37:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f3f518>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.518505
Train loss on 100 batch: 0.409882
Train loss on 150 batch: 0.370715
best-train-loss: 0.404351
best-valid-loss: 0.405460
best-kappa: 0.8544
: Epoch: 1 | Training Loss: 0.404351 | Val. Loss: 0.405460 | Val. Kappa Score: 0.8544 | LR: 0.001000 | Estimated time: 70.62
Train loss on 50 batch: 0.358028
Train loss on 100 batch: 0.346044
Train loss on 150 batch: 0.308112
best-train-loss: 0.370735
best-valid-loss: 0.340830
best-kappa: 0.8631
: Epoch: 2 | Training Loss: 0.370735 | Val. Loss: 0.340830 | Val. Kappa Score: 0.8631 | LR: 0.001000 | Estimated time: 69.46
Train loss on 50 batch: 0.329481
Train loss on 100 batch: 0.350965
Train loss on 150 batch: 0.334896
best-train-loss: 0.329613
best-valid-loss: 0.329778
best-kappa: 0.8649
: Epoch: 3 | Training Loss: 0.329613 | Val. Loss: 0.329778 | Val. Kappa Score: 0.8649 | LR: 0.001000 | Estimated time: 69.85
Train loss on 50 batch: 0.354855
Train loss on 100 batch: 0.343670
Train loss on 150 batch: 0.304898
: Epoch: 4 | Training Loss: 0.392458 | Val. Loss: 0.377454 | Val. Kappa Score: 0.8637 | LR: 0.001000 | Estimated time: 69.28
Train loss on 50 batch: 0.374409
Train loss on 100 batch: 0.377319
Train loss on 150 batch: 0.271608
: Epoch: 5 | Training Loss: 0.339118 | Val. Loss: 0.411270 | Val. Kappa Score: 0.8619 | LR: 0.001000 | Estimated time: 69.87
Train loss on 50 batch: 0.320198
Train loss on 100 batch: 0.287264
Train loss on 150 batch: 0.283902
: Epoch: 6 | Training Loss: 0.277461 | Val. Loss: 0.382265 | Val. Kappa Score: 0.8595 | LR: 0.000500 | Estimated time: 69.96
Train loss on 50 batch: 0.289668
Train loss on 100 batch: 0.278254
Train loss on 150 batch: 0.250273
best-train-loss: 0.273911
best-valid-loss: 0.291287
best-kappa: 0.8644
: Epoch: 7 | Training Loss: 0.273911 | Val. Loss: 0.291287 | Val. Kappa Score: 0.8644 | LR: 0.000500 | Estimated time: 70.06
Train loss on 50 batch: 0.245302
Train loss on 100 batch: 0.289438
Train loss on 150 batch: 0.224472
: Epoch: 8 | Training Loss: 0.272375 | Val. Loss: 0.321686 | Val. Kappa Score: 0.8663 | LR: 0.000500 | Estimated time: 69.12
Train loss on 50 batch: 0.259178
Train loss on 100 batch: 0.288361
Train loss on 150 batch: 0.254095
: Epoch: 9 | Training Loss: 0.270243 | Val. Loss: 0.307222 | Val. Kappa Score: 0.8680 | LR: 0.000500 | Estimated time: 70.01
Train loss on 50 batch: 0.253700
Train loss on 100 batch: 0.263653
Train loss on 150 batch: 0.279320
: Epoch: 10 | Training Loss: 0.325237 | Val. Loss: 0.299613 | Val. Kappa Score: 0.8686 | LR: 0.000250 | Estimated time: 70.32
Train loss on 50 batch: 0.259119
Train loss on 100 batch: 0.247943
Train loss on 150 batch: 0.227010
: Epoch: 11 | Training Loss: 0.250885 | Val. Loss: 0.294286 | Val. Kappa Score: 0.8697 | LR: 0.000250 | Estimated time: 69.84
Train loss on 50 batch: 0.234870
Train loss on 100 batch: 0.200011
Train loss on 150 batch: 0.254122
: Epoch: 12 | Training Loss: 0.225314 | Val. Loss: 0.301588 | Val. Kappa Score: 0.8707 | LR: 0.000250 | Estimated time: 70.06
Train loss on 50 batch: 0.211530
Train loss on 100 batch: 0.287304
Train loss on 150 batch: 0.221666
: Epoch: 13 | Training Loss: 0.244296 | Val. Loss: 0.301609 | Val. Kappa Score: 0.8720 | LR: 0.000125 | Estimated time: 70.23
Train loss on 50 batch: 0.210762
Train loss on 100 batch: 0.210092
Train loss on 150 batch: 0.223938
best-train-loss: 0.211811
best-valid-loss: 0.286808
best-kappa: 0.8720
: Epoch: 14 | Training Loss: 0.211811 | Val. Loss: 0.286808 | Val. Kappa Score: 0.8720 | LR: 0.000125 | Estimated time: 70.07
Train loss on 50 batch: 0.220941
Train loss on 100 batch: 0.200767
Train loss on 150 batch: 0.234710
best-train-loss: 0.225187
best-valid-loss: 0.285344
best-kappa: 0.8731
: Epoch: 15 | Training Loss: 0.225187 | Val. Loss: 0.285344 | Val. Kappa Score: 0.8731 | LR: 0.000125 | Estimated time: 69.42
Train loss on 50 batch: 0.207311
Train loss on 100 batch: 0.180313
Train loss on 150 batch: 0.213008
best-train-loss: 0.207343
best-valid-loss: 0.284706
best-kappa: 0.8739
: Epoch: 16 | Training Loss: 0.207343 | Val. Loss: 0.284706 | Val. Kappa Score: 0.8739 | LR: 0.000125 | Estimated time: 69.62
Train loss on 50 batch: 0.250982
Train loss on 100 batch: 0.231027
Train loss on 150 batch: 0.187437
: Epoch: 17 | Training Loss: 0.218308 | Val. Loss: 0.286666 | Val. Kappa Score: 0.8748 | LR: 0.000125 | Estimated time: 69.76
Train loss on 50 batch: 0.211297
Train loss on 100 batch: 0.191459
Train loss on 150 batch: 0.228872
: Epoch: 18 | Training Loss: 0.215074 | Val. Loss: 0.284831 | Val. Kappa Score: 0.8753 | LR: 0.000125 | Estimated time: 69.36
Train loss on 50 batch: 0.175675
Train loss on 100 batch: 0.214089
Train loss on 150 batch: 0.216878
: Epoch: 19 | Training Loss: 0.209609 | Val. Loss: 0.286188 | Val. Kappa Score: 0.8755 | LR: 0.000063 | Estimated time: 70.29
Train loss on 50 batch: 0.201552
Train loss on 100 batch: 0.228176
Train loss on 150 batch: 0.196692
best-train-loss: 0.209843
best-valid-loss: 0.283854
best-kappa: 0.8758
: Epoch: 20 | Training Loss: 0.209843 | Val. Loss: 0.283854 | Val. Kappa Score: 0.8758 | LR: 0.000063 | Estimated time: 70.33
Train loss on 50 batch: 0.200764
Train loss on 100 batch: 0.197773
Train loss on 150 batch: 0.201156
: Epoch: 21 | Training Loss: 0.223575 | Val. Loss: 0.284461 | Val. Kappa Score: 0.8762 | LR: 0.000063 | Estimated time: 69.39
Train loss on 50 batch: 0.204644
Train loss on 100 batch: 0.196627
Train loss on 150 batch: 0.194738
best-train-loss: 0.194165
best-valid-loss: 0.281357
best-kappa: 0.8765
: Epoch: 22 | Training Loss: 0.194165 | Val. Loss: 0.281357 | Val. Kappa Score: 0.8765 | LR: 0.000063 | Estimated time: 69.82
Train loss on 50 batch: 0.204508
Train loss on 100 batch: 0.207038
Train loss on 150 batch: 0.216151
: Epoch: 23 | Training Loss: 0.217144 | Val. Loss: 0.282236 | Val. Kappa Score: 0.8769 | LR: 0.000063 | Estimated time: 69.47
Train loss on 50 batch: 0.219915
Train loss on 100 batch: 0.195081
Train loss on 150 batch: 0.197104
: Epoch: 24 | Training Loss: 0.276553 | Val. Loss: 0.284402 | Val. Kappa Score: 0.8773 | LR: 0.000063 | Estimated time: 69.98
Train loss on 50 batch: 0.189517
Train loss on 100 batch: 0.192809
Train loss on 150 batch: 0.225936
best-train-loss: 0.205392
best-valid-loss: 0.281112
best-kappa: 0.8776
: Epoch: 25 | Training Loss: 0.205392 | Val. Loss: 0.281112 | Val. Kappa Score: 0.8776 | LR: 0.000063 | Estimated time: 69.34
Train loss on 50 batch: 0.195401
Train loss on 100 batch: 0.182891
Train loss on 150 batch: 0.209219
: Epoch: 26 | Training Loss: 0.230652 | Val. Loss: 0.283117 | Val. Kappa Score: 0.8779 | LR: 0.000063 | Estimated time: 69.83
Train loss on 50 batch: 0.224251
Train loss on 100 batch: 0.229298
Train loss on 150 batch: 0.187011
best-train-loss: 0.209685
best-valid-loss: 0.277106
best-kappa: 0.8782
: Epoch: 27 | Training Loss: 0.209685 | Val. Loss: 0.277106 | Val. Kappa Score: 0.8782 | LR: 0.000063 | Estimated time: 69.76
Train loss on 50 batch: 0.232307
Train loss on 100 batch: 0.174933
Train loss on 150 batch: 0.183206
best-train-loss: 0.211875
best-valid-loss: 0.276826
best-kappa: 0.8783
: Epoch: 28 | Training Loss: 0.211875 | Val. Loss: 0.276826 | Val. Kappa Score: 0.8783 | LR: 0.000063 | Estimated time: 68.79
Train loss on 50 batch: 0.151513
Train loss on 100 batch: 0.220950
Train loss on 150 batch: 0.208418
: Epoch: 29 | Training Loss: 0.209032 | Val. Loss: 0.279946 | Val. Kappa Score: 0.8785 | LR: 0.000063 | Estimated time: 69.53
Train loss on 50 batch: 0.209284
Train loss on 100 batch: 0.211368
Train loss on 150 batch: 0.201839
: Epoch: 30 | Training Loss: 0.220892 | Val. Loss: 0.279279 | Val. Kappa Score: 0.8788 | LR: 0.000063 | Estimated time: 70.36
Train loss on 50 batch: 0.175919
Train loss on 100 batch: 0.200036
Train loss on 150 batch: 0.174026
: Epoch: 31 | Training Loss: 0.197531 | Val. Loss: 0.281247 | Val. Kappa Score: 0.8789 | LR: 0.000031 | Estimated time: 69.81
Train loss on 50 batch: 0.207167
Train loss on 100 batch: 0.223236
Train loss on 150 batch: 0.175910
: Epoch: 32 | Training Loss: 0.193662 | Val. Loss: 0.281555 | Val. Kappa Score: 0.8787 | LR: 0.000031 | Estimated time: 70.09
Train loss on 50 batch: 0.201583
Train loss on 100 batch: 0.188845
Train loss on 150 batch: 0.169984
: Epoch: 33 | Training Loss: 0.194771 | Val. Loss: 0.282176 | Val. Kappa Score: 0.8791 | LR: 0.000031 | Estimated time: 70.15
Train loss on 50 batch: 0.185121
Train loss on 100 batch: 0.199741
Train loss on 150 batch: 0.203167
: Epoch: 34 | Training Loss: 0.193907 | Val. Loss: 0.281487 | Val. Kappa Score: 0.8791 | LR: 0.000016 | Estimated time: 69.59
Train loss on 50 batch: 0.179146
Train loss on 100 batch: 0.188867
Train loss on 150 batch: 0.198648
: Epoch: 35 | Training Loss: 0.211713 | Val. Loss: 0.279560 | Val. Kappa Score: 0.8790 | LR: 0.000016 | Estimated time: 69.82
Train loss on 50 batch: 0.176924
Train loss on 100 batch: 0.204588
Train loss on 150 batch: 0.188602
: Epoch: 36 | Training Loss: 0.203728 | Val. Loss: 0.282606 | Val. Kappa Score: 0.8790 | LR: 0.000016 | Estimated time: 69.26
Train loss on 50 batch: 0.188950
Train loss on 100 batch: 0.185641
Train loss on 150 batch: 0.187856
: Epoch: 37 | Training Loss: 0.200880 | Val. Loss: 0.279944 | Val. Kappa Score: 0.8789 | LR: 0.000008 | Estimated time: 69.25
Train loss on 50 batch: 0.177315
Train loss on 100 batch: 0.179359
Train loss on 150 batch: 0.189539
: Epoch: 38 | Training Loss: 0.249192 | Val. Loss: 0.279884 | Val. Kappa Score: 0.8793 | LR: 0.000008 | Estimated time: 69.72
time_estimated: 2654.32
n-epochs: 38
time_estimated: 2654.37
----------------------------------------

Experiment N: 162: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.08.31 12:29:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f3c5f8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.475989
Train loss on 100 batch: 0.390523
Train loss on 150 batch: 0.339488
best-train-loss: 0.383739
best-valid-loss: 0.392248
best-kappa: 0.8697
: Epoch: 1 | Training Loss: 0.383739 | Val. Loss: 0.392248 | Val. Kappa Score: 0.8697 | LR: 0.001000 | Estimated time: 70.02
Train loss on 50 batch: 0.303421
Train loss on 100 batch: 0.304463
Train loss on 150 batch: 0.268641
: Epoch: 2 | Training Loss: 0.328673 | Val. Loss: 0.441039 | Val. Kappa Score: 0.8615 | LR: 0.001000 | Estimated time: 69.96
Train loss on 50 batch: 0.316255
Train loss on 100 batch: 0.321946
Train loss on 150 batch: 0.301954
best-train-loss: 0.306079
best-valid-loss: 0.350593
best-kappa: 0.8657
: Epoch: 3 | Training Loss: 0.306079 | Val. Loss: 0.350593 | Val. Kappa Score: 0.8657 | LR: 0.001000 | Estimated time: 74.03
Train loss on 50 batch: 0.305928
Train loss on 100 batch: 0.303957
Train loss on 150 batch: 0.295005
: Epoch: 4 | Training Loss: 0.364686 | Val. Loss: 0.357997 | Val. Kappa Score: 0.8669 | LR: 0.001000 | Estimated time: 70.69
Train loss on 50 batch: 0.341864
Train loss on 100 batch: 0.343149
Train loss on 150 batch: 0.264044
best-train-loss: 0.321765
best-valid-loss: 0.336523
best-kappa: 0.8720
: Epoch: 5 | Training Loss: 0.321765 | Val. Loss: 0.336523 | Val. Kappa Score: 0.8720 | LR: 0.001000 | Estimated time: 71.29
Train loss on 50 batch: 0.288976
Train loss on 100 batch: 0.295500
Train loss on 150 batch: 0.282169
: Epoch: 6 | Training Loss: 0.268890 | Val. Loss: 0.452358 | Val. Kappa Score: 0.8640 | LR: 0.001000 | Estimated time: 71.11
Train loss on 50 batch: 0.273980
Train loss on 100 batch: 0.261889
Train loss on 150 batch: 0.240714
: Epoch: 7 | Training Loss: 0.266626 | Val. Loss: 0.361471 | Val. Kappa Score: 0.8663 | LR: 0.001000 | Estimated time: 72.72
Train loss on 50 batch: 0.249250
Train loss on 100 batch: 0.262350
Train loss on 150 batch: 0.226862
best-train-loss: 0.263206
best-valid-loss: 0.297449
best-kappa: 0.8692
: Epoch: 8 | Training Loss: 0.263206 | Val. Loss: 0.297449 | Val. Kappa Score: 0.8692 | LR: 0.001000 | Estimated time: 71.23
Train loss on 50 batch: 0.270542
Train loss on 100 batch: 0.285631
Train loss on 150 batch: 0.260111
: Epoch: 9 | Training Loss: 0.265821 | Val. Loss: 0.315876 | Val. Kappa Score: 0.8714 | LR: 0.001000 | Estimated time: 74.72
Train loss on 50 batch: 0.241714
Train loss on 100 batch: 0.249219
Train loss on 150 batch: 0.254682
: Epoch: 10 | Training Loss: 0.306522 | Val. Loss: 0.350313 | Val. Kappa Score: 0.8715 | LR: 0.001000 | Estimated time: 72.96
Train loss on 50 batch: 0.261913
Train loss on 100 batch: 0.259973
Train loss on 150 batch: 0.242513
: Epoch: 11 | Training Loss: 0.264420 | Val. Loss: 0.314838 | Val. Kappa Score: 0.8718 | LR: 0.000500 | Estimated time: 69.88
Train loss on 50 batch: 0.219889
Train loss on 100 batch: 0.209643
Train loss on 150 batch: 0.231838
: Epoch: 12 | Training Loss: 0.221716 | Val. Loss: 0.297862 | Val. Kappa Score: 0.8723 | LR: 0.000500 | Estimated time: 69.69
Train loss on 50 batch: 0.205831
Train loss on 100 batch: 0.247039
Train loss on 150 batch: 0.206854
: Epoch: 13 | Training Loss: 0.217871 | Val. Loss: 0.300100 | Val. Kappa Score: 0.8740 | LR: 0.000500 | Estimated time: 70.03
Train loss on 50 batch: 0.204291
Train loss on 100 batch: 0.221210
Train loss on 150 batch: 0.218843
best-train-loss: 0.219515
best-valid-loss: 0.271584
best-kappa: 0.8756
: Epoch: 14 | Training Loss: 0.219515 | Val. Loss: 0.271584 | Val. Kappa Score: 0.8756 | LR: 0.000500 | Estimated time: 69.70
Train loss on 50 batch: 0.223016
Train loss on 100 batch: 0.193435
Train loss on 150 batch: 0.208639
: Epoch: 15 | Training Loss: 0.205892 | Val. Loss: 0.279707 | Val. Kappa Score: 0.8769 | LR: 0.000500 | Estimated time: 68.96
Train loss on 50 batch: 0.216270
Train loss on 100 batch: 0.180852
Train loss on 150 batch: 0.219053
: Epoch: 16 | Training Loss: 0.207267 | Val. Loss: 0.277539 | Val. Kappa Score: 0.8774 | LR: 0.000500 | Estimated time: 70.12
Train loss on 50 batch: 0.219152
Train loss on 100 batch: 0.212702
Train loss on 150 batch: 0.183646
: Epoch: 17 | Training Loss: 0.204688 | Val. Loss: 0.281613 | Val. Kappa Score: 0.8784 | LR: 0.000250 | Estimated time: 70.74
Train loss on 50 batch: 0.189039
Train loss on 100 batch: 0.166982
Train loss on 150 batch: 0.207703
: Epoch: 18 | Training Loss: 0.191370 | Val. Loss: 0.275516 | Val. Kappa Score: 0.8794 | LR: 0.000250 | Estimated time: 70.98
Train loss on 50 batch: 0.165847
Train loss on 100 batch: 0.186106
Train loss on 150 batch: 0.179316
: Epoch: 19 | Training Loss: 0.192084 | Val. Loss: 0.292432 | Val. Kappa Score: 0.8801 | LR: 0.000250 | Estimated time: 73.28
Train loss on 50 batch: 0.190646
Train loss on 100 batch: 0.202443
Train loss on 150 batch: 0.165721
best-train-loss: 0.183696
best-valid-loss: 0.264644
best-kappa: 0.8806
: Epoch: 20 | Training Loss: 0.183696 | Val. Loss: 0.264644 | Val. Kappa Score: 0.8806 | LR: 0.000250 | Estimated time: 73.02
Train loss on 50 batch: 0.181671
Train loss on 100 batch: 0.164994
Train loss on 150 batch: 0.181987
: Epoch: 21 | Training Loss: 0.206208 | Val. Loss: 0.284580 | Val. Kappa Score: 0.8809 | LR: 0.000250 | Estimated time: 72.02
Train loss on 50 batch: 0.181764
Train loss on 100 batch: 0.183825
Train loss on 150 batch: 0.181478
best-train-loss: 0.186254
best-valid-loss: 0.260374
best-kappa: 0.8818
: Epoch: 22 | Training Loss: 0.186254 | Val. Loss: 0.260374 | Val. Kappa Score: 0.8818 | LR: 0.000250 | Estimated time: 72.84
Train loss on 50 batch: 0.175902
Train loss on 100 batch: 0.170149
Train loss on 150 batch: 0.165206
: Epoch: 23 | Training Loss: 0.167138 | Val. Loss: 0.272413 | Val. Kappa Score: 0.8826 | LR: 0.000250 | Estimated time: 72.42
Train loss on 50 batch: 0.171894
Train loss on 100 batch: 0.157578
Train loss on 150 batch: 0.162675
: Epoch: 24 | Training Loss: 0.232256 | Val. Loss: 0.302081 | Val. Kappa Score: 0.8823 | LR: 0.000250 | Estimated time: 74.06
Train loss on 50 batch: 0.173496
Train loss on 100 batch: 0.188001
Train loss on 150 batch: 0.191149
: Epoch: 25 | Training Loss: 0.187415 | Val. Loss: 0.267411 | Val. Kappa Score: 0.8828 | LR: 0.000125 | Estimated time: 74.56
Train loss on 50 batch: 0.183898
Train loss on 100 batch: 0.142202
Train loss on 150 batch: 0.158949
: Epoch: 26 | Training Loss: 0.182435 | Val. Loss: 0.263278 | Val. Kappa Score: 0.8832 | LR: 0.000125 | Estimated time: 74.61
Train loss on 50 batch: 0.167210
Train loss on 100 batch: 0.187438
Train loss on 150 batch: 0.148880
best-train-loss: 0.162131
best-valid-loss: 0.259979
best-kappa: 0.8836
: Epoch: 27 | Training Loss: 0.162131 | Val. Loss: 0.259979 | Val. Kappa Score: 0.8836 | LR: 0.000125 | Estimated time: 74.59
Train loss on 50 batch: 0.192321
Train loss on 100 batch: 0.151633
Train loss on 150 batch: 0.148419
best-train-loss: 0.163355
best-valid-loss: 0.259351
best-kappa: 0.8832
: Epoch: 28 | Training Loss: 0.163355 | Val. Loss: 0.259351 | Val. Kappa Score: 0.8832 | LR: 0.000125 | Estimated time: 73.81
Train loss on 50 batch: 0.136888
Train loss on 100 batch: 0.161147
Train loss on 150 batch: 0.149396
: Epoch: 29 | Training Loss: 0.152759 | Val. Loss: 0.269056 | Val. Kappa Score: 0.8832 | LR: 0.000125 | Estimated time: 74.37
Train loss on 50 batch: 0.160763
Train loss on 100 batch: 0.163980
Train loss on 150 batch: 0.164430
: Epoch: 30 | Training Loss: 0.163347 | Val. Loss: 0.262390 | Val. Kappa Score: 0.8832 | LR: 0.000125 | Estimated time: 75.37
Train loss on 50 batch: 0.141776
Train loss on 100 batch: 0.178419
Train loss on 150 batch: 0.150569
: Epoch: 31 | Training Loss: 0.167207 | Val. Loss: 0.265931 | Val. Kappa Score: 0.8835 | LR: 0.000063 | Estimated time: 74.50
Train loss on 50 batch: 0.150415
Train loss on 100 batch: 0.170864
Train loss on 150 batch: 0.141664
: Epoch: 32 | Training Loss: 0.154784 | Val. Loss: 0.263110 | Val. Kappa Score: 0.8834 | LR: 0.000063 | Estimated time: 74.20
Train loss on 50 batch: 0.163258
Train loss on 100 batch: 0.160063
Train loss on 150 batch: 0.125909
: Epoch: 33 | Training Loss: 0.153361 | Val. Loss: 0.262854 | Val. Kappa Score: 0.8840 | LR: 0.000063 | Estimated time: 70.35
Train loss on 50 batch: 0.145758
Train loss on 100 batch: 0.154113
Train loss on 150 batch: 0.166227
: Epoch: 34 | Training Loss: 0.154769 | Val. Loss: 0.261347 | Val. Kappa Score: 0.8839 | LR: 0.000031 | Estimated time: 70.05
Train loss on 50 batch: 0.132980
Train loss on 100 batch: 0.167256
Train loss on 150 batch: 0.151361
: Epoch: 35 | Training Loss: 0.167607 | Val. Loss: 0.260278 | Val. Kappa Score: 0.8838 | LR: 0.000031 | Estimated time: 69.94
Train loss on 50 batch: 0.124337
Train loss on 100 batch: 0.154261
Train loss on 150 batch: 0.144507
: Epoch: 36 | Training Loss: 0.149759 | Val. Loss: 0.262277 | Val. Kappa Score: 0.8838 | LR: 0.000031 | Estimated time: 69.83
Train loss on 50 batch: 0.143871
Train loss on 100 batch: 0.147013
Train loss on 150 batch: 0.151896
: Epoch: 37 | Training Loss: 0.154965 | Val. Loss: 0.262413 | Val. Kappa Score: 0.8839 | LR: 0.000016 | Estimated time: 70.84
Train loss on 50 batch: 0.134279
Train loss on 100 batch: 0.140548
Train loss on 150 batch: 0.158737
: Epoch: 38 | Training Loss: 0.178443 | Val. Loss: 0.264465 | Val. Kappa Score: 0.8840 | LR: 0.000016 | Estimated time: 71.11
time_estimated: 2737.39
n-epochs: 38
time_estimated: 2737.43
----------------------------------------

Experiment N: 163: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 17:28:02
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb95f04160>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.533912
Train loss on 100 batch: 0.399936
Train loss on 150 batch: 0.399654
best-train-loss: 0.415096
best-valid-loss: 0.392041
best-kappa: 0.8562
: Epoch: 1 | Training Loss: 0.415096 | Val. Loss: 0.392041 | Val. Kappa Score: 0.8562 | LR: 0.001000 | Estimated time: 70.13
Train loss on 50 batch: 0.327802
Train loss on 100 batch: 0.338426
Train loss on 150 batch: 0.303963
best-train-loss: 0.353578
best-valid-loss: 0.364388
best-kappa: 0.8626
: Epoch: 2 | Training Loss: 0.353578 | Val. Loss: 0.364388 | Val. Kappa Score: 0.8626 | LR: 0.001000 | Estimated time: 69.81
Train loss on 50 batch: 0.343398
Train loss on 100 batch: 0.371546
Train loss on 150 batch: 0.311036
best-train-loss: 0.332131
best-valid-loss: 0.348749
best-kappa: 0.8646
: Epoch: 3 | Training Loss: 0.332131 | Val. Loss: 0.348749 | Val. Kappa Score: 0.8646 | LR: 0.001000 | Estimated time: 69.90
Train loss on 50 batch: 0.307595
Train loss on 100 batch: 0.336034
Train loss on 150 batch: 0.320148
: Epoch: 4 | Training Loss: 0.404454 | Val. Loss: 0.369165 | Val. Kappa Score: 0.8662 | LR: 0.001000 | Estimated time: 69.71
Train loss on 50 batch: 0.366852
Train loss on 100 batch: 0.395708
Train loss on 150 batch: 0.283939
: Epoch: 5 | Training Loss: 0.345155 | Val. Loss: 0.351598 | Val. Kappa Score: 0.8650 | LR: 0.001000 | Estimated time: 70.64
Train loss on 50 batch: 0.296335
Train loss on 100 batch: 0.311927
Train loss on 150 batch: 0.309034
: Epoch: 6 | Training Loss: 0.289864 | Val. Loss: 0.401975 | Val. Kappa Score: 0.8626 | LR: 0.000500 | Estimated time: 70.04
Train loss on 50 batch: 0.290640
Train loss on 100 batch: 0.256375
Train loss on 150 batch: 0.255945
best-train-loss: 0.262329
best-valid-loss: 0.315972
best-kappa: 0.8655
: Epoch: 7 | Training Loss: 0.262329 | Val. Loss: 0.315972 | Val. Kappa Score: 0.8655 | LR: 0.000500 | Estimated time: 70.03
Train loss on 50 batch: 0.236834
Train loss on 100 batch: 0.286466
Train loss on 150 batch: 0.227267
best-train-loss: 0.270913
best-valid-loss: 0.304687
best-kappa: 0.8678
: Epoch: 8 | Training Loss: 0.270913 | Val. Loss: 0.304687 | Val. Kappa Score: 0.8678 | LR: 0.000500 | Estimated time: 69.32
Train loss on 50 batch: 0.246344
Train loss on 100 batch: 0.266897
Train loss on 150 batch: 0.264786
: Epoch: 9 | Training Loss: 0.259877 | Val. Loss: 0.318502 | Val. Kappa Score: 0.8692 | LR: 0.000500 | Estimated time: 70.12
Train loss on 50 batch: 0.240684
Train loss on 100 batch: 0.272248
Train loss on 150 batch: 0.257030
: Epoch: 10 | Training Loss: 0.318747 | Val. Loss: 0.322642 | Val. Kappa Score: 0.8699 | LR: 0.000500 | Estimated time: 70.19
Train loss on 50 batch: 0.250615
Train loss on 100 batch: 0.245091
Train loss on 150 batch: 0.230411
: Epoch: 11 | Training Loss: 0.242408 | Val. Loss: 0.316355 | Val. Kappa Score: 0.8700 | LR: 0.000250 | Estimated time: 69.84
Train loss on 50 batch: 0.241611
Train loss on 100 batch: 0.216994
Train loss on 150 batch: 0.258788
: Epoch: 12 | Training Loss: 0.235280 | Val. Loss: 0.311427 | Val. Kappa Score: 0.8704 | LR: 0.000250 | Estimated time: 70.56
Train loss on 50 batch: 0.204089
Train loss on 100 batch: 0.264679
Train loss on 150 batch: 0.216718
: Epoch: 13 | Training Loss: 0.234367 | Val. Loss: 0.314570 | Val. Kappa Score: 0.8715 | LR: 0.000250 | Estimated time: 70.35
Train loss on 50 batch: 0.213212
Train loss on 100 batch: 0.215656
Train loss on 150 batch: 0.226929
best-train-loss: 0.223222
best-valid-loss: 0.295934
best-kappa: 0.8722
: Epoch: 14 | Training Loss: 0.223222 | Val. Loss: 0.295934 | Val. Kappa Score: 0.8722 | LR: 0.000250 | Estimated time: 70.19
Train loss on 50 batch: 0.227728
Train loss on 100 batch: 0.222492
Train loss on 150 batch: 0.224821
: Epoch: 15 | Training Loss: 0.226428 | Val. Loss: 0.298424 | Val. Kappa Score: 0.8728 | LR: 0.000250 | Estimated time: 69.90
Train loss on 50 batch: 0.199453
Train loss on 100 batch: 0.204621
Train loss on 150 batch: 0.200091
: Epoch: 16 | Training Loss: 0.207267 | Val. Loss: 0.297214 | Val. Kappa Score: 0.8734 | LR: 0.000250 | Estimated time: 69.64
Train loss on 50 batch: 0.248643
Train loss on 100 batch: 0.206439
Train loss on 150 batch: 0.180554
: Epoch: 17 | Training Loss: 0.211568 | Val. Loss: 0.296915 | Val. Kappa Score: 0.8743 | LR: 0.000125 | Estimated time: 69.95
Train loss on 50 batch: 0.214650
Train loss on 100 batch: 0.176486
Train loss on 150 batch: 0.215552
best-train-loss: 0.206358
best-valid-loss: 0.294592
best-kappa: 0.8750
: Epoch: 18 | Training Loss: 0.206358 | Val. Loss: 0.294592 | Val. Kappa Score: 0.8750 | LR: 0.000125 | Estimated time: 68.92
Train loss on 50 batch: 0.180289
Train loss on 100 batch: 0.215689
Train loss on 150 batch: 0.197534
best-train-loss: 0.204716
best-valid-loss: 0.294368
best-kappa: 0.8755
: Epoch: 19 | Training Loss: 0.204716 | Val. Loss: 0.294368 | Val. Kappa Score: 0.8755 | LR: 0.000125 | Estimated time: 70.77
Train loss on 50 batch: 0.190274
Train loss on 100 batch: 0.224417
Train loss on 150 batch: 0.187383
: Epoch: 20 | Training Loss: 0.202974 | Val. Loss: 0.304803 | Val. Kappa Score: 0.8762 | LR: 0.000125 | Estimated time: 69.97
Train loss on 50 batch: 0.190476
Train loss on 100 batch: 0.188909
Train loss on 150 batch: 0.201674
: Epoch: 21 | Training Loss: 0.215342 | Val. Loss: 0.305737 | Val. Kappa Score: 0.8762 | LR: 0.000125 | Estimated time: 69.36
Train loss on 50 batch: 0.180155
Train loss on 100 batch: 0.202455
Train loss on 150 batch: 0.202770
: Epoch: 22 | Training Loss: 0.195364 | Val. Loss: 0.305588 | Val. Kappa Score: 0.8766 | LR: 0.000063 | Estimated time: 69.80
Train loss on 50 batch: 0.197202
Train loss on 100 batch: 0.201740
Train loss on 150 batch: 0.198343
: Epoch: 23 | Training Loss: 0.203132 | Val. Loss: 0.295825 | Val. Kappa Score: 0.8772 | LR: 0.000063 | Estimated time: 70.19
Train loss on 50 batch: 0.211826
Train loss on 100 batch: 0.188620
Train loss on 150 batch: 0.185363
: Epoch: 24 | Training Loss: 0.265878 | Val. Loss: 0.298520 | Val. Kappa Score: 0.8776 | LR: 0.000063 | Estimated time: 70.09
Train loss on 50 batch: 0.180087
Train loss on 100 batch: 0.186330
Train loss on 150 batch: 0.219439
best-train-loss: 0.195843
best-valid-loss: 0.293845
best-kappa: 0.8781
: Epoch: 25 | Training Loss: 0.195843 | Val. Loss: 0.293845 | Val. Kappa Score: 0.8781 | LR: 0.000063 | Estimated time: 69.89
Train loss on 50 batch: 0.189407
Train loss on 100 batch: 0.165769
Train loss on 150 batch: 0.207368
: Epoch: 26 | Training Loss: 0.223261 | Val. Loss: 0.297850 | Val. Kappa Score: 0.8784 | LR: 0.000063 | Estimated time: 69.66
Train loss on 50 batch: 0.205555
Train loss on 100 batch: 0.230419
Train loss on 150 batch: 0.174844
: Epoch: 27 | Training Loss: 0.205525 | Val. Loss: 0.296502 | Val. Kappa Score: 0.8790 | LR: 0.000063 | Estimated time: 69.51
Train loss on 50 batch: 0.216863
Train loss on 100 batch: 0.183055
Train loss on 150 batch: 0.181077
: Epoch: 28 | Training Loss: 0.202849 | Val. Loss: 0.293922 | Val. Kappa Score: 0.8790 | LR: 0.000031 | Estimated time: 70.05
Train loss on 50 batch: 0.163595
Train loss on 100 batch: 0.223485
Train loss on 150 batch: 0.199154
: Epoch: 29 | Training Loss: 0.196707 | Val. Loss: 0.295436 | Val. Kappa Score: 0.8792 | LR: 0.000031 | Estimated time: 71.53
Train loss on 50 batch: 0.189641
Train loss on 100 batch: 0.209176
Train loss on 150 batch: 0.192149
: Epoch: 30 | Training Loss: 0.197921 | Val. Loss: 0.295298 | Val. Kappa Score: 0.8796 | LR: 0.000031 | Estimated time: 70.59
Train loss on 50 batch: 0.180664
Train loss on 100 batch: 0.198845
Train loss on 150 batch: 0.164430
best-train-loss: 0.193601
best-valid-loss: 0.291892
best-kappa: 0.8800
: Epoch: 31 | Training Loss: 0.193601 | Val. Loss: 0.291892 | Val. Kappa Score: 0.8800 | LR: 0.000031 | Estimated time: 72.71
Train loss on 50 batch: 0.184923
Train loss on 100 batch: 0.200696
Train loss on 150 batch: 0.167137
: Epoch: 32 | Training Loss: 0.183097 | Val. Loss: 0.293688 | Val. Kappa Score: 0.8800 | LR: 0.000031 | Estimated time: 72.98
Train loss on 50 batch: 0.194165
Train loss on 100 batch: 0.183399
Train loss on 150 batch: 0.166638
: Epoch: 33 | Training Loss: 0.187670 | Val. Loss: 0.296454 | Val. Kappa Score: 0.8804 | LR: 0.000031 | Estimated time: 70.06
Train loss on 50 batch: 0.166857
Train loss on 100 batch: 0.186412
Train loss on 150 batch: 0.198195
: Epoch: 34 | Training Loss: 0.183433 | Val. Loss: 0.293202 | Val. Kappa Score: 0.8803 | LR: 0.000016 | Estimated time: 70.07
Train loss on 50 batch: 0.169721
Train loss on 100 batch: 0.204803
Train loss on 150 batch: 0.171226
: Epoch: 35 | Training Loss: 0.204166 | Val. Loss: 0.292573 | Val. Kappa Score: 0.8803 | LR: 0.000016 | Estimated time: 73.53
Train loss on 50 batch: 0.162434
Train loss on 100 batch: 0.182538
Train loss on 150 batch: 0.175993
: Epoch: 36 | Training Loss: 0.189011 | Val. Loss: 0.292323 | Val. Kappa Score: 0.8803 | LR: 0.000016 | Estimated time: 72.01
Train loss on 50 batch: 0.190479
Train loss on 100 batch: 0.180120
Train loss on 150 batch: 0.192965
best-train-loss: 0.192115
best-valid-loss: 0.291236
best-kappa: 0.8804
: Epoch: 37 | Training Loss: 0.192115 | Val. Loss: 0.291236 | Val. Kappa Score: 0.8804 | LR: 0.000016 | Estimated time: 73.01
Train loss on 50 batch: 0.169970
Train loss on 100 batch: 0.179293
Train loss on 150 batch: 0.185165
best-train-loss: 0.240785
best-valid-loss: 0.291128
best-kappa: 0.8806
: Epoch: 38 | Training Loss: 0.240785 | Val. Loss: 0.291128 | Val. Kappa Score: 0.8806 | LR: 0.000016 | Estimated time: 70.34
Train loss on 50 batch: 0.176845
Train loss on 100 batch: 0.184969
Train loss on 150 batch: 0.185704
: Epoch: 39 | Training Loss: 0.192704 | Val. Loss: 0.292747 | Val. Kappa Score: 0.8808 | LR: 0.000016 | Estimated time: 72.61
Train loss on 50 batch: 0.187782
Train loss on 100 batch: 0.171789
Train loss on 150 batch: 0.199264
: Epoch: 40 | Training Loss: 0.186382 | Val. Loss: 0.292606 | Val. Kappa Score: 0.8809 | LR: 0.000016 | Estimated time: 71.07
Train loss on 50 batch: 0.170290
Train loss on 100 batch: 0.183256
Train loss on 150 batch: 0.174045
: Epoch: 41 | Training Loss: 0.176966 | Val. Loss: 0.293735 | Val. Kappa Score: 0.8812 | LR: 0.000008 | Estimated time: 70.55
Train loss on 50 batch: 0.189439
Train loss on 100 batch: 0.152513
Train loss on 150 batch: 0.185049
: Epoch: 42 | Training Loss: 0.179214 | Val. Loss: 0.291681 | Val. Kappa Score: 0.8814 | LR: 0.000008 | Estimated time: 70.84
Train loss on 50 batch: 0.194434
Train loss on 100 batch: 0.177171
Train loss on 150 batch: 0.173601
best-train-loss: 0.185907
best-valid-loss: 0.290768
best-kappa: 0.8817
: Epoch: 43 | Training Loss: 0.185907 | Val. Loss: 0.290768 | Val. Kappa Score: 0.8817 | LR: 0.000008 | Estimated time: 69.94
Train loss on 50 batch: 0.158663
Train loss on 100 batch: 0.189294
Train loss on 150 batch: 0.189125
: Epoch: 44 | Training Loss: 0.171575 | Val. Loss: 0.293647 | Val. Kappa Score: 0.8820 | LR: 0.000008 | Estimated time: 69.99
Train loss on 50 batch: 0.175335
Train loss on 100 batch: 0.151893
Train loss on 150 batch: 0.205590
: Epoch: 45 | Training Loss: 0.180184 | Val. Loss: 0.293000 | Val. Kappa Score: 0.8821 | LR: 0.000008 | Estimated time: 70.78
Train loss on 50 batch: 0.181930
Train loss on 100 batch: 0.185097
Train loss on 150 batch: 0.197603
: Epoch: 46 | Training Loss: 0.184673 | Val. Loss: 0.292541 | Val. Kappa Score: 0.8822 | LR: 0.000004 | Estimated time: 70.53
Train loss on 50 batch: 0.175874
Train loss on 100 batch: 0.168856
Train loss on 150 batch: 0.162856
: Epoch: 47 | Training Loss: 0.176582 | Val. Loss: 0.292750 | Val. Kappa Score: 0.8823 | LR: 0.000004 | Estimated time: 72.76
Train loss on 50 batch: 0.148855
Train loss on 100 batch: 0.172317
Train loss on 150 batch: 0.180203
: Epoch: 48 | Training Loss: 0.189135 | Val. Loss: 0.293145 | Val. Kappa Score: 0.8822 | LR: 0.000004 | Estimated time: 72.64
Train loss on 50 batch: 0.167208
Train loss on 100 batch: 0.180358
Train loss on 150 batch: 0.187869
: Epoch: 49 | Training Loss: 0.187207 | Val. Loss: 0.294054 | Val. Kappa Score: 0.8823 | LR: 0.000002 | Estimated time: 72.41
Train loss on 50 batch: 0.160328
Train loss on 100 batch: 0.190088
Train loss on 150 batch: 0.202669
: Epoch: 50 | Training Loss: 0.180514 | Val. Loss: 0.292375 | Val. Kappa Score: 0.8824 | LR: 0.000002 | Estimated time: 71.66
Train loss on 50 batch: 0.181696
Train loss on 100 batch: 0.222441
Train loss on 150 batch: 0.160192
: Epoch: 51 | Training Loss: 0.184066 | Val. Loss: 0.293701 | Val. Kappa Score: 0.8826 | LR: 0.000002 | Estimated time: 74.25
Train loss on 50 batch: 0.196491
Train loss on 100 batch: 0.154430
Train loss on 150 batch: 0.181857
: Epoch: 52 | Training Loss: 0.180550 | Val. Loss: 0.295818 | Val. Kappa Score: 0.8827 | LR: 0.000001 | Estimated time: 74.58
Train loss on 50 batch: 0.200320
Train loss on 100 batch: 0.162989
Train loss on 150 batch: 0.170138
: Epoch: 53 | Training Loss: 0.178935 | Val. Loss: 0.297026 | Val. Kappa Score: 0.8829 | LR: 0.000001 | Estimated time: 73.33
time_estimated: 3757.12
n-epochs: 53
time_estimated: 3757.18
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:13:56
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b1e48>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:14:26
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b2e80>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:14:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b4e10>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:15:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b7e48>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:17:06
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b2eb8>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 164: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:17:26
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b5e48>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.726200
Train loss on 100 batch: 1.499405
Train loss on 150 batch: 1.383791
best-train-loss: 1.507025
best-valid-loss: 2.557341
best-kappa: -0.2979
: Epoch: 1 | Training Loss: 1.507025 | Val. Loss: 2.557341 | Val. Kappa Score: -0.2979 | LR: 0.001000 | Estimated time: 67.32
Train loss on 50 batch: 1.379943
Train loss on 100 batch: 1.337657
Train loss on 150 batch: 1.242240
best-train-loss: 1.344644
best-valid-loss: 1.606810
best-kappa: -0.1154
: Epoch: 2 | Training Loss: 1.344644 | Val. Loss: 1.606810 | Val. Kappa Score: -0.1154 | LR: 0.001000 | Estimated time: 66.45
Train loss on 50 batch: 1.309700
Train loss on 100 batch: 1.238001
Train loss on 150 batch: 1.322334
: Epoch: 3 | Training Loss: 1.289937 | Val. Loss: 1.754556 | Val. Kappa Score: -0.0727 | LR: 0.001000 | Estimated time: 65.85
Train loss on 50 batch: 1.311935
Train loss on 100 batch: 1.194351
Train loss on 150 batch: 1.224024
: Epoch: 4 | Training Loss: 1.298218 | Val. Loss: 1.670466 | Val. Kappa Score: -0.0545 | LR: 0.001000 | Estimated time: 66.57
Train loss on 50 batch: 1.294064
----------------------------------------

Experiment N: 165: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:22:37
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b3e10>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.114954
Train loss on 100 batch: 1.741755
Train loss on 150 batch: 1.660851
best-train-loss: 1.771080
best-valid-loss: 1.685078
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.771080 | Val. Loss: 1.685078 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 67.77
Train loss on 50 batch: 1.645024
Train loss on 100 batch: 1.619971
Train loss on 150 batch: 1.441077
: Epoch: 2 | Training Loss: 1.580864 | Val. Loss: 2.061479 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 66.78
Train loss on 50 batch: 1.644586
Train loss on 100 batch: 1.501530
Train loss on 150 batch: 1.565947
: Epoch: 3 | Training Loss: 1.551528 | Val. Loss: 1.850403 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 68.62
Train loss on 50 batch: 1.625741
Train loss on 100 batch: 1.413582
Train loss on 150 batch: 1.511906
: Epoch: 4 | Training Loss: 1.598570 | Val. Loss: 2.668556 | Val. Kappa Score: -0.0070 | LR: 0.000500 | Estimated time: 66.54
----------------------------------------

Experiment N: 166: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:28:14
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516b5dd8>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.108383
Train loss on 100 batch: 1.797444
Train loss on 150 batch: 1.637988
best-train-loss: 1.786649
best-valid-loss: 1.689908
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.786649 | Val. Loss: 1.689908 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 67.05
Train loss on 50 batch: 1.666786
Train loss on 100 batch: 1.659571
Train loss on 150 batch: 1.470638
: Epoch: 2 | Training Loss: 1.605863 | Val. Loss: 2.068990 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 66.55
Train loss on 50 batch: 1.661363
Train loss on 100 batch: 1.547780
Train loss on 150 batch: 1.539241
: Epoch: 3 | Training Loss: 1.555181 | Val. Loss: 1.875940 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 66.09
Train loss on 50 batch: 1.595605
----------------------------------------

Experiment N: 167: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.09.02 19:33:03
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51798a90>
early-stopping-patience: 10
parameters-amount: 6514465
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 167: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.09.02 19:33:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51797a20>
early-stopping-patience: 10
parameters-amount: 6514753
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.094987
Train loss on 100 batch: 1.830412
Train loss on 150 batch: 1.660632
best-train-loss: 1.788592
best-valid-loss: 1.738065
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.788592 | Val. Loss: 1.738065 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 55.18
Train loss on 50 batch: 1.581184
Train loss on 100 batch: 1.538654
Train loss on 150 batch: 1.409285
: Epoch: 2 | Training Loss: 1.530840 | Val. Loss: 1.806599 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 56.33
Train loss on 50 batch: 1.539323
Train loss on 100 batch: 1.450332
Train loss on 150 batch: 1.532894
best-train-loss: 1.476643
best-valid-loss: 1.499614
best-kappa: 0.0918
: Epoch: 3 | Training Loss: 1.476643 | Val. Loss: 1.499614 | Val. Kappa Score: 0.0918 | LR: 0.001000 | Estimated time: 56.65
Train loss on 50 batch: 1.483471
Train loss on 100 batch: 1.323253
Train loss on 150 batch: 1.343211
: Epoch: 4 | Training Loss: 1.452194 | Val. Loss: 2.254926 | Val. Kappa Score: 0.0697 | LR: 0.001000 | Estimated time: 56.82
Train loss on 50 batch: 1.340370
Train loss on 100 batch: 1.428459
Train loss on 150 batch: 1.336284
: Epoch: 5 | Training Loss: 1.360281 | Val. Loss: 2.378102 | Val. Kappa Score: 0.0557 | LR: 0.001000 | Estimated time: 57.95
Train loss on 50 batch: 1.416796
Train loss on 100 batch: 1.328118
Train loss on 150 batch: 1.238002
: Epoch: 6 | Training Loss: 1.320928 | Val. Loss: 2.399918 | Val. Kappa Score: 0.0335 | LR: 0.000500 | Estimated time: 56.70
Train loss on 50 batch: 1.279541
Train loss on 100 batch: 1.236388
Train loss on 150 batch: 1.296096
: Epoch: 7 | Training Loss: 1.276258 | Val. Loss: 1.725423 | Val. Kappa Score: 0.0641 | LR: 0.000500 | Estimated time: 56.25
Train loss on 50 batch: 1.302023
Train loss on 100 batch: 1.312250
Train loss on 150 batch: 1.119481
: Epoch: 8 | Training Loss: 1.219302 | Val. Loss: 1.865922 | Val. Kappa Score: 0.0554 | LR: 0.000500 | Estimated time: 57.22
Train loss on 50 batch: 1.159204
Train loss on 100 batch: 1.204219
Train loss on 150 batch: 1.269810
: Epoch: 9 | Training Loss: 1.219957 | Val. Loss: 2.499973 | Val. Kappa Score: 0.0354 | LR: 0.000250 | Estimated time: 58.67
Train loss on 50 batch: 1.216179
Train loss on 100 batch: 1.184576
----------------------------------------

Experiment N: 168: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.09.02 19:43:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51796a20>
early-stopping-patience: 10
parameters-amount: 6515329
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 168: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b1


: 
date: 2019.09.02 19:43:33
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51797a58>
early-stopping-patience: 10
parameters-amount: 6514753
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.787006
Train loss on 100 batch: 1.517113
Train loss on 150 batch: 1.372851
best-train-loss: 1.517988
best-valid-loss: 1.466940
best-kappa: 0.2161
: Epoch: 1 | Training Loss: 1.517988 | Val. Loss: 1.466940 | Val. Kappa Score: 0.2161 | LR: 0.001000 | Estimated time: 54.97
Train loss on 50 batch: 1.364027
Train loss on 100 batch: 1.302199
Train loss on 150 batch: 1.219687
: Epoch: 2 | Training Loss: 1.297896 | Val. Loss: 2.075839 | Val. Kappa Score: 0.0324 | LR: 0.001000 | Estimated time: 55.43
Train loss on 50 batch: 1.344280
Train loss on 100 batch: 1.219462
Train loss on 150 batch: 1.306980
: Epoch: 3 | Training Loss: 1.270950 | Val. Loss: 1.946943 | Val. Kappa Score: 0.0364 | LR: 0.001000 | Estimated time: 55.27
Train loss on 50 batch: 1.283690
Train loss on 100 batch: 1.188909
Train loss on 150 batch: 1.218525
: Epoch: 4 | Training Loss: 1.285019 | Val. Loss: 2.681567 | Val. Kappa Score: 0.0152 | LR: 0.000500 | Estimated time: 55.83
Train loss on 50 batch: 1.172338
Train loss on 100 batch: 1.238448
Train loss on 150 batch: 1.135275
: Epoch: 5 | Training Loss: 1.178005 | Val. Loss: 14.875519 | Val. Kappa Score: 0.0329 | LR: 0.000500 | Estimated time: 56.16
----------------------------------------

Experiment N: 169: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.09.02 19:48:53
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb517d46d8>
early-stopping-patience: 10
parameters-amount: 42502209
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 169: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNet101


: 
date: 2019.09.02 19:50:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb517d36d8>
early-stopping-patience: 10
parameters-amount: 42505345
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.942367
Train loss on 100 batch: 1.650831
Train loss on 150 batch: 1.519207
best-train-loss: 1.622196
best-valid-loss: 1.780486
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.622196 | Val. Loss: 1.780486 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 56.50
Train loss on 50 batch: 1.507099
Train loss on 100 batch: 1.420986
Train loss on 150 batch: 1.287905
: Epoch: 2 | Training Loss: 1.430327 | Val. Loss: 2.517625 | Val. Kappa Score: -0.1441 | LR: 0.001000 | Estimated time: 56.63
Train loss on 50 batch: 1.383871
Train loss on 100 batch: 1.413986
Train loss on 150 batch: 1.445101
: Epoch: 3 | Training Loss: 1.394638 | Val. Loss: 2.036698 | Val. Kappa Score: -0.0677 | LR: 0.001000 | Estimated time: 56.85
Train loss on 50 batch: 1.479976
Train loss on 100 batch: 1.292301
Train loss on 150 batch: 1.302470
: Epoch: 4 | Training Loss: 1.433319 | Val. Loss: 16.114859 | Val. Kappa Score: -0.0822 | LR: 0.000500 | Estimated time: 56.98
----------------------------------------

Experiment N: 170: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 19:55:32
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d094208>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.189959
Train loss on 100 batch: 0.761329
Train loss on 150 batch: 0.741163
best-train-loss: 0.802033
best-valid-loss: 0.871706
best-kappa: 0.6669
: Epoch: 1 | Training Loss: 0.802033 | Val. Loss: 0.871706 | Val. Kappa Score: 0.6669 | LR: 0.001000 | Estimated time: 66.52
Train loss on 50 batch: 0.419912
Train loss on 100 batch: 0.427388
Train loss on 150 batch: 0.418040
best-train-loss: 0.448708
best-valid-loss: 0.838720
best-kappa: 0.7022
: Epoch: 2 | Training Loss: 0.448708 | Val. Loss: 0.838720 | Val. Kappa Score: 0.7022 | LR: 0.001000 | Estimated time: 65.99
Train loss on 50 batch: 0.394871
Train loss on 100 batch: 0.431073
Train loss on 150 batch: 0.374730
best-train-loss: 0.389274
best-valid-loss: 0.367310
best-kappa: 0.7575
: Epoch: 3 | Training Loss: 0.389274 | Val. Loss: 0.367310 | Val. Kappa Score: 0.7575 | LR: 0.001000 | Estimated time: 68.54
Train loss on 50 batch: 0.299852
Train loss on 100 batch: 0.335508
Train loss on 150 batch: 0.338341
: Epoch: 4 | Training Loss: 0.359819 | Val. Loss: 0.576739 | Val. Kappa Score: 0.7757 | LR: 0.001000 | Estimated time: 67.61
Train loss on 50 batch: 0.371391
Train loss on 100 batch: 0.306518
Train loss on 150 batch: 0.270270
: Epoch: 5 | Training Loss: 0.320764 | Val. Loss: 0.403651 | Val. Kappa Score: 0.7914 | LR: 0.001000 | Estimated time: 66.51
Train loss on 50 batch: 0.260133
Train loss on 100 batch: 0.197090
Train loss on 150 batch: 0.227853
: Epoch: 6 | Training Loss: 0.225328 | Val. Loss: 0.400782 | Val. Kappa Score: 0.8001 | LR: 0.000500 | Estimated time: 66.30
Train loss on 50 batch: 0.191715
Train loss on 100 batch: 0.161451
Train loss on 150 batch: 0.130185
best-train-loss: 0.155755
best-valid-loss: 0.308426
best-kappa: 0.8124
: Epoch: 7 | Training Loss: 0.155755 | Val. Loss: 0.308426 | Val. Kappa Score: 0.8124 | LR: 0.000500 | Estimated time: 66.32
Train loss on 50 batch: 0.087233
Train loss on 100 batch: 0.098977
Train loss on 150 batch: 0.074270
: Epoch: 8 | Training Loss: 0.099552 | Val. Loss: 0.321779 | Val. Kappa Score: 0.8208 | LR: 0.000500 | Estimated time: 66.05
Train loss on 50 batch: 0.092301
Train loss on 100 batch: 0.095290
Train loss on 150 batch: 0.100401
: Epoch: 9 | Training Loss: 0.095119 | Val. Loss: 0.331257 | Val. Kappa Score: 0.8284 | LR: 0.000500 | Estimated time: 67.27
Train loss on 50 batch: 0.067456
Train loss on 100 batch: 0.076150
Train loss on 150 batch: 0.079689
: Epoch: 10 | Training Loss: 0.133561 | Val. Loss: 0.317642 | Val. Kappa Score: 0.8331 | LR: 0.000250 | Estimated time: 68.27
Train loss on 50 batch: 0.092618
Train loss on 100 batch: 0.072047
Train loss on 150 batch: 0.070244
: Epoch: 11 | Training Loss: 0.086924 | Val. Loss: 0.334540 | Val. Kappa Score: 0.8368 | LR: 0.000250 | Estimated time: 65.50
Train loss on 50 batch: 0.049728
Train loss on 100 batch: 0.053153
Train loss on 150 batch: 0.045525
: Epoch: 12 | Training Loss: 0.049328 | Val. Loss: 0.323202 | Val. Kappa Score: 0.8406 | LR: 0.000250 | Estimated time: 66.24
----------------------------------------

Experiment N: 171: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:09:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d094208>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: nan
Train loss on 100 batch: nan
Train loss on 150 batch: nan
----------------------------------------

Experiment N: 171: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:11:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d094160>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.197930
Train loss on 100 batch: 0.704162
Train loss on 150 batch: 0.686375
best-train-loss: 0.790630
best-valid-loss: 3.186240
best-kappa: 0.1926
: Epoch: 1 | Training Loss: 0.790630 | Val. Loss: 3.186240 | Val. Kappa Score: 0.1926 | LR: 0.001000 | Estimated time: 66.64
----------------------------------------

Experiment N: 172: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:14:57
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516fdf98>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.252971
Train loss on 100 batch: 0.690276
Train loss on 150 batch: 0.644546
best-train-loss: 0.792113
best-valid-loss: 1.551856
best-kappa: 0.4113
: Epoch: 1 | Training Loss: 0.792113 | Val. Loss: 1.551856 | Val. Kappa Score: 0.4113 | LR: 0.001000 | Estimated time: 66.15
Train loss on 50 batch: 0.490420
Train loss on 100 batch: 0.436593
Train loss on 150 batch: 0.394233
best-train-loss: 0.453243
best-valid-loss: 0.432130
best-kappa: 0.6259
: Epoch: 2 | Training Loss: 0.453243 | Val. Loss: 0.432130 | Val. Kappa Score: 0.6259 | LR: 0.001000 | Estimated time: 66.03
Train loss on 50 batch: 0.412120
----------------------------------------

Experiment N: 173: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:17:41
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d094240>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.731524
Train loss on 100 batch: 1.467829
Train loss on 150 batch: 1.439933
best-train-loss: 1.513892
best-valid-loss: 2.181362
best-kappa: 0.0349
: Epoch: 1 | Training Loss: 1.513892 | Val. Loss: 2.181362 | Val. Kappa Score: 0.0349 | LR: 0.001000 | Estimated time: 68.69
Train loss on 50 batch: 1.459053
----------------------------------------

Experiment N: 174: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:23:38
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d1df400>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.743172
Train loss on 100 batch: 1.459344
Train loss on 150 batch: 1.420715
----------------------------------------

Experiment N: 174: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:24:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d0941d0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.207338
Train loss on 100 batch: 0.868787
Train loss on 150 batch: 0.709616
best-train-loss: 0.851986
best-valid-loss: 0.933355
best-kappa: 0.6525
: Epoch: 1 | Training Loss: 0.851986 | Val. Loss: 0.933355 | Val. Kappa Score: 0.6525 | LR: 0.001000 | Estimated time: 69.94
Train loss on 50 batch: 0.549683
Train loss on 100 batch: 0.502440
Train loss on 150 batch: 0.452876
best-train-loss: 0.518273
best-valid-loss: 0.642077
best-kappa: 0.7051
: Epoch: 2 | Training Loss: 0.518273 | Val. Loss: 0.642077 | Val. Kappa Score: 0.7051 | LR: 0.001000 | Estimated time: 69.09
Train loss on 50 batch: 0.475472
Train loss on 100 batch: 0.542054
Train loss on 150 batch: 0.464743
best-train-loss: 0.472038
best-valid-loss: 0.427389
best-kappa: 0.7499
: Epoch: 3 | Training Loss: 0.472038 | Val. Loss: 0.427389 | Val. Kappa Score: 0.7499 | LR: 0.001000 | Estimated time: 70.84
Train loss on 50 batch: 0.382509
Train loss on 100 batch: 0.410088
Train loss on 150 batch: 0.462740
best-train-loss: 0.451175
best-valid-loss: 0.412047
best-kappa: 0.7737
: Epoch: 4 | Training Loss: 0.451175 | Val. Loss: 0.412047 | Val. Kappa Score: 0.7737 | LR: 0.001000 | Estimated time: 68.41
Train loss on 50 batch: 0.476041
Train loss on 100 batch: 0.412022
Train loss on 150 batch: 0.331437
: Epoch: 5 | Training Loss: 0.433476 | Val. Loss: 0.425179 | Val. Kappa Score: 0.7884 | LR: 0.001000 | Estimated time: 68.83
Train loss on 50 batch: 0.435184
Train loss on 100 batch: 0.394879
Train loss on 150 batch: 0.352494
: Epoch: 6 | Training Loss: 0.382553 | Val. Loss: 0.517718 | Val. Kappa Score: 0.7916 | LR: 0.001000 | Estimated time: 67.54
Train loss on 50 batch: 0.363072
Train loss on 100 batch: 0.322361
Train loss on 150 batch: 0.303701
best-train-loss: 0.334393
best-valid-loss: 0.378693
best-kappa: 0.8024
: Epoch: 7 | Training Loss: 0.334393 | Val. Loss: 0.378693 | Val. Kappa Score: 0.8024 | LR: 0.001000 | Estimated time: 68.06
Train loss on 50 batch: 0.273380
Train loss on 100 batch: 0.299208
Train loss on 150 batch: 0.261995
best-train-loss: 0.289268
best-valid-loss: 0.352872
best-kappa: 0.8109
: Epoch: 8 | Training Loss: 0.289268 | Val. Loss: 0.352872 | Val. Kappa Score: 0.8109 | LR: 0.001000 | Estimated time: 68.09
Train loss on 50 batch: 0.297552
Train loss on 100 batch: 0.316613
Train loss on 150 batch: 0.324174
best-train-loss: 0.302950
best-valid-loss: 0.333901
best-kappa: 0.8177
: Epoch: 9 | Training Loss: 0.302950 | Val. Loss: 0.333901 | Val. Kappa Score: 0.8177 | LR: 0.001000 | Estimated time: 67.32
Train loss on 50 batch: 0.259165
Train loss on 100 batch: 0.272737
Train loss on 150 batch: 0.319265
: Epoch: 10 | Training Loss: 0.349366 | Val. Loss: 0.510991 | Val. Kappa Score: 0.8158 | LR: 0.001000 | Estimated time: 67.88
Train loss on 50 batch: 0.411916
Train loss on 100 batch: 0.347293
Train loss on 150 batch: 0.363622
: Epoch: 11 | Training Loss: 0.373327 | Val. Loss: 0.415462 | Val. Kappa Score: 0.8187 | LR: 0.001000 | Estimated time: 66.72
Train loss on 50 batch: 0.330251
Train loss on 100 batch: 0.302347
Train loss on 150 batch: 0.252707
: Epoch: 12 | Training Loss: 0.279502 | Val. Loss: 0.399377 | Val. Kappa Score: 0.8244 | LR: 0.000500 | Estimated time: 66.61
Train loss on 50 batch: 0.238395
Train loss on 100 batch: 0.237226
Train loss on 150 batch: 0.214153
best-train-loss: 0.227844
best-valid-loss: 0.292445
best-kappa: 0.8295
: Epoch: 13 | Training Loss: 0.227844 | Val. Loss: 0.292445 | Val. Kappa Score: 0.8295 | LR: 0.000500 | Estimated time: 66.34
Train loss on 50 batch: 0.192591
Train loss on 100 batch: 0.178500
Train loss on 150 batch: 0.201551
best-train-loss: 0.197305
best-valid-loss: 0.281385
best-kappa: 0.8342
: Epoch: 14 | Training Loss: 0.197305 | Val. Loss: 0.281385 | Val. Kappa Score: 0.8342 | LR: 0.000500 | Estimated time: 67.74
Train loss on 50 batch: 0.236391
Train loss on 100 batch: 0.196356
Train loss on 150 batch: 0.194078
: Epoch: 15 | Training Loss: 0.202431 | Val. Loss: 0.340562 | Val. Kappa Score: 0.8367 | LR: 0.000500 | Estimated time: 68.22
Train loss on 50 batch: 0.195839
Train loss on 100 batch: 0.181116
Train loss on 150 batch: 0.175894
: Epoch: 16 | Training Loss: 0.183679 | Val. Loss: 0.286822 | Val. Kappa Score: 0.8399 | LR: 0.000500 | Estimated time: 70.78
Train loss on 50 batch: 0.251383
Train loss on 100 batch: 0.195151
Train loss on 150 batch: 0.174932
: Epoch: 17 | Training Loss: 0.196798 | Val. Loss: 0.313078 | Val. Kappa Score: 0.8428 | LR: 0.000250 | Estimated time: 68.88
Train loss on 50 batch: 0.162733
Train loss on 100 batch: 0.120778
Train loss on 150 batch: 0.142655
: Epoch: 18 | Training Loss: 0.143647 | Val. Loss: 0.300514 | Val. Kappa Score: 0.8454 | LR: 0.000250 | Estimated time: 70.17
Train loss on 50 batch: 0.103741
Train loss on 100 batch: 0.142948
Train loss on 150 batch: 0.135085
: Epoch: 19 | Training Loss: 0.133380 | Val. Loss: 0.315465 | Val. Kappa Score: 0.8477 | LR: 0.000250 | Estimated time: 70.36
Train loss on 50 batch: 0.126194
Train loss on 100 batch: 0.127563
Train loss on 150 batch: 0.114796
: Epoch: 20 | Training Loss: 0.123173 | Val. Loss: 0.316479 | Val. Kappa Score: 0.8498 | LR: 0.000125 | Estimated time: 70.74
Train loss on 50 batch: 0.111462
Train loss on 100 batch: 0.110577
Train loss on 150 batch: 0.119303
: Epoch: 21 | Training Loss: 0.129606 | Val. Loss: 0.282820 | Val. Kappa Score: 0.8521 | LR: 0.000125 | Estimated time: 69.70
Train loss on 50 batch: 0.104036
Train loss on 100 batch: 0.109376
Train loss on 150 batch: 0.097216
: Epoch: 22 | Training Loss: 0.100031 | Val. Loss: 0.296198 | Val. Kappa Score: 0.8540 | LR: 0.000125 | Estimated time: 68.83
Train loss on 50 batch: 0.089394
Train loss on 100 batch: 0.104741
Train loss on 150 batch: 0.094069
: Epoch: 23 | Training Loss: 0.092063 | Val. Loss: 0.304138 | Val. Kappa Score: 0.8559 | LR: 0.000063 | Estimated time: 68.95
Train loss on 50 batch: 0.088242
Train loss on 100 batch: 0.101966
Train loss on 150 batch: 0.083062
: Epoch: 24 | Training Loss: 0.138113 | Val. Loss: 0.293712 | Val. Kappa Score: 0.8572 | LR: 0.000063 | Estimated time: 68.99
time_estimated: 1651.01
n-epochs: 24
time_estimated: 1651.07
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:57:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d095198>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 20:58:54
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51701fd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:00:55
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51702f28>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:01:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54f9bf60>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:01:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516fffd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:02:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54f9c860>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:03:15
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d095198>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:03:48
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb55083da0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:04:34
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516fef98>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:04:54
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51700fd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:05:57
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51701f98>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:06:06
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51700fd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:06:17
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51742f98>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 175: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.02 21:12:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb516fdfd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.021112
Train loss on 100 batch: 1.442200
Train loss on 150 batch: 1.076315
best-train-loss: 1.405891
best-valid-loss: 1.751674
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.405891 | Val. Loss: 1.751674 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 67.17
Train loss on 50 batch: 1.014466
Train loss on 100 batch: 0.998826
Train loss on 150 batch: 0.858252
: Epoch: 2 | Training Loss: 0.978394 | Val. Loss: 1.781842 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 66.53
Train loss on 50 batch: 1.003485
Train loss on 100 batch: 0.975964
Train loss on 150 batch: 1.013382
best-train-loss: 0.972102
best-valid-loss: 1.180547
best-kappa: 0.1222
: Epoch: 3 | Training Loss: 0.972102 | Val. Loss: 1.180547 | Val. Kappa Score: 0.1222 | LR: 0.001000 | Estimated time: 70.65
Train loss on 50 batch: 0.954618
Train loss on 100 batch: 0.854032
Train loss on 150 batch: 0.874721
best-train-loss: 0.967833
best-valid-loss: 0.834122
best-kappa: 0.2579
: Epoch: 4 | Training Loss: 0.967833 | Val. Loss: 0.834122 | Val. Kappa Score: 0.2579 | LR: 0.001000 | Estimated time: 67.69
Train loss on 50 batch: 0.893349
Train loss on 100 batch: 0.979574
Train loss on 150 batch: 0.859530
: Epoch: 5 | Training Loss: 0.907725 | Val. Loss: 0.875016 | Val. Kappa Score: 0.3438 | LR: 0.001000 | Estimated time: 68.16
Train loss on 50 batch: 0.973010
Train loss on 100 batch: 0.888191
Train loss on 150 batch: 0.848236
best-train-loss: 0.915738
best-valid-loss: 0.790693
best-kappa: 0.4053
: Epoch: 6 | Training Loss: 0.915738 | Val. Loss: 0.790693 | Val. Kappa Score: 0.4053 | LR: 0.001000 | Estimated time: 65.27
Train loss on 50 batch: 0.958144
Train loss on 100 batch: 0.777637
Train loss on 150 batch: 0.866762
best-train-loss: 0.876791
best-valid-loss: 0.754766
best-kappa: 0.4511
: Epoch: 7 | Training Loss: 0.876791 | Val. Loss: 0.754766 | Val. Kappa Score: 0.4511 | LR: 0.001000 | Estimated time: 67.58
Train loss on 50 batch: 0.833832
Train loss on 100 batch: 0.921767
Train loss on 150 batch: 0.794518
: Epoch: 8 | Training Loss: 0.825397 | Val. Loss: 0.764811 | Val. Kappa Score: 0.4846 | LR: 0.001000 | Estimated time: 66.45
Train loss on 50 batch: 0.835442
Train loss on 100 batch: 0.854670
Train loss on 150 batch: 0.892833
: Epoch: 9 | Training Loss: 0.853543 | Val. Loss: 0.757332 | Val. Kappa Score: 0.5115 | LR: 0.001000 | Estimated time: 68.19
Train loss on 50 batch: 0.794501
Train loss on 100 batch: 0.847589
Train loss on 150 batch: 0.804694
: Epoch: 10 | Training Loss: 0.866264 | Val. Loss: 0.768974 | Val. Kappa Score: 0.5302 | LR: 0.000500 | Estimated time: 67.44
Train loss on 50 batch: 0.789314
Train loss on 100 batch: 0.823283
Train loss on 150 batch: 0.834391
: Epoch: 11 | Training Loss: 0.804634 | Val. Loss: 0.757111 | Val. Kappa Score: 0.5495 | LR: 0.000500 | Estimated time: 66.51
Train loss on 50 batch: 0.831318
Train loss on 100 batch: 0.782500
Train loss on 150 batch: 0.731588
best-train-loss: 0.778116
best-valid-loss: 0.720323
best-kappa: 0.5644
: Epoch: 12 | Training Loss: 0.778116 | Val. Loss: 0.720323 | Val. Kappa Score: 0.5644 | LR: 0.000500 | Estimated time: 66.35
Train loss on 50 batch: 0.717605
Train loss on 100 batch: 0.778289
Train loss on 150 batch: 0.738857
: Epoch: 13 | Training Loss: 0.755760 | Val. Loss: 0.827154 | Val. Kappa Score: 0.5760 | LR: 0.000500 | Estimated time: 66.80
Train loss on 50 batch: 0.686253
Train loss on 100 batch: 0.694196
Train loss on 150 batch: 0.794615
best-train-loss: 0.735543
best-valid-loss: 0.697907
best-kappa: 0.5887
: Epoch: 14 | Training Loss: 0.735543 | Val. Loss: 0.697907 | Val. Kappa Score: 0.5887 | LR: 0.000500 | Estimated time: 66.30
Train loss on 50 batch: 0.757981
Train loss on 100 batch: 0.629430
Train loss on 150 batch: 0.660210
best-train-loss: 0.699301
best-valid-loss: 0.671735
best-kappa: 0.5999
: Epoch: 15 | Training Loss: 0.699301 | Val. Loss: 0.671735 | Val. Kappa Score: 0.5999 | LR: 0.000500 | Estimated time: 66.42
Train loss on 50 batch: 0.698482
Train loss on 100 batch: 0.686684
Train loss on 150 batch: 0.699030
: Epoch: 16 | Training Loss: 0.696293 | Val. Loss: 0.694109 | Val. Kappa Score: 0.6099 | LR: 0.000500 | Estimated time: 65.99
Train loss on 50 batch: 0.788323
Train loss on 100 batch: 0.710744
Train loss on 150 batch: 0.668054
: Epoch: 17 | Training Loss: 0.721398 | Val. Loss: 0.711184 | Val. Kappa Score: 0.6180 | LR: 0.000500 | Estimated time: 66.29
Train loss on 50 batch: 0.734096
Train loss on 100 batch: 0.631444
Train loss on 150 batch: 0.684751
: Epoch: 18 | Training Loss: 0.665012 | Val. Loss: 0.689679 | Val. Kappa Score: 0.6252 | LR: 0.000250 | Estimated time: 66.45
Train loss on 50 batch: 0.641809
Train loss on 100 batch: 0.671994
Train loss on 150 batch: 0.623135
best-train-loss: 0.675593
best-valid-loss: 0.629907
best-kappa: 0.6318
: Epoch: 19 | Training Loss: 0.675593 | Val. Loss: 0.629907 | Val. Kappa Score: 0.6318 | LR: 0.000250 | Estimated time: 66.66
Train loss on 50 batch: 0.665264
Train loss on 100 batch: 0.653012
Train loss on 150 batch: 0.563134
best-train-loss: 0.647691
best-valid-loss: 0.603385
best-kappa: 0.6392
: Epoch: 20 | Training Loss: 0.647691 | Val. Loss: 0.603385 | Val. Kappa Score: 0.6392 | LR: 0.000250 | Estimated time: 66.42
Train loss on 50 batch: 0.621648
Train loss on 100 batch: 0.586630
Train loss on 150 batch: 0.647909
: Epoch: 21 | Training Loss: 0.618650 | Val. Loss: 0.603596 | Val. Kappa Score: 0.6462 | LR: 0.000250 | Estimated time: 67.52
Train loss on 50 batch: 0.564744
Train loss on 100 batch: 0.615801
Train loss on 150 batch: 0.665092
: Epoch: 22 | Training Loss: 0.617473 | Val. Loss: 0.616010 | Val. Kappa Score: 0.6520 | LR: 0.000250 | Estimated time: 70.54
Train loss on 50 batch: 0.617647
Train loss on 100 batch: 0.635839
Train loss on 150 batch: 0.610418
best-train-loss: 0.606038
best-valid-loss: 0.579044
best-kappa: 0.6573
: Epoch: 23 | Training Loss: 0.606038 | Val. Loss: 0.579044 | Val. Kappa Score: 0.6573 | LR: 0.000250 | Estimated time: 71.26
Train loss on 50 batch: 0.570086
Train loss on 100 batch: 0.584725
Train loss on 150 batch: 0.651539
best-train-loss: 0.640256
best-valid-loss: 0.568661
best-kappa: 0.6629
: Epoch: 24 | Training Loss: 0.640256 | Val. Loss: 0.568661 | Val. Kappa Score: 0.6629 | LR: 0.000250 | Estimated time: 66.63
Train loss on 50 batch: 0.586681
Train loss on 100 batch: 0.527003
Train loss on 150 batch: 0.695758
best-train-loss: 0.616826
best-valid-loss: 0.566492
best-kappa: 0.6685
: Epoch: 25 | Training Loss: 0.616826 | Val. Loss: 0.566492 | Val. Kappa Score: 0.6685 | LR: 0.000250 | Estimated time: 66.68
Train loss on 50 batch: 0.639409
Train loss on 100 batch: 0.505391
Train loss on 150 batch: 0.671721
: Epoch: 26 | Training Loss: 0.597596 | Val. Loss: 0.587638 | Val. Kappa Score: 0.6727 | LR: 0.000250 | Estimated time: 66.35
Train loss on 50 batch: 0.708263
Train loss on 100 batch: 0.618056
Train loss on 150 batch: 0.561126
: Epoch: 27 | Training Loss: 0.585194 | Val. Loss: 0.634007 | Val. Kappa Score: 0.6767 | LR: 0.000250 | Estimated time: 66.59
Train loss on 50 batch: 0.588255
Train loss on 100 batch: 0.592200
Train loss on 150 batch: 0.504225
: Epoch: 28 | Training Loss: 0.556723 | Val. Loss: 0.569438 | Val. Kappa Score: 0.6803 | LR: 0.000125 | Estimated time: 65.78
Train loss on 50 batch: 0.535609
Train loss on 100 batch: 0.534888
Train loss on 150 batch: 0.586144
: Epoch: 29 | Training Loss: 0.543790 | Val. Loss: 0.588154 | Val. Kappa Score: 0.6834 | LR: 0.000125 | Estimated time: 66.28
Train loss on 50 batch: 0.554094
Train loss on 100 batch: 0.605590
Train loss on 150 batch: 0.522307
----------------------------------------

Experiment N: 176: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 06:12:50
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51700fd0>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.463733
Train loss on 100 batch: 0.388537
Train loss on 150 batch: 0.334540
best-train-loss: 0.376678
best-valid-loss: 0.344953
best-kappa: 0.8677
: Epoch: 1 | Training Loss: 0.376678 | Val. Loss: 0.344953 | Val. Kappa Score: 0.8677 | LR: 0.001000 | Estimated time: 66.48
Train loss on 50 batch: 0.302058
Train loss on 100 batch: 0.281220
Train loss on 150 batch: 0.251992
: Epoch: 2 | Training Loss: 0.300692 | Val. Loss: 0.350151 | Val. Kappa Score: 0.8677 | LR: 0.001000 | Estimated time: 65.73
Train loss on 50 batch: 0.282790
Train loss on 100 batch: 0.303285
Train loss on 150 batch: 0.283787
best-train-loss: 0.282667
best-valid-loss: 0.312698
best-kappa: 0.8735
: Epoch: 3 | Training Loss: 0.282667 | Val. Loss: 0.312698 | Val. Kappa Score: 0.8735 | LR: 0.001000 | Estimated time: 65.88
Train loss on 50 batch: 0.262484
Train loss on 100 batch: 0.255558
Train loss on 150 batch: 0.278830
best-train-loss: 0.329452
best-valid-loss: 0.311035
best-kappa: 0.8752
: Epoch: 4 | Training Loss: 0.329452 | Val. Loss: 0.311035 | Val. Kappa Score: 0.8752 | LR: 0.001000 | Estimated time: 65.93
Train loss on 50 batch: 0.308930
Train loss on 100 batch: 0.282668
Train loss on 150 batch: 0.222682
: Epoch: 5 | Training Loss: 0.272209 | Val. Loss: 0.364691 | Val. Kappa Score: 0.8708 | LR: 0.001000 | Estimated time: 66.37
Train loss on 50 batch: 0.256726
Train loss on 100 batch: 0.248044
Train loss on 150 batch: 0.212595
: Epoch: 6 | Training Loss: 0.226203 | Val. Loss: 0.421175 | Val. Kappa Score: 0.8641 | LR: 0.001000 | Estimated time: 65.70
Train loss on 50 batch: 0.231861
Train loss on 100 batch: 0.215723
Train loss on 150 batch: 0.233168
: Epoch: 7 | Training Loss: 0.229823 | Val. Loss: 0.379958 | Val. Kappa Score: 0.8634 | LR: 0.000500 | Estimated time: 65.59
Train loss on 50 batch: 0.194033
Train loss on 100 batch: 0.223917
Train loss on 150 batch: 0.167762
: Epoch: 8 | Training Loss: 0.200716 | Val. Loss: 0.407364 | Val. Kappa Score: 0.8656 | LR: 0.000500 | Estimated time: 64.97
Train loss on 50 batch: 0.206246
Train loss on 100 batch: 0.213385
Train loss on 150 batch: 0.184326
: Epoch: 9 | Training Loss: 0.190993 | Val. Loss: 0.318403 | Val. Kappa Score: 0.8673 | LR: 0.000500 | Estimated time: 65.82
Train loss on 50 batch: 0.176832
Train loss on 100 batch: 0.176567
Train loss on 150 batch: 0.195139
: Epoch: 10 | Training Loss: 0.228148 | Val. Loss: 0.331798 | Val. Kappa Score: 0.8677 | LR: 0.000250 | Estimated time: 66.31
Train loss on 50 batch: 0.185722
Train loss on 100 batch: 0.164378
Train loss on 150 batch: 0.166537
best-train-loss: 0.178321
best-valid-loss: 0.299511
best-kappa: 0.8691
: Epoch: 11 | Training Loss: 0.178321 | Val. Loss: 0.299511 | Val. Kappa Score: 0.8691 | LR: 0.000250 | Estimated time: 65.17
Train loss on 50 batch: 0.151133
Train loss on 100 batch: 0.149674
Train loss on 150 batch: 0.176327
: Epoch: 12 | Training Loss: 0.157675 | Val. Loss: 0.339204 | Val. Kappa Score: 0.8694 | LR: 0.000250 | Estimated time: 65.21
Train loss on 50 batch: 0.172834
Train loss on 100 batch: 0.184867
Train loss on 150 batch: 0.146722
: Epoch: 13 | Training Loss: 0.165021 | Val. Loss: 0.314763 | Val. Kappa Score: 0.8713 | LR: 0.000250 | Estimated time: 66.03
Train loss on 50 batch: 0.148109
Train loss on 100 batch: 0.137343
Train loss on 150 batch: 0.178443
best-train-loss: 0.158933
best-valid-loss: 0.280708
best-kappa: 0.8728
: Epoch: 14 | Training Loss: 0.158933 | Val. Loss: 0.280708 | Val. Kappa Score: 0.8728 | LR: 0.000250 | Estimated time: 66.18
Train loss on 50 batch: 0.177750
Train loss on 100 batch: 0.142636
Train loss on 150 batch: 0.154175
: Epoch: 15 | Training Loss: 0.151906 | Val. Loss: 0.304598 | Val. Kappa Score: 0.8735 | LR: 0.000250 | Estimated time: 65.73
Train loss on 50 batch: 0.156514
Train loss on 100 batch: 0.146697
Train loss on 150 batch: 0.141646
best-train-loss: 0.146328
best-valid-loss: 0.279754
best-kappa: 0.8746
: Epoch: 16 | Training Loss: 0.146328 | Val. Loss: 0.279754 | Val. Kappa Score: 0.8746 | LR: 0.000250 | Estimated time: 65.82
Train loss on 50 batch: 0.178617
Train loss on 100 batch: 0.146875
Train loss on 150 batch: 0.125444
: Epoch: 17 | Training Loss: 0.146716 | Val. Loss: 0.308950 | Val. Kappa Score: 0.8755 | LR: 0.000250 | Estimated time: 66.04
Train loss on 50 batch: 0.144624
Train loss on 100 batch: 0.123354
Train loss on 150 batch: 0.155291
: Epoch: 18 | Training Loss: 0.142687 | Val. Loss: 0.310776 | Val. Kappa Score: 0.8767 | LR: 0.000250 | Estimated time: 65.83
Train loss on 50 batch: 0.122805
Train loss on 100 batch: 0.131699
Train loss on 150 batch: 0.142738
: Epoch: 19 | Training Loss: 0.137673 | Val. Loss: 0.299327 | Val. Kappa Score: 0.8777 | LR: 0.000125 | Estimated time: 66.45
Train loss on 50 batch: 0.119754
Train loss on 100 batch: 0.139866
Train loss on 150 batch: 0.127622
: Epoch: 20 | Training Loss: 0.128882 | Val. Loss: 0.285071 | Val. Kappa Score: 0.8789 | LR: 0.000125 | Estimated time: 65.74
Train loss on 50 batch: 0.119718
Train loss on 100 batch: 0.118365
Train loss on 150 batch: 0.119986
: Epoch: 21 | Training Loss: 0.148724 | Val. Loss: 0.287403 | Val. Kappa Score: 0.8800 | LR: 0.000125 | Estimated time: 65.09
Train loss on 50 batch: 0.103198
Train loss on 100 batch: 0.124523
Train loss on 150 batch: 0.134681
: Epoch: 22 | Training Loss: 0.115955 | Val. Loss: 0.282125 | Val. Kappa Score: 0.8809 | LR: 0.000063 | Estimated time: 65.50
Train loss on 50 batch: 0.112091
Train loss on 100 batch: 0.127754
Train loss on 150 batch: 0.103461
: Epoch: 23 | Training Loss: 0.111950 | Val. Loss: 0.284438 | Val. Kappa Score: 0.8813 | LR: 0.000063 | Estimated time: 66.74
Train loss on 50 batch: 0.112597
Train loss on 100 batch: 0.123769
Train loss on 150 batch: 0.102630
: Epoch: 24 | Training Loss: 0.169757 | Val. Loss: 0.285863 | Val. Kappa Score: 0.8815 | LR: 0.000063 | Estimated time: 65.84
Train loss on 50 batch: 0.119444
Train loss on 100 batch: 0.110400
Train loss on 150 batch: 0.127214
: Epoch: 25 | Training Loss: 0.118288 | Val. Loss: 0.279951 | Val. Kappa Score: 0.8822 | LR: 0.000031 | Estimated time: 65.38
Train loss on 50 batch: 0.128776
Train loss on 100 batch: 0.092103
Train loss on 150 batch: 0.104400
best-train-loss: 0.127442
best-valid-loss: 0.278270
best-kappa: 0.8827
: Epoch: 26 | Training Loss: 0.127442 | Val. Loss: 0.278270 | Val. Kappa Score: 0.8827 | LR: 0.000031 | Estimated time: 66.62
Train loss on 50 batch: 0.116031
Train loss on 100 batch: 0.123669
Train loss on 150 batch: 0.103325
: Epoch: 27 | Training Loss: 0.116624 | Val. Loss: 0.284880 | Val. Kappa Score: 0.8830 | LR: 0.000031 | Estimated time: 66.10
Train loss on 50 batch: 0.137574
Train loss on 100 batch: 0.108869
Train loss on 150 batch: 0.087300
: Epoch: 28 | Training Loss: 0.114477 | Val. Loss: 0.280727 | Val. Kappa Score: 0.8834 | LR: 0.000031 | Estimated time: 66.04
Train loss on 50 batch: 0.092295
Train loss on 100 batch: 0.120962
Train loss on 150 batch: 0.111634
: Epoch: 29 | Training Loss: 0.110233 | Val. Loss: 0.283218 | Val. Kappa Score: 0.8835 | LR: 0.000016 | Estimated time: 65.26
Train loss on 50 batch: 0.111738
Train loss on 100 batch: 0.110078
Train loss on 150 batch: 0.104363
: Epoch: 30 | Training Loss: 0.109122 | Val. Loss: 0.283587 | Val. Kappa Score: 0.8839 | LR: 0.000016 | Estimated time: 66.22
Train loss on 50 batch: 0.096617
Train loss on 100 batch: 0.121743
Train loss on 150 batch: 0.097690
: Epoch: 31 | Training Loss: 0.111418 | Val. Loss: 0.283432 | Val. Kappa Score: 0.8845 | LR: 0.000016 | Estimated time: 66.11
Train loss on 50 batch: 0.097625
Train loss on 100 batch: 0.105044
Train loss on 150 batch: 0.117277
: Epoch: 32 | Training Loss: 0.105970 | Val. Loss: 0.286420 | Val. Kappa Score: 0.8847 | LR: 0.000008 | Estimated time: 65.61
Train loss on 50 batch: 0.113912
Train loss on 100 batch: 0.102559
Train loss on 150 batch: 0.101977
: Epoch: 33 | Training Loss: 0.110208 | Val. Loss: 0.284986 | Val. Kappa Score: 0.8854 | LR: 0.000008 | Estimated time: 66.15
Train loss on 50 batch: 0.104582
Train loss on 100 batch: 0.115851
Train loss on 150 batch: 0.114923
: Epoch: 34 | Training Loss: 0.109500 | Val. Loss: 0.285201 | Val. Kappa Score: 0.8854 | LR: 0.000008 | Estimated time: 65.40
Train loss on 50 batch: 0.102010
Train loss on 100 batch: 0.112248
Train loss on 150 batch: 0.097136
: Epoch: 35 | Training Loss: 0.111506 | Val. Loss: 0.280987 | Val. Kappa Score: 0.8855 | LR: 0.000004 | Estimated time: 66.08
Train loss on 50 batch: 0.084521
Train loss on 100 batch: 0.115403
Train loss on 150 batch: 0.102126
: Epoch: 36 | Training Loss: 0.106789 | Val. Loss: 0.281858 | Val. Kappa Score: 0.8858 | LR: 0.000004 | Estimated time: 68.97
time_estimated: 2376.60
n-epochs: 36
time_estimated: 2376.65
----------------------------------------

Experiment N: 177: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 06:54:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51701f98>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.153126
Train loss on 100 batch: 0.143977
Train loss on 150 batch: 0.175271
best-train-loss: 0.154990
best-valid-loss: 0.355181
best-kappa: 0.8447
: Epoch: 1 | Training Loss: 0.154990 | Val. Loss: 0.355181 | Val. Kappa Score: 0.8447 | LR: 0.001000 | Estimated time: 69.16
Train loss on 50 batch: 0.141088
Train loss on 100 batch: 0.132821
Train loss on 150 batch: 0.124263
best-train-loss: 0.138199
best-valid-loss: 0.298216
best-kappa: 0.8690
: Epoch: 2 | Training Loss: 0.138199 | Val. Loss: 0.298216 | Val. Kappa Score: 0.8690 | LR: 0.001000 | Estimated time: 67.16
Train loss on 50 batch: 0.127064
Train loss on 100 batch: 0.147531
Train loss on 150 batch: 0.145091
: Epoch: 3 | Training Loss: 0.142260 | Val. Loss: 0.763676 | Val. Kappa Score: 0.8097 | LR: 0.001000 | Estimated time: 68.46
Train loss on 50 batch: 0.129654
Train loss on 100 batch: 0.139352
Train loss on 150 batch: 0.141181
: Epoch: 4 | Training Loss: 0.154522 | Val. Loss: 0.462213 | Val. Kappa Score: 0.8232 | LR: 0.001000 | Estimated time: 66.06
Train loss on 50 batch: 0.174587
Train loss on 100 batch: 0.151541
Train loss on 150 batch: 0.110777
: Epoch: 5 | Training Loss: 0.148184 | Val. Loss: 0.321520 | Val. Kappa Score: 0.8342 | LR: 0.000500 | Estimated time: 69.30
Train loss on 50 batch: 0.136031
Train loss on 100 batch: 0.127142
Train loss on 150 batch: 0.096321
: Epoch: 6 | Training Loss: 0.113674 | Val. Loss: 0.328810 | Val. Kappa Score: 0.8410 | LR: 0.000500 | Estimated time: 66.66
Train loss on 50 batch: 0.103187
Train loss on 100 batch: 0.097596
Train loss on 150 batch: 0.105528
: Epoch: 7 | Training Loss: 0.101655 | Val. Loss: 0.333859 | Val. Kappa Score: 0.8468 | LR: 0.000500 | Estimated time: 66.52
Train loss on 50 batch: 0.101970
Train loss on 100 batch: 0.115820
Train loss on 150 batch: 0.095266
: Epoch: 8 | Training Loss: 0.105877 | Val. Loss: 0.304820 | Val. Kappa Score: 0.8527 | LR: 0.000250 | Estimated time: 68.12
Train loss on 50 batch: 0.090533
Train loss on 100 batch: 0.101006
Train loss on 150 batch: 0.095634
: Epoch: 9 | Training Loss: 0.093221 | Val. Loss: 0.299501 | Val. Kappa Score: 0.8571 | LR: 0.000250 | Estimated time: 66.36
Train loss on 50 batch: 0.084102
Train loss on 100 batch: 0.089106
Train loss on 150 batch: 0.080884
best-train-loss: 0.116445
best-valid-loss: 0.289906
best-kappa: 0.8607
: Epoch: 10 | Training Loss: 0.116445 | Val. Loss: 0.289906 | Val. Kappa Score: 0.8607 | LR: 0.000250 | Estimated time: 66.95
Train loss on 50 batch: 0.100745
Train loss on 100 batch: 0.086262
Train loss on 150 batch: 0.091148
best-train-loss: 0.093491
best-valid-loss: 0.280567
best-kappa: 0.8642
: Epoch: 11 | Training Loss: 0.093491 | Val. Loss: 0.280567 | Val. Kappa Score: 0.8642 | LR: 0.000250 | Estimated time: 66.58
Train loss on 50 batch: 0.084574
Train loss on 100 batch: 0.093275
Train loss on 150 batch: 0.083199
: Epoch: 12 | Training Loss: 0.086205 | Val. Loss: 0.317173 | Val. Kappa Score: 0.8658 | LR: 0.000250 | Estimated time: 65.47
Train loss on 50 batch: 0.085146
Train loss on 100 batch: 0.104065
Train loss on 150 batch: 0.079927
: Epoch: 13 | Training Loss: 0.087656 | Val. Loss: 0.328463 | Val. Kappa Score: 0.8678 | LR: 0.000250 | Estimated time: 66.03
Train loss on 50 batch: 0.087809
Train loss on 100 batch: 0.078733
Train loss on 150 batch: 0.097068
: Epoch: 14 | Training Loss: 0.087585 | Val. Loss: 0.291634 | Val. Kappa Score: 0.8694 | LR: 0.000125 | Estimated time: 66.25
Train loss on 50 batch: 0.087657
Train loss on 100 batch: 0.066420
Train loss on 150 batch: 0.074036
: Epoch: 15 | Training Loss: 0.076601 | Val. Loss: 0.298230 | Val. Kappa Score: 0.8713 | LR: 0.000125 | Estimated time: 68.75
Train loss on 50 batch: 0.072369
Train loss on 100 batch: 0.073619
Train loss on 150 batch: 0.077602
: Epoch: 16 | Training Loss: 0.074322 | Val. Loss: 0.297869 | Val. Kappa Score: 0.8725 | LR: 0.000125 | Estimated time: 66.92
Train loss on 50 batch: 0.098629
Train loss on 100 batch: 0.081849
Train loss on 150 batch: 0.062847
: Epoch: 17 | Training Loss: 0.077837 | Val. Loss: 0.284448 | Val. Kappa Score: 0.8744 | LR: 0.000063 | Estimated time: 66.74
Train loss on 50 batch: 0.084031
Train loss on 100 batch: 0.060534
Train loss on 150 batch: 0.075688
: Epoch: 18 | Training Loss: 0.073887 | Val. Loss: 0.284814 | Val. Kappa Score: 0.8759 | LR: 0.000063 | Estimated time: 66.27
Train loss on 50 batch: 0.072241
Train loss on 100 batch: 0.074569
Train loss on 150 batch: 0.071971
: Epoch: 19 | Training Loss: 0.070572 | Val. Loss: 0.294223 | Val. Kappa Score: 0.8768 | LR: 0.000063 | Estimated time: 69.95
Train loss on 50 batch: 0.072629
Train loss on 100 batch: 0.074516
Train loss on 150 batch: 0.075180
: Epoch: 20 | Training Loss: 0.075020 | Val. Loss: 0.283761 | Val. Kappa Score: 0.8783 | LR: 0.000031 | Estimated time: 67.88
Train loss on 50 batch: 0.071538
Train loss on 100 batch: 0.061706
Train loss on 150 batch: 0.072246
: Epoch: 21 | Training Loss: 0.085019 | Val. Loss: 0.284399 | Val. Kappa Score: 0.8795 | LR: 0.000031 | Estimated time: 66.16
time_estimated: 1413.20
n-epochs: 21
time_estimated: 1413.25
----------------------------------------

Experiment N: 178: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 12:11:53
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb51701f60>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.553626
Train loss on 100 batch: 0.432884
Train loss on 150 batch: 0.437169
best-train-loss: 0.447471
best-valid-loss: 0.505656
best-kappa: 0.8113
: Epoch: 1 | Training Loss: 0.447471 | Val. Loss: 0.505656 | Val. Kappa Score: 0.8113 | LR: 0.001000 | Estimated time: 98.66
Train loss on 50 batch: 0.350497
Train loss on 100 batch: 0.353396
Train loss on 150 batch: 0.302686
best-train-loss: 0.380819
best-valid-loss: 0.341177
best-kappa: 0.8388
: Epoch: 2 | Training Loss: 0.380819 | Val. Loss: 0.341177 | Val. Kappa Score: 0.8388 | LR: 0.001000 | Estimated time: 98.30
Train loss on 50 batch: 0.374339
Train loss on 100 batch: 0.333969
Train loss on 150 batch: 0.325234
: Epoch: 3 | Training Loss: 0.334909 | Val. Loss: 0.516686 | Val. Kappa Score: 0.8400 | LR: 0.001000 | Estimated time: 96.41
Train loss on 50 batch: 0.309070
Train loss on 100 batch: 0.331133
Train loss on 150 batch: 0.292018
: Epoch: 4 | Training Loss: 0.403193 | Val. Loss: 0.410579 | Val. Kappa Score: 0.8433 | LR: 0.001000 | Estimated time: 95.05
Train loss on 50 batch: 0.372109
Train loss on 100 batch: 0.375388
Train loss on 150 batch: 0.245420
: Epoch: 5 | Training Loss: 0.323539 | Val. Loss: 0.360950 | Val. Kappa Score: 0.8454 | LR: 0.000500 | Estimated time: 97.64
Train loss on 50 batch: 0.261058
Train loss on 100 batch: 0.289228
Train loss on 150 batch: 0.249717
: Epoch: 6 | Training Loss: 0.257044 | Val. Loss: 0.398799 | Val. Kappa Score: 0.8467 | LR: 0.000500 | Estimated time: 95.88
Train loss on 50 batch: 0.276205
Train loss on 100 batch: 0.242733
Train loss on 150 batch: 0.243520
best-train-loss: 0.255200
best-valid-loss: 0.336879
best-kappa: 0.8513
: Epoch: 7 | Training Loss: 0.255200 | Val. Loss: 0.336879 | Val. Kappa Score: 0.8513 | LR: 0.000500 | Estimated time: 95.07
Train loss on 50 batch: 0.253082
Train loss on 100 batch: 0.269087
Train loss on 150 batch: 0.187755
: Epoch: 8 | Training Loss: 0.256998 | Val. Loss: 0.341501 | Val. Kappa Score: 0.8546 | LR: 0.000500 | Estimated time: 94.71
Train loss on 50 batch: 0.229137
Train loss on 100 batch: 0.269428
Train loss on 150 batch: 0.247178
: Epoch: 9 | Training Loss: 0.246419 | Val. Loss: 0.343823 | Val. Kappa Score: 0.8561 | LR: 0.000500 | Estimated time: 93.99
Train loss on 50 batch: 0.222300
Train loss on 100 batch: 0.225335
Train loss on 150 batch: 0.250956
: Epoch: 10 | Training Loss: 0.298769 | Val. Loss: 0.351377 | Val. Kappa Score: 0.8563 | LR: 0.000250 | Estimated time: 94.28
Train loss on 50 batch: 0.207190
Train loss on 100 batch: 0.223767
Train loss on 150 batch: 0.225681
best-train-loss: 0.222671
best-valid-loss: 0.328208
best-kappa: 0.8571
: Epoch: 11 | Training Loss: 0.222671 | Val. Loss: 0.328208 | Val. Kappa Score: 0.8571 | LR: 0.000250 | Estimated time: 94.86
Train loss on 50 batch: 0.192354
Train loss on 100 batch: 0.210657
Train loss on 150 batch: 0.216077
: Epoch: 12 | Training Loss: 0.202427 | Val. Loss: 0.336127 | Val. Kappa Score: 0.8586 | LR: 0.000250 | Estimated time: 94.83
Train loss on 50 batch: 0.178724
Train loss on 100 batch: 0.240080
Train loss on 150 batch: 0.190712
: Epoch: 13 | Training Loss: 0.215260 | Val. Loss: 0.364409 | Val. Kappa Score: 0.8598 | LR: 0.000250 | Estimated time: 94.83
Train loss on 50 batch: 0.191402
Train loss on 100 batch: 0.174241
Train loss on 150 batch: 0.218385
best-train-loss: 0.207828
best-valid-loss: 0.319639
best-kappa: 0.8611
: Epoch: 14 | Training Loss: 0.207828 | Val. Loss: 0.319639 | Val. Kappa Score: 0.8611 | LR: 0.000250 | Estimated time: 93.14
Train loss on 50 batch: 0.206429
Train loss on 100 batch: 0.173209
Train loss on 150 batch: 0.183324
: Epoch: 15 | Training Loss: 0.200772 | Val. Loss: 0.335561 | Val. Kappa Score: 0.8616 | LR: 0.000250 | Estimated time: 94.77
Train loss on 50 batch: 0.191663
Train loss on 100 batch: 0.170811
Train loss on 150 batch: 0.190095
: Epoch: 16 | Training Loss: 0.186703 | Val. Loss: 0.334171 | Val. Kappa Score: 0.8619 | LR: 0.000250 | Estimated time: 95.63
Train loss on 50 batch: 0.233298
Train loss on 100 batch: 0.182743
Train loss on 150 batch: 0.171731
: Epoch: 17 | Training Loss: 0.185366 | Val. Loss: 0.336334 | Val. Kappa Score: 0.8625 | LR: 0.000125 | Estimated time: 94.14
Train loss on 50 batch: 0.185392
Train loss on 100 batch: 0.153064
Train loss on 150 batch: 0.173844
: Epoch: 18 | Training Loss: 0.174019 | Val. Loss: 0.324575 | Val. Kappa Score: 0.8635 | LR: 0.000125 | Estimated time: 93.37
Train loss on 50 batch: 0.149628
Train loss on 100 batch: 0.162104
Train loss on 150 batch: 0.170936
: Epoch: 19 | Training Loss: 0.164877 | Val. Loss: 0.335154 | Val. Kappa Score: 0.8639 | LR: 0.000125 | Estimated time: 94.88
Train loss on 50 batch: 0.159527
Train loss on 100 batch: 0.188964
Train loss on 150 batch: 0.170334
: Epoch: 20 | Training Loss: 0.169751 | Val. Loss: 0.353846 | Val. Kappa Score: 0.8640 | LR: 0.000063 | Estimated time: 94.85
Train loss on 50 batch: 0.151959
Train loss on 100 batch: 0.155125
Train loss on 150 batch: 0.155996
: Epoch: 21 | Training Loss: 0.190322 | Val. Loss: 0.330162 | Val. Kappa Score: 0.8649 | LR: 0.000063 | Estimated time: 94.53
Train loss on 50 batch: 0.138690
Train loss on 100 batch: 0.157544
Train loss on 150 batch: 0.167294
: Epoch: 22 | Training Loss: 0.150996 | Val. Loss: 0.336842 | Val. Kappa Score: 0.8657 | LR: 0.000063 | Estimated time: 95.63
Train loss on 50 batch: 0.148940
Train loss on 100 batch: 0.152467
Train loss on 150 batch: 0.157396
: Epoch: 23 | Training Loss: 0.156647 | Val. Loss: 0.335615 | Val. Kappa Score: 0.8658 | LR: 0.000031 | Estimated time: 95.69
Train loss on 50 batch: 0.160454
Train loss on 100 batch: 0.151564
Train loss on 150 batch: 0.148106
: Epoch: 24 | Training Loss: 0.205025 | Val. Loss: 0.332609 | Val. Kappa Score: 0.8658 | LR: 0.000031 | Estimated time: 95.36
time_estimated: 2288.26
n-epochs: 24
time_estimated: 2288.32
----------------------------------------

Experiment N: 179: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 18:38:07
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb55ac0438>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.456448
Train loss on 100 batch: 0.383669
Train loss on 150 batch: 0.367633
best-train-loss: 0.381182
best-valid-loss: 0.393639
best-kappa: 0.8629
: Epoch: 1 | Training Loss: 0.381182 | Val. Loss: 0.393639 | Val. Kappa Score: 0.8629 | LR: 0.001000 | Estimated time: 71.97
Train loss on 50 batch: 0.301688
Train loss on 100 batch: 0.281646
Train loss on 150 batch: 0.267755
best-train-loss: 0.309470
best-valid-loss: 0.335143
best-kappa: 0.8664
: Epoch: 2 | Training Loss: 0.309470 | Val. Loss: 0.335143 | Val. Kappa Score: 0.8664 | LR: 0.001000 | Estimated time: 70.65
Train loss on 50 batch: 0.298762
Train loss on 100 batch: 0.297004
Train loss on 150 batch: 0.250475
: Epoch: 3 | Training Loss: 0.269429 | Val. Loss: 0.355899 | Val. Kappa Score: 0.8725 | LR: 0.001000 | Estimated time: 71.68
Train loss on 50 batch: 0.281041
Train loss on 100 batch: 0.249411
Train loss on 150 batch: 0.259009
: Epoch: 4 | Training Loss: 0.316319 | Val. Loss: 0.368134 | Val. Kappa Score: 0.8718 | LR: 0.001000 | Estimated time: 72.44
Train loss on 50 batch: 0.351875
Train loss on 100 batch: 0.321807
Train loss on 150 batch: 0.196164
: Epoch: 5 | Training Loss: 0.280927 | Val. Loss: 0.414327 | Val. Kappa Score: 0.8683 | LR: 0.000500 | Estimated time: 72.44
Train loss on 50 batch: 0.210392
Train loss on 100 batch: 0.203260
Train loss on 150 batch: 0.218370
best-train-loss: 0.202186
best-valid-loss: 0.323842
best-kappa: 0.8683
: Epoch: 6 | Training Loss: 0.202186 | Val. Loss: 0.323842 | Val. Kappa Score: 0.8683 | LR: 0.000500 | Estimated time: 71.68
Train loss on 50 batch: 0.207599
Train loss on 100 batch: 0.185487
Train loss on 150 batch: 0.195636
: Epoch: 7 | Training Loss: 0.201200 | Val. Loss: 0.375049 | Val. Kappa Score: 0.8688 | LR: 0.000500 | Estimated time: 71.65
Train loss on 50 batch: 0.194016
Train loss on 100 batch: 0.215338
Train loss on 150 batch: 0.151133
best-train-loss: 0.184440
best-valid-loss: 0.298387
best-kappa: 0.8713
: Epoch: 8 | Training Loss: 0.184440 | Val. Loss: 0.298387 | Val. Kappa Score: 0.8713 | LR: 0.000500 | Estimated time: 71.92
Train loss on 50 batch: 0.171878
Train loss on 100 batch: 0.206620
Train loss on 150 batch: 0.179930
: Epoch: 9 | Training Loss: 0.180718 | Val. Loss: 0.303953 | Val. Kappa Score: 0.8733 | LR: 0.000500 | Estimated time: 72.19
Train loss on 50 batch: 0.158099
Train loss on 100 batch: 0.149446
Train loss on 150 batch: 0.184817
best-train-loss: 0.192578
best-valid-loss: 0.291272
best-kappa: 0.8740
: Epoch: 10 | Training Loss: 0.192578 | Val. Loss: 0.291272 | Val. Kappa Score: 0.8740 | LR: 0.000500 | Estimated time: 72.12
Train loss on 50 batch: 0.172249
Train loss on 100 batch: 0.151404
Train loss on 150 batch: 0.160214
: Epoch: 11 | Training Loss: 0.173593 | Val. Loss: 0.301961 | Val. Kappa Score: 0.8748 | LR: 0.000500 | Estimated time: 72.12
Train loss on 50 batch: 0.133574
Train loss on 100 batch: 0.144803
Train loss on 150 batch: 0.157882
: Epoch: 12 | Training Loss: 0.146449 | Val. Loss: 0.317656 | Val. Kappa Score: 0.8750 | LR: 0.000500 | Estimated time: 72.45
Train loss on 50 batch: 0.145560
Train loss on 100 batch: 0.167694
Train loss on 150 batch: 0.148556
: Epoch: 13 | Training Loss: 0.149241 | Val. Loss: 0.327481 | Val. Kappa Score: 0.8751 | LR: 0.000250 | Estimated time: 71.79
Train loss on 50 batch: 0.124618
Train loss on 100 batch: 0.120063
Train loss on 150 batch: 0.149181
: Epoch: 14 | Training Loss: 0.131834 | Val. Loss: 0.297493 | Val. Kappa Score: 0.8763 | LR: 0.000250 | Estimated time: 71.96
Train loss on 50 batch: 0.126518
Train loss on 100 batch: 0.118939
Train loss on 150 batch: 0.113837
: Epoch: 15 | Training Loss: 0.116703 | Val. Loss: 0.339247 | Val. Kappa Score: 0.8764 | LR: 0.000250 | Estimated time: 72.75
Train loss on 50 batch: 0.107891
Train loss on 100 batch: 0.109622
Train loss on 150 batch: 0.116875
: Epoch: 16 | Training Loss: 0.112611 | Val. Loss: 0.324793 | Val. Kappa Score: 0.8760 | LR: 0.000125 | Estimated time: 72.38
Train loss on 50 batch: 0.140344
Train loss on 100 batch: 0.113269
Train loss on 150 batch: 0.097721
: Epoch: 17 | Training Loss: 0.112239 | Val. Loss: 0.321904 | Val. Kappa Score: 0.8762 | LR: 0.000125 | Estimated time: 71.50
Train loss on 50 batch: 0.123654
Train loss on 100 batch: 0.089006
Train loss on 150 batch: 0.105236
: Epoch: 18 | Training Loss: 0.106885 | Val. Loss: 0.307170 | Val. Kappa Score: 0.8773 | LR: 0.000125 | Estimated time: 72.86
Train loss on 50 batch: 0.085814
Train loss on 100 batch: 0.109407
Train loss on 150 batch: 0.103223
: Epoch: 19 | Training Loss: 0.099076 | Val. Loss: 0.304755 | Val. Kappa Score: 0.8779 | LR: 0.000063 | Estimated time: 73.31
Train loss on 50 batch: 0.106734
Train loss on 100 batch: 0.095888
Train loss on 150 batch: 0.098256
: Epoch: 20 | Training Loss: 0.100695 | Val. Loss: 0.303240 | Val. Kappa Score: 0.8787 | LR: 0.000063 | Estimated time: 72.50
time_estimated: 1443.84
n-epochs: 20
time_estimated: 1443.90
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:21:23
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54607f28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:22:23
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54607f28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:29:18
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5460af28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:34:42
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb5460aef0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:35:26
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609fd0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:36:09
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f60>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:36:40
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f60>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:37:31
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f60>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:37:44
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb545ba080>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 19:38:58
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f60>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.03 23:34:36
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54607f28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:21:39
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb545ba0b8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:22:07
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f28>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:22:24
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9d0961d0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:22:44
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb54609f60>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 00:25:10
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb546e2630>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 00:25:44
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb546e2630>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 00:28:13
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb546e35f8>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 00:28:58
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb546e55c0>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.368031
Train loss on 100 batch: 1.061309
Train loss on 150 batch: 1.019472
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 00:33:17
data-type: new
loss-func: CrossEntropyLoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb546e35f8>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.368031
Train loss on 100 batch: 1.061309
Train loss on 150 batch: 1.019472
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:43:00
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b00dd8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:43:34
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691e48>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:44:53
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691eb8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:46:19
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691e48>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:47:05
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691e48>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:47:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b01908>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.336477
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:48:24
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691eb8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:50:38
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691eb8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:51:28
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691e80>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:52:13
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50691e80>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.591421
Train loss on 100 batch: 1.452479
Train loss on 150 batch: 1.465944
----------------------------------------

Experiment N: 180: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 00:53:33
data-type: new
loss-func: AdaptiveLossFunction()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50693da0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.591421
Train loss on 100 batch: 1.452479
Train loss on 150 batch: 1.465944
best-train-loss: 1.481627
best-valid-loss: 1.447626
best-kappa: 0.6968
: Epoch: 1 | Training Loss: 1.481627 | Val. Loss: 1.447626 | Val. Kappa Score: 0.6968 | LR: 0.001000 | Estimated time: 67.04
----------------------------------------

Experiment N: 181: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 06:55:30
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02978>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.236304
Train loss on 100 batch: 1.453923
Train loss on 150 batch: 1.212498
Train loss on 200 batch: 1.243868
Train loss on 250 batch: 1.358825
Train loss on 300 batch: 1.143442
Train loss on 350 batch: 1.109360
Train loss on 400 batch: 1.082411
Train loss on 450 batch: 1.173704
Train loss on 500 batch: 1.144443
Train loss on 550 batch: 1.087570
best-train-loss: 1.295508
best-valid-loss: 1.085257
best-kappa: 0.6352
: Epoch: 1 | Training Loss: 1.295508 | Val. Loss: 1.085257 | Val. Kappa Score: 0.6352 | LR: 0.001000 | Estimated time: 164.26
Train loss on 50 batch: 1.100079
Train loss on 100 batch: 0.989734
Train loss on 150 batch: 1.053750
Train loss on 200 batch: 0.983808
Train loss on 250 batch: 1.010306
Train loss on 300 batch: 0.933661
Train loss on 350 batch: 0.940173
Train loss on 400 batch: 0.928978
Train loss on 450 batch: 0.903356
Train loss on 500 batch: 0.979514
Train loss on 550 batch: 0.886440
best-train-loss: 0.957380
best-valid-loss: 0.858208
best-kappa: 0.6452
: Epoch: 2 | Training Loss: 0.957380 | Val. Loss: 0.858208 | Val. Kappa Score: 0.6452 | LR: 0.001000 | Estimated time: 162.57
Train loss on 50 batch: 0.914902
Train loss on 100 batch: 0.897809
Train loss on 150 batch: 0.891038
Train loss on 200 batch: 0.815393
Train loss on 250 batch: 0.907609
Train loss on 300 batch: 0.915900
Train loss on 350 batch: 0.775571
Train loss on 400 batch: 0.820558
Train loss on 450 batch: 0.938614
Train loss on 500 batch: 0.795141
Train loss on 550 batch: 0.729495
: Epoch: 3 | Training Loss: 0.839644 | Val. Loss: 0.917982 | Val. Kappa Score: 0.6625 | LR: 0.001000 | Estimated time: 162.74
Train loss on 50 batch: 0.817676
Train loss on 100 batch: 0.851679
Train loss on 150 batch: 0.849203
Train loss on 200 batch: 0.837274
Train loss on 250 batch: 0.848301
Train loss on 300 batch: 0.822009
Train loss on 350 batch: 0.845969
Train loss on 400 batch: 0.776326
Train loss on 450 batch: 0.806327
Train loss on 500 batch: 0.689818
Train loss on 550 batch: 0.779979
best-train-loss: 0.791754
best-valid-loss: 0.730086
best-kappa: 0.6850
: Epoch: 4 | Training Loss: 0.791754 | Val. Loss: 0.730086 | Val. Kappa Score: 0.6850 | LR: 0.001000 | Estimated time: 163.42
Train loss on 50 batch: 0.764689
Train loss on 100 batch: 0.828202
Train loss on 150 batch: 0.798025
Train loss on 200 batch: 0.816006
Train loss on 250 batch: 0.800258
Train loss on 300 batch: 0.782114
Train loss on 350 batch: 0.623476
Train loss on 400 batch: 0.746976
Train loss on 450 batch: 0.817752
Train loss on 500 batch: 0.721007
Train loss on 550 batch: 0.737090
best-train-loss: 0.755142
best-valid-loss: 0.652675
best-kappa: 0.7025
: Epoch: 5 | Training Loss: 0.755142 | Val. Loss: 0.652675 | Val. Kappa Score: 0.7025 | LR: 0.001000 | Estimated time: 163.73
Train loss on 50 batch: 0.693828
Train loss on 100 batch: 0.752228
Train loss on 150 batch: 0.691355
Train loss on 200 batch: 0.729591
Train loss on 250 batch: 0.679570
Train loss on 300 batch: 0.620458
Train loss on 350 batch: 0.769496
Train loss on 400 batch: 0.747054
Train loss on 450 batch: 0.658342
Train loss on 500 batch: 0.766741
Train loss on 550 batch: 0.767230
: Epoch: 6 | Training Loss: 0.724208 | Val. Loss: 1.375176 | Val. Kappa Score: 0.6817 | LR: 0.001000 | Estimated time: 163.38
Train loss on 50 batch: 0.758044
Train loss on 100 batch: 0.727510
Train loss on 150 batch: 0.725030
Train loss on 200 batch: 0.730915
Train loss on 250 batch: 0.774174
Train loss on 300 batch: 0.624413
Train loss on 350 batch: 0.750750
Train loss on 400 batch: 0.703890
Train loss on 450 batch: 0.651092
Train loss on 500 batch: 0.688690
Train loss on 550 batch: 0.719086
: Epoch: 7 | Training Loss: 0.725917 | Val. Loss: 0.775833 | Val. Kappa Score: 0.6875 | LR: 0.001000 | Estimated time: 163.34
Train loss on 50 batch: 0.734767
Train loss on 100 batch: 0.728031
Train loss on 150 batch: 0.648513
Train loss on 200 batch: 0.700709
Train loss on 250 batch: 0.676281
Train loss on 300 batch: 0.640652
Train loss on 350 batch: 0.677385
Train loss on 400 batch: 0.756642
Train loss on 450 batch: 0.660891
Train loss on 500 batch: 0.648966
Train loss on 550 batch: 0.749565
: Epoch: 8 | Training Loss: 0.732283 | Val. Loss: 0.679580 | Val. Kappa Score: 0.6970 | LR: 0.000500 | Estimated time: 162.89
Train loss on 50 batch: 0.676940
Train loss on 100 batch: 0.548655
Train loss on 150 batch: 0.586504
Train loss on 200 batch: 0.588305
Train loss on 250 batch: 0.519266
Train loss on 300 batch: 0.563001
Train loss on 350 batch: 0.614093
Train loss on 400 batch: 0.654961
Train loss on 450 batch: 0.557683
Train loss on 500 batch: 0.583213
Train loss on 550 batch: 0.578231
best-train-loss: 0.582543
best-valid-loss: 0.558355
best-kappa: 0.7073
: Epoch: 9 | Training Loss: 0.582543 | Val. Loss: 0.558355 | Val. Kappa Score: 0.7073 | LR: 0.000500 | Estimated time: 162.67
Train loss on 50 batch: 0.601313
Train loss on 100 batch: 0.542992
Train loss on 150 batch: 0.677563
Train loss on 200 batch: 0.555025
Train loss on 250 batch: 0.618182
Train loss on 300 batch: 0.566520
Train loss on 350 batch: 0.569746
Train loss on 400 batch: 0.579371
Train loss on 450 batch: 0.501080
Train loss on 500 batch: 0.543123
Train loss on 550 batch: 0.529057
best-train-loss: 0.582959
best-valid-loss: 0.520509
best-kappa: 0.7179
: Epoch: 10 | Training Loss: 0.582959 | Val. Loss: 0.520509 | Val. Kappa Score: 0.7179 | LR: 0.000500 | Estimated time: 163.80
Train loss on 50 batch: 0.515840
Train loss on 100 batch: 0.513994
Train loss on 150 batch: 0.549039
Train loss on 200 batch: 0.520278
Train loss on 250 batch: 0.548483
Train loss on 300 batch: 0.567908
Train loss on 350 batch: 0.480518
Train loss on 400 batch: 0.602921
Train loss on 450 batch: 0.545481
Train loss on 500 batch: 0.664697
Train loss on 550 batch: 0.545818
: Epoch: 11 | Training Loss: 0.538672 | Val. Loss: 0.533595 | Val. Kappa Score: 0.7269 | LR: 0.000500 | Estimated time: 162.93
Train loss on 50 batch: 0.511120
Train loss on 100 batch: 0.526598
Train loss on 150 batch: 0.515169
Train loss on 200 batch: 0.510484
Train loss on 250 batch: 0.500372
Train loss on 300 batch: 0.470599
Train loss on 350 batch: 0.584271
Train loss on 400 batch: 0.539682
Train loss on 450 batch: 0.503741
Train loss on 500 batch: 0.541202
Train loss on 550 batch: 0.574746
: Epoch: 12 | Training Loss: 0.582000 | Val. Loss: 0.526150 | Val. Kappa Score: 0.7350 | LR: 0.000500 | Estimated time: 163.52
Train loss on 50 batch: 0.539220
Train loss on 100 batch: 0.508129
Train loss on 150 batch: 0.521082
Train loss on 200 batch: 0.581663
Train loss on 250 batch: 0.453642
Train loss on 300 batch: 0.577239
Train loss on 350 batch: 0.493174
Train loss on 400 batch: 0.596248
Train loss on 450 batch: 0.540357
Train loss on 500 batch: 0.551489
Train loss on 550 batch: 0.535119
: Epoch: 13 | Training Loss: 0.521804 | Val. Loss: 0.535999 | Val. Kappa Score: 0.7410 | LR: 0.000250 | Estimated time: 163.32
Train loss on 50 batch: 0.500602
Train loss on 100 batch: 0.462010
Train loss on 150 batch: 0.479930
Train loss on 200 batch: 0.455482
Train loss on 250 batch: 0.504256
Train loss on 300 batch: 0.481240
Train loss on 350 batch: 0.474874
Train loss on 400 batch: 0.486810
Train loss on 450 batch: 0.476824
Train loss on 500 batch: 0.485579
Train loss on 550 batch: 0.480679
best-train-loss: 0.500594
best-valid-loss: 0.503631
best-kappa: 0.7469
: Epoch: 14 | Training Loss: 0.500594 | Val. Loss: 0.503631 | Val. Kappa Score: 0.7469 | LR: 0.000250 | Estimated time: 163.28
Train loss on 50 batch: 0.502981
Train loss on 100 batch: 0.451748
Train loss on 150 batch: 0.475677
Train loss on 200 batch: 0.478740
Train loss on 250 batch: 0.476256
Train loss on 300 batch: 0.454995
Train loss on 350 batch: 0.460469
Train loss on 400 batch: 0.411787
Train loss on 450 batch: 0.438884
Train loss on 500 batch: 0.472690
Train loss on 550 batch: 0.430425
best-train-loss: 0.493315
best-valid-loss: 0.459463
best-kappa: 0.7534
: Epoch: 15 | Training Loss: 0.493315 | Val. Loss: 0.459463 | Val. Kappa Score: 0.7534 | LR: 0.000250 | Estimated time: 164.10
Train loss on 50 batch: 0.479821
Train loss on 100 batch: 0.507306
Train loss on 150 batch: 0.439995
Train loss on 200 batch: 0.463478
Train loss on 250 batch: 0.430918
Train loss on 300 batch: 0.446466
Train loss on 350 batch: 0.509323
Train loss on 400 batch: 0.433037
Train loss on 450 batch: 0.422036
Train loss on 500 batch: 0.504379
Train loss on 550 batch: 0.450703
: Epoch: 16 | Training Loss: 0.455645 | Val. Loss: 0.516323 | Val. Kappa Score: 0.7577 | LR: 0.000250 | Estimated time: 163.04
Train loss on 50 batch: 0.453351
Train loss on 100 batch: 0.424390
Train loss on 150 batch: 0.497343
Train loss on 200 batch: 0.412602
Train loss on 250 batch: 0.482109
Train loss on 300 batch: 0.441595
Train loss on 350 batch: 0.441842
Train loss on 400 batch: 0.427434
Train loss on 450 batch: 0.437115
Train loss on 500 batch: 0.408869
Train loss on 550 batch: 0.456618
best-train-loss: 0.429631
best-valid-loss: 0.457047
best-kappa: 0.7621
: Epoch: 17 | Training Loss: 0.429631 | Val. Loss: 0.457047 | Val. Kappa Score: 0.7621 | LR: 0.000250 | Estimated time: 163.11
Train loss on 50 batch: 0.391880
Train loss on 100 batch: 0.442626
Train loss on 150 batch: 0.447142
Train loss on 200 batch: 0.418631
Train loss on 250 batch: 0.403410
Train loss on 300 batch: 0.364875
Train loss on 350 batch: 0.450801
Train loss on 400 batch: 0.458268
Train loss on 450 batch: 0.480440
Train loss on 500 batch: 0.410150
Train loss on 550 batch: 0.438241
: Epoch: 18 | Training Loss: 0.436593 | Val. Loss: 0.465682 | Val. Kappa Score: 0.7666 | LR: 0.000250 | Estimated time: 162.73
Train loss on 50 batch: 0.404662
Train loss on 100 batch: 0.429807
Train loss on 150 batch: 0.428782
Train loss on 200 batch: 0.429679
Train loss on 250 batch: 0.493647
Train loss on 300 batch: 0.423465
Train loss on 350 batch: 0.456645
Train loss on 400 batch: 0.411039
Train loss on 450 batch: 0.390156
Train loss on 500 batch: 0.383190
Train loss on 550 batch: 0.485667
: Epoch: 19 | Training Loss: 0.434852 | Val. Loss: 0.466982 | Val. Kappa Score: 0.7703 | LR: 0.000250 | Estimated time: 162.75
Train loss on 50 batch: 0.480643
Train loss on 100 batch: 0.418837
Train loss on 150 batch: 0.379140
Train loss on 200 batch: 0.450753
Train loss on 250 batch: 0.435004
Train loss on 300 batch: 0.450726
Train loss on 350 batch: 0.404381
Train loss on 400 batch: 0.413927
Train loss on 450 batch: 0.494467
Train loss on 500 batch: 0.433540
Train loss on 550 batch: 0.426962
best-train-loss: 0.445430
best-valid-loss: 0.454840
best-kappa: 0.7735
: Epoch: 20 | Training Loss: 0.445430 | Val. Loss: 0.454840 | Val. Kappa Score: 0.7735 | LR: 0.000250 | Estimated time: 163.82
Train loss on 50 batch: 0.400142
Train loss on 100 batch: 0.489819
Train loss on 150 batch: 0.437446
Train loss on 200 batch: 0.426214
Train loss on 250 batch: 0.420668
Train loss on 300 batch: 0.404975
Train loss on 350 batch: 0.429796
Train loss on 400 batch: 0.387192
Train loss on 450 batch: 0.440695
Train loss on 500 batch: 0.337950
Train loss on 550 batch: 0.388705
: Epoch: 21 | Training Loss: 0.408878 | Val. Loss: 0.461770 | Val. Kappa Score: 0.7765 | LR: 0.000250 | Estimated time: 164.02
Train loss on 50 batch: 0.402568
Train loss on 100 batch: 0.397751
Train loss on 150 batch: 0.429409
Train loss on 200 batch: 0.376634
Train loss on 250 batch: 0.374184
Train loss on 300 batch: 0.389424
Train loss on 350 batch: 0.423190
Train loss on 400 batch: 0.465553
Train loss on 450 batch: 0.422057
Train loss on 500 batch: 0.424015
Train loss on 550 batch: 0.414579
: Epoch: 22 | Training Loss: 0.411737 | Val. Loss: 0.511398 | Val. Kappa Score: 0.7794 | LR: 0.000250 | Estimated time: 163.68
Train loss on 50 batch: 0.407298
Train loss on 100 batch: 0.342137
Train loss on 150 batch: 0.418320
Train loss on 200 batch: 0.384989
Train loss on 250 batch: 0.342521
Train loss on 300 batch: 0.424455
Train loss on 350 batch: 0.459781
Train loss on 400 batch: 0.369089
Train loss on 450 batch: 0.397060
Train loss on 500 batch: 0.411161
Train loss on 550 batch: 0.420976
: Epoch: 23 | Training Loss: 0.387990 | Val. Loss: 0.517887 | Val. Kappa Score: 0.7813 | LR: 0.000125 | Estimated time: 163.53
Train loss on 50 batch: 0.399791
Train loss on 100 batch: 0.327324
Train loss on 150 batch: 0.388631
Train loss on 200 batch: 0.383580
Train loss on 250 batch: 0.362542
Train loss on 300 batch: 0.395446
Train loss on 350 batch: 0.340076
Train loss on 400 batch: 0.377561
Train loss on 450 batch: 0.392046
Train loss on 500 batch: 0.370425
Train loss on 550 batch: 0.358238
best-train-loss: 0.385878
best-valid-loss: 0.450446
best-kappa: 0.7836
: Epoch: 24 | Training Loss: 0.385878 | Val. Loss: 0.450446 | Val. Kappa Score: 0.7836 | LR: 0.000125 | Estimated time: 163.58
Train loss on 50 batch: 0.385665
Train loss on 100 batch: 0.403322
Train loss on 150 batch: 0.385120
Train loss on 200 batch: 0.379701
Train loss on 250 batch: 0.350970
Train loss on 300 batch: 0.360566
Train loss on 350 batch: 0.366164
Train loss on 400 batch: 0.319695
Train loss on 450 batch: 0.397411
Train loss on 500 batch: 0.364875
Train loss on 550 batch: 0.373747
best-train-loss: 0.367513
best-valid-loss: 0.445766
best-kappa: 0.7861
: Epoch: 25 | Training Loss: 0.367513 | Val. Loss: 0.445766 | Val. Kappa Score: 0.7861 | LR: 0.000125 | Estimated time: 164.08
Train loss on 50 batch: 0.371646
Train loss on 100 batch: 0.370084
Train loss on 150 batch: 0.373706
Train loss on 200 batch: 0.361299
Train loss on 250 batch: 0.357622
Train loss on 300 batch: 0.365839
Train loss on 350 batch: 0.330778
Train loss on 400 batch: 0.361715
Train loss on 450 batch: 0.362375
Train loss on 500 batch: 0.324740
Train loss on 550 batch: 0.340070
best-train-loss: 0.352910
best-valid-loss: 0.435343
best-kappa: 0.7883
: Epoch: 26 | Training Loss: 0.352910 | Val. Loss: 0.435343 | Val. Kappa Score: 0.7883 | LR: 0.000125 | Estimated time: 163.79
Train loss on 50 batch: 0.363808
Train loss on 100 batch: 0.352879
Train loss on 150 batch: 0.337311
Train loss on 200 batch: 0.328071
Train loss on 250 batch: 0.394518
Train loss on 300 batch: 0.411894
Train loss on 350 batch: 0.366927
Train loss on 400 batch: 0.358957
Train loss on 450 batch: 0.338000
Train loss on 500 batch: 0.343448
Train loss on 550 batch: 0.344669
: Epoch: 27 | Training Loss: 0.352290 | Val. Loss: 0.438622 | Val. Kappa Score: 0.7903 | LR: 0.000125 | Estimated time: 162.44
Train loss on 50 batch: 0.406560
Train loss on 100 batch: 0.326907
Train loss on 150 batch: 0.364182
Train loss on 200 batch: 0.316132
Train loss on 250 batch: 0.305842
Train loss on 300 batch: 0.333214
Train loss on 350 batch: 0.336501
Train loss on 400 batch: 0.382957
Train loss on 450 batch: 0.346483
Train loss on 500 batch: 0.349272
Train loss on 550 batch: 0.354461
: Epoch: 28 | Training Loss: 0.352035 | Val. Loss: 0.449149 | Val. Kappa Score: 0.7923 | LR: 0.000125 | Estimated time: 163.17
Train loss on 50 batch: 0.354576
Train loss on 100 batch: 0.326583
Train loss on 150 batch: 0.335113
Train loss on 200 batch: 0.316906
Train loss on 250 batch: 0.309967
Train loss on 300 batch: 0.317350
Train loss on 350 batch: 0.356033
Train loss on 400 batch: 0.354492
Train loss on 450 batch: 0.389305
Train loss on 500 batch: 0.370914
Train loss on 550 batch: 0.346772
: Epoch: 29 | Training Loss: 0.345387 | Val. Loss: 0.443195 | Val. Kappa Score: 0.7942 | LR: 0.000063 | Estimated time: 163.23
Train loss on 50 batch: 0.336883
Train loss on 100 batch: 0.316689
Train loss on 150 batch: 0.367700
Train loss on 200 batch: 0.295110
Train loss on 250 batch: 0.315336
Train loss on 300 batch: 0.315468
Train loss on 350 batch: 0.363993
Train loss on 400 batch: 0.306109
Train loss on 450 batch: 0.370233
Train loss on 500 batch: 0.311585
Train loss on 550 batch: 0.310400
best-train-loss: 0.355451
best-valid-loss: 0.431400
best-kappa: 0.7960
: Epoch: 30 | Training Loss: 0.355451 | Val. Loss: 0.431400 | Val. Kappa Score: 0.7960 | LR: 0.000063 | Estimated time: 162.80
Train loss on 50 batch: 0.325920
Train loss on 100 batch: 0.352860
Train loss on 150 batch: 0.330050
Train loss on 200 batch: 0.293657
Train loss on 250 batch: 0.317918
Train loss on 300 batch: 0.291073
Train loss on 350 batch: 0.371121
Train loss on 400 batch: 0.320677
Train loss on 450 batch: 0.305487
Train loss on 500 batch: 0.330276
Train loss on 550 batch: 0.348204
: Epoch: 31 | Training Loss: 0.321108 | Val. Loss: 0.469160 | Val. Kappa Score: 0.7973 | LR: 0.000063 | Estimated time: 162.34
Train loss on 50 batch: 0.310883
Train loss on 100 batch: 0.333176
Train loss on 150 batch: 0.317550
Train loss on 200 batch: 0.308043
Train loss on 250 batch: 0.306262
Train loss on 300 batch: 0.360489
Train loss on 350 batch: 0.310875
Train loss on 400 batch: 0.304213
Train loss on 450 batch: 0.305268
Train loss on 500 batch: 0.372566
Train loss on 550 batch: 0.280100
: Epoch: 32 | Training Loss: 0.316082 | Val. Loss: 0.435724 | Val. Kappa Score: 0.7988 | LR: 0.000063 | Estimated time: 162.73
Train loss on 50 batch: 0.291124
Train loss on 100 batch: 0.273896
Train loss on 150 batch: 0.323827
Train loss on 200 batch: 0.326886
Train loss on 250 batch: 0.307652
Train loss on 300 batch: 0.301725
Train loss on 350 batch: 0.320329
Train loss on 400 batch: 0.330478
Train loss on 450 batch: 0.302720
Train loss on 500 batch: 0.320374
Train loss on 550 batch: 0.319619
: Epoch: 33 | Training Loss: 0.321681 | Val. Loss: 0.440457 | Val. Kappa Score: 0.8003 | LR: 0.000031 | Estimated time: 162.89
Train loss on 50 batch: 0.272556
Train loss on 100 batch: 0.314130
Train loss on 150 batch: 0.339866
Train loss on 200 batch: 0.321370
Train loss on 250 batch: 0.301614
Train loss on 300 batch: 0.281140
Train loss on 350 batch: 0.285034
Train loss on 400 batch: 0.297257
Train loss on 450 batch: 0.339454
Train loss on 500 batch: 0.275664
Train loss on 550 batch: 0.311007
: Epoch: 34 | Training Loss: 0.306388 | Val. Loss: 0.442778 | Val. Kappa Score: 0.8016 | LR: 0.000031 | Estimated time: 163.29
Train loss on 50 batch: 0.316769
Train loss on 100 batch: 0.290080
Train loss on 150 batch: 0.323960
Train loss on 200 batch: 0.296235
Train loss on 250 batch: 0.334337
Train loss on 300 batch: 0.344670
Train loss on 350 batch: 0.269496
Train loss on 400 batch: 0.281297
Train loss on 450 batch: 0.320699
Train loss on 500 batch: 0.303167
Train loss on 550 batch: 0.291918
: Epoch: 35 | Training Loss: 0.316279 | Val. Loss: 0.436618 | Val. Kappa Score: 0.8029 | LR: 0.000031 | Estimated time: 163.60
Train loss on 50 batch: 0.274425
Train loss on 100 batch: 0.287318
Train loss on 150 batch: 0.291156
Train loss on 200 batch: 0.286125
Train loss on 250 batch: 0.326772
Train loss on 300 batch: 0.322084
Train loss on 350 batch: 0.282180
Train loss on 400 batch: 0.309664
Train loss on 450 batch: 0.307757
Train loss on 500 batch: 0.299309
Train loss on 550 batch: 0.268178
: Epoch: 36 | Training Loss: 0.299839 | Val. Loss: 0.437943 | Val. Kappa Score: 0.8042 | LR: 0.000016 | Estimated time: 162.44
Train loss on 50 batch: 0.296884
Train loss on 100 batch: 0.307456
Train loss on 150 batch: 0.299150
Train loss on 200 batch: 0.331278
Train loss on 250 batch: 0.314758
Train loss on 300 batch: 0.268166
Train loss on 350 batch: 0.299382
Train loss on 400 batch: 0.281728
Train loss on 450 batch: 0.292252
Train loss on 500 batch: 0.315342
Train loss on 550 batch: 0.303543
: Epoch: 37 | Training Loss: 0.346731 | Val. Loss: 0.437794 | Val. Kappa Score: 0.8053 | LR: 0.000016 | Estimated time: 162.16
Train loss on 50 batch: 0.361141
Train loss on 100 batch: 0.275730
Train loss on 150 batch: 0.263313
Train loss on 200 batch: 0.331396
Train loss on 250 batch: 0.283584
Train loss on 300 batch: 0.317877
Train loss on 350 batch: 0.308619
Train loss on 400 batch: 0.301961
Train loss on 450 batch: 0.290823
Train loss on 500 batch: 0.254089
Train loss on 550 batch: 0.330326
: Epoch: 38 | Training Loss: 0.298045 | Val. Loss: 0.438625 | Val. Kappa Score: 0.8065 | LR: 0.000016 | Estimated time: 162.92
Train loss on 50 batch: 0.292977
Train loss on 100 batch: 0.298586
Train loss on 150 batch: 0.263992
Train loss on 200 batch: 0.296218
Train loss on 250 batch: 0.293211
Train loss on 300 batch: 0.333531
Train loss on 350 batch: 0.311595
Train loss on 400 batch: 0.294404
Train loss on 450 batch: 0.305792
Train loss on 500 batch: 0.274143
Train loss on 550 batch: 0.295966
: Epoch: 39 | Training Loss: 0.305784 | Val. Loss: 0.435094 | Val. Kappa Score: 0.8076 | LR: 0.000008 | Estimated time: 162.63
Train loss on 50 batch: 0.333607
Train loss on 100 batch: 0.306516
Train loss on 150 batch: 0.261894
Train loss on 200 batch: 0.316546
Train loss on 250 batch: 0.298620
Train loss on 300 batch: 0.273832
Train loss on 350 batch: 0.324914
Train loss on 400 batch: 0.309665
Train loss on 450 batch: 0.252690
Train loss on 500 batch: 0.259736
Train loss on 550 batch: 0.287990
: Epoch: 40 | Training Loss: 0.294618 | Val. Loss: 0.434586 | Val. Kappa Score: 0.8086 | LR: 0.000008 | Estimated time: 163.10
time_estimated: 6531.22
n-epochs: 40
time_estimated: 6531.27
----------------------------------------

Experiment N: 182: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 16:10:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02978>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.336477
Train loss on 100 batch: 0.804905
Train loss on 150 batch: 0.786735
best-train-loss: 0.912162
best-valid-loss: 0.629013
best-kappa: 0.7984
: Epoch: 1 | Training Loss: 0.912162 | Val. Loss: 0.629013 | Val. Kappa Score: 0.7984 | LR: 0.001000 | Estimated time: 63.11
----------------------------------------

Experiment N: 183: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 16:12:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02940>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.336477
Train loss on 100 batch: 0.804905
Train loss on 150 batch: 0.786735
best-train-loss: 0.912162
best-valid-loss: 0.629013
best-kappa: 0.7984
: Epoch: 1 | Training Loss: 0.912162 | Val. Loss: 0.629013 | Val. Kappa Score: 0.7984 | LR: 0.001000 | Estimated time: 67.84
Train loss on 50 batch: 0.607059
Train loss on 100 batch: 0.610488
Train loss on 150 batch: 0.492838
: Epoch: 2 | Training Loss: 0.605755 | Val. Loss: 0.965878 | Val. Kappa Score: 0.7205 | LR: 0.001000 | Estimated time: 62.52
Train loss on 50 batch: 0.552625
Train loss on 100 batch: 0.593129
Train loss on 150 batch: 0.542122
----------------------------------------

Experiment N: 184: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 16:15:35
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02940>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 184: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 16:16:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b03908>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 184: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:17:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be3e10>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321773
Train loss on 100 batch: 0.875027
Train loss on 150 batch: 0.739589
best-train-loss: 0.905650
best-valid-loss: 1.618762
best-kappa: 0.7136
: Epoch: 1 | Training Loss: 0.905650 | Val. Loss: 1.618762 | Val. Kappa Score: 0.7136 | LR: 0.001000 | Estimated time: 48.47
Train loss on 50 batch: 0.569125
Train loss on 100 batch: 0.594278
Train loss on 150 batch: 0.483998
----------------------------------------

Experiment N: 185: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:19:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be2e48>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321773
Train loss on 100 batch: 0.875028
Train loss on 150 batch: 0.739595
best-train-loss: 0.905653
best-valid-loss: 1.619120
best-kappa: 0.7136
: Epoch: 1 | Training Loss: 0.905653 | Val. Loss: 1.619120 | Val. Kappa Score: 0.7136 | LR: 0.001000 | Estimated time: 47.61
----------------------------------------

Experiment N: 186: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:20:46
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be2e48>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321772
Train loss on 100 batch: 0.875024
Train loss on 150 batch: 0.739599
best-train-loss: 0.905654
best-valid-loss: 1.625251
best-kappa: 0.7133
: Epoch: 1 | Training Loss: 0.905654 | Val. Loss: 1.625251 | Val. Kappa Score: 0.7133 | LR: 0.001000 | Estimated time: 50.56
----------------------------------------

Experiment N: 187: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:21:54
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be2eb8>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321772
Train loss on 100 batch: 0.875025
Train loss on 150 batch: 0.739595
best-train-loss: 0.905650
best-valid-loss: 1.622176
best-kappa: 0.7136
: Epoch: 1 | Training Loss: 0.905650 | Val. Loss: 1.622176 | Val. Kappa Score: 0.7136 | LR: 0.001000 | Estimated time: 47.64
----------------------------------------

Experiment N: 188: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:23:16
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be3e10>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321773
Train loss on 100 batch: 0.875026
Train loss on 150 batch: 0.739597
best-train-loss: 0.905646
best-valid-loss: 1.618833
best-kappa: 0.7136
: Epoch: 1 | Training Loss: 0.905646 | Val. Loss: 1.618833 | Val. Kappa Score: 0.7136 | LR: 0.001000 | Estimated time: 48.74
----------------------------------------

Experiment N: 189: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.04 16:24:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be3e10>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.321773
Train loss on 100 batch: 0.875028
Train loss on 150 batch: 0.739595
best-train-loss: 0.905653
best-valid-loss: 1.619120
best-kappa: 0.7136
: Epoch: 1 | Training Loss: 0.905653 | Val. Loss: 1.619120 | Val. Kappa Score: 0.7136 | LR: 0.001000 | Estimated time: 48.96
----------------------------------------

Experiment N: 190: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.09.04 19:53:04
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9c508080>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.543517
Train loss on 100 batch: 0.431424
Train loss on 150 batch: 0.399755
best-train-loss: 0.428008
best-valid-loss: 0.419388
best-kappa: 0.8388
: Epoch: 1 | Training Loss: 0.428008 | Val. Loss: 0.419388 | Val. Kappa Score: 0.8388 | LR: 0.001000 | Estimated time: 44.71
Train loss on 50 batch: 0.360922
Train loss on 100 batch: 0.354558
Train loss on 150 batch: 0.322524
: Epoch: 2 | Training Loss: 0.365285 | Val. Loss: 0.421377 | Val. Kappa Score: 0.8416 | LR: 0.001000 | Estimated time: 43.89
Train loss on 50 batch: 0.335266
Train loss on 100 batch: 0.356365
Train loss on 150 batch: 0.367081
best-train-loss: 0.340639
best-valid-loss: 0.361047
best-kappa: 0.8496
: Epoch: 3 | Training Loss: 0.340639 | Val. Loss: 0.361047 | Val. Kappa Score: 0.8496 | LR: 0.001000 | Estimated time: 43.77
Train loss on 50 batch: 0.366083
Train loss on 100 batch: 0.344328
Train loss on 150 batch: 0.327223
: Epoch: 4 | Training Loss: 0.391434 | Val. Loss: 0.388563 | Val. Kappa Score: 0.8542 | LR: 0.001000 | Estimated time: 43.80
Train loss on 50 batch: 0.377714
Train loss on 100 batch: 0.383187
Train loss on 150 batch: 0.277114
best-train-loss: 0.334468
best-valid-loss: 0.356181
best-kappa: 0.8572
: Epoch: 5 | Training Loss: 0.334468 | Val. Loss: 0.356181 | Val. Kappa Score: 0.8572 | LR: 0.001000 | Estimated time: 44.36
Train loss on 50 batch: 0.316983
Train loss on 100 batch: 0.332839
Train loss on 150 batch: 0.294261
: Epoch: 6 | Training Loss: 0.298512 | Val. Loss: 0.426607 | Val. Kappa Score: 0.8554 | LR: 0.001000 | Estimated time: 44.11
Train loss on 50 batch: 0.320186
Train loss on 100 batch: 0.296483
Train loss on 150 batch: 0.276047
best-train-loss: 0.297321
best-valid-loss: 0.351938
best-kappa: 0.8574
: Epoch: 7 | Training Loss: 0.297321 | Val. Loss: 0.351938 | Val. Kappa Score: 0.8574 | LR: 0.001000 | Estimated time: 44.13
Train loss on 50 batch: 0.248237
Train loss on 100 batch: 0.319478
Train loss on 150 batch: 0.249554
: Epoch: 8 | Training Loss: 0.276391 | Val. Loss: 0.369760 | Val. Kappa Score: 0.8589 | LR: 0.001000 | Estimated time: 43.39
Train loss on 50 batch: 0.282178
Train loss on 100 batch: 0.325386
Train loss on 150 batch: 0.291682
: Epoch: 9 | Training Loss: 0.293095 | Val. Loss: 0.368312 | Val. Kappa Score: 0.8596 | LR: 0.001000 | Estimated time: 43.79
Train loss on 50 batch: 0.284467
Train loss on 100 batch: 0.285665
Train loss on 150 batch: 0.281543
: Epoch: 10 | Training Loss: 0.338254 | Val. Loss: 0.371970 | Val. Kappa Score: 0.8598 | LR: 0.000500 | Estimated time: 44.25
Train loss on 50 batch: 0.263951
Train loss on 100 batch: 0.287651
Train loss on 150 batch: 0.262138
best-train-loss: 0.279884
best-valid-loss: 0.327123
best-kappa: 0.8611
: Epoch: 11 | Training Loss: 0.279884 | Val. Loss: 0.327123 | Val. Kappa Score: 0.8611 | LR: 0.000500 | Estimated time: 44.16
Train loss on 50 batch: 0.238238
Train loss on 100 batch: 0.222831
Train loss on 150 batch: 0.259568
: Epoch: 12 | Training Loss: 0.243998 | Val. Loss: 0.359663 | Val. Kappa Score: 0.8612 | LR: 0.000500 | Estimated time: 44.34
Train loss on 50 batch: 0.236695
Train loss on 100 batch: 0.265504
Train loss on 150 batch: 0.230141
: Epoch: 13 | Training Loss: 0.245135 | Val. Loss: 0.386806 | Val. Kappa Score: 0.8618 | LR: 0.000500 | Estimated time: 44.56
Train loss on 50 batch: 0.247723
Train loss on 100 batch: 0.222364
Train loss on 150 batch: 0.247460
best-train-loss: 0.247575
best-valid-loss: 0.310090
best-kappa: 0.8633
: Epoch: 14 | Training Loss: 0.247575 | Val. Loss: 0.310090 | Val. Kappa Score: 0.8633 | LR: 0.000500 | Estimated time: 44.24
Train loss on 50 batch: 0.267647
Train loss on 100 batch: 0.243763
Train loss on 150 batch: 0.237570
best-train-loss: 0.250994
best-valid-loss: 0.304972
best-kappa: 0.8642
: Epoch: 15 | Training Loss: 0.250994 | Val. Loss: 0.304972 | Val. Kappa Score: 0.8642 | LR: 0.000500 | Estimated time: 43.84
Train loss on 50 batch: 0.237048
Train loss on 100 batch: 0.213567
Train loss on 150 batch: 0.229161
: Epoch: 16 | Training Loss: 0.233528 | Val. Loss: 0.313359 | Val. Kappa Score: 0.8644 | LR: 0.000500 | Estimated time: 43.98
Train loss on 50 batch: 0.273474
Train loss on 100 batch: 0.228765
Train loss on 150 batch: 0.200345
best-train-loss: 0.227532
best-valid-loss: 0.294805
best-kappa: 0.8654
: Epoch: 17 | Training Loss: 0.227532 | Val. Loss: 0.294805 | Val. Kappa Score: 0.8654 | LR: 0.000500 | Estimated time: 44.88
Train loss on 50 batch: 0.220681
Train loss on 100 batch: 0.192821
Train loss on 150 batch: 0.244030
: Epoch: 18 | Training Loss: 0.217625 | Val. Loss: 0.322573 | Val. Kappa Score: 0.8666 | LR: 0.000500 | Estimated time: 44.36
Train loss on 50 batch: 0.196524
Train loss on 100 batch: 0.240083
Train loss on 150 batch: 0.237429
best-train-loss: 0.232504
best-valid-loss: 0.283464
best-kappa: 0.8676
: Epoch: 19 | Training Loss: 0.232504 | Val. Loss: 0.283464 | Val. Kappa Score: 0.8676 | LR: 0.000500 | Estimated time: 44.26
Train loss on 50 batch: 0.225726
Train loss on 100 batch: 0.241071
Train loss on 150 batch: 0.210311
: Epoch: 20 | Training Loss: 0.223034 | Val. Loss: 0.333351 | Val. Kappa Score: 0.8684 | LR: 0.000500 | Estimated time: 43.32
Train loss on 50 batch: 0.215410
Train loss on 100 batch: 0.202453
Train loss on 150 batch: 0.249900
: Epoch: 21 | Training Loss: 0.240573 | Val. Loss: 0.289250 | Val. Kappa Score: 0.8697 | LR: 0.000500 | Estimated time: 43.73
Train loss on 50 batch: 0.229418
Train loss on 100 batch: 0.234716
Train loss on 150 batch: 0.237253
: Epoch: 22 | Training Loss: 0.227603 | Val. Loss: 0.325421 | Val. Kappa Score: 0.8708 | LR: 0.000250 | Estimated time: 43.95
Train loss on 50 batch: 0.212532
Train loss on 100 batch: 0.226973
Train loss on 150 batch: 0.221281
: Epoch: 23 | Training Loss: 0.218284 | Val. Loss: 0.293555 | Val. Kappa Score: 0.8715 | LR: 0.000250 | Estimated time: 43.22
Train loss on 50 batch: 0.217145
Train loss on 100 batch: 0.213697
Train loss on 150 batch: 0.188162
: Epoch: 24 | Training Loss: 0.236305 | Val. Loss: 0.295471 | Val. Kappa Score: 0.8721 | LR: 0.000250 | Estimated time: 44.23
Train loss on 50 batch: 0.192790
Train loss on 100 batch: 0.201978
Train loss on 150 batch: 0.212774
: Epoch: 25 | Training Loss: 0.209268 | Val. Loss: 0.290198 | Val. Kappa Score: 0.8731 | LR: 0.000125 | Estimated time: 43.77
Train loss on 50 batch: 0.196175
Train loss on 100 batch: 0.167327
Train loss on 150 batch: 0.223957
: Epoch: 26 | Training Loss: 0.201789 | Val. Loss: 0.284031 | Val. Kappa Score: 0.8741 | LR: 0.000125 | Estimated time: 44.33
Train loss on 50 batch: 0.212483
Train loss on 100 batch: 0.228283
Train loss on 150 batch: 0.193623
: Epoch: 27 | Training Loss: 0.202245 | Val. Loss: 0.288325 | Val. Kappa Score: 0.8750 | LR: 0.000125 | Estimated time: 44.50
Train loss on 50 batch: 0.209070
Train loss on 100 batch: 0.179182
Train loss on 150 batch: 0.166848
: Epoch: 28 | Training Loss: 0.189120 | Val. Loss: 0.288740 | Val. Kappa Score: 0.8753 | LR: 0.000063 | Estimated time: 44.26
Train loss on 50 batch: 0.156174
Train loss on 100 batch: 0.218960
Train loss on 150 batch: 0.203228
: Epoch: 29 | Training Loss: 0.189284 | Val. Loss: 0.286017 | Val. Kappa Score: 0.8757 | LR: 0.000063 | Estimated time: 43.50
time_estimated: 1279.60
n-epochs: 29
time_estimated: 1279.66
----------------------------------------

Experiment N: 191: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.09.04 20:15:49
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9c5080b8>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.163160
Train loss on 100 batch: 0.939585
Train loss on 150 batch: 0.770766
Train loss on 200 batch: 0.781082
Train loss on 250 batch: 0.874752
Train loss on 300 batch: 0.775548
Train loss on 350 batch: 0.781792
Train loss on 400 batch: 0.781166
Train loss on 450 batch: 0.741318
Train loss on 500 batch: 0.672402
Train loss on 550 batch: 0.781536
best-train-loss: 0.798258
best-valid-loss: 1.142014
best-kappa: 0.6458
: Epoch: 1 | Training Loss: 0.798258 | Val. Loss: 1.142014 | Val. Kappa Score: 0.6458 | LR: 0.001000 | Estimated time: 98.05
Train loss on 50 batch: 0.688636
Train loss on 100 batch: 0.706241
Train loss on 150 batch: 0.713815
Train loss on 200 batch: 0.675898
Train loss on 250 batch: 0.741227
Train loss on 300 batch: 0.673410
Train loss on 350 batch: 0.700539
Train loss on 400 batch: 0.671315
Train loss on 450 batch: 0.699807
Train loss on 500 batch: 0.659548
Train loss on 550 batch: 0.628457
best-train-loss: 0.679989
best-valid-loss: 0.639058
best-kappa: 0.7079
: Epoch: 2 | Training Loss: 0.679989 | Val. Loss: 0.639058 | Val. Kappa Score: 0.7079 | LR: 0.001000 | Estimated time: 95.49
Train loss on 50 batch: 0.631499
Train loss on 100 batch: 0.635822
Train loss on 150 batch: 0.572668
Train loss on 200 batch: 0.609297
Train loss on 250 batch: 0.626184
Train loss on 300 batch: 0.634520
Train loss on 350 batch: 0.632054
Train loss on 400 batch: 0.644226
Train loss on 450 batch: 0.730748
Train loss on 500 batch: 0.693486
Train loss on 550 batch: 0.595610
best-train-loss: 0.639649
best-valid-loss: 0.588849
best-kappa: 0.7325
: Epoch: 3 | Training Loss: 0.639649 | Val. Loss: 0.588849 | Val. Kappa Score: 0.7325 | LR: 0.001000 | Estimated time: 96.11
Train loss on 50 batch: 0.602852
Train loss on 100 batch: 0.674818
Train loss on 150 batch: 0.639580
Train loss on 200 batch: 0.626603
Train loss on 250 batch: 0.677758
Train loss on 300 batch: 0.635171
Train loss on 350 batch: 0.727982
Train loss on 400 batch: 0.575934
Train loss on 450 batch: 0.633517
Train loss on 500 batch: 0.589481
Train loss on 550 batch: 0.589198
: Epoch: 4 | Training Loss: 0.632261 | Val. Loss: 0.835112 | Val. Kappa Score: 0.7271 | LR: 0.001000 | Estimated time: 95.44
Train loss on 50 batch: 0.599603
Train loss on 100 batch: 0.681645
Train loss on 150 batch: 0.686340
Train loss on 200 batch: 0.629854
Train loss on 250 batch: 0.631729
Train loss on 300 batch: 0.579780
Train loss on 350 batch: 0.587783
Train loss on 400 batch: 0.593490
Train loss on 450 batch: 0.639700
Train loss on 500 batch: 0.591023
Train loss on 550 batch: 0.620990
best-train-loss: 0.605926
best-valid-loss: 0.513837
best-kappa: 0.7457
: Epoch: 5 | Training Loss: 0.605926 | Val. Loss: 0.513837 | Val. Kappa Score: 0.7457 | LR: 0.001000 | Estimated time: 96.00
Train loss on 50 batch: 0.616954
Train loss on 100 batch: 0.623568
Train loss on 150 batch: 0.579557
Train loss on 200 batch: 0.623738
Train loss on 250 batch: 0.588629
Train loss on 300 batch: 0.556221
Train loss on 350 batch: 0.568411
Train loss on 400 batch: 0.608230
Train loss on 450 batch: 0.581589
Train loss on 500 batch: 0.513189
Train loss on 550 batch: 0.577467
: Epoch: 6 | Training Loss: 0.572856 | Val. Loss: 0.700102 | Val. Kappa Score: 0.7486 | LR: 0.001000 | Estimated time: 96.52
Train loss on 50 batch: 0.536941
Train loss on 100 batch: 0.561159
Train loss on 150 batch: 0.606603
Train loss on 200 batch: 0.591779
Train loss on 250 batch: 0.567080
Train loss on 300 batch: 0.555582
Train loss on 350 batch: 0.628388
Train loss on 400 batch: 0.611467
Train loss on 450 batch: 0.593875
Train loss on 500 batch: 0.560762
Train loss on 550 batch: 0.644907
: Epoch: 7 | Training Loss: 0.606112 | Val. Loss: 0.558425 | Val. Kappa Score: 0.7525 | LR: 0.001000 | Estimated time: 96.81
Train loss on 50 batch: 0.579173
Train loss on 100 batch: 0.590550
Train loss on 150 batch: 0.529123
Train loss on 200 batch: 0.596164
Train loss on 250 batch: 0.558872
Train loss on 300 batch: 0.538264
Train loss on 350 batch: 0.610766
Train loss on 400 batch: 0.568766
Train loss on 450 batch: 0.576371
Train loss on 500 batch: 0.570041
Train loss on 550 batch: 0.546693
: Epoch: 8 | Training Loss: 0.591426 | Val. Loss: 0.535906 | Val. Kappa Score: 0.7602 | LR: 0.000500 | Estimated time: 99.65
Train loss on 50 batch: 0.564424
Train loss on 100 batch: 0.534242
Train loss on 150 batch: 0.575112
Train loss on 200 batch: 0.551432
Train loss on 250 batch: 0.508053
Train loss on 300 batch: 0.442897
Train loss on 350 batch: 0.585561
Train loss on 400 batch: 0.551732
Train loss on 450 batch: 0.501716
Train loss on 500 batch: 0.517889
Train loss on 550 batch: 0.546735
: Epoch: 9 | Training Loss: 0.544362 | Val. Loss: 0.523478 | Val. Kappa Score: 0.7648 | LR: 0.000500 | Estimated time: 98.21
Train loss on 50 batch: 0.538270
Train loss on 100 batch: 0.538431
Train loss on 150 batch: 0.535390
Train loss on 200 batch: 0.495123
Train loss on 250 batch: 0.560757
Train loss on 300 batch: 0.475530
Train loss on 350 batch: 0.474184
Train loss on 400 batch: 0.562296
Train loss on 450 batch: 0.537781
Train loss on 500 batch: 0.500631
Train loss on 550 batch: 0.499953
best-train-loss: 0.521025
best-valid-loss: 0.513776
best-kappa: 0.7708
: Epoch: 10 | Training Loss: 0.521025 | Val. Loss: 0.513776 | Val. Kappa Score: 0.7708 | LR: 0.000500 | Estimated time: 97.86
Train loss on 50 batch: 0.495778
Train loss on 100 batch: 0.487021
Train loss on 150 batch: 0.537204
Train loss on 200 batch: 0.463771
Train loss on 250 batch: 0.498926
Train loss on 300 batch: 0.527988
Train loss on 350 batch: 0.481568
Train loss on 400 batch: 0.518224
Train loss on 450 batch: 0.581106
Train loss on 500 batch: 0.522506
Train loss on 550 batch: 0.524359
best-train-loss: 0.520362
best-valid-loss: 0.507079
best-kappa: 0.7755
: Epoch: 11 | Training Loss: 0.520362 | Val. Loss: 0.507079 | Val. Kappa Score: 0.7755 | LR: 0.000500 | Estimated time: 99.33
Train loss on 50 batch: 0.479344
Train loss on 100 batch: 0.542275
Train loss on 150 batch: 0.493139
Train loss on 200 batch: 0.449214
Train loss on 250 batch: 0.468165
Train loss on 300 batch: 0.497204
Train loss on 350 batch: 0.503387
Train loss on 400 batch: 0.533025
Train loss on 450 batch: 0.480660
Train loss on 500 batch: 0.489191
Train loss on 550 batch: 0.530310
: Epoch: 12 | Training Loss: 0.556315 | Val. Loss: 0.513290 | Val. Kappa Score: 0.7793 | LR: 0.000500 | Estimated time: 100.26
Train loss on 50 batch: 0.551256
Train loss on 100 batch: 0.462823
Train loss on 150 batch: 0.485613
Train loss on 200 batch: 0.503541
Train loss on 250 batch: 0.513317
Train loss on 300 batch: 0.478174
Train loss on 350 batch: 0.431704
Train loss on 400 batch: 0.492659
Train loss on 450 batch: 0.522191
Train loss on 500 batch: 0.481518
Train loss on 550 batch: 0.496308
best-train-loss: 0.509591
best-valid-loss: 0.488363
best-kappa: 0.7829
: Epoch: 13 | Training Loss: 0.509591 | Val. Loss: 0.488363 | Val. Kappa Score: 0.7829 | LR: 0.000500 | Estimated time: 100.38
Train loss on 50 batch: 0.484659
Train loss on 100 batch: 0.507374
Train loss on 150 batch: 0.544598
Train loss on 200 batch: 0.468920
Train loss on 250 batch: 0.488589
Train loss on 300 batch: 0.491123
Train loss on 350 batch: 0.473460
Train loss on 400 batch: 0.468472
Train loss on 450 batch: 0.506854
Train loss on 500 batch: 0.491069
Train loss on 550 batch: 0.519415
: Epoch: 14 | Training Loss: 0.496245 | Val. Loss: 0.533934 | Val. Kappa Score: 0.7850 | LR: 0.000500 | Estimated time: 101.77
Train loss on 50 batch: 0.506181
Train loss on 100 batch: 0.480977
Train loss on 150 batch: 0.456508
Train loss on 200 batch: 0.486389
Train loss on 250 batch: 0.492558
Train loss on 300 batch: 0.510511
Train loss on 350 batch: 0.487120
Train loss on 400 batch: 0.481194
Train loss on 450 batch: 0.504213
Train loss on 500 batch: 0.454443
Train loss on 550 batch: 0.543674
: Epoch: 15 | Training Loss: 0.501421 | Val. Loss: 0.620946 | Val. Kappa Score: 0.7847 | LR: 0.000500 | Estimated time: 100.72
Train loss on 50 batch: 0.555642
Train loss on 100 batch: 0.446464
Train loss on 150 batch: 0.505649
Train loss on 200 batch: 0.500517
Train loss on 250 batch: 0.556805
Train loss on 300 batch: 0.508621
Train loss on 350 batch: 0.529741
Train loss on 400 batch: 0.440858
Train loss on 450 batch: 0.428075
Train loss on 500 batch: 0.495682
Train loss on 550 batch: 0.442788
best-train-loss: 0.502560
best-valid-loss: 0.477719
best-kappa: 0.7878
: Epoch: 16 | Training Loss: 0.502560 | Val. Loss: 0.477719 | Val. Kappa Score: 0.7878 | LR: 0.000500 | Estimated time: 100.69
Train loss on 50 batch: 0.477398
Train loss on 100 batch: 0.530296
Train loss on 150 batch: 0.463108
Train loss on 200 batch: 0.523682
Train loss on 250 batch: 0.462871
Train loss on 300 batch: 0.492753
Train loss on 350 batch: 0.518986
Train loss on 400 batch: 0.532589
Train loss on 450 batch: 0.502159
Train loss on 500 batch: 0.514424
Train loss on 550 batch: 0.413905
: Epoch: 17 | Training Loss: 0.480658 | Val. Loss: 0.491266 | Val. Kappa Score: 0.7898 | LR: 0.000500 | Estimated time: 99.77
Train loss on 50 batch: 0.442934
Train loss on 100 batch: 0.462233
Train loss on 150 batch: 0.432901
Train loss on 200 batch: 0.518887
Train loss on 250 batch: 0.476865
Train loss on 300 batch: 0.440886
Train loss on 350 batch: 0.445599
Train loss on 400 batch: 0.479288
Train loss on 450 batch: 0.553425
Train loss on 500 batch: 0.441748
Train loss on 550 batch: 0.451460
best-train-loss: 0.451231
best-valid-loss: 0.461373
best-kappa: 0.7925
: Epoch: 18 | Training Loss: 0.451231 | Val. Loss: 0.461373 | Val. Kappa Score: 0.7925 | LR: 0.000500 | Estimated time: 100.40
Train loss on 50 batch: 0.443038
Train loss on 100 batch: 0.504385
Train loss on 150 batch: 0.429090
Train loss on 200 batch: 0.478711
Train loss on 250 batch: 0.441656
Train loss on 300 batch: 0.432477
Train loss on 350 batch: 0.454979
Train loss on 400 batch: 0.517020
Train loss on 450 batch: 0.470481
Train loss on 500 batch: 0.486079
Train loss on 550 batch: 0.482239
: Epoch: 19 | Training Loss: 0.495191 | Val. Loss: 0.478775 | Val. Kappa Score: 0.7952 | LR: 0.000500 | Estimated time: 99.11
Train loss on 50 batch: 0.520539
Train loss on 100 batch: 0.468598
Train loss on 150 batch: 0.476230
Train loss on 200 batch: 0.486559
Train loss on 250 batch: 0.430111
Train loss on 300 batch: 0.497061
Train loss on 350 batch: 0.435411
Train loss on 400 batch: 0.452503
Train loss on 450 batch: 0.537030
Train loss on 500 batch: 0.461445
Train loss on 550 batch: 0.427999
best-train-loss: 0.484412
best-valid-loss: 0.457145
best-kappa: 0.7974
: Epoch: 20 | Training Loss: 0.484412 | Val. Loss: 0.457145 | Val. Kappa Score: 0.7974 | LR: 0.000500 | Estimated time: 96.95
Train loss on 50 batch: 0.483189
Train loss on 100 batch: 0.481710
Train loss on 150 batch: 0.479812
Train loss on 200 batch: 0.476958
Train loss on 250 batch: 0.464875
Train loss on 300 batch: 0.385012
Train loss on 350 batch: 0.465997
Train loss on 400 batch: 0.456373
Train loss on 450 batch: 0.461489
Train loss on 500 batch: 0.456665
Train loss on 550 batch: 0.463664
: Epoch: 21 | Training Loss: 0.470859 | Val. Loss: 0.478042 | Val. Kappa Score: 0.7990 | LR: 0.000500 | Estimated time: 96.16
Train loss on 50 batch: 0.434052
Train loss on 100 batch: 0.443162
Train loss on 150 batch: 0.432940
Train loss on 200 batch: 0.472346
Train loss on 250 batch: 0.501191
Train loss on 300 batch: 0.435276
Train loss on 350 batch: 0.429600
Train loss on 400 batch: 0.405582
Train loss on 450 batch: 0.490307
Train loss on 500 batch: 0.472892
Train loss on 550 batch: 0.472649
: Epoch: 22 | Training Loss: 0.457629 | Val. Loss: 0.796997 | Val. Kappa Score: 0.7953 | LR: 0.000500 | Estimated time: 95.58
Train loss on 50 batch: 0.448863
Train loss on 100 batch: 0.499395
Train loss on 150 batch: 0.505160
Train loss on 200 batch: 0.457908
Train loss on 250 batch: 0.393545
Train loss on 300 batch: 0.474055
Train loss on 350 batch: 0.427335
Train loss on 400 batch: 0.451633
Train loss on 450 batch: 0.434497
Train loss on 500 batch: 0.467682
Train loss on 550 batch: 0.463601
: Epoch: 23 | Training Loss: 0.456404 | Val. Loss: 0.490237 | Val. Kappa Score: 0.7970 | LR: 0.000250 | Estimated time: 99.07
Train loss on 50 batch: 0.435243
Train loss on 100 batch: 0.470070
Train loss on 150 batch: 0.401308
Train loss on 200 batch: 0.436627
Train loss on 250 batch: 0.386554
Train loss on 300 batch: 0.459372
Train loss on 350 batch: 0.409042
Train loss on 400 batch: 0.477438
Train loss on 450 batch: 0.467817
Train loss on 500 batch: 0.441909
Train loss on 550 batch: 0.428972
best-train-loss: 0.436835
best-valid-loss: 0.440270
best-kappa: 0.7990
: Epoch: 24 | Training Loss: 0.436835 | Val. Loss: 0.440270 | Val. Kappa Score: 0.7990 | LR: 0.000250 | Estimated time: 98.98
Train loss on 50 batch: 0.434450
Train loss on 100 batch: 0.418508
Train loss on 150 batch: 0.401100
Train loss on 200 batch: 0.408653
Train loss on 250 batch: 0.435808
Train loss on 300 batch: 0.434201
Train loss on 350 batch: 0.414319
Train loss on 400 batch: 0.459695
Train loss on 450 batch: 0.437916
Train loss on 500 batch: 0.440699
Train loss on 550 batch: 0.435422
: Epoch: 25 | Training Loss: 0.442170 | Val. Loss: 0.457978 | Val. Kappa Score: 0.8009 | LR: 0.000250 | Estimated time: 99.04
Train loss on 50 batch: 0.414575
Train loss on 100 batch: 0.410693
Train loss on 150 batch: 0.435966
Train loss on 200 batch: 0.436286
Train loss on 250 batch: 0.422300
Train loss on 300 batch: 0.503316
Train loss on 350 batch: 0.420778
Train loss on 400 batch: 0.436030
Train loss on 450 batch: 0.413967
Train loss on 500 batch: 0.391600
Train loss on 550 batch: 0.427182
: Epoch: 26 | Training Loss: 0.455123 | Val. Loss: 0.442923 | Val. Kappa Score: 0.8027 | LR: 0.000250 | Estimated time: 95.40
Train loss on 50 batch: 0.396095
Train loss on 100 batch: 0.410250
Train loss on 150 batch: 0.399192
Train loss on 200 batch: 0.438437
Train loss on 250 batch: 0.488369
Train loss on 300 batch: 0.422228
Train loss on 350 batch: 0.448371
Train loss on 400 batch: 0.425531
Train loss on 450 batch: 0.387093
Train loss on 500 batch: 0.425680
Train loss on 550 batch: 0.475048
best-train-loss: 0.432191
best-valid-loss: 0.435860
best-kappa: 0.8045
: Epoch: 27 | Training Loss: 0.432191 | Val. Loss: 0.435860 | Val. Kappa Score: 0.8045 | LR: 0.000250 | Estimated time: 96.05
Train loss on 50 batch: 0.414250
Train loss on 100 batch: 0.400401
Train loss on 150 batch: 0.404167
Train loss on 200 batch: 0.450426
Train loss on 250 batch: 0.429418
Train loss on 300 batch: 0.412310
Train loss on 350 batch: 0.424402
Train loss on 400 batch: 0.411706
Train loss on 450 batch: 0.451688
Train loss on 500 batch: 0.445238
Train loss on 550 batch: 0.389884
: Epoch: 28 | Training Loss: 0.428167 | Val. Loss: 0.489885 | Val. Kappa Score: 0.8056 | LR: 0.000250 | Estimated time: 95.91
Train loss on 50 batch: 0.421424
Train loss on 100 batch: 0.387984
Train loss on 150 batch: 0.434793
Train loss on 200 batch: 0.354629
Train loss on 250 batch: 0.403504
Train loss on 300 batch: 0.395661
Train loss on 350 batch: 0.443765
Train loss on 400 batch: 0.428649
Train loss on 450 batch: 0.432145
Train loss on 500 batch: 0.381673
Train loss on 550 batch: 0.431051
: Epoch: 29 | Training Loss: 0.403169 | Val. Loss: 0.446569 | Val. Kappa Score: 0.8069 | LR: 0.000250 | Estimated time: 95.84
Train loss on 50 batch: 0.407866
Train loss on 100 batch: 0.421718
Train loss on 150 batch: 0.390644
Train loss on 200 batch: 0.428536
Train loss on 250 batch: 0.394994
Train loss on 300 batch: 0.437053
Train loss on 350 batch: 0.394853
Train loss on 400 batch: 0.423348
Train loss on 450 batch: 0.437984
Train loss on 500 batch: 0.381371
Train loss on 550 batch: 0.434300
: Epoch: 30 | Training Loss: 0.432467 | Val. Loss: 0.437930 | Val. Kappa Score: 0.8083 | LR: 0.000125 | Estimated time: 96.51
Train loss on 50 batch: 0.385779
Train loss on 100 batch: 0.444478
Train loss on 150 batch: 0.374080
Train loss on 200 batch: 0.397082
Train loss on 250 batch: 0.407283
Train loss on 300 batch: 0.414178
Train loss on 350 batch: 0.411357
Train loss on 400 batch: 0.416461
Train loss on 450 batch: 0.390217
Train loss on 500 batch: 0.429297
Train loss on 550 batch: 0.424073
best-train-loss: 0.394379
best-valid-loss: 0.433634
best-kappa: 0.8093
: Epoch: 31 | Training Loss: 0.394379 | Val. Loss: 0.433634 | Val. Kappa Score: 0.8093 | LR: 0.000125 | Estimated time: 95.04
Train loss on 50 batch: 0.340283
Train loss on 100 batch: 0.375019
Train loss on 150 batch: 0.400222
Train loss on 200 batch: 0.407544
Train loss on 250 batch: 0.384374
Train loss on 300 batch: 0.367545
Train loss on 350 batch: 0.412600
Train loss on 400 batch: 0.459933
Train loss on 450 batch: 0.380084
Train loss on 500 batch: 0.407534
Train loss on 550 batch: 0.397334
best-train-loss: 0.392114
best-valid-loss: 0.426489
best-kappa: 0.8107
: Epoch: 32 | Training Loss: 0.392114 | Val. Loss: 0.426489 | Val. Kappa Score: 0.8107 | LR: 0.000125 | Estimated time: 97.12
Train loss on 50 batch: 0.459873
Train loss on 100 batch: 0.348661
Train loss on 150 batch: 0.383249
Train loss on 200 batch: 0.438211
Train loss on 250 batch: 0.389937
Train loss on 300 batch: 0.416541
Train loss on 350 batch: 0.368973
Train loss on 400 batch: 0.399635
Train loss on 450 batch: 0.408268
Train loss on 500 batch: 0.385788
Train loss on 550 batch: 0.399115
: Epoch: 33 | Training Loss: 0.397502 | Val. Loss: 0.434360 | Val. Kappa Score: 0.8119 | LR: 0.000125 | Estimated time: 97.08
Train loss on 50 batch: 0.405889
Train loss on 100 batch: 0.426557
Train loss on 150 batch: 0.422727
Train loss on 200 batch: 0.412074
Train loss on 250 batch: 0.372408
Train loss on 300 batch: 0.394418
Train loss on 350 batch: 0.343234
Train loss on 400 batch: 0.440801
Train loss on 450 batch: 0.401025
Train loss on 500 batch: 0.397969
Train loss on 550 batch: 0.417471
: Epoch: 34 | Training Loss: 0.395916 | Val. Loss: 0.433282 | Val. Kappa Score: 0.8131 | LR: 0.000125 | Estimated time: 95.71
Train loss on 50 batch: 0.390935
Train loss on 100 batch: 0.369703
Train loss on 150 batch: 0.359384
Train loss on 200 batch: 0.394331
Train loss on 250 batch: 0.375551
Train loss on 300 batch: 0.379376
Train loss on 350 batch: 0.354270
Train loss on 400 batch: 0.365692
Train loss on 450 batch: 0.427888
Train loss on 500 batch: 0.417275
Train loss on 550 batch: 0.457551
: Epoch: 35 | Training Loss: 0.390385 | Val. Loss: 0.447733 | Val. Kappa Score: 0.8140 | LR: 0.000063 | Estimated time: 98.16
Train loss on 50 batch: 0.394738
Train loss on 100 batch: 0.410391
Train loss on 150 batch: 0.389577
Train loss on 200 batch: 0.350849
Train loss on 250 batch: 0.441778
Train loss on 300 batch: 0.373827
Train loss on 350 batch: 0.366941
Train loss on 400 batch: 0.369085
Train loss on 450 batch: 0.422267
Train loss on 500 batch: 0.398514
Train loss on 550 batch: 0.378943
best-train-loss: 0.417371
best-valid-loss: 0.426408
best-kappa: 0.8151
: Epoch: 36 | Training Loss: 0.417371 | Val. Loss: 0.426408 | Val. Kappa Score: 0.8151 | LR: 0.000063 | Estimated time: 95.22
Train loss on 50 batch: 0.392268
Train loss on 100 batch: 0.372737
Train loss on 150 batch: 0.394407
Train loss on 200 batch: 0.396403
Train loss on 250 batch: 0.369569
Train loss on 300 batch: 0.392150
Train loss on 350 batch: 0.396702
Train loss on 400 batch: 0.398355
Train loss on 450 batch: 0.446267
Train loss on 500 batch: 0.346754
Train loss on 550 batch: 0.391274
best-train-loss: 0.393731
best-valid-loss: 0.424883
best-kappa: 0.8161
: Epoch: 37 | Training Loss: 0.393731 | Val. Loss: 0.424883 | Val. Kappa Score: 0.8161 | LR: 0.000063 | Estimated time: 94.98
Train loss on 50 batch: 0.389151
Train loss on 100 batch: 0.372435
Train loss on 150 batch: 0.367516
Train loss on 200 batch: 0.375172
Train loss on 250 batch: 0.413611
Train loss on 300 batch: 0.356597
Train loss on 350 batch: 0.419026
Train loss on 400 batch: 0.390928
Train loss on 450 batch: 0.372475
Train loss on 500 batch: 0.399531
Train loss on 550 batch: 0.422807
: Epoch: 38 | Training Loss: 0.435455 | Val. Loss: 0.432236 | Val. Kappa Score: 0.8170 | LR: 0.000063 | Estimated time: 94.39
Train loss on 50 batch: 0.346111
Train loss on 100 batch: 0.364109
Train loss on 150 batch: 0.372598
Train loss on 200 batch: 0.395859
Train loss on 250 batch: 0.336977
Train loss on 300 batch: 0.386553
Train loss on 350 batch: 0.375707
Train loss on 400 batch: 0.409442
Train loss on 450 batch: 0.375913
Train loss on 500 batch: 0.397970
Train loss on 550 batch: 0.398932
: Epoch: 39 | Training Loss: 0.374113 | Val. Loss: 0.442190 | Val. Kappa Score: 0.8178 | LR: 0.000063 | Estimated time: 96.13
Train loss on 50 batch: 0.372824
Train loss on 100 batch: 0.435218
Train loss on 150 batch: 0.386979
Train loss on 200 batch: 0.379911
Train loss on 250 batch: 0.390880
Train loss on 300 batch: 0.388430
Train loss on 350 batch: 0.384583
Train loss on 400 batch: 0.409260
Train loss on 450 batch: 0.338433
Train loss on 500 batch: 0.355719
Train loss on 550 batch: 0.379948
: Epoch: 40 | Training Loss: 0.380516 | Val. Loss: 0.436553 | Val. Kappa Score: 0.8185 | LR: 0.000031 | Estimated time: 95.00
Train loss on 50 batch: 0.387773
Train loss on 100 batch: 0.388280
Train loss on 150 batch: 0.381172
Train loss on 200 batch: 0.367057
Train loss on 250 batch: 0.381848
Train loss on 300 batch: 0.385121
Train loss on 350 batch: 0.372131
Train loss on 400 batch: 0.372730
Train loss on 450 batch: 0.357545
Train loss on 500 batch: 0.437413
Train loss on 550 batch: 0.335028
: Epoch: 41 | Training Loss: 0.377287 | Val. Loss: 0.432857 | Val. Kappa Score: 0.8193 | LR: 0.000031 | Estimated time: 96.40
Train loss on 50 batch: 0.354093
Train loss on 100 batch: 0.390295
Train loss on 150 batch: 0.372222
Train loss on 200 batch: 0.391878
Train loss on 250 batch: 0.392224
Train loss on 300 batch: 0.349551
Train loss on 350 batch: 0.392095
Train loss on 400 batch: 0.392824
Train loss on 450 batch: 0.384555
Train loss on 500 batch: 0.387722
Train loss on 550 batch: 0.377293
: Epoch: 42 | Training Loss: 0.381325 | Val. Loss: 0.438852 | Val. Kappa Score: 0.8199 | LR: 0.000031 | Estimated time: 94.73
Train loss on 50 batch: 0.330322
Train loss on 100 batch: 0.358407
Train loss on 150 batch: 0.399446
Train loss on 200 batch: 0.399604
Train loss on 250 batch: 0.432604
Train loss on 300 batch: 0.431487
Train loss on 350 batch: 0.380036
Train loss on 400 batch: 0.344063
Train loss on 450 batch: 0.369992
Train loss on 500 batch: 0.383491
Train loss on 550 batch: 0.385462
: Epoch: 43 | Training Loss: 0.377187 | Val. Loss: 0.432813 | Val. Kappa Score: 0.8206 | LR: 0.000016 | Estimated time: 95.26
Train loss on 50 batch: 0.359551
Train loss on 100 batch: 0.402126
Train loss on 150 batch: 0.345976
Train loss on 200 batch: 0.404379
Train loss on 250 batch: 0.434120
Train loss on 300 batch: 0.348271
Train loss on 350 batch: 0.386546
Train loss on 400 batch: 0.404341
Train loss on 450 batch: 0.360034
Train loss on 500 batch: 0.393641
Train loss on 550 batch: 0.368349
: Epoch: 44 | Training Loss: 0.375211 | Val. Loss: 0.427816 | Val. Kappa Score: 0.8213 | LR: 0.000016 | Estimated time: 96.78
Train loss on 50 batch: 0.366320
Train loss on 100 batch: 0.391446
Train loss on 150 batch: 0.357700
Train loss on 200 batch: 0.357035
Train loss on 250 batch: 0.361221
Train loss on 300 batch: 0.321736
Train loss on 350 batch: 0.398623
Train loss on 400 batch: 0.372786
Train loss on 450 batch: 0.381848
Train loss on 500 batch: 0.381936
Train loss on 550 batch: 0.389787
: Epoch: 45 | Training Loss: 0.360259 | Val. Loss: 0.425665 | Val. Kappa Score: 0.8221 | LR: 0.000016 | Estimated time: 95.79
Train loss on 50 batch: 0.394905
Train loss on 100 batch: 0.391082
Train loss on 150 batch: 0.366683
Train loss on 200 batch: 0.383605
Train loss on 250 batch: 0.365874
Train loss on 300 batch: 0.416336
Train loss on 350 batch: 0.363304
Train loss on 400 batch: 0.371326
Train loss on 450 batch: 0.391440
Train loss on 500 batch: 0.354878
Train loss on 550 batch: 0.405984
: Epoch: 46 | Training Loss: 0.379148 | Val. Loss: 0.433128 | Val. Kappa Score: 0.8226 | LR: 0.000008 | Estimated time: 96.40
Train loss on 50 batch: 0.347979
Train loss on 100 batch: 0.368744
Train loss on 150 batch: 0.358755
Train loss on 200 batch: 0.387445
Train loss on 250 batch: 0.373133
Train loss on 300 batch: 0.444360
Train loss on 350 batch: 0.406732
Train loss on 400 batch: 0.391558
Train loss on 450 batch: 0.369635
Train loss on 500 batch: 0.364757
Train loss on 550 batch: 0.376673
: Epoch: 47 | Training Loss: 0.370508 | Val. Loss: 0.430268 | Val. Kappa Score: 0.8231 | LR: 0.000008 | Estimated time: 94.67
time_estimated: 4570.31
n-epochs: 47
time_estimated: 4570.38
----------------------------------------

Experiment N: 192: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.09.04 21:34:44
data-type: new_old_balanced
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9c4f2f98>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 192: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:35:38
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50affa90>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 192: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:36:36
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50af9b00>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.447420
Train loss on 100 batch: 1.051857
Train loss on 150 batch: 0.999312
best-train-loss: 1.104645
best-valid-loss: 0.947809
best-kappa: 0.6903
: Epoch: 1 | Training Loss: 1.104645 | Val. Loss: 0.947809 | Val. Kappa Score: 0.6903 | LR: 0.001000 | Estimated time: 238.21
Train loss on 50 batch: 0.901754
Train loss on 100 batch: 0.818688
Train loss on 150 batch: 0.720101
: Epoch: 2 | Training Loss: 0.823665 | Val. Loss: 1.433532 | Val. Kappa Score: 0.6226 | LR: 0.001000 | Estimated time: 239.38
Train loss on 50 batch: 0.778480
----------------------------------------

Experiment N: 193: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:45:47
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b009e8>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 193: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:46:01
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50affa20>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.418097
Train loss on 100 batch: 0.864205
Train loss on 150 batch: 0.817557
best-train-loss: 0.943453
best-valid-loss: 0.593398
best-kappa: 0.7632
: Epoch: 1 | Training Loss: 0.943453 | Val. Loss: 0.593398 | Val. Kappa Score: 0.7632 | LR: 0.001000 | Estimated time: 236.06
Train loss on 50 batch: 0.639028
Train loss on 100 batch: 0.592323
----------------------------------------

Experiment N: 194: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:52:23
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.515735
Train loss on 100 batch: 0.853504
Train loss on 150 batch: 0.792955
best-train-loss: 0.963290
best-valid-loss: 0.547321
best-kappa: 0.7850
: Epoch: 1 | Training Loss: 0.963290 | Val. Loss: 0.547321 | Val. Kappa Score: 0.7850 | LR: 0.001000 | Estimated time: 235.35
Train loss on 50 batch: 0.648624
----------------------------------------

Experiment N: 195: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 21:59:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afcb00>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.684953
Train loss on 100 batch: 1.289816
Train loss on 150 batch: 1.177721
best-train-loss: 1.300396
best-valid-loss: 1.286754
best-kappa: 0.1862
: Epoch: 1 | Training Loss: 1.300396 | Val. Loss: 1.286754 | Val. Kappa Score: 0.1862 | LR: 0.001000 | Estimated time: 66.71
Train loss on 50 batch: 1.107545
Train loss on 100 batch: 1.062076
Train loss on 150 batch: 1.021292
: Epoch: 2 | Training Loss: 1.056304 | Val. Loss: 2.084321 | Val. Kappa Score: 0.2378 | LR: 0.001000 | Estimated time: 61.43
Train loss on 50 batch: 0.964638
Train loss on 100 batch: 1.050102
Train loss on 150 batch: 0.970778
: Epoch: 3 | Training Loss: 0.979644 | Val. Loss: 1.692770 | Val. Kappa Score: 0.1586 | LR: 0.001000 | Estimated time: 63.24
Train loss on 50 batch: 0.944301
Train loss on 100 batch: 0.906236
----------------------------------------

Experiment N: 196: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:03:19
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.180913
Train loss on 100 batch: 0.800863
Train loss on 150 batch: 0.636551
best-train-loss: 0.797476
best-valid-loss: 0.943523
best-kappa: 0.6445
: Epoch: 1 | Training Loss: 0.797476 | Val. Loss: 0.943523 | Val. Kappa Score: 0.6445 | LR: 0.001000 | Estimated time: 68.88
Train loss on 50 batch: 0.501464
Train loss on 100 batch: 0.511426
Train loss on 150 batch: 0.489509
best-train-loss: 0.528069
best-valid-loss: 0.725808
best-kappa: 0.6842
: Epoch: 2 | Training Loss: 0.528069 | Val. Loss: 0.725808 | Val. Kappa Score: 0.6842 | LR: 0.001000 | Estimated time: 63.45
Train loss on 50 batch: 0.476137
Train loss on 100 batch: 0.497749
Train loss on 150 batch: 0.444553
: Epoch: 3 | Training Loss: 0.462415 | Val. Loss: 1.148919 | Val. Kappa Score: 0.7087 | LR: 0.001000 | Estimated time: 63.43
Train loss on 50 batch: 0.382041
Train loss on 100 batch: 0.410242
Train loss on 150 batch: 0.385102
best-train-loss: 0.430515
best-valid-loss: 0.523673
best-kappa: 0.7399
: Epoch: 4 | Training Loss: 0.430515 | Val. Loss: 0.523673 | Val. Kappa Score: 0.7399 | LR: 0.001000 | Estimated time: 62.23
Train loss on 50 batch: 0.596446
Train loss on 100 batch: 0.464803
Train loss on 150 batch: 0.373410
best-train-loss: 0.455306
best-valid-loss: 0.456025
best-kappa: 0.7592
: Epoch: 5 | Training Loss: 0.455306 | Val. Loss: 0.456025 | Val. Kappa Score: 0.7592 | LR: 0.001000 | Estimated time: 63.94
Train loss on 50 batch: 0.352667
Train loss on 100 batch: 0.373183
Train loss on 150 batch: 0.339714
: Epoch: 6 | Training Loss: 0.346737 | Val. Loss: 0.469414 | Val. Kappa Score: 0.7697 | LR: 0.001000 | Estimated time: 65.90
----------------------------------------

Experiment N: 197: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:10:24
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 197: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:11:22
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afea58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 197: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:13:45
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afea90>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.515738
Train loss on 100 batch: 0.853495
Train loss on 150 batch: 0.792932
best-train-loss: 0.963318
best-valid-loss: 0.535105
best-kappa: 0.7966
: Epoch: 1 | Training Loss: 0.963318 | Val. Loss: 0.535105 | Val. Kappa Score: 0.7966 | LR: 0.001000 | Estimated time: 230.02
Train loss on 50 batch: 0.648595
Train loss on 100 batch: 0.593528
Train loss on 150 batch: 0.484543
: Epoch: 2 | Training Loss: 0.594413 | Val. Loss: 0.670506 | Val. Kappa Score: 0.7906 | LR: 0.001000 | Estimated time: 228.39
Train loss on 50 batch: 0.607123
Train loss on 100 batch: 0.591268
Train loss on 150 batch: 0.517784
best-train-loss: 0.565367
best-valid-loss: 0.390920
best-kappa: 0.8103
: Epoch: 3 | Training Loss: 0.565367 | Val. Loss: 0.390920 | Val. Kappa Score: 0.8103 | LR: 0.001000 | Estimated time: 235.62
Train loss on 50 batch: 0.483029
Train loss on 100 batch: 0.490486
Train loss on 150 batch: 0.542747
: Epoch: 4 | Training Loss: 0.566830 | Val. Loss: 0.470582 | Val. Kappa Score: 0.8167 | LR: 0.001000 | Estimated time: 240.08
Train loss on 50 batch: 0.539281
Train loss on 100 batch: 0.555997
Train loss on 150 batch: 0.451268
: Epoch: 5 | Training Loss: 0.518269 | Val. Loss: 0.805729 | Val. Kappa Score: 0.7944 | LR: 0.001000 | Estimated time: 234.86
Train loss on 50 batch: 0.451364
Train loss on 100 batch: 0.412401
Train loss on 150 batch: 0.424375
: Epoch: 6 | Training Loss: 0.429800 | Val. Loss: 0.618063 | Val. Kappa Score: 0.7870 | LR: 0.000500 | Estimated time: 226.77
Train loss on 50 batch: 0.410976
----------------------------------------

Experiment N: 198: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:38:34
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.180915
Train loss on 100 batch: 0.800885
Train loss on 150 batch: 0.636545
best-train-loss: 0.797495
best-valid-loss: 0.908519
best-kappa: 0.6651
: Epoch: 1 | Training Loss: 0.797495 | Val. Loss: 0.908519 | Val. Kappa Score: 0.6651 | LR: 0.001000 | Estimated time: 232.96
Train loss on 50 batch: 0.501509
Train loss on 100 batch: 0.511026
Train loss on 150 batch: 0.488276
best-train-loss: 0.527816
best-valid-loss: 0.771692
best-kappa: 0.6761
: Epoch: 2 | Training Loss: 0.527816 | Val. Loss: 0.771692 | Val. Kappa Score: 0.6761 | LR: 0.001000 | Estimated time: 228.19
Train loss on 50 batch: 0.474198
----------------------------------------

Experiment N: 199: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:48:03
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda58>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.289325
Train loss on 100 batch: 0.764566
Train loss on 150 batch: 0.687335
best-train-loss: 0.836279
best-valid-loss: 0.550260
best-kappa: 0.8148
: Epoch: 1 | Training Loss: 0.836279 | Val. Loss: 0.550260 | Val. Kappa Score: 0.8148 | LR: 0.001000 | Estimated time: 227.34
Train loss on 50 batch: 0.493996
Train loss on 100 batch: 0.493237
Train loss on 150 batch: 0.480255
: Epoch: 2 | Training Loss: 0.510463 | Val. Loss: 1.598181 | Val. Kappa Score: 0.6278 | LR: 0.001000 | Estimated time: 224.50
----------------------------------------

Experiment N: 200: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 22:56:11
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b019e8>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.237481
Train loss on 100 batch: 0.767201
Train loss on 150 batch: 0.730797
best-train-loss: 0.819681
best-valid-loss: 0.620048
best-kappa: 0.7840
: Epoch: 1 | Training Loss: 0.819681 | Val. Loss: 0.620048 | Val. Kappa Score: 0.7840 | LR: 0.001000 | Estimated time: 228.62
Train loss on 50 batch: 0.514215
Train loss on 100 batch: 0.517302
Train loss on 150 batch: 0.453967
: Epoch: 2 | Training Loss: 0.513249 | Val. Loss: 0.779940 | Val. Kappa Score: 0.7485 | LR: 0.001000 | Estimated time: 226.68
----------------------------------------

Experiment N: 201: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:06:16
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bdc048>
early-stopping-patience: 10
parameters-amount: 86752581
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 201: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:07:49
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bdc048>
early-stopping-patience: 10
parameters-amount: 86755717
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 201: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:08:31
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bbbf60>
early-stopping-patience: 10
parameters-amount: 86747521
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.439847
Train loss on 100 batch: 1.050468
Train loss on 150 batch: 1.015687
best-train-loss: 1.378391
best-valid-loss: 1.807304
best-kappa: 0.0000
: Epoch: 1 | Training Loss: 1.378391 | Val. Loss: 1.807304 | Val. Kappa Score: 0.0000 | LR: 0.001000 | Estimated time: 232.35
Train loss on 50 batch: 1.267809
Train loss on 100 batch: 1.093270
----------------------------------------

Experiment N: 202: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:14:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bbafd0>
early-stopping-patience: 10
parameters-amount: 86747521
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 202: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:14:47
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bda080>
early-stopping-patience: 10
parameters-amount: 86744385
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.047003
Train loss on 100 batch: 0.878005
Train loss on 150 batch: 0.762537
best-train-loss: 1.099936
best-valid-loss: 0.574230
best-kappa: 0.7890
: Epoch: 1 | Training Loss: 1.099936 | Val. Loss: 0.574230 | Val. Kappa Score: 0.7890 | LR: 0.001000 | Estimated time: 75.90
Train loss on 50 batch: 0.582798
Train loss on 100 batch: 0.627706
Train loss on 150 batch: 0.538138
: Epoch: 2 | Training Loss: 0.622359 | Val. Loss: 0.577124 | Val. Kappa Score: 0.7730 | LR: 0.001000 | Estimated time: 71.86
Train loss on 50 batch: 0.619211
Train loss on 100 batch: 0.682148
Train loss on 150 batch: 0.554967
best-train-loss: 0.610204
best-valid-loss: 0.560235
best-kappa: 0.7798
: Epoch: 3 | Training Loss: 0.610204 | Val. Loss: 0.560235 | Val. Kappa Score: 0.7798 | LR: 0.001000 | Estimated time: 71.30
Train loss on 50 batch: 0.693383
----------------------------------------

Experiment N: 203: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:19:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bb9fd0>
early-stopping-patience: 10
parameters-amount: 86744385
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.363424
Train loss on 100 batch: 1.331111
Train loss on 150 batch: 1.096724
best-train-loss: 1.423745
best-valid-loss: 1.082620
best-kappa: 0.5711
: Epoch: 1 | Training Loss: 1.423745 | Val. Loss: 1.082620 | Val. Kappa Score: 0.5711 | LR: 0.001000 | Estimated time: 76.41
Train loss on 50 batch: 0.800564
Train loss on 100 batch: 0.653637
Train loss on 150 batch: 0.709674
best-train-loss: 0.721610
best-valid-loss: 0.749608
best-kappa: 0.6541
: Epoch: 2 | Training Loss: 0.721610 | Val. Loss: 0.749608 | Val. Kappa Score: 0.6541 | LR: 0.001000 | Estimated time: 71.34
Train loss on 50 batch: 0.669960
----------------------------------------

Experiment N: 204: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.04 23:22:14
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bda080>
early-stopping-patience: 10
parameters-amount: 86744385
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 2.363790
Train loss on 100 batch: 1.017806
Train loss on 150 batch: 0.831071
best-train-loss: 1.221927
best-valid-loss: 0.783539
best-kappa: 0.7200
: Epoch: 1 | Training Loss: 1.221927 | Val. Loss: 0.783539 | Val. Kappa Score: 0.7200 | LR: 0.001000 | Estimated time: 76.02
Train loss on 50 batch: 0.676147
Train loss on 100 batch: 0.579518
Train loss on 150 batch: 0.592345
: Epoch: 2 | Training Loss: 0.635204 | Val. Loss: 0.999127 | Val. Kappa Score: 0.6947 | LR: 0.001000 | Estimated time: 70.41
Train loss on 50 batch: 0.650547
Train loss on 100 batch: 0.713261
Train loss on 150 batch: 0.619548
best-train-loss: 0.657316
best-valid-loss: 0.527794
best-kappa: 0.7295
: Epoch: 3 | Training Loss: 0.657316 | Val. Loss: 0.527794 | Val. Kappa Score: 0.7295 | LR: 0.001000 | Estimated time: 71.99
Train loss on 50 batch: 0.664125
Train loss on 100 batch: 0.572337
Train loss on 150 batch: 0.565284
----------------------------------------

Experiment N: 205: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 23:27:20
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b01a90>
early-stopping-patience: 10
parameters-amount: 28343265
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 205: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 23:27:47
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02a20>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.163636
Train loss on 100 batch: 0.693117
Train loss on 150 batch: 0.684067
best-train-loss: 0.764587
best-valid-loss: 0.454986
best-kappa: 0.8296
: Epoch: 1 | Training Loss: 0.764587 | Val. Loss: 0.454986 | Val. Kappa Score: 0.8296 | LR: 0.001000 | Estimated time: 61.99
Train loss on 50 batch: 0.521988
Train loss on 100 batch: 0.542529
Train loss on 150 batch: 0.441412
: Epoch: 2 | Training Loss: 0.516672 | Val. Loss: 0.644173 | Val. Kappa Score: 0.7793 | LR: 0.001000 | Estimated time: 57.47
----------------------------------------

Experiment N: 206: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.04 23:30:03
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b01a58>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 1.192902
Train loss on 100 batch: 0.632624
Train loss on 150 batch: 0.652036
best-train-loss: 0.744199
best-valid-loss: 0.675665
best-kappa: 0.8009
: Epoch: 1 | Training Loss: 0.744199 | Val. Loss: 0.675665 | Val. Kappa Score: 0.8009 | LR: 0.001000 | Estimated time: 60.77
Train loss on 50 batch: 0.543369
Train loss on 100 batch: 0.516284
Train loss on 150 batch: 0.489283
best-train-loss: 0.526231
best-valid-loss: 0.528667
best-kappa: 0.8022
: Epoch: 2 | Training Loss: 0.526231 | Val. Loss: 0.528667 | Val. Kappa Score: 0.8022 | LR: 0.001000 | Estimated time: 57.32
----------------------------------------

Experiment N: 207: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 09:45:56
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02a58>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 207: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 09:46:25
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02a58>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 207: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 09:47:11
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b019e8>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.434336
Train loss on 100 batch: 0.343548
Train loss on 150 batch: 0.303009
best-train-loss: 0.347063
best-valid-loss: 0.489807
best-kappa: 0.6776
: Epoch: 1 | Training Loss: 0.347063 | Val. Loss: 0.489807 | Val. Kappa Score: 0.6776 | LR: 0.001000 | Estimated time: 59.02
Train loss on 50 batch: 0.283950
Train loss on 100 batch: 0.296615
Train loss on 150 batch: 0.243712
best-train-loss: 0.311006
best-valid-loss: 0.298931
best-kappa: 0.7774
: Epoch: 2 | Training Loss: 0.311006 | Val. Loss: 0.298931 | Val. Kappa Score: 0.7774 | LR: 0.001000 | Estimated time: 58.16
Train loss on 50 batch: 0.270942
Train loss on 100 batch: 0.272720
Train loss on 150 batch: 0.269145
: Epoch: 3 | Training Loss: 0.262574 | Val. Loss: 0.413815 | Val. Kappa Score: 0.8102 | LR: 0.001000 | Estimated time: 57.98
Train loss on 50 batch: 0.275148
Train loss on 100 batch: 0.269644
Train loss on 150 batch: 0.258808
best-train-loss: 0.358895
best-valid-loss: 0.288733
best-kappa: 0.8278
: Epoch: 4 | Training Loss: 0.358895 | Val. Loss: 0.288733 | Val. Kappa Score: 0.8278 | LR: 0.001000 | Estimated time: 58.47
Train loss on 50 batch: 0.303587
Train loss on 100 batch: 0.316839
Train loss on 150 batch: 0.227767
: Epoch: 5 | Training Loss: 0.276619 | Val. Loss: 0.312890 | Val. Kappa Score: 0.8393 | LR: 0.001000 | Estimated time: 58.50
Train loss on 50 batch: 0.273326
Train loss on 100 batch: 0.273168
Train loss on 150 batch: 0.231284
: Epoch: 6 | Training Loss: 0.244494 | Val. Loss: 0.453469 | Val. Kappa Score: 0.8370 | LR: 0.001000 | Estimated time: 58.17
Train loss on 50 batch: 0.254557
Train loss on 100 batch: 0.259285
Train loss on 150 batch: 0.224533
: Epoch: 7 | Training Loss: 0.243310 | Val. Loss: 0.335671 | Val. Kappa Score: 0.8444 | LR: 0.000500 | Estimated time: 57.79
Train loss on 50 batch: 0.204850
Train loss on 100 batch: 0.235525
Train loss on 150 batch: 0.183495
: Epoch: 8 | Training Loss: 0.234458 | Val. Loss: 0.366326 | Val. Kappa Score: 0.8505 | LR: 0.000500 | Estimated time: 57.63
Train loss on 50 batch: 0.218005
Train loss on 100 batch: 0.227735
Train loss on 150 batch: 0.216927
: Epoch: 9 | Training Loss: 0.216468 | Val. Loss: 0.297083 | Val. Kappa Score: 0.8551 | LR: 0.000500 | Estimated time: 58.20
Train loss on 50 batch: 0.198657
Train loss on 100 batch: 0.210397
Train loss on 150 batch: 0.220939
: Epoch: 10 | Training Loss: 0.298410 | Val. Loss: 0.355252 | Val. Kappa Score: 0.8580 | LR: 0.000250 | Estimated time: 58.13
Train loss on 50 batch: 0.226542
Train loss on 100 batch: 0.196291
Train loss on 150 batch: 0.191282
best-train-loss: 0.207169
best-valid-loss: 0.285000
best-kappa: 0.8599
: Epoch: 11 | Training Loss: 0.207169 | Val. Loss: 0.285000 | Val. Kappa Score: 0.8599 | LR: 0.000250 | Estimated time: 58.29
Train loss on 50 batch: 0.179655
Train loss on 100 batch: 0.186032
Train loss on 150 batch: 0.205767
: Epoch: 12 | Training Loss: 0.191735 | Val. Loss: 0.291094 | Val. Kappa Score: 0.8616 | LR: 0.000250 | Estimated time: 57.24
Train loss on 50 batch: 0.190521
Train loss on 100 batch: 0.234262
Train loss on 150 batch: 0.185466
: Epoch: 13 | Training Loss: 0.215303 | Val. Loss: 0.346107 | Val. Kappa Score: 0.8637 | LR: 0.000250 | Estimated time: 57.95
Train loss on 50 batch: 0.191717
Train loss on 100 batch: 0.188653
Train loss on 150 batch: 0.213028
: Epoch: 14 | Training Loss: 0.196575 | Val. Loss: 0.293982 | Val. Kappa Score: 0.8659 | LR: 0.000125 | Estimated time: 58.02
Train loss on 50 batch: 0.193397
Train loss on 100 batch: 0.185373
Train loss on 150 batch: 0.183125
best-train-loss: 0.193391
best-valid-loss: 0.284984
best-kappa: 0.8674
: Epoch: 15 | Training Loss: 0.193391 | Val. Loss: 0.284984 | Val. Kappa Score: 0.8674 | LR: 0.000125 | Estimated time: 58.28
Train loss on 50 batch: 0.186214
Train loss on 100 batch: 0.164761
Train loss on 150 batch: 0.183040
best-train-loss: 0.185705
best-valid-loss: 0.278958
best-kappa: 0.8687
: Epoch: 16 | Training Loss: 0.185705 | Val. Loss: 0.278958 | Val. Kappa Score: 0.8687 | LR: 0.000125 | Estimated time: 58.14
Train loss on 50 batch: 0.207461
Train loss on 100 batch: 0.193874
Train loss on 150 batch: 0.158993
: Epoch: 17 | Training Loss: 0.185142 | Val. Loss: 0.283628 | Val. Kappa Score: 0.8700 | LR: 0.000125 | Estimated time: 58.21
Train loss on 50 batch: 0.183562
Train loss on 100 batch: 0.159141
Train loss on 150 batch: 0.196415
: Epoch: 18 | Training Loss: 0.185075 | Val. Loss: 0.284451 | Val. Kappa Score: 0.8718 | LR: 0.000125 | Estimated time: 57.93
Train loss on 50 batch: 0.161896
Train loss on 100 batch: 0.183584
Train loss on 150 batch: 0.184018
: Epoch: 19 | Training Loss: 0.183255 | Val. Loss: 0.279988 | Val. Kappa Score: 0.8730 | LR: 0.000063 | Estimated time: 58.53
Train loss on 50 batch: 0.163836
Train loss on 100 batch: 0.216443
Train loss on 150 batch: 0.164320
: Epoch: 20 | Training Loss: 0.180139 | Val. Loss: 0.282269 | Val. Kappa Score: 0.8740 | LR: 0.000063 | Estimated time: 57.10
Train loss on 50 batch: 0.163760
Train loss on 100 batch: 0.169654
Train loss on 150 batch: 0.160557
best-train-loss: 0.211687
best-valid-loss: 0.276456
best-kappa: 0.8750
: Epoch: 21 | Training Loss: 0.211687 | Val. Loss: 0.276456 | Val. Kappa Score: 0.8750 | LR: 0.000063 | Estimated time: 57.26
Train loss on 50 batch: 0.158174
Train loss on 100 batch: 0.178786
Train loss on 150 batch: 0.170958
best-train-loss: 0.165230
best-valid-loss: 0.276355
best-kappa: 0.8759
: Epoch: 22 | Training Loss: 0.165230 | Val. Loss: 0.276355 | Val. Kappa Score: 0.8759 | LR: 0.000063 | Estimated time: 57.95
Train loss on 50 batch: 0.162332
Train loss on 100 batch: 0.176897
Train loss on 150 batch: 0.160763
: Epoch: 23 | Training Loss: 0.186024 | Val. Loss: 0.282182 | Val. Kappa Score: 0.8765 | LR: 0.000063 | Estimated time: 57.65
Train loss on 50 batch: 0.171955
Train loss on 100 batch: 0.169042
Train loss on 150 batch: 0.169037
: Epoch: 24 | Training Loss: 0.249486 | Val. Loss: 0.280119 | Val. Kappa Score: 0.8771 | LR: 0.000063 | Estimated time: 58.39
Train loss on 50 batch: 0.153055
Train loss on 100 batch: 0.164665
Train loss on 150 batch: 0.190102
: Epoch: 25 | Training Loss: 0.168968 | Val. Loss: 0.276510 | Val. Kappa Score: 0.8779 | LR: 0.000031 | Estimated time: 57.99
Train loss on 50 batch: 0.174356
Train loss on 100 batch: 0.142250
Train loss on 150 batch: 0.181942
: Epoch: 26 | Training Loss: 0.212105 | Val. Loss: 0.278633 | Val. Kappa Score: 0.8785 | LR: 0.000031 | Estimated time: 58.12
Train loss on 50 batch: 0.188237
Train loss on 100 batch: 0.194350
Train loss on 150 batch: 0.150686
: Epoch: 27 | Training Loss: 0.179350 | Val. Loss: 0.279356 | Val. Kappa Score: 0.8792 | LR: 0.000031 | Estimated time: 58.55
Train loss on 50 batch: 0.190388
Train loss on 100 batch: 0.161728
Train loss on 150 batch: 0.165059
: Epoch: 28 | Training Loss: 0.182297 | Val. Loss: 0.277410 | Val. Kappa Score: 0.8794 | LR: 0.000016 | Estimated time: 57.62
Train loss on 50 batch: 0.140751
Train loss on 100 batch: 0.188018
Train loss on 150 batch: 0.171623
: Epoch: 29 | Training Loss: 0.181059 | Val. Loss: 0.278103 | Val. Kappa Score: 0.8796 | LR: 0.000016 | Estimated time: 57.21
Train loss on 50 batch: 0.170617
Train loss on 100 batch: 0.176152
Train loss on 150 batch: 0.156759
: Epoch: 30 | Training Loss: 0.184514 | Val. Loss: 0.278342 | Val. Kappa Score: 0.8801 | LR: 0.000016 | Estimated time: 58.48
Train loss on 50 batch: 0.145463
Train loss on 100 batch: 0.186719
Train loss on 150 batch: 0.146564
: Epoch: 31 | Training Loss: 0.170395 | Val. Loss: 0.276743 | Val. Kappa Score: 0.8805 | LR: 0.000008 | Estimated time: 58.75
Train loss on 50 batch: 0.159380
Train loss on 100 batch: 0.175923
Train loss on 150 batch: 0.159443
: Epoch: 32 | Training Loss: 0.163279 | Val. Loss: 0.276800 | Val. Kappa Score: 0.8806 | LR: 0.000008 | Estimated time: 58.57
time_estimated: 1861.01
n-epochs: 32
time_estimated: 1861.08
----------------------------------------

Experiment N: 208: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 10:25:29
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afda90>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.611215
Train loss on 100 batch: 0.499561
Train loss on 150 batch: 0.547932
best-train-loss: 0.528397
best-valid-loss: 3.182696
best-kappa: 0.3733
: Epoch: 1 | Training Loss: 0.528397 | Val. Loss: 3.182696 | Val. Kappa Score: 0.3733 | LR: 0.005000 | Estimated time: 59.24
Train loss on 50 batch: 0.433852
Train loss on 100 batch: 0.500732
Train loss on 150 batch: 0.457404
best-train-loss: 0.495552
best-valid-loss: 0.445942
best-kappa: 0.5970
: Epoch: 2 | Training Loss: 0.495552 | Val. Loss: 0.445942 | Val. Kappa Score: 0.5970 | LR: 0.005000 | Estimated time: 57.70
Train loss on 50 batch: 0.497852
Train loss on 100 batch: 0.565106
Train loss on 150 batch: 0.431486
best-train-loss: 0.467420
best-valid-loss: 0.444857
best-kappa: 0.6834
: Epoch: 3 | Training Loss: 0.467420 | Val. Loss: 0.444857 | Val. Kappa Score: 0.6834 | LR: 0.005000 | Estimated time: 57.62
Train loss on 50 batch: 0.446165
Train loss on 100 batch: 0.412045
Train loss on 150 batch: 0.479761
: Epoch: 4 | Training Loss: 0.522090 | Val. Loss: 5.211814 | Val. Kappa Score: 0.5645 | LR: 0.005000 | Estimated time: 57.61
Train loss on 50 batch: 0.665766
Train loss on 100 batch: 0.577948
Train loss on 150 batch: 0.447776
: Epoch: 5 | Training Loss: 0.542769 | Val. Loss: 1.373704 | Val. Kappa Score: 0.5786 | LR: 0.005000 | Estimated time: 58.16
Train loss on 50 batch: 0.455207
Train loss on 100 batch: 0.407766
Train loss on 150 batch: 0.420584
: Epoch: 6 | Training Loss: 0.424382 | Val. Loss: 1.423307 | Val. Kappa Score: 0.5569 | LR: 0.002500 | Estimated time: 57.09
Train loss on 50 batch: 0.366988
Train loss on 100 batch: 0.355652
Train loss on 150 batch: 0.342674
best-train-loss: 0.358136
best-valid-loss: 0.362981
best-kappa: 0.6004
: Epoch: 7 | Training Loss: 0.358136 | Val. Loss: 0.362981 | Val. Kappa Score: 0.6004 | LR: 0.002500 | Estimated time: 58.14
Train loss on 50 batch: 0.298094
Train loss on 100 batch: 0.358298
Train loss on 150 batch: 0.283865
: Epoch: 8 | Training Loss: 0.324140 | Val. Loss: 0.526619 | Val. Kappa Score: 0.6296 | LR: 0.002500 | Estimated time: 58.28
Train loss on 50 batch: 0.345964
Train loss on 100 batch: 0.362639
Train loss on 150 batch: 0.299207
best-train-loss: 0.326466
best-valid-loss: 0.349901
best-kappa: 0.6557
: Epoch: 9 | Training Loss: 0.326466 | Val. Loss: 0.349901 | Val. Kappa Score: 0.6557 | LR: 0.002500 | Estimated time: 57.97
Train loss on 50 batch: 0.300478
Train loss on 100 batch: 0.364362
Train loss on 150 batch: 0.310319
: Epoch: 10 | Training Loss: 0.385704 | Val. Loss: 0.363154 | Val. Kappa Score: 0.6769 | LR: 0.002500 | Estimated time: 58.83
Train loss on 50 batch: 0.338338
Train loss on 100 batch: 0.320270
Train loss on 150 batch: 0.303336
: Epoch: 11 | Training Loss: 0.340297 | Val. Loss: 0.430737 | Val. Kappa Score: 0.6919 | LR: 0.002500 | Estimated time: 58.05
Train loss on 50 batch: 0.320904
Train loss on 100 batch: 0.259114
Train loss on 150 batch: 0.315547
: Epoch: 12 | Training Loss: 0.294251 | Val. Loss: 0.425128 | Val. Kappa Score: 0.7016 | LR: 0.001250 | Estimated time: 57.67
Train loss on 50 batch: 0.252239
Train loss on 100 batch: 0.297174
Train loss on 150 batch: 0.270347
best-train-loss: 0.286635
best-valid-loss: 0.309583
best-kappa: 0.7160
: Epoch: 13 | Training Loss: 0.286635 | Val. Loss: 0.309583 | Val. Kappa Score: 0.7160 | LR: 0.001250 | Estimated time: 57.83
Train loss on 50 batch: 0.259837
Train loss on 100 batch: 0.245992
Train loss on 150 batch: 0.277887
: Epoch: 14 | Training Loss: 0.265600 | Val. Loss: 0.576588 | Val. Kappa Score: 0.7138 | LR: 0.001250 | Estimated time: 57.81
Train loss on 50 batch: 0.289849
Train loss on 100 batch: 0.270203
Train loss on 150 batch: 0.259974
: Epoch: 15 | Training Loss: 0.274262 | Val. Loss: 0.372122 | Val. Kappa Score: 0.7221 | LR: 0.001250 | Estimated time: 58.11
Train loss on 50 batch: 0.259076
Train loss on 100 batch: 0.226285
Train loss on 150 batch: 0.248197
: Epoch: 16 | Training Loss: 0.248670 | Val. Loss: 0.400772 | Val. Kappa Score: 0.7310 | LR: 0.000625 | Estimated time: 57.78
Train loss on 50 batch: 0.270868
Train loss on 100 batch: 0.238354
Train loss on 150 batch: 0.199269
best-train-loss: 0.236130
best-valid-loss: 0.300574
best-kappa: 0.7396
: Epoch: 17 | Training Loss: 0.236130 | Val. Loss: 0.300574 | Val. Kappa Score: 0.7396 | LR: 0.000625 | Estimated time: 58.55
Train loss on 50 batch: 0.235149
Train loss on 100 batch: 0.205265
Train loss on 150 batch: 0.238409
: Epoch: 18 | Training Loss: 0.236985 | Val. Loss: 0.302523 | Val. Kappa Score: 0.7482 | LR: 0.000625 | Estimated time: 58.18
Train loss on 50 batch: 0.209844
Train loss on 100 batch: 0.214394
Train loss on 150 batch: 0.237280
best-train-loss: 0.228170
best-valid-loss: 0.291298
best-kappa: 0.7553
: Epoch: 19 | Training Loss: 0.228170 | Val. Loss: 0.291298 | Val. Kappa Score: 0.7553 | LR: 0.000625 | Estimated time: 58.26
Train loss on 50 batch: 0.212370
Train loss on 100 batch: 0.241207
Train loss on 150 batch: 0.178952
: Epoch: 20 | Training Loss: 0.206844 | Val. Loss: 0.300080 | Val. Kappa Score: 0.7622 | LR: 0.000625 | Estimated time: 57.77
Train loss on 50 batch: 0.209020
Train loss on 100 batch: 0.209173
Train loss on 150 batch: 0.228447
: Epoch: 21 | Training Loss: 0.245959 | Val. Loss: 0.341352 | Val. Kappa Score: 0.7677 | LR: 0.000625 | Estimated time: 57.59
Train loss on 50 batch: 0.214157
Train loss on 100 batch: 0.220815
Train loss on 150 batch: 0.229895
: Epoch: 22 | Training Loss: 0.220496 | Val. Loss: 0.298926 | Val. Kappa Score: 0.7733 | LR: 0.000313 | Estimated time: 57.79
Train loss on 50 batch: 0.188147
Train loss on 100 batch: 0.204321
Train loss on 150 batch: 0.191598
best-train-loss: 0.197948
best-valid-loss: 0.288600
best-kappa: 0.7785
: Epoch: 23 | Training Loss: 0.197948 | Val. Loss: 0.288600 | Val. Kappa Score: 0.7785 | LR: 0.000313 | Estimated time: 58.32
Train loss on 50 batch: 0.215438
Train loss on 100 batch: 0.189152
Train loss on 150 batch: 0.187276
best-train-loss: 0.252808
best-valid-loss: 0.283588
best-kappa: 0.7831
: Epoch: 24 | Training Loss: 0.252808 | Val. Loss: 0.283588 | Val. Kappa Score: 0.7831 | LR: 0.000313 | Estimated time: 57.81
Train loss on 50 batch: 0.198656
Train loss on 100 batch: 0.189406
Train loss on 150 batch: 0.223545
: Epoch: 25 | Training Loss: 0.217707 | Val. Loss: 0.293553 | Val. Kappa Score: 0.7872 | LR: 0.000313 | Estimated time: 57.59
Train loss on 50 batch: 0.207226
Train loss on 100 batch: 0.168736
Train loss on 150 batch: 0.208221
best-train-loss: 0.219126
best-valid-loss: 0.282938
best-kappa: 0.7912
: Epoch: 26 | Training Loss: 0.219126 | Val. Loss: 0.282938 | Val. Kappa Score: 0.7912 | LR: 0.000313 | Estimated time: 57.92
Train loss on 50 batch: 0.233500
Train loss on 100 batch: 0.239778
Train loss on 150 batch: 0.178705
best-train-loss: 0.204708
best-valid-loss: 0.274428
best-kappa: 0.7951
: Epoch: 27 | Training Loss: 0.204708 | Val. Loss: 0.274428 | Val. Kappa Score: 0.7951 | LR: 0.000313 | Estimated time: 57.96
Train loss on 50 batch: 0.218016
Train loss on 100 batch: 0.190497
Train loss on 150 batch: 0.184578
: Epoch: 28 | Training Loss: 0.198675 | Val. Loss: 0.303646 | Val. Kappa Score: 0.7978 | LR: 0.000313 | Estimated time: 58.06
Train loss on 50 batch: 0.159331
Train loss on 100 batch: 0.220070
Train loss on 150 batch: 0.206369
: Epoch: 29 | Training Loss: 0.192662 | Val. Loss: 0.305121 | Val. Kappa Score: 0.8007 | LR: 0.000313 | Estimated time: 58.18
Train loss on 50 batch: 0.203929
Train loss on 100 batch: 0.194830
Train loss on 150 batch: 0.186009
: Epoch: 30 | Training Loss: 0.201484 | Val. Loss: 0.290148 | Val. Kappa Score: 0.8036 | LR: 0.000156 | Estimated time: 57.59
Train loss on 50 batch: 0.153117
Train loss on 100 batch: 0.206473
Train loss on 150 batch: 0.167120
: Epoch: 31 | Training Loss: 0.194222 | Val. Loss: 0.297326 | Val. Kappa Score: 0.8063 | LR: 0.000156 | Estimated time: 58.45
Train loss on 50 batch: 0.187981
Train loss on 100 batch: 0.213524
Train loss on 150 batch: 0.171287
: Epoch: 32 | Training Loss: 0.190063 | Val. Loss: 0.286754 | Val. Kappa Score: 0.8087 | LR: 0.000156 | Estimated time: 57.55
Train loss on 50 batch: 0.197279
Train loss on 100 batch: 0.189785
Train loss on 150 batch: 0.152693
: Epoch: 33 | Training Loss: 0.183356 | Val. Loss: 0.289398 | Val. Kappa Score: 0.8114 | LR: 0.000078 | Estimated time: 57.59
Train loss on 50 batch: 0.171332
Train loss on 100 batch: 0.187114
Train loss on 150 batch: 0.208764
: Epoch: 34 | Training Loss: 0.182191 | Val. Loss: 0.286289 | Val. Kappa Score: 0.8135 | LR: 0.000078 | Estimated time: 57.37
Train loss on 50 batch: 0.153782
Train loss on 100 batch: 0.198029
Train loss on 150 batch: 0.175882
: Epoch: 35 | Training Loss: 0.189321 | Val. Loss: 0.283216 | Val. Kappa Score: 0.8157 | LR: 0.000078 | Estimated time: 57.69
Train loss on 50 batch: 0.156557
Train loss on 100 batch: 0.197254
Train loss on 150 batch: 0.162640
: Epoch: 36 | Training Loss: 0.184861 | Val. Loss: 0.283537 | Val. Kappa Score: 0.8177 | LR: 0.000039 | Estimated time: 57.44
Train loss on 50 batch: 0.182467
Train loss on 100 batch: 0.173644
Train loss on 150 batch: 0.184095
: Epoch: 37 | Training Loss: 0.181056 | Val. Loss: 0.284644 | Val. Kappa Score: 0.8197 | LR: 0.000039 | Estimated time: 57.64
time_estimated: 2146.64
n-epochs: 37
time_estimated: 2146.71
----------------------------------------

Experiment N: 209: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 11:01:16
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb509b8710>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 209: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 12:33:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50afea90>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.435216
Train loss on 100 batch: 0.332648
Train loss on 150 batch: 0.308543
best-train-loss: 0.343455
best-valid-loss: 0.766857
best-kappa: 0.6847
: Epoch: 1 | Training Loss: 0.343455 | Val. Loss: 0.766857 | Val. Kappa Score: 0.6847 | LR: 0.000500 | Estimated time: 59.54
Train loss on 50 batch: 0.285004
Train loss on 100 batch: 0.296984
Train loss on 150 batch: 0.218791
best-train-loss: 0.305326
best-valid-loss: 0.365204
best-kappa: 0.7822
: Epoch: 2 | Training Loss: 0.305326 | Val. Loss: 0.365204 | Val. Kappa Score: 0.7822 | LR: 0.000500 | Estimated time: 57.57
Train loss on 50 batch: 0.268484
Train loss on 100 batch: 0.266014
Train loss on 150 batch: 0.263127
: Epoch: 3 | Training Loss: 0.260710 | Val. Loss: 0.414758 | Val. Kappa Score: 0.8102 | LR: 0.000500 | Estimated time: 57.94
Train loss on 50 batch: 0.251006
Train loss on 100 batch: 0.256890
Train loss on 150 batch: 0.244422
best-train-loss: 0.350967
best-valid-loss: 0.286527
best-kappa: 0.8279
: Epoch: 4 | Training Loss: 0.350967 | Val. Loss: 0.286527 | Val. Kappa Score: 0.8279 | LR: 0.000500 | Estimated time: 58.52
Train loss on 50 batch: 0.296607
Train loss on 100 batch: 0.300062
Train loss on 150 batch: 0.211629
: Epoch: 5 | Training Loss: 0.264614 | Val. Loss: 0.291244 | Val. Kappa Score: 0.8397 | LR: 0.000500 | Estimated time: 60.50
Train loss on 50 batch: 0.253402
Train loss on 100 batch: 0.256302
Train loss on 150 batch: 0.218602
: Epoch: 6 | Training Loss: 0.229479 | Val. Loss: 0.355341 | Val. Kappa Score: 0.8450 | LR: 0.000500 | Estimated time: 58.47
Train loss on 50 batch: 0.234728
Train loss on 100 batch: 0.247685
Train loss on 150 batch: 0.221108
: Epoch: 7 | Training Loss: 0.233426 | Val. Loss: 0.335448 | Val. Kappa Score: 0.8510 | LR: 0.000250 | Estimated time: 60.24
Train loss on 50 batch: 0.206677
Train loss on 100 batch: 0.239522
Train loss on 150 batch: 0.178483
: Epoch: 8 | Training Loss: 0.237094 | Val. Loss: 0.299650 | Val. Kappa Score: 0.8568 | LR: 0.000250 | Estimated time: 61.39
Train loss on 50 batch: 0.223099
Train loss on 100 batch: 0.227614
Train loss on 150 batch: 0.211407
best-train-loss: 0.216941
best-valid-loss: 0.280899
best-kappa: 0.8609
: Epoch: 9 | Training Loss: 0.216941 | Val. Loss: 0.280899 | Val. Kappa Score: 0.8609 | LR: 0.000250 | Estimated time: 58.35
Train loss on 50 batch: 0.198110
Train loss on 100 batch: 0.225897
Train loss on 150 batch: 0.221966
: Epoch: 10 | Training Loss: 0.307460 | Val. Loss: 0.292828 | Val. Kappa Score: 0.8635 | LR: 0.000250 | Estimated time: 59.60
Train loss on 50 batch: 0.236437
Train loss on 100 batch: 0.205922
Train loss on 150 batch: 0.205137
: Epoch: 11 | Training Loss: 0.218306 | Val. Loss: 0.287943 | Val. Kappa Score: 0.8655 | LR: 0.000250 | Estimated time: 60.04
Train loss on 50 batch: 0.193783
Train loss on 100 batch: 0.192243
Train loss on 150 batch: 0.219070
: Epoch: 12 | Training Loss: 0.201325 | Val. Loss: 0.296856 | Val. Kappa Score: 0.8665 | LR: 0.000125 | Estimated time: 59.08
Train loss on 50 batch: 0.188682
Train loss on 100 batch: 0.234723
Train loss on 150 batch: 0.193649
: Epoch: 13 | Training Loss: 0.224160 | Val. Loss: 0.319604 | Val. Kappa Score: 0.8682 | LR: 0.000125 | Estimated time: 59.58
Train loss on 50 batch: 0.198957
Train loss on 100 batch: 0.202959
Train loss on 150 batch: 0.220815
: Epoch: 14 | Training Loss: 0.204225 | Val. Loss: 0.286226 | Val. Kappa Score: 0.8701 | LR: 0.000125 | Estimated time: 60.57
Train loss on 50 batch: 0.213486
Train loss on 100 batch: 0.202836
Train loss on 150 batch: 0.194777
: Epoch: 15 | Training Loss: 0.214486 | Val. Loss: 0.286878 | Val. Kappa Score: 0.8713 | LR: 0.000063 | Estimated time: 61.85
Train loss on 50 batch: 0.198475
Train loss on 100 batch: 0.178952
Train loss on 150 batch: 0.194049
best-train-loss: 0.198633
best-valid-loss: 0.280108
best-kappa: 0.8723
: Epoch: 16 | Training Loss: 0.198633 | Val. Loss: 0.280108 | Val. Kappa Score: 0.8723 | LR: 0.000063 | Estimated time: 59.95
Train loss on 50 batch: 0.228590
Train loss on 100 batch: 0.200228
Train loss on 150 batch: 0.168118
: Epoch: 17 | Training Loss: 0.197384 | Val. Loss: 0.281791 | Val. Kappa Score: 0.8734 | LR: 0.000063 | Estimated time: 60.76
Train loss on 50 batch: 0.193425
Train loss on 100 batch: 0.172402
Train loss on 150 batch: 0.197330
: Epoch: 18 | Training Loss: 0.195796 | Val. Loss: 0.281609 | Val. Kappa Score: 0.8748 | LR: 0.000063 | Estimated time: 62.05
Train loss on 50 batch: 0.166611
Train loss on 100 batch: 0.197046
Train loss on 150 batch: 0.201169
: Epoch: 19 | Training Loss: 0.194146 | Val. Loss: 0.280230 | Val. Kappa Score: 0.8756 | LR: 0.000031 | Estimated time: 64.19
Train loss on 50 batch: 0.178201
Train loss on 100 batch: 0.224355
Train loss on 150 batch: 0.176742
: Epoch: 20 | Training Loss: 0.191188 | Val. Loss: 0.280919 | Val. Kappa Score: 0.8766 | LR: 0.000031 | Estimated time: 62.98
Train loss on 50 batch: 0.178796
Train loss on 100 batch: 0.179628
Train loss on 150 batch: 0.179225
best-train-loss: 0.227478
best-valid-loss: 0.279838
best-kappa: 0.8777
: Epoch: 21 | Training Loss: 0.227478 | Val. Loss: 0.279838 | Val. Kappa Score: 0.8777 | LR: 0.000031 | Estimated time: 62.98
Train loss on 50 batch: 0.172393
Train loss on 100 batch: 0.190060
Train loss on 150 batch: 0.194103
: Epoch: 22 | Training Loss: 0.179766 | Val. Loss: 0.280124 | Val. Kappa Score: 0.8784 | LR: 0.000031 | Estimated time: 62.02
Train loss on 50 batch: 0.174137
Train loss on 100 batch: 0.184075
Train loss on 150 batch: 0.174169
: Epoch: 23 | Training Loss: 0.203612 | Val. Loss: 0.280860 | Val. Kappa Score: 0.8789 | LR: 0.000031 | Estimated time: 61.48
Train loss on 50 batch: 0.187810
Train loss on 100 batch: 0.188798
Train loss on 150 batch: 0.187279
: Epoch: 24 | Training Loss: 0.278027 | Val. Loss: 0.283614 | Val. Kappa Score: 0.8790 | LR: 0.000016 | Estimated time: 62.09
Train loss on 50 batch: 0.160595
Train loss on 100 batch: 0.179565
Train loss on 150 batch: 0.212934
: Epoch: 25 | Training Loss: 0.181660 | Val. Loss: 0.280464 | Val. Kappa Score: 0.8797 | LR: 0.000016 | Estimated time: 59.59
Train loss on 50 batch: 0.195966
Train loss on 100 batch: 0.150454
Train loss on 150 batch: 0.194284
: Epoch: 26 | Training Loss: 0.229941 | Val. Loss: 0.283915 | Val. Kappa Score: 0.8802 | LR: 0.000016 | Estimated time: 60.28
Train loss on 50 batch: 0.207758
Train loss on 100 batch: 0.208325
Train loss on 150 batch: 0.174012
: Epoch: 27 | Training Loss: 0.203491 | Val. Loss: 0.282628 | Val. Kappa Score: 0.8809 | LR: 0.000008 | Estimated time: 59.90
Train loss on 50 batch: 0.219054
Train loss on 100 batch: 0.179235
Train loss on 150 batch: 0.175196
: Epoch: 28 | Training Loss: 0.201996 | Val. Loss: 0.281968 | Val. Kappa Score: 0.8809 | LR: 0.000008 | Estimated time: 59.38
Train loss on 50 batch: 0.147544
Train loss on 100 batch: 0.197605
Train loss on 150 batch: 0.188897
: Epoch: 29 | Training Loss: 0.195785 | Val. Loss: 0.282469 | Val. Kappa Score: 0.8813 | LR: 0.000008 | Estimated time: 61.03
Train loss on 50 batch: 0.192755
Train loss on 100 batch: 0.193994
Train loss on 150 batch: 0.171947
: Epoch: 30 | Training Loss: 0.203774 | Val. Loss: 0.283202 | Val. Kappa Score: 0.8817 | LR: 0.000004 | Estimated time: 60.85
Train loss on 50 batch: 0.165587
Train loss on 100 batch: 0.193411
Train loss on 150 batch: 0.164241
: Epoch: 31 | Training Loss: 0.186740 | Val. Loss: 0.282304 | Val. Kappa Score: 0.8821 | LR: 0.000004 | Estimated time: 58.22
time_estimated: 1873.57
n-epochs: 31
time_estimated: 1873.63
----------------------------------------

Experiment N: 210: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 13:09:21
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50affa90>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 210: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 13:09:51
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b03a20>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 210: 



EXPERIMENT WITH BATCH_SIZE: 7, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 13:10:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b02a58>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 7
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 210: 



EXPERIMENT WITH BATCH_SIZE: 6, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 13:14:40
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50b049b0>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 6
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 210: 



EXPERIMENT WITH BATCH_SIZE: 8, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 13:15:31
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50affb00>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 8
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.615662
Train loss on 100 batch: 0.395084
Train loss on 150 batch: 0.412918
Train loss on 200 batch: 0.340011
Train loss on 250 batch: 0.358234
Train loss on 300 batch: 0.260847
Train loss on 350 batch: 0.332744
best-train-loss: 0.378930
best-valid-loss: 0.481992
best-kappa: 0.8100
: Epoch: 1 | Training Loss: 0.378930 | Val. Loss: 0.481992 | Val. Kappa Score: 0.8100 | LR: 0.001000 | Estimated time: 106.22
Train loss on 50 batch: 0.291928
Train loss on 100 batch: 0.322104
Train loss on 150 batch: 0.403230
Train loss on 200 batch: 0.302764
Train loss on 250 batch: 0.341092
Train loss on 300 batch: 0.259748
Train loss on 350 batch: 0.389423
best-train-loss: 0.343348
best-valid-loss: 0.395780
best-kappa: 0.8303
: Epoch: 2 | Training Loss: 0.343348 | Val. Loss: 0.395780 | Val. Kappa Score: 0.8303 | LR: 0.001000 | Estimated time: 104.05
Train loss on 50 batch: 0.282558
Train loss on 100 batch: 0.317563
Train loss on 150 batch: 0.265759
Train loss on 200 batch: 0.368174
Train loss on 250 batch: 0.252548
Train loss on 300 batch: 0.263908
Train loss on 350 batch: 0.266942
best-train-loss: 0.278754
best-valid-loss: 0.362706
best-kappa: 0.8434
: Epoch: 3 | Training Loss: 0.278754 | Val. Loss: 0.362706 | Val. Kappa Score: 0.8434 | LR: 0.001000 | Estimated time: 102.99
Train loss on 50 batch: 0.288820
Train loss on 100 batch: 0.289157
Train loss on 150 batch: 0.291644
Train loss on 200 batch: 0.378648
Train loss on 250 batch: 0.282894
Train loss on 300 batch: 0.274565
Train loss on 350 batch: 0.247823
best-train-loss: 0.377901
best-valid-loss: 0.318417
best-kappa: 0.8474
: Epoch: 4 | Training Loss: 0.377901 | Val. Loss: 0.318417 | Val. Kappa Score: 0.8474 | LR: 0.001000 | Estimated time: 102.73
Train loss on 50 batch: 0.312652
Train loss on 100 batch: 0.253121
Train loss on 150 batch: 0.305157
Train loss on 200 batch: 0.302802
Train loss on 250 batch: 0.264952
Train loss on 300 batch: 0.248502
Train loss on 350 batch: 0.282804
: Epoch: 5 | Training Loss: 0.297222 | Val. Loss: 0.522897 | Val. Kappa Score: 0.8209 | LR: 0.001000 | Estimated time: 103.22
Train loss on 50 batch: 0.316144
Train loss on 100 batch: 0.242738
Train loss on 150 batch: 0.249524
Train loss on 200 batch: 0.320632
Train loss on 250 batch: 0.228269
Train loss on 300 batch: 0.283656
Train loss on 350 batch: 0.263987
: Epoch: 6 | Training Loss: 0.261749 | Val. Loss: 0.326636 | Val. Kappa Score: 0.8254 | LR: 0.001000 | Estimated time: 102.82
Train loss on 50 batch: 0.263921
Train loss on 100 batch: 0.279715
Train loss on 150 batch: 0.278593
Train loss on 200 batch: 0.288140
Train loss on 250 batch: 0.284874
Train loss on 300 batch: 0.286993
Train loss on 350 batch: 0.280584
best-train-loss: 0.271465
best-valid-loss: 0.310927
best-kappa: 0.8320
: Epoch: 7 | Training Loss: 0.271465 | Val. Loss: 0.310927 | Val. Kappa Score: 0.8320 | LR: 0.001000 | Estimated time: 102.86
Train loss on 50 batch: 0.199740
Train loss on 100 batch: 0.245685
Train loss on 150 batch: 0.393628
Train loss on 200 batch: 0.263077
Train loss on 250 batch: 0.282392
Train loss on 300 batch: 0.241878
Train loss on 350 batch: 0.245444
: Epoch: 8 | Training Loss: 0.276511 | Val. Loss: 0.324960 | Val. Kappa Score: 0.8373 | LR: 0.001000 | Estimated time: 102.13
Train loss on 50 batch: 0.318729
Train loss on 100 batch: 0.300352
Train loss on 150 batch: 0.303432
Train loss on 200 batch: 0.248119
Train loss on 250 batch: 0.222355
Train loss on 300 batch: 0.310270
Train loss on 350 batch: 0.216758
: Epoch: 9 | Training Loss: 0.273184 | Val. Loss: 0.665476 | Val. Kappa Score: 0.8170 | LR: 0.001000 | Estimated time: 102.85
Train loss on 50 batch: 0.242534
Train loss on 100 batch: 0.216120
Train loss on 150 batch: 0.291042
Train loss on 200 batch: 0.286237
Train loss on 250 batch: 0.204852
Train loss on 300 batch: 0.321967
Train loss on 350 batch: 0.232178
: Epoch: 10 | Training Loss: 0.327339 | Val. Loss: 0.332609 | Val. Kappa Score: 0.8208 | LR: 0.000500 | Estimated time: 103.03
Train loss on 50 batch: 0.244194
Train loss on 100 batch: 0.240073
Train loss on 150 batch: 0.209386
Train loss on 200 batch: 0.311690
Train loss on 250 batch: 0.177017
Train loss on 300 batch: 0.271132
Train loss on 350 batch: 0.235512
best-train-loss: 0.244414
best-valid-loss: 0.278226
best-kappa: 0.8256
: Epoch: 11 | Training Loss: 0.244414 | Val. Loss: 0.278226 | Val. Kappa Score: 0.8256 | LR: 0.000500 | Estimated time: 102.70
Train loss on 50 batch: 0.197285
Train loss on 100 batch: 0.239142
Train loss on 150 batch: 0.197706
Train loss on 200 batch: 0.194799
Train loss on 250 batch: 0.261380
Train loss on 300 batch: 0.235660
Train loss on 350 batch: 0.216741
: Epoch: 12 | Training Loss: 0.220632 | Val. Loss: 0.303033 | Val. Kappa Score: 0.8286 | LR: 0.000500 | Estimated time: 102.54
Train loss on 50 batch: 0.207589
Train loss on 100 batch: 0.208221
Train loss on 150 batch: 0.228609
Train loss on 200 batch: 0.223159
Train loss on 250 batch: 0.201165
Train loss on 300 batch: 0.225347
Train loss on 350 batch: 0.229875
: Epoch: 13 | Training Loss: 0.213179 | Val. Loss: 0.338376 | Val. Kappa Score: 0.8314 | LR: 0.000500 | Estimated time: 101.58
Train loss on 50 batch: 0.187737
Train loss on 100 batch: 0.195012
Train loss on 150 batch: 0.198449
Train loss on 200 batch: 0.230966
Train loss on 250 batch: 0.269448
Train loss on 300 batch: 0.196748
Train loss on 350 batch: 0.197064
: Epoch: 14 | Training Loss: 0.223943 | Val. Loss: 0.308381 | Val. Kappa Score: 0.8332 | LR: 0.000250 | Estimated time: 102.48
Train loss on 50 batch: 0.209543
Train loss on 100 batch: 0.199374
Train loss on 150 batch: 0.181840
Train loss on 200 batch: 0.222891
Train loss on 250 batch: 0.218877
Train loss on 300 batch: 0.201671
Train loss on 350 batch: 0.199278
: Epoch: 15 | Training Loss: 0.211576 | Val. Loss: 0.311215 | Val. Kappa Score: 0.8354 | LR: 0.000250 | Estimated time: 102.50
Train loss on 50 batch: 0.199352
Train loss on 100 batch: 0.196661
Train loss on 150 batch: 0.189154
Train loss on 200 batch: 0.172946
Train loss on 250 batch: 0.224136
Train loss on 300 batch: 0.172484
Train loss on 350 batch: 0.184197
best-train-loss: 0.189800
best-valid-loss: 0.272644
best-kappa: 0.8374
: Epoch: 16 | Training Loss: 0.189800 | Val. Loss: 0.272644 | Val. Kappa Score: 0.8374 | LR: 0.000250 | Estimated time: 102.63
Train loss on 50 batch: 0.209514
Train loss on 100 batch: 0.239795
Train loss on 150 batch: 0.214928
Train loss on 200 batch: 0.248114
Train loss on 250 batch: 0.164713
Train loss on 300 batch: 0.184103
Train loss on 350 batch: 0.184697
: Epoch: 17 | Training Loss: 0.208490 | Val. Loss: 0.315013 | Val. Kappa Score: 0.8390 | LR: 0.000250 | Estimated time: 101.77
Train loss on 50 batch: 0.190117
Train loss on 100 batch: 0.198553
Train loss on 150 batch: 0.152796
Train loss on 200 batch: 0.152971
Train loss on 250 batch: 0.202668
Train loss on 300 batch: 0.198521
Train loss on 350 batch: 0.201115
: Epoch: 18 | Training Loss: 0.185314 | Val. Loss: 0.279808 | Val. Kappa Score: 0.8412 | LR: 0.000250 | Estimated time: 103.05
Train loss on 50 batch: 0.186842
Train loss on 100 batch: 0.138139
Train loss on 150 batch: 0.212079
Train loss on 200 batch: 0.180704
Train loss on 250 batch: 0.155993
Train loss on 300 batch: 0.215703
Train loss on 350 batch: 0.190723
: Epoch: 19 | Training Loss: 0.184554 | Val. Loss: 0.280497 | Val. Kappa Score: 0.8428 | LR: 0.000125 | Estimated time: 102.53
Train loss on 50 batch: 0.157934
Train loss on 100 batch: 0.237325
Train loss on 150 batch: 0.212594
Train loss on 200 batch: 0.234458
Train loss on 250 batch: 0.174154
Train loss on 300 batch: 0.174944
Train loss on 350 batch: 0.209493
: Epoch: 20 | Training Loss: 0.194457 | Val. Loss: 0.324877 | Val. Kappa Score: 0.8431 | LR: 0.000125 | Estimated time: 102.70
Train loss on 50 batch: 0.160826
Train loss on 100 batch: 0.181189
Train loss on 150 batch: 0.185400
Train loss on 200 batch: 0.176119
Train loss on 250 batch: 0.189089
Train loss on 300 batch: 0.171503
Train loss on 350 batch: 0.172423
: Epoch: 21 | Training Loss: 0.198690 | Val. Loss: 0.297007 | Val. Kappa Score: 0.8443 | LR: 0.000125 | Estimated time: 103.20
Train loss on 50 batch: 0.158099
Train loss on 100 batch: 0.173369
Train loss on 150 batch: 0.199832
Train loss on 200 batch: 0.203753
Train loss on 250 batch: 0.184595
Train loss on 300 batch: 0.183125
Train loss on 350 batch: 0.205599
: Epoch: 22 | Training Loss: 0.178206 | Val. Loss: 0.308117 | Val. Kappa Score: 0.8454 | LR: 0.000063 | Estimated time: 104.23
Train loss on 50 batch: 0.155140
Train loss on 100 batch: 0.180295
Train loss on 150 batch: 0.187253
Train loss on 200 batch: 0.168793
Train loss on 250 batch: 0.169843
Train loss on 300 batch: 0.177856
Train loss on 350 batch: 0.211395
: Epoch: 23 | Training Loss: 0.182520 | Val. Loss: 0.282789 | Val. Kappa Score: 0.8467 | LR: 0.000063 | Estimated time: 105.03
Train loss on 50 batch: 0.224133
Train loss on 100 batch: 0.163693
Train loss on 150 batch: 0.212168
Train loss on 200 batch: 0.138957
Train loss on 250 batch: 0.185675
Train loss on 300 batch: 0.152497
Train loss on 350 batch: 0.179670
best-train-loss: 0.253464
best-valid-loss: 0.269448
best-kappa: 0.8475
: Epoch: 24 | Training Loss: 0.253464 | Val. Loss: 0.269448 | Val. Kappa Score: 0.8475 | LR: 0.000063 | Estimated time: 104.24
Train loss on 50 batch: 0.182142
Train loss on 100 batch: 0.131363
Train loss on 150 batch: 0.151033
Train loss on 200 batch: 0.168656
Train loss on 250 batch: 0.174276
Train loss on 300 batch: 0.201810
Train loss on 350 batch: 0.175310
: Epoch: 25 | Training Loss: 0.171069 | Val. Loss: 0.269934 | Val. Kappa Score: 0.8488 | LR: 0.000063 | Estimated time: 103.86
Train loss on 50 batch: 0.196370
Train loss on 100 batch: 0.169903
Train loss on 150 batch: 0.142132
Train loss on 200 batch: 0.144636
Train loss on 250 batch: 0.159646
Train loss on 300 batch: 0.226743
Train loss on 350 batch: 0.204398
: Epoch: 26 | Training Loss: 0.195053 | Val. Loss: 0.286323 | Val. Kappa Score: 0.8497 | LR: 0.000063 | Estimated time: 102.81
Train loss on 50 batch: 0.172302
Train loss on 100 batch: 0.183806
Train loss on 150 batch: 0.187898
Train loss on 200 batch: 0.259689
Train loss on 250 batch: 0.169375
Train loss on 300 batch: 0.143975
Train loss on 350 batch: 0.133738
: Epoch: 27 | Training Loss: 0.189174 | Val. Loss: 0.270281 | Val. Kappa Score: 0.8504 | LR: 0.000031 | Estimated time: 102.75
Train loss on 50 batch: 0.196132
Train loss on 100 batch: 0.217682
Train loss on 150 batch: 0.148117
Train loss on 200 batch: 0.158978
Train loss on 250 batch: 0.194736
Train loss on 300 batch: 0.111520
Train loss on 350 batch: 0.169205
: Epoch: 28 | Training Loss: 0.174259 | Val. Loss: 0.271348 | Val. Kappa Score: 0.8509 | LR: 0.000031 | Estimated time: 102.29
Train loss on 50 batch: 0.141708
Train loss on 100 batch: 0.123216
Train loss on 150 batch: 0.178108
Train loss on 200 batch: 0.182492
Train loss on 250 batch: 0.175357
Train loss on 300 batch: 0.146629
Train loss on 350 batch: 0.176128
: Epoch: 29 | Training Loss: 0.166806 | Val. Loss: 0.271921 | Val. Kappa Score: 0.8517 | LR: 0.000031 | Estimated time: 102.34
Train loss on 50 batch: 0.156669
Train loss on 100 batch: 0.164525
Train loss on 150 batch: 0.199826
Train loss on 200 batch: 0.166822
Train loss on 250 batch: 0.184254
Train loss on 300 batch: 0.144185
Train loss on 350 batch: 0.181901
: Epoch: 30 | Training Loss: 0.168340 | Val. Loss: 0.275067 | Val. Kappa Score: 0.8526 | LR: 0.000016 | Estimated time: 103.60
Train loss on 50 batch: 0.113563
Train loss on 100 batch: 0.177092
Train loss on 150 batch: 0.229447
Train loss on 200 batch: 0.173959
Train loss on 250 batch: 0.164778
Train loss on 300 batch: 0.125392
Train loss on 350 batch: 0.182783
: Epoch: 31 | Training Loss: 0.167167 | Val. Loss: 0.273188 | Val. Kappa Score: 0.8530 | LR: 0.000016 | Estimated time: 103.53
Train loss on 50 batch: 0.189171
Train loss on 100 batch: 0.177616
Train loss on 150 batch: 0.191660
Train loss on 200 batch: 0.178933
Train loss on 250 batch: 0.167691
Train loss on 300 batch: 0.173056
Train loss on 350 batch: 0.184116
: Epoch: 32 | Training Loss: 0.174356 | Val. Loss: 0.272808 | Val. Kappa Score: 0.8533 | LR: 0.000016 | Estimated time: 103.60
Train loss on 50 batch: 0.152555
Train loss on 100 batch: 0.190280
Train loss on 150 batch: 0.173791
Train loss on 200 batch: 0.162170
Train loss on 250 batch: 0.138811
Train loss on 300 batch: 0.165736
Train loss on 350 batch: 0.198510
best-train-loss: 0.168608
best-valid-loss: 0.269159
best-kappa: 0.8540
: Epoch: 33 | Training Loss: 0.168608 | Val. Loss: 0.269159 | Val. Kappa Score: 0.8540 | LR: 0.000016 | Estimated time: 103.15
Train loss on 50 batch: 0.136408
Train loss on 100 batch: 0.167632
Train loss on 150 batch: 0.135177
Train loss on 200 batch: 0.190377
Train loss on 250 batch: 0.167875
Train loss on 300 batch: 0.164375
Train loss on 350 batch: 0.183878
: Epoch: 34 | Training Loss: 0.162325 | Val. Loss: 0.274797 | Val. Kappa Score: 0.8547 | LR: 0.000016 | Estimated time: 102.24
Train loss on 50 batch: 0.160027
Train loss on 100 batch: 0.139377
Train loss on 150 batch: 0.163458
Train loss on 200 batch: 0.194503
Train loss on 250 batch: 0.153822
Train loss on 300 batch: 0.191587
Train loss on 350 batch: 0.183713
: Epoch: 35 | Training Loss: 0.180964 | Val. Loss: 0.275564 | Val. Kappa Score: 0.8550 | LR: 0.000016 | Estimated time: 103.74
Train loss on 50 batch: 0.119223
Train loss on 100 batch: 0.167230
Train loss on 150 batch: 0.170564
Train loss on 200 batch: 0.186090
Train loss on 250 batch: 0.154331
Train loss on 300 batch: 0.170536
Train loss on 350 batch: 0.241397
: Epoch: 36 | Training Loss: 0.173512 | Val. Loss: 0.274500 | Val. Kappa Score: 0.8554 | LR: 0.000008 | Estimated time: 102.99
Train loss on 50 batch: 0.152276
Train loss on 100 batch: 0.144470
Train loss on 150 batch: 0.140649
Train loss on 200 batch: 0.188499
Train loss on 250 batch: 0.176482
Train loss on 300 batch: 0.149430
Train loss on 350 batch: 0.173785
: Epoch: 37 | Training Loss: 0.167165 | Val. Loss: 0.271646 | Val. Kappa Score: 0.8560 | LR: 0.000008 | Estimated time: 102.72
Train loss on 50 batch: 0.166796
Train loss on 100 batch: 0.140029
Train loss on 150 batch: 0.154228
Train loss on 200 batch: 0.169101
Train loss on 250 batch: 0.181747
Train loss on 300 batch: 0.160656
Train loss on 350 batch: 0.176533
: Epoch: 38 | Training Loss: 0.233378 | Val. Loss: 0.269424 | Val. Kappa Score: 0.8566 | LR: 0.000008 | Estimated time: 102.51
Train loss on 50 batch: 0.184296
Train loss on 100 batch: 0.134992
Train loss on 150 batch: 0.139222
Train loss on 200 batch: 0.194510
Train loss on 250 batch: 0.150880
Train loss on 300 batch: 0.188435
Train loss on 350 batch: 0.166177
: Epoch: 39 | Training Loss: 0.183291 | Val. Loss: 0.271305 | Val. Kappa Score: 0.8568 | LR: 0.000004 | Estimated time: 103.02
Train loss on 50 batch: 0.155655
Train loss on 100 batch: 0.169310
Train loss on 150 batch: 0.150571
Train loss on 200 batch: 0.164513
Train loss on 250 batch: 0.196866
Train loss on 300 batch: 0.153875
Train loss on 350 batch: 0.146127
: Epoch: 40 | Training Loss: 0.159294 | Val. Loss: 0.269535 | Val. Kappa Score: 0.8570 | LR: 0.000004 | Estimated time: 103.15
Train loss on 50 batch: 0.145050
Train loss on 100 batch: 0.164896
Train loss on 150 batch: 0.182351
Train loss on 200 batch: 0.163708
Train loss on 250 batch: 0.164879
Train loss on 300 batch: 0.159725
Train loss on 350 batch: 0.169219
: Epoch: 41 | Training Loss: 0.163533 | Val. Loss: 0.272229 | Val. Kappa Score: 0.8571 | LR: 0.000004 | Estimated time: 103.54
Train loss on 50 batch: 0.196207
Train loss on 100 batch: 0.198513
Train loss on 150 batch: 0.143629
Train loss on 200 batch: 0.107657
Train loss on 250 batch: 0.157345
Train loss on 300 batch: 0.183249
Train loss on 350 batch: 0.155834
: Epoch: 42 | Training Loss: 0.165084 | Val. Loss: 0.270124 | Val. Kappa Score: 0.8576 | LR: 0.000002 | Estimated time: 104.11
Train loss on 50 batch: 0.200261
Train loss on 100 batch: 0.169513
Train loss on 150 batch: 0.150627
Train loss on 200 batch: 0.146487
Train loss on 250 batch: 0.141212
Train loss on 300 batch: 0.150068
Train loss on 350 batch: 0.199866
: Epoch: 43 | Training Loss: 0.166243 | Val. Loss: 0.269869 | Val. Kappa Score: 0.8580 | LR: 0.000002 | Estimated time: 103.61
time_estimated: 4437.24
n-epochs: 43
time_estimated: 4437.31
----------------------------------------

Experiment N: 211: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b5


: 
date: 2019.09.05 23:11:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50affb00>
early-stopping-patience: 10
parameters-amount: 28342833
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 211: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.001, p_horizontalflip: 0.4, model_type: ResNext101


: 
date: 2019.09.05 23:12:32
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50bda0f0>
early-stopping-patience: 10
parameters-amount: 86744385
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.745900
Train loss on 100 batch: 0.546278
Train loss on 150 batch: 0.512142
best-train-loss: 0.555473
best-valid-loss: 0.461711
best-kappa: 0.8251
: Epoch: 1 | Training Loss: 0.555473 | Val. Loss: 0.461711 | Val. Kappa Score: 0.8251 | LR: 0.001000 | Estimated time: 98.77
Train loss on 50 batch: 0.445730
Train loss on 100 batch: 0.501429
Train loss on 150 batch: 0.394787
best-train-loss: 0.479543
best-valid-loss: 0.418450
best-kappa: 0.8313
: Epoch: 2 | Training Loss: 0.479543 | Val. Loss: 0.418450 | Val. Kappa Score: 0.8313 | LR: 0.001000 | Estimated time: 100.43
Train loss on 50 batch: 0.512012
Train loss on 100 batch: 0.482569
Train loss on 150 batch: 0.476030
best-train-loss: 0.489266
best-valid-loss: 0.412982
best-kappa: 0.8352
: Epoch: 3 | Training Loss: 0.489266 | Val. Loss: 0.412982 | Val. Kappa Score: 0.8352 | LR: 0.001000 | Estimated time: 102.10
Train loss on 50 batch: 0.456914
Train loss on 100 batch: 0.472631
Train loss on 150 batch: 0.433741
best-train-loss: 0.519987
best-valid-loss: 0.398771
best-kappa: 0.8390
: Epoch: 4 | Training Loss: 0.519987 | Val. Loss: 0.398771 | Val. Kappa Score: 0.8390 | LR: 0.001000 | Estimated time: 100.62
Train loss on 50 batch: 0.416514
Train loss on 100 batch: 0.457434
Train loss on 150 batch: 0.405549
: Epoch: 5 | Training Loss: 0.440776 | Val. Loss: 0.738890 | Val. Kappa Score: 0.8135 | LR: 0.001000 | Estimated time: 101.12
Train loss on 50 batch: 0.441898
Train loss on 100 batch: 0.415375
Train loss on 150 batch: 0.417792
: Epoch: 6 | Training Loss: 0.418879 | Val. Loss: 0.470962 | Val. Kappa Score: 0.8146 | LR: 0.001000 | Estimated time: 99.26
Train loss on 50 batch: 0.446472
Train loss on 100 batch: 0.404401
Train loss on 150 batch: 0.384980
best-train-loss: 0.423145
best-valid-loss: 0.383706
best-kappa: 0.8219
: Epoch: 7 | Training Loss: 0.423145 | Val. Loss: 0.383706 | Val. Kappa Score: 0.8219 | LR: 0.001000 | Estimated time: 105.55
Train loss on 50 batch: 0.375077
Train loss on 100 batch: 0.417646
Train loss on 150 batch: 0.354045
: Epoch: 8 | Training Loss: 0.374271 | Val. Loss: 0.385822 | Val. Kappa Score: 0.8263 | LR: 0.001000 | Estimated time: 101.58
Train loss on 50 batch: 0.386813
Train loss on 100 batch: 0.450089
Train loss on 150 batch: 0.378536
: Epoch: 9 | Training Loss: 0.393640 | Val. Loss: 0.434248 | Val. Kappa Score: 0.8281 | LR: 0.001000 | Estimated time: 103.84
Train loss on 50 batch: 0.350497
Train loss on 100 batch: 0.392900
Train loss on 150 batch: 0.376754
best-train-loss: 0.408570
best-valid-loss: 0.379167
best-kappa: 0.8298
: Epoch: 10 | Training Loss: 0.408570 | Val. Loss: 0.379167 | Val. Kappa Score: 0.8298 | LR: 0.001000 | Estimated time: 101.08
Train loss on 50 batch: 0.378199
Train loss on 100 batch: 0.353387
Train loss on 150 batch: 0.377986
best-train-loss: 0.382499
best-valid-loss: 0.363508
best-kappa: 0.8326
: Epoch: 11 | Training Loss: 0.382499 | Val. Loss: 0.363508 | Val. Kappa Score: 0.8326 | LR: 0.001000 | Estimated time: 106.87
Train loss on 50 batch: 0.373026
Train loss on 100 batch: 0.327610
Train loss on 150 batch: 0.403627
: Epoch: 12 | Training Loss: 0.382561 | Val. Loss: 0.478289 | Val. Kappa Score: 0.8311 | LR: 0.001000 | Estimated time: 105.77
Train loss on 50 batch: 0.367865
Train loss on 100 batch: 0.378996
Train loss on 150 batch: 0.380178
: Epoch: 13 | Training Loss: 0.365141 | Val. Loss: 0.480035 | Val. Kappa Score: 0.8317 | LR: 0.001000 | Estimated time: 103.66
Train loss on 50 batch: 0.337035
Train loss on 100 batch: 0.337546
Train loss on 150 batch: 0.381325
: Epoch: 14 | Training Loss: 0.358860 | Val. Loss: 0.404622 | Val. Kappa Score: 0.8330 | LR: 0.000500 | Estimated time: 101.69
Train loss on 50 batch: 0.394385
Train loss on 100 batch: 0.334163
Train loss on 150 batch: 0.332800
: Epoch: 15 | Training Loss: 0.340211 | Val. Loss: 0.430265 | Val. Kappa Score: 0.8322 | LR: 0.000500 | Estimated time: 104.68
Train loss on 50 batch: 0.335905
Train loss on 100 batch: 0.295737
Train loss on 150 batch: 0.303041
: Epoch: 16 | Training Loss: 0.323207 | Val. Loss: 0.369485 | Val. Kappa Score: 0.8339 | LR: 0.000500 | Estimated time: 102.86
Train loss on 50 batch: 0.368886
Train loss on 100 batch: 0.323472
Train loss on 150 batch: 0.297441
: Epoch: 17 | Training Loss: 0.333957 | Val. Loss: 0.369912 | Val. Kappa Score: 0.8354 | LR: 0.000250 | Estimated time: 107.91
Train loss on 50 batch: 0.318664
Train loss on 100 batch: 0.261253
Train loss on 150 batch: 0.309365
best-train-loss: 0.297838
best-valid-loss: 0.345350
best-kappa: 0.8373
: Epoch: 18 | Training Loss: 0.297838 | Val. Loss: 0.345350 | Val. Kappa Score: 0.8373 | LR: 0.000250 | Estimated time: 104.64
Train loss on 50 batch: 0.264165
Train loss on 100 batch: 0.297775
Train loss on 150 batch: 0.354720
: Epoch: 19 | Training Loss: 0.327886 | Val. Loss: 0.347051 | Val. Kappa Score: 0.8387 | LR: 0.000250 | Estimated time: 100.02
Train loss on 50 batch: 0.304024
Train loss on 100 batch: 0.315029
Train loss on 150 batch: 0.290224
: Epoch: 20 | Training Loss: 0.307576 | Val. Loss: 0.347504 | Val. Kappa Score: 0.8399 | LR: 0.000250 | Estimated time: 98.11
Train loss on 50 batch: 0.307608
Train loss on 100 batch: 0.278585
Train loss on 150 batch: 0.311432
: Epoch: 21 | Training Loss: 0.312325 | Val. Loss: 0.386478 | Val. Kappa Score: 0.8405 | LR: 0.000125 | Estimated time: 97.56
Train loss on 50 batch: 0.297804
Train loss on 100 batch: 0.294945
Train loss on 150 batch: 0.312972
: Epoch: 22 | Training Loss: 0.299965 | Val. Loss: 0.346332 | Val. Kappa Score: 0.8415 | LR: 0.000125 | Estimated time: 98.32
Train loss on 50 batch: 0.300252
Train loss on 100 batch: 0.279055
Train loss on 150 batch: 0.300561
: Epoch: 23 | Training Loss: 0.292402 | Val. Loss: 0.353040 | Val. Kappa Score: 0.8423 | LR: 0.000125 | Estimated time: 105.18
Train loss on 50 batch: 0.297459
Train loss on 100 batch: 0.307293
Train loss on 150 batch: 0.275189
: Epoch: 24 | Training Loss: 0.330640 | Val. Loss: 0.390547 | Val. Kappa Score: 0.8425 | LR: 0.000063 | Estimated time: 106.24
Train loss on 50 batch: 0.289336
Train loss on 100 batch: 0.255013
Train loss on 150 batch: 0.317458
best-train-loss: 0.305354
best-valid-loss: 0.337568
best-kappa: 0.8440
: Epoch: 25 | Training Loss: 0.305354 | Val. Loss: 0.337568 | Val. Kappa Score: 0.8440 | LR: 0.000063 | Estimated time: 104.13
Train loss on 50 batch: 0.288405
Train loss on 100 batch: 0.232658
Train loss on 150 batch: 0.329673
: Epoch: 26 | Training Loss: 0.300061 | Val. Loss: 0.352934 | Val. Kappa Score: 0.8453 | LR: 0.000063 | Estimated time: 103.25
Train loss on 50 batch: 0.304813
Train loss on 100 batch: 0.332539
Train loss on 150 batch: 0.263702
: Epoch: 27 | Training Loss: 0.294209 | Val. Loss: 0.341853 | Val. Kappa Score: 0.8463 | LR: 0.000063 | Estimated time: 103.67
Train loss on 50 batch: 0.342414
Train loss on 100 batch: 0.291183
Train loss on 150 batch: 0.270210
: Epoch: 28 | Training Loss: 0.288422 | Val. Loss: 0.340625 | Val. Kappa Score: 0.8469 | LR: 0.000031 | Estimated time: 100.58
Train loss on 50 batch: 0.249355
Train loss on 100 batch: 0.317879
Train loss on 150 batch: 0.284124
: Epoch: 29 | Training Loss: 0.281277 | Val. Loss: 0.352956 | Val. Kappa Score: 0.8476 | LR: 0.000031 | Estimated time: 106.18
Train loss on 50 batch: 0.286694
Train loss on 100 batch: 0.289029
Train loss on 150 batch: 0.277992
: Epoch: 30 | Training Loss: 0.278725 | Val. Loss: 0.354318 | Val. Kappa Score: 0.8481 | LR: 0.000031 | Estimated time: 103.16
Train loss on 50 batch: 0.246277
Train loss on 100 batch: 0.310110
Train loss on 150 batch: 0.284743
best-train-loss: 0.313044
best-valid-loss: 0.332205
best-kappa: 0.8490
: Epoch: 31 | Training Loss: 0.313044 | Val. Loss: 0.332205 | Val. Kappa Score: 0.8490 | LR: 0.000031 | Estimated time: 104.91
Train loss on 50 batch: 0.262029
Train loss on 100 batch: 0.326233
Train loss on 150 batch: 0.254140
: Epoch: 32 | Training Loss: 0.281755 | Val. Loss: 0.339345 | Val. Kappa Score: 0.8497 | LR: 0.000031 | Estimated time: 107.67
Train loss on 50 batch: 0.271686
Train loss on 100 batch: 0.283579
Train loss on 150 batch: 0.265272
: Epoch: 33 | Training Loss: 0.280888 | Val. Loss: 0.343393 | Val. Kappa Score: 0.8503 | LR: 0.000031 | Estimated time: 109.98
Train loss on 50 batch: 0.268515
Train loss on 100 batch: 0.287951
Train loss on 150 batch: 0.304506
best-train-loss: 0.291829
best-valid-loss: 0.329245
best-kappa: 0.8507
: Epoch: 34 | Training Loss: 0.291829 | Val. Loss: 0.329245 | Val. Kappa Score: 0.8507 | LR: 0.000031 | Estimated time: 109.68
Train loss on 50 batch: 0.263099
Train loss on 100 batch: 0.280971
Train loss on 150 batch: 0.260485
: Epoch: 35 | Training Loss: 0.283679 | Val. Loss: 0.342751 | Val. Kappa Score: 0.8512 | LR: 0.000031 | Estimated time: 110.38
Train loss on 50 batch: 0.239497
Train loss on 100 batch: 0.294734
Train loss on 150 batch: 0.261160
: Epoch: 36 | Training Loss: 0.283718 | Val. Loss: 0.338117 | Val. Kappa Score: 0.8516 | LR: 0.000031 | Estimated time: 109.94
Train loss on 50 batch: 0.290844
Train loss on 100 batch: 0.270739
Train loss on 150 batch: 0.280964
: Epoch: 37 | Training Loss: 0.287122 | Val. Loss: 0.332461 | Val. Kappa Score: 0.8520 | LR: 0.000016 | Estimated time: 109.89
Train loss on 50 batch: 0.268669
Train loss on 100 batch: 0.264425
Train loss on 150 batch: 0.270869
: Epoch: 38 | Training Loss: 0.313171 | Val. Loss: 0.352525 | Val. Kappa Score: 0.8521 | LR: 0.000016 | Estimated time: 109.82
Train loss on 50 batch: 0.273099
Train loss on 100 batch: 0.288175
Train loss on 150 batch: 0.289473
: Epoch: 39 | Training Loss: 0.287435 | Val. Loss: 0.332450 | Val. Kappa Score: 0.8526 | LR: 0.000016 | Estimated time: 110.71
Train loss on 50 batch: 0.274983
Train loss on 100 batch: 0.265016
Train loss on 150 batch: 0.283013
: Epoch: 40 | Training Loss: 0.272766 | Val. Loss: 0.330543 | Val. Kappa Score: 0.8531 | LR: 0.000008 | Estimated time: 102.51
Train loss on 50 batch: 0.264573
Train loss on 100 batch: 0.285646
Train loss on 150 batch: 0.282300
: Epoch: 41 | Training Loss: 0.297591 | Val. Loss: 0.332395 | Val. Kappa Score: 0.8536 | LR: 0.000008 | Estimated time: 109.53
Train loss on 50 batch: 0.291649
Train loss on 100 batch: 0.235582
Train loss on 150 batch: 0.304740
: Epoch: 42 | Training Loss: 0.288598 | Val. Loss: 0.332490 | Val. Kappa Score: 0.8541 | LR: 0.000008 | Estimated time: 109.61
Train loss on 50 batch: 0.285110
Train loss on 100 batch: 0.293029
Train loss on 150 batch: 0.246974
: Epoch: 43 | Training Loss: 0.291932 | Val. Loss: 0.330845 | Val. Kappa Score: 0.8547 | LR: 0.000004 | Estimated time: 109.75
Train loss on 50 batch: 0.277019
Train loss on 100 batch: 0.299359
Train loss on 150 batch: 0.275974
: Epoch: 44 | Training Loss: 0.278016 | Val. Loss: 0.329900 | Val. Kappa Score: 0.8550 | LR: 0.000004 | Estimated time: 111.15
time_estimated: 4609.63
n-epochs: 44
time_estimated: 4609.71
----------------------------------------

Experiment N: 212: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.09.06 18:43:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50ab8e48>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.551783
Train loss on 100 batch: 0.428695
Train loss on 150 batch: 0.370275
best-train-loss: 0.413563
best-valid-loss: 0.373031
best-kappa: 0.8636
: Epoch: 1 | Training Loss: 0.413563 | Val. Loss: 0.373031 | Val. Kappa Score: 0.8636 | LR: 0.000500 | Estimated time: 61.83
----------------------------------------

Experiment N: 213: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.09.06 22:35:10
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50ab7dd8>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.570278
Train loss on 100 batch: 0.417112
Train loss on 150 batch: 0.386481
best-train-loss: 0.435086
best-valid-loss: 0.386358
best-kappa: 0.8515
: Epoch: 1 | Training Loss: 0.435086 | Val. Loss: 0.386358 | Val. Kappa Score: 0.8515 | LR: 0.000500 | Estimated time: 55.35
Train loss on 50 batch: 0.327865
Train loss on 100 batch: 0.336269
Train loss on 150 batch: 0.332817
best-train-loss: 0.370768
best-valid-loss: 0.350051
best-kappa: 0.8580
: Epoch: 2 | Training Loss: 0.370768 | Val. Loss: 0.350051 | Val. Kappa Score: 0.8580 | LR: 0.000500 | Estimated time: 54.45
Train loss on 50 batch: 0.330810
Train loss on 100 batch: 0.347795
Train loss on 150 batch: 0.331624
best-train-loss: 0.332566
best-valid-loss: 0.334983
best-kappa: 0.8643
: Epoch: 3 | Training Loss: 0.332566 | Val. Loss: 0.334983 | Val. Kappa Score: 0.8643 | LR: 0.000500 | Estimated time: 57.74
Train loss on 50 batch: 0.319972
Train loss on 100 batch: 0.344515
Train loss on 150 batch: 0.299492
: Epoch: 4 | Training Loss: 0.384181 | Val. Loss: 0.454041 | Val. Kappa Score: 0.8534 | LR: 0.000500 | Estimated time: 55.44
Train loss on 50 batch: 0.359371
Train loss on 100 batch: 0.387146
Train loss on 150 batch: 0.271037
best-train-loss: 0.333511
best-valid-loss: 0.316771
best-kappa: 0.8560
: Epoch: 5 | Training Loss: 0.333511 | Val. Loss: 0.316771 | Val. Kappa Score: 0.8560 | LR: 0.000500 | Estimated time: 55.93
Train loss on 50 batch: 0.304641
Train loss on 100 batch: 0.307407
Train loss on 150 batch: 0.293765
: Epoch: 6 | Training Loss: 0.286886 | Val. Loss: 0.397595 | Val. Kappa Score: 0.8537 | LR: 0.000500 | Estimated time: 55.67
Train loss on 50 batch: 0.263888
Train loss on 100 batch: 0.280237
Train loss on 150 batch: 0.259616
best-train-loss: 0.269181
best-valid-loss: 0.304120
best-kappa: 0.8576
: Epoch: 7 | Training Loss: 0.269181 | Val. Loss: 0.304120 | Val. Kappa Score: 0.8576 | LR: 0.000500 | Estimated time: 55.59
Train loss on 50 batch: 0.243388
Train loss on 100 batch: 0.288185
Train loss on 150 batch: 0.232102
best-train-loss: 0.271287
best-valid-loss: 0.293225
best-kappa: 0.8621
: Epoch: 8 | Training Loss: 0.271287 | Val. Loss: 0.293225 | Val. Kappa Score: 0.8621 | LR: 0.000500 | Estimated time: 54.81
Train loss on 50 batch: 0.250047
Train loss on 100 batch: 0.323600
Train loss on 150 batch: 0.289064
: Epoch: 9 | Training Loss: 0.288926 | Val. Loss: 0.305567 | Val. Kappa Score: 0.8642 | LR: 0.000500 | Estimated time: 55.85
Train loss on 50 batch: 0.246318
Train loss on 100 batch: 0.236876
Train loss on 150 batch: 0.237353
best-train-loss: 0.319074
best-valid-loss: 0.262861
best-kappa: 0.8673
: Epoch: 10 | Training Loss: 0.319074 | Val. Loss: 0.262861 | Val. Kappa Score: 0.8673 | LR: 0.000500 | Estimated time: 55.55
Train loss on 50 batch: 0.263913
Train loss on 100 batch: 0.289370
Train loss on 150 batch: 0.272308
: Epoch: 11 | Training Loss: 0.267385 | Val. Loss: 0.280622 | Val. Kappa Score: 0.8693 | LR: 0.000500 | Estimated time: 55.39
Train loss on 50 batch: 0.224742
Train loss on 100 batch: 0.220745
Train loss on 150 batch: 0.255559
: Epoch: 12 | Training Loss: 0.239826 | Val. Loss: 0.308183 | Val. Kappa Score: 0.8698 | LR: 0.000500 | Estimated time: 55.76
Train loss on 50 batch: 0.222735
Train loss on 100 batch: 0.263342
Train loss on 150 batch: 0.206959
: Epoch: 13 | Training Loss: 0.238456 | Val. Loss: 0.280273 | Val. Kappa Score: 0.8717 | LR: 0.000250 | Estimated time: 55.10
Train loss on 50 batch: 0.215848
Train loss on 100 batch: 0.196454
Train loss on 150 batch: 0.235437
: Epoch: 14 | Training Loss: 0.216295 | Val. Loss: 0.274481 | Val. Kappa Score: 0.8730 | LR: 0.000250 | Estimated time: 55.37
Train loss on 50 batch: 0.223262
Train loss on 100 batch: 0.207238
Train loss on 150 batch: 0.197422
: Epoch: 15 | Training Loss: 0.215001 | Val. Loss: 0.292017 | Val. Kappa Score: 0.8739 | LR: 0.000250 | Estimated time: 55.47
Train loss on 50 batch: 0.219018
Train loss on 100 batch: 0.189667
Train loss on 150 batch: 0.200634
best-train-loss: 0.204067
best-valid-loss: 0.260101
best-kappa: 0.8751
: Epoch: 16 | Training Loss: 0.204067 | Val. Loss: 0.260101 | Val. Kappa Score: 0.8751 | LR: 0.000250 | Estimated time: 56.71
Train loss on 50 batch: 0.219281
Train loss on 100 batch: 0.214526
Train loss on 150 batch: 0.164611
best-train-loss: 0.199502
best-valid-loss: 0.258679
best-kappa: 0.8762
: Epoch: 17 | Training Loss: 0.199502 | Val. Loss: 0.258679 | Val. Kappa Score: 0.8762 | LR: 0.000250 | Estimated time: 55.60
Train loss on 50 batch: 0.186890
Train loss on 100 batch: 0.172348
Train loss on 150 batch: 0.200084
: Epoch: 18 | Training Loss: 0.195633 | Val. Loss: 0.262433 | Val. Kappa Score: 0.8775 | LR: 0.000250 | Estimated time: 56.26
Train loss on 50 batch: 0.156273
Train loss on 100 batch: 0.191178
Train loss on 150 batch: 0.177979
best-train-loss: 0.181714
best-valid-loss: 0.249257
best-kappa: 0.8787
: Epoch: 19 | Training Loss: 0.181714 | Val. Loss: 0.249257 | Val. Kappa Score: 0.8787 | LR: 0.000250 | Estimated time: 55.99
Train loss on 50 batch: 0.173721
Train loss on 100 batch: 0.205883
Train loss on 150 batch: 0.191164
: Epoch: 20 | Training Loss: 0.189523 | Val. Loss: 0.294117 | Val. Kappa Score: 0.8794 | LR: 0.000250 | Estimated time: 55.14
Train loss on 50 batch: 0.177553
Train loss on 100 batch: 0.165799
Train loss on 150 batch: 0.188455
: Epoch: 21 | Training Loss: 0.211719 | Val. Loss: 0.253998 | Val. Kappa Score: 0.8806 | LR: 0.000250 | Estimated time: 55.97
Train loss on 50 batch: 0.177436
Train loss on 100 batch: 0.194299
Train loss on 150 batch: 0.177528
: Epoch: 22 | Training Loss: 0.182913 | Val. Loss: 0.266672 | Val. Kappa Score: 0.8817 | LR: 0.000125 | Estimated time: 56.64
Train loss on 50 batch: 0.167809
Train loss on 100 batch: 0.179584
Train loss on 150 batch: 0.151677
: Epoch: 23 | Training Loss: 0.171039 | Val. Loss: 0.251964 | Val. Kappa Score: 0.8826 | LR: 0.000125 | Estimated time: 57.71
Train loss on 50 batch: 0.162751
Train loss on 100 batch: 0.168650
Train loss on 150 batch: 0.158649
: Epoch: 24 | Training Loss: 0.224050 | Val. Loss: 0.269295 | Val. Kappa Score: 0.8826 | LR: 0.000125 | Estimated time: 56.58
Train loss on 50 batch: 0.163909
Train loss on 100 batch: 0.145781
Train loss on 150 batch: 0.176700
: Epoch: 25 | Training Loss: 0.170502 | Val. Loss: 0.270136 | Val. Kappa Score: 0.8830 | LR: 0.000063 | Estimated time: 56.36
Train loss on 50 batch: 0.176597
Train loss on 100 batch: 0.127187
Train loss on 150 batch: 0.155066
: Epoch: 26 | Training Loss: 0.179088 | Val. Loss: 0.256648 | Val. Kappa Score: 0.8838 | LR: 0.000063 | Estimated time: 55.69
Train loss on 50 batch: 0.149903
Train loss on 100 batch: 0.191295
Train loss on 150 batch: 0.140935
: Epoch: 27 | Training Loss: 0.155885 | Val. Loss: 0.253871 | Val. Kappa Score: 0.8844 | LR: 0.000063 | Estimated time: 57.14
Train loss on 50 batch: 0.154826
Train loss on 100 batch: 0.149211
Train loss on 150 batch: 0.144894
: Epoch: 28 | Training Loss: 0.153823 | Val. Loss: 0.257277 | Val. Kappa Score: 0.8847 | LR: 0.000031 | Estimated time: 58.19
Train loss on 50 batch: 0.123130
Train loss on 100 batch: 0.156923
Train loss on 150 batch: 0.142837
: Epoch: 29 | Training Loss: 0.142897 | Val. Loss: 0.255595 | Val. Kappa Score: 0.8852 | LR: 0.000031 | Estimated time: 58.02
time_estimated: 1628.57
n-epochs: 29
time_estimated: 1628.65
----------------------------------------

Experiment N: 214: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.09.06 23:04:34
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50ab6e10>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 214: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.09.06 23:05:15
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50ab6e10>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 214: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b6


: 
date: 2019.09.06 23:27:08
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50ab8e10>
early-stopping-patience: 10
parameters-amount: 40738009
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.551783
Train loss on 100 batch: 0.428695
Train loss on 150 batch: 0.370275
best-train-loss: 0.413563
best-valid-loss: 0.373031
best-kappa: 0.8636
: Epoch: 1 | Training Loss: 0.413563 | Val. Loss: 0.373031 | Val. Kappa Score: 0.8636 | LR: 0.000500 | Estimated time: 61.45
Train loss on 50 batch: 0.328599
Train loss on 100 batch: 0.320693
Train loss on 150 batch: 0.314868
best-train-loss: 0.353526
best-valid-loss: 0.363535
best-kappa: 0.8604
: Epoch: 2 | Training Loss: 0.353526 | Val. Loss: 0.363535 | Val. Kappa Score: 0.8604 | LR: 0.000500 | Estimated time: 60.29
Train loss on 50 batch: 0.330992
Train loss on 100 batch: 0.344095
Train loss on 150 batch: 0.309335
best-train-loss: 0.322724
best-valid-loss: 0.322553
best-kappa: 0.8657
: Epoch: 3 | Training Loss: 0.322724 | Val. Loss: 0.322553 | Val. Kappa Score: 0.8657 | LR: 0.000500 | Estimated time: 62.04
Train loss on 50 batch: 0.303730
Train loss on 100 batch: 0.312424
Train loss on 150 batch: 0.276578
: Epoch: 4 | Training Loss: 0.366374 | Val. Loss: 0.483863 | Val. Kappa Score: 0.8575 | LR: 0.000500 | Estimated time: 60.26
Train loss on 50 batch: 0.398297
Train loss on 100 batch: 0.360298
Train loss on 150 batch: 0.254717
best-train-loss: 0.333514
best-valid-loss: 0.281358
best-kappa: 0.8625
: Epoch: 5 | Training Loss: 0.333514 | Val. Loss: 0.281358 | Val. Kappa Score: 0.8625 | LR: 0.000500 | Estimated time: 60.53
Train loss on 50 batch: 0.303498
Train loss on 100 batch: 0.302980
Train loss on 150 batch: 0.247184
: Epoch: 6 | Training Loss: 0.270018 | Val. Loss: 0.428633 | Val. Kappa Score: 0.8592 | LR: 0.000500 | Estimated time: 59.39
Train loss on 50 batch: 0.270702
Train loss on 100 batch: 0.263211
Train loss on 150 batch: 0.234712
best-train-loss: 0.262095
best-valid-loss: 0.277534
best-kappa: 0.8641
: Epoch: 7 | Training Loss: 0.262095 | Val. Loss: 0.277534 | Val. Kappa Score: 0.8641 | LR: 0.000500 | Estimated time: 59.85
Train loss on 50 batch: 0.221060
Train loss on 100 batch: 0.258702
Train loss on 150 batch: 0.211708
best-train-loss: 0.253912
best-valid-loss: 0.273455
best-kappa: 0.8681
: Epoch: 8 | Training Loss: 0.253912 | Val. Loss: 0.273455 | Val. Kappa Score: 0.8681 | LR: 0.000500 | Estimated time: 59.24
Train loss on 50 batch: 0.244506
Train loss on 100 batch: 0.285401
Train loss on 150 batch: 0.244459
: Epoch: 9 | Training Loss: 0.260058 | Val. Loss: 0.300225 | Val. Kappa Score: 0.8695 | LR: 0.000500 | Estimated time: 60.49
Train loss on 50 batch: 0.248004
Train loss on 100 batch: 0.240382
Train loss on 150 batch: 0.245269
: Epoch: 10 | Training Loss: 0.305228 | Val. Loss: 0.290428 | Val. Kappa Score: 0.8706 | LR: 0.000500 | Estimated time: 59.99
Train loss on 50 batch: 0.262849
Train loss on 100 batch: 0.263823
Train loss on 150 batch: 0.229477
: Epoch: 11 | Training Loss: 0.249074 | Val. Loss: 0.281813 | Val. Kappa Score: 0.8716 | LR: 0.000250 | Estimated time: 59.54
Train loss on 50 batch: 0.209045
Train loss on 100 batch: 0.199949
Train loss on 150 batch: 0.228554
: Epoch: 12 | Training Loss: 0.220458 | Val. Loss: 0.283583 | Val. Kappa Score: 0.8735 | LR: 0.000250 | Estimated time: 59.20
Train loss on 50 batch: 0.199761
Train loss on 100 batch: 0.244712
Train loss on 150 batch: 0.184973
best-train-loss: 0.205766
best-valid-loss: 0.261492
best-kappa: 0.8755
: Epoch: 13 | Training Loss: 0.205766 | Val. Loss: 0.261492 | Val. Kappa Score: 0.8755 | LR: 0.000250 | Estimated time: 59.53
Train loss on 50 batch: 0.212605
Train loss on 100 batch: 0.180216
Train loss on 150 batch: 0.234797
best-train-loss: 0.205578
best-valid-loss: 0.259539
best-kappa: 0.8772
: Epoch: 14 | Training Loss: 0.205578 | Val. Loss: 0.259539 | Val. Kappa Score: 0.8772 | LR: 0.000250 | Estimated time: 59.80
Train loss on 50 batch: 0.224626
Train loss on 100 batch: 0.215352
Train loss on 150 batch: 0.202621
: Epoch: 15 | Training Loss: 0.212314 | Val. Loss: 0.273966 | Val. Kappa Score: 0.8783 | LR: 0.000250 | Estimated time: 62.35
Train loss on 50 batch: 0.199785
Train loss on 100 batch: 0.171460
Train loss on 150 batch: 0.192424
best-train-loss: 0.194583
best-valid-loss: 0.255684
best-kappa: 0.8794
: Epoch: 16 | Training Loss: 0.194583 | Val. Loss: 0.255684 | Val. Kappa Score: 0.8794 | LR: 0.000250 | Estimated time: 61.26
Train loss on 50 batch: 0.199230
Train loss on 100 batch: 0.207822
Train loss on 150 batch: 0.161501
best-train-loss: 0.188592
best-valid-loss: 0.242907
best-kappa: 0.8801
: Epoch: 17 | Training Loss: 0.188592 | Val. Loss: 0.242907 | Val. Kappa Score: 0.8801 | LR: 0.000250 | Estimated time: 59.78
Train loss on 50 batch: 0.171749
Train loss on 100 batch: 0.175423
Train loss on 150 batch: 0.199124
: Epoch: 18 | Training Loss: 0.186236 | Val. Loss: 0.249387 | Val. Kappa Score: 0.8817 | LR: 0.000250 | Estimated time: 59.99
Train loss on 50 batch: 0.154731
Train loss on 100 batch: 0.186580
Train loss on 150 batch: 0.175413
: Epoch: 19 | Training Loss: 0.178161 | Val. Loss: 0.247249 | Val. Kappa Score: 0.8823 | LR: 0.000250 | Estimated time: 60.03
Train loss on 50 batch: 0.175296
Train loss on 100 batch: 0.206029
Train loss on 150 batch: 0.156618
: Epoch: 20 | Training Loss: 0.179080 | Val. Loss: 0.279830 | Val. Kappa Score: 0.8828 | LR: 0.000125 | Estimated time: 59.69
Train loss on 50 batch: 0.164396
Train loss on 100 batch: 0.152088
Train loss on 150 batch: 0.164765
: Epoch: 21 | Training Loss: 0.169952 | Val. Loss: 0.255230 | Val. Kappa Score: 0.8833 | LR: 0.000125 | Estimated time: 59.33
Train loss on 50 batch: 0.148363
Train loss on 100 batch: 0.181490
Train loss on 150 batch: 0.167150
: Epoch: 22 | Training Loss: 0.160545 | Val. Loss: 0.254285 | Val. Kappa Score: 0.8843 | LR: 0.000125 | Estimated time: 60.84
Train loss on 50 batch: 0.156805
Train loss on 100 batch: 0.169651
Train loss on 150 batch: 0.150041
: Epoch: 23 | Training Loss: 0.156361 | Val. Loss: 0.251583 | Val. Kappa Score: 0.8850 | LR: 0.000063 | Estimated time: 63.84
Train loss on 50 batch: 0.157030
Train loss on 100 batch: 0.143267
Train loss on 150 batch: 0.146695
: Epoch: 24 | Training Loss: 0.189331 | Val. Loss: 0.252543 | Val. Kappa Score: 0.8852 | LR: 0.000063 | Estimated time: 61.03
Train loss on 50 batch: 0.136844
Train loss on 100 batch: 0.147809
Train loss on 150 batch: 0.150758
: Epoch: 25 | Training Loss: 0.148475 | Val. Loss: 0.253804 | Val. Kappa Score: 0.8857 | LR: 0.000063 | Estimated time: 63.25
Train loss on 50 batch: 0.152625
Train loss on 100 batch: 0.127743
Train loss on 150 batch: 0.148001
: Epoch: 26 | Training Loss: 0.157138 | Val. Loss: 0.251715 | Val. Kappa Score: 0.8860 | LR: 0.000031 | Estimated time: 60.99
Train loss on 50 batch: 0.133055
Train loss on 100 batch: 0.159817
Train loss on 150 batch: 0.153883
: Epoch: 27 | Training Loss: 0.146007 | Val. Loss: 0.254346 | Val. Kappa Score: 0.8863 | LR: 0.000031 | Estimated time: 62.49
time_estimated: 1639.45
n-epochs: 27
time_estimated: 1639.52
----------------------------------------

Experiment N: 215: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 06:04:56
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50aa1e10>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.663880
Train loss on 100 batch: 0.494915
Train loss on 150 batch: 0.471881
Train loss on 200 batch: 0.396185
best-train-loss: 0.473714
best-valid-loss: 0.397676
best-kappa: 0.8482
: Epoch: 1 | Training Loss: 0.473714 | Val. Loss: 0.397676 | Val. Kappa Score: 0.8482 | LR: 0.000500 | Estimated time: 92.47
Train loss on 50 batch: 0.394589
Train loss on 100 batch: 0.362694
Train loss on 150 batch: 0.336020
Train loss on 200 batch: 0.280166
best-train-loss: 0.382506
best-valid-loss: 0.351097
best-kappa: 0.8571
: Epoch: 2 | Training Loss: 0.382506 | Val. Loss: 0.351097 | Val. Kappa Score: 0.8571 | LR: 0.000500 | Estimated time: 92.37
Train loss on 50 batch: 0.269170
----------------------------------------

Experiment N: 216: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 06:08:43
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50a9feb8>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.663880
Train loss on 100 batch: 0.494915
Train loss on 150 batch: 0.471881
Train loss on 200 batch: 0.396185
best-train-loss: 0.473714
best-valid-loss: 0.397676
best-kappa: 0.8482
: Epoch: 1 | Training Loss: 0.473714 | Val. Loss: 0.397676 | Val. Kappa Score: 0.8482 | LR: 0.000500 | Estimated time: 92.08
Train loss on 50 batch: 0.394589
Train loss on 100 batch: 0.362694
Train loss on 150 batch: 0.336020
Train loss on 200 batch: 0.280166
best-train-loss: 0.382506
best-valid-loss: 0.351097
best-kappa: 0.8571
: Epoch: 2 | Training Loss: 0.382506 | Val. Loss: 0.351097 | Val. Kappa Score: 0.8571 | LR: 0.000500 | Estimated time: 84.45
Train loss on 50 batch: 0.269170
Train loss on 100 batch: 0.374796
Train loss on 150 batch: 0.337447
Train loss on 200 batch: 0.391787
best-train-loss: 0.339251
best-valid-loss: 0.320744
best-kappa: 0.8625
: Epoch: 3 | Training Loss: 0.339251 | Val. Loss: 0.320744 | Val. Kappa Score: 0.8625 | LR: 0.000500 | Estimated time: 84.57
Train loss on 50 batch: 0.335854
Train loss on 100 batch: 0.317396
Train loss on 150 batch: 0.314780
Train loss on 200 batch: 0.308577
: Epoch: 4 | Training Loss: 0.371836 | Val. Loss: 0.388536 | Val. Kappa Score: 0.8618 | LR: 0.000500 | Estimated time: 84.29
Train loss on 50 batch: 0.324088
Train loss on 100 batch: 0.349984
Train loss on 150 batch: 0.349129
Train loss on 200 batch: 0.303634
: Epoch: 5 | Training Loss: 0.327970 | Val. Loss: 0.331181 | Val. Kappa Score: 0.8612 | LR: 0.000500 | Estimated time: 84.11
Train loss on 50 batch: 0.309340
Train loss on 100 batch: 0.289409
Train loss on 150 batch: 0.316126
Train loss on 200 batch: 0.305096
: Epoch: 6 | Training Loss: 0.295221 | Val. Loss: 0.369504 | Val. Kappa Score: 0.8593 | LR: 0.000250 | Estimated time: 84.33
Train loss on 50 batch: 0.313511
Train loss on 100 batch: 0.260245
Train loss on 150 batch: 0.265796
Train loss on 200 batch: 0.253969
: Epoch: 7 | Training Loss: 0.273614 | Val. Loss: 0.322133 | Val. Kappa Score: 0.8623 | LR: 0.000250 | Estimated time: 84.12
Train loss on 50 batch: 0.245752
Train loss on 100 batch: 0.312961
Train loss on 150 batch: 0.254566
Train loss on 200 batch: 0.244780
best-train-loss: 0.278821
best-valid-loss: 0.295848
best-kappa: 0.8642
: Epoch: 8 | Training Loss: 0.278821 | Val. Loss: 0.295848 | Val. Kappa Score: 0.8642 | LR: 0.000250 | Estimated time: 83.91
Train loss on 50 batch: 0.256672
Train loss on 100 batch: 0.307370
Train loss on 150 batch: 0.279493
Train loss on 200 batch: 0.284835
: Epoch: 9 | Training Loss: 0.278836 | Val. Loss: 0.301459 | Val. Kappa Score: 0.8661 | LR: 0.000250 | Estimated time: 84.18
Train loss on 50 batch: 0.257007
Train loss on 100 batch: 0.261922
Train loss on 150 batch: 0.295182
Train loss on 200 batch: 0.274878
: Epoch: 10 | Training Loss: 0.330256 | Val. Loss: 0.300303 | Val. Kappa Score: 0.8658 | LR: 0.000250 | Estimated time: 84.58
Train loss on 50 batch: 0.278725
Train loss on 100 batch: 0.257292
Train loss on 150 batch: 0.256550
Train loss on 200 batch: 0.251441
best-train-loss: 0.264982
best-valid-loss: 0.294762
best-kappa: 0.8643
: Epoch: 11 | Training Loss: 0.264982 | Val. Loss: 0.294762 | Val. Kappa Score: 0.8643 | LR: 0.000250 | Estimated time: 83.88
Train loss on 50 batch: 0.229828
Train loss on 100 batch: 0.267675
Train loss on 150 batch: 0.249508
Train loss on 200 batch: 0.238416
: Epoch: 12 | Training Loss: 0.246886 | Val. Loss: 0.380263 | Val. Kappa Score: 0.8640 | LR: 0.000250 | Estimated time: 83.82
Train loss on 50 batch: 0.242057
Train loss on 100 batch: 0.266710
Train loss on 150 batch: 0.275679
Train loss on 200 batch: 0.249511
: Epoch: 13 | Training Loss: 0.271457 | Val. Loss: 0.307618 | Val. Kappa Score: 0.8646 | LR: 0.000250 | Estimated time: 84.19
Train loss on 50 batch: 0.255811
Train loss on 100 batch: 0.255070
Train loss on 150 batch: 0.272235
Train loss on 200 batch: 0.268619
: Epoch: 14 | Training Loss: 0.262352 | Val. Loss: 0.332375 | Val. Kappa Score: 0.8651 | LR: 0.000125 | Estimated time: 84.00
Train loss on 50 batch: 0.273624
Train loss on 100 batch: 0.231968
Train loss on 150 batch: 0.269818
Train loss on 200 batch: 0.239748
: Epoch: 15 | Training Loss: 0.261397 | Val. Loss: 0.313005 | Val. Kappa Score: 0.8657 | LR: 0.000125 | Estimated time: 83.49
Train loss on 50 batch: 0.240665
Train loss on 100 batch: 0.249399
Train loss on 150 batch: 0.232167
Train loss on 200 batch: 0.256913
best-train-loss: 0.241487
best-valid-loss: 0.291884
best-kappa: 0.8657
: Epoch: 16 | Training Loss: 0.241487 | Val. Loss: 0.291884 | Val. Kappa Score: 0.8657 | LR: 0.000125 | Estimated time: 84.92
Train loss on 50 batch: 0.263966
Train loss on 100 batch: 0.260173
Train loss on 150 batch: 0.216109
Train loss on 200 batch: 0.220443
best-train-loss: 0.236018
best-valid-loss: 0.291549
best-kappa: 0.8660
: Epoch: 17 | Training Loss: 0.236018 | Val. Loss: 0.291549 | Val. Kappa Score: 0.8660 | LR: 0.000125 | Estimated time: 84.12
Train loss on 50 batch: 0.246793
Train loss on 100 batch: 0.249336
Train loss on 150 batch: 0.219097
Train loss on 200 batch: 0.253181
best-train-loss: 0.245894
best-valid-loss: 0.281658
best-kappa: 0.8669
: Epoch: 18 | Training Loss: 0.245894 | Val. Loss: 0.281658 | Val. Kappa Score: 0.8669 | LR: 0.000125 | Estimated time: 84.02
Train loss on 50 batch: 0.210792
Train loss on 100 batch: 0.229859
Train loss on 150 batch: 0.213550
Train loss on 200 batch: 0.267007
: Epoch: 19 | Training Loss: 0.235256 | Val. Loss: 0.302921 | Val. Kappa Score: 0.8672 | LR: 0.000125 | Estimated time: 84.28
Train loss on 50 batch: 0.215178
Train loss on 100 batch: 0.250022
Train loss on 150 batch: 0.277014
Train loss on 200 batch: 0.201908
: Epoch: 20 | Training Loss: 0.236139 | Val. Loss: 0.283546 | Val. Kappa Score: 0.8675 | LR: 0.000125 | Estimated time: 84.25
Train loss on 50 batch: 0.213818
Train loss on 100 batch: 0.250225
Train loss on 150 batch: 0.201412
Train loss on 200 batch: 0.233261
: Epoch: 21 | Training Loss: 0.258145 | Val. Loss: 0.283549 | Val. Kappa Score: 0.8679 | LR: 0.000063 | Estimated time: 84.09
Train loss on 50 batch: 0.224603
Train loss on 100 batch: 0.226874
Train loss on 150 batch: 0.235208
Train loss on 200 batch: 0.256363
: Epoch: 22 | Training Loss: 0.229084 | Val. Loss: 0.297020 | Val. Kappa Score: 0.8685 | LR: 0.000063 | Estimated time: 84.29
Train loss on 50 batch: 0.238961
Train loss on 100 batch: 0.225729
Train loss on 150 batch: 0.210388
Train loss on 200 batch: 0.217579
: Epoch: 23 | Training Loss: 0.236330 | Val. Loss: 0.287613 | Val. Kappa Score: 0.8693 | LR: 0.000063 | Estimated time: 84.72
Train loss on 50 batch: 0.238800
Train loss on 100 batch: 0.225021
Train loss on 150 batch: 0.215429
Train loss on 200 batch: 0.244232
: Epoch: 24 | Training Loss: 0.282036 | Val. Loss: 0.282259 | Val. Kappa Score: 0.8698 | LR: 0.000031 | Estimated time: 84.15
Train loss on 50 batch: 0.221726
Train loss on 100 batch: 0.226272
Train loss on 150 batch: 0.234004
Train loss on 200 batch: 0.265852
: Epoch: 25 | Training Loss: 0.239110 | Val. Loss: 0.285304 | Val. Kappa Score: 0.8702 | LR: 0.000031 | Estimated time: 84.15
Train loss on 50 batch: 0.267621
Train loss on 100 batch: 0.187225
Train loss on 150 batch: 0.206482
Train loss on 200 batch: 0.278366
: Epoch: 26 | Training Loss: 0.263765 | Val. Loss: 0.308818 | Val. Kappa Score: 0.8697 | LR: 0.000031 | Estimated time: 83.71
Train loss on 50 batch: 0.205686
Train loss on 100 batch: 0.224538
Train loss on 150 batch: 0.287248
Train loss on 200 batch: 0.191012
: Epoch: 27 | Training Loss: 0.238286 | Val. Loss: 0.288709 | Val. Kappa Score: 0.8696 | LR: 0.000016 | Estimated time: 84.30
Train loss on 50 batch: 0.262780
Train loss on 100 batch: 0.202008
Train loss on 150 batch: 0.215426
Train loss on 200 batch: 0.233272
: Epoch: 28 | Training Loss: 0.234882 | Val. Loss: 0.293249 | Val. Kappa Score: 0.8691 | LR: 0.000016 | Estimated time: 83.91
time_estimated: 2368.17
n-epochs: 28
time_estimated: 2368.24
----------------------------------------

Experiment N: 217: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 06:48:13
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb4c708f28>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
----------------------------------------

Experiment N: 217: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.001, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 07:17:27
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50aa2e10>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.597855
Train loss on 100 batch: 0.453876
Train loss on 150 batch: 0.485656
Train loss on 200 batch: 0.385543
best-train-loss: 0.456672
best-valid-loss: 0.387564
best-kappa: 0.8525
: Epoch: 1 | Training Loss: 0.456672 | Val. Loss: 0.387564 | Val. Kappa Score: 0.8525 | LR: 0.001000 | Estimated time: 84.70
Train loss on 50 batch: 0.376546
Train loss on 100 batch: 0.343074
Train loss on 150 batch: 0.341092
Train loss on 200 batch: 0.288190
: Epoch: 2 | Training Loss: 0.376515 | Val. Loss: 0.717651 | Val. Kappa Score: 0.7774 | LR: 0.001000 | Estimated time: 84.32
Train loss on 50 batch: 0.277036
Train loss on 100 batch: 0.377053
Train loss on 150 batch: 0.345797
Train loss on 200 batch: 0.380386
best-train-loss: 0.339651
best-valid-loss: 0.353718
best-kappa: 0.8094
: Epoch: 3 | Training Loss: 0.339651 | Val. Loss: 0.353718 | Val. Kappa Score: 0.8094 | LR: 0.001000 | Estimated time: 84.56
----------------------------------------

Experiment N: 218: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 07:22:38
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50a9ee80>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.657166
Train loss on 100 batch: 0.519485
Train loss on 150 batch: 0.466217
Train loss on 200 batch: 0.401041
best-train-loss: 0.482744
best-valid-loss: 0.398446
best-kappa: 0.8398
: Epoch: 1 | Training Loss: 0.482744 | Val. Loss: 0.398446 | Val. Kappa Score: 0.8398 | LR: 0.000500 | Estimated time: 74.44
Train loss on 50 batch: 0.402821
Train loss on 100 batch: 0.364068
Train loss on 150 batch: 0.357070
Train loss on 200 batch: 0.270518
best-train-loss: 0.379855
best-valid-loss: 0.369471
best-kappa: 0.8489
: Epoch: 2 | Training Loss: 0.379855 | Val. Loss: 0.369471 | Val. Kappa Score: 0.8489 | LR: 0.000500 | Estimated time: 73.90
Train loss on 50 batch: 0.285620
Train loss on 100 batch: 0.388209
Train loss on 150 batch: 0.348976
Train loss on 200 batch: 0.393036
: Epoch: 3 | Training Loss: 0.351147 | Val. Loss: 0.383921 | Val. Kappa Score: 0.8507 | LR: 0.000500 | Estimated time: 74.01
Train loss on 50 batch: 0.337580
Train loss on 100 batch: 0.311822
Train loss on 150 batch: 0.329067
Train loss on 200 batch: 0.318535
best-train-loss: 0.374208
best-valid-loss: 0.353677
best-kappa: 0.8527
: Epoch: 4 | Training Loss: 0.374208 | Val. Loss: 0.353677 | Val. Kappa Score: 0.8527 | LR: 0.000500 | Estimated time: 74.07
Train loss on 50 batch: 0.344946
Train loss on 100 batch: 0.332296
Train loss on 150 batch: 0.348300
Train loss on 200 batch: 0.317782
best-train-loss: 0.332505
best-valid-loss: 0.352136
best-kappa: 0.8505
: Epoch: 5 | Training Loss: 0.332505 | Val. Loss: 0.352136 | Val. Kappa Score: 0.8505 | LR: 0.000500 | Estimated time: 74.39
Train loss on 50 batch: 0.315131
Train loss on 100 batch: 0.320684
----------------------------------------

Experiment N: 219: 



EXPERIMENT WITH BATCH_SIZE: 12, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b7


: 
date: 2019.09.07 07:30:24
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50aa0e48>
early-stopping-patience: 10
parameters-amount: 63789521
n-epochs: 200
batch-size: 12
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.645035
Train loss on 100 batch: 0.534496
Train loss on 150 batch: 0.481610
Train loss on 200 batch: 0.412003
best-train-loss: 0.493424
best-valid-loss: 0.385458
best-kappa: 0.8354
: Epoch: 1 | Training Loss: 0.493424 | Val. Loss: 0.385458 | Val. Kappa Score: 0.8354 | LR: 0.000500 | Estimated time: 74.60
Train loss on 50 batch: 0.389403
Train loss on 100 batch: 0.363609
Train loss on 150 batch: 0.357431
Train loss on 200 batch: 0.292810
best-train-loss: 0.378115
best-valid-loss: 0.380831
best-kappa: 0.8453
: Epoch: 2 | Training Loss: 0.378115 | Val. Loss: 0.380831 | Val. Kappa Score: 0.8453 | LR: 0.000500 | Estimated time: 74.61
Train loss on 50 batch: 0.299474
Train loss on 100 batch: 0.383605
Train loss on 150 batch: 0.352141
Train loss on 200 batch: 0.385740
: Epoch: 3 | Training Loss: 0.345508 | Val. Loss: 0.480706 | Val. Kappa Score: 0.8329 | LR: 0.000500 | Estimated time: 74.87
----------------------------------------

Experiment N: 220: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b2


: 
date: 2019.09.07 10:50:39
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb9c509160>
early-stopping-patience: 10
parameters-amount: 7702403
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.417052
Train loss on 100 batch: 0.312975
Train loss on 150 batch: 0.323222
best-train-loss: 0.339803
best-valid-loss: 0.318564
best-kappa: 0.8841
: Epoch: 1 | Training Loss: 0.339803 | Val. Loss: 0.318564 | Val. Kappa Score: 0.8841 | LR: 0.000500 | Estimated time: 37.18
Train loss on 50 batch: 0.310079
Train loss on 100 batch: 0.277745
Train loss on 150 batch: 0.248053
best-train-loss: 0.322410
best-valid-loss: 0.299641
best-kappa: 0.8833
: Epoch: 2 | Training Loss: 0.322410 | Val. Loss: 0.299641 | Val. Kappa Score: 0.8833 | LR: 0.000500 | Estimated time: 36.85
Train loss on 50 batch: 0.271850
Train loss on 100 batch: 0.273590
Train loss on 150 batch: 0.289650
best-train-loss: 0.269236
best-valid-loss: 0.290894
best-kappa: 0.8868
: Epoch: 3 | Training Loss: 0.269236 | Val. Loss: 0.290894 | Val. Kappa Score: 0.8868 | LR: 0.000500 | Estimated time: 37.47
Train loss on 50 batch: 0.271304
Train loss on 100 batch: 0.252656
Train loss on 150 batch: 0.262626
: Epoch: 4 | Training Loss: 0.362635 | Val. Loss: 0.301239 | Val. Kappa Score: 0.8850 | LR: 0.000500 | Estimated time: 36.58
Train loss on 50 batch: 0.294747
Train loss on 100 batch: 0.281466
Train loss on 150 batch: 0.220357
: Epoch: 5 | Training Loss: 0.264134 | Val. Loss: 0.298785 | Val. Kappa Score: 0.8864 | LR: 0.000500 | Estimated time: 37.43
Train loss on 50 batch: 0.271407
Train loss on 100 batch: 0.270169
Train loss on 150 batch: 0.252179
: Epoch: 6 | Training Loss: 0.249732 | Val. Loss: 0.316153 | Val. Kappa Score: 0.8847 | LR: 0.000250 | Estimated time: 35.46
Train loss on 50 batch: 0.243322
Train loss on 100 batch: 0.253804
Train loss on 150 batch: 0.231031
best-train-loss: 0.243718
best-valid-loss: 0.279772
best-kappa: 0.8867
: Epoch: 7 | Training Loss: 0.243718 | Val. Loss: 0.279772 | Val. Kappa Score: 0.8867 | LR: 0.000250 | Estimated time: 34.87
Train loss on 50 batch: 0.219562
Train loss on 100 batch: 0.261944
Train loss on 150 batch: 0.187984
best-train-loss: 0.244479
best-valid-loss: 0.276343
best-kappa: 0.8887
: Epoch: 8 | Training Loss: 0.244479 | Val. Loss: 0.276343 | Val. Kappa Score: 0.8887 | LR: 0.000250 | Estimated time: 36.94
Train loss on 50 batch: 0.248255
Train loss on 100 batch: 0.254549
Train loss on 150 batch: 0.226182
best-train-loss: 0.239589
best-valid-loss: 0.271914
best-kappa: 0.8897
: Epoch: 9 | Training Loss: 0.239589 | Val. Loss: 0.271914 | Val. Kappa Score: 0.8897 | LR: 0.000250 | Estimated time: 36.63
Train loss on 50 batch: 0.212310
Train loss on 100 batch: 0.256391
Train loss on 150 batch: 0.239616
: Epoch: 10 | Training Loss: 0.333574 | Val. Loss: 0.276377 | Val. Kappa Score: 0.8896 | LR: 0.000250 | Estimated time: 36.53
Train loss on 50 batch: 0.243588
Train loss on 100 batch: 0.225895
Train loss on 150 batch: 0.203341
: Epoch: 11 | Training Loss: 0.226623 | Val. Loss: 0.274234 | Val. Kappa Score: 0.8897 | LR: 0.000250 | Estimated time: 35.33
Train loss on 50 batch: 0.200539
Train loss on 100 batch: 0.198735
Train loss on 150 batch: 0.248587
: Epoch: 12 | Training Loss: 0.213508 | Val. Loss: 0.272944 | Val. Kappa Score: 0.8909 | LR: 0.000125 | Estimated time: 36.02
Train loss on 50 batch: 0.200876
Train loss on 100 batch: 0.224838
Train loss on 150 batch: 0.197562
: Epoch: 13 | Training Loss: 0.226190 | Val. Loss: 0.273748 | Val. Kappa Score: 0.8920 | LR: 0.000125 | Estimated time: 35.60
Train loss on 50 batch: 0.204154
Train loss on 100 batch: 0.211344
Train loss on 150 batch: 0.211424
best-train-loss: 0.209210
best-valid-loss: 0.271128
best-kappa: 0.8921
: Epoch: 14 | Training Loss: 0.209210 | Val. Loss: 0.271128 | Val. Kappa Score: 0.8921 | LR: 0.000125 | Estimated time: 35.48
Train loss on 50 batch: 0.231088
Train loss on 100 batch: 0.204197
Train loss on 150 batch: 0.208674
: Epoch: 15 | Training Loss: 0.234251 | Val. Loss: 0.272572 | Val. Kappa Score: 0.8922 | LR: 0.000125 | Estimated time: 35.66
Train loss on 50 batch: 0.216269
Train loss on 100 batch: 0.182493
Train loss on 150 batch: 0.201140
: Epoch: 16 | Training Loss: 0.205742 | Val. Loss: 0.273064 | Val. Kappa Score: 0.8923 | LR: 0.000125 | Estimated time: 35.56
Train loss on 50 batch: 0.237796
Train loss on 100 batch: 0.210572
Train loss on 150 batch: 0.173097
best-train-loss: 0.207500
best-valid-loss: 0.270875
best-kappa: 0.8926
: Epoch: 17 | Training Loss: 0.207500 | Val. Loss: 0.270875 | Val. Kappa Score: 0.8926 | LR: 0.000125 | Estimated time: 34.74
Train loss on 50 batch: 0.214504
Train loss on 100 batch: 0.172445
Train loss on 150 batch: 0.204810
best-train-loss: 0.205814
best-valid-loss: 0.265843
best-kappa: 0.8930
: Epoch: 18 | Training Loss: 0.205814 | Val. Loss: 0.265843 | Val. Kappa Score: 0.8930 | LR: 0.000125 | Estimated time: 35.45
Train loss on 50 batch: 0.177603
Train loss on 100 batch: 0.223316
Train loss on 150 batch: 0.214848
best-train-loss: 0.207212
best-valid-loss: 0.263083
best-kappa: 0.8933
: Epoch: 19 | Training Loss: 0.207212 | Val. Loss: 0.263083 | Val. Kappa Score: 0.8933 | LR: 0.000125 | Estimated time: 35.48
Train loss on 50 batch: 0.196569
Train loss on 100 batch: 0.224229
Train loss on 150 batch: 0.192623
: Epoch: 20 | Training Loss: 0.204550 | Val. Loss: 0.268413 | Val. Kappa Score: 0.8935 | LR: 0.000125 | Estimated time: 34.91
Train loss on 50 batch: 0.218403
Train loss on 100 batch: 0.181715
Train loss on 150 batch: 0.193055
: Epoch: 21 | Training Loss: 0.251069 | Val. Loss: 0.271228 | Val. Kappa Score: 0.8936 | LR: 0.000125 | Estimated time: 35.49
Train loss on 50 batch: 0.189735
Train loss on 100 batch: 0.211372
Train loss on 150 batch: 0.219994
: Epoch: 22 | Training Loss: 0.199170 | Val. Loss: 0.265675 | Val. Kappa Score: 0.8941 | LR: 0.000063 | Estimated time: 35.64
Train loss on 50 batch: 0.183414
Train loss on 100 batch: 0.207930
Train loss on 150 batch: 0.191367
best-train-loss: 0.216384
best-valid-loss: 0.258561
best-kappa: 0.8943
: Epoch: 23 | Training Loss: 0.216384 | Val. Loss: 0.258561 | Val. Kappa Score: 0.8943 | LR: 0.000063 | Estimated time: 35.55
Train loss on 50 batch: 0.212168
Train loss on 100 batch: 0.210969
Train loss on 150 batch: 0.190531
: Epoch: 24 | Training Loss: 0.283644 | Val. Loss: 0.265267 | Val. Kappa Score: 0.8943 | LR: 0.000063 | Estimated time: 35.74
Train loss on 50 batch: 0.194236
Train loss on 100 batch: 0.196761
Train loss on 150 batch: 0.219684
: Epoch: 25 | Training Loss: 0.200984 | Val. Loss: 0.262517 | Val. Kappa Score: 0.8947 | LR: 0.000063 | Estimated time: 35.17
Train loss on 50 batch: 0.217582
Train loss on 100 batch: 0.159520
Train loss on 150 batch: 0.208167
: Epoch: 26 | Training Loss: 0.237691 | Val. Loss: 0.265930 | Val. Kappa Score: 0.8946 | LR: 0.000031 | Estimated time: 35.74
Train loss on 50 batch: 0.201945
Train loss on 100 batch: 0.240393
Train loss on 150 batch: 0.185748
: Epoch: 27 | Training Loss: 0.213647 | Val. Loss: 0.264454 | Val. Kappa Score: 0.8949 | LR: 0.000031 | Estimated time: 35.61
Train loss on 50 batch: 0.208452
Train loss on 100 batch: 0.198572
Train loss on 150 batch: 0.174457
: Epoch: 28 | Training Loss: 0.208745 | Val. Loss: 0.263657 | Val. Kappa Score: 0.8945 | LR: 0.000031 | Estimated time: 35.15
Train loss on 50 batch: 0.162828
Train loss on 100 batch: 0.211667
Train loss on 150 batch: 0.205343
: Epoch: 29 | Training Loss: 0.203839 | Val. Loss: 0.261600 | Val. Kappa Score: 0.8941 | LR: 0.000016 | Estimated time: 35.05
Train loss on 50 batch: 0.178765
Train loss on 100 batch: 0.204702
Train loss on 150 batch: 0.184647
: Epoch: 30 | Training Loss: 0.208586 | Val. Loss: 0.262369 | Val. Kappa Score: 0.8940 | LR: 0.000016 | Estimated time: 35.70
Train loss on 50 batch: 0.179961
Train loss on 100 batch: 0.208142
Train loss on 150 batch: 0.174315
: Epoch: 31 | Training Loss: 0.197875 | Val. Loss: 0.260482 | Val. Kappa Score: 0.8942 | LR: 0.000016 | Estimated time: 35.77
Train loss on 50 batch: 0.205482
Train loss on 100 batch: 0.195208
Train loss on 150 batch: 0.170263
: Epoch: 32 | Training Loss: 0.186944 | Val. Loss: 0.261060 | Val. Kappa Score: 0.8942 | LR: 0.000008 | Estimated time: 35.28
Train loss on 50 batch: 0.186591
Train loss on 100 batch: 0.192740
Train loss on 150 batch: 0.174760
: Epoch: 33 | Training Loss: 0.190991 | Val. Loss: 0.265853 | Val. Kappa Score: 0.8941 | LR: 0.000008 | Estimated time: 34.94
time_estimated: 1183.72
n-epochs: 33
time_estimated: 1183.80
----------------------------------------

Experiment N: 221: 



EXPERIMENT WITH BATCH_SIZE: 16, LR: 0.0005, p_horizontalflip: 0.4, model_type: efficientnet-b3


: 
date: 2019.09.07 18:32:42
data-type: new
loss-func: MSELoss()
optim: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 1e-05
)
scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efb50be5f60>
early-stopping-patience: 10
parameters-amount: 10697769
n-epochs: 200
batch-size: 16
best-train-loss: inf
best-valid-loss: inf
best-kappa: 0
lb-kappa-score: nan
Train loss on 50 batch: 0.423016
Train loss on 100 batch: 0.322438
Train loss on 150 batch: 0.337233
best-train-loss: 0.333643
best-valid-loss: 0.366558
best-kappa: 0.8647
: Epoch: 1 | Training Loss: 0.333643 | Val. Loss: 0.366558 | Val. Kappa Score: 0.8647 | LR: 0.000500 | Estimated time: 45.29
Train loss on 50 batch: 0.263852
Train loss on 100 batch: 0.289155
Train loss on 150 batch: 0.231397
: Epoch: 2 | Training Loss: 0.296501 | Val. Loss: 0.388622 | Val. Kappa Score: 0.8676 | LR: 0.000500 | Estimated time: 43.55
Train loss on 50 batch: 0.291680
Train loss on 100 batch: 0.282778
Train loss on 150 batch: 0.263073
best-train-loss: 0.271694
best-valid-loss: 0.303151
best-kappa: 0.8765
: Epoch: 3 | Training Loss: 0.271694 | Val. Loss: 0.303151 | Val. Kappa Score: 0.8765 | LR: 0.000500 | Estimated time: 44.66
Train loss on 50 batch: 0.261814
Train loss on 100 batch: 0.266196
Train loss on 150 batch: 0.254679
: Epoch: 4 | Training Loss: 0.351930 | Val. Loss: 0.307367 | Val. Kappa Score: 0.8773 | LR: 0.000500 | Estimated time: 44.16
Train loss on 50 batch: 0.290185
Train loss on 100 batch: 0.286848
Train loss on 150 batch: 0.221782
best-train-loss: 0.261970
best-valid-loss: 0.282976
best-kappa: 0.8803
: Epoch: 5 | Training Loss: 0.261970 | Val. Loss: 0.282976 | Val. Kappa Score: 0.8803 | LR: 0.000500 | Estimated time: 44.49
Train loss on 50 batch: 0.236119
Train loss on 100 batch: 0.259985
Train loss on 150 batch: 0.236180
: Epoch: 6 | Training Loss: 0.232982 | Val. Loss: 0.301564 | Val. Kappa Score: 0.8826 | LR: 0.000500 | Estimated time: 44.48
Train loss on 50 batch: 0.243498
Train loss on 100 batch: 0.262796
Train loss on 150 batch: 0.225259
: Epoch: 7 | Training Loss: 0.248004 | Val. Loss: 0.299223 | Val. Kappa Score: 0.8842 | LR: 0.000500 | Estimated time: 44.80
Train loss on 50 batch: 0.216796
Train loss on 100 batch: 0.247891
Train loss on 150 batch: 0.187541
best-train-loss: 0.233542
best-valid-loss: 0.271082
best-kappa: 0.8862
: Epoch: 8 | Training Loss: 0.233542 | Val. Loss: 0.271082 | Val. Kappa Score: 0.8862 | LR: 0.000500 | Estimated time: 44.09
Train loss on 50 batch: 0.223858
Train loss on 100 batch: 0.257811
Train loss on 150 batch: 0.199865
: Epoch: 9 | Training Loss: 0.224571 | Val. Loss: 0.306605 | Val. Kappa Score: 0.8861 | LR: 0.000500 | Estimated time: 44.44
Train loss on 50 batch: 0.196110
Train loss on 100 batch: 0.215595
Train loss on 150 batch: 0.226107
: Epoch: 10 | Training Loss: 0.303208 | Val. Loss: 0.292407 | Val. Kappa Score: 0.8857 | LR: 0.000500 | Estimated time: 44.98
Train loss on 50 batch: 0.240496
Train loss on 100 batch: 0.237309
Train loss on 150 batch: 0.201752
: Epoch: 11 | Training Loss: 0.229506 | Val. Loss: 0.308405 | Val. Kappa Score: 0.8857 | LR: 0.000250 | Estimated time: 44.66
Train loss on 50 batch: 0.195023
Train loss on 100 batch: 0.179782
Train loss on 150 batch: 0.220988
: Epoch: 12 | Training Loss: 0.203166 | Val. Loss: 0.278878 | Val. Kappa Score: 0.8861 | LR: 0.000250 | Estimated time: 44.77
Train loss on 50 batch: 0.189015
Train loss on 100 batch: 0.232521
Train loss on 150 batch: 0.182246
: Epoch: 13 | Training Loss: 0.211761 | Val. Loss: 0.272837 | Val. Kappa Score: 0.8872 | LR: 0.000250 | Estimated time: 44.50
Train loss on 50 batch: 0.195610
Train loss on 100 batch: 0.177071
Train loss on 150 batch: 0.219171
: Epoch: 14 | Training Loss: 0.194816 | Val. Loss: 0.275612 | Val. Kappa Score: 0.8875 | LR: 0.000125 | Estimated time: 43.53
Train loss on 50 batch: 0.224240
Train loss on 100 batch: 0.186135
Train loss on 150 batch: 0.200958
best-train-loss: 0.203919
best-valid-loss: 0.266828
best-kappa: 0.8881
: Epoch: 15 | Training Loss: 0.203919 | Val. Loss: 0.266828 | Val. Kappa Score: 0.8881 | LR: 0.000125 | Estimated time: 45.18
Train loss on 50 batch: 0.190838
Train loss on 100 batch: 0.165935
Train loss on 150 batch: 0.188740
: Epoch: 16 | Training Loss: 0.189173 | Val. Loss: 0.276127 | Val. Kappa Score: 0.8878 | LR: 0.000125 | Estimated time: 44.50
Train loss on 50 batch: 0.224029
Train loss on 100 batch: 0.189031
Train loss on 150 batch: 0.155440
: Epoch: 17 | Training Loss: 0.185850 | Val. Loss: 0.270006 | Val. Kappa Score: 0.8879 | LR: 0.000125 | Estimated time: 44.92
Train loss on 50 batch: 0.175082
Train loss on 100 batch: 0.163161
Train loss on 150 batch: 0.193944
: Epoch: 18 | Training Loss: 0.178927 | Val. Loss: 0.275813 | Val. Kappa Score: 0.8885 | LR: 0.000063 | Estimated time: 44.17
Train loss on 50 batch: 0.157579
Train loss on 100 batch: 0.191695
Train loss on 150 batch: 0.181441
: Epoch: 19 | Training Loss: 0.182048 | Val. Loss: 0.269962 | Val. Kappa Score: 0.8887 | LR: 0.000063 | Estimated time: 44.86
Train loss on 50 batch: 0.176517
Train loss on 100 batch: 0.203219
Train loss on 150 batch: 0.173725
: Epoch: 20 | Training Loss: 0.184983 | Val. Loss: 0.270194 | Val. Kappa Score: 0.8889 | LR: 0.000063 | Estimated time: 44.30
Train loss on 50 batch: 0.182317
Train loss on 100 batch: 0.173129
Train loss on 150 batch: 0.179065
: Epoch: 21 | Training Loss: 0.216755 | Val. Loss: 0.269678 | Val. Kappa Score: 0.8889 | LR: 0.000031 | Estimated time: 43.83
Train loss on 50 batch: 0.179803
Train loss on 100 batch: 0.190508
Train loss on 150 batch: 0.183596
best-train-loss: 0.181632
best-valid-loss: 0.266317
best-kappa: 0.8890
: Epoch: 22 | Training Loss: 0.181632 | Val. Loss: 0.266317 | Val. Kappa Score: 0.8890 | LR: 0.000031 | Estimated time: 44.18
Train loss on 50 batch: 0.187560
Train loss on 100 batch: 0.169788
Train loss on 150 batch: 0.179355
: Epoch: 23 | Training Loss: 0.192688 | Val. Loss: 0.266984 | Val. Kappa Score: 0.8891 | LR: 0.000031 | Estimated time: 44.19
Train loss on 50 batch: 0.183410
Train loss on 100 batch: 0.174607
Train loss on 150 batch: 0.169523
best-train-loss: 0.250286
best-valid-loss: 0.266027
best-kappa: 0.8891
: Epoch: 24 | Training Loss: 0.250286 | Val. Loss: 0.266027 | Val. Kappa Score: 0.8891 | LR: 0.000031 | Estimated time: 44.27
Train loss on 50 batch: 0.157754
Train loss on 100 batch: 0.170498
Train loss on 150 batch: 0.194706
best-train-loss: 0.177554
best-valid-loss: 0.265707
best-kappa: 0.8894
: Epoch: 25 | Training Loss: 0.177554 | Val. Loss: 0.265707 | Val. Kappa Score: 0.8894 | LR: 0.000031 | Estimated time: 44.13
Train loss on 50 batch: 0.185464
Train loss on 100 batch: 0.154199
Train loss on 150 batch: 0.198757
: Epoch: 26 | Training Loss: 0.223577 | Val. Loss: 0.267916 | Val. Kappa Score: 0.8893 | LR: 0.000031 | Estimated time: 44.78
Train loss on 50 batch: 0.171892
Train loss on 100 batch: 0.205576
Train loss on 150 batch: 0.176065
: Epoch: 27 | Training Loss: 0.190587 | Val. Loss: 0.266218 | Val. Kappa Score: 0.8894 | LR: 0.000031 | Estimated time: 44.71
Train loss on 50 batch: 0.187984
Train loss on 100 batch: 0.157804
Train loss on 150 batch: 0.169096
: Epoch: 28 | Training Loss: 0.183574 | Val. Loss: 0.265888 | Val. Kappa Score: 0.8895 | LR: 0.000016 | Estimated time: 44.13
Train loss on 50 batch: 0.155991
Train loss on 100 batch: 0.174842
Train loss on 150 batch: 0.178687
: Epoch: 29 | Training Loss: 0.176491 | Val. Loss: 0.266096 | Val. Kappa Score: 0.8895 | LR: 0.000016 | Estimated time: 44.51
Train loss on 50 batch: 0.158269
Train loss on 100 batch: 0.186019
Train loss on 150 batch: 0.169061
: Epoch: 30 | Training Loss: 0.187632 | Val. Loss: 0.267896 | Val. Kappa Score: 0.8895 | LR: 0.000016 | Estimated time: 44.84
Train loss on 50 batch: 0.160612
Train loss on 100 batch: 0.186831
Train loss on 150 batch: 0.161033
: Epoch: 31 | Training Loss: 0.180165 | Val. Loss: 0.266358 | Val. Kappa Score: 0.8895 | LR: 0.000008 | Estimated time: 44.42
Train loss on 50 batch: 0.177595
Train loss on 100 batch: 0.184774
Train loss on 150 batch: 0.164153
best-train-loss: 0.168458
best-valid-loss: 0.265085
best-kappa: 0.8893
: Epoch: 32 | Training Loss: 0.168458 | Val. Loss: 0.265085 | Val. Kappa Score: 0.8893 | LR: 0.000008 | Estimated time: 44.27
Train loss on 50 batch: 0.161721
Train loss on 100 batch: 0.166543
Train loss on 150 batch: 0.159712
: Epoch: 33 | Training Loss: 0.175414 | Val. Loss: 0.267754 | Val. Kappa Score: 0.8893 | LR: 0.000008 | Estimated time: 44.47
Train loss on 50 batch: 0.151812
Train loss on 100 batch: 0.164925
Train loss on 150 batch: 0.185269
: Epoch: 34 | Training Loss: 0.164564 | Val. Loss: 0.265425 | Val. Kappa Score: 0.8892 | LR: 0.000008 | Estimated time: 44.04
Train loss on 50 batch: 0.161326
Train loss on 100 batch: 0.199312
Train loss on 150 batch: 0.163819
best-train-loss: 0.196541
best-valid-loss: 0.264419
best-kappa: 0.8891
: Epoch: 35 | Training Loss: 0.196541 | Val. Loss: 0.264419 | Val. Kappa Score: 0.8891 | LR: 0.000008 | Estimated time: 44.12
Train loss on 50 batch: 0.155298
Train loss on 100 batch: 0.189745
Train loss on 150 batch: 0.146422
: Epoch: 36 | Training Loss: 0.179408 | Val. Loss: 0.265145 | Val. Kappa Score: 0.8891 | LR: 0.000008 | Estimated time: 44.48
Train loss on 50 batch: 0.170584
Train loss on 100 batch: 0.173787
Train loss on 150 batch: 0.162627
best-train-loss: 0.178427
best-valid-loss: 0.263762
best-kappa: 0.8893
: Epoch: 37 | Training Loss: 0.178427 | Val. Loss: 0.263762 | Val. Kappa Score: 0.8893 | LR: 0.000008 | Estimated time: 44.55
Train loss on 50 batch: 0.190392
Train loss on 100 batch: 0.164911
Train loss on 150 batch: 0.177359
best-train-loss: 0.241394
best-valid-loss: 0.263612
best-kappa: 0.8895
: Epoch: 38 | Training Loss: 0.241394 | Val. Loss: 0.263612 | Val. Kappa Score: 0.8895 | LR: 0.000008 | Estimated time: 44.58
Train loss on 50 batch: 0.154685
Train loss on 100 batch: 0.171201
Train loss on 150 batch: 0.174719
best-train-loss: 0.183086
best-valid-loss: 0.263393
best-kappa: 0.8897
: Epoch: 39 | Training Loss: 0.183086 | Val. Loss: 0.263393 | Val. Kappa Score: 0.8897 | LR: 0.000008 | Estimated time: 44.90
Train loss on 50 batch: 0.195367
Train loss on 100 batch: 0.164879
Train loss on 150 batch: 0.194302
best-train-loss: 0.190361
best-valid-loss: 0.263371
best-kappa: 0.8898
: Epoch: 40 | Training Loss: 0.190361 | Val. Loss: 0.263371 | Val. Kappa Score: 0.8898 | LR: 0.000008 | Estimated time: 44.79
Train loss on 50 batch: 0.151764
Train loss on 100 batch: 0.190681
Train loss on 150 batch: 0.178948
: Epoch: 41 | Training Loss: 0.171670 | Val. Loss: 0.264406 | Val. Kappa Score: 0.8899 | LR: 0.000008 | Estimated time: 43.80
Train loss on 50 batch: 0.197413
Train loss on 100 batch: 0.148119
Train loss on 150 batch: 0.170432
: Epoch: 42 | Training Loss: 0.173345 | Val. Loss: 0.264264 | Val. Kappa Score: 0.8899 | LR: 0.000004 | Estimated time: 44.57
Train loss on 50 batch: 0.178689
Train loss on 100 batch: 0.165126
Train loss on 150 batch: 0.173375
: Epoch: 43 | Training Loss: 0.178738 | Val. Loss: 0.263592 | Val. Kappa Score: 0.8902 | LR: 0.000004 | Estimated time: 44.94
Train loss on 50 batch: 0.163044
Train loss on 100 batch: 0.165723
Train loss on 150 batch: 0.186327
: Epoch: 44 | Training Loss: 0.166880 | Val. Loss: 0.264789 | Val. Kappa Score: 0.8903 | LR: 0.000004 | Estimated time: 43.98
Train loss on 50 batch: 0.188953
Train loss on 100 batch: 0.146530
Train loss on 150 batch: 0.193249
: Epoch: 45 | Training Loss: 0.174518 | Val. Loss: 0.264337 | Val. Kappa Score: 0.8906 | LR: 0.000002 | Estimated time: 44.63
Train loss on 50 batch: 0.170792
Train loss on 100 batch: 0.173319
Train loss on 150 batch: 0.161015
: Epoch: 46 | Training Loss: 0.167408 | Val. Loss: 0.264107 | Val. Kappa Score: 0.8907 | LR: 0.000002 | Estimated time: 44.43
Train loss on 50 batch: 0.171701
Train loss on 100 batch: 0.170934
Train loss on 150 batch: 0.153206
: Epoch: 47 | Training Loss: 0.176395 | Val. Loss: 0.263660 | Val. Kappa Score: 0.8907 | LR: 0.000002 | Estimated time: 44.36
Train loss on 50 batch: 0.139241
Train loss on 100 batch: 0.171768
Train loss on 150 batch: 0.171357
: Epoch: 48 | Training Loss: 0.170575 | Val. Loss: 0.264653 | Val. Kappa Score: 0.8909 | LR: 0.000001 | Estimated time: 44.53
Train loss on 50 batch: 0.162278
Train loss on 100 batch: 0.162742
Train loss on 150 batch: 0.174685
: Epoch: 49 | Training Loss: 0.184947 | Val. Loss: 0.263778 | Val. Kappa Score: 0.8910 | LR: 0.000001 | Estimated time: 44.70
Train loss on 50 batch: 0.148422
Train loss on 100 batch: 0.183125
Train loss on 150 batch: 0.204659
: Epoch: 50 | Training Loss: 0.174900 | Val. Loss: 0.263978 | Val. Kappa Score: 0.8911 | LR: 0.000001 | Estimated time: 44.69
time_estimated: 2227.21
n-epochs: 50
time_estimated: 2227.28
